{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc43a78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otten\\AppData\\Local\\Temp\\ipykernel_18560\\519585186.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tokenized_data = torch.load(load_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# the following cell is used to load tokenized data for testing, note that this loads the train test split, not the unsplit data. Unsplit data is used for testing our \n",
    "# code parrot jupyter errors dataset and the jupyter errors dataset. To load the unsplit data, you can uncomment the lines below and comment out the above lines.\n",
    "\n",
    "# To load tokenized data, ensure the path is correct. Tokenizer as well as code to save tokenized content is in the run model file.\n",
    "\n",
    "load_path = \"dataset\\\\tokenized_content\\\\file_name.pt\"\n",
    "\n",
    "tokenized_data = torch.load(load_path)\n",
    "\n",
    "train_ids = tokenized_data['train_ids']\n",
    "test_ids = tokenized_data['test_ids']\n",
    "train_masks = tokenized_data['train_masks']\n",
    "test_masks = tokenized_data['test_masks']\n",
    "train_labels = tokenized_data['train_labels']\n",
    "test_labels = tokenized_data['test_labels']\n",
    "\n",
    "# Uncomment the lines below to load unsplit data\n",
    "# test_ids = tokenized_data['test_ids']\n",
    "# test_masks = tokenized_data['test_masks']\n",
    "# test_labels = tokenized_data['test_labels']\n",
    "\n",
    "print(\"Tokenized data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3de3d",
   "metadata": {},
   "source": [
    "The following cell contains our configuration for cell level bug detection using Flake8. Flake8 was adapted for cell-level bug detection by first decoding tokenized content and mapping each notebook cell to its corresponding line numbers, preserving the line numbering. The notebooks were then converted into Python scripts, allowing Flake8 to analyze the entire file. We considered running Flake8 on each cell individually, but this approach caused many false positives. When Flake8 detects an error, we map the errorâ€™s line number back to the corresponding cell and create a prediction array where the buggy cell is marked with a 1, and all preceding cells are marked with 0. Since Flake8 only reports up to the first fatal error it encounters without reporting subsequent errors error, subsequent cells are not considered. We trim the labels accordingly to ensure a fair comparison. If no errors are detected, the prediction array consisted entirely of 0s, indicating no buggy cells. Errors we used in our Flake8 configuration were selected to reduce false positives in bug detection avoiding things such as stylistic recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import buggy_cell_vector_evalualtion_clean\n",
    "import re\n",
    "\n",
    "# tokenizer setup for decoding\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "\n",
    "# setting up the special tokens use for finding cell boundaries in tokenized content\n",
    "start_special_tokens = [f\"<CELL_{i}>\" for i in range(1, 1024)]\n",
    "end_special_tokens = [f\"<END_CELL_{i}>\" for i in range(1, 1024)]\n",
    "all_special_tokens = start_special_tokens + end_special_tokens\n",
    "\n",
    "# Add tokens if not already in the vocabulary.\n",
    "for token in all_special_tokens:\n",
    "    if token not in tokenizer.get_vocab():\n",
    "        tokenizer.add_tokens([token])\n",
    "\n",
    "# setting up our evaluation class\n",
    "vector_eval = buggy_cell_vector_evalualtion_clean.VectorEval()\n",
    "\n",
    "###### start decode and getting line numbers\n",
    "flat_codes, flat_labels, all_cell_line_ranges = [], [], []\n",
    "\n",
    "for chunks_ids, chunks_masks, chunk_label_lists in tqdm(\n",
    "    zip(test_ids, test_masks, test_labels),\n",
    "    total=len(test_ids),\n",
    "    desc=\"Decoding & cleaning notebooks\",\n",
    "    dynamic_ncols=True,\n",
    "):\n",
    "    file_ids = chunks_ids[:4] # we use 4 because that is the same number of chunks used when evaluating JupOtter\n",
    "    chunks_label = chunk_label_lists[:4]\n",
    "  \n",
    "    flat_list = file_ids.reshape(-1).tolist() \n",
    "\n",
    "    # Decode with special tokens so they can be used to detect cell boundaries\n",
    "    decoded_with_cells = tokenizer.decode(flat_list, skip_special_tokens=False)\n",
    "\n",
    "    # Split lines to find cell boundaries in terms of line numbers\n",
    "    lines = decoded_with_cells.split('\\n')\n",
    "    cell_line_ranges = [] #this will hold tuples of (start_line, end_line) corresponding to each cell in a notebook\n",
    "    current_cell_start = None\n",
    "    \n",
    "    for idx, line in enumerate(lines):\n",
    "        if re.search(r\"<CELL_\\d+>\", line): # if the current line is a new cell\n",
    "            # Start a new cell\n",
    "            if current_cell_start is not None:\n",
    "                # Close previous cell\n",
    "                cell_line_ranges.append((current_cell_start, idx - 1))\n",
    "            current_cell_start = idx + 1  # content starts next line\n",
    "        elif re.search(r\"<END_CELL_\\d+>\", line): # if the current line is end of a cell\n",
    "            # End current cell\n",
    "            if current_cell_start is not None:\n",
    "                cell_line_ranges.append((current_cell_start, idx - 1))\n",
    "                current_cell_start = None\n",
    "    \n",
    "    # close last cell\n",
    "    if current_cell_start is not None:\n",
    "        cell_line_ranges.append((current_cell_start, len(lines) - 1))\n",
    "    \n",
    "    # remove the special tokens to get clean code\n",
    "    decoded_clean = decoded_with_cells\n",
    "    for token in tokenizer.all_special_tokens:\n",
    "        pattern = re.escape(token)\n",
    "        decoded_clean = re.sub(pattern, \"\", decoded_clean)\n",
    "    decoded_clean = re.sub(r\"<CELL_\\d+>\", \"\", decoded_clean)\n",
    "    decoded_clean = re.sub(r\"<END_CELL_\\d+>\", \"\", decoded_clean)\n",
    "    \n",
    "    flat_codes.append(decoded_clean)\n",
    "    flat_labels.append([int(item.item()) for sublist in chunks_label for item in sublist])\n",
    "\n",
    "    all_cell_line_ranges.append(cell_line_ranges)\n",
    "\n",
    "results = []\n",
    "\n",
    "tq = tqdm(\n",
    "    enumerate(zip(flat_codes, flat_labels, all_cell_line_ranges)),\n",
    "    total=len(flat_codes),\n",
    "    desc=\"Static analysis Eval\",\n",
    "    dynamic_ncols=True,\n",
    "    leave=True,\n",
    ")\n",
    "skippedNoLineNum = 0\n",
    "buggy_pred = 0\n",
    "non_buggy_pred = 0\n",
    "skipped = 0\n",
    "for i, (code, label, cell_ranges) in tq:\n",
    "    cell_level_prediction = []\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False) as tmp_file:\n",
    "        tmp_file.write(code)\n",
    "        tmp_filename = tmp_file.name\n",
    "\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [ \n",
    "                    \"flake8\",\n",
    "                    \"--select=E9,F402,F405,F406,F407,F501,F502,F503,F505,F506,F507,F508,F509,F521,F524,F525,F621,F622,F633,F701,F702,F704,F706,F707,F821,F822,F823,F831,F901\",\n",
    "                    tmp_filename\n",
    "                ],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding='utf-8' \n",
    "        )\n",
    "\n",
    "        is_buggy = 0 if result.returncode == 0 else 1\n",
    "\n",
    "        if is_buggy:\n",
    "\n",
    "            match = re.search(r\"line (\\d+)\", result.stdout) # search for line number with the error\n",
    "            match2 = re.search(r\":(\\d+):\\d+:\", result.stdout)\n",
    "            if match or match2: # if we found a line number\n",
    "                if match:\n",
    "                    line_number = int(match.group(1))\n",
    "                else:\n",
    "                    line_number = int(match2.group(1))\n",
    "\n",
    "                for i in cell_ranges: # match the line number with error to its corresponding cell all cells after error are not counted\n",
    "                    if line_number >= i[0] and line_number <= i[1]:\n",
    "                        cell_level_prediction.append(1)\n",
    "                        break\n",
    "                    else:\n",
    "                        cell_level_prediction.append(0)\n",
    "                \n",
    "            else: # if buggy but could not find a line number\n",
    "                skippedNoLineNum += 1                                                                                        \n",
    "            buggy_pred += 1 \n",
    "        else:\n",
    "            non_buggy_pred += 1\n",
    "            for i in cell_ranges:\n",
    "                cell_level_prediction.append(0) # no buggy predictions, so make array of 0s indicating no bugs in any cells\n",
    "\n",
    "        vector_eval.eval_vector(cell_level_prediction, label[:len(cell_level_prediction)]) # cell level prediction needs to be trimmed because it cant detect errors after the first one it finds\n",
    "        results.append((cell_level_prediction, label))\n",
    "    except subprocess.TimeoutExpired:\n",
    "        skipped += 1\n",
    "        print(f\"Skipped file {tmp_filename} due to timeout.\")\n",
    "        continue  # skip this file and move on\n",
    "\n",
    "    os.remove(tmp_filename)\n",
    " \n",
    "    \n",
    "    # live metrics, only used to display in the tqdm bar\n",
    "    preds_so_far = results[-1][0]  # Get the last prediction\n",
    "    labels_so_far = results[-1][1]  # Get the last label\n",
    "    if preds_so_far != []:\n",
    "        f1 = f1_score(labels_so_far[:len(preds_so_far)], preds_so_far, zero_division=0)\n",
    "        acc = accuracy_score(labels_so_far[:len(preds_so_far)], preds_so_far)  # Ensure preds_so_far is trimmed to match labels_so_far\n",
    "        tq.set_postfix({'F1': f\"{f1:.3f}\", 'Acc': f\"{acc:.3f}\", 'Recall': f\"{recall_score(labels_so_far[:len(preds_so_far)], preds_so_far, zero_division=0):.3f}\"})\n",
    "        tq.refresh()  #update tqdm bar\n",
    "\n",
    "vector_eval.print_results()\n",
    "vector_eval.reset()\n",
    "\n",
    "# Evaluate\n",
    "correct = sum([pred == true for pred, true in results])\n",
    "total = len(results)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\nFile-level Bug Detection via Flake8 completed.\")\n",
    "print(f\"Skipped {skipped} files due to timeout.\")\n",
    "print(f\"Skipped {skippedNoLineNum} files due to no line number found in error message.\")\n",
    "print(f\"Buggy predictions: {buggy_pred}, Non-buggy predictions: {non_buggy_pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
