{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from simpledbf import Dbf5\n",
    "import os\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_pyth(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate the distance between two points \"\"\"\n",
    "    return np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
    "\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def p_dist(lon1, lat1, lon2, lat2, units=None):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two *CLOSE* points in meters using Pythagoras\n",
    "    \"\"\"\n",
    "    if units == 'm':\n",
    "        dist = dist_pyth(lon1, lat1, lon2, lat2)\n",
    "    elif units == 'deg':\n",
    "        dist = haversine(lon1, lat1, lon2, lat2)\n",
    "    else:\n",
    "        raise ValueError('Units must be meters (m) or degrees (deg).')\n",
    "        \n",
    "    return dist\n",
    "\n",
    "\n",
    "def p_thin(df, xcol='x', ycol='y', datacols='data', radius=10, method='nanmean', units=None):\n",
    "    \"\"\"\n",
    "    Thin a pandas point series based on distance of the points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pseries: Series of points\n",
    "    xcol: name of column with x coordinates\n",
    "    ycol: name of columns with y coordinates\n",
    "    datacol: name fo columns with data\n",
    "    radius: search radius for point distance\n",
    "    method: calculation method (a numpy method). Default: 'nanmean'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A thinned dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert units!=None,'Units must be meters (m) or degrees (deg).'\n",
    "    \n",
    "    thinned = pd.DataFrame([],columns=df.columns.values)\n",
    "    \n",
    "    print(len(df))\n",
    "    ct=0\n",
    "    while len(df)>0:\n",
    "        df['DIST'] = p_dist(df[xcol].iloc[0], df[ycol].iloc[0], df[xcol], df[ycol], units=units)\n",
    "        df = df.sort_values('DIST')\n",
    "\n",
    "        subset = df[df.DIST <= radius]\n",
    "        \n",
    "        if not subset.empty:\n",
    "            subset = subset.reset_index()\n",
    "            fill_dict = {}\n",
    "            fill_dict[xcol] = subset.loc[int(len(subset)/2), xcol]\n",
    "            fill_dict[ycol] = subset.loc[int(len(subset)/2), ycol]\n",
    "            for data in datacols:\n",
    "                try:\n",
    "                    fill_dict[data] = getattr(np,method)(subset[data].values)\n",
    "                except TypeError:\n",
    "                    fill_dict[data] = np.nan\n",
    "            thinned.loc[len(thinned)] = pd.Series(fill_dict)\n",
    "            ct+=1\n",
    "\n",
    "            if ct%100==0:\n",
    "                print(ct, len(df))\n",
    "        # delete the used points from the data\n",
    "        df = df.drop(df[df.DIST <= radius].index.values)\n",
    "        \n",
    "    print(len(thinned))\n",
    "    return thinned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlaThiDa templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templ_t = pd.read_excel('C:\\\\Users\\\\jlandman\\\\Desktop\\\\GlaThiDa_2-0_DataSubmissionForm_for_pandas.xls', sheetname='T - GLACIER THICKNESS OVERVIEW') \n",
    "templ_tt = pd.read_excel('C:\\\\Users\\\\jlandman\\\\Desktop\\\\GlaThiDa_2-0_DataSubmissionForm_for_pandas.xls', sheetname='TT - GL. THICKNESS DISTRIBUTION')\n",
    "templ_ttt = pd.read_excel('C:\\\\Users\\\\jlandman\\\\Desktop\\\\GlaThiDa_2-0_DataSubmissionForm_for_pandas.xls', sheetname='TTT - GL. THICKNESS POINT DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New GlaThiDa IDs for the treated glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gtd_ids = {'brewster': 2077,\n",
    "          'north': 2078,\n",
    "          'south':2079,\n",
    "          'starbuck_gprt':2080,\n",
    "          'starbuck_icebr':2081,\n",
    "          'tasman': 2082,\n",
    "          'urumqui':2083,\n",
    "          'west_washmawapta':2084}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brewster glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nzgd = pyproj.Proj(init='epsg:2193') # NZGD2000_New_Zealand_Transverse_Mercator_2000\n",
    "latlon = pyproj.Proj(init='epsg:4326')  #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "brew = {'punit': 'NZ',\n",
    "'gname': 'BREWSTER',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '19979999',\n",
    "'dem_date': '19860399',\n",
    "'gid': gtd_ids['brewster'],\n",
    "'lat': -44.07,\n",
    "'lon': 169.43,\n",
    "'area': 2.62,\n",
    "'mean_sl': 15,\n",
    "'mean_th': np.nan,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': np.nan,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'GPRt',\n",
    "'surv_meth_det': '',\n",
    "'no_points': 588,\n",
    "'no_prfls': 4,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'',\n",
    "'investig':'Bob JACOBEL and Ian OWENS; compiled by Brian ANDERSON',\n",
    "'spons_ag':'',\n",
    "'ref':'Willis, I. et al. (2009). Hydrological Processes, 23(3), p.384-396. DOI: 10.1002/hyp.7146',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Source_ID: Outline and DEM from aerial photography for the NZMS260 mapping series flown in 3/1986. Lat/lon from WGMS FoG2015. Data unpublished, but used in given reference. Mean slope calculated from DEM by WGMS.',\n",
    "'remarks_ttt':''\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brewster_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\brewster\\\\brewster_jacobel_owens_bed_xyz.csv'\n",
    "\n",
    "# read original data\n",
    "brew_dat = pd.read_csv(brewster_path)\n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = brew_dat['nztm_easting (m)'].values\n",
    "ys = brew_dat[' nztm_northing (m)'].values\n",
    "x1,y1 = nzgd(xs, ys)\n",
    "lons, lats = pyproj.transform(nzgd,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "brew_t = templ_t.copy()\n",
    "brew_t.loc[0,'GlaThiDa_ID'] = brew['gid']\n",
    "brew_t.loc[0,'POLITICAL_UNIT'] = brew['punit']\n",
    "brew_t.loc[0,'GLACIER_NAME'] = brew['gname']\n",
    "brew_t.loc[0,'SOURCE_ID'] = brew['src_id']\n",
    "brew_t.loc[0,'GLACIER_ID'] = brew['src_g_id']\n",
    "brew_t.loc[0,'LAT'] = brew['lat']\n",
    "brew_t.loc[0,'LON'] = brew['lon']\n",
    "brew_t.loc[0,'SURVEY_DATE'] = brew['survey_date']\n",
    "brew_t.loc[0,'DEM_DATE'] = brew['dem_date']\n",
    "brew_t.loc[0,'AREA'] = brew['area']\n",
    "brew_t.loc[0,'MEAN_SLOPE'] = brew['mean_sl']\n",
    "brew_t.loc[0,'MEAN_THICKNESS'] = brew['mean_th']\n",
    "brew_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = brew['mean_th_unc']\n",
    "brew_t.loc[0,'MAXIMUM_THICKNESS'] = brew['max_th']\n",
    "brew_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = brew['max_th_unc']\n",
    "brew_t.loc[0,'SURVEY_METHOD'] = brew['surv_meth']\n",
    "brew_t.loc[0,'SURVEY_METHOD_DETAILS'] = brew['surv_meth_det']\n",
    "brew_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = brew['no_points']\n",
    "brew_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = brew['no_prfls']\n",
    "brew_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = brew['length_prfls']\n",
    "brew_t.loc[0,'INTERPOLATION_METHOD'] = brew['interp_meth']\n",
    "brew_t.loc[0,'INVESTIGATOR'] = brew['investig']\n",
    "brew_t.loc[0,'SPONSORING_AGENCY'] = brew['spons_ag']\n",
    "brew_t.loc[0,'REFERENCES'] = brew['ref']\n",
    "brew_t.loc[0,'DATA_FLAG'] = brew['dflag']\n",
    "brew_t.loc[0,'REMARKS'] = brew['remarks_t']\n",
    "\n",
    "\n",
    "# fill TTT table\n",
    "brew_ttt = templ_ttt.copy()\n",
    "brew_ttt['POINT_ID'] = range(1,len(brew_dat)+1)\n",
    "brew_ttt['POINT_LAT'] = lats\n",
    "brew_ttt['POINT_LON'] = lons\n",
    "brew_ttt['ELEVATION'] = brew_dat[' surface_elevation (m asl)'].round()\n",
    "brew_ttt['THICKNESS'] = brew_dat[' ice_thickness (m)'].round()\n",
    "brew_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "brew_ttt['GlaThiDa_ID'] = brew['gid']\n",
    "brew_ttt['POLITICAL_UNIT'] = brew['punit']\n",
    "brew_ttt['GLACIER_NAME'] = brew['gname']\n",
    "brew_ttt['SURVEY_DATE'] = brew['survey_date']\n",
    "brew_ttt['DATA_FLAG'] = brew['dflag']\n",
    "brew_ttt['REMARKS'] = brew['remarks_ttt'] \n",
    "\n",
    "brew_t = brew_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "brew_ttt = brew_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "brew_t.to_excel(os.path.join(os.path.dirname(brewster_path),brewster_path.split('.')[0]+'_Johannes_T.xls'), index=False)\n",
    "brew_ttt.to_excel(os.path.join(os.path.dirname(brewster_path),brewster_path.split('.')[0]+'_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utm7n = pyproj.Proj(init='epsg:32607') # UTM 7N (WGS84)\n",
    "latlon = pyproj.Proj(init='epsg:4326')  #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "north = {'punit': 'CA',\n",
    "'gname': 'NORTH',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20119999',\n",
    "'dem_date': '20079999',\n",
    "'gid': gtd_ids['north'],\n",
    "'lat': 60.911031,\n",
    "'lon': -139.150803,\n",
    "'area': 6.9,\n",
    "'mean_sl': np.nan,\n",
    "'mean_th': np.nan,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': np.nan,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'OTH',\n",
    "'surv_meth_det': 'Radar sounding data at center frequencies of 10, 35, and 50MHz were collected using the ice-penetrating radar system described by Mingo and Flowers [2010].',\n",
    "'no_points': 7277,\n",
    "'no_prfls': np.nan,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'KRG',\n",
    "'investig':'Nat WILSON, Glenn FLOWERS, Laurent MINGO',\n",
    "'spons_ag':'',\n",
    "'ref':'Wilson, N. J., Flowers, G. E., & Mingo, L. (2013). Journal of Geophysical Research: Earth Surface, 118(3), pp.1443-1459. DOI:10.1002/jgrf.20096',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Lat/lon from Google Earth. Survey methods: GPRt and DRIh',\n",
    "'remarks_ttt':''\n",
    "       }\n",
    "\n",
    "#thin_value_north = 7\n",
    "search_dist_north = 10  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7278\n",
      "100 6980\n",
      "200 6740\n",
      "300 6508\n",
      "400 6299\n",
      "500 6073\n",
      "600 5815\n",
      "700 5576\n",
      "800 5173\n",
      "900 4839\n",
      "1000 4567\n",
      "1100 4344\n",
      "1200 4090\n",
      "1300 3826\n",
      "1400 3581\n",
      "1500 3296\n",
      "1600 2946\n",
      "1700 2698\n",
      "1800 2452\n",
      "1900 2231\n",
      "2000 2001\n",
      "2100 1773\n",
      "2200 1527\n",
      "2300 1342\n",
      "2400 1059\n",
      "2500 777\n",
      "2600 530\n",
      "2700 318\n",
      "2800 34\n",
      "2816\n"
     ]
    }
   ],
   "source": [
    "north_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\north_and_south_glacier\\\\depth_GL2_080911.xyz'\n",
    "\n",
    "# read original data\n",
    "north_dat = pd.read_csv(north_path, header=None, sep='\\t') # 0:easting (m), 1:northing (m), 2:depth (m), 3:estimated picking error (m) \n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = north_dat[0].values\n",
    "ys = north_dat[1].values\n",
    "x1,y1 = utm7n(xs, ys)\n",
    "lons, lats = pyproj.transform(utm7n,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "north_t = templ_t.copy()\n",
    "north_t.loc[0,'GlaThiDa_ID'] = north['gid']\n",
    "north_t.loc[0,'POLITICAL_UNIT'] = north['punit']\n",
    "north_t.loc[0,'GLACIER_NAME'] = north['gname']\n",
    "north_t.loc[0,'SOURCE_ID'] = north['src_id']\n",
    "north_t.loc[0,'GLACIER_ID'] = north['src_g_id']\n",
    "north_t.loc[0,'LAT'] = north['lat']\n",
    "north_t.loc[0,'LON'] = north['lon']\n",
    "north_t.loc[0,'SURVEY_DATE'] = north['survey_date']\n",
    "north_t.loc[0,'DEM_DATE'] = north['dem_date']\n",
    "north_t.loc[0,'AREA'] = north['area']\n",
    "north_t.loc[0,'MEAN_SLOPE'] = north['mean_sl']\n",
    "north_t.loc[0,'MEAN_THICKNESS'] = north['mean_th']\n",
    "north_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = north['mean_th_unc']\n",
    "north_t.loc[0,'MAXIMUM_THICKNESS'] = north['max_th']\n",
    "north_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = north['max_th_unc']\n",
    "north_t.loc[0,'SURVEY_METHOD'] = north['surv_meth']\n",
    "north_t.loc[0,'SURVEY_METHOD_DETAILS'] = north['surv_meth_det']\n",
    "north_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = north['no_points']\n",
    "north_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = north['no_prfls']\n",
    "north_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = north['length_prfls']\n",
    "north_t.loc[0,'INTERPOLATION_METHOD'] = north['interp_meth']\n",
    "north_t.loc[0,'INVESTIGATOR'] = north['investig']\n",
    "north_t.loc[0,'SPONSORING_AGENCY'] = north['spons_ag']\n",
    "north_t.loc[0,'REFERENCES'] = north['ref']\n",
    "north_t.loc[0,'DATA_FLAG'] = north['dflag']\n",
    "north_t.loc[0,'REMARKS'] = north['remarks_t']\n",
    "\n",
    "\n",
    "# fill TTT table and thin data\n",
    "north_ttt = templ_ttt.copy()\n",
    "north_ttt['POINT_LAT'] = lats\n",
    "north_ttt['POINT_LON'] = lons\n",
    "north_ttt['ELEVATION'] = np.nan\n",
    "north_ttt['THICKNESS'] = (north_dat[2]).astype(np.float64)\n",
    "north_ttt['THICKNESS_UNCERTAINTY'] = (north_dat[3]).astype(np.float64)\n",
    "# old point thinning\n",
    "#north_ttt = north_ttt.groupby(north_ttt.index // thin_value_north).mean() # average over every x values as specified above\n",
    "# thin the data and filter \"mean on empyt slice\" warnings (in case there is no elevation)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    north_ttt = p_thin(north_ttt, xcol='POINT_LON', ycol='POINT_LAT', datacols=['ELEVATION', 'THICKNESS', \n",
    "                                                                                'THICKNESS_UNCERTAINTY'], \n",
    "                       radius=search_dist_north, method='nanmean', units='deg')\n",
    "north_ttt['POINT_ID'] = range(1,len(north_ttt)+1)\n",
    "north_ttt['GlaThiDa_ID'] = north['gid']\n",
    "north_ttt['POLITICAL_UNIT'] = north['punit']\n",
    "north_ttt['GLACIER_NAME'] = north['gname']\n",
    "north_ttt['SURVEY_DATE'] = north['survey_date']\n",
    "north_ttt['DATA_FLAG'] = north['dflag']\n",
    "north_ttt['REMARKS'] = north['remarks_ttt'] + ' Point data have been thinned (mean) within a search distance of %s m.' % search_dist_north\n",
    "\n",
    "# do the reformatting again (doesn't work in combination with astype)\n",
    "north_ttt['THICKNESS'] = north_ttt['THICKNESS'].round()\n",
    "north_ttt['THICKNESS_UNCERTAINTY'] = north_ttt['THICKNESS_UNCERTAINTY'].round(2)\n",
    "\n",
    "north_t = north_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "north_ttt = north_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "north_t.to_excel(os.path.join(os.path.dirname(north_path),north_path.split('.')[0]+'_Johannes_T.xls'), index=False)\n",
    "north_ttt.to_excel(os.path.join(os.path.dirname(north_path),north_path.split('.')[0]+'_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utm7n = pyproj.Proj(init='epsg:32607') # UTM 7N (WGS84)\n",
    "latlon = pyproj.Proj(init='epsg:4326') #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "south = {'punit': 'CA',\n",
    "'gname': 'SOUTH',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20119999',\n",
    "'dem_date': '20079999',\n",
    "'gid': gtd_ids['south'],\n",
    "'lat': 60.817771,\n",
    "'lon': -139.124004,\n",
    "'area': 5.3,\n",
    "'mean_sl': np.nan,\n",
    "'mean_th': np.nan,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': np.nan,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'OTH',\n",
    "'surv_meth_det': 'Radar sounding data at center frequencies of 10, 35, and 50MHz were collected using the ice-penetrating radar system described by Mingo and Flowers [2010].',\n",
    "'no_points': 9618,\n",
    "'no_prfls': np.nan,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'KRG',\n",
    "'investig':'Nat WILSON, Glenn FLOWERS, Laurent MINGO',\n",
    "'spons_ag':'',\n",
    "'ref':'Wilson, N. J., Flowers, G. E., & Mingo, L. (2013). Journal of Geophysical Research: Earth Surface, 118(3), pp.1443-1459. DOI:10.1002/jgrf.20096',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Lat/lon from Google Earth. Survey methods: GPRt and DRIh',\n",
    "'remarks_ttt':''\n",
    "       }\n",
    "\n",
    "search_dist_south = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9619\n",
      "100 9347\n",
      "200 9125\n",
      "300 8840\n",
      "400 8535\n",
      "500 8158\n",
      "600 7821\n",
      "700 7517\n",
      "800 7212\n",
      "900 6900\n",
      "1000 6674\n",
      "1100 6371\n",
      "1200 6039\n",
      "1300 5807\n",
      "1400 5525\n",
      "1500 5357\n",
      "1600 5126\n",
      "1700 4758\n",
      "1800 4445\n",
      "1900 4187\n",
      "2000 3875\n",
      "2100 3599\n",
      "2200 3331\n",
      "2300 3082\n",
      "2400 2797\n",
      "2500 2524\n",
      "2600 2269\n",
      "2700 1848\n",
      "2800 1666\n",
      "2900 1403\n",
      "3000 1152\n",
      "3100 883\n",
      "3200 610\n",
      "3300 311\n",
      "3400 71\n",
      "3422\n"
     ]
    }
   ],
   "source": [
    "south_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\north_and_south_glacier\\\\depth_GL1_080911.xyz'\n",
    "\n",
    "# read original data\n",
    "south_dat = pd.read_csv(south_path, header=None, sep='\\t') # 0:easting (m), 1:northing (m), 2:depth (m), 3:estimated picking error (m) \n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = south_dat[0].values\n",
    "ys = south_dat[1].values\n",
    "x1,y1 = utm7n(xs, ys)\n",
    "lons, lats = pyproj.transform(utm7n,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "south_t = templ_t.copy()\n",
    "south_t.loc[0,'GlaThiDa_ID'] = south['gid']\n",
    "south_t.loc[0,'POLITICAL_UNIT'] = south['punit']\n",
    "south_t.loc[0,'GLACIER_NAME'] = south['gname']\n",
    "south_t.loc[0,'SOURCE_ID'] = south['src_id']\n",
    "south_t.loc[0,'GLACIER_ID'] = south['src_g_id']\n",
    "south_t.loc[0,'LAT'] = south['lat']\n",
    "south_t.loc[0,'LON'] = south['lon']\n",
    "south_t.loc[0,'SURVEY_DATE'] = south['survey_date']\n",
    "south_t.loc[0,'DEM_DATE'] = south['dem_date']\n",
    "south_t.loc[0,'AREA'] = south['area']\n",
    "south_t.loc[0,'MEAN_SLOPE'] = south['mean_sl']\n",
    "south_t.loc[0,'MEAN_THICKNESS'] = south['mean_th']\n",
    "south_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = south['mean_th_unc']\n",
    "south_t.loc[0,'MAXIMUM_THICKNESS'] = south['max_th']\n",
    "south_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = south['max_th_unc']\n",
    "south_t.loc[0,'SURVEY_METHOD'] = south['surv_meth']\n",
    "south_t.loc[0,'SURVEY_METHOD_DETAILS'] = south['surv_meth_det']\n",
    "south_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = south['no_points']\n",
    "south_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = south['no_prfls']\n",
    "south_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = south['length_prfls']\n",
    "south_t.loc[0,'INTERPOLATION_METHOD'] = south['interp_meth']\n",
    "south_t.loc[0,'INVESTIGATOR'] = south['investig']\n",
    "south_t.loc[0,'SPONSORING_AGENCY'] = south['spons_ag']\n",
    "south_t.loc[0,'REFERENCES'] = south['ref']\n",
    "south_t.loc[0,'DATA_FLAG'] = south['dflag']\n",
    "south_t.loc[0,'REMARKS'] = south['remarks_t']\n",
    "\n",
    "\n",
    "# fill TTT table and thin data\n",
    "south_ttt = templ_ttt.copy()\n",
    "south_ttt['POINT_ID'] = range(1,len(south_dat)+1)\n",
    "south_ttt['POINT_LAT'] = lats\n",
    "south_ttt['POINT_LON'] = lons\n",
    "south_ttt['ELEVATION'] = np.nan\n",
    "south_ttt['THICKNESS'] = (south_dat[2]).astype(np.float64)\n",
    "south_ttt['THICKNESS_UNCERTAINTY'] = (south_dat[3]).astype(np.float64)\n",
    "\n",
    "# old point thinning \n",
    "# south_ttt = south_ttt.groupby(south_ttt.index // thin_value_south).mean() # average over every x values as specified above\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    south_ttt = p_thin(south_ttt, xcol='POINT_LON', ycol='POINT_LAT', datacols=['ELEVATION', 'THICKNESS', \n",
    "                                                                                'THICKNESS_UNCERTAINTY'], \n",
    "                       radius=search_dist_south, method='nanmean', units='deg')\n",
    "south_ttt['GlaThiDa_ID'] = south['gid']\n",
    "south_ttt['POLITICAL_UNIT'] = south['punit']\n",
    "south_ttt['GLACIER_NAME'] = south['gname']\n",
    "south_ttt['SURVEY_DATE'] = south['survey_date']\n",
    "south_ttt['DATA_FLAG'] = south['dflag']\n",
    "south_ttt['REMARKS'] = south['remarks_ttt'] \n",
    "\n",
    "# do the reformatting again (doesn't work in combination with astype)\n",
    "south_ttt['THICKNESS'] = south_ttt['THICKNESS'].round()\n",
    "south_ttt['THICKNESS_UNCERTAINTY'] = south_ttt['THICKNESS_UNCERTAINTY'].round(2)\n",
    "south_t = south_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "south_ttt = south_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "south_t.to_excel(os.path.join(os.path.dirname(south_path),south_path.split('.')[0]+'_Johannes_T.xls'), index=False)\n",
    "south_ttt.to_excel(os.path.join(os.path.dirname(south_path),south_path.split('.')[0]+'_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbuck glacier GPRt and ICEBRIDGE measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbuck GPRt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aqps = pyproj.Proj(init='epsg:3031') # Antarctica polar stereographic\n",
    "latlon = pyproj.Proj(init='epsg:4326')  #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "starb = {'punit': 'AQ',\n",
    "'gname': 'STARBUCK',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20121299',\n",
    "'dem_date': '20079999',\n",
    "'gid': gtd_ids['starbuck_gprt'],\n",
    "'lat': -65.614439,\n",
    "'lon': -62.418465,\n",
    "'area': 258,\n",
    "'mean_sl': np.nan,\n",
    "'mean_th': 312,\n",
    "'mean_th_unc': 30,\n",
    "'max_th': 1020,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'GPRt',\n",
    "'surv_meth_det': 'Deep-Look Radio-Echo Sounder (DELORES), 1-4 MHz range (3MHz central frequ.)',\n",
    "'no_points': 1315,\n",
    "'no_prfls': 41,\n",
    "'length_prfls': 90,\n",
    "'interp_meth':'',\n",
    "'investig':'Daniel FARINOTTI and colleagues',\n",
    "'spons_ag':'',\n",
    "'ref':'Farinotti, D. et al. (2014). Annals of Glaciology, 55(67), pp. 22-28. DOI:10.3189/2014AoG67A025',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Lat/lon from Google Earth. DEM from Cook et al. (2012) (doi: 10.5194/essd-4-129-2012)',\n",
    "'remarks_ttt':''\n",
    "       }\n",
    "\n",
    "search_dist_starbuck = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315\n",
      "100 1216\n",
      "200 1116\n",
      "300 1016\n",
      "400 916\n",
      "500 816\n",
      "600 716\n",
      "700 613\n",
      "800 512\n",
      "900 412\n",
      "1000 311\n",
      "1100 210\n",
      "1200 109\n",
      "1300 9\n",
      "1308\n"
     ]
    }
   ],
   "source": [
    "starb_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\starbuck\\\\starbuck_RES_data_including_MCoRDS.txt'\n",
    "\n",
    "# read original data\n",
    "starb_dat = pd.read_csv(starb_path, comment='#', delim_whitespace=True) \n",
    "\n",
    "# select here the GPRt measurements\n",
    "starb_dat = starb_dat[starb_dat.orgnm != 'icebridge']\n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = starb_dat['lon'].values\n",
    "ys = starb_dat['lat'].values\n",
    "x1,y1 = aqps(xs, ys)\n",
    "lons, lats = pyproj.transform(aqps,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "starb_t = templ_t.copy()\n",
    "starb_t.loc[0,'GlaThiDa_ID'] = starb['gid']\n",
    "starb_t.loc[0,'POLITICAL_UNIT'] = starb['punit']\n",
    "starb_t.loc[0,'GLACIER_NAME'] = starb['gname']\n",
    "starb_t.loc[0,'SOURCE_ID'] = starb['src_id']\n",
    "starb_t.loc[0,'GLACIER_ID'] = starb['src_g_id']\n",
    "starb_t.loc[0,'LAT'] = starb['lat']\n",
    "starb_t.loc[0,'LON'] = starb['lon']\n",
    "starb_t.loc[0,'SURVEY_DATE'] = starb['survey_date']\n",
    "starb_t.loc[0,'DEM_DATE'] = starb['dem_date']\n",
    "starb_t.loc[0,'AREA'] = starb['area']\n",
    "starb_t.loc[0,'MEAN_SLOPE'] = starb['mean_sl']\n",
    "starb_t.loc[0,'MEAN_THICKNESS'] = starb['mean_th']\n",
    "starb_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = starb['mean_th_unc']\n",
    "starb_t.loc[0,'MAXIMUM_THICKNESS'] = starb['max_th']\n",
    "starb_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = starb['max_th_unc']\n",
    "starb_t.loc[0,'SURVEY_METHOD'] = starb['surv_meth']\n",
    "starb_t.loc[0,'SURVEY_METHOD_DETAILS'] = starb['surv_meth_det']\n",
    "starb_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = starb['no_points']\n",
    "starb_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = starb['no_prfls']\n",
    "starb_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = starb['length_prfls']\n",
    "starb_t.loc[0,'INTERPOLATION_METHOD'] = starb['interp_meth']\n",
    "starb_t.loc[0,'INVESTIGATOR'] = starb['investig']\n",
    "starb_t.loc[0,'SPONSORING_AGENCY'] = starb['spons_ag']\n",
    "starb_t.loc[0,'REFERENCES'] = starb['ref']\n",
    "starb_t.loc[0,'DATA_FLAG'] = starb['dflag']\n",
    "starb_t.loc[0,'REMARKS'] = starb['remarks_t']\n",
    "\n",
    "\n",
    "# fill TTT table\n",
    "starb_ttt = templ_ttt.copy()\n",
    "starb_ttt['POINT_LAT'] = lats\n",
    "starb_ttt['POINT_LON'] = lons\n",
    "starb_ttt['ELEVATION'] = starb_dat['z_surf']\n",
    "starb_ttt['THICKNESS'] = starb_dat['ice_th']\n",
    "starb_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    starb_ttt = p_thin(starb_ttt, xcol='POINT_LON', ycol='POINT_LAT', datacols=['ELEVATION', 'THICKNESS',\n",
    "                                                                                'THICKNESS_UNCERTAINTY'], \n",
    "                       radius=search_dist_starbuck, method='nanmean', units='deg')\n",
    "\n",
    "starb_ttt['THICKNESS'] = starb_ttt['THICKNESS'].round()\n",
    "starb_ttt['THICKNESS_UNCERTAINTY'] = starb_ttt['THICKNESS_UNCERTAINTY'].round()\n",
    "starb_ttt['ELEVATION'] = starb_ttt['ELEVATION'].round()\n",
    "starb_ttt['POINT_ID'] = range(1,len(starb_ttt)+1)\n",
    "starb_ttt['GlaThiDa_ID'] = starb['gid']\n",
    "starb_ttt['POLITICAL_UNIT'] = starb['punit']\n",
    "starb_ttt['GLACIER_NAME'] = starb['gname']\n",
    "starb_ttt['SURVEY_DATE'] = starb['survey_date']\n",
    "starb_ttt['DATA_FLAG'] = starb['dflag']\n",
    "starb_ttt['REMARKS'] = starb['remarks_ttt'] + ' Point data have been thinned (mean) within a search distance of %s m.' % search_dist_starbuck\n",
    "starb_t = starb_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "starb_ttt = starb_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "starb_t.to_excel(os.path.join(os.path.dirname(starb_path),starb_path.split('.')[0]+'_GPRt_Johannes_T.xls'), index=False)\n",
    "starb_ttt.to_excel(os.path.join(os.path.dirname(starb_path),starb_path.split('.')[0]+'_GPRt_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbuck glacier ICEBRIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "starb_i = {'punit': 'AQ',\n",
    "'gname': 'STARBUCK',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20111014',\n",
    "'dem_date': '20079999',\n",
    "'gid': gtd_ids['starbuck_icebr'],\n",
    "'lat': -65.614439,\n",
    "'lon': -62.418465,\n",
    "'area': 258,\n",
    "'mean_sl': np.nan,\n",
    "'mean_th': np.nan,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': np.nan,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'OTH',\n",
    "'surv_meth_det': 'Deep-Look Radio-Echo Sounder (DELORES), 1-4 MHz range (3MHz central frequ.)',\n",
    "'no_points': 103,\n",
    "'no_prfls': np.nan,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'',\n",
    "'investig':'',\n",
    "'spons_ag':'',\n",
    "'ref':'Farinotti, D. et al. (2014). Annals of Glaciology, 55(67), pp. 22-28. DOI:10.3189/2014AoG67A025',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Survey Method: NASA IceBridge project (MCoRDS sensor). Data used as base for cross-validation in given reference. DEM from Cook et al. (2012) (doi: 10.5194/essd-4-129-2012)',\n",
    "'remarks_ttt':''\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pn         lon         lat  z_surf  ice_th  qGPS      orgnm\n",
      "1315  42 -2379060.68  1247358.92   459.9   101.0     1  icebridge\n",
      "1316  42 -2379126.81  1247461.36   454.4   179.2     1  icebridge\n",
      "1317  42 -2379192.66  1247564.34   453.2   270.1     1  icebridge\n",
      "1318  42 -2379258.07  1247667.41   451.8   344.4     1  icebridge\n",
      "1319  42 -2379323.15  1247770.63   450.3   436.4     1  icebridge\n",
      "  GlaThiDa_ID POLITICAL_UNIT GLACIER_NAME SURVEY_DATE  POINT_ID  POINT_LAT  \\\n",
      "0         NaN            NaN          NaN         NaN         1 -65.635913   \n",
      "1         NaN            NaN          NaN         NaN         2 -65.634978   \n",
      "2         NaN            NaN          NaN         NaN         3 -65.634043   \n",
      "3         NaN            NaN          NaN         NaN         4 -65.633111   \n",
      "4         NaN            NaN          NaN         NaN         5 -65.632181   \n",
      "\n",
      "   POINT_LON  ELEVATION  THICKNESS THICKNESS_UNCERTAINTY DATA_FLAG REMARKS  \n",
      "0 -62.331649      460.0      101.0                   NaN       NaN     NaN  \n",
      "1 -62.330368      454.0      179.0                   NaN       NaN     NaN  \n",
      "2 -62.329075      453.0      270.0                   NaN       NaN     NaN  \n",
      "3 -62.327777      452.0      344.0                   NaN       NaN     NaN  \n",
      "4 -62.326472      450.0      436.0                   NaN       NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "starb_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\starbuck\\\\starbuck_RES_data_including_MCoRDS.txt'\n",
    "\n",
    "# read original data\n",
    "starb_i_dat = pd.read_csv(starb_path, comment='#', delim_whitespace=True) \n",
    "\n",
    "# select here the GPRt measurements\n",
    "starb_i_dat = starb_i_dat[starb_i_dat.orgnm == 'icebridge']\n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = starb_i_dat['lon'].values\n",
    "ys = starb_i_dat['lat'].values\n",
    "x1,y1 = aqps(xs, ys)\n",
    "lons, lats = pyproj.transform(aqps,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "starb_i_t = templ_t.copy()\n",
    "starb_i_t.loc[0,'GlaThiDa_ID'] = starb_i['gid']\n",
    "starb_i_t.loc[0,'POLITICAL_UNIT'] = starb_i['punit']\n",
    "starb_i_t.loc[0,'GLACIER_NAME'] = starb_i['gname']\n",
    "starb_i_t.loc[0,'SOURCE_ID'] = starb_i['src_id']\n",
    "starb_i_t.loc[0,'GLACIER_ID'] = starb_i['src_g_id']\n",
    "starb_i_t.loc[0,'LAT'] = starb_i['lat']\n",
    "starb_i_t.loc[0,'LON'] = starb_i['lon']\n",
    "starb_i_t.loc[0,'SURVEY_DATE'] = starb_i['survey_date']\n",
    "starb_i_t.loc[0,'DEM_DATE'] = starb_i['dem_date']\n",
    "starb_i_t.loc[0,'AREA'] = starb_i['area']\n",
    "starb_i_t.loc[0,'MEAN_SLOPE'] = starb_i['mean_sl']\n",
    "starb_i_t.loc[0,'MEAN_THICKNESS'] = starb_i['mean_th']\n",
    "starb_i_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = starb_i['mean_th_unc']\n",
    "starb_i_t.loc[0,'MAXIMUM_THICKNESS'] = starb_i['max_th']\n",
    "starb_i_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = starb_i['max_th_unc']\n",
    "starb_i_t.loc[0,'SURVEY_METHOD'] = starb_i['surv_meth']\n",
    "starb_i_t.loc[0,'SURVEY_METHOD_DETAILS'] = starb_i['surv_meth_det']\n",
    "starb_i_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = starb_i['no_points']\n",
    "starb_i_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = starb_i['no_prfls']\n",
    "starb_i_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = starb_i['length_prfls']\n",
    "starb_i_t.loc[0,'INTERPOLATION_METHOD'] = starb_i['interp_meth']\n",
    "starb_i_t.loc[0,'INVESTIGATOR'] = starb_i['investig']\n",
    "starb_i_t.loc[0,'SPONSORING_AGENCY'] = starb_i['spons_ag']\n",
    "starb_i_t.loc[0,'REFERENCES'] = starb_i['ref']\n",
    "starb_i_t.loc[0,'DATA_FLAG'] = starb_i['dflag']\n",
    "starb_i_t.loc[0,'REMARKS'] = starb_i['remarks_t']\n",
    "\n",
    "# fill TTT table\n",
    "starb_i_ttt = templ_ttt.copy()\n",
    "starb_i_ttt['POINT_ID'] = range(1,len(starb_i_dat)+1)\n",
    "starb_i_ttt['POINT_LAT'] = lats\n",
    "starb_i_ttt['POINT_LON'] = lons\n",
    "starb_i_ttt['ELEVATION'] = starb_i_dat['z_surf'].values.round()\n",
    "starb_i_ttt['THICKNESS'] = starb_i_dat['ice_th'].values.round()\n",
    "starb_i_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "starb_i_ttt['GlaThiDa_ID'] = starb_i['gid']\n",
    "starb_i_ttt['POLITICAL_UNIT'] = starb_i['punit']\n",
    "starb_i_ttt['GLACIER_NAME'] = starb_i['gname']\n",
    "starb_i_ttt['SURVEY_DATE'] = starb_i['survey_date']\n",
    "starb_i_ttt['DATA_FLAG'] = starb_i['dflag']\n",
    "starb_i_ttt['REMARKS'] = starb_i['remarks_ttt'] \n",
    "\n",
    "starb_i_t = starb_i_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "starb_i_ttt = starb_i_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "starb_i_t.to_excel(os.path.join(os.path.dirname(starb_path),starb_path.split('.')[0]+'_IceBridge_Johannes_T.xls'), index=False)\n",
    "starb_i_ttt.to_excel(os.path.join(os.path.dirname(starb_path),starb_path.split('.')[0]+'_IceBridge_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasman Glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nzgd = pyproj.Proj(init='epsg:2193') # NZGD2000_New_Zealand_Transverse_Mercator_2000\n",
    "latlon = pyproj.Proj(init='epsg:4326')  #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "tasman = {'punit': 'NZ',\n",
    "'gname': 'TASMAN',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '',\n",
    "'dem_date': '19869999',\n",
    "'gid': gtd_ids['tasman'],\n",
    "'lat':  -43.52,\n",
    "'lon': 170.32,\n",
    "'area': 100.3,\n",
    "'mean_sl': 19,\n",
    "'mean_th': np.nan,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': np.nan,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'SEI',\n",
    "'surv_meth_det': 'Two generalised cross profiles of ice thickness are inferred from reflection seismics.  x, y and ice thickness values are taken at points spaced along the published profiles (Figure 18, p23). A map of interpolated ice thickness (Figure 19, p26), but it is only based on measurements at the two widely-spaced profiles',\n",
    "'no_points': np.nan,\n",
    "'no_prfls': 2,\n",
    "'length_prfls': 3,\n",
    "'interp_meth':'',\n",
    "'investig':'',\n",
    "'spons_ag':'',\n",
    "'ref':'Anderton, P. W. (1975). Hydrological Research Annual Report 33. Ministry of Works and Development.',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'No mean/max thickness given as there are only highly varying estimates for two cross-sections of the glacier in the reference. Mean slope calculated from DEM by WGMS.',\n",
    "'remarks_ttt':''\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasman_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\tasman\\\\tasman_anderton_bed_xyz.csv'\n",
    "\n",
    "# read original data\n",
    "tasman_dat = pd.read_csv(tasman_path)\n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = tasman_dat['nztm_easting (m)'].values\n",
    "ys = tasman_dat[' nztm_northing (m)'].values\n",
    "x1,y1 = nzgd(xs, ys)\n",
    "lons, lats = pyproj.transform(nzgd,latlon,xs,ys)\n",
    "\n",
    "# fill T table\n",
    "tasman_t = templ_t.copy()\n",
    "tasman_t.loc[0,'GlaThiDa_ID'] = tasman['gid']\n",
    "tasman_t.loc[0,'POLITICAL_UNIT'] = tasman['punit']\n",
    "tasman_t.loc[0,'GLACIER_NAME'] = tasman['gname']\n",
    "tasman_t.loc[0,'SOURCE_ID'] = tasman['src_id']\n",
    "tasman_t.loc[0,'GLACIER_ID'] = tasman['src_g_id']\n",
    "tasman_t.loc[0,'LAT'] = tasman['lat']\n",
    "tasman_t.loc[0,'LON'] = tasman['lon']\n",
    "tasman_t.loc[0,'SURVEY_DATE'] = tasman['survey_date']\n",
    "tasman_t.loc[0,'DEM_DATE'] = tasman['dem_date']\n",
    "tasman_t.loc[0,'AREA'] = tasman['area']\n",
    "tasman_t.loc[0,'MEAN_SLOPE'] = tasman['mean_sl']\n",
    "tasman_t.loc[0,'MEAN_THICKNESS'] = tasman['mean_th']\n",
    "tasman_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = tasman['mean_th_unc']\n",
    "tasman_t.loc[0,'MAXIMUM_THICKNESS'] = tasman['max_th']\n",
    "tasman_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = tasman['max_th_unc']\n",
    "tasman_t.loc[0,'SURVEY_METHOD'] = tasman['surv_meth']\n",
    "tasman_t.loc[0,'SURVEY_METHOD_DETAILS'] = tasman['surv_meth_det']\n",
    "tasman_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = tasman['no_points']\n",
    "tasman_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = tasman['no_prfls']\n",
    "tasman_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = tasman['length_prfls']\n",
    "tasman_t.loc[0,'INTERPOLATION_METHOD'] = tasman['interp_meth']\n",
    "tasman_t.loc[0,'INVESTIGATOR'] = tasman['investig']\n",
    "tasman_t.loc[0,'SPONSORING_AGENCY'] = tasman['spons_ag']\n",
    "tasman_t.loc[0,'REFERENCES'] = tasman['ref']\n",
    "tasman_t.loc[0,'DATA_FLAG'] = tasman['dflag']\n",
    "tasman_t.loc[0,'REMARKS'] = tasman['remarks_t']\n",
    "\n",
    "# fill TTT table\n",
    "tasman_ttt = templ_ttt.copy()\n",
    "tasman_ttt['POINT_ID'] = range(1,len(tasman_dat)+1)\n",
    "tasman_ttt['POINT_LAT'] = lats\n",
    "tasman_ttt['POINT_LON'] = lons\n",
    "tasman_ttt['ELEVATION'] = tasman_dat[' surface_elevation (m asl)'].round()\n",
    "tasman_ttt['THICKNESS'] = tasman_dat[' ice_thickness (m)'].round()\n",
    "tasman_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "tasman_ttt['GlaThiDa_ID'] = tasman['gid']\n",
    "tasman_ttt['POLITICAL_UNIT'] = tasman['punit']\n",
    "tasman_ttt['GLACIER_NAME'] = tasman['gname']\n",
    "tasman_ttt['SURVEY_DATE'] = tasman['survey_date']\n",
    "tasman_ttt['DATA_FLAG'] = tasman['dflag']\n",
    "tasman_ttt['REMARKS'] = tasman['remarks_ttt'] \n",
    "\n",
    "tasman_t = tasman_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "tasman_ttt = tasman_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "tasman_t.to_excel(os.path.join(os.path.dirname(tasman_path),tasman_path.split('.')[0]+'_Johannes_T.xls'), index=False)\n",
    "tasman_ttt.to_excel(os.path.join(os.path.dirname(tasman_path),tasman_path.split('.')[0]+'_Johannes_TTT.xls'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urumqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "urum = {'punit': 'CN',\n",
    "'gname': 'URUMQI NO.1',\n",
    "'src_id':'OTH',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20149999',\n",
    "'dem_date': '20129999',\n",
    "'gid': gtd_ids['urumqui'],\n",
    "'lat':  43.111240,\n",
    "'lon': 86.810015,\n",
    "'area': 1.59,\n",
    "'mean_sl': 20,\n",
    "'mean_th': 44.5,\n",
    "'mean_th_unc': np.nan,\n",
    "'max_th': 141,\n",
    "'max_th_unc': np.nan,\n",
    "'surv_meth': 'GPRt',\n",
    "'surv_meth_det': '',\n",
    "'no_points': 1387,\n",
    "'no_prfls': 16,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'KRG',\n",
    "'investig':'',\n",
    "'spons_ag':'',\n",
    "'ref':'Wang, P. et al. (2016). Environmental Earth Sciences, 75(8), pp. 1-11. DOI: 10.1007/s12665-016-5551-3',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Lat/lon from Google Earth and located on upper tongue of eastern branch. Mean slope calculated from DEM by WGMS.',\n",
    "'remarks_ttt':''\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urum_path_w = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\urumqui\\\\west_branch\\\\original_west.shp'\n",
    "urum_path_e = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\urumqui\\\\east_branch\\\\original_east.shp'\n",
    "urum_out = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\urumqui\\\\'\n",
    "\n",
    "# read original data\n",
    "urumw_dat = gpd.read_file(urum_path_w)\n",
    "urume_dat = gpd.read_file(urum_path_e)\n",
    "\n",
    "urumall_dat = urumw_dat.append(urume_dat,ignore_index=True)\n",
    "urumall_dat = urumall_dat.reindex(range(1,len(urumall_dat)+1))\n",
    "\n",
    "\n",
    "lats = urumall_dat.N\n",
    "lons = urumall_dat.E\n",
    "elev = urumall_dat.a_s_l.round()\n",
    "ice_th = urumall_dat['冰川厚度（'].round()\n",
    "\n",
    "\n",
    "# fill T table\n",
    "urum_t = templ_t.copy()\n",
    "urum_t.loc[0,'GlaThiDa_ID'] = urum['gid']\n",
    "urum_t.loc[0,'POLITICAL_UNIT'] = urum['punit']\n",
    "urum_t.loc[0,'GLACIER_NAME'] = urum['gname']\n",
    "urum_t.loc[0,'SOURCE_ID'] = urum['src_id']\n",
    "urum_t.loc[0,'GLACIER_ID'] = urum['src_g_id']\n",
    "urum_t.loc[0,'LAT'] = urum['lat']\n",
    "urum_t.loc[0,'LON'] = urum['lon']\n",
    "urum_t.loc[0,'SURVEY_DATE'] = urum['survey_date']\n",
    "urum_t.loc[0,'DEM_DATE'] = urum['dem_date']\n",
    "urum_t.loc[0,'AREA'] = urum['area']\n",
    "urum_t.loc[0,'MEAN_SLOPE'] = urum['mean_sl']\n",
    "urum_t.loc[0,'MEAN_THICKNESS'] = urum['mean_th']\n",
    "urum_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = urum['mean_th_unc']\n",
    "urum_t.loc[0,'MAXIMUM_THICKNESS'] = urum['max_th']\n",
    "urum_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = urum['max_th_unc']\n",
    "urum_t.loc[0,'SURVEY_METHOD'] = urum['surv_meth']\n",
    "urum_t.loc[0,'SURVEY_METHOD_DETAILS'] = urum['surv_meth_det']\n",
    "urum_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = urum['no_points']\n",
    "urum_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = urum['no_prfls']\n",
    "urum_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = urum['length_prfls']\n",
    "urum_t.loc[0,'INTERPOLATION_METHOD'] = urum['interp_meth']\n",
    "urum_t.loc[0,'INVESTIGATOR'] = urum['investig']\n",
    "urum_t.loc[0,'SPONSORING_AGENCY'] = urum['spons_ag']\n",
    "urum_t.loc[0,'REFERENCES'] = urum['ref']\n",
    "urum_t.loc[0,'DATA_FLAG'] = urum['dflag']\n",
    "urum_t.loc[0,'REMARKS'] = urum['remarks_t']\n",
    "\n",
    "# fill TTT table\n",
    "urum_ttt = templ_ttt.copy()\n",
    "urum_ttt['POINT_ID'] = range(1,len(urumw_dat)+len(urume_dat)+1)\n",
    "urum_ttt['POINT_LAT'] = lats\n",
    "urum_ttt['POINT_LON'] = lons\n",
    "urum_ttt['ELEVATION'] = elev\n",
    "urum_ttt['THICKNESS'] = ice_th\n",
    "urum_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "urum_ttt['GlaThiDa_ID'] = urum['gid']\n",
    "urum_ttt['POLITICAL_UNIT'] = urum['punit']\n",
    "urum_ttt['GLACIER_NAME'] = urum['gname']\n",
    "urum_ttt['SURVEY_DATE'] = urum['survey_date']\n",
    "urum_ttt['DATA_FLAG'] = urum['dflag']\n",
    "urum_ttt['REMARKS'] = urum['remarks_ttt'] \n",
    "\n",
    "urum_t = urum_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "urum_ttt = urum_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "urum_t.to_excel(os.path.join(urum_out,'Urumqi_Johannes_T.xls'), index=False)\n",
    "urum_ttt.to_excel(os.path.join(urum_out,'Urumqi_Johannes_TTT.xls'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# West Washmawapta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "wwmw = {'punit': 'CA',\n",
    "'gname': 'WEST WASHMAWAPTA',\n",
    "'src_id':'',\n",
    "'src_g_id':'',\n",
    "'survey_date': '20069999',\n",
    "'dem_date': '20079999',\n",
    "'gid': gtd_ids['west_washmawapta'],\n",
    "'lat': 51.1833,\n",
    "'lon': -116.3189,\n",
    "'area': 1,\n",
    "'mean_sl': 16,\n",
    "'mean_th': 70,\n",
    "'mean_th_unc': 7,\n",
    "'max_th': 185,\n",
    "'max_th_unc': 13,\n",
    "'surv_meth': 'GPRt',\n",
    "'surv_meth_det': 'Icefield Instruments icepenetrating radar with 5 MHz center frequency and 10m antennae 50m apart. Assuming a signal propagation speed of 1.68*10^8 m/s, and migrating individual profiles using the circle-tangent technique.',\n",
    "'no_points': 199,\n",
    "'no_prfls': 21,\n",
    "'length_prfls': np.nan,\n",
    "'interp_meth':'',\n",
    "'investig':'',\n",
    "'spons_ag':'',\n",
    "'ref':'Sanders, J. W. et al. (2010). American Journal of Science, 310(8), pp.753-773. DOI: 10.2475/08.2010.03]',\n",
    "'dflag':np.nan,\n",
    "'remarks_t':'Near the steeply-sloping marginal walls, where the ice is thin and the topography complex, errors increased to 13 +- 2 m (27 +- 8%). Mean slope calculated from DEM by WGMS.',\n",
    "'remarks_ttt':''\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utm11n = pyproj.Proj(init='epsg:32611') # UTM 11N (WGS84)\n",
    "latlon = pyproj.Proj(init='epsg:4326')  #WGS84 lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wwmw_path = 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\WG_Farinotti_data_package\\\\west_washmawapta\\\\radar_table.txt'\n",
    "\n",
    "# read original data\n",
    "wwmw_dat = pd.read_csv(wwmw_path)\n",
    "\n",
    "\n",
    "\n",
    "ice_th = (wwmw_dat['SurfaceElev'] - wwmw_dat['BedrockElev']).round()\n",
    "\n",
    "# convert New Real TM to WGS84 lat/lon\n",
    "xs = wwmw_dat['Easting'].values\n",
    "ys = wwmw_dat['Northing'].values\n",
    "x1,y1 = utm11n(xs, ys)\n",
    "lons, lats = pyproj.transform(utm11n,latlon,xs,ys)\n",
    "\n",
    "\n",
    "# fill T table\n",
    "wwmw_t = templ_t.copy()\n",
    "wwmw_t.loc[0,'GlaThiDa_ID'] = wwmw['gid']\n",
    "wwmw_t.loc[0,'POLITICAL_UNIT'] = wwmw['punit']\n",
    "wwmw_t.loc[0,'GLACIER_NAME'] = wwmw['gname']\n",
    "wwmw_t.loc[0,'SOURCE_ID'] = wwmw['src_id']\n",
    "wwmw_t.loc[0,'GLACIER_ID'] = wwmw['src_g_id']\n",
    "wwmw_t.loc[0,'LAT'] = wwmw['lat']\n",
    "wwmw_t.loc[0,'LON'] = wwmw['lon']\n",
    "wwmw_t.loc[0,'SURVEY_DATE'] = wwmw['survey_date']\n",
    "wwmw_t.loc[0,'DEM_DATE'] = wwmw['dem_date']\n",
    "wwmw_t.loc[0,'AREA'] = wwmw['area']\n",
    "wwmw_t.loc[0,'MEAN_SLOPE'] = wwmw['mean_sl']\n",
    "wwmw_t.loc[0,'MEAN_THICKNESS'] = wwmw['mean_th']\n",
    "wwmw_t.loc[0,'MEAN_THICKNESS_UNCERTAINTY'] = wwmw['mean_th_unc']\n",
    "wwmw_t.loc[0,'MAXIMUM_THICKNESS'] = wwmw['max_th']\n",
    "wwmw_t.loc[0,'MAX_THICKNESS_UNCERTAINTY'] = wwmw['max_th_unc']\n",
    "wwmw_t.loc[0,'SURVEY_METHOD'] = wwmw['surv_meth']\n",
    "wwmw_t.loc[0,'SURVEY_METHOD_DETAILS'] = wwmw['surv_meth_det']\n",
    "wwmw_t.loc[0,'NUMBER_OF_SURVEY_POINTS'] = wwmw['no_points']\n",
    "wwmw_t.loc[0,'NUMBER_OF_SURVEY_PROFILES'] = wwmw['no_prfls']\n",
    "wwmw_t.loc[0,'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = wwmw['length_prfls']\n",
    "wwmw_t.loc[0,'INTERPOLATION_METHOD'] = wwmw['interp_meth']\n",
    "wwmw_t.loc[0,'INVESTIGATOR'] = wwmw['investig']\n",
    "wwmw_t.loc[0,'SPONSORING_AGENCY'] = wwmw['spons_ag']\n",
    "wwmw_t.loc[0,'REFERENCES'] = wwmw['ref']\n",
    "wwmw_t.loc[0,'DATA_FLAG'] = wwmw['dflag']\n",
    "wwmw_t.loc[0,'REMARKS'] = wwmw['remarks_t']\n",
    "\n",
    "# fill TTT table\n",
    "wwmw_ttt = templ_ttt.copy()\n",
    "wwmw_ttt['POINT_ID'] = range(1,len(wwmw_dat)+1)\n",
    "wwmw_ttt['POINT_LAT'] = lats\n",
    "wwmw_ttt['POINT_LON'] = lons\n",
    "wwmw_ttt['ELEVATION'] = wwmw_dat['SurfaceElev'].round()\n",
    "wwmw_ttt['THICKNESS'] = ice_th\n",
    "wwmw_ttt['THICKNESS_UNCERTAINTY'] = np.nan\n",
    "wwmw_ttt['GlaThiDa_ID'] = wwmw['gid']\n",
    "wwmw_ttt['POLITICAL_UNIT'] = wwmw['punit']\n",
    "wwmw_ttt['GLACIER_NAME'] = wwmw['gname']\n",
    "wwmw_ttt['SURVEY_DATE'] = wwmw['survey_date']\n",
    "wwmw_ttt['DATA_FLAG'] = wwmw['dflag']\n",
    "wwmw_ttt['REMARKS'] = wwmw['remarks_ttt'] \n",
    "\n",
    "wwmw_t = wwmw_t[['GlaThiDa_ID', 'POLITICAL_UNIT', 'GLACIER_NAME', 'SOURCE_ID', 'GLACIER_ID', 'LAT', 'LON', 'SURVEY_DATE', \n",
    "                 'DEM_DATE', 'AREA', 'MEAN_SLOPE', 'MEAN_THICKNESS', 'MEAN_THICKNESS_UNCERTAINTY', 'MAXIMUM_THICKNESS', \n",
    "                 'MAX_THICKNESS_UNCERTAINTY', 'SURVEY_METHOD', 'SURVEY_METHOD_DETAILS', 'NUMBER_OF_SURVEY_POINTS',\n",
    "                 'NUMBER_OF_SURVEY_PROFILES', 'TOTAL_LENGTH_OF_SURVEY_PROFILES', 'INTERPOLATION_METHOD', 'INVESTIGATOR', \n",
    "                 'SPONSORING_AGENCY', 'REFERENCES', 'DATA_FLAG', 'REMARKS']]\n",
    "wwmw_ttt = wwmw_ttt[['GlaThiDa_ID','POLITICAL_UNIT','GLACIER_NAME','SURVEY_DATE','POINT_ID','POINT_LAT','POINT_LON',\n",
    "                     'ELEVATION','THICKNESS','THICKNESS_UNCERTAINTY','DATA_FLAG','REMARKS']]\n",
    "\n",
    "wwmw_t.to_excel(os.path.join(os.path.dirname(wwmw_path),'West_Washmawapta_Johannes_T.xls'), index=False)\n",
    "wwmw_ttt.to_excel(os.path.join(os.path.dirname(wwmw_path),'West_Washmawapta_Johannes_TTT.xls'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
