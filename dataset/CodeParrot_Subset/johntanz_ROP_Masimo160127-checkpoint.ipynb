{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Masimo Analysis\n",
    "\n",
    "For Pulse Ox. Analysis, make sure the data file is the right .csv format:\n",
    "    \n",
    "    a) Headings on Row 1\n",
    "    b) Open the csv file through Notepad or TextEdit and delete extra \n",
    "    row commas (non-printable characters)\n",
    "    c) There are always Dates in Column A and Time in Column B. \n",
    "    d) There might be a row that says \"Time Gap Present\". Delete this row from Notepad \n",
    "    or TextEdit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the usual beginning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "from pandas import concat\n",
    "\n",
    "#define any string with 'C' as NaN\n",
    "def readD(val):\n",
    "    if 'C' in val:\n",
    "        return np.nan\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import File into Python\n",
    "Change File Name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/John/Dropbox/LLU/ROP/Pulse Ox/ROP018PO.csv',\n",
    "            parse_dates={'timestamp': ['Date','Time']},\n",
    "            index_col='timestamp',\n",
    "            usecols=['Date', 'Time', 'SpO2', 'PR', 'PI', 'Exceptions'],\n",
    "            na_values=['0'],\n",
    "            converters={'Exceptions':  readD}\n",
    "            )\n",
    "\n",
    "#parse_dates tells the read_csv function to combine the date and time column \n",
    "#into one timestamp column and parse it as a timestamp.\n",
    "#    pandas is smart enough to know how to parse a date in various formats\n",
    "\n",
    "#index_col sets the timestamp column to be the index.\n",
    "\n",
    "#usecols tells the read_csv function to select only the subset of the columns.\n",
    "#na_values is used to turn 0 into NaN\n",
    "\n",
    "#converters: readD is the dict that means any string with 'C' with be NaN (for PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfclean = df[27:33][df[27:33].loc[:, ['SpO2', 'PR', 'PI', 'Exceptions']].apply(pd.notnull).all(1)]\n",
    "#clean the dataframe to get rid of rows that have NaN for PI purposes\n",
    "df_clean = df[df.loc[:, ['PI', 'Exceptions']].apply(pd.notnull).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pulse ox date/time is 1 mins and 32 seconds faster than phone. Have to correct for it.\"\"\"\n",
    "\n",
    "TC = timedelta(minutes=1, seconds=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set Date and Time of ROP Exam and Eye Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_first = df.first_valid_index() #get the first number from index\n",
    "\n",
    "Y = pd.to_datetime(df_first) #convert index to datetime\n",
    "# Y = TIME DATA COLLECTION BEGAN / First data point on CSV\n",
    "\n",
    "# SYNTAX: \n",
    "# datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])\n",
    "\n",
    "W = datetime(2016, 1, 20, 7, 30)+TC\n",
    "# W = first eye drop dtarts\n",
    "X = datetime(2016, 1, 20, 8, 42)+TC\n",
    "# X = ROP Exam Started\n",
    "Z = datetime(2016, 1, 20, 8, 46)+TC\n",
    "# Z = ROP Exam Ended\n",
    "\n",
    "df_last = df.last_valid_index() #get the last number from index\n",
    "\n",
    "Q = pd.to_datetime(df_last) \n",
    "\n",
    "# Q = TIME DATA COLLECTION ENDED / Last Data point on CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Averages\n",
      "PI :\t1.35605010241 \n",
      "SpO2 :\t99.2296877312 \n",
      "PR :\t166.723203769\n"
     ]
    }
   ],
   "source": [
    "avg0PI = df_clean.PI[Y:W].mean()\n",
    "avg0O2 = df.SpO2[Y:W].mean()\n",
    "avg0PR = df.PR[Y:W].mean()\n",
    "\n",
    "print 'Baseline Averages\\n', 'PI :\\t',avg0PI, '\\nSpO2 :\\t',avg0O2,'\\nPR :\\t',avg0PR,\n",
    "#df.std() for standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average q 5 Min for 1 hour after 1st Eye Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI DurEyeD  SpO2 DurEyeD  PR DurEyeD\n",
      "2016-01-20 07:31:32    1.700662     99.768212  170.284768\n",
      "2016-01-20 07:36:32    1.671034     99.344371  163.066225\n",
      "2016-01-20 07:41:32    1.566434     99.046358  158.715232\n"
     ]
    }
   ],
   "source": [
    "# Every 5 min Average from start of eye drops to start of exam\n",
    "\n",
    "def perdeltadrop(start, end, delta):\n",
    "    rdrop = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        rdrop.append(curr)\n",
    "        curr += delta\n",
    "    return rdrop\n",
    "    \n",
    "dfdropPI = df_clean.PI[W:W+timedelta(hours=1)]\n",
    "dfdropO2 = df.SpO2[W:W+timedelta(hours=1)]\n",
    "dfdropPR = df.PR[W:W+timedelta(hours=1)]\n",
    "windrop = timedelta(minutes=5)#make the range\n",
    "rdrop = perdeltadrop(W, W+timedelta(minutes=15), windrop)\n",
    "\n",
    "avgdropPI = Series(index = rdrop, name = 'PI DurEyeD')\n",
    "avgdropO2 = Series(index = rdrop, name = 'SpO2 DurEyeD')\n",
    "avgdropPR = Series(index = rdrop, name = 'PR DurEyeD')\n",
    "\n",
    "for i in rdrop:\n",
    "    avgdropPI[i] = dfdropPI[i:(i+windrop)].mean()\n",
    "    avgdropO2[i] = dfdropO2[i:(i+windrop)].mean()\n",
    "    avgdropPR[i] = dfdropPR[i:(i+windrop)].mean()\n",
    "    \n",
    "resultdrops = concat([avgdropPI, avgdropO2, avgdropPR], axis=1, join='inner')\n",
    "print resultdrops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average Every 10 Sec During ROP Exam for first 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI DurEx  SpO2 DurEx    PR DurEX\n",
      "2016-01-20 08:43:32  1.066667   99.500000  160.000000\n",
      "2016-01-20 08:43:42  0.916667   99.500000  161.166667\n",
      "2016-01-20 08:43:52  0.866667   99.833333  154.666667\n",
      "2016-01-20 08:44:02       NaN   99.833333  148.666667\n",
      "2016-01-20 08:44:12  0.966667  100.000000  146.000000\n",
      "2016-01-20 08:44:22  1.000000  100.000000  144.166667\n",
      "2016-01-20 08:44:32  0.950000  100.000000  144.166667\n",
      "2016-01-20 08:44:42  0.933333  100.000000  142.666667\n",
      "2016-01-20 08:44:52  0.900000  100.000000  142.500000\n",
      "2016-01-20 08:45:02  0.883333  100.000000  145.166667\n",
      "2016-01-20 08:45:12  0.800000  100.000000  145.333333\n",
      "2016-01-20 08:45:22  0.866667  100.000000  142.333333\n",
      "2016-01-20 08:45:32  1.033333  100.000000  143.500000\n",
      "2016-01-20 08:45:42  1.083333  100.000000  143.333333\n",
      "2016-01-20 08:45:52  0.966667  100.000000  145.500000\n",
      "2016-01-20 08:46:02  0.966667  100.000000  144.333333\n",
      "2016-01-20 08:46:12  1.033333  100.000000  143.000000\n",
      "2016-01-20 08:46:22  1.216667  100.000000  145.166667\n",
      "2016-01-20 08:46:32  1.083333  100.000000  145.166667\n",
      "2016-01-20 08:46:42  1.050000  100.000000  142.666667\n",
      "2016-01-20 08:46:52  1.033333  100.000000  143.166667\n",
      "2016-01-20 08:47:02  1.100000  100.000000  145.333333\n",
      "2016-01-20 08:47:12  1.150000  100.000000  148.500000\n",
      "2016-01-20 08:47:22  1.083333  100.000000  147.333333\n"
     ]
    }
   ],
   "source": [
    "#AVERAGE DURING ROP EXAM FOR FIRST FOUR MINUTES\n",
    "def perdelta1(start, end, delta):\n",
    "    r1 = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        r1.append(curr)\n",
    "        curr += delta\n",
    "    return r1\n",
    "\n",
    "df1PI = df_clean.PI[X:X+timedelta(minutes=4)]\n",
    "df1O2 = df.SpO2[X:X+timedelta(minutes=4)]\n",
    "df1PR = df.PR[X:X+timedelta(minutes=4)]\n",
    "win1 = timedelta(seconds=10) #any unit of time & make the range\n",
    "\n",
    "r1 = perdelta1(X, X+timedelta(minutes=4), win1)\n",
    "\n",
    "#make the series to store\n",
    "avg1PI = Series(index = r1, name = 'PI DurEx')\n",
    "avg1O2 = Series(index = r1, name = 'SpO2 DurEx')\n",
    "avg1PR = Series(index = r1, name = 'PR DurEX')\n",
    "#average!\n",
    "for i1 in r1:\n",
    "    avg1PI[i1] = df1PI[i1:(i1+win1)].mean()\n",
    "    avg1O2[i1] = df1O2[i1:(i1+win1)].mean()\n",
    "    avg1PR[i1] = df1PR[i1:(i1+win1)].mean()\n",
    "\n",
    "result1 = concat([avg1PI, avg1O2, avg1PR], axis=1, join='inner')\n",
    "print result1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average Every 5 Mins Hour 1-2 After ROP Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI q5MinHr1  O2 q5MinHr1  PR q5MinHr1\n",
      "2016-01-20 08:47:32     0.912500   100.000000   145.841060\n",
      "2016-01-20 08:52:32     0.931852    99.907285   160.304636\n",
      "2016-01-20 08:57:32     1.201626    99.125828   184.920530\n",
      "2016-01-20 09:02:32     1.088350    98.907285   177.973510\n",
      "2016-01-20 09:07:32     0.982781    99.854305   161.543046\n",
      "2016-01-20 09:12:32     0.974648    99.337748   159.417219\n",
      "2016-01-20 09:17:32     0.920530    99.953642   154.516556\n",
      "2016-01-20 09:22:32     0.704636   100.000000   150.807947\n",
      "2016-01-20 09:27:32     0.833775   100.000000   154.304636\n",
      "2016-01-20 09:32:32     0.890728   100.000000   153.470199\n",
      "2016-01-20 09:37:32     0.865517    99.847682   157.529801\n",
      "2016-01-20 09:42:32     0.930464    99.198675   162.814570\n"
     ]
    }
   ],
   "source": [
    "#AVERAGE EVERY 5 MINUTES ONE HOUR AFTER ROP EXAM\n",
    "\n",
    "def perdelta2(start, end, delta):\n",
    "    r2 = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        r2.append(curr)\n",
    "        curr += delta\n",
    "    return r2\n",
    "\n",
    "# datetime(year, month, day, hour, etc.)\n",
    "\n",
    "df2PI = df_clean.PI[Z:(Z+timedelta(hours=1))]\n",
    "df2O2 = df.SpO2[Z:(Z+timedelta(hours=1))]\n",
    "df2PR = df.PR[Z:(Z+timedelta(hours=1))]\n",
    "win2 = timedelta(minutes=5) #any unit of time, make the range\n",
    "\n",
    "r2 = perdelta2(Z, (Z+timedelta(hours=1)), win2) #define the average using function\n",
    "\n",
    "#make the series to store\n",
    "avg2PI = Series(index = r2, name = 'PI q5MinHr1')\n",
    "avg2O2 = Series(index = r2, name = 'O2 q5MinHr1')\n",
    "avg2PR = Series(index = r2, name = 'PR q5MinHr1')\n",
    "\n",
    "#average!\n",
    "for i2 in r2:\n",
    "    avg2PI[i2] = df2PI[i2:(i2+win2)].mean()\n",
    "    avg2O2[i2] = df2O2[i2:(i2+win2)].mean()\n",
    "    avg2PR[i2] = df2PR[i2:(i2+win2)].mean()\n",
    "\n",
    "result2 = concat([avg2PI, avg2O2, avg2PR], axis=1, join='inner')\n",
    "print result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average Every 15 Mins Hour 2-3 After ROP Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI q15MinHr2  O2 q15MinHr2  PR q15MinHr2\n",
      "2016-01-20 09:47:32      0.979405     98.707317    157.152993\n",
      "2016-01-20 10:02:32      0.761419     99.995565    149.669623\n",
      "2016-01-20 10:17:32      1.014856     99.101996    154.711752\n",
      "2016-01-20 10:32:32      1.071788     99.082040    168.013304\n"
     ]
    }
   ],
   "source": [
    "#AVERAGE EVERY 15 MINUTES TWO HOURS AFTER ROP EXAM\n",
    "\n",
    "def perdelta3(start, end, delta):\n",
    "    r3 = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        r3.append(curr)\n",
    "        curr += delta\n",
    "    return r3\n",
    "\n",
    "# datetime(year, month, day, hour, etc.)\n",
    "\n",
    "df3PI = df_clean.PI[(Z+timedelta(hours=1)):(Z+timedelta(hours=2))]\n",
    "df3O2 = df.SpO2[(Z+timedelta(hours=1)):(Z+timedelta(hours=2))]\n",
    "df3PR = df.PR[(Z+timedelta(hours=1)):(Z+timedelta(hours=2))]\n",
    "win3 = timedelta(minutes=15) #any unit of time, make the range\n",
    "\n",
    "r3 = perdelta3((Z+timedelta(hours=1)), (Z+timedelta(hours=2)), win3)\n",
    "\n",
    "#make the series to store\n",
    "avg3PI = Series(index = r3, name = 'PI q15MinHr2')\n",
    "avg3O2 = Series(index = r3, name = 'O2 q15MinHr2')\n",
    "avg3PR = Series(index = r3, name = 'PR q15MinHr2')\n",
    "\n",
    "#average!\n",
    "for i3 in r3:\n",
    "    avg3PI[i3] = df3PI[i3:(i3+win3)].mean()\n",
    "    avg3O2[i3] = df3O2[i3:(i3+win3)].mean()\n",
    "    avg3PR[i3] = df3PR[i3:(i3+win3)].mean()\n",
    "    \n",
    "result3 = concat([avg3PI, avg3O2, avg3PR], axis=1, join='inner')\n",
    "print result3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average Every 30 Mins Hour 3-4 After ROP Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI q30MinHr3  O2 q30MinHr3  PR q30MinHr3\n",
      "2016-01-20 10:47:32      1.386217     99.134259    171.837958\n",
      "2016-01-20 11:17:32      1.026341     99.591565    154.558269\n"
     ]
    }
   ],
   "source": [
    "#AVERAGE EVERY 30 MINUTES THREE HOURS AFTER ROP EXAM\n",
    "\n",
    "def perdelta4(start, end, delta):\n",
    "    r4 = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        r4.append(curr)\n",
    "        curr += delta\n",
    "    return r4\n",
    "\n",
    "# datetime(year, month, day, hour, etc.)\n",
    "\n",
    "df4PI = df_clean.PI[(Z+timedelta(hours=2)):(Z+timedelta(hours=3))]\n",
    "df4O2 = df.SpO2[(Z+timedelta(hours=2)):(Z+timedelta(hours=3))]\n",
    "df4PR = df.PR[(Z+timedelta(hours=2)):(Z+timedelta(hours=3))]\n",
    "win4 = timedelta(minutes=30) #any unit of time, make the range\n",
    "\n",
    "r4 = perdelta4((Z+timedelta(hours=2)), (Z+timedelta(hours=3)), win4)\n",
    "\n",
    "#make the series to store\n",
    "avg4PI = Series(index = r4, name = 'PI q30MinHr3')\n",
    "avg4O2 = Series(index = r4, name = 'O2 q30MinHr3')\n",
    "avg4PR = Series(index = r4, name = 'PR q30MinHr3')\n",
    "\n",
    "#average!\n",
    "for i4 in r4:\n",
    "    avg4PI[i4] = df4PI[i4:(i4+win4)].mean()\n",
    "    avg4O2[i4] = df4O2[i4:(i4+win4)].mean()\n",
    "    avg4PR[i4] = df4PR[i4:(i4+win4)].mean()\n",
    "    \n",
    "result4 = concat([avg4PI, avg4O2, avg4PR], axis=1, join='inner')\n",
    "print result4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Average Every Hour 4-24 Hours Post ROP Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PI q60MinHr4+  O2 q60MinHr4+  PR q60MinHr4+\n",
      "2016-01-20 11:47:32       1.237150      98.755136     159.428096\n",
      "2016-01-20 12:47:32       1.112176      99.624098     158.508051\n",
      "2016-01-20 13:47:32       0.893443      98.670011     169.287618\n",
      "2016-01-20 14:47:32       0.833333      99.376458     161.461966\n",
      "2016-01-20 15:47:32       0.980292      99.831205     161.027207\n",
      "2016-01-20 16:47:32       0.969146      99.183661     172.601333\n",
      "2016-01-20 17:47:32       0.739141      99.748318     161.591893\n",
      "2016-01-20 18:47:32       0.869034      99.560414     167.052748\n",
      "2016-01-20 19:47:32       1.115094      97.426471     151.538937\n",
      "2016-01-20 20:47:32       1.054682      99.752915     154.097723\n",
      "2016-01-20 21:47:32       1.372682      99.913381     144.239867\n",
      "2016-01-20 22:47:32       1.048323      99.640200     167.298168\n",
      "2016-01-20 23:47:32       0.997668      99.843420     161.482510\n",
      "2016-01-21 00:47:32       1.389339      99.641866     156.231538\n",
      "2016-01-21 01:47:32       1.238602      99.194892     161.962243\n",
      "2016-01-21 02:47:32       0.914874      99.347029     160.974459\n",
      "2016-01-21 03:47:32       1.070903      99.767351     160.925597\n",
      "2016-01-21 04:47:32       1.106503      99.515677     171.529675\n",
      "2016-01-21 05:47:32       1.040858      99.350916     159.776791\n",
      "2016-01-21 06:47:32       1.701805      99.360957     177.924276\n",
      "2016-01-21 07:47:32       0.864127      99.222357     185.818291\n"
     ]
    }
   ],
   "source": [
    "#AVERAGE EVERY 60 MINUTES 4-24 HOURS AFTER ROP EXAM\n",
    "\n",
    "def perdelta5(start, end, delta):\n",
    "    r5 = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        r5.append(curr)\n",
    "        curr += delta\n",
    "    return r5\n",
    "\n",
    "# datetime(year, month, day, hour, etc.)\n",
    "\n",
    "df5PI = df_clean.PI[(Z+timedelta(hours=3)):(Z+timedelta(hours=24))]\n",
    "df5O2 = df.SpO2[(Z+timedelta(hours=3)):(Z+timedelta(hours=24))]\n",
    "df5PR = df.PR[(Z+timedelta(hours=3)):(Z+timedelta(hours=24))]\n",
    "win5 = timedelta(minutes=60) #any unit of time, make the range\n",
    "\n",
    "r5 = perdelta5((Z+timedelta(hours=3)), (Z+timedelta(hours=24)), win5)\n",
    "\n",
    "#make the series to store\n",
    "avg5PI = Series(index = r5, name = 'PI q60MinHr4+')\n",
    "avg5O2 = Series(index = r5, name = 'O2 q60MinHr4+')\n",
    "avg5PR = Series(index = r5, name = 'PR q60MinHr4+')\n",
    "\n",
    "#average!\n",
    "for i5 in r5:\n",
    "    avg5PI[i5] = df5PI[i5:(i5+win5)].mean()\n",
    "    avg5O2[i5] = df5O2[i5:(i5+win5)].mean()\n",
    "    avg5PR[i5] = df5PR[i5:(i5+win5)].mean()\n",
    "\n",
    "result5 = concat([avg5PI, avg5O2, avg5PR], axis=1, join='inner')\n",
    "print result5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mild, Moderate, and Severe Desaturation Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_O2_pre = df[Y:W]\n",
    "\n",
    "\n",
    "#Find count of these ranges\n",
    "below = 0 # v <=80\n",
    "middle = 0 #v >= 81 and v<=84\n",
    "above = 0 #v >=85 and v<=89\n",
    "ls = []\n",
    "\n",
    "b_dict = {}\n",
    "m_dict = {}\n",
    "a_dict = {}\n",
    "\n",
    "for i, v in df_O2_pre['SpO2'].iteritems():\n",
    "    \n",
    "    if v <= 80: #below block\n",
    "        \n",
    "        if not ls: \n",
    "            ls.append(v)\n",
    "        else:\n",
    "            if ls[0] >= 81: #if the range before was not below 80\n",
    "\n",
    "                if len(ls) >= 5: #if the range was greater than 10 seconds, set to 5 because data points are every 2\n",
    "\n",
    "                    if ls[0] <= 84: #was it in the middle range?\n",
    "                        m_dict[middle] = ls\n",
    "                        middle += 1\n",
    "                        ls = [v]\n",
    "                    elif ls[0] >= 85 and ls[0] <=89: #was it in the above range?\n",
    "                        a_dict[above] = ls\n",
    "                        above += 1\n",
    "                        ls = [v]\n",
    "\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls = [v]\n",
    "            else: #if in the same range\n",
    "                ls.append(v)\n",
    "                \n",
    "    elif v >= 81 and v<= 84: #middle block\n",
    "        \n",
    "        if not ls:\n",
    "            ls.append(v)\n",
    "        else:\n",
    "            if ls[0] <= 80 or (ls[0]>=85 and ls[0]<= 89): #if not in the middle range\n",
    "                if len(ls) >= 5: #if range was greater than 10 seconds\n",
    "\n",
    "                    if ls[0] <= 80: #was it in the below range?\n",
    "                        b_dict[below] = ls\n",
    "                        below += 1\n",
    "                        ls = [v]\n",
    "                    elif ls[0] >= 85 and ls[0] <=89: #was it in the above range?\n",
    "                        a_dict[above] = ls\n",
    "                        above += 1\n",
    "                        ls = [v]\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls = [v]\n",
    "\n",
    "            else:\n",
    "                ls.append(v)\n",
    "    \n",
    "    elif v >= 85 and v <=89: #above block\n",
    "        \n",
    "        if not ls:\n",
    "            ls.append(v)\n",
    "        else:\n",
    "            if ls[0] <=84 : #if not in the above range\n",
    "\n",
    "                if len(ls) >= 5: #if range was greater than \n",
    "                    if ls[0] <= 80: #was it in the below range?\n",
    "                        b_dict[below] = ls\n",
    "                        below += 1\n",
    "                        ls = [v]\n",
    "                    elif ls[0] >= 81 and ls[0] <=84: #was it in the middle range?\n",
    "                        m_dict[middle] = ls\n",
    "                        middle += 1\n",
    "                        ls = [v]\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls = [v]\n",
    "            else:\n",
    "                ls.append(v)\n",
    "    \n",
    "    else: #v>90 or something else weird. start the list over\n",
    "        ls = []\n",
    "#final list check\n",
    "if len(ls) >= 5:\n",
    "    if ls[0] <= 80: #was it in the below range?\n",
    "        b_dict[below] = ls\n",
    "        below += 1\n",
    "        ls = [v]\n",
    "    elif ls[0] >= 81 and ls[0] <=84: #was it in the middle range?\n",
    "        m_dict[middle] = ls\n",
    "        middle += 1\n",
    "        ls = [v]\n",
    "    elif ls[0] >= 85 and ls[0] <=89: #was it in the above range?\n",
    "        a_dict[above] = ls\n",
    "        above += 1\n",
    "        \n",
    "b_len = 0.0\n",
    "for key, val in b_dict.iteritems():\n",
    "    b_len += len(val)\n",
    "\n",
    "m_len = 0.0\n",
    "for key, val in m_dict.iteritems():\n",
    "    m_len += len(val)\n",
    "    \n",
    "a_len = 0.0\n",
    "for key, val in a_dict.iteritems():\n",
    "    a_len += len(val)\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   #post exam duraiton length analysis\n",
    "df_O2_post = df[Z:Q]\n",
    "\n",
    "\n",
    "#Find count of these ranges\n",
    "below2 = 0 # v <=80\n",
    "middle2= 0 #v >= 81 and v<=84\n",
    "above2 = 0 #v >=85 and v<=89\n",
    "ls2 = []\n",
    "\n",
    "b_dict2 = {}\n",
    "m_dict2 = {}\n",
    "a_dict2 = {}\n",
    "\n",
    "for i2, v2 in df_O2_post['SpO2'].iteritems():\n",
    "    \n",
    "    if v2 <= 80: #below block\n",
    "        \n",
    "        if not ls2: \n",
    "            ls2.append(v2)\n",
    "        else:\n",
    "            if ls2[0] >= 81: #if the range before was not below 80\n",
    "\n",
    "                if len(ls2) >= 5: #if the range was greater than 10 seconds, set to 5 because data points are every 2\n",
    "\n",
    "                    if ls2[0] <= 84: #was it in the middle range?\n",
    "                        m_dict2[middle2] = ls2\n",
    "                        middle2 += 1\n",
    "                        ls2 = [v2]\n",
    "                    elif ls2[0] >= 85 and ls2[0] <=89: #was it in the above range?\n",
    "                        a_dict2[above2] = ls2\n",
    "                        above2 += 1\n",
    "                        ls2 = [v2]\n",
    "\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls2 = [v2]\n",
    "            else: #if in the same range\n",
    "                ls2.append(v2)\n",
    "                \n",
    "    elif v2 >= 81 and v2<= 84: #middle block\n",
    "        \n",
    "        if not ls2:\n",
    "            ls2.append(v2)\n",
    "        else:\n",
    "            if ls2[0] <= 80 or (ls2[0]>=85 and ls2[0]<= 89): #if not in the middle range\n",
    "                if len(ls2) >= 5: #if range was greater than 10 seconds\n",
    "\n",
    "                    if ls2[0] <= 80: #was it in the below range?\n",
    "                        b_dict2[below2] = ls2\n",
    "                        below2 += 1\n",
    "                        ls2 = [v2]\n",
    "                    elif ls2[0] >= 85 and ls2[0] <=89: #was it in the above range?\n",
    "                        a_dict2[above2] = ls2\n",
    "                        above2 += 1\n",
    "                        ls2 = [v2]\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls2 = [v2]\n",
    "\n",
    "            else:\n",
    "                ls2.append(v2)\n",
    "    \n",
    "    elif v2 >= 85 and v2 <=89: #above block\n",
    "        \n",
    "        if not ls2:\n",
    "            ls2.append(v2)\n",
    "        else:\n",
    "            if ls2[0] <=84 : #if not in the above range\n",
    "\n",
    "                if len(ls2) >= 5: #if range was greater than \n",
    "                    if ls2[0] <= 80: #was it in the below range?\n",
    "                        b_dict2[below2] = ls2\n",
    "                        below2 += 1\n",
    "                        ls2 = [v2]\n",
    "                    elif ls2[0] >= 81 and ls2[0] <=84: #was it in the middle range?\n",
    "                        m_dict2[middle2] = ls2\n",
    "                        middle2 += 1\n",
    "                        ls2 = [v2]\n",
    "                else: #old list wasn't long enough to count\n",
    "                    ls2 = [v2]\n",
    "            else:\n",
    "                ls2.append(v2)\n",
    "    \n",
    "    else: #v2>90 or something else weird. start the list over\n",
    "        ls2 = []\n",
    "#final list check\n",
    "if len(ls2) >= 5:\n",
    "    if ls2[0] <= 80: #was it in the below range?\n",
    "        b_dict2[below2] = ls2\n",
    "        below2 += 1\n",
    "        ls2= [v2]\n",
    "    elif ls2[0] >= 81 and ls2[0] <=84: #was it in the middle range?\n",
    "        m_dict2[middle2] = ls2\n",
    "        middle2 += 1\n",
    "        ls2 = [v2]\n",
    "    elif ls2[0] >= 85 and ls2[0] <=89: #was it in the above range?\n",
    "        a_dict2[above2] = ls2\n",
    "        above2 += 1\n",
    "        \n",
    "b_len2 = 0.0\n",
    "for key, val2 in b_dict2.iteritems():\n",
    "    b_len2 += len(val2)\n",
    "\n",
    "m_len2 = 0.0\n",
    "for key, val2 in m_dict2.iteritems():\n",
    "    m_len2 += len(val2)\n",
    "    \n",
    "a_len2 = 0.0\n",
    "for key, val2 in a_dict2.iteritems():\n",
    "    a_len2 += len(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desat Counts for X mins\n",
      "\n",
      "Pre Mild Desat (85-89) Count: 0\tfor 0.0 min\n",
      "Pre Mod Desat (81-84) Count: 0\tfor 0.0 min\n",
      "Pre Sev Desat (=< 80) Count: 1\tfor 0.6 min\n",
      "\n",
      "Post Mild Desat (85-89) Count: 3\tfor 0.633333333333 min\n",
      "Post Mod Desat (81-84) Count: 4\tfor 0.9 min\n",
      "Post Sev Desat (=< 80) Count: 8\tfor 2.6 min\n",
      "\n",
      "Data Recording Time!\n",
      "**********\n",
      "Pre-Exam Data Recording Length\t0 days 16:19:32\n",
      "Post-Exam Data Recording Length\t0 days 23:27:40\n",
      "Total Data Recording Length\t1 days 15:51:12\n"
     ]
    }
   ],
   "source": [
    "#print results from count and min\n",
    "\n",
    "print \"Desat Counts for X mins\\n\"    \n",
    "print \"Pre Mild Desat (85-89) Count: %s\\t\" %above, \"for %s min\" %((a_len*2)/60.)\n",
    "print \"Pre Mod Desat (81-84) Count: %s\\t\" %middle, \"for %s min\" %((m_len*2)/60.) \n",
    "print \"Pre Sev Desat (=< 80) Count: %s\\t\" %below, \"for %s min\\n\" %((b_len*2)/60.)\n",
    "\n",
    "print \"Post Mild Desat (85-89) Count: %s\\t\" %above2, \"for %s min\" %((a_len2*2)/60.) \n",
    "print \"Post Mod Desat (81-84) Count: %s\\t\" %middle2, \"for %s min\" %((m_len2*2)/60.) \n",
    "print \"Post Sev Desat (=< 80) Count: %s\\t\" %below2, \"for %s min\\n\" %((b_len2*2)/60.) \n",
    "\n",
    "\n",
    "\n",
    "print \"Data Recording Time!\"\n",
    "print '*' * 10\n",
    "print \"Pre-Exam Data Recording Length\\t\", X - Y # start of exam - first data point\n",
    "print \"Post-Exam Data Recording Length\\t\", Q - Z #last data point - end of exam\n",
    "print \"Total Data Recording Length\\t\", Q - Y #last data point - first data point\n",
    "\n",
    "Pre = ['Pre',(X-Y)]\n",
    "Post = ['Post',(Q-Z)]\n",
    "Total = ['Total',(Q-Y)]\n",
    "RTL = [Pre, Post, Total]\n",
    "\n",
    "PreMild = ['Pre Mild Desats \\t',(above), 'for', (a_len*2)/60., 'mins']\n",
    "PreMod = ['Pre Mod Desats \\t',(middle), 'for', (m_len*2)/60., 'mins']\n",
    "PreSev = ['Pre Sev Desats \\t',(below), 'for', (b_len*2)/60., 'mins']\n",
    "PreDesats = [PreMild, PreMod, PreSev]\n",
    "\n",
    "PostMild = ['Post Mild Desats \\t',(above2), 'for', (a_len2*2)/60., 'mins']\n",
    "PostMod = ['Post Mod Desats \\t',(middle2), 'for', (m_len2*2)/60., 'mins']\n",
    "PostSev = ['Post Sev Desats \\t',(below2), 'for', (b_len2*2)/60., 'mins']\n",
    "PostDesats = [PostMild, PostMod, PostSev]\n",
    "\n",
    "#creating a list for recording time length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint \"Mild check\"\\nfor key, val in b_dict.iteritems():\\n    print all(i <=80 for i in val)\\n\\nprint \"Moderate check\"\\nfor key, val in m_dict.iteritems():\\n    print all(i >= 81 and i<=84 for i in val)\\n    \\nprint \"Severe check\"\\nfor key, val in a_dict.iteritems():\\n    print all(i >= 85 and i<=89 for i in val)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#did it count check sort correctly? get rid of the ''' if you want to check your values\n",
    "'''\n",
    "print \"Mild check\"\n",
    "for key, val in b_dict.iteritems():\n",
    "    print all(i <=80 for i in val)\n",
    "\n",
    "print \"Moderate check\"\n",
    "for key, val in m_dict.iteritems():\n",
    "    print all(i >= 81 and i<=84 for i in val)\n",
    "    \n",
    "print \"Severe check\"\n",
    "for key, val in a_dict.iteritems():\n",
    "    print all(i >= 85 and i<=89 for i in val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "class excel_tab(csv.excel):\n",
    "        delimiter = '\\t'\n",
    "csv.register_dialect(\"excel_tab\", excel_tab)\n",
    "\n",
    "with open('ROP018_PO.csv', 'w') as f:    #CHANGE CSV FILE NAME, saves in same directory\n",
    "    writer = csv.writer(f, dialect=excel_tab)\n",
    "    #writer.writerow(['PI, O2, PR']) accidently found this out but using commas = gives me columns YAY! fix this\n",
    "    #to make code look nice ok nice\n",
    "    writer.writerow([avg0PI, ',PI Start'])\n",
    "    for i in rdrop:\n",
    "        writer.writerow([avgdropPI[i]]) #NEEDS BRACKETS TO MAKE IT SEQUENCE\n",
    "    for i in r1:\n",
    "        writer.writerow([avg1PI[i]])\n",
    "    for i in r2:\n",
    "        writer.writerow([avg2PI[i]])\n",
    "    for i in r3:\n",
    "        writer.writerow([avg3PI[i]])\n",
    "    for i in r4:\n",
    "        writer.writerow([avg4PI[i]])\n",
    "    for i in r5:\n",
    "        writer.writerow([avg5PI[i]])\n",
    "    writer.writerow([avg0O2, ',SpO2 Start'])\n",
    "    for i in rdrop:\n",
    "        writer.writerow([avgdropO2[i]])\n",
    "    for i in r1:\n",
    "        writer.writerow([avg1O2[i]])\n",
    "    for i in r2:\n",
    "        writer.writerow([avg2O2[i]])\n",
    "    for i in r3:\n",
    "        writer.writerow([avg3O2[i]])\n",
    "    for i in r4:\n",
    "        writer.writerow([avg4O2[i]])\n",
    "    for i in r5:\n",
    "        writer.writerow([avg5O2[i]])\n",
    "    writer.writerow([avg0PR, ',PR Start'])\n",
    "    for i in rdrop:\n",
    "        writer.writerow([avgdropPR[i]])\n",
    "    for i in r1:\n",
    "        writer.writerow([avg1PR[i]])\n",
    "    for i in r2:\n",
    "        writer.writerow([avg2PR[i]])\n",
    "    for i in r3:\n",
    "        writer.writerow([avg3PR[i]])\n",
    "    for i in r4:\n",
    "        writer.writerow([avg4PR[i]])\n",
    "    for i in r5:\n",
    "        writer.writerow([avg5PR[i]])\n",
    "    writer.writerow(['Data Recording Time Length'])\n",
    "    writer.writerows(RTL)\n",
    "    writer.writerow(['Pre Desat Counts for X Minutes'])\n",
    "    writer.writerows(PreDesats)\n",
    "    writer.writerow(['Post Dest Counts for X Minutes'])\n",
    "    writer.writerows(PostDesats)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
