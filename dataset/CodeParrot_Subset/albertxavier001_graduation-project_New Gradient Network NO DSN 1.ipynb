{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "\n",
    "#######\n",
    "# args.test_scene = ['alley_2', 'bamboo_2', 'bandage_2', 'cave_4', 'market_5', 'mountain_1', 'shaman_3', 'sleeping_2', 'temple_3']\n",
    "args.test_scene = 'alley_1'\n",
    "gradient=False\n",
    "args.gpu_num = 1\n",
    "#######\n",
    "\n",
    "writer_comment = '{}_rgb_no_dsn'.format(args.test_scene)\n",
    "if gradient == True:\n",
    "    writer_comment = '{}_gd_no_dsn'.format(args.test_scene)\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 6\n",
    "s0 = ss*5\n",
    "s0 = 0\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = [0,0,0,0,0,s0]\n",
    "args.training_merge_thresholds = [s0+ss*3*3,s0+ss*2*3, s0+ss*1*3, s0, -1, s0+ss*4*3]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6\n",
    "    test_merge_losses = [nn.MSELoss()] * 6    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(epoch, go_through_merge=False, phase='train'):\n",
    "    if phase == 'train': net.train()\n",
    "    else: net.eval()\n",
    "    \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)  \n",
    "    test_merge_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_merge_cnts_trainphase   = [0.00001] * len(args.training_thresholds)\n",
    "    \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt0 = gt_albedo.cpu().data.numpy()\n",
    "            n,c,h,w = gt0.shape\n",
    "            gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "            gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "            \n",
    "            if use_gpu: \n",
    "                gt = gt.cuda()\n",
    "                gt_mg = gt_mg.cuda()\n",
    "            \n",
    "            if i != 5: \n",
    "                loss = mse_losses[i](ft_test[i], gt)\n",
    "                test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                test_cnts_trainphase[i] += 1\n",
    "            \n",
    "            if go_through_merge != False and i != 4:\n",
    "                if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                    if i==5: gt2=gt\n",
    "                    else: gt2=gt_mg\n",
    "#                     print(i)\n",
    "#                     print('merge size', merged_RGB[i].size())\n",
    "#                     print('gt2 size', gt2.size())\n",
    "                    loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                    test_merge_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                    test_merge_cnts_trainphase[i] += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            if ind == 0: \n",
    "                if i != 5:\n",
    "                    v = v[0].cpu().data.numpy()\n",
    "                    v = v.transpose(1,2,0)\n",
    "                    v = v[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/test-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                        v = merged_RGB[i][0].cpu().data.numpy()\n",
    "                        v = v.transpose(1,2,0)\n",
    "                        v = v[:,:,0:3]\n",
    "                        cv2.imwrite('snapshot{}/test-mg-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                    \n",
    "    run_losses = test_losses_trainphase\n",
    "    run_cnts = test_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)\n",
    "    \n",
    "    run_losses = test_merge_losses_trainphase\n",
    "    run_cnts = test_merge_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'mg test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'mg test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'mg test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'mg test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'mg test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'mg test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None, base_lr=args.base_lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "#         print('para gp', param_group)\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        param_group['lr'] = base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "        if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        \n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "#     epoch = 234\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    if epoch < args.training_thresholds[-1]: \n",
    "        adjust_learning_rate(optimizer, epoch, beg=0, end=s0-1)\n",
    "    elif epoch < args.training_merge_thresholds[-1]:\n",
    "        adjust_learning_rate(optimizer, (epoch-s0)%(ss), beg=0, end=ss-1, base_lr=args.base_lr)\n",
    "    else:\n",
    "        adjust_learning_rate(optimizer, epoch, beg=args.training_merge_thresholds[-1], end=args.epoches-1, base_lr=args.base_lr)  \n",
    "        \n",
    "        \n",
    "#     if epoch < args.training_thresholds[-1]: go_through_merge = False\n",
    "#     elif epoch >= args.training_merge_thresholds[5]: go_through_merge = '32M'\n",
    "#     elif epoch >= args.training_merge_thresholds[0]: go_through_merge = '16M'\n",
    "#     elif epoch >= args.training_merge_thresholds[1]: go_through_merge = '08M'\n",
    "#     elif epoch >= args.training_merge_thresholds[2]: go_through_merge = '04M'\n",
    "#     elif epoch >= args.training_merge_thresholds[3]: go_through_merge = '02M'\n",
    "    go_through_merge = '32M'\n",
    "    \n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    run_merge_losses = [0] * len(args.training_thresholds)\n",
    "    run_merge_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    if (epoch in args.training_merge_thresholds) == True:\n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "        \n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        \"\"\"prepare  training data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        input_img, gt_albedo, gt_shading = Variable(input_img), Variable(gt_albedo), Variable(gt_shading)\n",
    "        if use_gpu: input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "\n",
    "        if args.display_curindex % args.display_interval == 0: cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        ft_predict, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                \"\"\"prepare resized gt\"\"\"\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt0 = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt0.shape\n",
    "                gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "                gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "                if use_gpu: \n",
    "                    gt = gt.cuda()\n",
    "                    gt_mg = gt_mg.cuda()\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    display = display[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), display[:,:,::-1]*255)                \n",
    "                \n",
    "                \"\"\"compute loss\"\"\"\n",
    "                if i != 5: \n",
    "                    loss = mse_losses[i](ft_predict[i], gt)\n",
    "                    run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "#                     loss.backward(retain_graph=True)\n",
    "                    run_cnts[i] += 1\n",
    "                \n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "#                         print(epoch, go_through_merge, i)\n",
    "                        \n",
    "#                         print (merged_RGB[i].cpu().data.numpy().max(), merged_RGB[i].cpu().data.numpy().min())\n",
    "                        if i!=5: continue\n",
    "                        if i==5: gt2=gt\n",
    "                        else: gt2=gt_mg\n",
    "#                         print(i)\n",
    "#                         print('merge size', merged_RGB[i].size())\n",
    "#                         print('gt2 size', gt2.size())\n",
    "                        loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                        run_merge_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        run_merge_cnts[i] += 1\n",
    "                \n",
    "                \"\"\"save training image\"\"\"\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    \n",
    "                    if i != 5:\n",
    "                        im = (ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                        im = im[:,:,0:3]\n",
    "                        \n",
    "                        cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "                    \n",
    "                    if go_through_merge != False and i != 4:\n",
    "                        if ((go_through_merge == '32M') or\n",
    "                        (go_through_merge == '16M' and i != 5) or  \n",
    "                        (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                        (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                        (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                            im = (merged_RGB[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                            im = im[:,:,0:3]\n",
    "                            cv2.imwrite('snapshot{}/train-mg-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    loss_output = ''\n",
    "    for i,v in enumerate(run_merge_losses):\n",
    "        if i == len(run_merge_losses)-1: \n",
    "            loss_output += 'mg merged: %6f' % (run_merge_losses[i] / run_merge_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' mg %2dM: %6f' % ((2**(4-i)), (run_merge_losses[i] / run_merge_cnts[i]))\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"save at every epoch\"\"\"\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_model(epoch, phase='train', go_through_merge=go_through_merge)\n",
    "        test_model(epoch, phase='test', go_through_merge=go_through_merge)\n",
    "\n",
    "        writer.add_scalars('16M loss', {'train 16M ': np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "        writer.add_scalars('8M loss', {'train 8M ': np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "        writer.add_scalars('4M loss', {'train 4M ': np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "        writer.add_scalars('2M loss', {'train 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "        writer.add_scalars('1M loss', {'train 1M ': np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "        writer.add_scalars('merged loss', {'train merged ': np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
