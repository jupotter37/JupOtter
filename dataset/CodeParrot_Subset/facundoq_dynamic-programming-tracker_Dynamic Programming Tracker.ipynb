{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Tracker for Hands\n",
    "Implementation of  [Dreuw06 - Tracking Using Dynamic Programming\n",
    "for Appearance-Based Sign Language Recognition](http://thomas.deselaers.de/publications/papers/dreuw_fg06.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage\n",
    "from scipy import ndimage\n",
    "from skimage.draw import circle_perimeter_aa,circle\n",
    "from skimage import transform\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.animation as anim\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "import numba\n",
    "import skvideo.io\n",
    "import skvideo.datasets\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scoring\n",
    "import util\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video shape: (54, 368, 480, 3)\n",
      "Resulting video shape: (20, 368, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "test_path='test_data/All_Blacks.5846.main_glosses.mb.r480x360.mp4'\n",
    "#test_path='test_data/_1276_small_3.mov'\n",
    "output_path='tmp/'\n",
    "filename =os.path.basename(test_path)\n",
    "tracked_video_path= os.path.join(output_path,filename)\n",
    "debug_video_path=os.path.join(output_path,\"_debug\".join(os.path.splitext(filename)))\n",
    "data = skvideo.io.ffprobe(test_path)['video']\n",
    "rate = data['@r_frame_rate']\n",
    "video = skvideo.io.vread(test_path)/255\n",
    "\n",
    "print(\"Original video shape: %s\" % str(video.shape))\n",
    "video=video[0:20,:,:,:]\n",
    "util.video_rgb_to_hsv(video)\n",
    "\n",
    "T,h,w,c=video.shape\n",
    "\n",
    "# new_size=(320,320)\n",
    "# video_original=video\n",
    "# video=np.zeros((T,new_size[0],new_size[1],c))\n",
    "# for t in range(T):\n",
    "#     video[t,:,:,:] = transform.resize(video_original[t,:,:,:], new_size, order=1)\n",
    "\n",
    "T,h,w,c=video.shape\n",
    "\n",
    "print(\"Resulting video shape: %s\" % str(video.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 368, 480)\n",
      "Movement score treshold: 0.017744\n",
      "Pixel score treshold: 0.024918\n",
      "Optical flow treshold: 0.421541\n"
     ]
    }
   ],
   "source": [
    "def jump_penalty_euclidean(p1,p2):\n",
    "  d=p1-p2\n",
    "  return np.sum(d**2)\n",
    "def skin_config_asllvd():\n",
    "    mu_hsv=np.array([20.0,35.0,73.0])/255.0\n",
    "    #mu_rgb=np.array([176,134,112])\n",
    "    cov=np.array([0.3,0.5,10])\n",
    "    return mu_hsv,cov\n",
    "def skin_config_boston():\n",
    "    mu_hsv=np.array([357,56.0,85.0])/255.0\n",
    "    #mu_rgb=np.array([176,134,112])\n",
    "    cov=np.array([0.3,0.7,15])\n",
    "    return mu_hsv,cov\n",
    "\n",
    "mu,cov=skin_config_asllvd()\n",
    "#mu,cov=skin_config_boston()\n",
    "\n",
    "movement_weight=0.1\n",
    "optical_flow_weight=0.4\n",
    "scorers=[scoring.manhattan_movement_score,lambda video:scoring.skin_pixel_scorer(video,mu,cov),scoring.optical_flow_movement_score]\n",
    "scorers_labels=['manhattan_movement','pixel','optical_flow']\n",
    "scorers_weights=[movement_weight,1-movement_weight-optical_flow_weight,optical_flow_weight]\n",
    "local_score,scores=scoring.calculate_local_score(video,scorers,scorers_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for frame:\n",
      "1/19 - 2/19 - 3/19 - 4/19 - 5/19 - 6/19 - 7/19 - 8/19 - 9/19 - 10/19 - 11/19 - 12/19 - 13/19 - 14/19 - 15/19 - 16/19 - 17/19 - 18/19 - 19/19 - Tracking coordinates\n",
      "[[315 315 324 336 342 338 313 288 263 238 213 214 201 198 192 190 190 191\n",
      "  197 202]\n",
      " [183 179 184 184 194 219 235 243 251 255 250 251 256 254 257 262 262 264\n",
      "  257 254]]\n"
     ]
    }
   ],
   "source": [
    "class DPTracker:  \n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def backtrack_path(self,backtracking_path,score):\n",
    "    Tm,h,w,dim_indices=backtracking_path.shape\n",
    "    T=Tm+1\n",
    "    path=np.zeros((T,2),dtype=int) # 2 => (x,y)\n",
    "    best_index_last_frame = np.argmax(score[-1,:,:])\n",
    "    x,y= np.unravel_index(best_index_last_frame , score[-1,:,:].shape)\n",
    "    path[-1,:]=np.array([x,y])\n",
    "    for t in reversed(range(T-1)):\n",
    "      x,y= tuple(path[t+1,:])\n",
    "      path[t, :] = backtracking_path[t,x,y,:]\n",
    "    return path\n",
    "\n",
    "  @numba.jit\n",
    "  def track(self,video,local_score,jump_penalty_matrix):\n",
    "    video = ndimage.gaussian_filter(video, sigma=(0, 2, 2, 0), order=0)\n",
    "    T,h,w,c=video.shape\n",
    "    self.backtracking_path=np.zeros((T-1,h,w,2),dtype=int) # 2 => (x,y) for T-1\n",
    "    self.score=np.zeros((T,h,w))\n",
    "    n=int((jump_penalty_matrix.shape[0]-1)/2)\n",
    "    n2=n+1\n",
    "    \n",
    "\n",
    "    self.score[0,:,:]=local_score[0,:,:]\n",
    "    self.local_score =local_score\n",
    "        \n",
    "    initial_values=np.zeros((h,w,2))\n",
    "\n",
    "    for i in range(h):\n",
    "      for j in range(w):\n",
    "        initial_values[i,j,:]=np.array([i,j])\n",
    "    self.backtracking_path[:,:,:,:]=initial_values\n",
    "    \n",
    "    print(\"Calculating score for frame:\")\n",
    "    for t in range(1,T):\n",
    "      print(\"%d/%d - \" % (t,T-1), end=\"\")\n",
    "      for i in range(n, h-n):\n",
    "        for j in range(n, w-n):\n",
    "          neighbourhood_score=self.score[t-1,i-n:i+n2,j-n:j+n2]\n",
    "          previous_score=neighbourhood_score-jump_penalty_matrix\n",
    "            \n",
    "          index=np.argmax(previous_score)\n",
    "          best_score=previous_score.flat[index]\n",
    "          relative_x,relative_y=np.unravel_index(index, jump_penalty_matrix.shape)\n",
    "          x = i + relative_x - n\n",
    "          y = j + relative_y - n\n",
    "          self.backtracking_path[t-1, i, j, 0] =x\n",
    "          self.backtracking_path[t-1, i, j, 1] =y\n",
    "          self.score[t,i,j]=self.local_score[t,i,j]+best_score #np.mean(previous_score)\n",
    "    self.path=self.backtrack_path(self.backtracking_path,self.score)\n",
    "    \n",
    "    return self.path\n",
    "\n",
    "def generate_jump_penalty_matrix(jump_penalty, neighbourhood):\n",
    "    n=neighbourhood*2+1\n",
    "    matrix=np.zeros((n,n))\n",
    "    center=np.array([neighbourhood,neighbourhood])\n",
    "    for i in range(n):\n",
    "      for j in range(n):\n",
    "        position=np.array([i,j])\n",
    "        matrix[i,j]=jump_penalty(center,position)\n",
    "    return matrix\n",
    "\n",
    "neighbourhood_size=25\n",
    "jump_penalty_weight=0.0003\n",
    "jump_penalty_matrix=jump_penalty_weight * generate_jump_penalty_matrix(jump_penalty_euclidean,neighbourhood_size)\n",
    "\n",
    "\n",
    "tracker=DPTracker()\n",
    "track_result=tracker.track(video,local_score,jump_penalty_matrix)\n",
    "\n",
    "print(\"Tracking coordinates\")\n",
    "print(track_result.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_tracked(video,track_result):\n",
    "  T,h,w,c = video.shape\n",
    "  image_shape=(h,w)\n",
    "  radius=5\n",
    "  color=np.array([1.0,0,0])\n",
    "  for t in range(T):\n",
    "    x,y=tuple(track_result[t,:])\n",
    "    if (x-radius>=0) and (x+radius<h) and (y-radius>=0) and (y+radius<w):\n",
    "      rr,cc=circle(x,y,radius,shape=image_shape)\n",
    "      video[t,rr,cc,:]=color\n",
    "  return video\n",
    "\n",
    "\n",
    "def generate_debug_video(video,scores,labels,output_path):\n",
    "#   FFMpegWriter= anim.writers['ffmpeg']\n",
    "  metadata=dict(title=\"Output\")\n",
    "#   writer=FFMpegWriter(fps=6,bitrate=16384*2,metadata=metadata)\n",
    "\n",
    "  columns=int(np.ceil(len(scores)/2))+1\n",
    "  f,axes=plt.subplots(2,columns,dpi=100)\n",
    "  axes =list(itertools.chain.from_iterable(axes))\n",
    "  image_ax=axes[0]\n",
    "  f.set_size_inches(10,10, True)\n",
    "  T,h,w,c=video.shape\n",
    "  base_file,ext=os.path.splitext(output_path)\n",
    "  if not os.path.exists(base_file):\n",
    "    os.mkdir(base_file)\n",
    "#   with writer.saving(f,debug_video_path,T):\n",
    "  cbars=[]\n",
    "  ranges=[]\n",
    "  for s in range(len(scores)):\n",
    "    ranges.append( (0,np.max(scores[s])) )\n",
    "  for t in range(T):\n",
    "    plt.suptitle(\"Frame %d/%d\" % (t,T-1))\n",
    "    image_ax.cla()\n",
    "    plot=image_ax.imshow(video[t,:,:,:])\n",
    "    \n",
    "    for s in range(len(scores)):\n",
    "      ax=axes[s+1]\n",
    "      ax.cla()\n",
    "      ax.set_title(labels[s],fontsize=10)\n",
    "    \n",
    "      data=scores[s][t,:,:]\n",
    "      vmin,vmax=ranges[s]\n",
    "      plot=ax.imshow(data,cmap='gray',vmin=vmin,vmax=vmax)  \n",
    "      if t==0:\n",
    "        cbar=f.colorbar(plot, ax=ax)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "        cbar_ticks = np.linspace(vmin,vmax, num=10, endpoint=True)\n",
    "        cbar.set_ticks(cbar_ticks)\n",
    "        cbars.append(cbar)\n",
    "#       plot.set_clim([data.min(), data.max()])\n",
    "#       cbar_ticks = np.linspace(data.min(), data.max(), num=10, endpoint=True)\n",
    "#       cbars[s].set_ticks(cbar_ticks) \n",
    "#       plot.autoscale()\n",
    "    a='%s/%03d.png' % (base_file,t)\n",
    "    plt.savefig(a)\n",
    "#       writer.grab_frame()\n",
    "\n",
    "tracked_video=np.copy(video)\n",
    "util.video_hsv_to_rgb(tracked_video)\n",
    "tracked_video=tracked_video/255.0\n",
    "tracked_video=draw_tracked(tracked_video,track_result)\n",
    "tracked_video=tracked_video.astype('short')\n",
    "show_scores=[local_score,tracker.score]+scores\n",
    "show_scores_label=['local','global']+scorers_labels\n",
    "generate_debug_video(tracked_video, show_scores,show_scores_label,debug_video_path)\n",
    "\n",
    "# skvideo.io.vwrite(tracked_video_path, tracked_video, outputdict={\n",
    "#   '-vcodec': 'libx264',\n",
    "#   '-pix_fmt': 'yuv420p',\n",
    "#   '-r': rate,\n",
    "# })\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=tracker.local_score\n",
    "plt.imshow(score[T-2,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(score[T-3,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(score[T-4,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(tracked_video[T-1,:,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "mean_scores=np.sum(tracker.score,axis=(1,2))\n",
    "print(mean_scores.shape)\n",
    "plt.plot(mean_scores)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
