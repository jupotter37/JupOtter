{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('fin-dprep-train.pkl')\n",
    "test_df = pd.read_pickle('fin-dprep-test.pkl')\n",
    "\n",
    "features_to_use = pickle.load(open('fin-dprep-flist.pkl', 'rb'))\n",
    "\n",
    "medium_price = pd.read_pickle('fin-medium-price-r2.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, medium_price, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, medium_price, left_on='listing_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adams = pd.read_pickle('features-adams.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, adams, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, adams, left_on='listing_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"predicted_price_diff\"] = np.log(train_df[\"price\"]) - np.log(train_df[\"predicted_price\"])\n",
    "test_df[\"predicted_price_diff\"] = np.log(test_df[\"price\"]) - np.log(test_df[\"predicted_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeansProcessor:\n",
    "    def __init__(self, key, outkey = None, tgt = 'interest_cat'):\n",
    "        self.key = key\n",
    "        self.outkey = key if outkey is None else outkey\n",
    "        \n",
    "        self.count = {}\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.global_means = 0\n",
    "        \n",
    "        self.tgt = tgt\n",
    "        \n",
    "        self.outkeys = [self.outkey + '_level', self.outkey + '_level_std']\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.global_means = df[self.tgt].mean()\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            \n",
    "            self.count[k[0]] = len(k[1])\n",
    "\n",
    "            if len(k[1]) < 0:\n",
    "                self.means[k[0]] = np.nan\n",
    "                self.std[k[0]] = np.nan\n",
    "            else:\n",
    "                self.means[k[0]] = np.mean(k[1][self.tgt])\n",
    "                self.std[k[0]] = np.std(k[1][self.tgt])\n",
    "            \n",
    "    def predict(self, df):\n",
    "        for l in self.outkeys:\n",
    "            df[l] = np.nan # self.global_means[l]\n",
    "            \n",
    "        df[self.outkey + '_count'] = 0\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            if k[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            if k[0] in self.means:\n",
    "                df.loc[k[1].index, self.outkey + '_count'] = self.count[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level'] = self.means[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level_std'] = self.std[k[0]]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_features(self):\n",
    "        return self.outkeys.copy() + [self.outkey + '_count']\n",
    "\n",
    "# i kept the same index randomization (with fixed seed) so I could validate this code against\n",
    "# the original...\n",
    "\n",
    "target_num_map = {'low':0, 'medium':1, 'high':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "def proc_fold(fold):\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    \n",
    "    cv_train = train_df.iloc[train_index]\n",
    "    cv_valid = train_df.iloc[test_index][['interest_level', 'manager_id', 'building_id']]\n",
    "    cv_test = test_df.copy()\n",
    "    \n",
    "    m_build = MeansProcessor('building_id', 'building_sort')\n",
    "    m_build.fit(cv_train)\n",
    "    cv_valid = m_build.predict(cv_valid)\n",
    "    cv_test = m_build.predict(cv_test)\n",
    "\n",
    "    m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "    m_mgr.fit(cv_train)\n",
    "    cv_valid = m_mgr.predict(cv_valid)\n",
    "    cv_test = m_mgr.predict(cv_test)\n",
    "\n",
    "    m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "    m_comb.fit(cv_train)\n",
    "    cv_valid = m_comb.predict(cv_valid)\n",
    "    cv_test = m_comb.predict(cv_test)\n",
    "\n",
    "    return cv_train, cv_valid, cv_test\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "folds = [(k[0], k[1]) for k in kf.split(list(range(train_df.shape[0])), train_y)]\n",
    "\n",
    "#with Pool(5) as pool:\n",
    "#    rv = pool.map(proc_fold, folds)\n",
    "\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    rv = pickle.load(open('0420-model-groupfeatures.pkl', 'rb'))\n",
    "except:\n",
    "    with Pool(5) as pool:\n",
    "        rv = pool.map(proc_fold, folds)\n",
    "\n",
    "        pickle.dump(rv, open('0420-model-groupfeatures.pkl', 'wb'))\n",
    "\n",
    "# dummies to get feature id's\n",
    "m_build = MeansProcessor('building_id', 'building_sort')\n",
    "m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "\n",
    "group_features = m_build.get_features() + m_mgr.get_features() + m_comb.get_features()\n",
    "\n",
    "cv_test = []\n",
    "for r in rv:\n",
    "    cv_test.append(test_df.merge(r[2][group_features], left_index=True, right_index=True))\n",
    "\n",
    "cv_allvalid = pd.concat([r[1] for r in rv])\n",
    "\n",
    "train_df = train_df.merge(cv_allvalid[group_features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for dev_index, val_index in kf.split(range(train_df.shape[0]), train_df.interest_cat):\n",
    "    train_ids.append(train_df.iloc[dev_index].listing_id.values)\n",
    "    val_ids.append(train_df.iloc[val_index].listing_id.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adams_features = ['num_rot15_X', 'num_rot15_Y', 'num_rot30_X', 'num_rot30_Y', 'num_rot45_X', 'num_rot45_Y', 'num_rot60_X', 'num_rot60_Y', 'num_rho', 'num_phi', 'num_cap_share', 'num_nr_of_lines', 'num_redacted', 'num_email', 'num_phone_nr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fl = features_to_use + m_build.get_features() + m_mgr.get_features() + m_comb.get_features() + tfidf_fn\n",
    "\n",
    "fl = features_to_use.copy() + group_features + adams_features.copy()\n",
    "\n",
    "#fl.remove('price')\n",
    "#fl.remove('price_t')\n",
    "#fl.remove('price_per_room')\n",
    "fl.append('predicted_price')\n",
    "fl.append('predicted_price_diff')\n",
    "\n",
    "fl.append('manager_lazy_rate')\n",
    "\n",
    "fl.append('density_exp01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run3_to_stackdf(run):\n",
    "    \n",
    "    df_testpreds3 = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds3.columns = ['low', 'medium', 'high']\n",
    "    df_testpreds3['listing_id'] = test_df.listing_id\n",
    "\n",
    "    df_allpreds3 = pd.concat([run[1][['low', 'medium', 'high', 'listing_id']], df_testpreds3])\n",
    "\n",
    "    df_allpreds3.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds3.set_index('listing_id', inplace=True)\n",
    "    \n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds3, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "15a46712-582b-28f7-1626-917cdab4f7e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    #param['base_score'] = [np.mean(train_y == i) for i in [0, 1, 2]]\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(train_df, cv_test, kf, features_to_use):\n",
    "    train_X = train_df[features_to_use]\n",
    "    train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        interest = cut_df.interest_level.apply(lambda x: target_num_map[x])\n",
    "        out_df['interest_tgt'] = interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(log_loss(df_cv.interest_tgt, df_cv[['low', 'medium', 'high']]))\n",
    "\n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.0843\ttest-mlogloss:1.08452\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962632\ttest-mlogloss:0.965063\n",
      "[20]\ttrain-mlogloss:0.871514\ttest-mlogloss:0.875962\n",
      "[30]\ttrain-mlogloss:0.800614\ttest-mlogloss:0.80751\n",
      "[40]\ttrain-mlogloss:0.745262\ttest-mlogloss:0.754446\n",
      "[50]\ttrain-mlogloss:0.700616\ttest-mlogloss:0.712114\n",
      "[60]\ttrain-mlogloss:0.665245\ttest-mlogloss:0.679158\n",
      "[70]\ttrain-mlogloss:0.636389\ttest-mlogloss:0.652703\n",
      "[80]\ttrain-mlogloss:0.612529\ttest-mlogloss:0.631245\n",
      "[90]\ttrain-mlogloss:0.592969\ttest-mlogloss:0.613856\n",
      "[100]\ttrain-mlogloss:0.576529\ttest-mlogloss:0.599517\n",
      "[110]\ttrain-mlogloss:0.562609\ttest-mlogloss:0.587732\n",
      "[120]\ttrain-mlogloss:0.550703\ttest-mlogloss:0.577969\n",
      "[130]\ttrain-mlogloss:0.540578\ttest-mlogloss:0.569841\n",
      "[140]\ttrain-mlogloss:0.531801\ttest-mlogloss:0.562976\n",
      "[150]\ttrain-mlogloss:0.524123\ttest-mlogloss:0.557312\n",
      "[160]\ttrain-mlogloss:0.517427\ttest-mlogloss:0.552572\n",
      "[170]\ttrain-mlogloss:0.511243\ttest-mlogloss:0.548362\n",
      "[180]\ttrain-mlogloss:0.505627\ttest-mlogloss:0.54462\n",
      "[190]\ttrain-mlogloss:0.500577\ttest-mlogloss:0.541516\n",
      "[200]\ttrain-mlogloss:0.496057\ttest-mlogloss:0.538659\n",
      "[210]\ttrain-mlogloss:0.491808\ttest-mlogloss:0.536176\n",
      "[220]\ttrain-mlogloss:0.487873\ttest-mlogloss:0.534084\n",
      "[230]\ttrain-mlogloss:0.484331\ttest-mlogloss:0.532278\n",
      "[240]\ttrain-mlogloss:0.480666\ttest-mlogloss:0.53036\n",
      "[250]\ttrain-mlogloss:0.477285\ttest-mlogloss:0.528804\n",
      "[260]\ttrain-mlogloss:0.47432\ttest-mlogloss:0.527401\n",
      "[270]\ttrain-mlogloss:0.471564\ttest-mlogloss:0.526083\n",
      "[280]\ttrain-mlogloss:0.468669\ttest-mlogloss:0.524847\n",
      "[290]\ttrain-mlogloss:0.465895\ttest-mlogloss:0.523686\n",
      "[300]\ttrain-mlogloss:0.463197\ttest-mlogloss:0.522611\n",
      "[310]\ttrain-mlogloss:0.460487\ttest-mlogloss:0.521429\n",
      "[320]\ttrain-mlogloss:0.457938\ttest-mlogloss:0.520591\n",
      "[330]\ttrain-mlogloss:0.455568\ttest-mlogloss:0.519834\n",
      "[340]\ttrain-mlogloss:0.453265\ttest-mlogloss:0.519078\n",
      "[350]\ttrain-mlogloss:0.451087\ttest-mlogloss:0.518366\n",
      "[360]\ttrain-mlogloss:0.448954\ttest-mlogloss:0.517783\n",
      "[370]\ttrain-mlogloss:0.446849\ttest-mlogloss:0.517062\n",
      "[380]\ttrain-mlogloss:0.444869\ttest-mlogloss:0.5165\n",
      "[390]\ttrain-mlogloss:0.442804\ttest-mlogloss:0.515907\n",
      "[400]\ttrain-mlogloss:0.440687\ttest-mlogloss:0.515336\n",
      "[410]\ttrain-mlogloss:0.438678\ttest-mlogloss:0.514888\n",
      "[420]\ttrain-mlogloss:0.436954\ttest-mlogloss:0.514387\n",
      "[430]\ttrain-mlogloss:0.435228\ttest-mlogloss:0.513875\n",
      "[440]\ttrain-mlogloss:0.433318\ttest-mlogloss:0.513475\n",
      "[450]\ttrain-mlogloss:0.431625\ttest-mlogloss:0.513108\n",
      "[460]\ttrain-mlogloss:0.429857\ttest-mlogloss:0.512725\n",
      "[470]\ttrain-mlogloss:0.428154\ttest-mlogloss:0.512363\n",
      "[480]\ttrain-mlogloss:0.426557\ttest-mlogloss:0.511999\n",
      "[490]\ttrain-mlogloss:0.424958\ttest-mlogloss:0.511635\n",
      "[500]\ttrain-mlogloss:0.423205\ttest-mlogloss:0.511248\n",
      "[510]\ttrain-mlogloss:0.421512\ttest-mlogloss:0.510888\n",
      "[520]\ttrain-mlogloss:0.419972\ttest-mlogloss:0.510564\n",
      "[530]\ttrain-mlogloss:0.418096\ttest-mlogloss:0.510237\n",
      "[540]\ttrain-mlogloss:0.41628\ttest-mlogloss:0.509821\n",
      "[550]\ttrain-mlogloss:0.414723\ttest-mlogloss:0.50958\n",
      "[560]\ttrain-mlogloss:0.412994\ttest-mlogloss:0.509304\n",
      "[570]\ttrain-mlogloss:0.411486\ttest-mlogloss:0.509035\n",
      "[580]\ttrain-mlogloss:0.409767\ttest-mlogloss:0.508842\n",
      "[590]\ttrain-mlogloss:0.408127\ttest-mlogloss:0.508621\n",
      "[600]\ttrain-mlogloss:0.406433\ttest-mlogloss:0.508357\n",
      "[610]\ttrain-mlogloss:0.404847\ttest-mlogloss:0.508142\n",
      "[620]\ttrain-mlogloss:0.40339\ttest-mlogloss:0.507952\n",
      "[630]\ttrain-mlogloss:0.401846\ttest-mlogloss:0.507808\n",
      "[640]\ttrain-mlogloss:0.400383\ttest-mlogloss:0.50764\n",
      "[650]\ttrain-mlogloss:0.398718\ttest-mlogloss:0.507481\n",
      "[660]\ttrain-mlogloss:0.397126\ttest-mlogloss:0.507334\n",
      "[670]\ttrain-mlogloss:0.39575\ttest-mlogloss:0.507187\n",
      "[680]\ttrain-mlogloss:0.394337\ttest-mlogloss:0.507069\n",
      "[690]\ttrain-mlogloss:0.392872\ttest-mlogloss:0.506936\n",
      "[700]\ttrain-mlogloss:0.391407\ttest-mlogloss:0.506771\n",
      "[710]\ttrain-mlogloss:0.389959\ttest-mlogloss:0.506608\n",
      "[720]\ttrain-mlogloss:0.388267\ttest-mlogloss:0.506379\n",
      "[730]\ttrain-mlogloss:0.386816\ttest-mlogloss:0.506181\n",
      "[740]\ttrain-mlogloss:0.38532\ttest-mlogloss:0.505946\n",
      "[750]\ttrain-mlogloss:0.384012\ttest-mlogloss:0.505938\n",
      "[760]\ttrain-mlogloss:0.382522\ttest-mlogloss:0.505894\n",
      "[770]\ttrain-mlogloss:0.380949\ttest-mlogloss:0.505814\n",
      "[780]\ttrain-mlogloss:0.379504\ttest-mlogloss:0.505735\n",
      "[790]\ttrain-mlogloss:0.378122\ttest-mlogloss:0.505645\n",
      "[800]\ttrain-mlogloss:0.376661\ttest-mlogloss:0.505621\n",
      "[810]\ttrain-mlogloss:0.375335\ttest-mlogloss:0.505439\n",
      "[820]\ttrain-mlogloss:0.373878\ttest-mlogloss:0.505299\n",
      "[830]\ttrain-mlogloss:0.372356\ttest-mlogloss:0.50525\n",
      "[840]\ttrain-mlogloss:0.371048\ttest-mlogloss:0.505213\n",
      "[850]\ttrain-mlogloss:0.369632\ttest-mlogloss:0.505144\n",
      "[860]\ttrain-mlogloss:0.36851\ttest-mlogloss:0.505121\n",
      "[870]\ttrain-mlogloss:0.366969\ttest-mlogloss:0.505027\n",
      "[880]\ttrain-mlogloss:0.365698\ttest-mlogloss:0.504924\n",
      "[890]\ttrain-mlogloss:0.364287\ttest-mlogloss:0.504829\n",
      "[900]\ttrain-mlogloss:0.362869\ttest-mlogloss:0.504778\n",
      "[910]\ttrain-mlogloss:0.361409\ttest-mlogloss:0.504671\n",
      "[920]\ttrain-mlogloss:0.359955\ttest-mlogloss:0.504559\n",
      "[930]\ttrain-mlogloss:0.3586\ttest-mlogloss:0.504512\n",
      "[940]\ttrain-mlogloss:0.357286\ttest-mlogloss:0.504529\n",
      "[950]\ttrain-mlogloss:0.355944\ttest-mlogloss:0.50434\n",
      "[960]\ttrain-mlogloss:0.354625\ttest-mlogloss:0.504263\n",
      "[970]\ttrain-mlogloss:0.353351\ttest-mlogloss:0.5042\n",
      "[980]\ttrain-mlogloss:0.352217\ttest-mlogloss:0.504188\n",
      "[990]\ttrain-mlogloss:0.350983\ttest-mlogloss:0.504131\n",
      "[1000]\ttrain-mlogloss:0.349605\ttest-mlogloss:0.504078\n",
      "[1010]\ttrain-mlogloss:0.348465\ttest-mlogloss:0.504065\n",
      "[1020]\ttrain-mlogloss:0.347195\ttest-mlogloss:0.50405\n",
      "[1030]\ttrain-mlogloss:0.34616\ttest-mlogloss:0.504\n",
      "[1040]\ttrain-mlogloss:0.344973\ttest-mlogloss:0.504012\n",
      "[1050]\ttrain-mlogloss:0.343676\ttest-mlogloss:0.503997\n",
      "[1060]\ttrain-mlogloss:0.342548\ttest-mlogloss:0.503949\n",
      "[1070]\ttrain-mlogloss:0.341165\ttest-mlogloss:0.503902\n",
      "[1080]\ttrain-mlogloss:0.340019\ttest-mlogloss:0.503825\n",
      "[1090]\ttrain-mlogloss:0.338769\ttest-mlogloss:0.503852\n",
      "[1100]\ttrain-mlogloss:0.337513\ttest-mlogloss:0.503765\n",
      "[1110]\ttrain-mlogloss:0.33628\ttest-mlogloss:0.503702\n",
      "[1120]\ttrain-mlogloss:0.335216\ttest-mlogloss:0.503638\n",
      "[1130]\ttrain-mlogloss:0.333951\ttest-mlogloss:0.503662\n",
      "[1140]\ttrain-mlogloss:0.33272\ttest-mlogloss:0.503663\n",
      "[1150]\ttrain-mlogloss:0.331435\ttest-mlogloss:0.50358\n",
      "[1160]\ttrain-mlogloss:0.330239\ttest-mlogloss:0.503633\n",
      "[1170]\ttrain-mlogloss:0.328997\ttest-mlogloss:0.503613\n",
      "[1180]\ttrain-mlogloss:0.327721\ttest-mlogloss:0.50357\n",
      "[1190]\ttrain-mlogloss:0.326513\ttest-mlogloss:0.503569\n",
      "Stopping. Best iteration:\n",
      "[1148]\ttrain-mlogloss:0.331644\ttest-mlogloss:0.503548\n",
      "\n",
      "[0.50354797493140779]\n",
      "[0]\ttrain-mlogloss:1.08441\ttest-mlogloss:1.08447\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.963338\ttest-mlogloss:0.96512\n",
      "[20]\ttrain-mlogloss:0.872293\ttest-mlogloss:0.875789\n",
      "[30]\ttrain-mlogloss:0.801673\ttest-mlogloss:0.80687\n",
      "[40]\ttrain-mlogloss:0.746456\ttest-mlogloss:0.753397\n",
      "[50]\ttrain-mlogloss:0.701918\ttest-mlogloss:0.710507\n",
      "[60]\ttrain-mlogloss:0.666698\ttest-mlogloss:0.676959\n",
      "[70]\ttrain-mlogloss:0.637917\ttest-mlogloss:0.65002\n",
      "[80]\ttrain-mlogloss:0.614188\ttest-mlogloss:0.62805\n",
      "[90]\ttrain-mlogloss:0.59472\ttest-mlogloss:0.610331\n",
      "[100]\ttrain-mlogloss:0.578207\ttest-mlogloss:0.59564\n",
      "[110]\ttrain-mlogloss:0.564296\ttest-mlogloss:0.583486\n",
      "[120]\ttrain-mlogloss:0.552471\ttest-mlogloss:0.573411\n",
      "[130]\ttrain-mlogloss:0.542331\ttest-mlogloss:0.565022\n",
      "[140]\ttrain-mlogloss:0.533491\ttest-mlogloss:0.557949\n",
      "[150]\ttrain-mlogloss:0.525761\ttest-mlogloss:0.55193\n",
      "[160]\ttrain-mlogloss:0.518923\ttest-mlogloss:0.546847\n",
      "[170]\ttrain-mlogloss:0.512907\ttest-mlogloss:0.542477\n",
      "[180]\ttrain-mlogloss:0.507334\ttest-mlogloss:0.538635\n",
      "[190]\ttrain-mlogloss:0.502388\ttest-mlogloss:0.535317\n",
      "[200]\ttrain-mlogloss:0.497888\ttest-mlogloss:0.532502\n",
      "[210]\ttrain-mlogloss:0.493461\ttest-mlogloss:0.530008\n",
      "[220]\ttrain-mlogloss:0.489623\ttest-mlogloss:0.527737\n",
      "[230]\ttrain-mlogloss:0.485919\ttest-mlogloss:0.525744\n",
      "[240]\ttrain-mlogloss:0.482474\ttest-mlogloss:0.523962\n",
      "[250]\ttrain-mlogloss:0.479292\ttest-mlogloss:0.522355\n",
      "[260]\ttrain-mlogloss:0.476407\ttest-mlogloss:0.520875\n",
      "[270]\ttrain-mlogloss:0.473338\ttest-mlogloss:0.51953\n",
      "[280]\ttrain-mlogloss:0.470426\ttest-mlogloss:0.518263\n",
      "[290]\ttrain-mlogloss:0.467696\ttest-mlogloss:0.517177\n",
      "[300]\ttrain-mlogloss:0.465222\ttest-mlogloss:0.516321\n",
      "[310]\ttrain-mlogloss:0.462826\ttest-mlogloss:0.51541\n",
      "[320]\ttrain-mlogloss:0.460516\ttest-mlogloss:0.514552\n",
      "[330]\ttrain-mlogloss:0.457944\ttest-mlogloss:0.513648\n",
      "[340]\ttrain-mlogloss:0.455696\ttest-mlogloss:0.512938\n",
      "[350]\ttrain-mlogloss:0.453398\ttest-mlogloss:0.512143\n",
      "[360]\ttrain-mlogloss:0.451104\ttest-mlogloss:0.511343\n",
      "[370]\ttrain-mlogloss:0.448978\ttest-mlogloss:0.510797\n",
      "[380]\ttrain-mlogloss:0.446959\ttest-mlogloss:0.510284\n",
      "[390]\ttrain-mlogloss:0.444992\ttest-mlogloss:0.509778\n",
      "[400]\ttrain-mlogloss:0.443042\ttest-mlogloss:0.50922\n",
      "[410]\ttrain-mlogloss:0.440953\ttest-mlogloss:0.508712\n",
      "[420]\ttrain-mlogloss:0.438952\ttest-mlogloss:0.5083\n",
      "[430]\ttrain-mlogloss:0.437078\ttest-mlogloss:0.507833\n",
      "[440]\ttrain-mlogloss:0.435347\ttest-mlogloss:0.507542\n",
      "[450]\ttrain-mlogloss:0.433531\ttest-mlogloss:0.507203\n",
      "[460]\ttrain-mlogloss:0.431669\ttest-mlogloss:0.506852\n",
      "[470]\ttrain-mlogloss:0.429938\ttest-mlogloss:0.506513\n",
      "[480]\ttrain-mlogloss:0.428168\ttest-mlogloss:0.506195\n",
      "[490]\ttrain-mlogloss:0.426265\ttest-mlogloss:0.505867\n",
      "[500]\ttrain-mlogloss:0.42444\ttest-mlogloss:0.505696\n",
      "[510]\ttrain-mlogloss:0.422833\ttest-mlogloss:0.50536\n",
      "[520]\ttrain-mlogloss:0.42106\ttest-mlogloss:0.505053\n",
      "[530]\ttrain-mlogloss:0.419275\ttest-mlogloss:0.504855\n",
      "[540]\ttrain-mlogloss:0.417739\ttest-mlogloss:0.504622\n",
      "[550]\ttrain-mlogloss:0.415985\ttest-mlogloss:0.504339\n",
      "[560]\ttrain-mlogloss:0.41443\ttest-mlogloss:0.503984\n",
      "[570]\ttrain-mlogloss:0.41288\ttest-mlogloss:0.503696\n",
      "[580]\ttrain-mlogloss:0.411124\ttest-mlogloss:0.50348\n",
      "[590]\ttrain-mlogloss:0.409498\ttest-mlogloss:0.503242\n",
      "[600]\ttrain-mlogloss:0.407858\ttest-mlogloss:0.503054\n",
      "[610]\ttrain-mlogloss:0.406342\ttest-mlogloss:0.5029\n",
      "[620]\ttrain-mlogloss:0.404835\ttest-mlogloss:0.502742\n",
      "[630]\ttrain-mlogloss:0.403322\ttest-mlogloss:0.502587\n",
      "[640]\ttrain-mlogloss:0.401903\ttest-mlogloss:0.502477\n",
      "[650]\ttrain-mlogloss:0.400476\ttest-mlogloss:0.502355\n",
      "[660]\ttrain-mlogloss:0.39893\ttest-mlogloss:0.502176\n",
      "[670]\ttrain-mlogloss:0.397316\ttest-mlogloss:0.502036\n",
      "[680]\ttrain-mlogloss:0.395909\ttest-mlogloss:0.501942\n",
      "[690]\ttrain-mlogloss:0.394373\ttest-mlogloss:0.501752\n",
      "[700]\ttrain-mlogloss:0.392947\ttest-mlogloss:0.501647\n",
      "[710]\ttrain-mlogloss:0.391624\ttest-mlogloss:0.501503\n",
      "[720]\ttrain-mlogloss:0.390085\ttest-mlogloss:0.501304\n",
      "[730]\ttrain-mlogloss:0.388485\ttest-mlogloss:0.501104\n",
      "[740]\ttrain-mlogloss:0.387125\ttest-mlogloss:0.501058\n",
      "[750]\ttrain-mlogloss:0.385653\ttest-mlogloss:0.500946\n",
      "[760]\ttrain-mlogloss:0.38423\ttest-mlogloss:0.500878\n",
      "[770]\ttrain-mlogloss:0.382705\ttest-mlogloss:0.500801\n",
      "[780]\ttrain-mlogloss:0.381314\ttest-mlogloss:0.500695\n",
      "[790]\ttrain-mlogloss:0.379896\ttest-mlogloss:0.500481\n",
      "[800]\ttrain-mlogloss:0.378673\ttest-mlogloss:0.500342\n",
      "[810]\ttrain-mlogloss:0.377267\ttest-mlogloss:0.500304\n",
      "[820]\ttrain-mlogloss:0.375808\ttest-mlogloss:0.500208\n",
      "[830]\ttrain-mlogloss:0.37454\ttest-mlogloss:0.500205\n",
      "[840]\ttrain-mlogloss:0.373047\ttest-mlogloss:0.500074\n",
      "[850]\ttrain-mlogloss:0.371705\ttest-mlogloss:0.499973\n",
      "[860]\ttrain-mlogloss:0.370419\ttest-mlogloss:0.499936\n",
      "[870]\ttrain-mlogloss:0.369036\ttest-mlogloss:0.499895\n",
      "[880]\ttrain-mlogloss:0.3678\ttest-mlogloss:0.499854\n",
      "[890]\ttrain-mlogloss:0.3665\ttest-mlogloss:0.499792\n",
      "[900]\ttrain-mlogloss:0.365206\ttest-mlogloss:0.499683\n",
      "[910]\ttrain-mlogloss:0.363882\ttest-mlogloss:0.499602\n",
      "[920]\ttrain-mlogloss:0.362477\ttest-mlogloss:0.499523\n",
      "[930]\ttrain-mlogloss:0.361074\ttest-mlogloss:0.499432\n",
      "[940]\ttrain-mlogloss:0.359805\ttest-mlogloss:0.499419\n",
      "[950]\ttrain-mlogloss:0.358464\ttest-mlogloss:0.499283\n",
      "[960]\ttrain-mlogloss:0.357269\ttest-mlogloss:0.499233\n",
      "[970]\ttrain-mlogloss:0.355916\ttest-mlogloss:0.499079\n",
      "[980]\ttrain-mlogloss:0.35467\ttest-mlogloss:0.499032\n",
      "[990]\ttrain-mlogloss:0.353303\ttest-mlogloss:0.49894\n",
      "[1000]\ttrain-mlogloss:0.351995\ttest-mlogloss:0.498896\n",
      "[1010]\ttrain-mlogloss:0.350829\ttest-mlogloss:0.498867\n",
      "[1020]\ttrain-mlogloss:0.349608\ttest-mlogloss:0.498833\n",
      "[1030]\ttrain-mlogloss:0.34845\ttest-mlogloss:0.498787\n",
      "[1040]\ttrain-mlogloss:0.34714\ttest-mlogloss:0.498707\n",
      "[1050]\ttrain-mlogloss:0.345986\ttest-mlogloss:0.498684\n",
      "[1060]\ttrain-mlogloss:0.344971\ttest-mlogloss:0.498691\n",
      "[1070]\ttrain-mlogloss:0.343566\ttest-mlogloss:0.498622\n",
      "[1080]\ttrain-mlogloss:0.342284\ttest-mlogloss:0.498547\n",
      "[1090]\ttrain-mlogloss:0.340959\ttest-mlogloss:0.49846\n",
      "[1100]\ttrain-mlogloss:0.339795\ttest-mlogloss:0.498383\n",
      "[1110]\ttrain-mlogloss:0.33853\ttest-mlogloss:0.498366\n",
      "[1120]\ttrain-mlogloss:0.337245\ttest-mlogloss:0.498369\n",
      "[1130]\ttrain-mlogloss:0.33597\ttest-mlogloss:0.4983\n",
      "[1140]\ttrain-mlogloss:0.334827\ttest-mlogloss:0.498267\n",
      "[1150]\ttrain-mlogloss:0.333687\ttest-mlogloss:0.498134\n",
      "[1160]\ttrain-mlogloss:0.332545\ttest-mlogloss:0.498063\n",
      "[1170]\ttrain-mlogloss:0.33133\ttest-mlogloss:0.497993\n",
      "[1180]\ttrain-mlogloss:0.330098\ttest-mlogloss:0.497883\n",
      "[1190]\ttrain-mlogloss:0.328995\ttest-mlogloss:0.49781\n",
      "[1200]\ttrain-mlogloss:0.327856\ttest-mlogloss:0.497813\n",
      "[1210]\ttrain-mlogloss:0.326682\ttest-mlogloss:0.497791\n",
      "[1220]\ttrain-mlogloss:0.325566\ttest-mlogloss:0.497639\n",
      "[1230]\ttrain-mlogloss:0.324294\ttest-mlogloss:0.497647\n",
      "[1240]\ttrain-mlogloss:0.323246\ttest-mlogloss:0.49762\n",
      "[1250]\ttrain-mlogloss:0.322107\ttest-mlogloss:0.497593\n",
      "[1260]\ttrain-mlogloss:0.320932\ttest-mlogloss:0.497562\n",
      "[1270]\ttrain-mlogloss:0.319832\ttest-mlogloss:0.497478\n",
      "[1280]\ttrain-mlogloss:0.318678\ttest-mlogloss:0.497483\n",
      "[1290]\ttrain-mlogloss:0.317526\ttest-mlogloss:0.497437\n",
      "[1300]\ttrain-mlogloss:0.316343\ttest-mlogloss:0.497394\n",
      "[1310]\ttrain-mlogloss:0.315194\ttest-mlogloss:0.497328\n",
      "[1320]\ttrain-mlogloss:0.314014\ttest-mlogloss:0.497331\n",
      "[1330]\ttrain-mlogloss:0.313055\ttest-mlogloss:0.497315\n",
      "[1340]\ttrain-mlogloss:0.312034\ttest-mlogloss:0.497276\n",
      "[1350]\ttrain-mlogloss:0.310972\ttest-mlogloss:0.497395\n",
      "[1360]\ttrain-mlogloss:0.309897\ttest-mlogloss:0.497488\n",
      "[1370]\ttrain-mlogloss:0.308827\ttest-mlogloss:0.497463\n",
      "[1380]\ttrain-mlogloss:0.30767\ttest-mlogloss:0.497458\n",
      "[1390]\ttrain-mlogloss:0.306563\ttest-mlogloss:0.497535\n",
      "Stopping. Best iteration:\n",
      "[1340]\ttrain-mlogloss:0.312034\ttest-mlogloss:0.497276\n",
      "\n",
      "[0.50354797493140779, 0.49727635213071869]\n",
      "[0]\ttrain-mlogloss:1.08426\ttest-mlogloss:1.08473\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962354\ttest-mlogloss:0.966784\n",
      "[20]\ttrain-mlogloss:0.870781\ttest-mlogloss:0.87868\n",
      "[30]\ttrain-mlogloss:0.799577\ttest-mlogloss:0.810948\n",
      "[40]\ttrain-mlogloss:0.744205\ttest-mlogloss:0.758608\n",
      "[50]\ttrain-mlogloss:0.699562\ttest-mlogloss:0.716695\n",
      "[60]\ttrain-mlogloss:0.664085\ttest-mlogloss:0.683849\n",
      "[70]\ttrain-mlogloss:0.635242\ttest-mlogloss:0.657538\n",
      "[80]\ttrain-mlogloss:0.611469\ttest-mlogloss:0.636129\n",
      "[90]\ttrain-mlogloss:0.591668\ttest-mlogloss:0.618659\n",
      "[100]\ttrain-mlogloss:0.575058\ttest-mlogloss:0.60424\n",
      "[110]\ttrain-mlogloss:0.561069\ttest-mlogloss:0.592427\n",
      "[120]\ttrain-mlogloss:0.549162\ttest-mlogloss:0.582647\n",
      "[130]\ttrain-mlogloss:0.538953\ttest-mlogloss:0.574408\n",
      "[140]\ttrain-mlogloss:0.530174\ttest-mlogloss:0.567637\n",
      "[150]\ttrain-mlogloss:0.522513\ttest-mlogloss:0.561946\n",
      "[160]\ttrain-mlogloss:0.51571\ttest-mlogloss:0.557206\n",
      "[170]\ttrain-mlogloss:0.509541\ttest-mlogloss:0.552922\n",
      "[180]\ttrain-mlogloss:0.504099\ttest-mlogloss:0.549406\n",
      "[190]\ttrain-mlogloss:0.499039\ttest-mlogloss:0.546253\n",
      "[200]\ttrain-mlogloss:0.494542\ttest-mlogloss:0.543474\n",
      "[210]\ttrain-mlogloss:0.490419\ttest-mlogloss:0.541056\n",
      "[220]\ttrain-mlogloss:0.486534\ttest-mlogloss:0.538834\n",
      "[230]\ttrain-mlogloss:0.482746\ttest-mlogloss:0.536719\n",
      "[240]\ttrain-mlogloss:0.479371\ttest-mlogloss:0.534935\n",
      "[250]\ttrain-mlogloss:0.476163\ttest-mlogloss:0.533408\n",
      "[260]\ttrain-mlogloss:0.473017\ttest-mlogloss:0.53202\n",
      "[270]\ttrain-mlogloss:0.470215\ttest-mlogloss:0.530825\n",
      "[280]\ttrain-mlogloss:0.467495\ttest-mlogloss:0.529702\n",
      "[290]\ttrain-mlogloss:0.464672\ttest-mlogloss:0.528519\n",
      "[300]\ttrain-mlogloss:0.461912\ttest-mlogloss:0.527592\n",
      "[310]\ttrain-mlogloss:0.459434\ttest-mlogloss:0.52673\n",
      "[320]\ttrain-mlogloss:0.456968\ttest-mlogloss:0.525802\n",
      "[330]\ttrain-mlogloss:0.454311\ttest-mlogloss:0.524903\n",
      "[340]\ttrain-mlogloss:0.452007\ttest-mlogloss:0.52426\n",
      "[350]\ttrain-mlogloss:0.449917\ttest-mlogloss:0.523643\n",
      "[360]\ttrain-mlogloss:0.447734\ttest-mlogloss:0.523065\n",
      "[370]\ttrain-mlogloss:0.445301\ttest-mlogloss:0.522406\n",
      "[380]\ttrain-mlogloss:0.443257\ttest-mlogloss:0.521839\n",
      "[390]\ttrain-mlogloss:0.441171\ttest-mlogloss:0.521375\n",
      "[400]\ttrain-mlogloss:0.439199\ttest-mlogloss:0.520917\n",
      "[410]\ttrain-mlogloss:0.437249\ttest-mlogloss:0.52042\n",
      "[420]\ttrain-mlogloss:0.435247\ttest-mlogloss:0.519972\n",
      "[430]\ttrain-mlogloss:0.433564\ttest-mlogloss:0.519614\n",
      "[440]\ttrain-mlogloss:0.431711\ttest-mlogloss:0.519282\n",
      "[450]\ttrain-mlogloss:0.429893\ttest-mlogloss:0.51893\n",
      "[460]\ttrain-mlogloss:0.427968\ttest-mlogloss:0.518588\n",
      "[470]\ttrain-mlogloss:0.426423\ttest-mlogloss:0.518248\n",
      "[480]\ttrain-mlogloss:0.424701\ttest-mlogloss:0.51798\n",
      "[490]\ttrain-mlogloss:0.422972\ttest-mlogloss:0.517625\n",
      "[500]\ttrain-mlogloss:0.421223\ttest-mlogloss:0.517306\n",
      "[510]\ttrain-mlogloss:0.41941\ttest-mlogloss:0.517073\n",
      "[520]\ttrain-mlogloss:0.417667\ttest-mlogloss:0.516773\n",
      "[530]\ttrain-mlogloss:0.416166\ttest-mlogloss:0.516626\n",
      "[540]\ttrain-mlogloss:0.41441\ttest-mlogloss:0.516381\n",
      "[550]\ttrain-mlogloss:0.412924\ttest-mlogloss:0.516156\n",
      "[560]\ttrain-mlogloss:0.411245\ttest-mlogloss:0.515916\n",
      "[570]\ttrain-mlogloss:0.409568\ttest-mlogloss:0.515626\n",
      "[580]\ttrain-mlogloss:0.408187\ttest-mlogloss:0.51539\n",
      "[590]\ttrain-mlogloss:0.406699\ttest-mlogloss:0.515215\n",
      "[600]\ttrain-mlogloss:0.404991\ttest-mlogloss:0.515124\n",
      "[610]\ttrain-mlogloss:0.403465\ttest-mlogloss:0.514865\n",
      "[620]\ttrain-mlogloss:0.40177\ttest-mlogloss:0.514694\n",
      "[630]\ttrain-mlogloss:0.400031\ttest-mlogloss:0.51442\n",
      "[640]\ttrain-mlogloss:0.398467\ttest-mlogloss:0.514233\n",
      "[650]\ttrain-mlogloss:0.397062\ttest-mlogloss:0.514072\n",
      "[660]\ttrain-mlogloss:0.395534\ttest-mlogloss:0.513916\n",
      "[670]\ttrain-mlogloss:0.393961\ttest-mlogloss:0.513689\n",
      "[680]\ttrain-mlogloss:0.392397\ttest-mlogloss:0.513418\n",
      "[690]\ttrain-mlogloss:0.390923\ttest-mlogloss:0.513178\n",
      "[700]\ttrain-mlogloss:0.389441\ttest-mlogloss:0.513011\n",
      "[710]\ttrain-mlogloss:0.387945\ttest-mlogloss:0.512965\n",
      "[720]\ttrain-mlogloss:0.386502\ttest-mlogloss:0.512822\n",
      "[730]\ttrain-mlogloss:0.385117\ttest-mlogloss:0.512737\n",
      "[740]\ttrain-mlogloss:0.383892\ttest-mlogloss:0.512516\n",
      "[750]\ttrain-mlogloss:0.382671\ttest-mlogloss:0.512389\n",
      "[760]\ttrain-mlogloss:0.381222\ttest-mlogloss:0.512272\n",
      "[770]\ttrain-mlogloss:0.379735\ttest-mlogloss:0.512119\n",
      "[780]\ttrain-mlogloss:0.378362\ttest-mlogloss:0.512072\n",
      "[790]\ttrain-mlogloss:0.376936\ttest-mlogloss:0.512047\n",
      "[800]\ttrain-mlogloss:0.375588\ttest-mlogloss:0.511921\n",
      "[810]\ttrain-mlogloss:0.374278\ttest-mlogloss:0.511752\n",
      "[820]\ttrain-mlogloss:0.372873\ttest-mlogloss:0.511569\n",
      "[830]\ttrain-mlogloss:0.371578\ttest-mlogloss:0.511432\n",
      "[840]\ttrain-mlogloss:0.370315\ttest-mlogloss:0.511311\n",
      "[850]\ttrain-mlogloss:0.369046\ttest-mlogloss:0.511137\n",
      "[860]\ttrain-mlogloss:0.36767\ttest-mlogloss:0.511073\n",
      "[870]\ttrain-mlogloss:0.366365\ttest-mlogloss:0.511045\n",
      "[880]\ttrain-mlogloss:0.364996\ttest-mlogloss:0.510975\n",
      "[890]\ttrain-mlogloss:0.363611\ttest-mlogloss:0.51087\n",
      "[900]\ttrain-mlogloss:0.362221\ttest-mlogloss:0.51079\n",
      "[910]\ttrain-mlogloss:0.360919\ttest-mlogloss:0.510684\n",
      "[920]\ttrain-mlogloss:0.359511\ttest-mlogloss:0.510571\n",
      "[930]\ttrain-mlogloss:0.35835\ttest-mlogloss:0.510513\n",
      "[940]\ttrain-mlogloss:0.357178\ttest-mlogloss:0.510547\n",
      "[950]\ttrain-mlogloss:0.355781\ttest-mlogloss:0.510484\n",
      "[960]\ttrain-mlogloss:0.354429\ttest-mlogloss:0.510396\n",
      "[970]\ttrain-mlogloss:0.353049\ttest-mlogloss:0.510353\n",
      "[980]\ttrain-mlogloss:0.351611\ttest-mlogloss:0.510288\n",
      "[990]\ttrain-mlogloss:0.350424\ttest-mlogloss:0.510237\n",
      "[1000]\ttrain-mlogloss:0.349147\ttest-mlogloss:0.510164\n",
      "[1010]\ttrain-mlogloss:0.347782\ttest-mlogloss:0.510067\n",
      "[1020]\ttrain-mlogloss:0.346452\ttest-mlogloss:0.510097\n",
      "[1030]\ttrain-mlogloss:0.345001\ttest-mlogloss:0.509948\n",
      "[1040]\ttrain-mlogloss:0.343686\ttest-mlogloss:0.509896\n",
      "[1050]\ttrain-mlogloss:0.342457\ttest-mlogloss:0.509862\n",
      "[1060]\ttrain-mlogloss:0.34129\ttest-mlogloss:0.509761\n",
      "[1070]\ttrain-mlogloss:0.340106\ttest-mlogloss:0.509657\n",
      "[1080]\ttrain-mlogloss:0.33887\ttest-mlogloss:0.509685\n",
      "[1090]\ttrain-mlogloss:0.337587\ttest-mlogloss:0.509662\n",
      "[1100]\ttrain-mlogloss:0.336529\ttest-mlogloss:0.5097\n",
      "[1110]\ttrain-mlogloss:0.335251\ttest-mlogloss:0.509607\n",
      "[1120]\ttrain-mlogloss:0.334053\ttest-mlogloss:0.50952\n",
      "[1130]\ttrain-mlogloss:0.332875\ttest-mlogloss:0.509482\n",
      "[1140]\ttrain-mlogloss:0.331785\ttest-mlogloss:0.509379\n",
      "[1150]\ttrain-mlogloss:0.33052\ttest-mlogloss:0.509339\n",
      "[1160]\ttrain-mlogloss:0.329345\ttest-mlogloss:0.509313\n",
      "[1170]\ttrain-mlogloss:0.3281\ttest-mlogloss:0.509281\n",
      "[1180]\ttrain-mlogloss:0.326889\ttest-mlogloss:0.509157\n",
      "[1190]\ttrain-mlogloss:0.325753\ttest-mlogloss:0.509109\n",
      "[1200]\ttrain-mlogloss:0.32447\ttest-mlogloss:0.509071\n",
      "[1210]\ttrain-mlogloss:0.323233\ttest-mlogloss:0.509133\n",
      "[1220]\ttrain-mlogloss:0.322028\ttest-mlogloss:0.509153\n",
      "[1230]\ttrain-mlogloss:0.320999\ttest-mlogloss:0.509164\n",
      "[1240]\ttrain-mlogloss:0.319809\ttest-mlogloss:0.509093\n",
      "Stopping. Best iteration:\n",
      "[1198]\ttrain-mlogloss:0.324769\ttest-mlogloss:0.509041\n",
      "\n",
      "[0.50354797493140779, 0.49727635213071869, 0.50904081005502133]\n",
      "[0]\ttrain-mlogloss:1.0843\ttest-mlogloss:1.0847\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.96257\ttest-mlogloss:0.966603\n",
      "[20]\ttrain-mlogloss:0.871066\ttest-mlogloss:0.878328\n",
      "[30]\ttrain-mlogloss:0.800099\ttest-mlogloss:0.810332\n",
      "[40]\ttrain-mlogloss:0.744821\ttest-mlogloss:0.757618\n",
      "[50]\ttrain-mlogloss:0.700201\ttest-mlogloss:0.715542\n",
      "[60]\ttrain-mlogloss:0.664688\ttest-mlogloss:0.682406\n",
      "[70]\ttrain-mlogloss:0.635823\ttest-mlogloss:0.655865\n",
      "[80]\ttrain-mlogloss:0.611975\ttest-mlogloss:0.634174\n",
      "[90]\ttrain-mlogloss:0.592279\ttest-mlogloss:0.616644\n",
      "[100]\ttrain-mlogloss:0.575817\ttest-mlogloss:0.602275\n",
      "[110]\ttrain-mlogloss:0.561844\ttest-mlogloss:0.590401\n",
      "[120]\ttrain-mlogloss:0.54992\ttest-mlogloss:0.580621\n",
      "[130]\ttrain-mlogloss:0.539747\ttest-mlogloss:0.572348\n",
      "[140]\ttrain-mlogloss:0.530845\ttest-mlogloss:0.565423\n",
      "[150]\ttrain-mlogloss:0.523199\ttest-mlogloss:0.559518\n",
      "[160]\ttrain-mlogloss:0.516331\ttest-mlogloss:0.5544\n",
      "[170]\ttrain-mlogloss:0.510257\ttest-mlogloss:0.550114\n",
      "[180]\ttrain-mlogloss:0.504637\ttest-mlogloss:0.546228\n",
      "[190]\ttrain-mlogloss:0.499619\ttest-mlogloss:0.542805\n",
      "[200]\ttrain-mlogloss:0.495018\ttest-mlogloss:0.539955\n",
      "[210]\ttrain-mlogloss:0.490889\ttest-mlogloss:0.537424\n",
      "[220]\ttrain-mlogloss:0.48685\ttest-mlogloss:0.535091\n",
      "[230]\ttrain-mlogloss:0.483195\ttest-mlogloss:0.5331\n",
      "[240]\ttrain-mlogloss:0.479688\ttest-mlogloss:0.531309\n",
      "[250]\ttrain-mlogloss:0.476225\ttest-mlogloss:0.529677\n",
      "[260]\ttrain-mlogloss:0.473105\ttest-mlogloss:0.528236\n",
      "[270]\ttrain-mlogloss:0.470114\ttest-mlogloss:0.526924\n",
      "[280]\ttrain-mlogloss:0.467271\ttest-mlogloss:0.525814\n",
      "[290]\ttrain-mlogloss:0.464591\ttest-mlogloss:0.524661\n",
      "[300]\ttrain-mlogloss:0.462065\ttest-mlogloss:0.523795\n",
      "[310]\ttrain-mlogloss:0.459373\ttest-mlogloss:0.522848\n",
      "[320]\ttrain-mlogloss:0.456814\ttest-mlogloss:0.521983\n",
      "[330]\ttrain-mlogloss:0.454387\ttest-mlogloss:0.521174\n",
      "[340]\ttrain-mlogloss:0.452069\ttest-mlogloss:0.52035\n",
      "[350]\ttrain-mlogloss:0.449827\ttest-mlogloss:0.519663\n",
      "[360]\ttrain-mlogloss:0.447658\ttest-mlogloss:0.518948\n",
      "[370]\ttrain-mlogloss:0.4456\ttest-mlogloss:0.518367\n",
      "[380]\ttrain-mlogloss:0.443258\ttest-mlogloss:0.517796\n",
      "[390]\ttrain-mlogloss:0.441213\ttest-mlogloss:0.51728\n",
      "[400]\ttrain-mlogloss:0.439221\ttest-mlogloss:0.516685\n",
      "[410]\ttrain-mlogloss:0.43726\ttest-mlogloss:0.516183\n",
      "[420]\ttrain-mlogloss:0.435591\ttest-mlogloss:0.515699\n",
      "[430]\ttrain-mlogloss:0.433517\ttest-mlogloss:0.515236\n",
      "[440]\ttrain-mlogloss:0.431896\ttest-mlogloss:0.514953\n",
      "[450]\ttrain-mlogloss:0.43002\ttest-mlogloss:0.514533\n",
      "[460]\ttrain-mlogloss:0.428287\ttest-mlogloss:0.514197\n",
      "[470]\ttrain-mlogloss:0.426531\ttest-mlogloss:0.513803\n",
      "[480]\ttrain-mlogloss:0.424743\ttest-mlogloss:0.513481\n",
      "[490]\ttrain-mlogloss:0.422938\ttest-mlogloss:0.513322\n",
      "[500]\ttrain-mlogloss:0.421196\ttest-mlogloss:0.513009\n",
      "[510]\ttrain-mlogloss:0.419446\ttest-mlogloss:0.512763\n",
      "[520]\ttrain-mlogloss:0.418057\ttest-mlogloss:0.512542\n",
      "[530]\ttrain-mlogloss:0.416336\ttest-mlogloss:0.512287\n",
      "[540]\ttrain-mlogloss:0.414579\ttest-mlogloss:0.512071\n",
      "[550]\ttrain-mlogloss:0.41291\ttest-mlogloss:0.511819\n",
      "[560]\ttrain-mlogloss:0.411506\ttest-mlogloss:0.511657\n",
      "[570]\ttrain-mlogloss:0.410062\ttest-mlogloss:0.511449\n",
      "[580]\ttrain-mlogloss:0.408554\ttest-mlogloss:0.511278\n",
      "[590]\ttrain-mlogloss:0.406948\ttest-mlogloss:0.511126\n",
      "[600]\ttrain-mlogloss:0.405218\ttest-mlogloss:0.511036\n",
      "[610]\ttrain-mlogloss:0.403522\ttest-mlogloss:0.510878\n",
      "[620]\ttrain-mlogloss:0.40191\ttest-mlogloss:0.510636\n",
      "[630]\ttrain-mlogloss:0.400306\ttest-mlogloss:0.510392\n",
      "[640]\ttrain-mlogloss:0.398943\ttest-mlogloss:0.510222\n",
      "[650]\ttrain-mlogloss:0.397394\ttest-mlogloss:0.510102\n",
      "[660]\ttrain-mlogloss:0.395815\ttest-mlogloss:0.509959\n",
      "[670]\ttrain-mlogloss:0.394188\ttest-mlogloss:0.509811\n",
      "[680]\ttrain-mlogloss:0.392644\ttest-mlogloss:0.509661\n",
      "[690]\ttrain-mlogloss:0.391195\ttest-mlogloss:0.509526\n",
      "[700]\ttrain-mlogloss:0.389678\ttest-mlogloss:0.509392\n",
      "[710]\ttrain-mlogloss:0.388326\ttest-mlogloss:0.509219\n",
      "[720]\ttrain-mlogloss:0.386889\ttest-mlogloss:0.509137\n",
      "[730]\ttrain-mlogloss:0.385465\ttest-mlogloss:0.50896\n",
      "[740]\ttrain-mlogloss:0.383957\ttest-mlogloss:0.508974\n",
      "[750]\ttrain-mlogloss:0.382314\ttest-mlogloss:0.50882\n",
      "[760]\ttrain-mlogloss:0.380806\ttest-mlogloss:0.508721\n",
      "[770]\ttrain-mlogloss:0.379301\ttest-mlogloss:0.508567\n",
      "[780]\ttrain-mlogloss:0.377876\ttest-mlogloss:0.508469\n",
      "[790]\ttrain-mlogloss:0.376585\ttest-mlogloss:0.508399\n",
      "[800]\ttrain-mlogloss:0.375081\ttest-mlogloss:0.508344\n",
      "[810]\ttrain-mlogloss:0.373704\ttest-mlogloss:0.508262\n",
      "[820]\ttrain-mlogloss:0.372186\ttest-mlogloss:0.50814\n",
      "[830]\ttrain-mlogloss:0.370851\ttest-mlogloss:0.508021\n",
      "[840]\ttrain-mlogloss:0.369565\ttest-mlogloss:0.507855\n",
      "[850]\ttrain-mlogloss:0.368268\ttest-mlogloss:0.507857\n",
      "[860]\ttrain-mlogloss:0.366846\ttest-mlogloss:0.507776\n",
      "[870]\ttrain-mlogloss:0.365489\ttest-mlogloss:0.507637\n",
      "[880]\ttrain-mlogloss:0.363997\ttest-mlogloss:0.507527\n",
      "[890]\ttrain-mlogloss:0.362688\ttest-mlogloss:0.507513\n",
      "[900]\ttrain-mlogloss:0.361354\ttest-mlogloss:0.507454\n",
      "[910]\ttrain-mlogloss:0.359985\ttest-mlogloss:0.507398\n",
      "[920]\ttrain-mlogloss:0.358702\ttest-mlogloss:0.507347\n",
      "[930]\ttrain-mlogloss:0.357415\ttest-mlogloss:0.507253\n",
      "[940]\ttrain-mlogloss:0.356102\ttest-mlogloss:0.50712\n",
      "[950]\ttrain-mlogloss:0.354722\ttest-mlogloss:0.507072\n",
      "[960]\ttrain-mlogloss:0.353535\ttest-mlogloss:0.507031\n",
      "[970]\ttrain-mlogloss:0.352123\ttest-mlogloss:0.507001\n",
      "[980]\ttrain-mlogloss:0.350841\ttest-mlogloss:0.506907\n",
      "[990]\ttrain-mlogloss:0.349527\ttest-mlogloss:0.50684\n",
      "[1000]\ttrain-mlogloss:0.348065\ttest-mlogloss:0.506725\n",
      "[1010]\ttrain-mlogloss:0.346883\ttest-mlogloss:0.506746\n",
      "[1020]\ttrain-mlogloss:0.345745\ttest-mlogloss:0.506719\n",
      "[1030]\ttrain-mlogloss:0.344487\ttest-mlogloss:0.506677\n",
      "[1040]\ttrain-mlogloss:0.343146\ttest-mlogloss:0.506574\n",
      "[1050]\ttrain-mlogloss:0.341875\ttest-mlogloss:0.506514\n",
      "[1060]\ttrain-mlogloss:0.340505\ttest-mlogloss:0.506429\n",
      "[1070]\ttrain-mlogloss:0.339232\ttest-mlogloss:0.50633\n",
      "[1080]\ttrain-mlogloss:0.337991\ttest-mlogloss:0.506265\n",
      "[1090]\ttrain-mlogloss:0.336845\ttest-mlogloss:0.506233\n",
      "[1100]\ttrain-mlogloss:0.335681\ttest-mlogloss:0.506185\n",
      "[1110]\ttrain-mlogloss:0.334446\ttest-mlogloss:0.506179\n",
      "[1120]\ttrain-mlogloss:0.333324\ttest-mlogloss:0.506201\n",
      "[1130]\ttrain-mlogloss:0.332089\ttest-mlogloss:0.506163\n",
      "[1140]\ttrain-mlogloss:0.330955\ttest-mlogloss:0.506104\n",
      "[1150]\ttrain-mlogloss:0.329747\ttest-mlogloss:0.506074\n",
      "[1160]\ttrain-mlogloss:0.328571\ttest-mlogloss:0.505996\n",
      "[1170]\ttrain-mlogloss:0.327361\ttest-mlogloss:0.506024\n",
      "[1180]\ttrain-mlogloss:0.326179\ttest-mlogloss:0.505952\n",
      "[1190]\ttrain-mlogloss:0.325048\ttest-mlogloss:0.505891\n",
      "[1200]\ttrain-mlogloss:0.323968\ttest-mlogloss:0.505875\n",
      "[1210]\ttrain-mlogloss:0.322867\ttest-mlogloss:0.505808\n",
      "[1220]\ttrain-mlogloss:0.321694\ttest-mlogloss:0.505867\n",
      "[1230]\ttrain-mlogloss:0.320454\ttest-mlogloss:0.505893\n",
      "[1240]\ttrain-mlogloss:0.319324\ttest-mlogloss:0.505865\n",
      "[1250]\ttrain-mlogloss:0.318108\ttest-mlogloss:0.505806\n",
      "[1260]\ttrain-mlogloss:0.316875\ttest-mlogloss:0.505727\n",
      "[1270]\ttrain-mlogloss:0.315737\ttest-mlogloss:0.505709\n",
      "[1280]\ttrain-mlogloss:0.314662\ttest-mlogloss:0.505695\n",
      "[1290]\ttrain-mlogloss:0.313601\ttest-mlogloss:0.50568\n",
      "[1300]\ttrain-mlogloss:0.312365\ttest-mlogloss:0.505622\n",
      "[1310]\ttrain-mlogloss:0.311312\ttest-mlogloss:0.505735\n",
      "[1320]\ttrain-mlogloss:0.310273\ttest-mlogloss:0.505719\n",
      "[1330]\ttrain-mlogloss:0.309157\ttest-mlogloss:0.505707\n",
      "[1340]\ttrain-mlogloss:0.30811\ttest-mlogloss:0.505725\n",
      "[1350]\ttrain-mlogloss:0.307024\ttest-mlogloss:0.505628\n",
      "Stopping. Best iteration:\n",
      "[1300]\ttrain-mlogloss:0.312365\ttest-mlogloss:0.505622\n",
      "\n",
      "[0.50354797493140779, 0.49727635213071869, 0.50904081005502133, 0.50562155057920022]\n",
      "[0]\ttrain-mlogloss:1.08437\ttest-mlogloss:1.08469\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.961517\ttest-mlogloss:0.964832\n",
      "[20]\ttrain-mlogloss:0.869499\ttest-mlogloss:0.875438\n",
      "[30]\ttrain-mlogloss:0.798566\ttest-mlogloss:0.806999\n",
      "[40]\ttrain-mlogloss:0.743055\ttest-mlogloss:0.753922\n",
      "[50]\ttrain-mlogloss:0.699129\ttest-mlogloss:0.712352\n",
      "[60]\ttrain-mlogloss:0.663576\ttest-mlogloss:0.679108\n",
      "[70]\ttrain-mlogloss:0.634785\ttest-mlogloss:0.652494\n",
      "[80]\ttrain-mlogloss:0.611254\ttest-mlogloss:0.631034\n",
      "[90]\ttrain-mlogloss:0.591908\ttest-mlogloss:0.613743\n",
      "[100]\ttrain-mlogloss:0.575665\ttest-mlogloss:0.59951\n",
      "[110]\ttrain-mlogloss:0.562081\ttest-mlogloss:0.587843\n",
      "[120]\ttrain-mlogloss:0.550551\ttest-mlogloss:0.578276\n",
      "[130]\ttrain-mlogloss:0.540389\ttest-mlogloss:0.570079\n",
      "[140]\ttrain-mlogloss:0.531721\ttest-mlogloss:0.563221\n",
      "[150]\ttrain-mlogloss:0.523981\ttest-mlogloss:0.557387\n",
      "[160]\ttrain-mlogloss:0.517068\ttest-mlogloss:0.552458\n",
      "[170]\ttrain-mlogloss:0.510985\ttest-mlogloss:0.548231\n",
      "[180]\ttrain-mlogloss:0.505312\ttest-mlogloss:0.544558\n",
      "[190]\ttrain-mlogloss:0.500503\ttest-mlogloss:0.541199\n",
      "[200]\ttrain-mlogloss:0.495856\ttest-mlogloss:0.538408\n",
      "[210]\ttrain-mlogloss:0.491453\ttest-mlogloss:0.535809\n",
      "[220]\ttrain-mlogloss:0.487475\ttest-mlogloss:0.533604\n",
      "[230]\ttrain-mlogloss:0.483761\ttest-mlogloss:0.531505\n",
      "[240]\ttrain-mlogloss:0.480191\ttest-mlogloss:0.529776\n",
      "[250]\ttrain-mlogloss:0.476755\ttest-mlogloss:0.52803\n",
      "[260]\ttrain-mlogloss:0.473638\ttest-mlogloss:0.526556\n",
      "[270]\ttrain-mlogloss:0.470523\ttest-mlogloss:0.52521\n",
      "[280]\ttrain-mlogloss:0.467623\ttest-mlogloss:0.523973\n",
      "[290]\ttrain-mlogloss:0.464854\ttest-mlogloss:0.522805\n",
      "[300]\ttrain-mlogloss:0.462263\ttest-mlogloss:0.521746\n",
      "[310]\ttrain-mlogloss:0.459581\ttest-mlogloss:0.520755\n",
      "[320]\ttrain-mlogloss:0.457196\ttest-mlogloss:0.519821\n",
      "[330]\ttrain-mlogloss:0.454562\ttest-mlogloss:0.518978\n",
      "[340]\ttrain-mlogloss:0.452289\ttest-mlogloss:0.518345\n",
      "[350]\ttrain-mlogloss:0.450212\ttest-mlogloss:0.517635\n",
      "[360]\ttrain-mlogloss:0.447927\ttest-mlogloss:0.516965\n",
      "[370]\ttrain-mlogloss:0.445661\ttest-mlogloss:0.516356\n",
      "[380]\ttrain-mlogloss:0.443638\ttest-mlogloss:0.515821\n",
      "[390]\ttrain-mlogloss:0.441685\ttest-mlogloss:0.515256\n",
      "[400]\ttrain-mlogloss:0.439611\ttest-mlogloss:0.514698\n",
      "[410]\ttrain-mlogloss:0.437697\ttest-mlogloss:0.514221\n",
      "[420]\ttrain-mlogloss:0.435804\ttest-mlogloss:0.513727\n",
      "[430]\ttrain-mlogloss:0.433926\ttest-mlogloss:0.513322\n",
      "[440]\ttrain-mlogloss:0.431995\ttest-mlogloss:0.512914\n",
      "[450]\ttrain-mlogloss:0.430253\ttest-mlogloss:0.512556\n",
      "[460]\ttrain-mlogloss:0.42848\ttest-mlogloss:0.512116\n",
      "[470]\ttrain-mlogloss:0.426735\ttest-mlogloss:0.511707\n",
      "[480]\ttrain-mlogloss:0.424914\ttest-mlogloss:0.511423\n",
      "[490]\ttrain-mlogloss:0.423261\ttest-mlogloss:0.511043\n",
      "[500]\ttrain-mlogloss:0.42161\ttest-mlogloss:0.510801\n",
      "[510]\ttrain-mlogloss:0.419805\ttest-mlogloss:0.510524\n",
      "[520]\ttrain-mlogloss:0.418161\ttest-mlogloss:0.510257\n",
      "[530]\ttrain-mlogloss:0.416549\ttest-mlogloss:0.510007\n",
      "[540]\ttrain-mlogloss:0.414969\ttest-mlogloss:0.509764\n",
      "[550]\ttrain-mlogloss:0.413303\ttest-mlogloss:0.509539\n",
      "[560]\ttrain-mlogloss:0.41152\ttest-mlogloss:0.50934\n",
      "[570]\ttrain-mlogloss:0.41007\ttest-mlogloss:0.509105\n",
      "[580]\ttrain-mlogloss:0.408359\ttest-mlogloss:0.508863\n",
      "[590]\ttrain-mlogloss:0.406938\ttest-mlogloss:0.508725\n",
      "[600]\ttrain-mlogloss:0.405358\ttest-mlogloss:0.508521\n",
      "[610]\ttrain-mlogloss:0.403832\ttest-mlogloss:0.508249\n",
      "[620]\ttrain-mlogloss:0.402341\ttest-mlogloss:0.508104\n",
      "[630]\ttrain-mlogloss:0.400572\ttest-mlogloss:0.507892\n",
      "[640]\ttrain-mlogloss:0.399136\ttest-mlogloss:0.507744\n",
      "[650]\ttrain-mlogloss:0.397506\ttest-mlogloss:0.507566\n",
      "[660]\ttrain-mlogloss:0.396105\ttest-mlogloss:0.50735\n",
      "[670]\ttrain-mlogloss:0.394499\ttest-mlogloss:0.50718\n",
      "[680]\ttrain-mlogloss:0.392887\ttest-mlogloss:0.506973\n",
      "[690]\ttrain-mlogloss:0.391279\ttest-mlogloss:0.506815\n",
      "[700]\ttrain-mlogloss:0.389798\ttest-mlogloss:0.506686\n",
      "[710]\ttrain-mlogloss:0.388279\ttest-mlogloss:0.506577\n",
      "[720]\ttrain-mlogloss:0.386946\ttest-mlogloss:0.506397\n",
      "[730]\ttrain-mlogloss:0.385378\ttest-mlogloss:0.506309\n",
      "[740]\ttrain-mlogloss:0.384035\ttest-mlogloss:0.506183\n",
      "[750]\ttrain-mlogloss:0.382516\ttest-mlogloss:0.506095\n",
      "[760]\ttrain-mlogloss:0.38108\ttest-mlogloss:0.505983\n",
      "[770]\ttrain-mlogloss:0.37966\ttest-mlogloss:0.505891\n",
      "[780]\ttrain-mlogloss:0.378238\ttest-mlogloss:0.505788\n",
      "[790]\ttrain-mlogloss:0.3769\ttest-mlogloss:0.505683\n",
      "[800]\ttrain-mlogloss:0.375646\ttest-mlogloss:0.505608\n",
      "[810]\ttrain-mlogloss:0.374144\ttest-mlogloss:0.505501\n",
      "[820]\ttrain-mlogloss:0.372702\ttest-mlogloss:0.505424\n",
      "[830]\ttrain-mlogloss:0.371296\ttest-mlogloss:0.505411\n",
      "[840]\ttrain-mlogloss:0.369804\ttest-mlogloss:0.505351\n",
      "[850]\ttrain-mlogloss:0.368521\ttest-mlogloss:0.505282\n",
      "[860]\ttrain-mlogloss:0.367096\ttest-mlogloss:0.505201\n",
      "[870]\ttrain-mlogloss:0.365739\ttest-mlogloss:0.505056\n",
      "[880]\ttrain-mlogloss:0.364203\ttest-mlogloss:0.504942\n",
      "[890]\ttrain-mlogloss:0.36287\ttest-mlogloss:0.504868\n",
      "[900]\ttrain-mlogloss:0.361514\ttest-mlogloss:0.504776\n",
      "[910]\ttrain-mlogloss:0.3601\ttest-mlogloss:0.504664\n",
      "[920]\ttrain-mlogloss:0.35877\ttest-mlogloss:0.504659\n",
      "[930]\ttrain-mlogloss:0.3574\ttest-mlogloss:0.504576\n",
      "[940]\ttrain-mlogloss:0.356138\ttest-mlogloss:0.504547\n",
      "[950]\ttrain-mlogloss:0.354866\ttest-mlogloss:0.504486\n",
      "[960]\ttrain-mlogloss:0.353533\ttest-mlogloss:0.504421\n",
      "[970]\ttrain-mlogloss:0.352283\ttest-mlogloss:0.504366\n",
      "[980]\ttrain-mlogloss:0.350951\ttest-mlogloss:0.504301\n",
      "[990]\ttrain-mlogloss:0.349846\ttest-mlogloss:0.5042\n",
      "[1000]\ttrain-mlogloss:0.348739\ttest-mlogloss:0.504165\n",
      "[1010]\ttrain-mlogloss:0.347497\ttest-mlogloss:0.50409\n",
      "[1020]\ttrain-mlogloss:0.346223\ttest-mlogloss:0.50396\n",
      "[1030]\ttrain-mlogloss:0.34486\ttest-mlogloss:0.503909\n",
      "[1040]\ttrain-mlogloss:0.343493\ttest-mlogloss:0.503808\n",
      "[1050]\ttrain-mlogloss:0.342261\ttest-mlogloss:0.503758\n",
      "[1060]\ttrain-mlogloss:0.341042\ttest-mlogloss:0.503685\n",
      "[1070]\ttrain-mlogloss:0.339874\ttest-mlogloss:0.503614\n",
      "[1080]\ttrain-mlogloss:0.338726\ttest-mlogloss:0.503542\n",
      "[1090]\ttrain-mlogloss:0.337481\ttest-mlogloss:0.503559\n",
      "[1100]\ttrain-mlogloss:0.336182\ttest-mlogloss:0.503523\n",
      "[1110]\ttrain-mlogloss:0.335128\ttest-mlogloss:0.503474\n",
      "[1120]\ttrain-mlogloss:0.333994\ttest-mlogloss:0.50349\n",
      "[1130]\ttrain-mlogloss:0.332911\ttest-mlogloss:0.503507\n",
      "[1140]\ttrain-mlogloss:0.331737\ttest-mlogloss:0.503426\n",
      "[1150]\ttrain-mlogloss:0.330541\ttest-mlogloss:0.503429\n",
      "[1160]\ttrain-mlogloss:0.329218\ttest-mlogloss:0.503446\n",
      "[1170]\ttrain-mlogloss:0.328009\ttest-mlogloss:0.50342\n",
      "[1180]\ttrain-mlogloss:0.32684\ttest-mlogloss:0.503287\n",
      "[1190]\ttrain-mlogloss:0.3257\ttest-mlogloss:0.503249\n",
      "[1200]\ttrain-mlogloss:0.324627\ttest-mlogloss:0.50324\n",
      "[1210]\ttrain-mlogloss:0.323567\ttest-mlogloss:0.50319\n",
      "[1220]\ttrain-mlogloss:0.322341\ttest-mlogloss:0.503154\n",
      "[1230]\ttrain-mlogloss:0.32121\ttest-mlogloss:0.503181\n",
      "[1240]\ttrain-mlogloss:0.319958\ttest-mlogloss:0.503165\n",
      "[1250]\ttrain-mlogloss:0.318721\ttest-mlogloss:0.503188\n",
      "[1260]\ttrain-mlogloss:0.317462\ttest-mlogloss:0.503167\n",
      "[1270]\ttrain-mlogloss:0.316274\ttest-mlogloss:0.503114\n",
      "[1280]\ttrain-mlogloss:0.315078\ttest-mlogloss:0.503138\n",
      "[1290]\ttrain-mlogloss:0.313979\ttest-mlogloss:0.503143\n",
      "[1300]\ttrain-mlogloss:0.312816\ttest-mlogloss:0.503163\n",
      "[1310]\ttrain-mlogloss:0.31169\ttest-mlogloss:0.50316\n",
      "[1320]\ttrain-mlogloss:0.310757\ttest-mlogloss:0.503137\n",
      "Stopping. Best iteration:\n",
      "[1273]\ttrain-mlogloss:0.315966\ttest-mlogloss:0.503096\n",
      "\n",
      "[0.50354797493140779, 0.49727635213071869, 0.50904081005502133, 0.50562155057920022, 0.50309564042943167]\n",
      "0.503716503364\n"
     ]
    }
   ],
   "source": [
    "rv3 = run_cv(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs3 = run3_to_stackdf(rv3)\n",
    "pickle.dump(dfs3, open('modeloutput-xgb-clf-r3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_to_stackdf(run):\n",
    "    df_testpreds = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds.columns = ['level']\n",
    "    df_testpreds['listing_id'] = cv_test[0].listing_id\n",
    "    df_allpreds = pd.concat([run[1][['level', 'listing_id']], df_testpreds])\n",
    "\n",
    "    df_allpreds.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB1(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'reg:logistic'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 1\n",
    "    param['eval_metric'] = \"rmse\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    param['base_score'] = train_y.mean()\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium_regression_tgt = (.5 + (9/13)) / 2\n",
    "\n",
    "def run_cv1(train_df, cv_test, kf, features_to_use):\n",
    "    \n",
    "    train_X = train_df[features_to_use] #sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "    train_y3 = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "    \n",
    "    train_y = np.zeros_like(train_y3, dtype=np.float32)\n",
    "    train_y[train_y3 == 1] = medium_regression_tgt\n",
    "    train_y[train_y3 == 2] = 1\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB1(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(model.best_score)\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        \n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"level\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        out_df['interest_tgt'] = val_y # cut_df.interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(np.sqrt(sklearn.metrics.mean_squared_error(df_cv.interest_tgt, df_cv.level)))\n",
    "    \n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.334207\ttest-rmse:0.334246\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313838\ttest-rmse:0.314438\n",
      "[20]\ttrain-rmse:0.29779\ttest-rmse:0.29909\n",
      "[30]\ttrain-rmse:0.285302\ttest-rmse:0.287287\n",
      "[40]\ttrain-rmse:0.27554\ttest-rmse:0.278241\n",
      "[50]\ttrain-rmse:0.268255\ttest-rmse:0.271672\n",
      "[60]\ttrain-rmse:0.262388\ttest-rmse:0.266489\n",
      "[70]\ttrain-rmse:0.258037\ttest-rmse:0.262683\n",
      "[80]\ttrain-rmse:0.2544\ttest-rmse:0.259523\n",
      "[90]\ttrain-rmse:0.251435\ttest-rmse:0.257065\n",
      "[100]\ttrain-rmse:0.248993\ttest-rmse:0.255148\n",
      "[110]\ttrain-rmse:0.246917\ttest-rmse:0.253506\n",
      "[120]\ttrain-rmse:0.245168\ttest-rmse:0.252138\n",
      "[130]\ttrain-rmse:0.243581\ttest-rmse:0.250978\n",
      "[140]\ttrain-rmse:0.242149\ttest-rmse:0.249958\n",
      "[150]\ttrain-rmse:0.240888\ttest-rmse:0.24912\n",
      "[160]\ttrain-rmse:0.239864\ttest-rmse:0.248472\n",
      "[170]\ttrain-rmse:0.23884\ttest-rmse:0.247824\n",
      "[180]\ttrain-rmse:0.237959\ttest-rmse:0.247244\n",
      "[190]\ttrain-rmse:0.237147\ttest-rmse:0.246759\n",
      "[200]\ttrain-rmse:0.236228\ttest-rmse:0.246335\n",
      "[210]\ttrain-rmse:0.235378\ttest-rmse:0.24584\n",
      "[220]\ttrain-rmse:0.234634\ttest-rmse:0.245451\n",
      "[230]\ttrain-rmse:0.233899\ttest-rmse:0.24507\n",
      "[240]\ttrain-rmse:0.233375\ttest-rmse:0.244773\n",
      "[250]\ttrain-rmse:0.232802\ttest-rmse:0.244463\n",
      "[260]\ttrain-rmse:0.232169\ttest-rmse:0.244183\n",
      "[270]\ttrain-rmse:0.231624\ttest-rmse:0.243925\n",
      "[280]\ttrain-rmse:0.231101\ttest-rmse:0.243663\n",
      "[290]\ttrain-rmse:0.230498\ttest-rmse:0.243431\n",
      "[300]\ttrain-rmse:0.230045\ttest-rmse:0.24323\n",
      "[310]\ttrain-rmse:0.229596\ttest-rmse:0.243034\n",
      "[320]\ttrain-rmse:0.22899\ttest-rmse:0.242834\n",
      "[330]\ttrain-rmse:0.22857\ttest-rmse:0.242652\n",
      "[340]\ttrain-rmse:0.228186\ttest-rmse:0.242506\n",
      "[350]\ttrain-rmse:0.227671\ttest-rmse:0.242362\n",
      "[360]\ttrain-rmse:0.227087\ttest-rmse:0.242227\n",
      "[370]\ttrain-rmse:0.226571\ttest-rmse:0.242033\n",
      "[380]\ttrain-rmse:0.226087\ttest-rmse:0.24189\n",
      "[390]\ttrain-rmse:0.225687\ttest-rmse:0.241813\n",
      "[400]\ttrain-rmse:0.225102\ttest-rmse:0.241633\n",
      "[410]\ttrain-rmse:0.224542\ttest-rmse:0.24151\n",
      "[420]\ttrain-rmse:0.223946\ttest-rmse:0.241387\n",
      "[430]\ttrain-rmse:0.223446\ttest-rmse:0.241264\n",
      "[440]\ttrain-rmse:0.222965\ttest-rmse:0.241135\n",
      "[450]\ttrain-rmse:0.222482\ttest-rmse:0.241039\n",
      "[460]\ttrain-rmse:0.222055\ttest-rmse:0.240929\n",
      "[470]\ttrain-rmse:0.221512\ttest-rmse:0.240795\n",
      "[480]\ttrain-rmse:0.221065\ttest-rmse:0.240694\n",
      "[490]\ttrain-rmse:0.220728\ttest-rmse:0.240615\n",
      "[500]\ttrain-rmse:0.220333\ttest-rmse:0.240523\n",
      "[510]\ttrain-rmse:0.219999\ttest-rmse:0.240476\n",
      "[520]\ttrain-rmse:0.219455\ttest-rmse:0.240416\n",
      "[530]\ttrain-rmse:0.219018\ttest-rmse:0.240327\n",
      "[540]\ttrain-rmse:0.218645\ttest-rmse:0.240249\n",
      "[550]\ttrain-rmse:0.218106\ttest-rmse:0.240167\n",
      "[560]\ttrain-rmse:0.217571\ttest-rmse:0.240131\n",
      "[570]\ttrain-rmse:0.217186\ttest-rmse:0.24007\n",
      "[580]\ttrain-rmse:0.216688\ttest-rmse:0.239979\n",
      "[590]\ttrain-rmse:0.21621\ttest-rmse:0.239899\n",
      "[600]\ttrain-rmse:0.215744\ttest-rmse:0.239857\n",
      "[610]\ttrain-rmse:0.21541\ttest-rmse:0.239805\n",
      "[620]\ttrain-rmse:0.214905\ttest-rmse:0.239755\n",
      "[630]\ttrain-rmse:0.214556\ttest-rmse:0.239699\n",
      "[640]\ttrain-rmse:0.214117\ttest-rmse:0.23964\n",
      "[650]\ttrain-rmse:0.213696\ttest-rmse:0.239565\n",
      "[660]\ttrain-rmse:0.213246\ttest-rmse:0.239531\n",
      "[670]\ttrain-rmse:0.212853\ttest-rmse:0.239449\n",
      "[680]\ttrain-rmse:0.212505\ttest-rmse:0.239414\n",
      "[690]\ttrain-rmse:0.212031\ttest-rmse:0.239379\n",
      "[700]\ttrain-rmse:0.211502\ttest-rmse:0.239345\n",
      "[710]\ttrain-rmse:0.21113\ttest-rmse:0.23932\n",
      "[720]\ttrain-rmse:0.21067\ttest-rmse:0.239253\n",
      "[730]\ttrain-rmse:0.210238\ttest-rmse:0.239201\n",
      "[740]\ttrain-rmse:0.209893\ttest-rmse:0.239154\n",
      "[750]\ttrain-rmse:0.209434\ttest-rmse:0.239095\n",
      "[760]\ttrain-rmse:0.208963\ttest-rmse:0.239039\n",
      "[770]\ttrain-rmse:0.208544\ttest-rmse:0.238977\n",
      "[780]\ttrain-rmse:0.208165\ttest-rmse:0.238905\n",
      "[790]\ttrain-rmse:0.207726\ttest-rmse:0.238811\n",
      "[800]\ttrain-rmse:0.207382\ttest-rmse:0.238765\n",
      "[810]\ttrain-rmse:0.207012\ttest-rmse:0.238745\n",
      "[820]\ttrain-rmse:0.206605\ttest-rmse:0.238713\n",
      "[830]\ttrain-rmse:0.206202\ttest-rmse:0.23866\n",
      "[840]\ttrain-rmse:0.205757\ttest-rmse:0.238657\n",
      "[850]\ttrain-rmse:0.205373\ttest-rmse:0.238644\n",
      "[860]\ttrain-rmse:0.204958\ttest-rmse:0.238607\n",
      "[870]\ttrain-rmse:0.204606\ttest-rmse:0.238583\n",
      "[880]\ttrain-rmse:0.204173\ttest-rmse:0.238536\n",
      "[890]\ttrain-rmse:0.203884\ttest-rmse:0.238526\n",
      "[900]\ttrain-rmse:0.203426\ttest-rmse:0.23848\n",
      "[910]\ttrain-rmse:0.203046\ttest-rmse:0.238436\n",
      "[920]\ttrain-rmse:0.202674\ttest-rmse:0.238413\n",
      "[930]\ttrain-rmse:0.20221\ttest-rmse:0.238382\n",
      "[940]\ttrain-rmse:0.20186\ttest-rmse:0.238375\n",
      "[950]\ttrain-rmse:0.201444\ttest-rmse:0.238347\n",
      "[960]\ttrain-rmse:0.20102\ttest-rmse:0.23833\n",
      "[970]\ttrain-rmse:0.200692\ttest-rmse:0.238311\n",
      "[980]\ttrain-rmse:0.20025\ttest-rmse:0.238301\n",
      "[990]\ttrain-rmse:0.199801\ttest-rmse:0.238303\n",
      "[1000]\ttrain-rmse:0.199396\ttest-rmse:0.238279\n",
      "[1010]\ttrain-rmse:0.199022\ttest-rmse:0.238274\n",
      "[1020]\ttrain-rmse:0.198643\ttest-rmse:0.238248\n",
      "[1030]\ttrain-rmse:0.198348\ttest-rmse:0.238215\n",
      "[1040]\ttrain-rmse:0.19799\ttest-rmse:0.238195\n",
      "[1050]\ttrain-rmse:0.197678\ttest-rmse:0.2382\n",
      "[1060]\ttrain-rmse:0.19728\ttest-rmse:0.238156\n",
      "[1070]\ttrain-rmse:0.196929\ttest-rmse:0.23812\n",
      "[1080]\ttrain-rmse:0.196534\ttest-rmse:0.23807\n",
      "[1090]\ttrain-rmse:0.19622\ttest-rmse:0.238083\n",
      "[1100]\ttrain-rmse:0.195799\ttest-rmse:0.238069\n",
      "[1110]\ttrain-rmse:0.195425\ttest-rmse:0.238067\n",
      "[1120]\ttrain-rmse:0.195083\ttest-rmse:0.238073\n",
      "[1130]\ttrain-rmse:0.194663\ttest-rmse:0.23804\n",
      "[1140]\ttrain-rmse:0.194367\ttest-rmse:0.23803\n",
      "[1150]\ttrain-rmse:0.194004\ttest-rmse:0.238014\n",
      "[1160]\ttrain-rmse:0.193643\ttest-rmse:0.238008\n",
      "[1170]\ttrain-rmse:0.193261\ttest-rmse:0.237982\n",
      "[1180]\ttrain-rmse:0.19286\ttest-rmse:0.237949\n",
      "[1190]\ttrain-rmse:0.192459\ttest-rmse:0.23793\n",
      "[1200]\ttrain-rmse:0.192057\ttest-rmse:0.23791\n",
      "[1210]\ttrain-rmse:0.191714\ttest-rmse:0.237894\n",
      "[1220]\ttrain-rmse:0.191347\ttest-rmse:0.237895\n",
      "[1230]\ttrain-rmse:0.190948\ttest-rmse:0.237879\n",
      "[1240]\ttrain-rmse:0.190604\ttest-rmse:0.237843\n",
      "[1250]\ttrain-rmse:0.190214\ttest-rmse:0.237815\n",
      "[1260]\ttrain-rmse:0.189863\ttest-rmse:0.237804\n",
      "[1270]\ttrain-rmse:0.189436\ttest-rmse:0.237775\n",
      "[1280]\ttrain-rmse:0.189103\ttest-rmse:0.23776\n",
      "[1290]\ttrain-rmse:0.188756\ttest-rmse:0.237747\n",
      "[1300]\ttrain-rmse:0.188435\ttest-rmse:0.237736\n",
      "[1310]\ttrain-rmse:0.188003\ttest-rmse:0.237714\n",
      "[1320]\ttrain-rmse:0.187613\ttest-rmse:0.237663\n",
      "[1330]\ttrain-rmse:0.187307\ttest-rmse:0.237645\n",
      "[1340]\ttrain-rmse:0.186947\ttest-rmse:0.237644\n",
      "[1350]\ttrain-rmse:0.186576\ttest-rmse:0.237657\n",
      "[1360]\ttrain-rmse:0.186228\ttest-rmse:0.237643\n",
      "[1370]\ttrain-rmse:0.185895\ttest-rmse:0.237682\n",
      "[1380]\ttrain-rmse:0.185459\ttest-rmse:0.237656\n",
      "[1390]\ttrain-rmse:0.185138\ttest-rmse:0.237601\n",
      "[1400]\ttrain-rmse:0.184826\ttest-rmse:0.237591\n",
      "[1410]\ttrain-rmse:0.18449\ttest-rmse:0.237602\n",
      "[1420]\ttrain-rmse:0.184151\ttest-rmse:0.237583\n",
      "[1430]\ttrain-rmse:0.183794\ttest-rmse:0.237552\n",
      "[1440]\ttrain-rmse:0.183433\ttest-rmse:0.237568\n",
      "[1450]\ttrain-rmse:0.183089\ttest-rmse:0.23753\n",
      "[1460]\ttrain-rmse:0.18277\ttest-rmse:0.237504\n",
      "[1470]\ttrain-rmse:0.182445\ttest-rmse:0.237508\n",
      "[1480]\ttrain-rmse:0.182045\ttest-rmse:0.237526\n",
      "[1490]\ttrain-rmse:0.181734\ttest-rmse:0.237504\n",
      "[1500]\ttrain-rmse:0.181468\ttest-rmse:0.2375\n",
      "[1510]\ttrain-rmse:0.181231\ttest-rmse:0.237491\n",
      "[1520]\ttrain-rmse:0.180947\ttest-rmse:0.237486\n",
      "[1530]\ttrain-rmse:0.180595\ttest-rmse:0.237489\n",
      "[1540]\ttrain-rmse:0.180192\ttest-rmse:0.237507\n",
      "[1550]\ttrain-rmse:0.179865\ttest-rmse:0.237501\n",
      "[1560]\ttrain-rmse:0.179501\ttest-rmse:0.237523\n",
      "[1570]\ttrain-rmse:0.179137\ttest-rmse:0.237528\n",
      "Stopping. Best iteration:\n",
      "[1520]\ttrain-rmse:0.180947\ttest-rmse:0.237486\n",
      "\n",
      "[0.237486]\n",
      "[0]\ttrain-rmse:0.334188\ttest-rmse:0.334237\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313895\ttest-rmse:0.314328\n",
      "[20]\ttrain-rmse:0.297897\ttest-rmse:0.298755\n",
      "[30]\ttrain-rmse:0.285451\ttest-rmse:0.286825\n",
      "[40]\ttrain-rmse:0.275749\ttest-rmse:0.277552\n",
      "[50]\ttrain-rmse:0.268425\ttest-rmse:0.270724\n",
      "[60]\ttrain-rmse:0.262726\ttest-rmse:0.265503\n",
      "[70]\ttrain-rmse:0.258354\ttest-rmse:0.261597\n",
      "[80]\ttrain-rmse:0.254709\ttest-rmse:0.258391\n",
      "[90]\ttrain-rmse:0.251762\ttest-rmse:0.255882\n",
      "[100]\ttrain-rmse:0.249267\ttest-rmse:0.253841\n",
      "[110]\ttrain-rmse:0.247295\ttest-rmse:0.252208\n",
      "[120]\ttrain-rmse:0.245461\ttest-rmse:0.250854\n",
      "[130]\ttrain-rmse:0.243865\ttest-rmse:0.249683\n",
      "[140]\ttrain-rmse:0.242477\ttest-rmse:0.248658\n",
      "[150]\ttrain-rmse:0.241306\ttest-rmse:0.247816\n",
      "[160]\ttrain-rmse:0.240241\ttest-rmse:0.247045\n",
      "[170]\ttrain-rmse:0.239169\ttest-rmse:0.246338\n",
      "[180]\ttrain-rmse:0.238234\ttest-rmse:0.24572\n",
      "[190]\ttrain-rmse:0.23726\ttest-rmse:0.245181\n",
      "[200]\ttrain-rmse:0.236489\ttest-rmse:0.244748\n",
      "[210]\ttrain-rmse:0.235712\ttest-rmse:0.244356\n",
      "[220]\ttrain-rmse:0.234954\ttest-rmse:0.243959\n",
      "[230]\ttrain-rmse:0.234181\ttest-rmse:0.243612\n",
      "[240]\ttrain-rmse:0.233532\ttest-rmse:0.243308\n",
      "[250]\ttrain-rmse:0.232865\ttest-rmse:0.243013\n",
      "[260]\ttrain-rmse:0.232242\ttest-rmse:0.242777\n",
      "[270]\ttrain-rmse:0.231808\ttest-rmse:0.242556\n",
      "[280]\ttrain-rmse:0.231295\ttest-rmse:0.242312\n",
      "[290]\ttrain-rmse:0.230784\ttest-rmse:0.242165\n",
      "[300]\ttrain-rmse:0.230312\ttest-rmse:0.242017\n",
      "[310]\ttrain-rmse:0.229763\ttest-rmse:0.241784\n",
      "[320]\ttrain-rmse:0.229197\ttest-rmse:0.241608\n",
      "[330]\ttrain-rmse:0.228665\ttest-rmse:0.241466\n",
      "[340]\ttrain-rmse:0.228102\ttest-rmse:0.241312\n",
      "[350]\ttrain-rmse:0.227485\ttest-rmse:0.241108\n",
      "[360]\ttrain-rmse:0.227034\ttest-rmse:0.24102\n",
      "[370]\ttrain-rmse:0.226411\ttest-rmse:0.240862\n",
      "[380]\ttrain-rmse:0.22607\ttest-rmse:0.240767\n",
      "[390]\ttrain-rmse:0.225561\ttest-rmse:0.240671\n",
      "[400]\ttrain-rmse:0.225139\ttest-rmse:0.240613\n",
      "[410]\ttrain-rmse:0.22461\ttest-rmse:0.240502\n",
      "[420]\ttrain-rmse:0.224074\ttest-rmse:0.240387\n",
      "[430]\ttrain-rmse:0.223488\ttest-rmse:0.240299\n",
      "[440]\ttrain-rmse:0.222977\ttest-rmse:0.240228\n",
      "[450]\ttrain-rmse:0.222557\ttest-rmse:0.240163\n",
      "[460]\ttrain-rmse:0.222071\ttest-rmse:0.240033\n",
      "[470]\ttrain-rmse:0.221544\ttest-rmse:0.239939\n",
      "[480]\ttrain-rmse:0.221029\ttest-rmse:0.23984\n",
      "[490]\ttrain-rmse:0.220597\ttest-rmse:0.23974\n",
      "[500]\ttrain-rmse:0.220075\ttest-rmse:0.239637\n",
      "[510]\ttrain-rmse:0.21966\ttest-rmse:0.239564\n",
      "[520]\ttrain-rmse:0.219253\ttest-rmse:0.239529\n",
      "[530]\ttrain-rmse:0.2189\ttest-rmse:0.239477\n",
      "[540]\ttrain-rmse:0.218449\ttest-rmse:0.239412\n",
      "[550]\ttrain-rmse:0.217926\ttest-rmse:0.239336\n",
      "[560]\ttrain-rmse:0.217507\ttest-rmse:0.23928\n",
      "[570]\ttrain-rmse:0.217038\ttest-rmse:0.239233\n",
      "[580]\ttrain-rmse:0.216744\ttest-rmse:0.239181\n",
      "[590]\ttrain-rmse:0.216228\ttest-rmse:0.239112\n",
      "[600]\ttrain-rmse:0.215787\ttest-rmse:0.239029\n",
      "[610]\ttrain-rmse:0.215374\ttest-rmse:0.238946\n",
      "[620]\ttrain-rmse:0.215007\ttest-rmse:0.23889\n",
      "[630]\ttrain-rmse:0.214628\ttest-rmse:0.23886\n",
      "[640]\ttrain-rmse:0.214119\ttest-rmse:0.238814\n",
      "[650]\ttrain-rmse:0.213666\ttest-rmse:0.238769\n",
      "[660]\ttrain-rmse:0.213174\ttest-rmse:0.238711\n",
      "[670]\ttrain-rmse:0.212806\ttest-rmse:0.238657\n",
      "[680]\ttrain-rmse:0.212346\ttest-rmse:0.238615\n",
      "[690]\ttrain-rmse:0.211865\ttest-rmse:0.238569\n",
      "[700]\ttrain-rmse:0.211485\ttest-rmse:0.238542\n",
      "[710]\ttrain-rmse:0.211151\ttest-rmse:0.238457\n",
      "[720]\ttrain-rmse:0.210728\ttest-rmse:0.238404\n",
      "[730]\ttrain-rmse:0.210299\ttest-rmse:0.238411\n",
      "[740]\ttrain-rmse:0.209903\ttest-rmse:0.238372\n",
      "[750]\ttrain-rmse:0.209489\ttest-rmse:0.238361\n",
      "[760]\ttrain-rmse:0.209184\ttest-rmse:0.238338\n",
      "[770]\ttrain-rmse:0.208774\ttest-rmse:0.23826\n",
      "[780]\ttrain-rmse:0.208341\ttest-rmse:0.238263\n",
      "[790]\ttrain-rmse:0.207972\ttest-rmse:0.238259\n",
      "[800]\ttrain-rmse:0.207556\ttest-rmse:0.238232\n",
      "[810]\ttrain-rmse:0.207129\ttest-rmse:0.238191\n",
      "[820]\ttrain-rmse:0.206727\ttest-rmse:0.238161\n",
      "[830]\ttrain-rmse:0.206312\ttest-rmse:0.238113\n",
      "[840]\ttrain-rmse:0.205931\ttest-rmse:0.238041\n",
      "[850]\ttrain-rmse:0.205547\ttest-rmse:0.238037\n",
      "[860]\ttrain-rmse:0.205118\ttest-rmse:0.237971\n",
      "[870]\ttrain-rmse:0.204606\ttest-rmse:0.237935\n",
      "[880]\ttrain-rmse:0.204263\ttest-rmse:0.237914\n",
      "[890]\ttrain-rmse:0.203986\ttest-rmse:0.237907\n",
      "[900]\ttrain-rmse:0.203592\ttest-rmse:0.237876\n",
      "[910]\ttrain-rmse:0.203231\ttest-rmse:0.237838\n",
      "[920]\ttrain-rmse:0.202749\ttest-rmse:0.23782\n",
      "[930]\ttrain-rmse:0.202361\ttest-rmse:0.237829\n",
      "[940]\ttrain-rmse:0.202002\ttest-rmse:0.237791\n",
      "[950]\ttrain-rmse:0.201517\ttest-rmse:0.237804\n",
      "[960]\ttrain-rmse:0.201111\ttest-rmse:0.23779\n",
      "[970]\ttrain-rmse:0.200719\ttest-rmse:0.237792\n",
      "[980]\ttrain-rmse:0.200296\ttest-rmse:0.237759\n",
      "[990]\ttrain-rmse:0.199819\ttest-rmse:0.237721\n",
      "[1000]\ttrain-rmse:0.199455\ttest-rmse:0.237705\n",
      "[1010]\ttrain-rmse:0.199145\ttest-rmse:0.237727\n",
      "[1020]\ttrain-rmse:0.19882\ttest-rmse:0.237714\n",
      "[1030]\ttrain-rmse:0.198353\ttest-rmse:0.237707\n",
      "[1040]\ttrain-rmse:0.197897\ttest-rmse:0.237695\n",
      "[1050]\ttrain-rmse:0.197546\ttest-rmse:0.237701\n",
      "[1060]\ttrain-rmse:0.197171\ttest-rmse:0.237689\n",
      "[1070]\ttrain-rmse:0.196806\ttest-rmse:0.237633\n",
      "[1080]\ttrain-rmse:0.196373\ttest-rmse:0.237662\n",
      "[1090]\ttrain-rmse:0.196043\ttest-rmse:0.237674\n",
      "[1100]\ttrain-rmse:0.195755\ttest-rmse:0.237667\n",
      "[1110]\ttrain-rmse:0.195355\ttest-rmse:0.237675\n",
      "[1120]\ttrain-rmse:0.194978\ttest-rmse:0.237699\n",
      "Stopping. Best iteration:\n",
      "[1075]\ttrain-rmse:0.196628\ttest-rmse:0.237626\n",
      "\n",
      "[0.237486, 0.237626]\n",
      "[0]\ttrain-rmse:0.334147\ttest-rmse:0.334257\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313507\ttest-rmse:0.315023\n",
      "[20]\ttrain-rmse:0.297255\ttest-rmse:0.30019\n",
      "[30]\ttrain-rmse:0.28468\ttest-rmse:0.288742\n",
      "[40]\ttrain-rmse:0.27486\ttest-rmse:0.279944\n",
      "[50]\ttrain-rmse:0.267487\ttest-rmse:0.273484\n",
      "[60]\ttrain-rmse:0.261667\ttest-rmse:0.268495\n",
      "[70]\ttrain-rmse:0.257249\ttest-rmse:0.264832\n",
      "[80]\ttrain-rmse:0.253564\ttest-rmse:0.261776\n",
      "[90]\ttrain-rmse:0.250589\ttest-rmse:0.259433\n",
      "[100]\ttrain-rmse:0.248166\ttest-rmse:0.257565\n",
      "[110]\ttrain-rmse:0.246152\ttest-rmse:0.25604\n",
      "[120]\ttrain-rmse:0.244417\ttest-rmse:0.254818\n",
      "[130]\ttrain-rmse:0.242875\ttest-rmse:0.253663\n",
      "[140]\ttrain-rmse:0.241516\ttest-rmse:0.252783\n",
      "[150]\ttrain-rmse:0.240343\ttest-rmse:0.25199\n",
      "[160]\ttrain-rmse:0.239241\ttest-rmse:0.251289\n",
      "[170]\ttrain-rmse:0.23827\ttest-rmse:0.250665\n",
      "[180]\ttrain-rmse:0.237251\ttest-rmse:0.250054\n",
      "[190]\ttrain-rmse:0.236361\ttest-rmse:0.249485\n",
      "[200]\ttrain-rmse:0.235523\ttest-rmse:0.249039\n",
      "[210]\ttrain-rmse:0.234875\ttest-rmse:0.248645\n",
      "[220]\ttrain-rmse:0.234187\ttest-rmse:0.248266\n",
      "[230]\ttrain-rmse:0.233435\ttest-rmse:0.247863\n",
      "[240]\ttrain-rmse:0.232607\ttest-rmse:0.247441\n",
      "[250]\ttrain-rmse:0.232051\ttest-rmse:0.247175\n",
      "[260]\ttrain-rmse:0.231385\ttest-rmse:0.246906\n",
      "[270]\ttrain-rmse:0.230791\ttest-rmse:0.246627\n",
      "[280]\ttrain-rmse:0.23028\ttest-rmse:0.246423\n",
      "[290]\ttrain-rmse:0.229765\ttest-rmse:0.246247\n",
      "[300]\ttrain-rmse:0.229147\ttest-rmse:0.246021\n",
      "[310]\ttrain-rmse:0.228754\ttest-rmse:0.245856\n",
      "[320]\ttrain-rmse:0.22829\ttest-rmse:0.245687\n",
      "[330]\ttrain-rmse:0.227828\ttest-rmse:0.245497\n",
      "[340]\ttrain-rmse:0.227446\ttest-rmse:0.245346\n",
      "[350]\ttrain-rmse:0.226878\ttest-rmse:0.245195\n",
      "[360]\ttrain-rmse:0.226333\ttest-rmse:0.245074\n",
      "[370]\ttrain-rmse:0.225761\ttest-rmse:0.244915\n",
      "[380]\ttrain-rmse:0.225273\ttest-rmse:0.244764\n",
      "[390]\ttrain-rmse:0.224687\ttest-rmse:0.244592\n",
      "[400]\ttrain-rmse:0.22416\ttest-rmse:0.244418\n",
      "[410]\ttrain-rmse:0.223628\ttest-rmse:0.244339\n",
      "[420]\ttrain-rmse:0.223086\ttest-rmse:0.24426\n",
      "[430]\ttrain-rmse:0.222548\ttest-rmse:0.244124\n",
      "[440]\ttrain-rmse:0.222107\ttest-rmse:0.244007\n",
      "[450]\ttrain-rmse:0.221668\ttest-rmse:0.243948\n",
      "[460]\ttrain-rmse:0.221243\ttest-rmse:0.243821\n",
      "[470]\ttrain-rmse:0.220681\ttest-rmse:0.243715\n",
      "[480]\ttrain-rmse:0.220214\ttest-rmse:0.243614\n",
      "[490]\ttrain-rmse:0.219749\ttest-rmse:0.243521\n",
      "[500]\ttrain-rmse:0.219329\ttest-rmse:0.243481\n",
      "[510]\ttrain-rmse:0.218891\ttest-rmse:0.243399\n",
      "[520]\ttrain-rmse:0.218496\ttest-rmse:0.24333\n",
      "[530]\ttrain-rmse:0.218092\ttest-rmse:0.243271\n",
      "[540]\ttrain-rmse:0.217661\ttest-rmse:0.243199\n",
      "[550]\ttrain-rmse:0.217254\ttest-rmse:0.243106\n",
      "[560]\ttrain-rmse:0.216829\ttest-rmse:0.243049\n",
      "[570]\ttrain-rmse:0.216392\ttest-rmse:0.242995\n",
      "[580]\ttrain-rmse:0.215867\ttest-rmse:0.242929\n",
      "[590]\ttrain-rmse:0.215477\ttest-rmse:0.242856\n",
      "[600]\ttrain-rmse:0.215092\ttest-rmse:0.242767\n",
      "[610]\ttrain-rmse:0.214651\ttest-rmse:0.242662\n",
      "[620]\ttrain-rmse:0.214208\ttest-rmse:0.242652\n",
      "[630]\ttrain-rmse:0.213748\ttest-rmse:0.24259\n",
      "[640]\ttrain-rmse:0.213373\ttest-rmse:0.242508\n",
      "[650]\ttrain-rmse:0.212934\ttest-rmse:0.24246\n",
      "[660]\ttrain-rmse:0.212641\ttest-rmse:0.242439\n",
      "[670]\ttrain-rmse:0.212242\ttest-rmse:0.242403\n",
      "[680]\ttrain-rmse:0.211907\ttest-rmse:0.242327\n",
      "[690]\ttrain-rmse:0.211341\ttest-rmse:0.242262\n",
      "[700]\ttrain-rmse:0.210999\ttest-rmse:0.242228\n",
      "[710]\ttrain-rmse:0.210479\ttest-rmse:0.242203\n",
      "[720]\ttrain-rmse:0.210112\ttest-rmse:0.242165\n",
      "[730]\ttrain-rmse:0.20973\ttest-rmse:0.242133\n",
      "[740]\ttrain-rmse:0.209305\ttest-rmse:0.242098\n",
      "[750]\ttrain-rmse:0.208915\ttest-rmse:0.242044\n",
      "[760]\ttrain-rmse:0.208522\ttest-rmse:0.241989\n",
      "[770]\ttrain-rmse:0.208091\ttest-rmse:0.241938\n",
      "[780]\ttrain-rmse:0.207662\ttest-rmse:0.241867\n",
      "[790]\ttrain-rmse:0.207204\ttest-rmse:0.241836\n",
      "[800]\ttrain-rmse:0.206771\ttest-rmse:0.241812\n",
      "[810]\ttrain-rmse:0.206285\ttest-rmse:0.241795\n",
      "[820]\ttrain-rmse:0.205894\ttest-rmse:0.24173\n",
      "[830]\ttrain-rmse:0.205437\ttest-rmse:0.241696\n",
      "[840]\ttrain-rmse:0.204946\ttest-rmse:0.241683\n",
      "[850]\ttrain-rmse:0.204467\ttest-rmse:0.241651\n",
      "[860]\ttrain-rmse:0.204097\ttest-rmse:0.241607\n",
      "[870]\ttrain-rmse:0.203732\ttest-rmse:0.241605\n",
      "[880]\ttrain-rmse:0.203366\ttest-rmse:0.241583\n",
      "[890]\ttrain-rmse:0.202945\ttest-rmse:0.241568\n",
      "[900]\ttrain-rmse:0.202579\ttest-rmse:0.241545\n",
      "[910]\ttrain-rmse:0.202171\ttest-rmse:0.241535\n",
      "[920]\ttrain-rmse:0.201762\ttest-rmse:0.241521\n",
      "[930]\ttrain-rmse:0.201335\ttest-rmse:0.241497\n",
      "[940]\ttrain-rmse:0.200986\ttest-rmse:0.241469\n",
      "[950]\ttrain-rmse:0.20062\ttest-rmse:0.241446\n",
      "[960]\ttrain-rmse:0.200299\ttest-rmse:0.241438\n",
      "[970]\ttrain-rmse:0.199929\ttest-rmse:0.241373\n",
      "[980]\ttrain-rmse:0.199488\ttest-rmse:0.241346\n",
      "[990]\ttrain-rmse:0.199085\ttest-rmse:0.241316\n",
      "[1000]\ttrain-rmse:0.198721\ttest-rmse:0.241298\n",
      "[1010]\ttrain-rmse:0.198419\ttest-rmse:0.241268\n",
      "[1020]\ttrain-rmse:0.198033\ttest-rmse:0.241269\n",
      "[1030]\ttrain-rmse:0.197702\ttest-rmse:0.241251\n",
      "[1040]\ttrain-rmse:0.197323\ttest-rmse:0.241243\n",
      "[1050]\ttrain-rmse:0.196983\ttest-rmse:0.24123\n",
      "[1060]\ttrain-rmse:0.196506\ttest-rmse:0.241199\n",
      "[1070]\ttrain-rmse:0.196158\ttest-rmse:0.24116\n",
      "[1080]\ttrain-rmse:0.195813\ttest-rmse:0.241156\n",
      "[1090]\ttrain-rmse:0.195477\ttest-rmse:0.241168\n",
      "[1100]\ttrain-rmse:0.19514\ttest-rmse:0.241138\n",
      "[1110]\ttrain-rmse:0.194768\ttest-rmse:0.241158\n",
      "[1120]\ttrain-rmse:0.19433\ttest-rmse:0.241152\n",
      "[1130]\ttrain-rmse:0.193963\ttest-rmse:0.241149\n",
      "[1140]\ttrain-rmse:0.193657\ttest-rmse:0.241121\n",
      "[1150]\ttrain-rmse:0.193241\ttest-rmse:0.241102\n",
      "[1160]\ttrain-rmse:0.192806\ttest-rmse:0.241085\n",
      "[1170]\ttrain-rmse:0.192406\ttest-rmse:0.241083\n",
      "[1180]\ttrain-rmse:0.192027\ttest-rmse:0.241033\n",
      "[1190]\ttrain-rmse:0.191615\ttest-rmse:0.240985\n",
      "[1200]\ttrain-rmse:0.191181\ttest-rmse:0.240956\n",
      "[1210]\ttrain-rmse:0.190807\ttest-rmse:0.240929\n",
      "[1220]\ttrain-rmse:0.190467\ttest-rmse:0.240894\n",
      "[1230]\ttrain-rmse:0.190171\ttest-rmse:0.240875\n",
      "[1240]\ttrain-rmse:0.189822\ttest-rmse:0.24085\n",
      "[1250]\ttrain-rmse:0.189382\ttest-rmse:0.24086\n",
      "[1260]\ttrain-rmse:0.189042\ttest-rmse:0.240822\n",
      "[1270]\ttrain-rmse:0.188645\ttest-rmse:0.24077\n",
      "[1280]\ttrain-rmse:0.188351\ttest-rmse:0.240787\n",
      "[1290]\ttrain-rmse:0.187988\ttest-rmse:0.240787\n",
      "[1300]\ttrain-rmse:0.187698\ttest-rmse:0.240769\n",
      "[1310]\ttrain-rmse:0.187318\ttest-rmse:0.240771\n",
      "[1320]\ttrain-rmse:0.186978\ttest-rmse:0.240768\n",
      "[1330]\ttrain-rmse:0.186713\ttest-rmse:0.240769\n",
      "[1340]\ttrain-rmse:0.186314\ttest-rmse:0.240757\n",
      "[1350]\ttrain-rmse:0.185984\ttest-rmse:0.240729\n",
      "[1360]\ttrain-rmse:0.185622\ttest-rmse:0.240748\n",
      "[1370]\ttrain-rmse:0.185297\ttest-rmse:0.240743\n",
      "[1380]\ttrain-rmse:0.184947\ttest-rmse:0.240741\n",
      "[1390]\ttrain-rmse:0.184615\ttest-rmse:0.240742\n",
      "Stopping. Best iteration:\n",
      "[1346]\ttrain-rmse:0.186137\ttest-rmse:0.240721\n",
      "\n",
      "[0.237486, 0.237626, 0.240721]\n",
      "[0]\ttrain-rmse:0.334172\ttest-rmse:0.3343\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313717\ttest-rmse:0.314793\n",
      "[20]\ttrain-rmse:0.297577\ttest-rmse:0.299581\n",
      "[30]\ttrain-rmse:0.284995\ttest-rmse:0.287832\n",
      "[40]\ttrain-rmse:0.275272\ttest-rmse:0.278891\n",
      "[50]\ttrain-rmse:0.26783\ttest-rmse:0.272154\n",
      "[60]\ttrain-rmse:0.262065\ttest-rmse:0.267103\n",
      "[70]\ttrain-rmse:0.257667\ttest-rmse:0.263269\n",
      "[80]\ttrain-rmse:0.253994\ttest-rmse:0.260183\n",
      "[90]\ttrain-rmse:0.251059\ttest-rmse:0.257769\n",
      "[100]\ttrain-rmse:0.248575\ttest-rmse:0.255809\n",
      "[110]\ttrain-rmse:0.246476\ttest-rmse:0.254194\n",
      "[120]\ttrain-rmse:0.244665\ttest-rmse:0.252891\n",
      "[130]\ttrain-rmse:0.24309\ttest-rmse:0.251793\n",
      "[140]\ttrain-rmse:0.241712\ttest-rmse:0.250898\n",
      "[150]\ttrain-rmse:0.240568\ttest-rmse:0.250139\n",
      "[160]\ttrain-rmse:0.23942\ttest-rmse:0.249399\n",
      "[170]\ttrain-rmse:0.23842\ttest-rmse:0.248757\n",
      "[180]\ttrain-rmse:0.23754\ttest-rmse:0.248278\n",
      "[190]\ttrain-rmse:0.236681\ttest-rmse:0.247821\n",
      "[200]\ttrain-rmse:0.235779\ttest-rmse:0.247346\n",
      "[210]\ttrain-rmse:0.235031\ttest-rmse:0.246942\n",
      "[220]\ttrain-rmse:0.234333\ttest-rmse:0.246573\n",
      "[230]\ttrain-rmse:0.233726\ttest-rmse:0.24627\n",
      "[240]\ttrain-rmse:0.233019\ttest-rmse:0.245957\n",
      "[250]\ttrain-rmse:0.232296\ttest-rmse:0.245675\n",
      "[260]\ttrain-rmse:0.231638\ttest-rmse:0.245424\n",
      "[270]\ttrain-rmse:0.231058\ttest-rmse:0.245135\n",
      "[280]\ttrain-rmse:0.230466\ttest-rmse:0.244889\n",
      "[290]\ttrain-rmse:0.230018\ttest-rmse:0.24465\n",
      "[300]\ttrain-rmse:0.229493\ttest-rmse:0.244475\n",
      "[310]\ttrain-rmse:0.228886\ttest-rmse:0.244266\n",
      "[320]\ttrain-rmse:0.228373\ttest-rmse:0.244051\n",
      "[330]\ttrain-rmse:0.227917\ttest-rmse:0.243856\n",
      "[340]\ttrain-rmse:0.227328\ttest-rmse:0.243686\n",
      "[350]\ttrain-rmse:0.226816\ttest-rmse:0.243514\n",
      "[360]\ttrain-rmse:0.226299\ttest-rmse:0.243361\n",
      "[370]\ttrain-rmse:0.225892\ttest-rmse:0.243227\n",
      "[380]\ttrain-rmse:0.225283\ttest-rmse:0.243124\n",
      "[390]\ttrain-rmse:0.224879\ttest-rmse:0.243003\n",
      "[400]\ttrain-rmse:0.224339\ttest-rmse:0.242812\n",
      "[410]\ttrain-rmse:0.223945\ttest-rmse:0.24271\n",
      "[420]\ttrain-rmse:0.223566\ttest-rmse:0.242612\n",
      "[430]\ttrain-rmse:0.222974\ttest-rmse:0.242495\n",
      "[440]\ttrain-rmse:0.222538\ttest-rmse:0.242392\n",
      "[450]\ttrain-rmse:0.222044\ttest-rmse:0.242299\n",
      "[460]\ttrain-rmse:0.221537\ttest-rmse:0.24214\n",
      "[470]\ttrain-rmse:0.22111\ttest-rmse:0.242006\n",
      "[480]\ttrain-rmse:0.220682\ttest-rmse:0.241929\n",
      "[490]\ttrain-rmse:0.22028\ttest-rmse:0.241829\n",
      "[500]\ttrain-rmse:0.219875\ttest-rmse:0.241755\n",
      "[510]\ttrain-rmse:0.2194\ttest-rmse:0.241688\n",
      "[520]\ttrain-rmse:0.219064\ttest-rmse:0.241652\n",
      "[530]\ttrain-rmse:0.218546\ttest-rmse:0.241553\n",
      "[540]\ttrain-rmse:0.218132\ttest-rmse:0.241471\n",
      "[550]\ttrain-rmse:0.217588\ttest-rmse:0.2414\n",
      "[560]\ttrain-rmse:0.217169\ttest-rmse:0.241354\n",
      "[570]\ttrain-rmse:0.216601\ttest-rmse:0.241273\n",
      "[580]\ttrain-rmse:0.216196\ttest-rmse:0.241204\n",
      "[590]\ttrain-rmse:0.215698\ttest-rmse:0.241131\n",
      "[600]\ttrain-rmse:0.215225\ttest-rmse:0.241053\n",
      "[610]\ttrain-rmse:0.21485\ttest-rmse:0.240989\n",
      "[620]\ttrain-rmse:0.21442\ttest-rmse:0.240935\n",
      "[630]\ttrain-rmse:0.21403\ttest-rmse:0.240876\n",
      "[640]\ttrain-rmse:0.213557\ttest-rmse:0.240791\n",
      "[650]\ttrain-rmse:0.213268\ttest-rmse:0.240759\n",
      "[660]\ttrain-rmse:0.212812\ttest-rmse:0.240695\n",
      "[670]\ttrain-rmse:0.212421\ttest-rmse:0.240649\n",
      "[680]\ttrain-rmse:0.211953\ttest-rmse:0.240586\n",
      "[690]\ttrain-rmse:0.211518\ttest-rmse:0.240575\n",
      "[700]\ttrain-rmse:0.211107\ttest-rmse:0.24049\n",
      "[710]\ttrain-rmse:0.210668\ttest-rmse:0.240452\n",
      "[720]\ttrain-rmse:0.210193\ttest-rmse:0.240407\n",
      "[730]\ttrain-rmse:0.209767\ttest-rmse:0.240405\n",
      "[740]\ttrain-rmse:0.209315\ttest-rmse:0.240385\n",
      "[750]\ttrain-rmse:0.208951\ttest-rmse:0.240325\n",
      "[760]\ttrain-rmse:0.208527\ttest-rmse:0.240303\n",
      "[770]\ttrain-rmse:0.208104\ttest-rmse:0.240268\n",
      "[780]\ttrain-rmse:0.207715\ttest-rmse:0.240233\n",
      "[790]\ttrain-rmse:0.207265\ttest-rmse:0.240171\n",
      "[800]\ttrain-rmse:0.206933\ttest-rmse:0.24011\n",
      "[810]\ttrain-rmse:0.206527\ttest-rmse:0.240075\n",
      "[820]\ttrain-rmse:0.20613\ttest-rmse:0.240048\n",
      "[830]\ttrain-rmse:0.205754\ttest-rmse:0.240005\n",
      "[840]\ttrain-rmse:0.205405\ttest-rmse:0.23998\n",
      "[850]\ttrain-rmse:0.205104\ttest-rmse:0.239971\n",
      "[860]\ttrain-rmse:0.204683\ttest-rmse:0.239929\n",
      "[870]\ttrain-rmse:0.20423\ttest-rmse:0.23994\n",
      "[880]\ttrain-rmse:0.20388\ttest-rmse:0.239889\n",
      "[890]\ttrain-rmse:0.203475\ttest-rmse:0.239877\n",
      "[900]\ttrain-rmse:0.203126\ttest-rmse:0.239857\n",
      "[910]\ttrain-rmse:0.202716\ttest-rmse:0.239827\n",
      "[920]\ttrain-rmse:0.202274\ttest-rmse:0.239804\n",
      "[930]\ttrain-rmse:0.201868\ttest-rmse:0.23979\n",
      "[940]\ttrain-rmse:0.201511\ttest-rmse:0.239771\n",
      "[950]\ttrain-rmse:0.201129\ttest-rmse:0.239742\n",
      "[960]\ttrain-rmse:0.200758\ttest-rmse:0.239715\n",
      "[970]\ttrain-rmse:0.200435\ttest-rmse:0.239696\n",
      "[980]\ttrain-rmse:0.20009\ttest-rmse:0.239677\n",
      "[990]\ttrain-rmse:0.1997\ttest-rmse:0.239658\n",
      "[1000]\ttrain-rmse:0.19933\ttest-rmse:0.239625\n",
      "[1010]\ttrain-rmse:0.198932\ttest-rmse:0.239603\n",
      "[1020]\ttrain-rmse:0.198608\ttest-rmse:0.23958\n",
      "[1030]\ttrain-rmse:0.198225\ttest-rmse:0.239572\n",
      "[1040]\ttrain-rmse:0.197886\ttest-rmse:0.239515\n",
      "[1050]\ttrain-rmse:0.197478\ttest-rmse:0.2395\n",
      "[1060]\ttrain-rmse:0.197105\ttest-rmse:0.239436\n",
      "[1070]\ttrain-rmse:0.196677\ttest-rmse:0.239439\n",
      "[1080]\ttrain-rmse:0.196293\ttest-rmse:0.239399\n",
      "[1090]\ttrain-rmse:0.195829\ttest-rmse:0.239337\n",
      "[1100]\ttrain-rmse:0.195502\ttest-rmse:0.23934\n",
      "[1110]\ttrain-rmse:0.195153\ttest-rmse:0.23931\n",
      "[1120]\ttrain-rmse:0.194788\ttest-rmse:0.239265\n",
      "[1130]\ttrain-rmse:0.1944\ttest-rmse:0.239263\n",
      "[1140]\ttrain-rmse:0.194068\ttest-rmse:0.239235\n",
      "[1150]\ttrain-rmse:0.193711\ttest-rmse:0.239256\n",
      "[1160]\ttrain-rmse:0.193288\ttest-rmse:0.239277\n",
      "[1170]\ttrain-rmse:0.192892\ttest-rmse:0.239259\n",
      "[1180]\ttrain-rmse:0.192608\ttest-rmse:0.23928\n",
      "[1190]\ttrain-rmse:0.192321\ttest-rmse:0.239252\n",
      "[1200]\ttrain-rmse:0.192007\ttest-rmse:0.23925\n",
      "[1210]\ttrain-rmse:0.191608\ttest-rmse:0.239256\n",
      "[1220]\ttrain-rmse:0.19117\ttest-rmse:0.23924\n",
      "[1230]\ttrain-rmse:0.190837\ttest-rmse:0.239239\n",
      "[1240]\ttrain-rmse:0.190398\ttest-rmse:0.239224\n",
      "[1250]\ttrain-rmse:0.190025\ttest-rmse:0.239219\n",
      "[1260]\ttrain-rmse:0.189737\ttest-rmse:0.239231\n",
      "[1270]\ttrain-rmse:0.189364\ttest-rmse:0.239235\n",
      "[1280]\ttrain-rmse:0.189032\ttest-rmse:0.239241\n",
      "[1290]\ttrain-rmse:0.188662\ttest-rmse:0.239201\n",
      "[1300]\ttrain-rmse:0.188317\ttest-rmse:0.239183\n",
      "[1310]\ttrain-rmse:0.187987\ttest-rmse:0.23923\n",
      "[1320]\ttrain-rmse:0.187663\ttest-rmse:0.239253\n",
      "[1330]\ttrain-rmse:0.187282\ttest-rmse:0.239233\n",
      "[1340]\ttrain-rmse:0.186947\ttest-rmse:0.239242\n",
      "Stopping. Best iteration:\n",
      "[1297]\ttrain-rmse:0.18846\ttest-rmse:0.23917\n",
      "\n",
      "[0.237486, 0.237626, 0.240721, 0.23917]\n",
      "[0]\ttrain-rmse:0.334199\ttest-rmse:0.334187\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313606\ttest-rmse:0.314316\n",
      "[20]\ttrain-rmse:0.297341\ttest-rmse:0.298725\n",
      "[30]\ttrain-rmse:0.284749\ttest-rmse:0.286696\n",
      "[40]\ttrain-rmse:0.275155\ttest-rmse:0.277816\n",
      "[50]\ttrain-rmse:0.267837\ttest-rmse:0.271085\n",
      "[60]\ttrain-rmse:0.261946\ttest-rmse:0.265793\n",
      "[70]\ttrain-rmse:0.25745\ttest-rmse:0.261853\n",
      "[80]\ttrain-rmse:0.253868\ttest-rmse:0.258793\n",
      "[90]\ttrain-rmse:0.251041\ttest-rmse:0.256447\n",
      "[100]\ttrain-rmse:0.248688\ttest-rmse:0.254571\n",
      "[110]\ttrain-rmse:0.24672\ttest-rmse:0.253033\n",
      "[120]\ttrain-rmse:0.244978\ttest-rmse:0.251724\n",
      "[130]\ttrain-rmse:0.24341\ttest-rmse:0.250592\n",
      "[140]\ttrain-rmse:0.241999\ttest-rmse:0.249584\n",
      "[150]\ttrain-rmse:0.240746\ttest-rmse:0.248734\n",
      "[160]\ttrain-rmse:0.239672\ttest-rmse:0.248023\n",
      "[170]\ttrain-rmse:0.238739\ttest-rmse:0.247427\n",
      "[180]\ttrain-rmse:0.237782\ttest-rmse:0.246855\n",
      "[190]\ttrain-rmse:0.236904\ttest-rmse:0.2463\n",
      "[200]\ttrain-rmse:0.236024\ttest-rmse:0.245773\n",
      "[210]\ttrain-rmse:0.23533\ttest-rmse:0.24537\n",
      "[220]\ttrain-rmse:0.234538\ttest-rmse:0.24494\n",
      "[230]\ttrain-rmse:0.233816\ttest-rmse:0.244617\n",
      "[240]\ttrain-rmse:0.23316\ttest-rmse:0.244293\n",
      "[250]\ttrain-rmse:0.232604\ttest-rmse:0.244082\n",
      "[260]\ttrain-rmse:0.23203\ttest-rmse:0.243818\n",
      "[270]\ttrain-rmse:0.231417\ttest-rmse:0.243581\n",
      "[280]\ttrain-rmse:0.230808\ttest-rmse:0.243296\n",
      "[290]\ttrain-rmse:0.230311\ttest-rmse:0.243118\n",
      "[300]\ttrain-rmse:0.229784\ttest-rmse:0.242925\n",
      "[310]\ttrain-rmse:0.229183\ttest-rmse:0.242683\n",
      "[320]\ttrain-rmse:0.228645\ttest-rmse:0.242526\n",
      "[330]\ttrain-rmse:0.228081\ttest-rmse:0.242323\n",
      "[340]\ttrain-rmse:0.227603\ttest-rmse:0.242164\n",
      "[350]\ttrain-rmse:0.227101\ttest-rmse:0.242019\n",
      "[360]\ttrain-rmse:0.22661\ttest-rmse:0.24188\n",
      "[370]\ttrain-rmse:0.226155\ttest-rmse:0.241765\n",
      "[380]\ttrain-rmse:0.225674\ttest-rmse:0.241643\n",
      "[390]\ttrain-rmse:0.225169\ttest-rmse:0.241524\n",
      "[400]\ttrain-rmse:0.224741\ttest-rmse:0.24141\n",
      "[410]\ttrain-rmse:0.224221\ttest-rmse:0.241279\n",
      "[420]\ttrain-rmse:0.223788\ttest-rmse:0.241197\n",
      "[430]\ttrain-rmse:0.223331\ttest-rmse:0.24109\n",
      "[440]\ttrain-rmse:0.222889\ttest-rmse:0.241004\n",
      "[450]\ttrain-rmse:0.222371\ttest-rmse:0.240933\n",
      "[460]\ttrain-rmse:0.221943\ttest-rmse:0.240838\n",
      "[470]\ttrain-rmse:0.22148\ttest-rmse:0.240746\n",
      "[480]\ttrain-rmse:0.220922\ttest-rmse:0.240652\n",
      "[490]\ttrain-rmse:0.220568\ttest-rmse:0.24057\n",
      "[500]\ttrain-rmse:0.220146\ttest-rmse:0.240505\n",
      "[510]\ttrain-rmse:0.219699\ttest-rmse:0.240499\n",
      "[520]\ttrain-rmse:0.21918\ttest-rmse:0.240458\n",
      "[530]\ttrain-rmse:0.218723\ttest-rmse:0.240394\n",
      "[540]\ttrain-rmse:0.218302\ttest-rmse:0.240306\n",
      "[550]\ttrain-rmse:0.217813\ttest-rmse:0.240242\n",
      "[560]\ttrain-rmse:0.217443\ttest-rmse:0.240152\n",
      "[570]\ttrain-rmse:0.217047\ttest-rmse:0.240089\n",
      "[580]\ttrain-rmse:0.216582\ttest-rmse:0.240107\n",
      "[590]\ttrain-rmse:0.216208\ttest-rmse:0.240091\n",
      "[600]\ttrain-rmse:0.215883\ttest-rmse:0.240067\n",
      "[610]\ttrain-rmse:0.215318\ttest-rmse:0.239946\n",
      "[620]\ttrain-rmse:0.214836\ttest-rmse:0.239905\n",
      "[630]\ttrain-rmse:0.214393\ttest-rmse:0.239833\n",
      "[640]\ttrain-rmse:0.21395\ttest-rmse:0.239784\n",
      "[650]\ttrain-rmse:0.21359\ttest-rmse:0.239744\n",
      "[660]\ttrain-rmse:0.213177\ttest-rmse:0.239715\n",
      "[670]\ttrain-rmse:0.212833\ttest-rmse:0.239651\n",
      "[680]\ttrain-rmse:0.212358\ttest-rmse:0.239581\n",
      "[690]\ttrain-rmse:0.211876\ttest-rmse:0.239572\n",
      "[700]\ttrain-rmse:0.211499\ttest-rmse:0.239494\n",
      "[710]\ttrain-rmse:0.211019\ttest-rmse:0.239458\n",
      "[720]\ttrain-rmse:0.210622\ttest-rmse:0.239422\n",
      "[730]\ttrain-rmse:0.210189\ttest-rmse:0.239405\n",
      "[740]\ttrain-rmse:0.20984\ttest-rmse:0.239365\n",
      "[750]\ttrain-rmse:0.20949\ttest-rmse:0.239329\n",
      "[760]\ttrain-rmse:0.209059\ttest-rmse:0.239311\n",
      "[770]\ttrain-rmse:0.208536\ttest-rmse:0.23926\n",
      "[780]\ttrain-rmse:0.208153\ttest-rmse:0.239231\n",
      "[790]\ttrain-rmse:0.207725\ttest-rmse:0.239199\n",
      "[800]\ttrain-rmse:0.207261\ttest-rmse:0.239157\n",
      "[810]\ttrain-rmse:0.206921\ttest-rmse:0.239153\n",
      "[820]\ttrain-rmse:0.206507\ttest-rmse:0.239147\n",
      "[830]\ttrain-rmse:0.206104\ttest-rmse:0.239154\n",
      "[840]\ttrain-rmse:0.205783\ttest-rmse:0.239113\n",
      "[850]\ttrain-rmse:0.205374\ttest-rmse:0.239087\n",
      "[860]\ttrain-rmse:0.205032\ttest-rmse:0.239038\n",
      "[870]\ttrain-rmse:0.20463\ttest-rmse:0.238982\n",
      "[880]\ttrain-rmse:0.20425\ttest-rmse:0.238977\n",
      "[890]\ttrain-rmse:0.204013\ttest-rmse:0.238956\n",
      "[900]\ttrain-rmse:0.203543\ttest-rmse:0.238914\n",
      "[910]\ttrain-rmse:0.203162\ttest-rmse:0.238912\n",
      "[920]\ttrain-rmse:0.20279\ttest-rmse:0.238857\n",
      "[930]\ttrain-rmse:0.20238\ttest-rmse:0.238815\n",
      "[940]\ttrain-rmse:0.201958\ttest-rmse:0.23879\n",
      "[950]\ttrain-rmse:0.20162\ttest-rmse:0.238777\n",
      "[960]\ttrain-rmse:0.201237\ttest-rmse:0.23877\n",
      "[970]\ttrain-rmse:0.20083\ttest-rmse:0.238715\n",
      "[980]\ttrain-rmse:0.200407\ttest-rmse:0.238701\n",
      "[990]\ttrain-rmse:0.200056\ttest-rmse:0.238695\n",
      "[1000]\ttrain-rmse:0.199647\ttest-rmse:0.238688\n",
      "[1010]\ttrain-rmse:0.199312\ttest-rmse:0.238664\n",
      "[1020]\ttrain-rmse:0.198949\ttest-rmse:0.238643\n",
      "[1030]\ttrain-rmse:0.198562\ttest-rmse:0.238653\n",
      "[1040]\ttrain-rmse:0.198151\ttest-rmse:0.23864\n",
      "[1050]\ttrain-rmse:0.197744\ttest-rmse:0.238594\n",
      "[1060]\ttrain-rmse:0.197473\ttest-rmse:0.238589\n",
      "[1070]\ttrain-rmse:0.197102\ttest-rmse:0.238545\n",
      "[1080]\ttrain-rmse:0.196735\ttest-rmse:0.238548\n",
      "[1090]\ttrain-rmse:0.196317\ttest-rmse:0.238526\n",
      "[1100]\ttrain-rmse:0.195967\ttest-rmse:0.238511\n",
      "[1110]\ttrain-rmse:0.195552\ttest-rmse:0.238477\n",
      "[1120]\ttrain-rmse:0.195151\ttest-rmse:0.238464\n",
      "[1130]\ttrain-rmse:0.194797\ttest-rmse:0.238431\n",
      "[1140]\ttrain-rmse:0.194417\ttest-rmse:0.238408\n",
      "[1150]\ttrain-rmse:0.194012\ttest-rmse:0.23843\n",
      "[1160]\ttrain-rmse:0.19364\ttest-rmse:0.238402\n",
      "[1170]\ttrain-rmse:0.193284\ttest-rmse:0.238379\n",
      "[1180]\ttrain-rmse:0.192892\ttest-rmse:0.238384\n",
      "[1190]\ttrain-rmse:0.192505\ttest-rmse:0.238393\n",
      "[1200]\ttrain-rmse:0.192143\ttest-rmse:0.238406\n",
      "[1210]\ttrain-rmse:0.191809\ttest-rmse:0.238378\n",
      "[1220]\ttrain-rmse:0.191433\ttest-rmse:0.238368\n",
      "[1230]\ttrain-rmse:0.19106\ttest-rmse:0.238397\n",
      "[1240]\ttrain-rmse:0.190678\ttest-rmse:0.238407\n",
      "[1250]\ttrain-rmse:0.19031\ttest-rmse:0.238365\n",
      "[1260]\ttrain-rmse:0.189949\ttest-rmse:0.238371\n",
      "[1270]\ttrain-rmse:0.189674\ttest-rmse:0.238358\n",
      "[1280]\ttrain-rmse:0.189368\ttest-rmse:0.238356\n",
      "[1290]\ttrain-rmse:0.189\ttest-rmse:0.238338\n",
      "[1300]\ttrain-rmse:0.18863\ttest-rmse:0.238333\n",
      "[1310]\ttrain-rmse:0.188249\ttest-rmse:0.238355\n",
      "[1320]\ttrain-rmse:0.187893\ttest-rmse:0.238351\n",
      "[1330]\ttrain-rmse:0.187557\ttest-rmse:0.238325\n",
      "[1340]\ttrain-rmse:0.187207\ttest-rmse:0.238317\n",
      "[1350]\ttrain-rmse:0.18692\ttest-rmse:0.23832\n",
      "[1360]\ttrain-rmse:0.18655\ttest-rmse:0.238324\n",
      "[1370]\ttrain-rmse:0.186231\ttest-rmse:0.238346\n",
      "[1380]\ttrain-rmse:0.185921\ttest-rmse:0.238348\n",
      "Stopping. Best iteration:\n",
      "[1339]\ttrain-rmse:0.187228\ttest-rmse:0.238312\n",
      "\n",
      "[0.237486, 0.237626, 0.240721, 0.23917, 0.238312]\n",
      "0.238666\n"
     ]
    }
   ],
   "source": [
    "rv1 = run_cv1(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs1 = run_to_stackdf(rv1)\n",
    "pickle.dump(dfs1, open('modeloutput-xgb-reg-r3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 410,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
