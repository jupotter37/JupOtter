{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging `SelectivePCA`'s `weight=True` capability\n",
    "\n",
    "Some algorithms intrinsically treat each feature with the same amount of importance. For many such algorithms, i.e., clustering algorithms, this is a fallacy and can cause inappropriate results. The following notebook demonstrates `skutil`'s weighting capability via `SelectivePCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target # this is unsupervised; we aren't going to split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic *k*-Means, no weighting:\n",
    "\n",
    "Here, we'll run a basic *k*-Means (k=3) preceded by a default `SelectivePCA` (no weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.89333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from skutil.decomposition import SelectivePCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# define our default pipe\n",
    "pca = SelectivePCA(n_components=0.99)\n",
    "pipe = Pipeline([\n",
    "        ('pca',   pca),\n",
    "        ('model', KMeans(3))\n",
    "    ])\n",
    "\n",
    "# fit the pipe\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# predict and score\n",
    "print('Train accuracy: %.5f' % accuracy_score(y, pipe.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice accuracy, but not a stellar one... Surely we can improve this, right? Part of the problem is that clustering (distance metrics) treats all the features equally. Since PCA intrinsically orders features based on importance, we can weight them according to the variability they each explain. Thus, the most important features will be up weighted, and the least important features will be down weighted.\n",
    "\n",
    "Here is the `explained_variance_ratio_` vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92461621,  0.05301557,  0.01718514])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.pca_.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what our weighting vector will ultimately look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87160064,  1.        ,  0.96416957])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pca.pca_.explained_variance_ratio_\n",
    "weights -= np.median(weights)\n",
    "weights += 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### *k*-Means with weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy (with weighting): 0.90667\n"
     ]
    }
   ],
   "source": [
    "# define our weighted pipe\n",
    "pca = SelectivePCA(n_components=0.99, weight=True)\n",
    "pipe = Pipeline([\n",
    "        ('pca',   pca),\n",
    "        ('model', KMeans(3))\n",
    "    ])\n",
    "\n",
    "# fit the pipe\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# predict and score\n",
    "print('Train accuracy (with weighting): %.5f' % accuracy_score(y, pipe.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not limited just to `KMeans` or even to clustering tasks. Any algorithm that does not intrinsically perform any kind of regularization or other feature selection may be subject to this trap, and `SelectivePCA`'s weighting can help!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
