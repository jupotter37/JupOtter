{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plb\n",
    "import matplotlib as mpl\n",
    "import pyart\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numpy.ma as ma\n",
    "\n",
    "from pylab import *\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def velocity_quality(radar, field='velocity', gatefilter=None, w_speckle=np.ones((3,3)), N_speckle=4, \n",
    "                     w_outliers=np.ones((3,5)), N_outliers=9, upper_fac=1.5, \n",
    "                     speckle_filter=True, outlier_filter=True):\n",
    "    \n",
    "    ## General function to evaluate quality of the velocity field ##\n",
    "    \n",
    "    Ny, Ny_H, Ny_L, f, N, prf_odd = get_dualPRF_pars(radar)\n",
    "        \n",
    "    v_field = radar.fields[field]\n",
    "    v_data_ma = v_field['data'].copy()\n",
    "    \n",
    "    if gatefilter is not None:\n",
    "        gatefilter_mask = gatefilter.gate_excluded \n",
    "        v_data_ma.mask = (v_field['data'].mask) | (gatefilter_mask)\n",
    "    \n",
    "    aff = ['T', 'True', True, 'Yes', 1]\n",
    "    if speckle_filter in aff:\n",
    "        speckle_filter=True\n",
    "    if outlier_filter in aff:\n",
    "        outlier_filter=True\n",
    "     \n",
    "    list_out = []\n",
    "    dict_out = {'na':v_data_ma.mask, \n",
    "                'speckle':np.zeros(shape(v_data_ma)).astype(bool),\n",
    "                'outlier':np.zeros(shape(v_data_ma)).astype(bool),\n",
    "                'edge':np.zeros(shape(v_data_ma)).astype(bool)}\n",
    "    point_f = nan\n",
    "    out_f = nan\n",
    "    g_data = v_data_ma.copy()\n",
    "    \n",
    "    for nsweep, sweep_slice in enumerate(radar.iter_slice()):\n",
    "        \n",
    "        fix_ang = radar.fixed_angle['data'][nsweep]\n",
    "    \n",
    "        v_data_ma_sw = v_data_ma[sweep_slice]\n",
    "        v_data_sw = v_data_ma_sw.data\n",
    "        v_mask_sw = v_data_ma_sw.mask\n",
    "        \n",
    "        valid_num = np.sum(~v_mask_sw)\n",
    "        \n",
    "        # Identify and count speckle-noise gates\n",
    "        if speckle_filter:\n",
    "            point_f, dict_out['speckle'][sweep_slice] = local_valid(v_mask_sw, weights=w_speckle, \n",
    "                                                                    Nmin=N_speckle, mode='mirror')\n",
    "        \n",
    "        # Identify and count dualPRF outlier gates\n",
    "        if (outlier_filter) & (prf_odd is not None):\n",
    "            out_f, dict_out['outlier'][sweep_slice] = dualPRF_outliers(v_data_ma_sw, Ny, Ny_H, Ny_L, prf_odd, \n",
    "                                                                        weights=w_outliers, Nmin=N_outliers, \n",
    "                                                                        upper_lim_fac=upper_fac)\n",
    "        \n",
    "        # Mask NA values, speckle noise and dual-PRF outliers\n",
    "        vcorr_mask_sw = ((v_mask_sw) | (dict_out['speckle'][sweep_slice])) | (dict_out['outlier'][sweep_slice])\n",
    "       \n",
    "        # Apply edge-finding function to velocity field (corrected by new mask)\n",
    "        vcorr_data_ma_sw = ma.array(data=v_data_sw, mask=vcorr_mask_sw)\n",
    "        g_data_sw, edge_f, dict_out['edge'][sweep_slice] = aliased_edges(vcorr_data_ma_sw, Ny)\n",
    "        g_data[sweep_slice] = ma.array(g_data_sw, mask=vcorr_mask_sw)\n",
    "        \n",
    "        # Retrieve date and time at the beginning of the sweep\n",
    "        datetime_list = datetime_sw(radar, sweep_slice)\n",
    "        \n",
    "        list_out.append(datetime_list+[fix_ang, valid_num, point_f, out_f, edge_f])\n",
    "    \n",
    "    # Returns a list with the fractions and a dictionary with the masks:\n",
    "    return list_out, dict_out, g_data\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def local_valid(mask, weights, Nmin=None, mode='mirror', **kwargs):\n",
    "    \n",
    "    ## Find speckle-gates: gates with a number of valid neighbours below a given threshold ##\n",
    "    \n",
    "    if Nmin is None:\n",
    "        Nmin = 1\n",
    "        \n",
    "    # Count number of non-masked local values\n",
    "    k = weights\n",
    "    valid = ndimage.convolve((~mask).astype(int), k, mode=mode, **kwargs)\n",
    "    \n",
    "    mask_out = np.zeros(mask.shape)\n",
    "    mask_out[valid<Nmin]=1\n",
    "    \n",
    "    mask_out = (mask_out.astype(bool)) & (~mask)\n",
    "    \n",
    "    count = float(np.sum(mask_out))/np.sum(~mask)\n",
    "    \n",
    "    return count, mask_out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dualPRF_pars(radar):\n",
    "    \n",
    "    ## Retrieve relevant parameters of dual-PRF velocity task ##  \n",
    "    \n",
    "    pars = radar.instrument_parameters\n",
    "    \n",
    "    Ny = pars['nyquist_velocity']['data'][0]\n",
    "    prt_mode = pars['prt_mode']['data'][0]\n",
    "    Ny_H = Ny\n",
    "    Ny_L = Ny\n",
    "    prf_odd = None\n",
    "    f = 1\n",
    "    N = None\n",
    "    \n",
    "    if prt_mode=='dual':\n",
    "    \n",
    "        f = pars['prt_ratio']['data'][0]\n",
    "        N = round(1/(f-1))\n",
    "        Ny_H = Ny/N\n",
    "        Ny_L = Ny/(N+1)   \n",
    "        prf_odd = pars['prf_flag']['data'][0]\n",
    "    \n",
    "    return Ny, Ny_H, Ny_L, f, N, prf_odd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dualPRF_outliers(data_ma, Ny, Ny_H, Ny_L, prf_odd=0, weights=np.ones((3,5)), Nmin=9, upper_lim_fac=1.5):\n",
    "    \n",
    "    ## Find outliers resulting from dual-PRF dealiasing errors ##\n",
    "    \n",
    "    # Nyquist velocities corresponding to odd and even rays\n",
    "    Ny_odd = Ny_H\n",
    "    Ny_even = Ny_L\n",
    "    \n",
    "    if prf_odd is None:\n",
    "        return\n",
    "    if prf_odd==1:\n",
    "        Ny_odd = Ny_L\n",
    "        Ny_even = Ny_H\n",
    "    \n",
    "    # Footprint (region around the pixel where median is computed)\n",
    "    k = weights\n",
    "    \n",
    "    data = data_ma.data\n",
    "    mask = data_ma.mask\n",
    "    \n",
    "    # Convert masked data to nan and apply median filter \n",
    "    data_nan = np.where(np.logical_not(mask), data, np.nan)\n",
    "    med_data = sp.ndimage.generic_filter(data_nan, np.nanmedian, footprint=k, mode='mirror')\n",
    "    \n",
    "    # Absolute deviation of the pixel velocity from the local median\n",
    "    dev_data = np.abs(data_nan - med_data)\n",
    "    dev_data[where(np.isnan(dev_data))]=0\n",
    "    \n",
    "    # Separate into odd and even rays\n",
    "    dev_odd = dev_data[1::2, :]\n",
    "    dev_even = dev_data[0::2, :]\n",
    "    \n",
    "    # Outlier matrix\n",
    "    mask_out = np.zeros(dev_data.shape)\n",
    "    mask_out_odd = mask_out[1::2, :]\n",
    "    mask_out_even = mask_out[0::2, :]\n",
    "    mask_out_odd[ma.where((dev_odd>=Ny_odd)&(dev_odd<=upper_lim_fac*Ny))] = 1\n",
    "    mask_out_even[ma.where((dev_even>=Ny_even)&(dev_even<=upper_lim_fac*Ny))] = 1\n",
    "     \n",
    "    # Find local medians calculated with the required minimum number of valid values\n",
    "    count_nmin, mask_nmin = local_valid(mask, k, Nmin=Nmin, mode='mirror')\n",
    "    \n",
    "    # Outlier mask (gives number of outliers)\n",
    "    mask_out = (mask_out.astype(bool)) & (~mask_nmin)\n",
    "    count_out = float(np.sum(mask_out))/np.sum(~mask)\n",
    "    \n",
    "    # Return fraction of outliers and mask for outliers\n",
    "    return count_out, mask_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maconvolve(ma_array, weights, Nmin=None, mode='mirror', **kwargs):\n",
    "\n",
    "    ## Convolve masked array with generic kernel ##  \n",
    "\n",
    "    k = weights\n",
    "    data = ma_array.data\n",
    "    mask = ma_array.mask\n",
    "    \n",
    "    # Minimum number of non-masked local values required for the convolution\n",
    "    if Nmin is None:\n",
    "        Nmin=1\n",
    "    \n",
    "    # Data convolution (replace masked values by 0)\n",
    "    data_conv = ndimage.convolve(ma.filled(data,0), k, mode=mode, **kwargs)\n",
    "    \n",
    "    w_valid = np.ones(k.shape)\n",
    "    # Count number of non-masked local values\n",
    "    valid, mask_conv = local_valid(mask, w_valid, Nmin=Nmin, mode=mode, **kwargs)\n",
    "    \n",
    "    # New mask and replace masked values by required fill value\n",
    "    mask_out = mask_conv | mask\n",
    "    data_out = ma.masked_array(data_conv, mask_out)\n",
    "        \n",
    "    # Return the convolved masked array\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aliased_edges(data_ma, Ny, lower_lim_fac=1.5):\n",
    "    \n",
    "    ## Find edges of aliased regions based on the horizontal velocity gradients ##\n",
    "    \n",
    "    # Gradient kernels in x,y (r,az) dimensions\n",
    "    kx = np.array([[-1, 0, 1]])\n",
    "    ky = np.transpose(kx)\n",
    "    \n",
    "    mask = data_ma.mask\n",
    "    \n",
    "    # Horizonal gradient components\n",
    "    gx_data = maconvolve(data_ma, weights=kx, Nmin=3, mode='wrap')\n",
    "    gy_data = maconvolve(data_ma, weights=ky, Nmin=3, mode='reflect')\n",
    "        \n",
    "    # Magnitude and direction of horizontal gradient\n",
    "    g_data = np.sqrt(ma.filled(gx_data,0)**2 + ma.filled(gy_data,0)**2)\n",
    "    \n",
    "    # Edge mask (gives number of edges)\n",
    "    g_mask = np.zeros(g_data.shape)\n",
    "    g_mask[(g_data>=lower_lim_fac*Ny)] = 1\n",
    "    \n",
    "    count_g = float(np.sum(g_mask))/np.sum(~mask)\n",
    "    \n",
    "    # Return fraction of edges and mask for edges\n",
    "    return g_data, count_g, g_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def connected_edges(mask, struc=np.ones((3,3)), nmin=10):\n",
    "    \n",
    "    # Find and label connected edges    \n",
    "    lab_array, n_reg = ndimage.label(mask.astype(int), structure=struc)\n",
    "    \n",
    "    # Differentiate between small (noise) and large (aliasing) edge regions\n",
    "    n_edges = np.empty(n_reg)\n",
    "    \n",
    "    for i in range(0, n_reg):\n",
    "        n_edges[i] = np.sum(lab_array==i+1)\n",
    "        \n",
    "    reg_s = np.sum(n_edges<=nmin)\n",
    "    reg_l = np.sum(n_edges>nmin)\n",
    "    \n",
    "    f_reg_s = 0\n",
    "    f_reg_l = 0\n",
    "    \n",
    "    # Count fractions in each case\n",
    "    if np.sum(mask)!=0:\n",
    "        f_reg_s = np.sum(n_edges[n_edges<=nmin])/np.sum(mask)\n",
    "        f_reg_l = np.sum(n_edges[n_edges>nmin])/np.sum(mask)\n",
    "    \n",
    "    # Return an array with the labelled edge-gates, a list with the number of \n",
    "    # edge-gates in each region and a list with the number of small and large \n",
    "    # regions and with the fraction of large and small edge-gates\n",
    "    return lab_array, n_edges, [reg_s, reg_l, f_reg_s, f_reg_l]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_outfile(table, f, headers=None, mode='w+'):\n",
    "    \n",
    "    ## Write list to an ascii file in table form ##\n",
    "    \n",
    "    f1=open(f, mode)\n",
    "    \n",
    "    if (headers is not None) & (mode=='w+'):\n",
    "        f1.writelines([\"%s \" % hdr for hdr in headers])\n",
    "        f1.writelines('\\n')\n",
    "        \n",
    "    for sw in table:\n",
    "        for item in sw:\n",
    "            if (type(item)==float)|(type(item)==float64):\n",
    "                f1.writelines(\"%6.5f \" % item)\n",
    "            elif type(item)==int64:\n",
    "                f1.writelines(\"%d \" % item)\n",
    "            else:\n",
    "                f1.writelines(\"%s \" % str(item))\n",
    "                \n",
    "        f1.writelines('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetime_sw(radar, sw_slice):\n",
    "    \n",
    "    ## Retrieve date and time at the start of a sweep from a radar object ##\n",
    "    dt_vol = pyart.graph.RadarDisplay(radar).time_begin\n",
    "    \n",
    "    sec_sw = min(radar.time['data'][sw_slice])-1\n",
    "    dt_sw = dt_vol + datetime.timedelta(seconds=sec_sw)\n",
    "    \n",
    "    date_sw = dt_sw.date()\n",
    "    time_sw = dt_sw.time()\n",
    "    \n",
    "    # Return date and time list\n",
    "    return [date_sw, time_sw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate_vid(mask_dict):\n",
    "    \n",
    "    ## Assign an id to velocity field gates based on the mask dictionary ##\n",
    "    \n",
    "    out_array = np.zeros(mask_dict[mask_dict.keys()[0]].shape)\n",
    "    out_ids = ['valid']\n",
    "    lab=1\n",
    "    for k in mask_dict.keys():\n",
    "        m = mask_dict[k]\n",
    "        out_array[m] = lab\n",
    "        out_ids.append(k)\n",
    "        lab += 1\n",
    "    \n",
    "    # Return an array with the labelled gates and a list with the description of the ids\n",
    "    return out_array, out_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/patriciaaltube/Desktop/VelocityQ/data_process/CDV130618/'\n",
    "out_path_file = '/Users/patriciaaltube/Desktop/VelocityQ/results/'\n",
    "out_path_base = '/Users/patriciaaltube/Desktop/VelocityQ/plots/V_filtersON/'\n",
    "\n",
    "hdrs = ['Date', 'Time', 'Elev', 'Valid_Num', 'Point_Frac', 'Outlier_Frac', \n",
    "        'Edge_Frac', 'SmallReg_Num', 'LargeReg_Num', \n",
    "        'SmallEdge_Frac', 'LargeEdge_frac']\n",
    "\n",
    "lab_colors=['lightgrey','white','red', 'black', 'blue']\n",
    "id_cmap = matplotlib.colors.ListedColormap(lab_colors)\n",
    "#v_cmap = pyart.graph.cm.NWSVel\n",
    "v_cmap = plt.get_cmap('RdBu')\n",
    "\n",
    "for f in glob.glob(data_path + '*.RAW*'):\n",
    "    \n",
    "    fileout_name = f[-23:-14]\n",
    "    out_file = out_path_file + fileout_name + '_VQI.txt'\n",
    "    \n",
    "    radar = pyart.io.read(f)\n",
    "    frac_list, mask_dict  = velocity_quality(radar, field='velocity', speckle_filter=True, outlier_filter=True)\n",
    "    \n",
    "    if not os.path.isfile(out_file):\n",
    "        write_outfile(frac_list, hdrs, out_file, mode='w+')\n",
    "    else:\n",
    "        write_outfile(frac_list, hdrs, out_file, mode='a+')\n",
    "        \n",
    "    figout_name = f[-23:-10]\n",
    "\n",
    "    id_array, id_list = bin_vid(mask_dict)\n",
    "    \n",
    "    id_field = radar.fields['velocity'].copy()\n",
    "    id_field['data'] = id_array\n",
    "    id_field['long_name'] = 'Velocity flags'\n",
    "    id_field['standard_name'] = 'velocity_flags'\n",
    "    id_field['units'] = ''\n",
    "    radar.add_field('gate_vid', id_field)\n",
    "    \n",
    "    plt.close('all')\n",
    "    \n",
    "    for sw in range(0, radar.nsweeps):\n",
    "        \n",
    "        elev=radar.fixed_angle['data'][sw]\n",
    "        \n",
    "        out_path = out_path_base + 'elev%1.0f'%elev + '/'\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "            \n",
    "        out_fig = out_path + figout_name + '_elev%1.0f'%elev + '.png'\n",
    "    \n",
    "        display = pyart.graph.RadarDisplay(radar)\n",
    "        fig = plt.figure(figsize=(8, 14))\n",
    "\n",
    "        ax = fig.add_subplot(211)\n",
    "        display.plot('velocity', sweep = sw, vmin = -40, vmax = 40, ax=ax, cmap=v_cmap)\n",
    "        plt.xlim((-100, 100))\n",
    "        plt.ylim((-100, 100))\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(212)\n",
    "        display.plot('gate_vid', sweep = sw, vmin = 0, vmax = 5, ax=ax, cmap=id_cmap)\n",
    "        tick_locs = np.linspace(0,len(id_list) -1 ,len(id_list))+0.5\n",
    "        display.cbs[-1].locator = matplotlib.ticker.FixedLocator(tick_locs)\n",
    "        display.cbs[-1].formatter   = matplotlib.ticker.FixedFormatter(id_list)\n",
    "        display.cbs[-1].update_ticks()\n",
    "        plt.xlim((-100, 100))\n",
    "        plt.ylim((-100, 100))\n",
    "\n",
    "        plt.savefig(out_fig)\n",
    "        \n",
    "        out_fig_hist = out_path_fig + figout_name + '_hist_elev%1.0f'%elev + '.pdf'\n",
    "        plot_data=radar.get_field(sw, 'gradient_module')\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        (n, bins, patches) = ax.hist(plot_data.compressed(), bins=round(3.5*20), color='grey', alpha=0.8)\n",
    "        ax.set_ylim([0,500])\n",
    "        ax.set_xlim([0, 3.5*40])\n",
    "        ax.set_xlabel('Gradient module (m/s)')\n",
    "        ax.set_ylabel('Pixel counts')\n",
    "\n",
    "        pp = PdfPages(out_fig_hist)\n",
    "        pp.savefig()\n",
    "        pp.close()\n",
    "        #plt.savefig(out_fig_hist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
