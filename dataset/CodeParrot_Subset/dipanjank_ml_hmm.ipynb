{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "HMMs are probabilistic sequence  classifiers. A sequence classifier is a model whose job is to assign some label or class to each unit in a sequence. Given a sequence of units (words, letters, morphemes, sentences, whatever) their job is to compute a probability distribution over possible labels and choose the best label sequence.\n",
    "\n",
    "<img src=\"http://www.cs.virginia.edu/%7Ehw5x/Course/CS6501-Text-Mining/_site/docs/codes/HMM.PNG\" width=\"400\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* The $t_i$s are instances of the hidden or latent variable. \n",
    "* The $w_i$s are instances of the tangible 'output' variable.\n",
    "\n",
    "For example, in a part of speech tagger, the $w_i$s are the words and the $t_i$s are the parts of speech we wish to assign to these words.\n",
    "\n",
    "**Markov Assumption:** Current state $t_i$ only depends on previous k tags for a k-th order HMM. Assuming an HMM of order 1,\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(t_i \\mid t_1, t_2, \\ldots t_{i-1}) = P(t_i  \\mid t_{i-1})\n",
    "\\end{equation}$$\n",
    "\n",
    "**Output Independence Assumption:** Current output state $w_i$ only depends on the current hidden state $t_i$. Assuming an HMM of order 1,\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(w_1, w_2,\\ldots w_i, t_1, t_2, \\ldots t_i) = P(w_i \\mid t_i)\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Components of a Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we'll describe the different components of an HMM using the Ice Cream task. \n",
    "\n",
    "    Imagine that you are a climatologist in the year 2799 studying the history of global warming. You cannot find any records of the weather for the summer of 2007, but you do find Jason Eisner’s diary, which lists how many ice creams Jason ate every day that summer. Our goal is to use these observations to estimate the temperature every day. \n",
    "\n",
    "We’ll simplify this weather task by assuming there are only two kinds of days: cold (C) and hot (H). Also, Jason cares about his health so he only eats 1-3 icecreams. So the Eisner task is as follows:\n",
    "\n",
    "Given a sequence of observations, each observation an integer between 1-3, corresponding to the number of ice creams eaten on a given day, figure out the correct ‘hidden’ sequence of weather states (H or C) which caused Jason to eat the ice cream. \n",
    "\n",
    "<img src=\"https://qph.ec.quoracdn.net/main-qimg-8fce62d562ac08766c168507f194956c\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The 3 HMM Problems\n",
    "\n",
    "Hidden Markov Models are characterized by three fundamental problems:\n",
    "\n",
    "**Problem 1 (Computing Likelihood):** Given an HMM $\\lambda = (A, B)$ and an observation sequence O, determine the likelihood $P(O \\mid \\lambda)$.\n",
    "\n",
    "**Problem 2 (Decoding):** Given an HMM $\\lambda = (A, B)$ and an observation sequence O, find the most likely sequence Q.\n",
    "\n",
    "**Problem 3 (Learning):** Given an HMM $\\lambda = (A, B)$ and an observation sequence O, learn the HMM parameters A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computing Likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's calculate the probability of the observation equence {3, 1} from the ice-cream HMM. This is the marginal probability\n",
    "\n",
    "$P(O) = \\sum_Q P(O, Q) = P(O \\mid Q) \\times P(Q) = \\sum_Q [\\prod_{i=1}^T P(o_i \\mid q_i) \\times \\prod_{i=1}^T P(q_i | q_{i-1})] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$P(3,1) = P(3, 1, H, H) + P(3, 1, H, C) + P(3, 1, C, H) + P(3, 1, C, C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$P(3, 1, H, H) = P(3 \\mid H) \\times P(1 \\mid H) \\times P(H \\mid H) \\times P(H) = 0.4 \\times 0.2 \\times 0.7 \\times 0.5 = 0.028$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$P(3, 1, H, C) = P(3 \\mid H) \\times P(1 \\mid C) \\times P(H \\mid C) \\times P(H) = 0.4 \\times 0.5 \\times 0.4 \\times 0.5 = 0.04$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$P(3, 1, C, H) = P(3 \\mid C) \\times P(1 \\mid H) \\times P(C \\mid H) \\times P(C) = 0.1 \\times 0.2 \\times 0.3 \\times 0.5 = 0.003$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$P(3, 1, C, C) = P(3 \\mid C) \\times P(1 \\mid C) \\times P(C \\mid C) \\times P(C) = 0.1 \\times 0.5 \\times 0.6 \\times 0.5 = 0.015$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, $P(3, 1) = 0.028 + 0.04 + 0.003 + 0.015 = 0.086$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "While computing $P(O \\mid \\lambda)$ is this way is simple, for an HMM with T steps and N values for the hidden state, this computation take $O(T \\times N^T)$ time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Dynamic Programming solution to this problem is called the Forward Algorithm.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://danieltakeshi.github.io/assets/forward_trellis.png\" /></td>\n",
    "        <td><img src=\"hmm_forward.PNG\" /></td>\n",
    "    </tr>\n",
    "</table>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What's the complexity of the forward algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decoding: The Viterbi Algorithm\n",
    "\n",
    "Since we already know how to calculate the likelihood of a given observation sequence $P(O \\mid Q)$, the corresponding most likely hidden sequence is $argmax_{Q} P(O \\mid Q)$\n",
    "\n",
    "However, since the Forward algorithm takes $O(T \\times N^2)$ time to calculate the likelihood of a given observation sequence and there are $T^N$ subsequences to evaluate, the direct evaluation method again has exponential time complexity. \n",
    "\n",
    "The solution is to look for the most likely sequence directly using Dynamic Programming.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"viterbi_trellis.PNG\" /></td>\n",
    "        <td><img src=\"viterbi_defn.PNG\" /></td>\n",
    "    </tr>\n",
    "</table>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Learning: The Baum-Welch Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "The example and diagrams are from <a href=\"http://www.mit.edu/~6.863/spring2011/jmnew/6.pdf\">Speech and Language Processing:  An introduction to natural language processing, computational linguistics, and speech recognition.  Daniel Jurafsky & James H. Martin.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## In Code\n",
    "\n",
    "In the section below, let's try to code a bare-bones HMM implementation for a toy problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOT     0.5\n",
       "COLD    0.5\n",
       "Name: pi, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "init_probs = pd.Series(index=['HOT', 'COLD'], data=[0.5, 0.5], name='pi')\n",
    "init_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLD</th>\n",
       "      <th>HOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOT</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLD</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COLD  HOT\n",
       "HOT    0.3  0.7\n",
       "COLD   0.6  0.4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_probs = pd.DataFrame(index=['HOT', 'COLD'], data={'HOT': [0.7, 0.4], 'COLD': [0.3, 0.6]})\n",
    "trans_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLD</th>\n",
       "      <th>HOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COLD  HOT\n",
       "1   0.5  0.2\n",
       "2   0.4  0.4\n",
       "3   0.1  0.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probs = pd.concat({\n",
    "    'HOT': pd.Series(index=[1, 2, 3], data=[0.2, 0.4, 0.4]),\n",
    "    'COLD': pd.Series(index=[1, 2, 3], data=[0.5, 0.4, 0.1]),\n",
    "}, axis=1)\n",
    "\n",
    "emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class SimpleHMM:\n",
    "    \n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.pi = init_probs\n",
    "        self.A = trans_probs\n",
    "        self.B = emission_probs\n",
    "        \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def forward_probs(self, obs):\n",
    "        \"\"\"Calculate forward probability of output sequence `obs`.\"\"\"\n",
    "        hidden_states = self.A.columns\n",
    "        fwd = pd.DataFrame(columns=hidden_states)\n",
    "        \n",
    "        for i, o in enumerate(obs):\n",
    "            for s in hidden_states:\n",
    "                if i == 0:\n",
    "                    prob_s = self.pi[s] * self.B[s][o]\n",
    "                else:\n",
    "                    prob_s = 0\n",
    "                    for s_prime in hidden_states:\n",
    "                        temp = self.A[s_prime][s] * self.B[s][o]       \n",
    "                        prob_s += fwd.loc[i-1, s_prime] * temp                        \n",
    "                    \n",
    "                fwd.loc[i, s] = prob_s\n",
    "                \n",
    "        return fwd\n",
    "    \n",
    "    def decode(self, obs):\n",
    "        \"\"\"Given a sequence of obaservations `obs`, return the most likely sequence of \n",
    "            hidden states using the Viterbi algorithm.\n",
    "        \"\"\"\n",
    "        hidden_states = self.A.columns\n",
    "        n_states = len(hidden_states)\n",
    "        viterbi_probs = pd.DataFrame(columns=hidden_states)\n",
    "        \n",
    "        state_transitions = []\n",
    "        \n",
    "        for i, o in enumerate(obs):\n",
    "            if i == 0:\n",
    "                for s in hidden_states:                \n",
    "                    viterbi_probs.loc[0, s] = self.pi[s] * self.B[s][o]\n",
    "            else:\n",
    "                for s in hidden_states:\n",
    "                    current_state_probs = []\n",
    "                    \n",
    "                    for s_prime in hidden_states:\n",
    "                        temp = viterbi_probs.loc[i-1, s_prime] * self.A[s_prime][s]\n",
    "                        current_state_probs.append([(s_prime, s), temp])\n",
    "                    \n",
    "                    current_state_probs = pd.DataFrame(current_state_probs, columns=['transition', 'probs'])\n",
    "                    current_state_probs = current_state_probs.set_index('transition')\n",
    "                    \n",
    "                    max_prob = current_state_probs['probs'].max()\n",
    "                    max_prob_transition = current_state_probs['probs'].argmax()                    \n",
    "                    state_transitions.append([i] + list(max_prob_transition))\n",
    "                    viterbi_probs.loc[i, s] = max_prob * self.B[s][o]\n",
    "        \n",
    "        state_transitions = pd.DataFrame(state_transitions, columns=['seq', 'start_state', 'end_state'])\n",
    "        state_transitions = state_transitions.set_index('seq')\n",
    "        \n",
    "        return self._find_most_likely_path(obs, viterbi_probs, state_transitions)\n",
    "        \n",
    "    def _find_most_likely_path(self, obs, viterbi_probs, state_transitions):\n",
    "        \"\"\"For observed sequence `obs`, use the Viterbi probability and the state transition matrices \n",
    "            to backtrace the most likely sequence path.\"\"\"\n",
    "        \n",
    "        final_state = viterbi_probs.tail(1).T.squeeze().argmax()\n",
    "        n_obs = len(obs)\n",
    "        \n",
    "        end_state = final_state\n",
    "        states = [end_state, ]\n",
    "        \n",
    "        for i in range(n_obs-1, 0, -1):\n",
    "            possible_trans = state_transitions.loc[i, :]\n",
    "            # print('For i = %s, end_state = %s' % (i, end_state))\n",
    "            start_state = possible_trans.loc[possible_trans.end_state == end_state, 'start_state'].values[0]\n",
    "            # print('For i = %s, start_state=%s' % (i, start_state))\n",
    "            states.append(start_state)\n",
    "            end_state = start_state\n",
    "            \n",
    "        most_likely_seq = list(reversed(states))\n",
    "        \n",
    "        return most_likely_seq\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLD</th>\n",
       "      <th>HOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COLD    HOT\n",
       "0   0.05    0.2\n",
       "1  0.055  0.031"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the HMM to calculate the output probability of [3, 1]\n",
    "hmm = SimpleHMM(init_probs, trans_probs, emission_probs)\n",
    "fwd_probs = hmm.forward_probs([3, 1])\n",
    "fwd_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086000000000000007"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_probs.tail(1).sum(axis=1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOT', 'COLD', 'COLD', 'HOT']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.decode([3, 1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
