{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeFhDRJgNfH_"
   },
   "source": [
    "# MNIST Hessian Spectral Density Calculator\n",
    "\n",
    "This notebook trains a simple MLP for MNIST, runs the Lanczos algorithm on its full-batch Hessian, and then plots the spectral density. This shows how to use the python TensorFlow LanczosExperiment class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "U0R8uZC4Em5n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import experiment_utils\n",
    "import lanczos_experiment\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(\"./../jax\"))\n",
    "import density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-PpCfoFGMS0"
   },
   "outputs": [],
   "source": [
    "COLAB_PATH = '/tmp/spectral-density'\n",
    "TRAIN_PATH = os.path.join(COLAB_PATH, 'train')\n",
    "LANCZOS_PATH = os.path.join(COLAB_PATH, 'lanczos')\n",
    "\n",
    "os.makedirs(TRAIN_PATH)\n",
    "os.makedirs(LANCZOS_PATH)\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.02\n",
    "\n",
    "NUM_TRAIN_STEPS = 10000\n",
    "NUM_SUMMARIZE_STEPS = 1000\n",
    "NUM_LANCZOS_STEPS = 90\n",
    "\n",
    "def data_fn(num_epochs=None, shuffle=False, initializable=False):\n",
    "  \"\"\"Returns tf.data dataset for MNIST.\"\"\"\n",
    "  dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "  dataset = dataset.repeat(num_epochs)\n",
    "  \n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(buffer_size=1024)\n",
    "  dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "  if initializable:    \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    init_op = iterator.initializer\n",
    "  else:\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    init_op = None\n",
    "    \n",
    "  output = iterator.get_next() \n",
    "  images = (tf.to_float(output['image']) - 128) / 128.0\n",
    "  one_hot_labels = tf.one_hot(output['label'], NUM_CLASSES)  \n",
    "  return images, one_hot_labels, init_op\n",
    "\n",
    "def model_fn(features, one_hot_labels):\n",
    "  \"\"\"Builds MLP for MNIST and computes loss.\n",
    "\n",
    "  Args:\n",
    "    features: a [batch_size, height, width, channels] float32 tensor.\n",
    "    one_hot_labels: A [batch_size, NUM_CLASSES] int tensor.\n",
    "    \n",
    "  Returns:\n",
    "    A scalar loss tensor, and a [batch_size, NUM_CLASSES] prediction tensor.\n",
    "  \"\"\"\n",
    "  net = tf.reshape(features, [BATCH_SIZE, IMAGE_SIZE * IMAGE_SIZE])\n",
    "  net = tf.layers.dense(net, 256, activation=tf.nn.relu)\n",
    "  net = tf.layers.dense(net, 256, activation=tf.nn.relu)\n",
    "  net = tf.layers.dense(net, NUM_CLASSES)\n",
    "  \n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "      logits=net, labels=one_hot_labels))\n",
    "    \n",
    "  return loss, tf.nn.softmax(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVkAVAT_GBM6"
   },
   "source": [
    "## Train a MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31621,
     "status": "ok",
     "timestamp": 1558464166413,
     "user": {
      "displayName": "Ying Xiao",
      "photoUrl": "https://lh6.googleusercontent.com/-wc5QLou16Lg/AAAAAAAAAAI/AAAAAAAAACo/A_DqsuPQDsA/s64/photo.jpg",
      "userId": "00610379902306501069"
     },
     "user_tz": 420
    },
    "id": "eMy42D-pFHBZ",
    "outputId": "e12c6c99-4139-48e6-fac7-106839d1a599"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "images, one_hot_labels, _ = data_fn(num_epochs=None, shuffle=True, initializable=False) \n",
    "\n",
    "loss, predictions = model_fn(images, one_hot_labels)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(tf.math.argmax(predictions, axis=1),\n",
    "                          tf.math.argmax(one_hot_labels, axis=1))))\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "# Simple training loop that saves the model checkpoint every 1000 steps.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  for i in range(NUM_TRAIN_STEPS):\n",
    "    if i % NUM_SUMMARIZE_STEPS == 0:\n",
    "      saver.save(sess, os.path.join(TRAIN_PATH, 'model.ckpt'), global_step=i)\n",
    "    \n",
    "    outputs = sess.run([loss, train_op])\n",
    "    \n",
    "    if i % NUM_SUMMARIZE_STEPS == 0:\n",
    "      print 'Step: ', i, 'Loss: ', outputs[0] \n",
    "  \n",
    "  # Save a final checkpoint.\n",
    "  saver.save(sess, os.path.join(TRAIN_PATH, 'model.ckpt'), \n",
    "             global_step=NUM_TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1558464029756,
     "user": {
      "displayName": "Ying Xiao",
      "photoUrl": "https://lh6.googleusercontent.com/-wc5QLou16Lg/AAAAAAAAAAI/AAAAAAAAACo/A_DqsuPQDsA/s64/photo.jpg",
      "userId": "00610379902306501069"
     },
     "user_tz": 420
    },
    "id": "XjtVbmTCWuUg",
    "outputId": "d7d31c96-ad1b-4698-dc65-8735365f8212"
   },
   "outputs": [],
   "source": [
    "# Check that the model fits the training data.\n",
    "with tf.Session() as sess:\n",
    "  saver.restore(sess, os.path.join(TRAIN_PATH, 'model.ckpt-10000'))\n",
    "  \n",
    "  minibatch_accuracy = 0.0\n",
    "  for i in range(100):\n",
    "    minibatch_accuracy += sess.run(accuracy) / 100\n",
    "    \n",
    "print 'Accuracy on training data:',  minibatch_accuracy    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxArOnKKGDjr"
   },
   "source": [
    "## Run Lanczos on the MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpZN94fKGFVn"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "checkpoint_to_load = os.path.join(TRAIN_PATH, 'model.ckpt-10000')\n",
    "\n",
    "# For Lanczos, the tf.data pipeline should have some very specific characteristics:\n",
    "# 1. It should stop after a single epoch.\n",
    "# 2. It should be deterministic (i.e., no data augmentation).\n",
    "# 3. It should be initializable (we use it to restart the pipeline for each Lanczos iteration).\n",
    "images, one_hot_labels, init = data_fn(num_epochs=1, shuffle=False, initializable=True)\n",
    "\n",
    "loss, _ = model_fn(images, one_hot_labels)\n",
    "\n",
    "# Setup for Lanczos mode.\n",
    "restore_specs = [\n",
    "    experiment_utils.RestoreSpec(tf.trainable_variables(),\n",
    "                                 checkpoint_to_load)]\n",
    "\n",
    "# This callback is used to restart the tf.data pipeline for each Lanczos\n",
    "# iteration on each worker (the chief has a slightly different callback). You \n",
    "# can check the logs to see the status of the computation: new \n",
    "# phases of Lanczos iteration are indicated by \"New phase i\", and local steps \n",
    "# per worker are logged with \"Local step j\".\n",
    "def end_of_input(sess, train_op):\n",
    "  try:\n",
    "    sess.run(train_op)\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    sess.run(init)\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "# This object stores the state for the phases of the Lanczos iteration.\n",
    "experiment = lanczos_experiment.LanczosExperiment(\n",
    "    loss, \n",
    "    worker=0,  # These two flags will change when the number of workers > 1.\n",
    "    num_workers=1,\n",
    "    save_path=LANCZOS_PATH, \n",
    "    end_of_input=end_of_input,\n",
    "    lanczos_steps=NUM_LANCZOS_STEPS,\n",
    "    num_draws=1,\n",
    "    output_address=LANCZOS_PATH)\n",
    "\n",
    "# For distributed training, there are a few options:\n",
    "# Multi-gpu single worker: Partition the tf.data per tower of the model, and pass the aggregate\n",
    "#   loss to the LanczosExperiment class.\n",
    "# Multi-gpu multi worker: Set num_workers in LanczosExperiment to be equal to the number of workers.\n",
    "\n",
    "# These have to be ordered.\n",
    "train_op = experiment.get_train_op()\n",
    "saver = experiment.get_saver(checkpoint_to_load, restore_specs)\n",
    "init_fn = experiment.get_init_fn()\n",
    "train_fn = experiment.get_train_fn()\n",
    "local_init_op = tf.group(tf.local_variables_initializer(), init)\n",
    "\n",
    "train_step_kwargs = {}\n",
    "\n",
    "# The LanczosExperiment class is designed with slim in mind since it gives us\n",
    "# very specific control of the main training loop.\n",
    "tf.contrib.slim.learning.train(\n",
    "    train_op,\n",
    "    train_step_kwargs=train_step_kwargs,\n",
    "    train_step_fn=train_fn,\n",
    "    logdir=LANCZOS_PATH,\n",
    "    is_chief=True,\n",
    "    init_fn=init_fn,\n",
    "    local_init_op=local_init_op,\n",
    "    global_step=tf.zeros([], dtype=tf.int64),  # Dummy global step.\n",
    "    saver=saver,\n",
    "    save_interval_secs=0,  # The LanczosExperiment class controls saving.\n",
    "    summary_op=None,  # DANGER DANGER: Do not change this.\n",
    "    summary_writer=None)\n",
    "\n",
    "# This cell takes a little time to run: maybe 7 mins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfZJWL4LGFvh"
   },
   "source": [
    "## Visualize the Hessian eigenvalue density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1558464561015,
     "user": {
      "displayName": "Ying Xiao",
      "photoUrl": "https://lh6.googleusercontent.com/-wc5QLou16Lg/AAAAAAAAAAI/AAAAAAAAACo/A_DqsuPQDsA/s64/photo.jpg",
      "userId": "00610379902306501069"
     },
     "user_tz": 420
    },
    "id": "ETs3S8THGHw_",
    "outputId": "a5571a9a-59b3-40a4-cd9b-afa38bbf72f9"
   },
   "outputs": [],
   "source": [
    "# Outputs are saved as numpy saved files. The most interesting ones are \n",
    "# 'tridiag_1' and 'lanczos_vec_1'.\n",
    "with open(os.path.join(LANCZOS_PATH, 'tridiag_1'), 'rb') as f:\n",
    "  tridiagonal = np.load(f)\n",
    "\n",
    "  # For legacy reasons, we need to squeeze tridiagonal.\n",
    "  tridiagonal = np.squeeze(tridiagonal)\n",
    "  # Note that the output shape is [NUM_LANCZOS_STEPS, NUM_LANCZOS_STEPS].\n",
    "  print tridiagonal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j460uvloest0"
   },
   "outputs": [],
   "source": [
    "# The function tridiag_to_density computes the density (i.e., trace estimator \n",
    "# the standard Gaussian c * exp(-(x - t)**2.0 / 2 sigma**2.0) where t is \n",
    "# from a uniform grid. Passing a reasonable sigma**2.0 to this function is \n",
    "# important -- somewhere between 1e-3 and 1e-5 seems to work best.\n",
    "density, grids = density.tridiag_to_density([tridiagonal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 324
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1558464565927,
     "user": {
      "displayName": "Ying Xiao",
      "photoUrl": "https://lh6.googleusercontent.com/-wc5QLou16Lg/AAAAAAAAAAI/AAAAAAAAACo/A_DqsuPQDsA/s64/photo.jpg",
      "userId": "00610379902306501069"
     },
     "user_tz": 420
    },
    "id": "P3jOxTgSfSoX",
    "outputId": "f7bcd42c-bcb2-4822-c967-766a8f0226af"
   },
   "outputs": [],
   "source": [
    "# We add a small epsilon to make the plot not ugly.\n",
    "plt.semilogy(grids, density + 1.0e-7)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('Density')\n",
    "plt.title('MNIST hessian eigenvalue density at step 10000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNA33o3mf67M"
   },
   "source": [
    "Note that this is only one draw so not all the individual peaks are the exact same height, we can make this more accurate by taking more draws.\n",
    "\n",
    "Exercise left to reader: run multiple draws and see what the density looks like!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "mnist_spectral_density.ipynb",
   "provenance": [
    {
     "file_id": "1MWjHZh78Wa9X-_n0d3GVB8-iZ6WZTa2B",
     "timestamp": 1558464608269
    },
    {
     "file_id": "/piper/depot/google3/learning/faster_training/optimization/g3doc/mnist_spectral_density.ipynb",
     "timestamp": 1558456686172
    },
    {
     "file_id": "1SwqMxixRil-AMGWpNBhuDFSTkvR9fWgU",
     "timestamp": 1557157671561
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
