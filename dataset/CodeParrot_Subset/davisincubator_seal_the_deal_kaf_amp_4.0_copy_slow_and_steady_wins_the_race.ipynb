{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['adult_females', 'adult_males', 'juveniles', 'pups', 'subadult_males']\n",
    "\n",
    "my_dir = \"/seal_the_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify run number, which selects appropriate file name subset and file name suffix\n",
    "# will need 9 runs total\n",
    "\n",
    "# completed runs: \n",
    "\n",
    "run_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.jpg', '7.jpg', '9.jpg', '21.jpg', '30.jpg']\n",
      "['3.jpg', '7.jpg', '9.jpg', '21.jpg', '30.jpg', '34.jpg', '71.jpg', '81.jpg', '89.jpg', '97.jpg', '151.jpg', '184.jpg', '215.jpg', '234.jpg', '242.jpg', '268.jpg', '290.jpg', '311.jpg', '331.jpg', '344.jpg', '380.jpg', '384.jpg', '406.jpg', '421.jpg', '469.jpg', '475.jpg', '490.jpg', '499.jpg', '507.jpg', '530.jpg', '531.jpg', '605.jpg', '607.jpg', '614.jpg', '621.jpg', '638.jpg', '644.jpg', '687.jpg', '712.jpg', '721.jpg', '767.jpg', '779.jpg', '781.jpg', '794.jpg', '800.jpg', '811.jpg', '839.jpg', '840.jpg', '869.jpg', '882.jpg', '901.jpg', '903.jpg', '905.jpg', '909.jpg', '913.jpg', '927.jpg', '946.jpg', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "mismatch_id=[3,7,9,21,30,34,71,81,89,97,151,184,215,234,242,268,290,311,331,344,380,384,406,421,469,475,490,499,507,530,531,605,607,614,621,638,644,687,712,721,767,779,781,794,800,811,839,840,869,882,901,903,905,909,913,927,946]\n",
    "blacklist = []\n",
    "for i in mismatch_id:\n",
    "    blacklist.append(str(i) + '.jpg')\n",
    "print(blacklist[:5])\n",
    "blacklist.append('train.csv')\n",
    "print(blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir(my_dir + \"Train/\")\n",
    "file_names = sorted(file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "file_names = file_names[0:1]\n",
    "\n",
    "# dataframe to store results in\n",
    "coordinates_df = pd.DataFrame(index=file_names, columns=class_names)\n",
    "\n",
    "#print(file_names[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3991f6452ba648f8a1f4eac62eadabf9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm_notebook(file_names):\n",
    "    if filename in blacklist:\n",
    "        file_names.remove(filename)\n",
    "    else:\n",
    "        # read the Train and Train Dotted images\n",
    "        image_1 = cv2.imread(my_dir + \"/TrainDotted/\" + filename)\n",
    "        image_2 = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "\n",
    "        cut = np.copy(image_2)\n",
    "\n",
    "        # absolute difference between Train and Train Dotted\n",
    "        image_3 = cv2.absdiff(image_1,image_2)\n",
    "\n",
    "    # mask out blackened regions from Train Dotted\n",
    "        mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "        mask_1[mask_1 < 20] = 0\n",
    "        mask_1[mask_1 > 0] = 255\n",
    "\n",
    "        mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "        mask_2[mask_2 < 20] = 0\n",
    "        mask_2[mask_2 > 0] = 255\n",
    "\n",
    "        image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "        image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n",
    "\n",
    "        # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "        image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect blobs\n",
    "        blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "\n",
    "        adult_males = []\n",
    "        subadult_males = []\n",
    "        pups = []\n",
    "        juveniles = []\n",
    "        adult_females = [] \n",
    "\n",
    "        image_circles = image_1\n",
    "\n",
    "        for blob in blobs:\n",
    "            # get the coordinates for each blob\n",
    "            y, x, s = blob\n",
    "            # get the color of the pixel from Train Dotted in the center of the blob\n",
    "            g,b,r = image_1[int(y)][int(x)][:]\n",
    "\n",
    "            # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "            if r > 200 and g < 50 and b < 50: # RED\n",
    "                adult_males.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (0,0,255), 10) \n",
    "            elif r > 200 and g > 200 and b < 50: # MAGENTA\n",
    "                subadult_males.append((int(x),int(y))) \n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (250,10,250), 10)\n",
    "            elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n",
    "                pups.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (20,180,35), 10)\n",
    "            elif r < 100 and  100 < g and b < 100: # BLUE\n",
    "                juveniles.append((int(x),int(y))) \n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (180,60,30), 10)\n",
    "            elif r < 150 and g < 50 and b < 100:  # BROWN\n",
    "                adult_females.append((int(x),int(y)))\n",
    "                cv2.circle(image_circles, (int(x),int(y)), 20, (0,42,84), 10)  \n",
    "\n",
    "            cv2.rectangle(cut, (int(x)-112,int(y)-112),(int(x)+112,int(y)+112), 0,-1)\n",
    "\n",
    "        coordinates_df[\"adult_males\"][filename] = adult_males\n",
    "        coordinates_df[\"subadult_males\"][filename] = subadult_males\n",
    "        coordinates_df[\"adult_females\"][filename] = adult_females\n",
    "        coordinates_df[\"juveniles\"][filename] = juveniles\n",
    "        coordinates_df[\"pups\"][filename] = pups\n",
    "        \n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804b871581404468b7015b1d79b7d30d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for filename in tqdm_notebook(file_names):    \n",
    "    image = cv2.imread(my_dir + \"/Train/\" + filename)\n",
    "    for lion_class in class_names:\n",
    "        try:\n",
    "            for coordinates in coordinates_df[lion_class][filename]:\n",
    "                thumb = image[coordinates[1]-32:coordinates[1]+32,coordinates[0]-32:coordinates[0]+32,:]\n",
    "                if np.shape(thumb) == (64, 64, 3):\n",
    "                    x.append(thumb)\n",
    "                    y.append(lion_class)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,np.shape(cut)[0],224):\n",
    "    for j in range(0,np.shape(cut)[1],224):                \n",
    "        thumb = cut[i:i+64,j:j+64,:]\n",
    "        if np.amin(cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)) != 0:\n",
    "            if np.shape(thumb) == (64,64,3):\n",
    "                x.append(thumb)\n",
    "                y.append(\"negative\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names.append(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my_model = '2017-06-23_model.h5'#what is the model file named?\n",
    "\n",
    "my_model = '2017-06-25_model.h5'#what is the model file named?\n",
    "\n",
    "model = load_model(my_dir + my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number: 1\n",
      "['0.jpg', '1.jpg', '2.jpg', '3.jpg', '4.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_file_names = os.listdir(my_dir + \"Test/\")\n",
    "test_file_names = sorted(test_file_names, key=lambda \n",
    "                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item)) \n",
    "\n",
    "# select a subset of files to run on\n",
    "\n",
    "if run_num == 1:\n",
    "    test_file_names = test_file_names[:2000]\n",
    "elif run_num == 2:\n",
    "    test_file_names = test_file_names[2000:4000]\n",
    "elif run_num == 3:\n",
    "    test_file_names = test_file_names[4000:6000]\n",
    "elif run_num == 4: \n",
    "    test_file_names = test_file_names[6000:8000]\n",
    "elif run_num == 5:\n",
    "    test_file_names = test_file_names[8000:10000]\n",
    "elif run_num == 6:\n",
    "    test_file_names = test_file_names[10000:12000]\n",
    "elif run_num == 7:\n",
    "    test_file_names = test_file_names[12000:14000]\n",
    "elif run_num == 8:\n",
    "    test_file_names = test_file_names[14000:16000]\n",
    "elif run_num == 9:\n",
    "    test_file_names = test_file_names[16000:]\n",
    "\n",
    "\n",
    "# dataframe to store results in\n",
    "test_coordinates_df = pd.DataFrame(0,index=test_file_names, columns=class_names)\n",
    "\n",
    "print('run number:', run_num)\n",
    "print(test_file_names[:5])\n",
    "#print(test_coordinates_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09517be6ec924b95a17cc13d59f29ee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 0 images at 16:10\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm_notebook(test_file_names):\n",
    "    file_int = int(filename[:-4])\n",
    "    current_time = datetime.datetime.now().time().isoformat()[:5]\n",
    "    if file_int%500 == 0:\n",
    "        print('completed %d images at %s' % (file_int, current_time))\n",
    "        \n",
    "    img = cv2.imread(my_dir + \"Test/\"  + filename)\n",
    "\n",
    "    x_test = []\n",
    "\n",
    "    for i in range(0,np.shape(img)[0],64):\n",
    "        for j in range(0,np.shape(img)[1],64):                \n",
    "            thumb = img[i:i+64,j:j+64,:]        \n",
    "            if np.shape(thumb) == (64,64,3):\n",
    "                x_test.append(thumb)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    y_predicted = model.predict(x_test, verbose=0)\n",
    "\n",
    "    y_predicted = encoder.inverse_transform(y_predicted)\n",
    "\n",
    "    the_counter = Counter(y_predicted)\n",
    "    \n",
    "    #print(the_counter)\n",
    "    \n",
    "    for key in the_counter:\n",
    "        test_coordinates_df.set_value(index = filename, col = key, value = the_counter[key])\n",
    "        \n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           adult_males  subadult_males  adult_females  juveniles  pups\n",
      "0.jpg                6               3             62         28   117\n",
      "1.jpg               38              10            199         95   534\n",
      "2.jpg              324              27            821        401   543\n",
      "3.jpg               69               8            201        157   926\n",
      "4.jpg              215              36            441        235   711\n",
      "5.jpg              116              11            250        139  1093\n",
      "6.jpg               46               5            337        110  1429\n",
      "7.jpg               15               2            102         85   802\n",
      "8.jpg               24               4            160         96   538\n",
      "9.jpg              212              15           1164        303  2154\n",
      "10.jpg              48               5            190         97   840\n",
      "11.jpg              13               1            188        227  1780\n",
      "12.jpg              87              20            498        146   628\n",
      "13.jpg              57               1             45         29   885\n",
      "14.jpg             456              23            813        364  1144\n",
      "15.jpg              69              18            263        109   168\n",
      "16.jpg             106              10            239        132   517\n",
      "17.jpg             213              38            997        303  1119\n",
      "18.jpg              59              11            327         91   863\n",
      "19.jpg             104               8            198        117   488\n",
      "20.jpg              50               5            124         79  1258\n",
      "21.jpg              40               5            150         91   216\n",
      "22.jpg              53               8            255        113   364\n",
      "23.jpg              77              11            306        166   580\n",
      "24.jpg             481              60            509        310   237\n",
      "25.jpg              51              14            113         91   321\n",
      "26.jpg              49               5            226        129   859\n",
      "27.jpg              51               8            295        230  1402\n",
      "28.jpg              41               1             95        133  1024\n",
      "29.jpg              75               5            190         96   256\n",
      "...                ...             ...            ...        ...   ...\n",
      "18606.jpg            0               0              0          0     0\n",
      "18607.jpg            0               0              0          0     0\n",
      "18608.jpg            0               0              0          0     0\n",
      "18609.jpg            0               0              0          0     0\n",
      "18610.jpg            0               0              0          0     0\n",
      "18611.jpg            0               0              0          0     0\n",
      "18612.jpg            0               0              0          0     0\n",
      "18613.jpg            0               0              0          0     0\n",
      "18614.jpg            0               0              0          0     0\n",
      "18615.jpg            0               0              0          0     0\n",
      "18616.jpg            0               0              0          0     0\n",
      "18617.jpg            0               0              0          0     0\n",
      "18618.jpg            0               0              0          0     0\n",
      "18619.jpg            0               0              0          0     0\n",
      "18620.jpg            0               0              0          0     0\n",
      "18621.jpg            0               0              0          0     0\n",
      "18622.jpg            0               0              0          0     0\n",
      "18623.jpg            0               0              0          0     0\n",
      "18624.jpg            0               0              0          0     0\n",
      "18625.jpg            0               0              0          0     0\n",
      "18626.jpg            0               0              0          0     0\n",
      "18627.jpg            0               0              0          0     0\n",
      "18628.jpg            0               0              0          0     0\n",
      "18629.jpg            0               0              0          0     0\n",
      "18630.jpg            0               0              0          0     0\n",
      "18631.jpg            0               0              0          0     0\n",
      "18632.jpg            0               0              0          0     0\n",
      "18633.jpg            0               0              0          0     0\n",
      "18634.jpg            0               0              0          0     0\n",
      "18635.jpg            0               0              0          0     0\n",
      "\n",
      "[18636 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "protect_df = test_coordinates_df\n",
    "#print(test_coordinates_df)\n",
    "\n",
    "del test_coordinates_df['negative']\n",
    "test_coordinates_df = test_coordinates_df[['adult_males', 'subadult_males', 'adult_females', 'juveniles', 'pups']]\n",
    "print(test_coordinates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_coordinates_df.to_csv(my_dir + datetime.date.today().isoformat() + '_submission_' + str(run_num) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
