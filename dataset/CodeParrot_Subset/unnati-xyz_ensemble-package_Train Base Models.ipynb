{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import ensembles as en\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn import datasets, linear_model, preprocessing, grid_search\n",
    "from sklearn.preprocessing import Imputer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, accuracy_score, \\\n",
    "mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials \n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from functools import partial\n",
    "np.random.seed(1338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "gradient_boosting \n",
      " 0.946058545288\n",
      "decision_tree \n",
      " 0.909509450372\n",
      "Gradient Boosting Model\n",
      " <xgboost.core.Booster object at 0x7f0264451780>\n",
      "\n",
      "Decision Tree Model\n",
      " GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_depth': [6], 'max_leaf_nodes': [None], 'max_features': [None], 'class_weight': [None], 'random_state': [None], 'min_samples_leaf': [1], 'min_samples_split': [2], 'criterion': ['gini'], 'presort': [False], 'min_weight_fraction_leaf': [0.0], 'splitter': ['best']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)\n",
      "CPU times: user 1.4 s, sys: 88 ms, total: 1.49 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "en.train_base_models(['gradient_boosting','decision_tree'],[param_gb, param_dt], save_models = True)\n",
    "\n",
    "#Models saved as .pkl files\n",
    "[gb, dt] = en.get_base_models()\n",
    "\n",
    "print('Gradient Boosting Model\\n', gb)\n",
    "print('\\nDecision Tree Model\\n', dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 36)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "12672/14416 [=========================>....] - ETA: 0slinear_regression \n",
      " 0.929172991818\n",
      "logistic_regression \n",
      " 0.929891719578\n",
      "multi_layer_perceptron \n",
      " 0.5\n",
      "CPU times: user 6.25 s, sys: 512 ms, total: 6.76 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y',encode = 'binary')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(4)\n",
    "\n",
    "#Setting penalty, rest are default values\n",
    "param_lor = en.parameter_set_logistic_regression(penalty = ['l1'])\n",
    "\n",
    "#Setting fit_intercept, rest are default values\n",
    "param_lr = en.parameter_set_linear_regression(fit_intercept = [False])\n",
    "\n",
    "#Setting dim_layer, activation, rest are deafault values\n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = False, \\\n",
    "                                                    dim_layer = [[32], [64], [32], [1]], \\\n",
    "                                                   activation = [['sigmoid'], ['relu'], ['sigmoid'], ['relu']])\n",
    "\n",
    "#MLP does not work well with binary encode (changes to be made)\n",
    "en.train_base_models(['linear_regression','logistic_regression', 'multi_layer_perceptron'], \\\n",
    "                     [param_lr, param_lor, param_mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (4119, 36)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "decision_tree \n",
      " 0.916712400212\n",
      "decision_tree \n",
      " 0.736683372899\n",
      "gradient_boosting \n",
      " 0.933923749864\n",
      "CPU times: user 5.64 s, sys: 120 ms, total: 5.76 s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y', encode ='binary', split = True, stratify = False, split_size = 0.1)\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15], colsample_bylevel = [0.1])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt_1 = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "#Default Values\n",
    "param_dt_2 = en.parameter_set_decision_tree()\n",
    "\n",
    "en.train_base_models(['decision_tree','decision_tree', 'gradient_boosting'], \\\n",
    "                     [param_dt_1, param_dt_2, param_gb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.5579 - acc: 0.7256     \n",
      "Epoch 2/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3437 - acc: 0.8874     \n",
      "Epoch 3/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3360 - acc: 0.8874     \n",
      "Epoch 4/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3310 - acc: 0.8874     \n",
      "Epoch 5/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3262 - acc: 0.8874     \n",
      "Epoch 6/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3214 - acc: 0.8874     \n",
      "Epoch 7/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3168 - acc: 0.8874     \n",
      "Epoch 8/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3123 - acc: 0.8874     \n",
      "Epoch 9/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3079 - acc: 0.8874     \n",
      "Epoch 10/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3035 - acc: 0.8874     \n",
      "Epoch 1/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.4567 - acc: 0.8172     \n",
      "Epoch 2/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3525 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3471 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3431 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3393 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3354 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3315 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3276 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3235 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3194 - acc: 0.8873     \n",
      "Epoch 1/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.4163 - acc: 0.8868     \n",
      "Epoch 2/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3587 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3536 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3500 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3465 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3431 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3397 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3364 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3330 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.3295 - acc: 0.8873     \n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.4110 - acc: 0.8776     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3578 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3509 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3446 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3385 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3324 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3262 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3200 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3136 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.3071 - acc: 0.8873     \n",
      "13856/14415 [===========================>..] - ETA: 0s\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "13024/14416 [==========================>...] - ETA: 0srandom_forest \n",
      " 0.916069580126\n",
      "multi_layer_perceptron \n",
      " 0.833374803025\n",
      "gradient_boosting \n",
      " 0.946983249614\n",
      "CPU times: user 2.07 s, sys: 156 ms, total: 2.22 s\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(3)\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Setting n_estimators, criterion, rest are default values\n",
    "#Hyper parameter optimisation - n_estimators\n",
    "param_rf = en.parameter_set_random_forest(n_estimators = [6, 10, 12], criterion = ['entropy'])\n",
    "\n",
    "#Setting dim_layer, activation, rest are default values\n",
    "#Hyper parameter optimisation : dim_layer - Layer1 and Layer 2\n",
    "#Hyper parameter optimisation : activation - Layer1 \n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = True, \\\n",
    "                                                    dim_layer = [[32,64,128], [32,64], [1]], \\\n",
    "                                                   activation = [['sigmoid','relu'], \\\n",
    "                                                                 ['sigmoid'], ['sigmoid','relu']], \\\n",
    "                                                   optimizer = 'sgd')\n",
    "\n",
    "en.train_base_models(['random_forest','multi_layer_perceptron', 'gradient_boosting'], \\\n",
    "                     [param_rf, param_mlp, param_gb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 2/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 3/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 4/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 5/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 6/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 7/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 8/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 9/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 10/10\n",
      "9609/9609 [==============================] - 0s - loss: 1.8149 - acc: 0.8874     \n",
      "Epoch 1/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.4594 - acc: 0.8292     \n",
      "Epoch 2/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2607 - acc: 0.9048     \n",
      "Epoch 3/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2545 - acc: 0.9055     \n",
      "Epoch 4/10\n",
      "9610/9610 [==============================] - 1s - loss: 0.2627 - acc: 0.9062     \n",
      "Epoch 5/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2462 - acc: 0.9046     \n",
      "Epoch 6/10\n",
      "9610/9610 [==============================] - 1s - loss: 0.2495 - acc: 0.9067     \n",
      "Epoch 7/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2429 - acc: 0.9088     \n",
      "Epoch 8/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2408 - acc: 0.9086     \n",
      "Epoch 9/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2443 - acc: 0.9084     \n",
      "Epoch 10/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2404 - acc: 0.9101     \n",
      "Epoch 1/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 2/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2591 - acc: 0.9014     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2504 - acc: 0.9075     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2448 - acc: 0.9095     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2367 - acc: 0.9118     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2347 - acc: 0.9073     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2398 - acc: 0.9109     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2352 - acc: 0.9083     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 1s - loss: 0.2438 - acc: 0.9100     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 1s - loss: 0.2311 - acc: 0.9072     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2394 - acc: 0.9077     \n",
      "13344/14415 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "12512/14416 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest \n",
      " 0.940931586899\n",
      "multi_layer_perceptron \n",
      " 0.920753152178\n",
      "gradient_boosting \n",
      " 0.946383804379\n",
      "logistic_regression \n",
      " 0.924926235455\n",
      "linear_regression \n",
      " 0.923427646435\n",
      "decision_tree \n",
      " 0.921747654592\n",
      "CPU times: user 2.56 s, sys: 196 ms, total: 2.76 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(3)\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb_1 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb_2 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15], colsample_bylevel = [0.1])\n",
    "\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "#Setting max_depth, n_estimators, max_features, rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - n_estimators\n",
    "param_rf = en.parameter_set_random_forest(max_depth = [6, 10, 12, 15], n_estimators = [10, 20, 30], \\\n",
    "                                          max_features = ['log2'])\n",
    "\n",
    "#Setting penalty, C, rest are default values\n",
    "#Hyper parameter optimisation - penalty\n",
    "#Hyper parameter optimisation - C\n",
    "param_lor = en.parameter_set_logistic_regression(penalty = ['l1','l2'], C = [1.0, 2.0, 3.0, 5.0, 10.0])\n",
    "\n",
    "#Setting fit_intercept, rest are default values\n",
    "param_lr = en.parameter_set_linear_regression(fit_intercept = [False])\n",
    "\n",
    "#Setting dim_layer, activation, rest are default values\n",
    "#Hyper parameter optimisation : dim_layer - Layer1 and Layer 2\n",
    "#Hyper parameter optimisation : activation - Layer1 and Layer 2\n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = True, \\\n",
    "                                                    dim_layer = [[32,64,128], [32,64], [1]], \\\n",
    "                                                   activation = [['sigmoid','relu'], \\\n",
    "                                                                 ['sigmoid'], ['sigmoid','relu']], \\\n",
    "                                                   optimizer = 'rmsprop')\n",
    "\n",
    "\n",
    "\n",
    "en.train_base_models(['random_forest','multi_layer_perceptron', 'gradient_boosting', \\\n",
    "                      'logistic_regression','linear_regression', 'decision_tree'], \\\n",
    "                     [param_rf, param_mlp, param_gb_1, param_lor, param_lr, param_dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
