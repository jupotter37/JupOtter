{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Multilayer perceptrons in gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import gluon\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_examples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    return data.astype(np.float32) / 255, label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(dataset=gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)\n",
    "test_data = gluon.data.DataLoader(dataset=gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MLP model with mx.Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense0 = gluon.nn.Dense(64)\n",
    "            self.dense1 = gluon.nn.Dense(64)\n",
    "            self.dense2 = gluon.nn.Dense(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = mx.nd.relu(self.dense0(x))\n",
    "        x = mx.nd.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "net.collect_params().initialize(mx.init.Normal(sigma=.01), \n",
    "                                ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a single forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.nd.ones(shape=[1, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Hidden Representation 1: \n",
      "[[0.         0.25953296 0.5081844  0.47407073 0.5739144  0.04646487\n",
      "  0.3490802  0.         0.         0.         0.         0.\n",
      "  0.09897906 0.         0.44429356 0.5806929  0.         0.\n",
      "  0.07937321 0.13445261 0.17002776 0.         0.59629107 0.\n",
      "  0.51476306 0.2620116  0.07252947 0.         0.44609177 0.\n",
      "  0.10297956 0.12023637 0.01070242 0.14927042 0.         0.11931495\n",
      "  0.06247869 0.34996682 0.23720959 0.33213574 0.         0.\n",
      "  0.35576025 0.02980644 0.         0.         0.3602543  0.01930529\n",
      "  0.5578985  0.         0.         0.22368181 0.3668564  0.0344954\n",
      "  0.16685106 0.         0.07805604 0.04645126 0.46009526 0.\n",
      "  0.         0.         0.         0.4059968 ]]\n",
      "<NDArray 1x64 @cpu(0)>\n",
      "----------------------------------------------------------------------\n",
      "Hidden Representation 2: \n",
      "[[0.         0.         0.00471901 0.00809325 0.00563266 0.00358269\n",
      "  0.01304015 0.         0.         0.0179144  0.00409093 0.01971137\n",
      "  0.01811438 0.         0.         0.03330275 0.03080758 0.\n",
      "  0.01005297 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01851467 0.         0.00467824\n",
      "  0.         0.00476716 0.00890849 0.         0.01493133 0.\n",
      "  0.01890475 0.         0.01004198 0.         0.         0.\n",
      "  0.         0.         0.0218619  0.         0.01256697 0.\n",
      "  0.00875257 0.01837254 0.         0.012395   0.         0.\n",
      "  0.         0.         0.03347883 0.         0.00547096 0.0096815\n",
      "  0.03013829 0.         0.02648943 0.        ]]\n",
      "<NDArray 1x64 @cpu(0)>\n",
      "----------------------------------------------------------------------\n",
      "Network output: \n",
      "[[ 0.0010479  -0.00023263  0.00024665 -0.00137001 -0.00089217 -0.00043491\n",
      "   0.0017453  -0.00114445  0.00024293 -0.0004818 ]]\n",
      "<NDArray 1x10 @cpu(0)>\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.0010479  -0.00023263  0.00024665 -0.00137001 -0.00089217 -0.00043491\n",
       "   0.0017453  -0.00114445  0.00024293 -0.0004818 ]]\n",
       "<NDArray 1x10 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense0 = gluon.nn.Dense(units=64, activation=\"relu\")\n",
    "            self.dense1 = gluon.nn.Dense(units=64, activation=\"relu\")\n",
    "            self.dense2 = gluon.nn.Dense(units=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense0(x)\n",
    "        print(\"-\" * 70)\n",
    "        print(\"Hidden Representation 1: %s\" % x)\n",
    "        x = self.dense1(x)\n",
    "        print(\"-\" * 70)\n",
    "        print(\"Hidden Representation 2: %s\" % x)\n",
    "        x = self.dense2(x)\n",
    "        print(\"-\" * 70)\n",
    "        print(\"Network output: %s\" % x)\n",
    "        print(\"-\" * 70)\n",
    "        return x\n",
    "\n",
    "net = MLP()\n",
    "net.collect_params().initialize(mx.init.Normal(sigma=.01), ctx=model_ctx)\n",
    "net(data.as_in_context(model_ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster modeling with gluon.nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a sequential model\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(units=num_hidden, \n",
    "                           activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(units=num_hidden, \n",
    "                           activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(units=num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "net.collect_params().initialize(mx.init.Normal(sigma=.1), \n",
    "                                ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax cross-entropy\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "trainer = gluon.Trainer(params=net.collect_params(),\n",
    "                        optimizer='sgd',\n",
    "                        optimizer_params={'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        output = net(data)\n",
    "        predictions = mx.nd.argmax(data=output,\n",
    "                                   axis=1)\n",
    "        # Updating accuracy metric\n",
    "        acc.update(preds=predictions, \n",
    "                   labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "smoothing_constant = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:31<04:41, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 1.2724453049023947, Train_acc 0.8347, Test_acc 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|â–ˆâ–ˆ        | 2/10 [01:05<04:20, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 0.48276078701019287, Train_acc 0.87955, Test_acc 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:35<03:43, 31.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Loss: 0.37886862614949546, Train_acc 0.8980166666666667, Test_acc 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:05<03:08, 31.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Loss: 0.33094510640303293, Train_acc 0.9094666666666666, Test_acc 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [02:34<02:34, 30.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Loss: 0.30067180269559224, Train_acc 0.9174833333333333, Test_acc 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:04<02:03, 30.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss: 0.2779835115830104, Train_acc 0.9238333333333333, Test_acc 0.9227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [03:34<01:31, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Loss: 0.2602314037243525, Train_acc 0.9279833333333334, Test_acc 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [04:03<01:00, 30.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Loss: 0.24440940081278484, Train_acc 0.93445, Test_acc 0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [04:33<00:30, 30.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8. Loss: 0.23077674449682237, Train_acc 0.9357666666666666, Test_acc 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:03<00:00, 30.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss: 0.21937609051863352, Train_acc 0.9384166666666667, Test_acc 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(epochs)):\n",
    "    cumulative_loss = 0\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        with mx.autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        cumulative_loss += mx.nd.sum(loss).asscalar()\n",
    "\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384166666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
