{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from psi.controller import util\n",
    "from psi.controller.calibration.api import FlatCalibration, PointCalibration\n",
    "from psi.controller.calibration.util import load_calibration, psd, psd_df, db, dbtopa\n",
    "from psi.controller.calibration import tone\n",
    "from psi.core.enaml.api import load_manifest_from_file\n",
    "\n",
    "frequencies = [250, 500, 1000, 2000, 4000, 8000, 16000, 32000]\n",
    "\n",
    "io_file = 'c:/psi/io/pika.enaml'\n",
    "cal_file = 'c:/psi/io/pika/default.json'\n",
    "\n",
    "io_manifest = load_manifest_from_file(io_file, 'IOManifest')\n",
    "io = io_manifest()\n",
    "audio_engine = io.find('NI_audio')\n",
    "\n",
    "channels = audio_engine.get_channels(active=False)\n",
    "load_calibration(cal_file, channels)\n",
    "\n",
    "mic_channel = audio_engine.get_channel('microphone_channel')\n",
    "mic_channel.gain = 40\n",
    "print(mic_channel.calibration)\n",
    "\n",
    "speaker_channel = audio_engine.get_channel('speaker_1')\n",
    "print(speaker_channel.calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_gain_result = tone.tone_sens(\n",
    "    frequencies=frequencies,\n",
    "    engine=audio_engine,\n",
    "    ao_channel_name='speaker_1',\n",
    "    ai_channel_names=['microphone_channel'],\n",
    "    gains=-30,\n",
    "    debug=True,\n",
    "    duration=0.1,\n",
    "    iti=0,\n",
    "    trim=0.01,\n",
    "    repetitions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = pl.subplots(4, 2)\n",
    "\n",
    "for ax, freq in zip(axes.ravel(), frequencies):\n",
    "    w = fixed_gain_result.loc['microphone_channel', freq]['waveform'].T\n",
    "    ax.plot(w)\n",
    "    ax.set_title(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_sens = fixed_gain_result.loc['microphone_channel', 'sens']\n",
    "calibration = PointCalibration(tone_sens.index, tone_sens.values)\n",
    "gains = calibration.get_gain(frequencies, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_gain_result = tone.tone_spl(\n",
    "    frequencies=frequencies,\n",
    "    engine=audio_engine,\n",
    "    ao_channel_name='speaker_1',\n",
    "    ai_channel_names=['microphone_channel'],\n",
    "    gains=gains,\n",
    "    debug=True,\n",
    "    duration=0.1,\n",
    "    iti=0,\n",
    "    trim=0.01,\n",
    "    repetitions=2,\n",
    ")\n",
    "\n",
    "variable_gain_result['spl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psi.token.primitives import ChirpFactory\n",
    "\n",
    "factory = ChirpFactory(fs=speaker_channel.fs,\n",
    "                       start_frequency=500,\n",
    "                       end_frequency=50000,\n",
    "                       duration=0.02,\n",
    "                       level=-40,\n",
    "                       calibration=FlatCalibration.as_attenuation())\n",
    "\n",
    "n = factory.get_remaining_samples()\n",
    "chirp_waveform = factory.next(n)\n",
    "\n",
    "result = util.acquire(audio_engine, chirp_waveform, 'speaker_1', ['microphone_channel'], repetitions=64, trim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirp_response = result['microphone_channel'][0]\n",
    "chirp_psd = psd_df(chirp_response, mic_channel.fs)\n",
    "chirp_psd_mean = chirp_psd.mean(axis=0)\n",
    "chirp_psd_mean_db = db(chirp_psd_mean)\n",
    "\n",
    "signal_psd = db(psd_df(chirp_waveform, speaker_channel.fs))\n",
    "\n",
    "freq = chirp_psd.columns.values\n",
    "chirp_spl = mic_channel.calibration.get_spl(freq, chirp_psd)\n",
    "chirp_spl_mean = chirp_spl.mean(axis=0)\n",
    "chirp_sens = signal_psd - chirp_spl_mean - db(20e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirp_sens.loc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = pl.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "chirp_response_mean = np.mean(chirp_response, axis=0)\n",
    "print(chirp_response_mean.min(), chirp_response_mean.max())\n",
    "axes[0].plot(chirp_response_mean)\n",
    "\n",
    "freq = chirp_spl_mean.index.values\n",
    "axes[1].semilogx(freq[1:], chirp_spl_mean[1:])\n",
    "x = psd_df(chirp_response_mean, mic_channel.fs)\n",
    "y = mic_channel.calibration.get_spl(x.index, x.values)\n",
    "axes[1].semilogx(freq[1:], y[1:], 'r')\n",
    "axes[1].axis(xmin=500, xmax=50000)\n",
    "\n",
    "axes[2].semilogx(freq[1:], chirp_sens[1:])\n",
    "axes[2].plot(tone_sens, 'ko')\n",
    "axes[2].axis(xmin=500, xmax=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
