{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCLOD Test for Coefficient 1\n",
    "\n",
    "This script performs the main VCLOD test for this thesis with a specific diffusion coefficient. We investigate the energy error of the VCLOD dependent on the updated correctors. For this purpose, we update every corrector individually and compare it to the reference solution. This enables a good comparison between percentages. We desire to yield a fast decrease of the energy error of the VCLOD method since, due to the error indicator, we sort and update the element correctors in terms of the effect that comes with the perturbation.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import csv\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from visualize import drawCoefficient\n",
    "from data import * \n",
    "\n",
    "from gridlod import interp, coef, util, fem, world, linalg, femsolver\n",
    "import pg_rand, femsolverCoarse, buildcoef2d\n",
    "from gridlod.world import World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result function\n",
    "\n",
    "The 'result' function investigates the VCLOD for each percentage. The reference solution is computed by a standard FEM on the fine mesh. We compute the 'worst solution' that represents zero percentage updating and clearly has no computational cost at all. Afterwards, we compute the error indicator for the given patch size $k=4$ and use every value gradually. Furthermore we store the resulting energy error for the VCLOD as well as the optimal energy error that results from 100 percentage updating. Once again, we take advantage of the 'gridlod' module in order to compute the required matrices.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result(pglod, world, A, R, f, k, String):\n",
    "    print \"-------------- \" + String + \" ---------------\" \n",
    "    NWorldFine = world.NWorldFine\n",
    "    NWorldCoarse = world.NWorldCoarse\n",
    "    NCoarseElement = world.NCoarseElement\n",
    "    \n",
    "    boundaryConditions = world.boundaryConditions\n",
    "    NpFine = np.prod(NWorldFine+1)\n",
    "    NpCoarse = np.prod(NWorldCoarse+1)\n",
    "        \n",
    "    # new Coefficient\n",
    "    ANew = R.flatten()\n",
    "    Anew = coef.coefficientFine(NWorldCoarse, NCoarseElement, ANew)\n",
    "    \n",
    "    # reference solution\n",
    "    f_fine = np.ones(NpFine)\n",
    "    uFineFem, AFine, MFine = femsolver.solveFine(world, ANew, f_fine, None, boundaryConditions)\n",
    "    \n",
    "    # worst solution\n",
    "    KFull = pglod.assembleMsStiffnessMatrix()\n",
    "    MFull = fem.assemblePatchMatrix(NWorldCoarse, world.MLocCoarse)\n",
    "    free  = util.interiorpIndexMap(NWorldCoarse)                                 \n",
    "    \n",
    "    bFull = MFull*f\n",
    "    KFree = KFull[free][:,free]\n",
    "    bFree = bFull[free]\n",
    "\n",
    "    xFree = sparse.linalg.spsolve(KFree, bFree)\n",
    "    \n",
    "    basis = fem.assembleProlongationMatrix(NWorldCoarse, NCoarseElement)\n",
    "    \n",
    "    basisCorrectors = pglod.assembleBasisCorrectors()\n",
    "    modifiedBasis = basis - basisCorrectors\n",
    "    \n",
    "    xFull = np.zeros(NpCoarse)\n",
    "    xFull[free] = xFree\n",
    "    uCoarse = xFull\n",
    "    uLodFine = modifiedBasis*xFull\n",
    "    \n",
    "    uLodFineWorst = uLodFine\n",
    "    \n",
    "    # energy error\n",
    "    errorworst = np.sqrt(np.dot(uFineFem - uLodFineWorst, AFine*(uFineFem - uLodFineWorst)))\n",
    "    \n",
    "    # tolerance = 0 \n",
    "    vis, eps = pglod.updateCorrectors(Anew, 0, f, 1, clearFineQuantities=False, Computing=False)\n",
    "    \n",
    "    PotentialCorrectors = np.sum(vis)\n",
    "    elemente = np.arange(np.prod(NWorldCoarse))\n",
    "            \n",
    "    # identify tolerances\n",
    "    epsnozero = filter(lambda x: x!=0, eps)\n",
    "    \n",
    "    assert(np.size(epsnozero) != 0)\n",
    "    \n",
    "    mini = np.min(epsnozero)\n",
    "    minilog = int(round(np.log10(mini)-0.49))\n",
    "    epsnozero.append(10**(minilog))\n",
    "    ToleranceListcomplete = []\n",
    "    for i in range(0,int(np.size(epsnozero))):\n",
    "        ToleranceListcomplete.append(epsnozero[i])\n",
    "\n",
    "    ToleranceListcomplete.sort()\n",
    "    ToleranceListcomplete = np.unique(ToleranceListcomplete)\n",
    "\n",
    "    # with tolerance\n",
    "    errorplotinfo = []\n",
    "    tolerancesafe = []\n",
    "    errorBest = []\n",
    "    errorWorst = []\n",
    "    recomputefractionsafe = []\n",
    "    recomputefraction = 0\n",
    "    Correctors = 0\n",
    "    leng = np.size(ToleranceListcomplete)\n",
    "    for k in range(leng-1,-1,-1):\n",
    "        tol = ToleranceListcomplete[k]\n",
    "        print \" --- \"+ str(-k+leng) + \"/\" + str(leng)+ \" --- Tolerance: \" + str(round(tol,5)) + \" in \"+ String +\" ---- \", \n",
    "        vistol = pglod.updateCorrectors(Anew, tol, f, clearFineQuantities=False, Testing=True)\n",
    "        \n",
    "        Correctors += np.sum(vistol)\n",
    "        \n",
    "        recomputefraction += float(np.sum(vistol))/PotentialCorrectors * 100\n",
    "        recomputefractionsafe.append(recomputefraction)\n",
    "        \n",
    "        KFull = pglod.assembleMsStiffnessMatrix()\n",
    "        MFull = fem.assemblePatchMatrix(NWorldCoarse, world.MLocCoarse)\n",
    "        free  = util.interiorpIndexMap(NWorldCoarse)                                 \n",
    "\n",
    "        bFull = MFull*f\n",
    "        KFree = KFull[free][:,free]\n",
    "        bFree = bFull[free]\n",
    "\n",
    "        xFree = sparse.linalg.spsolve(KFree, bFree)\n",
    "        basis = fem.assembleProlongationMatrix(NWorldCoarse, NCoarseElement)\n",
    "\n",
    "        basisCorrectors = pglod.assembleBasisCorrectors()\n",
    "\n",
    "        modifiedBasis = basis - basisCorrectors\n",
    "\n",
    "        xFull = np.zeros(NpCoarse)\n",
    "        xFull[free] = xFree\n",
    "        uCoarse = xFull\n",
    "        uLodFine = modifiedBasis*xFull\n",
    "        \n",
    "        #energy error\n",
    "        errortol = np.sqrt(np.dot(uFineFem - uLodFine, AFine*(uFineFem - uLodFine)))\n",
    "        \n",
    "        errorplotinfo.append(errortol)\n",
    "        tolerancesafe.append(tol)\n",
    "    \n",
    "    # 100% updating\n",
    "    uLodFinebest = uLodFine\n",
    "    errorbest = np.sqrt(np.dot(uFineFem - uLodFinebest, AFine*(uFineFem - uLodFinebest)))\n",
    "    \n",
    "    for k in range(leng-1,-1,-1):\n",
    "        errorBest.append(errorbest)\n",
    "        errorWorst.append(errorworst)\n",
    "\n",
    "    return vis, eps, PotentialCorrectors, recomputefractionsafe, errorplotinfo, errorWorst, errorBest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "We use the same setting as we have already used before containing the 'buildcoef2d' class in order to construct the coefficient. We visualize the coefficient and store the information in an extern folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bg = 0.05       #background\n",
    "val = 1         #values\n",
    "\n",
    "#fine World\n",
    "NWorldFine = np.array([256, 256])\n",
    "NpFine = np.prod(NWorldFine+1)                                                                               \n",
    "\n",
    "#coarse World\n",
    "NWorldCoarse = np.array([16,16])\n",
    "NpCoarse = np.prod(NWorldCoarse+1)\n",
    "\n",
    "#ratio between Fine and Coarse\n",
    "NCoarseElement = NWorldFine/NWorldCoarse\n",
    "\n",
    "boundaryConditions = np.array([[0, 0],\n",
    "                               [0, 0]])\n",
    "\n",
    "world = World(NWorldCoarse, NCoarseElement, boundaryConditions)\n",
    "\n",
    "#righthandside\n",
    "f = np.ones(NpCoarse)\n",
    "\n",
    "#Coefficient 1\n",
    "CoefClass = buildcoef2d.Coefficient2d(NWorldFine,\n",
    "                        bg                  = bg,\n",
    "                        val                 = val,\n",
    "                        length              = 2,\n",
    "                        thick               = 2,\n",
    "                        space               = 2,\n",
    "                        probfactor          = 1,\n",
    "                        right               = 1,\n",
    "                        down                = 0,\n",
    "                        diagr1              = 0,\n",
    "                        diagr2              = 0,\n",
    "                        diagl1              = 0,\n",
    "                        diagl2              = 0,\n",
    "                        LenSwitch           = None,\n",
    "                        thickSwitch         = None,\n",
    "                        equidistant         = True,\n",
    "                        ChannelHorizontal   = None,\n",
    "                        ChannelVertical     = None,\n",
    "                        BoundarySpace       = True)\n",
    "\n",
    "A = CoefClass.BuildCoefficient()\n",
    "ABase = A.flatten()\n",
    "\n",
    "ROOT = '../test_data/Coef1/'\n",
    "\n",
    "#safe NworldFine\n",
    "with open(\"%s/NWorldFine.txt\" % ROOT, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for val in NWorldFine:\n",
    "        writer.writerow([val])\n",
    "\n",
    "#safe NworldCoarse\n",
    "with open(\"%s/NWorldCoarse.txt\" % ROOT, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for val in NWorldCoarse:\n",
    "        writer.writerow([val])\n",
    "\n",
    "#ABase\n",
    "with open(\"%s/OriginalCoeff.txt\" % ROOT, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for val in ABase:\n",
    "        writer.writerow([val])\n",
    "\n",
    "#fine-fem\n",
    "f_fine = np.ones(NpFine)\n",
    "uFineFem, AFine, MFine = femsolver.solveFine(world, ABase, f_fine, None, boundaryConditions)\n",
    "\n",
    "#fine solution\n",
    "with open(\"%s/finescale.txt\" % ROOT, 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for val in uFineFem:\n",
    "        writer.writerow([val])\n",
    "        \n",
    "plt.figure(\"Original\")\n",
    "drawCoefficient(NWorldFine, ABase,greys=True)\n",
    "plt.title(\"Original coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbations of the same entries\n",
    "\n",
    "To keep comparability, we use the 'specific' perturbation function and use a random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "random.seed(20)\n",
    "\n",
    "# decision\n",
    "valc = np.shape(CoefClass.ShapeRemember)[0]\n",
    "numbers = []\n",
    "decision = np.zeros(100)\n",
    "decision[0] = 1\n",
    "\n",
    "\n",
    "for i in range(0,valc):\n",
    "    a = random.sample(decision,1)[0]\n",
    "    if a == 1:\n",
    "        numbers.append(i)\n",
    "\n",
    "value1 = 3\n",
    "C1 = CoefClass.SpecificValueChange(ratio=value1,\n",
    "                                    Number = numbers,\n",
    "                                    probfactor=1,\n",
    "                                    randomvalue=None,\n",
    "                                    negative=None,\n",
    "                                    ShapeRestriction=True,\n",
    "                                    ShapeWave=None,\n",
    "                                    ChangeRight=1,\n",
    "                                    ChangeDown=1,\n",
    "                                    ChangeDiagr1=1,\n",
    "                                    ChangeDiagr2=1,\n",
    "                                    ChangeDiagl1=1,\n",
    "                                    ChangeDiagl2=1,\n",
    "                                    Original = True,\n",
    "                                    NewShapeChange = True)\n",
    "\n",
    "V = CoefClass.SpecificVanish(Number = numbers,\n",
    "                                probfactor=1,\n",
    "                                PartlyVanish=None,\n",
    "                                ChangeRight=1,\n",
    "                                ChangeDown=1,\n",
    "                                ChangeDiagr1=1,\n",
    "                                ChangeDiagr2=1,\n",
    "                                ChangeDiagl1=1,\n",
    "                                ChangeDiagl2=1,\n",
    "                                Original = True)\n",
    "\n",
    "M1 = CoefClass.SpecificMove(probfactor=1,\n",
    "                            Number = numbers,\n",
    "                            steps=1,\n",
    "                            randomstep=None,\n",
    "                            randomDirection=None,\n",
    "                            ChangeRight=1,\n",
    "                            ChangeDown=1,\n",
    "                            ChangeDiagr1=1,\n",
    "                            ChangeDiagr2=1,\n",
    "                            ChangeDiagl1=1,\n",
    "                            ChangeDiagl2=1,\n",
    "                            Right=1,\n",
    "                            BottomRight=0,\n",
    "                            Bottom=0,\n",
    "                            BottomLeft=0,\n",
    "                            Left=0,\n",
    "                            TopLeft=0,\n",
    "                            Top=0,\n",
    "                            TopRight=0,\n",
    "                            Original = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precomputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "NWorldFine = world.NWorldFine\n",
    "NWorldCoarse = world.NWorldCoarse\n",
    "NCoarseElement = world.NCoarseElement\n",
    "\n",
    "boundaryConditions = world.boundaryConditions\n",
    "NpFine = np.prod(NWorldFine+1)\n",
    "NpCoarse = np.prod(NWorldCoarse+1)\n",
    "\n",
    "#interpolant\n",
    "IPatchGenerator = lambda i, N: interp.L2ProjectionPatchMatrix(i, N, NWorldCoarse, NCoarseElement, boundaryConditions)\n",
    "\n",
    "#old Coefficient\n",
    "ABase = A.flatten()\n",
    "Aold = coef.coefficientFine(NWorldCoarse, NCoarseElement, ABase)\n",
    "\n",
    "pglod = pg_rand.VcPetrovGalerkinLOD(Aold, world, k, IPatchGenerator, 0)\n",
    "pglod.originCorrectors(clearFineQuantities=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the result function for each perturbation and store the result subsequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Specific value change3 ---------------\n",
      "Not Recomputed!\n",
      " --- 1/257 --- Tolerance: 0.45442 in Specific value change3 ----  To be recomputed:  0.0 %\n",
      " --- 2/257 --- Tolerance: 0.44603 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 3/257 --- Tolerance: 0.43992 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 4/257 --- Tolerance: 0.43274 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 5/257 --- Tolerance: 0.42811 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 6/257 --- Tolerance: 0.4281 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 7/257 --- Tolerance: 0.42809 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 8/257 --- Tolerance: 0.42776 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 9/257 --- Tolerance: 0.41789 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 10/257 --- Tolerance: 0.41786 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 11/257 --- Tolerance: 0.41785 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 12/257 --- Tolerance: 0.41785 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 13/257 --- Tolerance: 0.37991 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 14/257 --- Tolerance: 0.3799 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 15/257 --- Tolerance: 0.37989 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 16/257 --- Tolerance: 0.37989 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 17/257 --- Tolerance: 0.3792 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 18/257 --- Tolerance: 0.37917 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 19/257 --- Tolerance: 0.37827 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 20/257 --- Tolerance: 0.37649 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 21/257 --- Tolerance: 0.37646 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 22/257 --- Tolerance: 0.37199 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 23/257 --- Tolerance: 0.37199 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 24/257 --- Tolerance: 0.37196 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 25/257 --- Tolerance: 0.36837 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 26/257 --- Tolerance: 0.36834 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 27/257 --- Tolerance: 0.36834 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 28/257 --- Tolerance: 0.31227 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 29/257 --- Tolerance: 0.31212 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 30/257 --- Tolerance: 0.31072 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 31/257 --- Tolerance: 0.30757 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 32/257 --- Tolerance: 0.30734 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 33/257 --- Tolerance: 0.30734 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 34/257 --- Tolerance: 0.30729 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 35/257 --- Tolerance: 0.30375 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 36/257 --- Tolerance: 0.30369 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 37/257 --- Tolerance: 0.30368 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 38/257 --- Tolerance: 0.30367 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 39/257 --- Tolerance: 0.30367 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 40/257 --- Tolerance: 0.03318 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 41/257 --- Tolerance: 0.03305 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 42/257 --- Tolerance: 0.03091 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 43/257 --- Tolerance: 0.03068 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 44/257 --- Tolerance: 0.03044 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 45/257 --- Tolerance: 0.03026 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 46/257 --- Tolerance: 0.03015 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 47/257 --- Tolerance: 0.03014 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 48/257 --- Tolerance: 0.02874 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 49/257 --- Tolerance: 0.02376 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 50/257 --- Tolerance: 0.02309 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 51/257 --- Tolerance: 0.02298 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 52/257 --- Tolerance: 0.02281 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 53/257 --- Tolerance: 0.02215 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 54/257 --- Tolerance: 0.02178 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 55/257 --- Tolerance: 0.01897 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 56/257 --- Tolerance: 0.01872 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 57/257 --- Tolerance: 0.01783 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 58/257 --- Tolerance: 0.01746 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 59/257 --- Tolerance: 0.01738 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 60/257 --- Tolerance: 0.01736 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 61/257 --- Tolerance: 0.01734 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 62/257 --- Tolerance: 0.01734 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 63/257 --- Tolerance: 0.01701 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 64/257 --- Tolerance: 0.01571 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 65/257 --- Tolerance: 0.01564 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 66/257 --- Tolerance: 0.01474 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 67/257 --- Tolerance: 0.01441 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 68/257 --- Tolerance: 0.0144 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 69/257 --- Tolerance: 0.01416 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 70/257 --- Tolerance: 0.01415 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 71/257 --- Tolerance: 0.01412 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 72/257 --- Tolerance: 0.01403 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 73/257 --- Tolerance: 0.01403 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 74/257 --- Tolerance: 0.01115 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 75/257 --- Tolerance: 0.01113 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 76/257 --- Tolerance: 0.01063 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 77/257 --- Tolerance: 0.01037 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 78/257 --- Tolerance: 0.01031 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 79/257 --- Tolerance: 0.01031 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 80/257 --- Tolerance: 0.01024 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 81/257 --- Tolerance: 0.00996 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 82/257 --- Tolerance: 0.0097 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 83/257 --- Tolerance: 0.00965 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 84/257 --- Tolerance: 0.00958 in Specific value change3 ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 85/257 --- Tolerance: 0.00954 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 86/257 --- Tolerance: 0.00941 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 87/257 --- Tolerance: 0.00925 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 88/257 --- Tolerance: 0.00923 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 89/257 --- Tolerance: 0.00906 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 90/257 --- Tolerance: 0.00905 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 91/257 --- Tolerance: 0.00902 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 92/257 --- Tolerance: 0.00896 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 93/257 --- Tolerance: 0.00822 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 94/257 --- Tolerance: 0.00816 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 95/257 --- Tolerance: 0.00807 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 96/257 --- Tolerance: 0.00804 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 97/257 --- Tolerance: 0.00777 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 98/257 --- Tolerance: 0.00746 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 99/257 --- Tolerance: 0.00745 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 100/257 --- Tolerance: 0.00729 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 101/257 --- Tolerance: 0.00728 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 102/257 --- Tolerance: 0.00727 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 103/257 --- Tolerance: 0.00725 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 104/257 --- Tolerance: 0.00714 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 105/257 --- Tolerance: 0.00714 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 106/257 --- Tolerance: 0.00714 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 107/257 --- Tolerance: 0.00709 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 108/257 --- Tolerance: 0.00703 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 109/257 --- Tolerance: 0.00698 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 110/257 --- Tolerance: 0.00698 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 111/257 --- Tolerance: 0.00696 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 112/257 --- Tolerance: 0.00695 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 113/257 --- Tolerance: 0.00692 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 114/257 --- Tolerance: 0.00689 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 115/257 --- Tolerance: 0.00687 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 116/257 --- Tolerance: 0.00687 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 117/257 --- Tolerance: 0.00684 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 118/257 --- Tolerance: 0.00683 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 119/257 --- Tolerance: 0.00682 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 120/257 --- Tolerance: 0.00679 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 121/257 --- Tolerance: 0.00674 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 122/257 --- Tolerance: 0.00674 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 123/257 --- Tolerance: 0.00668 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 124/257 --- Tolerance: 0.00651 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 125/257 --- Tolerance: 0.00644 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 126/257 --- Tolerance: 0.00637 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 127/257 --- Tolerance: 0.00636 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 128/257 --- Tolerance: 0.00634 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 129/257 --- Tolerance: 0.00633 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 130/257 --- Tolerance: 0.00632 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 132/257 --- Tolerance: 0.00631 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 133/257 --- Tolerance: 0.00616 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 134/257 --- Tolerance: 0.00592 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 135/257 --- Tolerance: 0.00571 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 136/257 --- Tolerance: 0.00571 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 137/257 --- Tolerance: 0.00569 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 138/257 --- Tolerance: 0.00569 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 139/257 --- Tolerance: 0.00567 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 140/257 --- Tolerance: 0.00563 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 141/257 --- Tolerance: 0.00562 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 142/257 --- Tolerance: 0.0055 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 143/257 --- Tolerance: 0.00544 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 144/257 --- Tolerance: 0.00544 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 145/257 --- Tolerance: 0.00542 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 146/257 --- Tolerance: 0.00542 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 147/257 --- Tolerance: 0.00537 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 148/257 --- Tolerance: 0.00537 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 149/257 --- Tolerance: 0.00533 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 150/257 --- Tolerance: 0.00531 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 151/257 --- Tolerance: 0.00521 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 152/257 --- Tolerance: 0.0052 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 153/257 --- Tolerance: 0.0052 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 154/257 --- Tolerance: 0.00519 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 155/257 --- Tolerance: 0.00515 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 156/257 --- Tolerance: 0.0051 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 157/257 --- Tolerance: 0.00503 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 158/257 --- Tolerance: 0.00501 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 159/257 --- Tolerance: 0.00496 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 160/257 --- Tolerance: 0.00496 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 161/257 --- Tolerance: 0.00493 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 162/257 --- Tolerance: 0.00486 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 163/257 --- Tolerance: 0.00481 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 164/257 --- Tolerance: 0.00451 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 165/257 --- Tolerance: 0.00441 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 166/257 --- Tolerance: 0.00432 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 167/257 --- Tolerance: 0.00416 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 168/257 --- Tolerance: 0.00372 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 169/257 --- Tolerance: 0.00351 in Specific value change3 ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 170/257 --- Tolerance: 0.00351 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 171/257 --- Tolerance: 0.00346 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 172/257 --- Tolerance: 0.00327 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 173/257 --- Tolerance: 0.00318 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 174/257 --- Tolerance: 0.0029 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 175/257 --- Tolerance: 0.00267 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 176/257 --- Tolerance: 0.0026 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 177/257 --- Tolerance: 0.00224 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 178/257 --- Tolerance: 0.00198 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 179/257 --- Tolerance: 0.00194 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 180/257 --- Tolerance: 0.00188 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 181/257 --- Tolerance: 0.00186 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 182/257 --- Tolerance: 0.00185 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 183/257 --- Tolerance: 0.00171 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 184/257 --- Tolerance: 0.00166 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 185/257 --- Tolerance: 0.00165 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 186/257 --- Tolerance: 0.00147 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 187/257 --- Tolerance: 0.00129 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 188/257 --- Tolerance: 0.00124 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 189/257 --- Tolerance: 0.0012 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 190/257 --- Tolerance: 0.00119 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 191/257 --- Tolerance: 0.00108 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 192/257 --- Tolerance: 0.00108 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 193/257 --- Tolerance: 0.00106 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 194/257 --- Tolerance: 0.00096 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 195/257 --- Tolerance: 0.00095 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 196/257 --- Tolerance: 0.00094 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 197/257 --- Tolerance: 0.0009 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 198/257 --- Tolerance: 0.00089 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 199/257 --- Tolerance: 0.00089 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 200/257 --- Tolerance: 0.00063 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 201/257 --- Tolerance: 0.00062 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 202/257 --- Tolerance: 0.00059 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 203/257 --- Tolerance: 0.0005 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 204/257 --- Tolerance: 0.0005 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 205/257 --- Tolerance: 0.00042 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 206/257 --- Tolerance: 0.00038 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 207/257 --- Tolerance: 0.00037 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 208/257 --- Tolerance: 0.00031 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 209/257 --- Tolerance: 0.00029 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 210/257 --- Tolerance: 0.00029 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 211/257 --- Tolerance: 0.00029 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 212/257 --- Tolerance: 0.00028 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 213/257 --- Tolerance: 0.00028 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 214/257 --- Tolerance: 0.00028 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 215/257 --- Tolerance: 0.00023 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 216/257 --- Tolerance: 0.00023 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 217/257 --- Tolerance: 0.00023 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 218/257 --- Tolerance: 0.00023 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 219/257 --- Tolerance: 0.00023 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 220/257 --- Tolerance: 0.00021 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 221/257 --- Tolerance: 0.0002 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 222/257 --- Tolerance: 0.00019 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 223/257 --- Tolerance: 0.00018 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 224/257 --- Tolerance: 0.00017 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 225/257 --- Tolerance: 0.00016 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 226/257 --- Tolerance: 0.00015 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 227/257 --- Tolerance: 0.00014 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 228/257 --- Tolerance: 0.00014 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 229/257 --- Tolerance: 0.00014 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 230/257 --- Tolerance: 0.00014 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 231/257 --- Tolerance: 0.00013 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 232/257 --- Tolerance: 0.00012 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 233/257 --- Tolerance: 0.00012 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 234/257 --- Tolerance: 0.00011 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 235/257 --- Tolerance: 0.00011 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 236/257 --- Tolerance: 0.0001 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 237/257 --- Tolerance: 9e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 238/257 --- Tolerance: 8e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 239/257 --- Tolerance: 7e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 240/257 --- Tolerance: 6e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 241/257 --- Tolerance: 5e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 242/257 --- Tolerance: 5e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 243/257 --- Tolerance: 4e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 244/257 --- Tolerance: 4e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 245/257 --- Tolerance: 4e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 246/257 --- Tolerance: 3e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 247/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 248/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 249/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 250/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 251/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 252/257 --- Tolerance: 2e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 253/257 --- Tolerance: 1e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 254/257 --- Tolerance: 1e-05 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 255/257 --- Tolerance: 0.0 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 256/257 --- Tolerance: 0.0 in Specific value change3 ----  To be recomputed:  0.390625 %\n",
      " --- 257/257 --- Tolerance: 0.0 in Specific value change3 ----  To be recomputed:  0.390625 %\n"
     ]
    }
   ],
   "source": [
    "vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest = result(pglod ,world, A, C1, f, k, 'Specific value change' + str(value1))\n",
    "\n",
    "safeChange(ROOT, C1, vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disappearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Vanish ---------------\n",
      "Not Recomputed!\n",
      " --- 1/257 --- Tolerance: 1.74144 in Vanish ----  To be recomputed:  0.0 %\n",
      " --- 2/257 --- Tolerance: 1.68025 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 3/257 --- Tolerance: 1.65778 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 4/257 --- Tolerance: 1.60702 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 5/257 --- Tolerance: 1.57571 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 6/257 --- Tolerance: 1.57566 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 7/257 --- Tolerance: 1.57564 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 8/257 --- Tolerance: 1.57416 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 9/257 --- Tolerance: 1.52505 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 10/257 --- Tolerance: 1.52491 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 11/257 --- Tolerance: 1.5249 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 12/257 --- Tolerance: 1.5249 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 13/257 --- Tolerance: 1.31377 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 14/257 --- Tolerance: 1.31375 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 15/257 --- Tolerance: 1.31369 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 16/257 --- Tolerance: 1.31369 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 17/257 --- Tolerance: 1.31078 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 18/257 --- Tolerance: 1.30639 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 19/257 --- Tolerance: 1.29781 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 20/257 --- Tolerance: 1.29769 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 21/257 --- Tolerance: 1.29256 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 22/257 --- Tolerance: 1.27479 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 23/257 --- Tolerance: 1.27479 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 24/257 --- Tolerance: 1.27469 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 25/257 --- Tolerance: 1.25844 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 26/257 --- Tolerance: 1.25835 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 27/257 --- Tolerance: 1.25834 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 28/257 --- Tolerance: 0.99781 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 29/257 --- Tolerance: 0.99755 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 30/257 --- Tolerance: 0.99662 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 31/257 --- Tolerance: 0.98319 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 32/257 --- Tolerance: 0.98249 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 33/257 --- Tolerance: 0.98247 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 34/257 --- Tolerance: 0.98233 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 35/257 --- Tolerance: 0.96793 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 36/257 --- Tolerance: 0.96773 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 37/257 --- Tolerance: 0.96771 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 38/257 --- Tolerance: 0.96767 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 39/257 --- Tolerance: 0.96767 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 40/257 --- Tolerance: 0.09398 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 41/257 --- Tolerance: 0.0936 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 42/257 --- Tolerance: 0.08756 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 43/257 --- Tolerance: 0.0869 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 44/257 --- Tolerance: 0.08621 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 45/257 --- Tolerance: 0.08571 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 46/257 --- Tolerance: 0.08539 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 47/257 --- Tolerance: 0.08536 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 48/257 --- Tolerance: 0.08139 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 49/257 --- Tolerance: 0.06731 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 50/257 --- Tolerance: 0.0654 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 51/257 --- Tolerance: 0.06508 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 52/257 --- Tolerance: 0.06461 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 53/257 --- Tolerance: 0.06274 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 54/257 --- Tolerance: 0.0617 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 55/257 --- Tolerance: 0.05373 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 56/257 --- Tolerance: 0.05301 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 57/257 --- Tolerance: 0.05051 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 58/257 --- Tolerance: 0.04944 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 59/257 --- Tolerance: 0.04922 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 60/257 --- Tolerance: 0.04916 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 61/257 --- Tolerance: 0.04911 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 62/257 --- Tolerance: 0.04911 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 63/257 --- Tolerance: 0.04818 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 64/257 --- Tolerance: 0.0445 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 65/257 --- Tolerance: 0.0443 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 66/257 --- Tolerance: 0.04176 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 67/257 --- Tolerance: 0.0408 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 68/257 --- Tolerance: 0.0408 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 69/257 --- Tolerance: 0.04012 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 70/257 --- Tolerance: 0.04008 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 71/257 --- Tolerance: 0.03998 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 72/257 --- Tolerance: 0.03974 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 73/257 --- Tolerance: 0.03974 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 74/257 --- Tolerance: 0.03159 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 75/257 --- Tolerance: 0.03152 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 76/257 --- Tolerance: 0.03009 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 77/257 --- Tolerance: 0.02937 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 78/257 --- Tolerance: 0.02921 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 79/257 --- Tolerance: 0.0292 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 80/257 --- Tolerance: 0.029 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 81/257 --- Tolerance: 0.0282 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 82/257 --- Tolerance: 0.02747 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 83/257 --- Tolerance: 0.02734 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 84/257 --- Tolerance: 0.02713 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 85/257 --- Tolerance: 0.02703 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 86/257 --- Tolerance: 0.02665 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 87/257 --- Tolerance: 0.0262 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 88/257 --- Tolerance: 0.02615 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 89/257 --- Tolerance: 0.02565 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 90/257 --- Tolerance: 0.02563 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 91/257 --- Tolerance: 0.02555 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 92/257 --- Tolerance: 0.02539 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 93/257 --- Tolerance: 0.02328 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 94/257 --- Tolerance: 0.0231 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 95/257 --- Tolerance: 0.02286 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 96/257 --- Tolerance: 0.02277 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 97/257 --- Tolerance: 0.02199 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 98/257 --- Tolerance: 0.02114 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 99/257 --- Tolerance: 0.0211 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 100/257 --- Tolerance: 0.02064 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 101/257 --- Tolerance: 0.02061 in Vanish ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 102/257 --- Tolerance: 0.02059 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 103/257 --- Tolerance: 0.02054 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 104/257 --- Tolerance: 0.02023 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 105/257 --- Tolerance: 0.02022 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 106/257 --- Tolerance: 0.02021 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 107/257 --- Tolerance: 0.02008 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 108/257 --- Tolerance: 0.01991 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 109/257 --- Tolerance: 0.01976 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 110/257 --- Tolerance: 0.01976 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 111/257 --- Tolerance: 0.01971 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 112/257 --- Tolerance: 0.01968 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 113/257 --- Tolerance: 0.01959 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 114/257 --- Tolerance: 0.01953 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 115/257 --- Tolerance: 0.01947 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 116/257 --- Tolerance: 0.01945 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 117/257 --- Tolerance: 0.01938 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 118/257 --- Tolerance: 0.01935 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 119/257 --- Tolerance: 0.01932 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 120/257 --- Tolerance: 0.01922 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 121/257 --- Tolerance: 0.0191 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 122/257 --- Tolerance: 0.01908 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 123/257 --- Tolerance: 0.01893 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 124/257 --- Tolerance: 0.01843 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 125/257 --- Tolerance: 0.01825 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 126/257 --- Tolerance: 0.01804 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 127/257 --- Tolerance: 0.018 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 128/257 --- Tolerance: 0.01795 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 129/257 --- Tolerance: 0.01794 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 130/257 --- Tolerance: 0.0179 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 131/257 --- Tolerance: 0.01788 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 132/257 --- Tolerance: 0.01787 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 133/257 --- Tolerance: 0.01746 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 134/257 --- Tolerance: 0.01677 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 135/257 --- Tolerance: 0.01618 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 136/257 --- Tolerance: 0.01616 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 137/257 --- Tolerance: 0.01612 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 138/257 --- Tolerance: 0.01611 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 139/257 --- Tolerance: 0.01607 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 140/257 --- Tolerance: 0.01595 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 141/257 --- Tolerance: 0.01593 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 142/257 --- Tolerance: 0.01558 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 143/257 --- Tolerance: 0.01542 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 144/257 --- Tolerance: 0.01541 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 145/257 --- Tolerance: 0.01536 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 146/257 --- Tolerance: 0.01536 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 147/257 --- Tolerance: 0.01521 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 148/257 --- Tolerance: 0.01521 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 149/257 --- Tolerance: 0.01511 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 150/257 --- Tolerance: 0.01505 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 151/257 --- Tolerance: 0.01475 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 152/257 --- Tolerance: 0.01472 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 153/257 --- Tolerance: 0.01472 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 154/257 --- Tolerance: 0.01471 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 155/257 --- Tolerance: 0.01457 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 156/257 --- Tolerance: 0.01444 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 157/257 --- Tolerance: 0.01424 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 158/257 --- Tolerance: 0.01419 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 159/257 --- Tolerance: 0.01406 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 160/257 --- Tolerance: 0.01406 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 161/257 --- Tolerance: 0.01396 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 162/257 --- Tolerance: 0.01376 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 163/257 --- Tolerance: 0.01362 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 164/257 --- Tolerance: 0.01276 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 165/257 --- Tolerance: 0.0125 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 166/257 --- Tolerance: 0.01222 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 167/257 --- Tolerance: 0.01179 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 168/257 --- Tolerance: 0.01052 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 169/257 --- Tolerance: 0.00995 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 170/257 --- Tolerance: 0.00993 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 171/257 --- Tolerance: 0.0098 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 172/257 --- Tolerance: 0.00927 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 173/257 --- Tolerance: 0.00901 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 174/257 --- Tolerance: 0.00822 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 175/257 --- Tolerance: 0.00756 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 176/257 --- Tolerance: 0.00736 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 177/257 --- Tolerance: 0.00634 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 178/257 --- Tolerance: 0.0056 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 179/257 --- Tolerance: 0.00548 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 180/257 --- Tolerance: 0.00533 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 181/257 --- Tolerance: 0.00528 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 182/257 --- Tolerance: 0.00523 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 183/257 --- Tolerance: 0.00484 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 184/257 --- Tolerance: 0.00469 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 185/257 --- Tolerance: 0.00467 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 186/257 --- Tolerance: 0.00417 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 187/257 --- Tolerance: 0.00367 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 188/257 --- Tolerance: 0.00352 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 189/257 --- Tolerance: 0.00339 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 190/257 --- Tolerance: 0.00337 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 191/257 --- Tolerance: 0.00306 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 192/257 --- Tolerance: 0.00306 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 193/257 --- Tolerance: 0.00301 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 194/257 --- Tolerance: 0.00271 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 195/257 --- Tolerance: 0.00269 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 196/257 --- Tolerance: 0.00266 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 197/257 --- Tolerance: 0.00254 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 198/257 --- Tolerance: 0.00253 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 199/257 --- Tolerance: 0.00253 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 200/257 --- Tolerance: 0.00179 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 201/257 --- Tolerance: 0.00175 in Vanish ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 202/257 --- Tolerance: 0.00168 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 203/257 --- Tolerance: 0.00141 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 204/257 --- Tolerance: 0.00141 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 205/257 --- Tolerance: 0.0012 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 206/257 --- Tolerance: 0.00107 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 207/257 --- Tolerance: 0.00106 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 208/257 --- Tolerance: 0.00089 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 209/257 --- Tolerance: 0.00083 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 210/257 --- Tolerance: 0.00083 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 211/257 --- Tolerance: 0.00082 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 212/257 --- Tolerance: 0.00079 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 213/257 --- Tolerance: 0.00079 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 214/257 --- Tolerance: 0.00078 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 215/257 --- Tolerance: 0.00066 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 216/257 --- Tolerance: 0.00066 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 217/257 --- Tolerance: 0.00065 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 218/257 --- Tolerance: 0.00064 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 219/257 --- Tolerance: 0.00064 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 220/257 --- Tolerance: 0.00059 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 221/257 --- Tolerance: 0.00056 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 222/257 --- Tolerance: 0.00055 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 223/257 --- Tolerance: 0.00051 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 224/257 --- Tolerance: 0.00047 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 225/257 --- Tolerance: 0.00045 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 226/257 --- Tolerance: 0.00042 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 227/257 --- Tolerance: 0.0004 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 228/257 --- Tolerance: 0.00039 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 229/257 --- Tolerance: 0.00038 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 230/257 --- Tolerance: 0.00038 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 231/257 --- Tolerance: 0.00038 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 232/257 --- Tolerance: 0.00033 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 233/257 --- Tolerance: 0.00033 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 234/257 --- Tolerance: 0.00032 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 235/257 --- Tolerance: 0.00031 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 236/257 --- Tolerance: 0.0003 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 237/257 --- Tolerance: 0.00025 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 238/257 --- Tolerance: 0.00022 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 239/257 --- Tolerance: 0.0002 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 240/257 --- Tolerance: 0.00018 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 241/257 --- Tolerance: 0.00015 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 242/257 --- Tolerance: 0.00013 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 243/257 --- Tolerance: 0.00012 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 244/257 --- Tolerance: 0.00011 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 245/257 --- Tolerance: 0.00011 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 246/257 --- Tolerance: 9e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 247/257 --- Tolerance: 7e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 248/257 --- Tolerance: 6e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 249/257 --- Tolerance: 6e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 250/257 --- Tolerance: 5e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 251/257 --- Tolerance: 4e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 252/257 --- Tolerance: 4e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 253/257 --- Tolerance: 2e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 254/257 --- Tolerance: 1e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 255/257 --- Tolerance: 1e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 256/257 --- Tolerance: 1e-05 in Vanish ----  To be recomputed:  0.390625 %\n",
      " --- 257/257 --- Tolerance: 0.0 in Vanish ----  To be recomputed:  0.390625 %\n"
     ]
    }
   ],
   "source": [
    "vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest = result(pglod ,world, A, V, f, k, 'Vanish')\n",
    "\n",
    "safeVanish(ROOT, V, vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- One Step Move ---------------\n",
      "Not Recomputed!\n",
      " --- 1/257 --- Tolerance: 1.17346 in One Step Move ----  To be recomputed:  0.0 %\n",
      " --- 2/257 --- Tolerance: 1.1567 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 3/257 --- Tolerance: 1.14926 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 4/257 --- Tolerance: 1.13475 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 5/257 --- Tolerance: 1.1344 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 6/257 --- Tolerance: 1.10064 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 7/257 --- Tolerance: 1.10012 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 8/257 --- Tolerance: 1.10011 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 9/257 --- Tolerance: 1.1001 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 10/257 --- Tolerance: 1.0981 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 11/257 --- Tolerance: 1.06567 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 12/257 --- Tolerance: 1.06564 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 13/257 --- Tolerance: 0.97643 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 14/257 --- Tolerance: 0.9532 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 15/257 --- Tolerance: 0.95134 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 16/257 --- Tolerance: 0.95103 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 17/257 --- Tolerance: 0.94894 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 18/257 --- Tolerance: 0.94882 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 19/257 --- Tolerance: 0.94073 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 20/257 --- Tolerance: 0.93004 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 21/257 --- Tolerance: 0.91853 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 22/257 --- Tolerance: 0.91813 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 23/257 --- Tolerance: 0.91806 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 24/257 --- Tolerance: 0.90298 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 25/257 --- Tolerance: 0.88687 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 26/257 --- Tolerance: 0.88677 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 27/257 --- Tolerance: 0.87506 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 28/257 --- Tolerance: 0.7406 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 29/257 --- Tolerance: 0.72571 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 30/257 --- Tolerance: 0.7251 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 31/257 --- Tolerance: 0.72508 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 32/257 --- Tolerance: 0.7247 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 33/257 --- Tolerance: 0.72468 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 34/257 --- Tolerance: 0.71892 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 35/257 --- Tolerance: 0.70776 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 36/257 --- Tolerance: 0.70233 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 37/257 --- Tolerance: 0.70172 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 38/257 --- Tolerance: 0.6998 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 39/257 --- Tolerance: 0.69948 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 40/257 --- Tolerance: 0.36481 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 41/257 --- Tolerance: 0.30984 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 42/257 --- Tolerance: 0.30857 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 43/257 --- Tolerance: 0.30856 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 44/257 --- Tolerance: 0.30627 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 45/257 --- Tolerance: 0.25114 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 46/257 --- Tolerance: 0.24279 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 47/257 --- Tolerance: 0.12718 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 48/257 --- Tolerance: 0.1266 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 49/257 --- Tolerance: 0.08428 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 50/257 --- Tolerance: 0.08344 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 51/257 --- Tolerance: 0.08308 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 52/257 --- Tolerance: 0.07898 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 53/257 --- Tolerance: 0.07861 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 54/257 --- Tolerance: 0.07806 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 55/257 --- Tolerance: 0.07726 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 56/257 --- Tolerance: 0.07165 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 57/257 --- Tolerance: 0.06983 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 58/257 --- Tolerance: 0.0691 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 59/257 --- Tolerance: 0.06905 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 60/257 --- Tolerance: 0.06892 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 61/257 --- Tolerance: 0.06805 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 62/257 --- Tolerance: 0.06774 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 63/257 --- Tolerance: 0.06774 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 64/257 --- Tolerance: 0.06757 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 65/257 --- Tolerance: 0.06757 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 66/257 --- Tolerance: 0.06746 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 67/257 --- Tolerance: 0.06739 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 68/257 --- Tolerance: 0.06681 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 69/257 --- Tolerance: 0.06563 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 70/257 --- Tolerance: 0.06544 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 71/257 --- Tolerance: 0.06037 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 72/257 --- Tolerance: 0.06018 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 73/257 --- Tolerance: 0.06018 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 74/257 --- Tolerance: 0.05971 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 75/257 --- Tolerance: 0.05935 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 76/257 --- Tolerance: 0.05833 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 77/257 --- Tolerance: 0.0583 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 78/257 --- Tolerance: 0.0577 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 79/257 --- Tolerance: 0.05696 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 80/257 --- Tolerance: 0.05634 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 81/257 --- Tolerance: 0.05607 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 82/257 --- Tolerance: 0.05586 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 83/257 --- Tolerance: 0.05563 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 84/257 --- Tolerance: 0.05272 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 85/257 --- Tolerance: 0.05188 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 86/257 --- Tolerance: 0.05044 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 87/257 --- Tolerance: 0.04765 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 88/257 --- Tolerance: 0.0476 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 89/257 --- Tolerance: 0.04729 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 90/257 --- Tolerance: 0.04669 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 91/257 --- Tolerance: 0.04661 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 92/257 --- Tolerance: 0.04548 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 93/257 --- Tolerance: 0.04391 in One Step Move ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 94/257 --- Tolerance: 0.04383 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 95/257 --- Tolerance: 0.04352 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 96/257 --- Tolerance: 0.04157 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 97/257 --- Tolerance: 0.04114 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 98/257 --- Tolerance: 0.04039 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 99/257 --- Tolerance: 0.04035 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 100/257 --- Tolerance: 0.04021 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 101/257 --- Tolerance: 0.04011 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 102/257 --- Tolerance: 0.03976 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 103/257 --- Tolerance: 0.03894 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 104/257 --- Tolerance: 0.03884 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 105/257 --- Tolerance: 0.03861 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 106/257 --- Tolerance: 0.03826 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 107/257 --- Tolerance: 0.03784 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 108/257 --- Tolerance: 0.03777 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 109/257 --- Tolerance: 0.03759 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 110/257 --- Tolerance: 0.03736 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 111/257 --- Tolerance: 0.03695 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 112/257 --- Tolerance: 0.03665 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 113/257 --- Tolerance: 0.03655 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 114/257 --- Tolerance: 0.03583 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 115/257 --- Tolerance: 0.0356 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 116/257 --- Tolerance: 0.03529 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 117/257 --- Tolerance: 0.03436 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 118/257 --- Tolerance: 0.0341 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 119/257 --- Tolerance: 0.03305 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 120/257 --- Tolerance: 0.03092 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 121/257 --- Tolerance: 0.03066 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 122/257 --- Tolerance: 0.03049 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 123/257 --- Tolerance: 0.03037 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 124/257 --- Tolerance: 0.03032 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 125/257 --- Tolerance: 0.02952 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 126/257 --- Tolerance: 0.02948 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 127/257 --- Tolerance: 0.02868 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 128/257 --- Tolerance: 0.02864 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 129/257 --- Tolerance: 0.02775 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 130/257 --- Tolerance: 0.02767 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 131/257 --- Tolerance: 0.02737 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 132/257 --- Tolerance: 0.02735 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 133/257 --- Tolerance: 0.0273 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 134/257 --- Tolerance: 0.02668 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 135/257 --- Tolerance: 0.02631 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 136/257 --- Tolerance: 0.0259 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 137/257 --- Tolerance: 0.02352 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 138/257 --- Tolerance: 0.02342 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 139/257 --- Tolerance: 0.02299 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 140/257 --- Tolerance: 0.02282 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 141/257 --- Tolerance: 0.02262 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 142/257 --- Tolerance: 0.02204 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 143/257 --- Tolerance: 0.02194 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 144/257 --- Tolerance: 0.02162 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 145/257 --- Tolerance: 0.02136 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 146/257 --- Tolerance: 0.02084 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 147/257 --- Tolerance: 0.02061 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 148/257 --- Tolerance: 0.02015 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 149/257 --- Tolerance: 0.01962 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 150/257 --- Tolerance: 0.01959 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 151/257 --- Tolerance: 0.0193 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 152/257 --- Tolerance: 0.01913 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 153/257 --- Tolerance: 0.01867 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 154/257 --- Tolerance: 0.01861 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 155/257 --- Tolerance: 0.01822 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 156/257 --- Tolerance: 0.01776 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 157/257 --- Tolerance: 0.01748 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 158/257 --- Tolerance: 0.01711 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 159/257 --- Tolerance: 0.0168 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 160/257 --- Tolerance: 0.01676 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 161/257 --- Tolerance: 0.0167 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 162/257 --- Tolerance: 0.01668 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 163/257 --- Tolerance: 0.01664 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 164/257 --- Tolerance: 0.01647 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 165/257 --- Tolerance: 0.01619 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 166/257 --- Tolerance: 0.01566 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 167/257 --- Tolerance: 0.01495 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 168/257 --- Tolerance: 0.01428 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 169/257 --- Tolerance: 0.01408 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 170/257 --- Tolerance: 0.01404 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 171/257 --- Tolerance: 0.01386 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 172/257 --- Tolerance: 0.01227 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 173/257 --- Tolerance: 0.01138 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 174/257 --- Tolerance: 0.01122 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 175/257 --- Tolerance: 0.01047 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 176/257 --- Tolerance: 0.00992 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 177/257 --- Tolerance: 0.00982 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 178/257 --- Tolerance: 0.00909 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 179/257 --- Tolerance: 0.00891 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 180/257 --- Tolerance: 0.00755 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 181/257 --- Tolerance: 0.00611 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 182/257 --- Tolerance: 0.00604 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 183/257 --- Tolerance: 0.00603 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 184/257 --- Tolerance: 0.00599 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 185/257 --- Tolerance: 0.00591 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 186/257 --- Tolerance: 0.00585 in One Step Move ----  To be recomputed:  0.390625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- 187/257 --- Tolerance: 0.00551 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 188/257 --- Tolerance: 0.00518 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 189/257 --- Tolerance: 0.00514 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 190/257 --- Tolerance: 0.00505 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 191/257 --- Tolerance: 0.00472 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 192/257 --- Tolerance: 0.00461 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 193/257 --- Tolerance: 0.00427 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 194/257 --- Tolerance: 0.00427 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 195/257 --- Tolerance: 0.00417 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 196/257 --- Tolerance: 0.00385 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 197/257 --- Tolerance: 0.00335 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 198/257 --- Tolerance: 0.00333 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 199/257 --- Tolerance: 0.00322 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 200/257 --- Tolerance: 0.00317 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 201/257 --- Tolerance: 0.00303 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 202/257 --- Tolerance: 0.00261 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 203/257 --- Tolerance: 0.00257 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 204/257 --- Tolerance: 0.00221 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 205/257 --- Tolerance: 0.00215 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 206/257 --- Tolerance: 0.00198 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 207/257 --- Tolerance: 0.00188 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 208/257 --- Tolerance: 0.0017 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 209/257 --- Tolerance: 0.00143 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 210/257 --- Tolerance: 0.00135 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 211/257 --- Tolerance: 0.00133 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 212/257 --- Tolerance: 0.00129 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 213/257 --- Tolerance: 0.00127 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 214/257 --- Tolerance: 0.00119 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 215/257 --- Tolerance: 0.0011 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 216/257 --- Tolerance: 0.00102 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 217/257 --- Tolerance: 0.00092 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 218/257 --- Tolerance: 0.00088 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 219/257 --- Tolerance: 0.00086 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 220/257 --- Tolerance: 0.00086 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 221/257 --- Tolerance: 0.00081 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 222/257 --- Tolerance: 0.00071 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 223/257 --- Tolerance: 0.00071 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 224/257 --- Tolerance: 0.00066 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 225/257 --- Tolerance: 0.0006 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 226/257 --- Tolerance: 0.00059 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 227/257 --- Tolerance: 0.00059 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 228/257 --- Tolerance: 0.00058 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 229/257 --- Tolerance: 0.00058 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 230/257 --- Tolerance: 0.00056 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 231/257 --- Tolerance: 0.00055 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 232/257 --- Tolerance: 0.00048 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 233/257 --- Tolerance: 0.00042 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 234/257 --- Tolerance: 0.00042 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 235/257 --- Tolerance: 0.00039 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 236/257 --- Tolerance: 0.00039 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 237/257 --- Tolerance: 0.00037 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 238/257 --- Tolerance: 0.00034 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 239/257 --- Tolerance: 0.00033 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 240/257 --- Tolerance: 0.00028 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 241/257 --- Tolerance: 0.00027 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 242/257 --- Tolerance: 0.00022 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 243/257 --- Tolerance: 0.0002 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 244/257 --- Tolerance: 0.00015 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 245/257 --- Tolerance: 0.00014 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 246/257 --- Tolerance: 0.00013 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 247/257 --- Tolerance: 0.00012 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 248/257 --- Tolerance: 0.0001 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 249/257 --- Tolerance: 8e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 250/257 --- Tolerance: 6e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 251/257 --- Tolerance: 5e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 252/257 --- Tolerance: 4e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 253/257 --- Tolerance: 4e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 254/257 --- Tolerance: 2e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 255/257 --- Tolerance: 2e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 256/257 --- Tolerance: 2e-05 in One Step Move ----  To be recomputed:  0.390625 %\n",
      " --- 257/257 --- Tolerance: 1e-05 in One Step Move ----  To be recomputed:  0.390625 %\n"
     ]
    }
   ],
   "source": [
    "vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest = result(pglod ,world, A, M1, f, k, 'One Step Move')\n",
    "\n",
    "safeShift(ROOT, M1, vis, eps, PotentialUpdated, recomputefractionsafe, errorplotinfo, errorworst, errorbest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
