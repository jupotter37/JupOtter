{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Existing Constrainted Optimizers\n",
    "\n",
    "Let's examine the Barnes problem.  It's a simple 2D problem (so that we can visualize) with 3 nonlinear constraints. Additionally, we will provide analytic gradients.  We could easily compute the gradients with automatic differentiation, but they are simple enough to compute manually.\n",
    "\n",
    "We will optimize this problem using three different tools:\n",
    "- **Scipy minimize**: a wrapper to a couple different optimizers.  Convenient, but not very good solvers.  I never use these.\n",
    "- **Matlab's fmincon**: I recently created a wrapper that allows you to use Matlab's fmincon (if you also have Matlab).  fmincon has four different solvers.\n",
    "- **pyoptsparse**: This is a wrapper to a dozen different solvers.  One of these, SNOPT, is my most frequently used optimizer.  This one is more work to setup, but is more versatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def barnes(x):\n",
    "\n",
    "    a1 = 75.196\n",
    "    a3 = 0.12694\n",
    "    a5 = 1.0345e-5\n",
    "    a7 = 0.030234\n",
    "    a9 = 3.5256e-5\n",
    "    a11 = 0.25645\n",
    "    a13 = 1.3514e-5\n",
    "    a15 = -5.2375e-6\n",
    "    a17 = 7.0e-10\n",
    "    a19 = -1.6638e-6\n",
    "    a21 = 0.0005\n",
    "    a2 = -3.8112\n",
    "    a4 = -2.0567e-3\n",
    "    a6 = -6.8306\n",
    "    a8 = -1.28134e-3\n",
    "    a10 = -2.266e-7\n",
    "    a12 = -3.4604e-3\n",
    "    a14 = -28.106\n",
    "    a16 = -6.3e-8\n",
    "    a18 = 3.4054e-4\n",
    "    a20 = -2.8673\n",
    "\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    y1 = x1*x2\n",
    "    y2 = y1*x1\n",
    "    y3 = x2**2\n",
    "    y4 = x1**2\n",
    "\n",
    "    # --- function value ---\n",
    "    \n",
    "    f = a1 + a2*x1 + a3*y4 + a4*y4*x1 + a5*y4**2 + \\\n",
    "        a6*x2 + a7*y1 + a8*x1*y1 + a9*y1*y4 + a10*y2*y4 + \\\n",
    "        a11*y3 + a12*x2*y3 + a13*y3**2 + a14/(x2+1) + \\\n",
    "        a15*y3*y4 + a16*y1*y4*x2 + a17*y1*y3*y4 + a18*x1*y3 + \\\n",
    "        a19*y1*y3 + a20*exp(a21*y1)\n",
    "\n",
    "    # --- constraints ---\n",
    "\n",
    "    c = np.zeros(3)\n",
    "    c[0] = 1 - y1/700.0\n",
    "    c[1] = y4/25.0**2 - x2/5.0\n",
    "    c[2] = (x1/500.0- 0.11) - (x2/50.0-1)**2\n",
    "    \n",
    "    \n",
    "    # --- derivatives of f ---\n",
    "    \n",
    "    dy1 = x2\n",
    "    dy2 = y1 + x1*dy1\n",
    "    dy4 = 2*x1\n",
    "    dfdx1 = a2 + a3*dy4 + a4*y4 + a4*x1*dy4 + a5*2*y4*dy4 + \\\n",
    "        a7*dy1 + a8*y1 + a8*x1*dy1 + a9*y1*dy4 + a9*y4*dy1 + a10*y2*dy4 + a10*y4*dy2 + \\\n",
    "        a15*y3*dy4 + a16*x2*y1*dy4 + a16*x2*y4*dy1 + a17*y3*y1*dy4 + a17*y3*y4*dy1 + a18*y3 + \\\n",
    "        a19*y3*dy1 + a20*exp(a21*y1)*a21*dy1\n",
    "\n",
    "    dy1 = x1\n",
    "    dy2 = x1*dy1\n",
    "    dy3 = 2*x2\n",
    "    dfdx2 = a6 + a7*dy1 + a8*x1*dy1 + a9*y4*dy1 + a10*y4*dy2 + \\\n",
    "        a11*dy3 + a12*x2*dy3 + a12*y3 + a13*2*y3*dy3 + a14*-1/(x2+1)**2 + \\\n",
    "        a15*y4*dy3 + a16*y4*y1 + a16*y4*x2*dy1 + a17*y4*y1*dy3 + a17*y4*y3*dy1 + a18*x1*dy3 + \\\n",
    "        a19*y3*dy1 + a19*y1*dy3 + a20*exp(a21*y1)*a21*dy1\n",
    "\n",
    "    dfdx = np.array([dfdx1, dfdx2])\n",
    "    \n",
    "\n",
    "    # --- derivatives of c ---\n",
    "    \n",
    "    dcdx = np.zeros((3, 2))\n",
    "    dcdx[0, 0] = -x2/700.0\n",
    "    dcdx[0, 1] = -x1/700.0\n",
    "    dcdx[1, 0] = 2*x1/25**2\n",
    "    dcdx[1, 1] = -1.0/5\n",
    "    dcdx[2, 0] = 1.0/500\n",
    "    dcdx[2, 1] = -2*(x2/50.0-1)/50.0\n",
    "\n",
    "    return f, c, dfdx, dcdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a contour plot, show the constraints, and plot the optimal solution (denoted with a star).  The feasible region is the area above the star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEfCAYAAACOHkfVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZcj/AajrsRA+6cqpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1079e2a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "n = 200\n",
    "x1 = np.linspace(0, 65, n)\n",
    "x2 = np.linspace(0, 70, n)\n",
    "\n",
    "[X1, X2] = np.meshgrid(x1, x2, indexing='ij')\n",
    "F = np.zeros((n, n))\n",
    "C1 = np.zeros((n, n))\n",
    "C2 = np.zeros((n, n))\n",
    "C3 = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        f, c, _, _ = barnes([X1[i, j], X2[i, j]])\n",
    "        F[i, j] = f\n",
    "        C1[i, j] = c[0]\n",
    "        C2[i, j] = c[1]\n",
    "        C3[i, j] = c[2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.contourf(X1, X2, F, 100)\n",
    "plt.colorbar()\n",
    "plt.contour(X1, X2, C1, levels=[0], linewidths=2, colors='k')\n",
    "plt.contour(X1, X2, C2, levels=[0], linewidths=2, colors='k')\n",
    "plt.contour(X1, X2, C3, levels=[0], linewidths=2, colors='k')\n",
    "plt.plot(49.526, 19.622, 'r*', markersize=14.0)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy\n",
    "\n",
    "First, we will use the built-in optimizers available in Scipy.  To be honest, none of these are particularly good optimizers and so I don't use them, but they are already in Scipy so there are easy to use.  They should work fine for the purposes of our homework problems.  Like Matlab's optimizer, Scipy's wants you to provide objectives and constraints separately. Additionally, for some reason, it wants you to provide the constraint gradients separately.  We are going to use some shared global variables to accomplish that.  This isn't the most ideal approach, but it's the simplest without having to introduce object oriented programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NIT    FC           OBJFUN            GNORM\n",
      "    1     1    -4.643412E-02     9.293328E-02\n",
      "    2     2    -1.311850E+00     3.458173E-02\n",
      "    3     3    -1.046811E+00     1.946381E-02\n",
      "    4     4    -1.032584E+00     1.869941E-02\n",
      "    5     5    -1.032511E+00     1.869569E-02\n",
      "    7     6    -1.032511E+00     1.869569E-02\n",
      "    8     7    -1.032511E+00     1.869569E-02\n",
      "    9    18    -1.032511E+00     1.869569E-02\n",
      "   10    29    -1.032511E+00     1.869569E-02\n",
      "   12    40    -1.032511E+00     1.869569E-02\n",
      "   14    51    -1.032511E+00     1.869569E-02\n",
      "   16    62    -1.032511E+00     1.869569E-02\n",
      "   17    73    -1.032511E+00     1.869569E-02\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1.03251089717\n",
      "            Iterations: 17\n",
      "            Function evaluations: 73\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "[ 46.1256296   17.02058965]\n",
      "-1.03251089717\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# -------- starting point and bounds --------------\n",
    "x0 = [10, 10]\n",
    "ub = [65, 70]\n",
    "lb = [0, 0]\n",
    "# -------------------------------------------------\n",
    "\n",
    "# convert bounds to list of tuples in format scipy wants\n",
    "bounds = []\n",
    "for i in range(len(lb)):\n",
    "    bounds.append((lb[i], ub[i]))\n",
    "\n",
    "# ----- common variables ----------\n",
    "# these are variables we are going to save to be reused.\n",
    "xlast = [-1]\n",
    "csave = []\n",
    "dcsave = []\n",
    "# -------------------------\n",
    "\n",
    "def obj(x):\n",
    "\n",
    "    f, c, df, dc = barnes(x)\n",
    "\n",
    "    # save the x we evaluated at so we don't call barnes again in con at same x.\n",
    "    global xlast, csave, dcsave\n",
    "    xlast = x\n",
    "    csave = c\n",
    "    dcsave = dc\n",
    "\n",
    "    return f/30.0, df/30.0  # scaling so that objective is of order(1)\n",
    "\n",
    "\n",
    "def con(x):\n",
    "    global xlast, csave, dcsave\n",
    "    \n",
    "    if not np.all(xlast == x):  # check if we've already evaluated at this point, if not then reevaluate\n",
    "        f, csave, df, dcsave = barnes(x)\n",
    "        xlast = x\n",
    "\n",
    "    return csave\n",
    "\n",
    "\n",
    "def congrad(x):\n",
    "    global xlast, csave, dcsave\n",
    "    \n",
    "    if not np.all(xlast == x):  # check if we've already evaluated at this point, if not then reevaluate\n",
    "        f, csave, df, dcsave = barnes(x)\n",
    "        xlast = x\n",
    "        \n",
    "    return dcsave\n",
    "    \n",
    "\n",
    "# jac=True means we are providing gradients of f\n",
    "# tol is our convergence tolerances\n",
    "# constraint type 'ineq' means inequality.  \n",
    "# The jac for constraints is the function that returns the constraint gradients\n",
    "# other options display iterations, and the maximum number of iterations\n",
    "res = minimize(obj, x0, method='SLSQP', jac=True, bounds=bounds, tol=1e-7,\n",
    "    constraints={'type': 'ineq', 'fun': con, 'jac': congrad}, \n",
    "    options={'disp': True, 'iprint': 2, 'maxiter': 1000})\n",
    "print res.message  # print result information\n",
    "print res.x  # resulting x value\n",
    "print res.fun  # resulting function value\n",
    "# see documentation for other outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SLSQP does ok, but doesn't converge as well as it should.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fmincon\n",
    "\n",
    "Matlab's fmincon is a good optimizer.  I recently created a wrapper that allows us to call it from Python (if you also have Matlab and its optimization toolbox).  You first need to download the files opt.py and optimize.m from [here](https://github.com/BYUFLOWLab/pyfmincon).  You can then use fmincon just like in the Matlab example, but run entirely from Python, complete with callbacks to Python functions.\n",
    "\n",
    "First, I will create a short wrapper function so that I can perform scaling or any other transformations that I want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def barneswrap(x):\n",
    "\n",
    "    f, c, dfdx, dcdx = barnes(x)\n",
    "\n",
    "    return f/30.0, c, dfdx/30.0, np.transpose(dcdx)  # transpose b.c. of matlab definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- starting matlab engine ---\n",
      "--- calling fmincon ---\n"
     ]
    }
   ],
   "source": [
    "from opt import fmincon\n",
    "\n",
    "# --- name of function to optimize ----\n",
    "function = 'barnes.barneswrap'  # in this case I needed to put the barneswrap function in a file called barnes.py because I can't call back into this notebook.\n",
    "providegradients = True\n",
    "\n",
    "# -------- starting point and bounds --------------\n",
    "x0 = np.array([10.0, 10.0])\n",
    "ub = np.array([65.0, 70.0])\n",
    "lb = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "# ---- set options ----\n",
    "options = {'Algorithm': 'active-set', 'AlwaysHonorConstraints': 'bounds',\n",
    "    'display': 'iter-detailed', 'MaxIter': 1000, 'MaxFunEvals': 10000,\n",
    "    'TolCon': 1e-6, 'TolFun': 1e-6, 'Diagnostics': 'on'}\n",
    "\n",
    "# --- load fmincon and run ----\n",
    "xopt, fopt, exitflag, output = fmincon(x0, ub, lb, function, options,\n",
    "    providegradients=providegradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(rest of output to terminal pasted below):\n",
    "\n",
    "```\n",
    "____________________________________________________________\n",
    "   Diagnostic Information\n",
    "\n",
    "Number of variables: 2\n",
    "\n",
    "Functions \n",
    "Objective and gradient:               optimize/obj\n",
    "Hessian:                              finite-differencing (or Quasi-Newton)\n",
    "Nonlinear constraints and gradient:   optimize/con\n",
    "\n",
    "Constraints\n",
    "Number of nonlinear inequality constraints: 3\n",
    "Number of nonlinear equality constraints:   0\n",
    " \n",
    "Number of linear inequality constraints:    0\n",
    "Number of linear equality constraints:      0\n",
    "Number of lower bound constraints:          2\n",
    "Number of upper bound constraints:          2\n",
    "\n",
    "Algorithm selected\n",
    "   active-set\n",
    "\n",
    "\n",
    "____________________________________________________________\n",
    "   End diagnostic information\n",
    "\n",
    "                                Max     Line search  Directional  First-order \n",
    " Iter F-count        f(x)   constraint   steplength   derivative   optimality Procedure \n",
    "    0      1   -0.0464341       0.8571                                         Infeasible start point\n",
    "    1      3    -0.593993      -0.1654            1       -0.084      3.3e+03   \n",
    "    2      5    -0.607653      -0.1727            1      -0.0185       0.0535  Hessian modified twice  \n",
    "    3      7    -0.839436      -0.1437            1      -0.0187       0.0321  Hessian modified  \n",
    "    4      9     -0.85503    -0.004513            1     -0.00814       0.0115   \n",
    "    5     11     -0.85577   -4.479e-06            1     -0.00938       0.0141   \n",
    "    6     13    -0.870254    0.0006384            1      -0.0148        0.011  Hessian modified  \n",
    "    7     15     -1.03914       0.2137            1      -0.0118       0.0127  Hessian modified  \n",
    "    8     17     -1.02281     0.001222            1       0.0171       0.0152  Hessian modified  \n",
    "    9     19      -1.0386     0.002213            1      -0.0126      0.00855  Hessian modified  \n",
    "   10     21     -1.05581      0.01156            1      -0.0089      0.00156   \n",
    "   11     23     -1.05457    5.584e-05            1      0.00404     0.000214   \n",
    "   12     25     -1.05456    1.269e-06            1     0.000101     6.98e-06  Hessian modified  \n",
    "   13     27     -1.05456    1.087e-09            1     0.000144     2.11e-09  Hessian modified  \n",
    "\n",
    "Optimization completed: The first-order optimality measure, 2.107406e-09, is less\n",
    "than options.TolFun = 1.000000e-06, and the maximum constraint violation, 1.086800e-09,\n",
    "is less than options.TolCon = 1.000000e-06.\n",
    "\n",
    "Optimization Metric                                                 Options\n",
    "first-order optimality =   2.11e-09                        TolFun =   1e-06 (selected)\n",
    "max(constraint violation) =   1.09e-09                     TolCon =   1e-06 (selected)\n",
    "\n",
    "Active inequalities (to within options.TolCon = 1e-06):\n",
    "  lower      upper     ineqlin   ineqnonlin\n",
    "                                     2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.5262866794,19.6228245726]\n",
      "-1.05456034736\n"
     ]
    }
   ],
   "source": [
    "print xopt\n",
    "print fopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finds a better solution, than does scipy.  It actually converges to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyoptsparse\n",
    "\n",
    "The optimization framework I generally use is [pyoptsparse](https://bitbucket.org/mdolab/pyoptsparse) (which is a successor to pyopt).  This is an interface to a dozen or so different optimizers.  Among those the one I use most frequently is SNOPT.  This is a commercial code, but if you are a student in our department come talk to me and I can get you a copy through our department license.  SNOPT is an advanced optimizer with many options.\n",
    "\n",
    "pyoptsparse is not documented super well at this time.  There is some documentation available, but you need to build it through sphinx.  Most of what you'd find is shown in the below example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyoptsparse\n",
    "\n",
    "def func(xdict):  # return both f and c\n",
    "\n",
    "    x = xdict['x']  # uses a dictionary with whatever keys you define below\n",
    "    f, c, df, dc = barnes(x)\n",
    "    \n",
    "    # you must reutrn your outputs in a dictionary format as well\n",
    "    # again keys are customizable but must match below\n",
    "    outputs = {}\n",
    "    outputs['obj'] = f / 30.0  # scaling \n",
    "    outputs['con'] = c\n",
    "    \n",
    "    # these gradients aren't directly used in this function but we will save them for later\n",
    "    outputs['g-obj'] = df / 30.0\n",
    "    outputs['g-con'] = dc\n",
    "    outputs['g-x'] = x\n",
    "    \n",
    "    fail = False  # can use a flag to denote a failure, optimizer will try to recover and progress\n",
    "    \n",
    "    return outputs, fail\n",
    "\n",
    "\n",
    "def grad(xdict, fdict):\n",
    "    \n",
    "    # check if this was the x-location we just evaluated from func\n",
    "    if not np.array_equal(xdict['x'], fdict['g-x']):\n",
    "        f, c, df, dc = barnes(x)\n",
    "    else:\n",
    "        df = fdict['g-obj']\n",
    "        dc = fdict['g-con']\n",
    "    \n",
    "    # this dictionary format allows you to supply partial derivatives separately.\n",
    "    gout = {}\n",
    "    gout['obj'] = {}\n",
    "    gout['obj']['x'] = df\n",
    "    gout['con'] = {}\n",
    "    gout['con']['x'] = dc\n",
    "\n",
    "    fail = False\n",
    "\n",
    "    return gout, fail\n",
    "\n",
    "\n",
    "# -------- starting point and bounds --------------\n",
    "x0 = [10, 10]\n",
    "ub = [65, 70]\n",
    "lb = [0, 0]\n",
    "# -------------------------------------------------\n",
    "\n",
    "# define the problem.  Use same keys as above.\n",
    "optProb = pyoptsparse.Optimization('barnes', func)\n",
    "optProb.addObj('obj')\n",
    "optProb.addVarGroup('x', len(x0), type='c', lower=lb, upper=ub, value=x0)\n",
    "optProb.addConGroup('con', 3, lower=-float(\"inf\"), upper=0.0)  # notice we can use a 2-sided constraint\n",
    "\n",
    "# choose the solver, in this case SNOPT\n",
    "opt = pyoptsparse.SNOPT()\n",
    "# set options.  There are about 100 different options.  See SNOPT manual for full list\n",
    "opt.setOption('Major feasibility tolerance', 1e-6)\n",
    "opt.setOption('Major optimality tolerance', 1e-6)\n",
    "opt.setOption('iPrint', 6)  # normally you would not want to do this, but this notebook can't write files.  In general, you'll get two output files with detailed information.\n",
    "opt.setOption('iSumm', 6)\n",
    "sol = opt(optProb, sens=grad)  # define where we are getting gradients from.  Other options include FD and CS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(rest of terminal output pasted below)\n",
    "\n",
    "```\n",
    "  ==============================\n",
    "         S N O P T  7.2-12.3 (Aug 2014)\n",
    "         ==============================\n",
    "\n",
    " ==============================\n",
    " S N O P T  7.2-12.3 (Aug 2014)\n",
    " ==============================\n",
    "      Major feasibility tolerance  1.00000000E-06\n",
    "      Major optimality tolerance  1.00000000E-06\n",
    "      Derivative level               3\n",
    "1\n",
    " \n",
    " \n",
    " SNMEMB EXIT 100 -- finished successfully\n",
    " SNMEMB EXIT 100 -- finished successfully\n",
    " SNMEMB INFO 104 -- memory requirements estimated\n",
    " SNMEMB INFO 104 -- memory requirements estimated\n",
    "\n",
    "         ==============================\n",
    "         S N O P T  7.2-12.3 (Aug 2014)\n",
    "         ==============================\n",
    "\n",
    " ==============================\n",
    " S N O P T  7.2-12.3 (Aug 2014)\n",
    " ==============================\n",
    "      Major feasibility tolerance  1.00000000E-06\n",
    "      Major optimality tolerance  1.00000000E-06\n",
    "      Derivative level               3\n",
    "1\n",
    " \n",
    " \n",
    " Parameters\n",
    " ==========\n",
    "\n",
    " Files\n",
    " -----\n",
    " Solution file..........         0       Old basis file ........         0       Standard input.........         5\n",
    " Insert file............         0       New basis file ........         0       (Printer)..............         6\n",
    " Punch file.............         0       Backup basis file......         0       (Specs file)...........         0\n",
    " Load file..............         0       Dump file..............         0       Standard output........         6\n",
    "\n",
    " Frequencies\n",
    " -----------\n",
    " Print frequency........       100       Check frequency........        60       Save new basis map.....       100\n",
    " Summary frequency......       100       Factorization frequency        50       Expand frequency.......     10000\n",
    "\n",
    " QP subproblems\n",
    " --------------\n",
    " QPsolver Cholesky......\n",
    " Scale tolerance........     0.900       Minor feasibility tol..  1.00E-06       Iteration limit........     10000\n",
    " Scale option...........         0       Minor optimality  tol..  5.00E-07       Minor print level......         1\n",
    " Crash tolerance........     0.100       Pivot tolerance........  3.25E-11       Partial price..........         1\n",
    " Crash option...........         3       Elastic weight.........  1.00E+04       Prtl price section ( A)         2\n",
    "                                         New superbasics........        99       Prtl price section (-I)         3\n",
    "\n",
    " The SQP Method\n",
    " --------------\n",
    " Minimize...............                 Cold start.............                 Proximal Point method..         1\n",
    " Nonlinear objectiv vars         2       Major optimality tol...  1.00E-06       Function precision.....  3.00E-13\n",
    " Unbounded step size....  1.00E+20       Superbasics limit......         2       Difference interval....  5.48E-07\n",
    " Unbounded objective....  1.00E+15       Reduced Hessian dim....         2       Central difference int.  6.70E-05\n",
    " Major step limit.......  2.00E+00       Derivative linesearch..                 Derivative level.......         3\n",
    " Major iterations limit.      1000       Linesearch tolerance...   0.90000       Verify level...........         0\n",
    " Minor iterations limit.       500       Penalty parameter......  0.00E+00       Major Print Level......         1\n",
    "\n",
    " Hessian Approximation\n",
    " ---------------------\n",
    " Full-Memory Hessian....                 Hessian updates........  99999999       Hessian frequency......  99999999\n",
    "                                                                                 Hessian flush..........  99999999\n",
    "\n",
    " Nonlinear constraints\n",
    " ---------------------\n",
    " Nonlinear constraints..         3       Major feasibility tol..  1.00E-06       Violation limit........  1.00E+06\n",
    " Nonlinear Jacobian vars         2\n",
    "\n",
    " Miscellaneous\n",
    " -------------\n",
    " LU factor tolerance....      3.99       LU singularity tol.....  3.25E-11       Timing level...........         3\n",
    " LU update tolerance....      3.99       LU swap tolerance......  1.22E-04       Debug level............         0\n",
    " LU partial  pivoting...                 eps (machine precision)  2.22E-16       System information.....        No\n",
    "                                                                                 Sticky parameters......        No\n",
    "1\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "\n",
    " Matrix statistics\n",
    " -----------------\n",
    "               Total      Normal        Free       Fixed     Bounded\n",
    " Rows              3           3           0           0           0\n",
    " Columns           2           0           0           0           2\n",
    "\n",
    " No. of matrix elements                    6     Density     100.000\n",
    " Biggest  constant element        0.0000E+00  (excluding fixed columns,\n",
    " Smallest constant element        0.0000E+00   free rows, and RHS)\n",
    "\n",
    " No. of objective coefficients             0\n",
    "\n",
    " Nonlinear constraints       3     Linear constraints       0\n",
    "\n",
    " Nonlinear constraints       3     Linear constraints       0\n",
    " Nonlinear variables         2     Linear variables         0\n",
    " Nonlinear variables         2     Linear variables         0\n",
    " Jacobian  variables         2     Objective variables      2\n",
    " Jacobian  variables         2     Objective variables      2\n",
    " Total constraints           3     Total variables          2\n",
    " Total constraints           3     Total variables          2\n",
    "1\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    " The user has defined       6   out of       6   constraint gradients.\n",
    " The user has defined       6   out of       6   constraint gradients.\n",
    " The user has defined       2   out of       2   objective  gradients.\n",
    " The user has defined       2   out of       2   objective  gradients.\n",
    "\n",
    " Cheap test of user-supplied problem derivatives...\n",
    "\n",
    " The constraint gradients seem to be OK.\n",
    "\n",
    " -->  The largest discrepancy was    4.14E-09  in constraint     4\n",
    " \n",
    "\n",
    " The objective  gradients seem to be OK.\n",
    "\n",
    " Gradient projected in one direction   8.49257519325E-03\n",
    " Difference approximation              8.49259367756E-03\n",
    "1\n",
    " \n",
    " \n",
    " \n",
    "\n",
    "   Itns Major Minors    Step   nCon Feasible  Optimal  MeritFunction     L+U BSwap     nS  condHz Penalty\n",
    "      2     0      2              1  5.7E-02  1.7E-01 -4.6434117E-02       7                              _  r\n",
    "\n",
    " Major Minors     Step   nCon Feasible  Optimal  MeritFunction    nS Penalty\n",
    "     0      2               1  5.7E-02  1.7E-01 -4.6434117E-02                 r\n",
    "      2     1      0 2.4E-02      2  5.2E-02  1.6E-01  1.0807111E+02       7                      3.0E+02 _n rl\n",
    "     1      0  2.4E-02      2  5.2E-02  1.6E-01  1.0807111E+02       3.0E+02 n rl\n",
    "      2     2      0 2.6E-02      3  4.7E-02  1.5E-02  1.4673728E+02       7                      4.2E+02 _sm l\n",
    "     2      0  2.6E-02      3  4.7E-02  1.5E-02  1.4673728E+02       4.2E+02 sm l\n",
    "      3     3      1 9.6E-01      4 (0.0E+00) 1.4E-02 -2.6802284E+01       7            1 5.2E+04 2.1E+01 _ m l\n",
    "     3      1  9.6E-01      4 (0.0E+00) 1.4E-02 -2.6802284E+01     1 2.1E+01  m l\n",
    "      4     4      1 6.0E-05      7 (0.0E+00) 1.1E-01 -1.1353613E+01       7            1 6.6E+02 1.1E+02 _ M\n",
    "     4      1  6.0E-05      7 (0.0E+00) 1.1E-01 -1.1353613E+01     1 1.1E+02  M\n",
    "      5     5      1 2.1E-03     10 (0.0E+00) 1.5E-01 -6.5535385E+00       7            1 6.6E+02 2.9E+02 _ M\n",
    "     5      1  2.1E-03     10 (0.0E+00) 1.5E-01 -6.5535385E+00     1 2.9E+02  M\n",
    "      6     6      1 3.3E-01     13 (0.0E+00) 9.8E-02 -2.0542686E+00       7            1 3.5E+02 5.4E+02 _ M\n",
    "     6      1  3.3E-01     13 (0.0E+00) 9.8E-02 -2.0542686E+00     1 5.4E+02  M\n",
    "      7     7      1 2.8E-01     16 (0.0E+00) 6.8E-02 -1.1304024E+00       7            1 2.2E+02 8.2E+02 _ M\n",
    "     7      1  2.8E-01     16 (0.0E+00) 6.8E-02 -1.1304024E+00     1 8.2E+02  M\n",
    "      8     8      1 4.2E-02     20 (0.0E+00) 6.3E-02 -9.6396090E-01       7            1 2.1E+02 1.4E+03 _ M\n",
    "     8      1  4.2E-02     20 (0.0E+00) 6.3E-02 -9.6396090E-01     1 1.4E+03  M\n",
    "      9     9      1 1.2E-01     24 (0.0E+00) 5.4E-02 -8.5955984E-01       7            1 1.8E+02 2.1E+03 _ M\n",
    "     9      1  1.2E-01     24 (0.0E+00) 5.4E-02 -8.5955984E-01     1 2.1E+03  M\n",
    "     10    10      1 2.5E-01     28 (0.0E+00) 3.4E-02 -8.2681328E-01       7            1 1.3E+02 2.9E+03 _ M\n",
    "\n",
    " Major Minors     Step   nCon Feasible  Optimal  MeritFunction    nS Penalty\n",
    "    10      1  2.5E-01     28 (0.0E+00) 3.4E-02 -8.2681328E-01     1 2.9E+03  M\n",
    "     11    11      1 4.4E-01     31 (0.0E+00) 1.2E-02 -8.3337227E-01       7            1 7.4E+01 3.4E+03 _ M\n",
    "    11      1  4.4E-01     31 (0.0E+00) 1.2E-02 -8.3337227E-01     1 3.4E+03  M\n",
    "     13    12      2 1.0E+00     32 (6.0E-07) 3.3E-02 -8.7787542E-01       7     1      1 1.7E+00 8.6E+02 _\n",
    "    12      2  1.0E+00     32 (6.0E-07) 3.3E-02 -8.7787542E-01     1 8.6E+02\n",
    "     14    13      1 1.0E+00     34  7.4E-03  3.3E-03 -1.0729636E+00       7            1 2.6E+01 9.8E+01 _ m\n",
    "    13      1  1.0E+00     34  7.4E-03  3.3E-03 -1.0729636E+00     1 9.8E+01  m\n",
    "     15    14      1 1.0E+00     36  1.3E-04  2.9E-03 -1.0519477E+00       7            1 1.7E+00 3.3E+01 _ M\n",
    "    14      1  1.0E+00     36  1.3E-04  2.9E-03 -1.0519477E+00     1 3.3E+01  M\n",
    "     16    15      1 1.0E+00     37  3.9E-05  5.4E-05 -1.0545592E+00       7            1 1.8E+00 3.3E+01 _\n",
    "    15      1  1.0E+00     37  3.9E-05  5.4E-05 -1.0545592E+00     1 3.3E+01\n",
    "     17    16      1 1.0E+00     38 (2.2E-09) 1.8E-06 -1.0545603E+00       7            1 1.7E+00 3.3E+01 _\n",
    "    16      1  1.0E+00     38 (2.2E-09) 1.8E-06 -1.0545603E+00     1 3.3E+01\n",
    "     18    17      1 1.0E+00     39 (1.9E-11)(1.7E-07)-1.0545603E+00       7            1 1.9E+00 3.3E+01 _\n",
    "    17      1  1.0E+00     39 (1.9E-11)(1.7E-07)-1.0545603E+00     1 3.3E+01\n",
    "1\n",
    " \n",
    " \n",
    " SNOPTC EXIT   0 -- finished successfully\n",
    " SNOPTC EXIT   0 -- finished successfully\n",
    " SNOPTC INFO   1 -- optimality conditions satisfied\n",
    " SNOPTC INFO   1 -- optimality conditions satisfied\n",
    "\n",
    " Problem name                 barnes\n",
    "\n",
    " Problem name                 barnes\n",
    " No. of iterations                  18   Objective value     -1.0545603473E+00\n",
    " No. of iterations                  18   Objective value     -1.0545603473E+00\n",
    " No. of major iterations            17   Linear objective     0.0000000000E+00\n",
    " No. of major iterations            17   Linear objective     0.0000000000E+00\n",
    " Penalty parameter           3.330E+01   Nonlinear objective -1.0545603473E+00\n",
    " Penalty parameter           3.330E+01   Nonlinear objective -1.0545603473E+00\n",
    " No. of calls to funobj             40   No. of calls to funcon             40\n",
    " No. of calls to funobj             40   No. of calls to funcon             40\n",
    " No. of superbasics                  1   No. of basic nonlinears             2\n",
    " No. of superbasics                  1   No. of basic nonlinears             2\n",
    " No. of degenerate steps             0   Percentage                       0.00\n",
    " No. of degenerate steps             0   Percentage                       0.00\n",
    " Max x                       1 5.0E+01   Max pi                      2 1.2E-01\n",
    " Max x                       1 5.0E+01   Max pi                      2 1.2E-01\n",
    " Max Primal infeas           0 0.0E+00   Max Dual infeas             2 3.4E-07\n",
    " Max Primal infeas           0 0.0E+00   Max Dual infeas             2 3.4E-07\n",
    " Nonlinear constraint violn    9.4E-10\n",
    " Nonlinear constraint violn    9.4E-10\n",
    "1\n",
    " \n",
    " \n",
    " Name           barnes                   Objective Value     -1.0545603473E+00\n",
    "\n",
    " Status         Optimal Soln             Iteration     18    Superbasics     1\n",
    "\n",
    " Objective       (Min)\n",
    " RHS            ??@\t?\n",
    " Ranges         pN3\n",
    " Bounds         \n",
    "\n",
    " Section 1 - Rows\n",
    "\n",
    "  Number  ...Row.. State  ...Activity...  Slack Activity  ..Lower Limit.  ..Upper Limit.  .Dual Activity    ..i\n",
    " \n",
    "       3  r      1   SBS        -0.38835        -0.38835           None           .               .           1\n",
    "       4  r      2    UL         0.00000         0.00000           None           .             -0.12169      2\n",
    "       5  r      3    BS        -0.38006        -0.38006           None           .               .           3\n",
    "1\n",
    " \n",
    " \n",
    " Section 2 - Columns\n",
    "\n",
    "  Number  .Column. State  ...Activity...  .Obj Gradient.  ..Lower Limit.  ..Upper Limit.  Reduced Gradnt    m+j\n",
    " \n",
    "       1  x      1    BS        49.52622        -0.01929          .             65.00000         0.00000      4\n",
    "       2  x      2    BS        19.62277         0.02434          .             70.00000        -0.00000      5\n",
    "\n",
    " Solution printed on file   6\n",
    " \n",
    " \n",
    " Time for MPS input                             0.00 seconds\n",
    " Time for MPS input                             0.00 seconds\n",
    " Time for solving problem                       0.03 seconds\n",
    " Time for solving problem                       0.03 seconds\n",
    " Time for solution output                       0.00 seconds\n",
    " Time for solution output                       0.00 seconds\n",
    " Time for constraint functions                  0.03 seconds\n",
    " Time for constraint functions                  0.03 seconds\n",
    " Time for objective function                    0.00 seconds\n",
    " Time for objective function                    0.00 seconds\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name        Type                         Bound\n",
      "     \n",
      "\n",
      "barnes\n",
      "================================================================================\n",
      "\n",
      "        Objective Function: func\n",
      "\n",
      "    Solution: \n",
      "--------------------------------------------------------------------------------\n",
      "    Total Time:                    0.0305\n",
      "       User Objective Time :       0.0015\n",
      "       User Sensitivity Time :     0.0001\n",
      "       Interface Time :            0.0258\n",
      "       Opt Solver Time:            0.0031\n",
      "    Calls to Objective Function :      40\n",
      "    Calls to Sens Function :           39\n",
      "\n",
      "    Objectives:\n",
      "        Name        Value        Optimum\n",
      "\t    obj       -1.05456             0\n",
      "\n",
      "   Variables (c - continuous, i - integer, d - discrete):\n",
      "           Name      Type       Value       Lower Bound  Upper Bound\n",
      "\t    x_0       c\t     49.526219       0.00e+00     6.50e+01 \n",
      "\t    x_1       c\t     19.622771       0.00e+00     7.00e+01 \n",
      "\n",
      "   Constraints (i - inequality, e - equality):\n",
      "        Name    Type                    Bounds\n",
      "\t    con   \t  i            -inf <= -0.388345 <= 0.00e+00\n",
      "\t    con   \t  i            -inf <= 0.000000 <= 0.00e+00\n",
      "\t    con   \t  i            -inf <= -0.380058 <= 0.00e+00\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('x', array([ 49.52621914,  19.62277105]))])\n"
     ]
    }
   ],
   "source": [
    "print sol.xStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.05456034733\n"
     ]
    }
   ],
   "source": [
    "print sol.fStar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNOPT finds the same answer the fmincon does, and spits out a lot of information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
