{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import csv\n",
    "import calendar\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "DATA_FOLDER = 'Data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Functions needed to solve task 1\n",
    "'''\n",
    "\n",
    "#function to import excel file into a dataframe\n",
    "def importdata(path,date):\n",
    "    allpathFiles = glob.glob(DATA_FOLDER+path+'/*.csv')\n",
    "    list_data = []\n",
    "    for file in allpathFiles:\n",
    "        excel = pd.read_csv(file,parse_dates=[date])\n",
    "        list_data.append(excel)\n",
    "    return pd.concat(list_data)\n",
    "\n",
    "#function to add the month on a new column of a DataFrame\n",
    "def add_month(df):\n",
    "    copy_df = df.copy()\n",
    "    months = [calendar.month_name[x.month] for x in copy_df.Date]\n",
    "    copy_df['Month'] = months\n",
    "    return copy_df\n",
    "\n",
    "#founction which loc only the column within a country and a specified month\n",
    "#return a dataframe\n",
    "def chooseCountry_month(dataframe,country,descr,month):\n",
    "    df = dataframe.loc[(dataframe['Country']==country) & (dataframe['Description']==descr)]\n",
    "    #df = add_month(df)\n",
    "    df_month = df.loc[(df['Month']==month)]\n",
    "    return df_month\n",
    "\n",
    "# Create a dataframe with the number of death, the new cases and the daily infos for a country and a specified month \n",
    "def getmonthresults(dataframe,country,month):\n",
    "    if country =='Liberia':\n",
    "        descr_kill ='Total death/s in confirmed cases'\n",
    "        descr_cases ='Total confirmed cases'\n",
    "    if country =='Guinea':\n",
    "        descr_kill ='Total deaths of confirmed'\n",
    "        descr_cases ='Total cases of confirmed'\n",
    "    if country == 'Sierra Leone': \n",
    "        descr_kill ='death_confirmed'\n",
    "        descr_cases ='cum_confirmed'\n",
    "    \n",
    "    df_kill = chooseCountry_month(dataframe,country,descr_kill,month)\n",
    "    df_cases = chooseCountry_month(dataframe,country,descr_cases,month)\n",
    "    \n",
    "    #calculate the number of new cases and of new deaths for the all month\n",
    "    res_kill = int(df_kill.iloc[len(df_kill)-1].Totals)-int(df_kill.iloc[0].Totals)\n",
    "    res_cases = int(df_cases.iloc[len(df_cases)-1].Totals)-int(df_cases.iloc[0].Totals)\n",
    "    #calculate the number of days counted which is last day of register - first day of register\n",
    "    nb_day = df_kill.iloc[len(df_kill)-1].Date.day-df_kill.iloc[0].Date.day \n",
    "    \n",
    "\n",
    "    # Sometimes the values in the dataframe are wrong due to the excelfiles which are not all the same!\n",
    "    # We then get negative results. Therefor we replace them all by NaN ! \n",
    "    if(res_cases < 0)&(res_kill <0):\n",
    "        monthreport = pd.DataFrame({'New cases':[np.nan],'Deaths':[np.nan],'daily average of New cases':[np.nan],'daily average of Deaths':[np.nan],'month':[month],'Country':[country]})\n",
    "    elif(res_cases >= 0) &( res_kill <0):\n",
    "        monthreport = pd.DataFrame({'New cases':[res_cases],'Deaths':[np.nan],'daily average of New cases':[res_cases/nb_day],'daily average of Deaths':[np.nan],'month':[month],'Country':[country]})\n",
    "    elif(res_cases < 0) & (res_kill >= 0):\n",
    "        monthreport = pd.DataFrame({'New cases':[np.nan],'Deaths':[res_kill],'daily average of New cases':[np.nan],'daily average of Deaths':[res_kill/nb_day],'month':[month],'Country':[country]})\n",
    "    elif(nb_day == 0):\n",
    "        monthreport = pd.DataFrame({'New cases':'notEnoughdatas','Deaths':'notEnoughdatas','daily average of New cases':'notEnoughdatas','daily average of Deaths':'notEnoughdatas','month':[month],'Country':[country]})\n",
    "    else:    \n",
    "        monthreport = pd.DataFrame({'New cases':[res_cases],'Deaths':[res_kill],'daily average of New cases':[res_cases/nb_day],'daily average of Deaths':[res_kill/nb_day],'month':[month],'Country':[country]})\n",
    "    return monthreport\n",
    "\n",
    "#check if the  month and the country is in the dataframe df\n",
    "def checkData(df,month,country):\n",
    "    check = df.loc[(df['Country']==country)& (df['Month']== month)]\n",
    "    return check\n",
    "\n",
    "#return a dataframe with all the infos(daily new cases, daily death) for each month and each country\n",
    "def getResults(data):\n",
    "    Countries = ['Guinea','Liberia','Sierra Leone']\n",
    "    Months = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    results=[]\n",
    "    compteur =0\n",
    "    for country in Countries:\n",
    "        for month in Months:\n",
    "            if not(checkData(data,month,country).empty) : #check if the datas for the month and country exist \n",
    "                res = getmonthresults(data,country,month)\n",
    "                results.append(res)  \n",
    "    return pd.concat(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import data from guinea\n",
    "path_guinea = 'Ebola/guinea_data/'\n",
    "data_guinea = importdata(path_guinea,'Date')\n",
    "\n",
    "# set the new order / change the columns / keep only the relevant datas / add the name of the country\n",
    "data_guinea = data_guinea[['Date', 'Description','Totals']]\n",
    "data_guinea['Country'] = ['Guinea']*len(data_guinea)\n",
    "\n",
    "#search for New cases and death!!   \n",
    "#descr(newcases): \"Total cases of confirmed\"  // descr(deaths): \"Total deaths of confirmed\"\n",
    "data_guinea = data_guinea.loc[(data_guinea.Description=='Total cases of confirmed')|(data_guinea.Description=='Total deaths of confirmed')]\n",
    "\n",
    "   \n",
    "#import data from liberia\n",
    "path_liberia = 'Ebola/liberia_data/'\n",
    "data_liberia = importdata(path_liberia,'Date')\n",
    "# set the new order / change the columns / keep only the relevant datas / add the name of the country\n",
    "data_liberia = data_liberia[['Date', 'Variable','National']]\n",
    "data_liberia['Country'] = ['Liberia']*len(data_liberia)\n",
    "\n",
    "#search for New cases and death!!    \n",
    "#descr(newcases): \"Total confirmed cases\"  // descr(deaths): \"Total death/s in confirmed cases\"  \n",
    "data_liberia = data_liberia.loc[(data_liberia.Variable=='Total confirmed cases')|(data_liberia.Variable=='Total death/s in confirmed cases')]\n",
    "\n",
    "#change the name of the columns to be able merge the 3 data sets\n",
    "data_liberia = data_liberia.rename(columns={'Date': 'Date', 'Variable': 'Description','National':'Totals'})\n",
    "\n",
    "    \n",
    "#import data from sierra leonne\n",
    "path_sl = 'Ebola/sl_data/'\n",
    "data_sl = importdata(path_sl,'date')\n",
    "# set the new order / change the columns / keep only the relevant datas / add the name of the country\n",
    "data_sl = data_sl[['date', 'variable','National']]\n",
    "data_sl['Country'] = ['Sierra Leone']*len(data_sl)\n",
    "\n",
    "#search for new cases and death    \n",
    "#descr(newcases): \"cum_confirmed\"  // descr(deaths): \"death_confirmed\"\n",
    "data_sl = data_sl.loc[(data_sl.variable=='cum_confirmed')|(data_sl.variable=='death_confirmed')]\n",
    "#change the name of the columns to be able merge the 3 data sets\n",
    "data_sl = data_sl.rename(columns={'date': 'Date', 'variable': 'Description','National':'Totals'})\n",
    "\n",
    "\n",
    "#merge the 3 dataframe into ONE which we'll apply our analysis\n",
    "dataFrame = [data_guinea,data_liberia,data_sl]\n",
    "data = pd.concat(dataFrame)\n",
    "\n",
    "# Replace the NaN by 0;\n",
    "data = data.fillna(0)\n",
    "#add a column with the month\n",
    "data = add_month(data)\n",
    "\n",
    "#get the results from the data set -> see the function\n",
    "results = getResults(data)\n",
    "\n",
    "#print the resuults\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheet10_Meta = pd.read_excel(DATA_FOLDER +'microbiome/metadata.xls') \n",
    "allFiles = glob.glob(DATA_FOLDER + 'microbiome' + \"/MID*.xls\")\n",
    "allFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Creating and filling the DataFrame\n",
    "In order to iterate only once over the data folder, we will attach the metadata to each excel spreadsheet right after creating a DataFrame with it. This will allow the code to be shorter and clearer, but also to iterate only once on every line and therefore be more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty DataFrame to store our data and initializing a counter.\n",
    "Combined_data = pd.DataFrame()\n",
    "K = 0\n",
    "while (K < int(len(allFiles))):\n",
    "    \n",
    "    #Creating a DataFrame and filling it with the excel's data\n",
    "    df = pd.read_excel(allFiles[K], header=None)\n",
    "    \n",
    "    #Getting the metadata of the corresponding spreadsheet\n",
    "    df['BARCODE'] = Sheet10_Meta.at[int(K), 'BARCODE']\n",
    "    df['GROUP'] = Sheet10_Meta.at[int(K), 'GROUP']\n",
    "    df['SAMPLE'] = Sheet10_Meta.at[int(K),'SAMPLE']\n",
    "    \n",
    "    #Append the recently created DataFrame to our combined one\n",
    "    Combined_data = Combined_data.append(df)\n",
    "    \n",
    "    K = K + 1\n",
    "    \n",
    "#Renaming the columns with meaningfull names\n",
    "Combined_data.columns = ['Name', 'Value','BARCODE','GROUP','SAMPLE']\n",
    "Combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3. Cleaning and reindexing\n",
    "At first we get rid of the NaN value, we must replace them by \"unknown\". In order to have a more meaningful and single index, we will reset it to be the name of the RNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the NaN values with unknwown\n",
    "Combined_data = Combined_data.fillna('unknown')\n",
    "\n",
    "#Reseting the index\n",
    "Combined_data = Combined_data.set_index('Name')\n",
    "\n",
    "#Showing the result\n",
    "Combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "\n",
    "##### Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "\n",
    "Assumptions: \n",
    "    - \"For each exercise, please provide both a written explanation of the steps you will apply to manipulate the data, and the corresponding code.\" We assume that \"written explanation can come in the form of commented code as well as text\"\n",
    "    - We assume that we must not describe the value range of attributes that contain string as we dont feel the length of strings or ASCI-values don't give any insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Here is a sample of the information in the titanic dataframe\n",
    "''' \n",
    "\n",
    "# Importing titanic.xls info with Pandas\n",
    "titanic = pd.read_excel('Data/titanic.xls')\n",
    "\n",
    "# printing only the 30 first and last rows of information\n",
    "print(titanic.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To describe the INTENDED values and types of the data we will show you the titanic.html file that was provided to us\n",
    "Notice:\n",
    "    - 'age' is of type double, so someone can be 17.5 years old, mostly used with babies that are 0.x years old\n",
    "    - 'cabin' is stored as integer, but it har characters and letters\n",
    "    - By this model, embarked is stored as an integer, witch has to be interpreted as the 3 different embarkation ports\n",
    "    - It says that 'boat' is stored as a integer even though it has spaces and letters, it should be stored as string\n",
    "    \n",
    "PS: it might be that the information stored as integer is supposed to be categorical data,\n",
    "        ...because they have a \"small\" amount of valid options\n",
    "''' \n",
    "\n",
    "# Display html info in Jupyter Notebook\n",
    "from IPython.core.display import display, HTML\n",
    "htmlFile = 'Data/titanic.html'\n",
    "display(HTML(htmlFile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "The default types of the data after import:\n",
    "Notice:\n",
    "    - the strings and characters are imported as objects\n",
    "    - 'survived' is imported as int instead of double (which is in our opinion better since it's only 0 and 1\n",
    "    - 'sex' is imported as object not integer because it is a string\n",
    "'''\n",
    "\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Below you can see the value range of the different numerical values.\n",
    "\n",
    "name, sex, ticket, cabin, embarked, boat and home.dest is not included because they can't be quantified numerically.\n",
    "''' \n",
    "\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Additional information that is important to remember when manipulation the data\n",
    "is if/where there are NaN values in the dataset\n",
    "'''\n",
    "\n",
    "# This displays the number of NaN there is in different attributes\n",
    "print(pd.isnull(titanic).sum())\n",
    "\n",
    "'''\n",
    "Some of this data is missing while some is meant to describe 'No' or something of meaning.\n",
    "Example:\n",
    "    Cabin has 1014 NaN in its column, it might be that every passenger had a cabin and the data is missing.\n",
    "    Or it could mean that most passengers did not have a cabin or a mix. The displayed titanic.html file \n",
    "    give us some insight if it is correct. It says that there are 0 NaN in the column. This indicates that\n",
    "    there are 1014 people without a cabin. Boat has also 823 NaN's, while the titanic lists 0 NaN's. \n",
    "    It is probably because most of those who died probably weren't in a boat.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What attributes should be stored as categorical information?\n",
    "\n",
    "Categorical data is essentially 8-bit integers which means it can store up to 2^8 = 256 categories\n",
    "Benefit is that it makes memory usage lower and it has a performance increase in calculations.\n",
    "'''\n",
    "\n",
    "print('Number of unique values in... :')\n",
    "for attr in titanic:\n",
    "    print(\"   {attr}: {u}\".format(attr=attr, u=len(titanic[attr].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We think it will be smart to categorize: 'pclass', 'survived', 'sex', 'cabin', 'embarked' and 'boat'\n",
    "because they have under 256 categories and don't have a strong numerical value like 'age'\n",
    "'survived' is a bordercase because it might be more practical to work with integers in some settings\n",
    "'''\n",
    "\n",
    "# changing the attributes to categorical data\n",
    "titanic.pclass = titanic.pclass.astype('category')\n",
    "titanic.survived = titanic.survived.astype('category')\n",
    "titanic.sex = titanic.sex.astype('category')\n",
    "titanic.cabin = titanic.cabin.astype('category')\n",
    "titanic.embarked = titanic.embarked.astype('category')\n",
    "titanic.boat = titanic.boat.astype('category')\n",
    "\n",
    "#Illustrate the change by printing out the new types\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2\n",
    "###### \"Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \"\n",
    "\n",
    "assumptions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plotting the ratio different classes(1st, 2nd and 3rd class) the passengers have\n",
    "pc = titanic.pclass.value_counts().sort_index().plot(kind='bar')\n",
    "pc.set_title('Travel classes')\n",
    "pc.set_ylabel('Number of passengers')\n",
    "pc.set_xlabel('Travel class')\n",
    "pc.set_xticklabels(('1st class', '2nd class', '3rd class'))\n",
    "plt.show(pc)\n",
    "\n",
    "#Plotting the amount of people that embarked from different cities(C=Cherbourg, Q=Queenstown, S=Southampton)\n",
    "em = titanic.embarked.value_counts().sort_index().plot(kind='bar')\n",
    "em.set_title('Ports of embarkation')\n",
    "em.set_ylabel('Number of passengers')\n",
    "em.set_xlabel('Port of embarkation')\n",
    "em.set_xticklabels(('Cherbourg', 'Queenstown', 'Southampton'))\n",
    "plt.show(em)\n",
    "\n",
    "#Plotting what sex the passengers are\n",
    "sex = titanic.sex.value_counts().plot(kind='bar')\n",
    "sex.set_title('Gender of the passengers')\n",
    "sex.set_ylabel('Number of Passengers')\n",
    "sex.set_xlabel('Gender')\n",
    "sex.set_xticklabels(('Female', 'Male'))\n",
    "plt.show(sex)\n",
    "\n",
    "#Plotting agegroup of passengers\n",
    "bins = [0,10,20,30,40,50,60,70,80]\n",
    "age_grouped = pd.DataFrame(pd.cut(titanic.age, bins))\n",
    "ag = age_grouped.age.value_counts().sort_index().plot.bar()\n",
    "ag.set_title('Age of Passengers ')\n",
    "ag.set_ylabel('Number of passengers')\n",
    "ag.set_xlabel('Age groups')\n",
    "plt.show(ag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3\n",
    "###### Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "\n",
    "assumptions: \n",
    "- Because we are tasked with categorizing persons by the floor of their cabin it was problematic that you had cabin input: \"F E57\" and \"F G63\". There were only 7 of these instances with conflicting cabinfloors. We also presumed that the was a floor \"T\". Even though there was only one instance, so it might have been a typo.\n",
    "- We assume that you don't want to include people without cabinfloor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parsing the cabinfloor, into floors A, B, C, D, E, F, G, T and display in a pie chart\n",
    "\n",
    "'''\n",
    "#Dropping NaN (People without cabin)\n",
    "cabin_floors = titanic.cabin.dropna()\n",
    "\n",
    "# removes digits and spaces\n",
    "cabin_floors = cabin_floors.str.replace(r'[\\d ]+', '')\n",
    "# removes duplicate letters and leave unique (CC -> C) (FG -> G)\n",
    "cabin_floors = cabin_floors.str.replace(r'(.)(?=.*\\1)', '')\n",
    "# removes ambigous data from the dataset (FE -> NaN)(FG -> NaN)\n",
    "cabin_floors = cabin_floors.str.replace(r'([A-Z]{1})\\w+', 'NaN' )\n",
    "\n",
    "# Recategorizing (Since we altered the entries, we messed with the categories)\n",
    "cabin_floors = cabin_floors.astype('category')\n",
    "# Removing NaN (uin this case ambigous data)\n",
    "cabin_floors = cabin_floors.cat.remove_categories('NaN')\n",
    "cabin_floors = cabin_floors.dropna()\n",
    "\n",
    "# Preparing data for plt.pie\n",
    "numberOfCabinPlaces = cabin_floors.count()\n",
    "grouped = cabin_floors.groupby(cabin_floors).count()\n",
    "sizes = np.array(grouped)\n",
    "labels = np.array(grouped.index)\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', pctdistance=0.75, labeldistance=1.1)\n",
    "print(\"There are {cabin} passengers that have cabins and {nocabin} passengers without a cabin\"\n",
    "      .format(cabin=numberOfCabinPlaces, nocabin=(len(titanic) - numberOfCabinPlaces)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.4\n",
    "###### For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "\n",
    "assumptions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the number of people that survived and died given a specific travelclass\n",
    "def survivedPerClass(pclass):\n",
    "    survived = len(titanic.survived[titanic.survived == 1][titanic.pclass == pclass])\n",
    "    died = len(titanic.survived[titanic.survived == 0][titanic.pclass == pclass])\n",
    "    return [survived, died]\n",
    "\n",
    "# Fixing the layout horizontal\n",
    "the_grid = plt.GridSpec(1, 3)\n",
    "labels = [\"Survived\", \"Died\"]\n",
    "\n",
    "# Each iteration plots a pie chart\n",
    "for p in titanic.pclass.unique():\n",
    "    sizes = survivedPerClass(p)\n",
    "    plt.subplot(the_grid[0, p-1], aspect=1 )\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5\n",
    "##### \"Calculate the proportion of the passengers that survived by travel class and sex. Present your results in a single histogram.\"\n",
    "\n",
    "assumptions: \n",
    "    1. By \"proportions\" We assume it is a likelyhood-percentage of surviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by selected data and get a count for each category\n",
    "survivalrate = titanic.groupby(['pclass', 'sex', 'survived']).size()\n",
    "\n",
    "# calculate percentage\n",
    "survivalpercentage = survivalrate.groupby(level=['pclass', 'sex']).apply(lambda x: x / x.sum() * 100)\n",
    "\n",
    "# plotting in a histogram\n",
    "histogram = survivalpercentage.filter(like='1', axis=0).plot(kind='bar')\n",
    "histogram.set_title('Proportion of the passengers that survived by travel class and sex')\n",
    "histogram.set_ylabel('Percent likelyhood of surviving titanic')\n",
    "histogram.set_xlabel('class/gender group')\n",
    "plt.show(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.6\n",
    "##### \"Create 2 equally populated age categories and calculate survival proportions by age category, travel class and sex. Present your results in a DataFrame with unique index.\"\n",
    "\n",
    "assumptions: \n",
    "1. By \"proportions\" we assume it is a likelyhood-percentage of surviving\n",
    "2. To create 2 equally populated age categories; we will find the median and round up from the median to nearest whole year difference before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaN rows\n",
    "age_without_nan = titanic.age.dropna()\n",
    "\n",
    "#categorizing\n",
    "age_categories = pd.qcut(age_without_nan, 2, labels=[\"Younger\", \"Older\"])\n",
    "\n",
    "#Numbers to explain difference\n",
    "median = int(np.float64(age_without_nan.median()))\n",
    "amount = int(age_without_nan[median])\n",
    "print(\"The Median age is {median} years old\".format(median = median))\n",
    "print(\"and there are {amount} passengers that are {median} year old \\n\".format(amount=amount, median=median))\n",
    "\n",
    "print(age_categories.groupby(age_categories).count())\n",
    "print(\"\\nAs you can see the pd.qcut does not cut into entirely equal sized bins, because the age is of a discreet nature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported for the sake of surpressing some warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# extract relevant attributes\n",
    "csas = titanic[['pclass', 'sex', 'age', 'survived']]\n",
    "csas.dropna(subset=['age'], inplace=True)\n",
    "\n",
    "# Defining the categories\n",
    "csas['age_group'] = csas.age > csas.age.median()\n",
    "csas['age_group'] = csas['age_group'].map(lambda age_category: 'older' if age_category else \"younger\")\n",
    "\n",
    "# Converting to int to make it able to aggregate and give percentage\n",
    "csas.survived = csas.survived.astype(int)\n",
    "\n",
    "g_categories = csas.groupby(['pclass', 'age_group', 'sex'])\n",
    "result = pd.DataFrame(g_categories.survived.mean()).rename(columns={'survived': 'survived proportion'})\n",
    "\n",
    "# reset current index and spesify the unique index\n",
    "result.reset_index(inplace=True)\n",
    "unique_index = result.pclass.astype(str) + ': ' + result.age_group.astype(str) + ' ' + result.sex.astype(str)\n",
    "\n",
    "# Finalize the unique index dataframe\n",
    "result_w_unique = result[['survived proportion']]\n",
    "result_w_unique.set_index(unique_index, inplace=True)\n",
    "print(result_w_unique)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
