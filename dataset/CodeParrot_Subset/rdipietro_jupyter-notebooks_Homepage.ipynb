{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rob](images/rob.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"https://github.com/rdipietro\"><i class=\"fab fa-github\"></i> GitHub</a> &nbsp; &nbsp; <a href=\"https://twitter.com/rsdipietro\"><i class=\"fab fa-twitter\"></i> Twitter</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm Rob DiPietro, a PhD student in the [Department of Computer Science at Johns Hopkins](https://www.cs.jhu.edu/), where I'm advised by [Gregory D. Hager](http://www.cs.jhu.edu/~hager/). My research focuses on machine learning for complex time-series data, applied primarily to health care. For example, is it possible to learn meaningful representations of surgical motion without supervision? And can we use these representations to improve automated skill assessment and automated coaching during surgical training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Recent News](#recent-news)\n",
    "- [Recent Projects](#recent-projects)\n",
    "- [Open-Source Contributions](#open-source-contributions)\n",
    "- [Teaching](#teaching)\n",
    "- [Tutorials](#tutorials)\n",
    "- [Curriculum Vitae / Publications](#curriculum-vitae-publications)\n",
    "- [Some Fun](#some-fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"recent-news\"></a>\n",
    "## Recent News\n",
    "\n",
    "Our paper on surgical activity recognition has been accepted as an oral presentation at MICCAI 2016:\n",
    "\n",
    "R. DiPietro, C. Lea, A. Malpani, N. Ahmidi, S. Vedula, G.I. Lee, M.R. Lee, G.D. Hager: Recognizing Surgical Activities with Recurrent Neural Networks. Medical Image Computing and Computer Assisted Intervention (2016).\n",
    "\n",
    "http://arxiv.org/abs/1606.06329\n",
    "\n",
    "https://github.com/rdipietro/miccai-2016-surgical-activity-rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"recent-projects\"></a>\n",
    "## Recent Projects\n",
    "\n",
    "### Unsupervised Learning for Surgical Motion\n",
    "\n",
    "![Encoding Visualization](images/encoding-visualization.png)\n",
    "\n",
    "Here we learn meaningful representations of surgical motion, without supervision, by learning to predict the future. This is accomplished by combining an RNN encoder-decoder with mixture density networks to model the distribution over future motion given past motion.\n",
    "\n",
    "The visualization shows 2-D dimensionality reductions (using t-SNE) of our obtained encodings, colored according to high-level activity, which we emphasize were not used during training. The 3 primary activities are suture throw (green), knot tying (orange), and grasp pull run suture (red), while the final activity, intermaneuver segment (blue), encompasses everything that occurs in between the primary activities.\n",
    "\n",
    "(Under submission; link to paper and PyTorch code coming soon.)\n",
    "\n",
    "### RNNs for Extremely Long-Term Dependencies\n",
    "\n",
    "![Gradient Magnitudes](images/mnist-gradient-mags.png)\n",
    "\n",
    "Here we develop mixed history recurrent neural networks (MIST RNNs), which use an attention mechanism over exponentially-spaced delays to the past in order to capture extremely long-term dependencies.\n",
    "\n",
    "The visualization shows gradient norms as a function of delay, $\\tau$. These norms can be interpreted as how much learning signal is available for a loss at time $t$ from events at time $t - \\tau$ of the past.\n",
    "\n",
    "For more information, please see [our paper](https://openreview.net/forum?id=HkElQvkvz), which was accepted as a workshop paper at ICLR 2018. Code for an older version of our paper can also be found [here](https://github.com/rdipietro/mist-rnns); we hope to release an updated version soon (now in PyTorch).\n",
    "\n",
    "### RNNs for Surgical Activity Recognition\n",
    "\n",
    "![Maneuver Recognition](images/maneuver-rec.png)\n",
    "\n",
    "Here we apply long short-term memory to the task of surgical activity recognition from motion (e.g., x, y, z over time), and in doing so improve state-of-the-art performance in terms of both accuracy and edit distance.\n",
    "\n",
    "The visualization shows results for three test sequences: best performance (top), median performance (middle), and worst performance (bottom), as measured by accuracy. In all cases, we are recognizing 4 activities over time – suture throw (black), knot tying (blue), grasp pull run suture (green), and intermaneuver segment (yellow) – showing ground truth labels above and predictions below.\n",
    "\n",
    "For more information, please see [our paper](https://arxiv.org/abs/1606.06329), which was accepted as an oral presentation at MICCAI 2016. Code is also available [here](https://github.com/rdipietro/miccai-2016-surgical-activity-rec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open-source-contributions\"></a>\n",
    "## Open-Source Contributions\n",
    "\n",
    "Nowadays nearly all of my code is written using Python, NumPy, and PyTorch. I moved to PyTorch from TensorFlow in 2017, and my experience has resembled [Andrej Karpathy's](https://twitter.com/karpathy/status/868178954032513024) :).\n",
    "\n",
    "I've made small open-source contributions (code, tests, and/or docs) to [TensorFlow](https://github.com/tensorflow/tensorflow), [PyTorch](https://github.com/pytorch/pytorch), [Edward](https://github.com/blei-lab/edward), [Pyro](https://github.com/uber/pyro), and other projects.\n",
    "\n",
    "Some of my projects can be found here: <a href=\"https://github.com/rdipietro\"><i class=\"fab fa-github\"></i> GitHub</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"teaching\"></a>\n",
    "## Teaching\n",
    "\n",
    "I've fortunately had the chance to teach quite a bit at Hopkins. I love teaching, despite its tendency to devour time.\n",
    "\n",
    "### Johns Hopkins University\n",
    "\n",
    "- **Co-Instructor for EN.601.382, Machine Learning: Deep Learning Lab.** Spring, 2018.\n",
    "- **Co-Instructor for EN.601.482/682, Machine Learning: Deep Learning.** Spring, 2018.\n",
    "- **Teaching Assistant for EN.601.475/675, Introduction to Machine Learning.** Fall, 2017.\n",
    "- **Instructor for EN.500.111, HEART: Machine Learning for Surgical Workflow Analysis.** Fall, 2015.\n",
    "- **Teaching Assistant for EN.600.476/676, Machine Learning: Data to Models.** Spring, 2015.\n",
    "- **Co-Instructor for EN.600.120, Intermediate Programming.** Spring, 2014.\n",
    "- **Instructor for EN.600.101, MATLAB for Data Analytics.** Intersession, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tutorials\"></a>\n",
    "## Tutorials\n",
    "\n",
    "- [A Friendly Introduction to Cross-Entropy Loss](http://rdipietro.github.io/friendly-intro-to-cross-entropy-loss). Introduces entropy, cross entropy, KL divergence, and discusses connections to likelihood.\n",
    "- [TensorFlow Scan Examples](http://rdipietro.github.io/tensorflow-scan-examples). This is an old tutorial in which we build, train, and evaluate a simple recurrent neural network from scratch. I do not recommend this tutorial. Instead, I recommend switching to PyTorch if at all possible :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"curriculum-vitae-publications\"></a>\n",
    "## Curriculum Vitae / Publications\n",
    "\n",
    "My CV is [here](dipietro-cv.pdf) and my publications are [here](https://scholar.google.com/citations?user=hgSJHaUAAAAJ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"some-fun\"></a>\n",
    "## Some Fun\n",
    "\n",
    "#### Paragliding in Switzerland (2014)\n",
    "\n",
    "![Paragliding](images/paragliding.jpg)\n",
    "\n",
    "#### Skydiving in Switzerland (2010)\n",
    "\n",
    "![Skydiving](images/skydiving.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
