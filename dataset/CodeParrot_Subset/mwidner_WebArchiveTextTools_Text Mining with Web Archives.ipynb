{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÃ©cile Alduy and I have been working with a team of undergraduate RAs and with some members of the Stanford University Libraries staff to build a corpus of the public discourse of French presidential candidates in advance of the 2017 elections. In this notebook, I will describe the methods by which we have been converting web pages into corpora for analysis and will provide some sample Python code.\n",
    "\n",
    "Collaborating with Nicholas Taylor, SUL's Web Archiving Service Manager, and Sarah Sussman, the curator of French and Italian Collections, we have identified several key websites and begun periodic crawls using [ArchiveIt](https://archive-it.org/). One of the first challenges for any text-mining project that uses web archives as a source is, unsurprisingly, getting the correct text from each website. Although it's possible to simply extract *all* the text from a web page, there's a lot of extraneous information that we don't want to deal with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* general-purpose solution\n",
    "* WARC structure\n",
    "* warcat \n",
    "* BeautifulSoup\n",
    "* post-processing\n",
    "* corpus building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def extract_text(site_info, input_file, corpus_dir, word_count=0):\n",
    "      '''\n",
    "      Extract the actual text from the HTML\n",
    "      Write out file with text content\n",
    "      Return extracted metadata about text\n",
    "      '''\n",
    "      results = dict()\n",
    "      try:\n",
    "        soup = BeautifulSoup(open(input_file, encoding=\"utf-8\"), 'html.parser')\n",
    "      except UnicodeDecodeError as err:\n",
    "        # print(input_file + ' is not UTF8', err)\n",
    "        return\n",
    "\n",
    "      if soup is None:\n",
    "        return\n",
    "\n",
    "      # Skip page if there's a filter and it isn't matched\n",
    "      if len(site_info['filter']) and not len(soup.select(site_info['filter'])):\n",
    "        return\n",
    "\n",
    "      # Fields in CSV with BeautifulSoup select() options\n",
    "      for item in ['title','date','author','content']:\n",
    "        results[item] = ''\n",
    "        if (not len(site_info[item])):\n",
    "          continue\n",
    "        contents = soup.select(site_info[item])\n",
    "        if contents is not None and len(contents):\n",
    "          # Assume only the first result is relevant\n",
    "          # BS4 returns a list of results even if only 1 found\n",
    "          results[item] = clean_string(contents[0].getText())\n",
    "\n",
    "      results['word_count'] = len(results['content'].split())\n",
    "      results['filename'] = generate_unique_filename(corpus_dir, site_info['name'], results)\n",
    "      if os.path.isfile(results['filename']):\n",
    "        return\n",
    "\n",
    "      # Save the original URL\n",
    "      results['url'] = get_original_url(site_info, input_file)\n",
    "\n",
    "      if (len(results['title']) and results['word_count'] >= int(word_count)):\n",
    "        # Ensure the path exists\n",
    "        if not os.path.isdir(os.path.dirname(results['filename'])):\n",
    "          os.makedirs(os.path.dirname(results['filename']))\n",
    "        with open(results['filename'], 'w') as content:\n",
    "          content.write(str(results['content']))\n",
    "        return results\n",
    "      return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
