{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import tqdm\n",
    "import sys\n",
    "sys.path.append('/Users/ed/yelp-classification/machine_learning')\n",
    "import yelp_ml as yml\n",
    "#reload(yml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lh_neg = open('../input/negative-words.txt', 'r', encoding = \"ISO-8859-1\").read()\n",
    "lh_neg = lh_neg.split('\\n')\n",
    "lh_pos = open('../input/positive-words.txt', 'r', encoding = \"ISO-8859-1\").read()\n",
    "lh_pos = lh_pos.split('\\n')\n",
    "users = json.load(open('../input/many_reviews_dictionary.json'))\n",
    "\n",
    "word_list = list(set(lh_pos + lh_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix users JSON\n",
    "users_dict = {}\n",
    "user_ids = []\n",
    "\n",
    "users_dict = {}\n",
    "user_ids = []\n",
    "\n",
    "for list in users['reviews']:\n",
    "    users_dict[list[0]['user_id']]= list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for list_reviews in users['reviews']:\n",
    "    user_ids.append(list_reviews[0]['user_id'])\n",
    "    \n",
    "#We have 228 users, creat a new dictionary where the user_ids are the keys and the entries are a list of reviews\n",
    "\n",
    "    \n",
    "with open('cleaned_large_user_dictionary.json', 'w') as outfile:\n",
    "    json.dump(users_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running a few tests on a subset of users, the keys are our unique user IDs. We proceed as follows for each user ID:\n",
    "\n",
    "1.Create a user dataframe with the following columns:•(review_text, review rating, business_id)\n",
    "\n",
    "2.Create a list of unique business IDs for that user\n",
    "\n",
    "3.Connect to the MongoDB server and pull all of the reviews for the restaurants that the user has reviewed\n",
    "\n",
    "4.Create a restaurant dataframe with the following columns:•(review_text, biz rating, business_id)\n",
    "\n",
    "5.Do a 80/20 training/test split, randomizing over the set of user' reviewed restaurants\n",
    "\n",
    "6.Train the LSI model on the set of training reviews, get the number of topics used in fitting\n",
    "\n",
    "7.Set up the FeatureUnion with the desired features, then fit according to the train reviews and transform the train reviews \n",
    "\n",
    "8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####Test Machine Learning Algorithms\n",
    "ip = 'Insert IP here'\n",
    "conn = MongoClient(ip, 27017)\n",
    "conn.database_names()\n",
    "db = conn.get_database('cleaned_data')\n",
    "reviews = db.get_collection('restaurant_reviews')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Create a user dataframe with the following columns:•(review_text, review rating, business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useridlist =[]\n",
    "\n",
    "for user in users_dict.keys():\n",
    "    useridlist.append(user)\n",
    "print(useridlist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_user_df(user_specific_reviews):\n",
    "    #Input:\n",
    "    #user_specific_reviews: A list of reviews for a specific user\n",
    "    #Output: A dataframe with the columns (user_reviews, user_ratings, biz_ids)\n",
    "    user_reviews = []\n",
    "    user_ratings = []\n",
    "    business_ids = []\n",
    "\n",
    "    for review in user_specific_reviews:\n",
    "        user_reviews.append(review['text'])\n",
    "        user_ratings.append(review['stars'])\n",
    "        business_ids.append(review['business_id'])\n",
    "\n",
    "    ###WE SHOULD MAKE THE OUR OWN PUNCTUATION RULES\n",
    "    #https://www.tutorialspoint.com/python/string_translate.htm\n",
    "    #I'm gonna have to go and figure out what this does -ed\n",
    "    #user_reviews = [review.encode('utf-8').translate(None, string.punctuation) for review in user_reviews]\n",
    "\n",
    "    user_df = pd.DataFrame({'review_text': user_reviews, 'rating': user_ratings, 'biz_id': business_ids})\n",
    "    return user_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test to make users_dict,make_user_df works \n",
    "user_specific_reviews = users_dict[useridlist[0]]\n",
    "x= make_user_df(user_specific_reviews)\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Create a list of unique business IDs for that user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_ids = list(set(user['biz_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Connect to the MongoDB server and pull all of the reviews for the restaurants that the user has reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restreview = {}\n",
    "\n",
    "for i in range(0, len(business_ids)):\n",
    "    rlist = []\n",
    "    for obj in reviews.find({'business_id':business_ids[i]}):\n",
    "        rlist.append(obj)\n",
    "        restreview[business_ids[i]] = rlist\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create a restaurant dataframe with the following columns:•(review_text, biz rating, business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_df = yml.make_biz_df(user, restreview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Do a 80/20 training/test split, randomizing over the set of user' reviewed restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Create a training and test sample from the user reviewed restaurants\n",
    "split_samp = .30\n",
    "random_int = random.randint(1, len(business_ids)-1)\n",
    "len_random = int(len(business_ids) * split_samp)\n",
    "test_set = business_ids[random_int:random_int+len_random]\n",
    "training_set = business_ids[0:random_int]+business_ids[random_int+len_random:len(business_ids)]\n",
    "train_reviews, train_ratings = [], []\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list of training reviews and training ratings\n",
    "for rest_id in training_set:\n",
    "    train_reviews.extend(list(user_df[user_df['biz_id'] == rest_id]['review_text']))\n",
    "    train_ratings.extend(list(user_df[user_df['biz_id'] == rest_id]['rating']))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transform the star labels into a binary class problem, 0 if rating is < 4 else 1\n",
    "train_labels = [1 if x >=4 else 0 for x in train_ratings]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Train the LSI model on the set of training reviews, get the number of topics used in fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is just for my understand of how the model is working under the hood\n",
    "def fit_lsi(train_reviews):\n",
    "    #Input: train_reviews is a list of reviews that will be used to train the LSI feature transformer\n",
    "    #Output: A trained LSI model and the transformed training reviews\n",
    "\n",
    "    texts = [[word for word in review.lower().split() if (word not in stop_words)]\n",
    "              for review in train_reviews]\n",
    "    \n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    numpy_matrix = matutils.corpus2dense(corpus, num_terms=10000)\n",
    "    singular_values = np.linalg.svd(numpy_matrix, full_matrices=False, compute_uv=False)\n",
    "    mean_sv = sum(list(singular_values))/len(singular_values)\n",
    "    topics = int(mean_sv)\n",
    "\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "    lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=topics)\n",
    "\n",
    "    return lsi, topics, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit LSI model and return number of LSI topics\n",
    "lsi, topics, dictionary = yml.fit_lsi(train_reviews)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Set up the FeatureUnion with the desired features, then fit according to the train reviews and transform the train reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a FeatureUnion object with the desired features then fit to train reviews\n",
    "comb_features = yml.make_featureunion()\n",
    "comb_features.fit(train_reviews)\n",
    "    \n",
    "train_features = comb_features.transform(train_reviews)\n",
    "train_lsi = yml.get_lsi_features(train_reviews, lsi, topics, dictionary)\n",
    "train_features = sparse.hstack((train_features, train_lsi))\n",
    "train_features = train_features.todense()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit each model in turn \n",
    "model_runs = [(True, False, False, False, False), (False, True, False, False, False), \n",
    "                  (False, False, True, False, False), (False, False, False, True, False),\n",
    "                 (False, False, False, False, True)]\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(model_runs))):\n",
    "    clf = yml.fit_model(train_features, train_labels, svm_clf = model_runs[i][0], \n",
    "                        RandomForest = model_runs[i][1], nb = model_runs[i][2])\n",
    "    threshold = 0.7\n",
    "    error = yml.test_user_set(test_set, clf, restaurant_df, user_df, comb_features, threshold, lsi, topics, dictionary)\n",
    "    test_results[clf] = error\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Get top predictions\n",
    "\n",
    "for key in test_results.keys():\n",
    "    results = test_results[test_results.keys()[0]]\n",
    "    log_loss = yml.get_log_loss()\n",
    "    print log_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
