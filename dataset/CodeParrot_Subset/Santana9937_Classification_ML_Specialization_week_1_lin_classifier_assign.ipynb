{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "In this notebook, you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use DataFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping files with Amazon Baby Products Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of baby product reviews from Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put files in current direction into a list\n",
    "files_list = [f for f in os.listdir('.') if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filename of unzipped file\n",
    "unzipped_file = 'amazon_baby.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If upzipped file not in files_list, unzip the file\n",
    "if unzipped_file not in files_list:\n",
    "    zip_file = unzipped_file + '.zip'\n",
    "    unzipping = zipfile.ZipFile(zip_file)\n",
    "    unzipping.extractall()\n",
    "    unzipping.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the products data \n",
    "\n",
    "The dataset is loaded into a Pandas DataFrame called products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"amazon_baby.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                  Planetwise Wipe Pouch\n",
       "review    it came early and was not disappointed. i love...\n",
       "rating                                                    5\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.ix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing the punctuation from the strings in the review column, we will fall all NA values with empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products[\"review\"] = products[\"review\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are removing all the punctuation from the strings in the review column and saving the result into a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products[\"review_clean\"] = products[\"review\"].str.translate(None, string.punctuation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are create a function we will applyi to the \"ratings\" column of the dataframe to determine if the review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_func(x):\n",
    "    # If rating is >=4, return a positive sentiment (+1)\n",
    "    if x>=4:\n",
    "        return 1\n",
    "    # Else, return a negative sentiment (-1)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a \"sentiment\" column by applying the sent_func to the \"rating\" column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(sent_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I only purchased a second-year calendar for my...</td>\n",
       "      <td>2</td>\n",
       "      <td>I only purchased a secondyear calendar for my ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I LOVE this calendar for recording events of m...</td>\n",
       "      <td>5</td>\n",
       "      <td>I LOVE this calendar for recording events of m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "20  Nature's Lullabies Second Year Sticker Calendar   \n",
       "21  Nature's Lullabies Second Year Sticker Calendar   \n",
       "22  Nature's Lullabies Second Year Sticker Calendar   \n",
       "\n",
       "                                               review  rating  \\\n",
       "20  I had a hard time finding a second year calend...       5   \n",
       "21  I only purchased a second-year calendar for my...       2   \n",
       "22  I LOVE this calendar for recording events of m...       5   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "20  I had a hard time finding a second year calend...          1  \n",
       "21  I only purchased a secondyear calendar for my ...         -1  \n",
       "22  I LOVE this calendar for recording events of m...          1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.ix[20:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the indicies for the train and test data and putting them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('module-2-assignment-train-idx.txt', 'r') as train_file:\n",
    "    ind_list_train = map(int,train_file.read().split(','))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('module-2-assignment-test-idx.txt', 'r') as test_file:\n",
    "    ind_list_test = map(int,test_file.read().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the indicies of the train and test data to create the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = products.iloc[ind_list_train,:]\n",
    "test_data = products.iloc[ind_list_test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n",
      "33336\n"
     ]
    }
   ],
   "source": [
    "print len(train_data)\n",
    "print len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "- Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "- Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "- Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use this token pattern to keep single-letter words\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of the LogisticRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fit method to train the classifier. This model should use the sparse word count matrix (*train_matrix*) as features and the column sentiment of *train_data* as the target. Use the default values for other parameters. Call this model *sentiment_model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_model = logreg.fit(train_matrix, train_data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all the weights from the model into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121713\n"
     ]
    }
   ],
   "source": [
    "weights_list = list(sentiment_model.intercept_) + list(sentiment_model.coef_.flatten())\n",
    "weights_sent_model = np.array(weights_list, dtype = np.double)\n",
    "print len(weights_sent_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** How many weights are >= 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 85915\n",
      "Number of negative weights: 35798\n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = len(weights_sent_model[weights_sent_model >= 0.0])\n",
    "num_negative_weights = len(weights_sent_model[weights_sent_model < 0.0])\n",
    "\n",
    "print \"Number of positive weights: %i\" % num_positive_weights\n",
    "print \"Number of negative weights: %i\" % num_negative_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59    5\n",
      "71    2\n",
      "91    1\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "59                          Our Baby Girl Memory Book   \n",
       "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "59  Absolutely love it and all of the Scripture in...       5   \n",
       "71  Would not purchase again or recommend. The dec...       2   \n",
       "91  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "59  Absolutely love it and all of the Scripture in...          1  \n",
       "71  Would not purchase again or recommend The deca...         -1  \n",
       "91  Was so excited to get this product for my baby...         -1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data.ix[[59,71,91]]\n",
    "print sample_test_data['rating']\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data['review'].ix[59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data['review'].ix[71]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** . For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.61129645  -3.14942405 -10.42641065]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "pred_sent_test_data = []\n",
    "for val in scores:\n",
    "    if val>0:\n",
    "        pred_sent_test_data.append(1)\n",
    "    else:\n",
    "        pred_sent_test_data.append(-1)\n",
    "print pred_sent_test_data        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to Scikit-Learn:\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to Scikit-Learn:\" \n",
    "print sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.96356994e-01,   4.11139780e-02,   2.96383837e-05])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pos_score = 1.0/(1.0 + np.exp(-scores))\n",
    "prob_pos_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to Scikit-Learn:\n",
      "[  9.96356994e-01   4.11139780e-02   2.96383837e-05]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to Scikit-Learn:\" \n",
    "print sentiment_model.predict_proba(sample_test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The 3rd data point has the lowest probability of being positive **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**.\n",
    "\n",
    "Using the `sentiment_model`, find the 40 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-40 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`.\n",
    "2.  Sort the data according to those predictions and pick the top 40. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the scores with the sentiment_model decision function and then calculating the probability that y = +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_test_data = sentiment_model.decision_function(test_matrix)\n",
    "prob_test_data = 1.0/(1.0 + np.exp(-scores_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the 40 most positive and the 40 most negative values, we will create a list of tuples with the entries (probability, index). We will then sort the list and will be able to extract the indicies corresponding to each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of indicies in the test data\n",
    "ind_vals_test_data = test_data.index.values\n",
    "# Empty list that will be filled with the tuples (probability, index)\n",
    "score_label_lst_test = len(scores_test_data)*[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the list of tuples with the (probability, index) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(scores_test_data)):\n",
    "    score_label_lst_test[i] = (prob_test_data[i],ind_vals_test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the list with the entries (probability, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_label_lst_test.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the top 40 positive reviews and the top 40 negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_40_pos_test_rev = score_label_lst_test[-40:]\n",
    "top_40_neg_test_rev = score_label_lst_test[0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the indicies of the top 40 positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_top_40_pos_test = 40*[-1]\n",
    "for i,val in enumerate(top_40_pos_test_rev):\n",
    "    ind_top_40_pos_test[i] = val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the indicies of the top 40 negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_top_40_neg_test = 40*[-1]\n",
    "for i,val in enumerate(top_40_neg_test_rev):\n",
    "    ind_top_40_neg_test[i] = val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 40 most positive reviews? [multiple choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8841      Peg Perego Primo Viaggio Car Seat / Infant Car...\n",
       "172085                  Stokke Scoot Stroller - Light Green\n",
       "49749     Peg Perego Aria Light Weight One Hand Fold Str...\n",
       "154622    Rainy Day Indoor Playground toddler swing to b...\n",
       "42907             Prince Lionheart bebePOD Plus, Watermelon\n",
       "178750    Joovy Groove Ultralight Umbrella Stroller, Cha...\n",
       "119618                 Quinny 2012 Buzz Stroller, Rebel Red\n",
       "70808                 Skip Hop Studio Diaper Bag, Black Dot\n",
       "2985                            BABYBJORN Potty Chair - Red\n",
       "51417     The First Years True Fit Convertible Car Seat,...\n",
       "26833     Lilly Gold Sit 'n' Stroll 5 in 1 Car Seat and ...\n",
       "115731            Emily Green 6&quot; Bowl, Sunshine Safari\n",
       "99692                             Dr. Brown's Bottle Warmer\n",
       "13168         Roundabout Convertible Car Seat - Grey Wicker\n",
       "166827    Britax Boulevard 70-G3 Convertible Car Seat Se...\n",
       "14008         Stork Craft Beatrice Combo Tower Chest, White\n",
       "59276                      Britax Frontier Booster Car Seat\n",
       "121668    Door Monkey, Childproof Door Lock &amp; Pinch ...\n",
       "80881        Delta Universal 6 Drawer Dresser, Black Cherry\n",
       "172351    Phil &amp; Teds Navigator Buggy Golden Kiwi Fr...\n",
       "147996    Baby Jogger City Mini GT Double Stroller, Shad...\n",
       "182089    Summer Infant Wide View Digital Color Video Mo...\n",
       "22586        Britax Decathlon Convertible Car Seat, Tiffany\n",
       "165593    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
       "50315            P'Kolino Silly Soft Seating in Tias, Green\n",
       "52631     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
       "66059          Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
       "80155     Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
       "87017       Baby Einstein Around The World Discovery Center\n",
       "97325     Freemie Hands-Free Concealable Breast Pump Col...\n",
       "100166    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
       "114796    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
       "119182    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
       "133651                    Britax 2012 B-Agile Stroller, Red\n",
       "137034           Graco Pack 'n Play Element Playard - Flint\n",
       "140816           Diono RadianRXT Convertible Car Seat, Plum\n",
       "147949    Baby Jogger City Mini GT Single Stroller, Shad...\n",
       "168081    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
       "168697    Graco FastAction Fold Jogger Click Connect Str...\n",
       "180646        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.ix[ind_top_40_pos_test][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16042           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
       "120209    Levana Safe N'See Digital Video Baby Monitor w...\n",
       "77072        Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "48694     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "155287    VTech Communications Safe &amp; Sounds Full Co...\n",
       "94560     The First Years True Choice P400 Premium Digit...\n",
       "53207                   Safety 1st High-Def Digital Monitor\n",
       "81332                 Cloth Diaper Sprayer--styles may vary\n",
       "113995    Motorola Digital Video Baby Monitor with Room ...\n",
       "10677                     Philips AVENT Newborn Starter Set\n",
       "9915           Cosco Alpha Omega Elite Convertible Car Seat\n",
       "59546                Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "75994            Peg-Perego Tatamia High Chair, White Latte\n",
       "172090    Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
       "40079     Chicco Cortina KeyFit 30 Travel System in Adve...\n",
       "149987                     NUK Cook-n-Blend Baby Food Maker\n",
       "154878    VTech Communications Safe &amp; Sound Digital ...\n",
       "1116                  Safety 1st Deluxe 4-in-1 Bath Station\n",
       "83234         Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
       "31741                Regalo My Cot Portable Bed, Royal Blue\n",
       "176046         Baby Trend Inertia Infant Car Seat - Horizon\n",
       "105055                  Angelcare Baby Sound Monitor, White\n",
       "95420          One Step Ahead Hide-Away Extra Long Bed Rail\n",
       "116391    Keekaroo Height Right High Chair, Infant Inser...\n",
       "153488         Kidz Delight Smooth Touch Tablet, Fun N Play\n",
       "83571     Nuby Natural Touch Silicone Travel Infa Feeder...\n",
       "96572      Baby Jogger Summit XC Double Stroller, Red/Black\n",
       "139654    Fisher-Price Discover 'n Grow Take-Along Play ...\n",
       "99594     Valco Baby Tri-mode Twin Stroller EX- Hot Choc...\n",
       "66354     Levana BABYVIEW20 Interference Free Digital Wi...\n",
       "17089     Playtex Nurser With Drop-Ins Liner, 4 Ounce, C...\n",
       "140418    Jolly Jumper Arctic Sneak A Peek Infant Car Se...\n",
       "82324     Cloud b Gentle Giraffe On The Go Travel Sound ...\n",
       "172823    Ergobaby Performance Collection Charcoal Grey ...\n",
       "54267              Pearhead Babyprints Keepsake, Year-Round\n",
       "76000            Peg-Perego Tatamia High Chair, White Latte\n",
       "148431    Munchkin Nursery Projector and Sound System, W...\n",
       "1020                  Safety 1st Deluxe 4-in-1 Bath Station\n",
       "122105             Baby Trend Encore Travel System-Columbia\n",
       "26194                            Sunshine Kids Travel - Bag\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.ix[ind_top_40_neg_test][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifer. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    \n",
    "    # Constructing the wordcount vector\n",
    "    data_matrix = vectorizer.transform(data['review_clean'])\n",
    "    \n",
    "    # Getting the predictions\n",
    "    preds_data = model.predict(data_matrix)\n",
    "    \n",
    "    # Computing the number of correctly classified examples and the total examples\n",
    "    n_correct = float(np.sum(preds_data == true_labels.values))\n",
    "    n_total = float(len(preds_data))\n",
    "\n",
    "    # Computing the accuracy by dividing number of \n",
    "    #correctly classified examples by total number of examples\n",
    "    accuracy = n_correct/n_total\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932145428366\n"
     ]
    }
   ],
   "source": [
    "acc_sent_mod_test = get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])\n",
    "print acc_sent_mod_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.93\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy on Test Data: %.2f\" %(acc_sent_mod_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** No, you may be overfitting. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, computing the accuracy of the sentiment model on the training data for a future quiz question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96789740361\n"
     ]
    }
   ],
   "source": [
    "acc_sent_mod_train = get_classification_accuracy(sentiment_model, train_data, train_data['sentiment'])\n",
    "print acc_sent_mod_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finding the weights of significant words for the sentiment_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this section, we will find the weights of significant words for the sentiment_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating a vocab list. The vocab list constains all the words used for the sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121712\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of the significant words in the utf-8 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "un_sig_words = [u'love', u'great', u'easy', u'old', u'little', u'perfect', u'loves', \n",
    "                u'well', u'able', u'car', u'broke', u'less', u'even', u'waste', u'disappointed', \n",
    "                u'work', u'product', u'money', u'would', u'return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list that will store all the indicies where the significant words appear in the vocab list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_vocab_sig_words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the index where each significant word appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in un_sig_words:\n",
    "    ind_vocab_sig_words.append(vocab.index(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating an empty list that will store the weights of the significant words. Then, using the index to find the weight for each signigicant word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws_sent_mod_sig_words = []\n",
    "for ind in ind_vocab_sig_words:\n",
    "    ws_sent_mod_sig_words.append(sentiment_model.coef_.flatten()[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a series that will store the weights of the significant words and displaying this Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love            1.574856\n",
       "great           1.228180\n",
       "easy            1.358323\n",
       "old             0.052743\n",
       "little          0.637940\n",
       "perfect         1.862897\n",
       "loves           1.518146\n",
       "well            0.540171\n",
       "able            0.390223\n",
       "car             0.124075\n",
       "broke          -1.392661\n",
       "less           -0.277272\n",
       "even           -0.464528\n",
       "waste          -1.992954\n",
       "disappointed   -2.195897\n",
       "work           -0.460691\n",
       "product        -0.191460\n",
       "money          -0.784845\n",
       "would          -0.288619\n",
       "return         -1.654747\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_sent_mod_ser = pd.Series(data=ws_sent_mod_sig_words, index=un_sig_words)\n",
    "ws_sent_mod_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subet of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of the LogisticRegression class. Using the fit method to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model simple_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_reg = linear_model.LogisticRegression()\n",
    "simple_model = logreg.fit(train_matrix_word_subset, train_data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the weights for the 20 significant words from the simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws_simp_model = list(simple_model.coef_.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the weights in a Series with the words corresponding to the weights as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love            1.363690\n",
       "great           0.944000\n",
       "easy            1.192538\n",
       "old             0.085513\n",
       "little          0.520186\n",
       "perfect         1.509812\n",
       "loves           1.673074\n",
       "well            0.503760\n",
       "able            0.190909\n",
       "car             0.058855\n",
       "broke          -1.651576\n",
       "less           -0.209563\n",
       "even           -0.511380\n",
       "waste          -2.033699\n",
       "disappointed   -2.348298\n",
       "work           -0.621169\n",
       "product        -0.320556\n",
       "money          -0.898031\n",
       "would          -0.362167\n",
       "return         -2.109331\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_simp_mod_ser = pd.Series(data=ws_simp_model, index=significant_words)\n",
    "ws_simp_mod_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print len(simple_model.coef_[simple_model.coef_>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Yes, see weights below for the significant words for the sentiment model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love            1.574856\n",
       "great           1.228180\n",
       "easy            1.358323\n",
       "old             0.052743\n",
       "little          0.637940\n",
       "perfect         1.862897\n",
       "loves           1.518146\n",
       "well            0.540171\n",
       "able            0.390223\n",
       "car             0.124075\n",
       "broke          -1.392661\n",
       "less           -0.277272\n",
       "even           -0.464528\n",
       "waste          -1.992954\n",
       "disappointed   -2.195897\n",
       "work           -0.460691\n",
       "product        -0.191460\n",
       "money          -0.784845\n",
       "would          -0.288619\n",
       "return         -1.654747\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_sent_mod_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967897403609762"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sent_mod_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866822570007\n"
     ]
    }
   ],
   "source": [
    "preds_simp_mod_train = simple_model.predict(train_matrix_word_subset)\n",
    "n_cor_preds_simp_mod_train = float(np.sum(preds_simp_mod_train == train_data['sentiment'].values))\n",
    "n_tol_preds_simp_mod_train = float(len(preds_simp_mod_train))\n",
    "acc_simp_mod_train = n_cor_preds_simp_mod_train/n_tol_preds_simp_mod_train\n",
    "print acc_simp_mod_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_model\n"
     ]
    }
   ],
   "source": [
    "if acc_sent_mod_train>acc_simp_mod_train:\n",
    "    print \"sentiment_model\"\n",
    "else:\n",
    "    print \"simple_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this excercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321454283657308"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sent_mod_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869360451164\n"
     ]
    }
   ],
   "source": [
    "preds_simp_mod_test = simple_model.predict(test_matrix_word_subset)\n",
    "n_cor_preds_simp_mod_test = float(np.sum(preds_simp_mod_test == test_data['sentiment'].values))\n",
    "n_tol_preds_simp_mod_test = float(len(preds_simp_mod_test))\n",
    "acc_simp_mod_test = n_cor_preds_simp_mod_test/n_tol_preds_simp_mod_test\n",
    "print acc_simp_mod_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_model\n"
     ]
    }
   ],
   "source": [
    "if acc_sent_mod_test>acc_simp_mod_test:\n",
    "    print \"sentiment_model\"\n",
    "else:\n",
    "    print \"simple_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment is Majority Classifier for Training Data\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "acc_pos_train = float(num_positive)/float(len(train_data['sentiment']))\n",
    "acc_neg_train = float(num_negative)/float(len(train_data['sentiment']))\n",
    "if acc_pos_train>acc_neg_train:\n",
    "    print \"Positive Sentiment is Majority Classifier for Training Data\"\n",
    "else:\n",
    "    print \"Negative Sentiment is Majority Classifier for Training Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Majority Class Classifier on Test Data: 0.84\n"
     ]
    }
   ],
   "source": [
    "num_pos_test = (test_data['sentiment'] == +1).sum()\n",
    "acc_pos_test = float(num_pos_test)/float(len(test_data['sentiment']))\n",
    "print \"Accuracy of Majority Class Classifier on Test Data: %.2f\" %(acc_pos_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the sentiment_model is better than majority class classifier\n"
     ]
    }
   ],
   "source": [
    "if acc_sent_mod_test>acc_pos_test:\n",
    "    print \"Yes, the sentiment_model is better than majority class classifier\"\n",
    "else:\n",
    "    print \"No, the majority class classifier is better than sentiment_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
