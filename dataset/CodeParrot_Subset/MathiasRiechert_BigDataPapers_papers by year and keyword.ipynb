{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# papers by year and keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter:\n",
    "database=\"wos12b\"\n",
    "searchterm=\"big data\" #lowecase!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cx_Oracle #ensure that OS, InstantClient (Basic, ODBC, SDK) and cx_Oracle are all 64 bit. Install with \"pip install cx_Oracle\". Add link to InstantClient in Path variable!\n",
    "import pandas as pd\n",
    "import plotly    #cmd: conda install plotly\n",
    "plotly.__version__\n",
    "# (*) To communicate with Plotly's server, sign in with credentials file\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "# (*) Useful Python/Plotly tools\n",
    "\n",
    "import random\n",
    "\n",
    "from plotly.grid_objs import Grid, Column\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db-connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsn_tns=cx_Oracle.makedsn('127.0.0.1','6025',service_name='bibliodb01.fiz.karlsruhe')\n",
    " #open connection:\n",
    "db=cx_Oracle.connect(<username>, <password>, dsn_tns)\n",
    "print(db.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% functions:\n",
    "def read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute( query )\n",
    "        names = [ x[0] for x in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        return pd.DataFrame( rows, columns=names)\n",
    "    finally:\n",
    "        if cursor is not None:\n",
    "            cursor.close()\n",
    "\n",
    "def array_to_string(arr):\n",
    "    returnstring=\"(\"\n",
    "    firstval=True\n",
    "    for value in arr:\n",
    "        if firstval:\n",
    "            returnstring = returnstring + \"'\"+str(value)+\"'\"\n",
    "            firstval=False\n",
    "        else:\n",
    "            returnstring = returnstring + \",'\"+str(value)+\"'\"\n",
    "    returnstring=returnstring+\")\"\n",
    "    return returnstring\n",
    "    \n",
    "\n",
    "def get_random_color(pastel_factor = 0.5):\n",
    "    return [(x+pastel_factor)/(1.0+pastel_factor) for x in [random.uniform(0,1.0) for i in [1,2,3]]]\n",
    "\n",
    "def color_distance(c1,c2):\n",
    "    return sum([abs(x[0]-x[1]) for x in zip(c1,c2)])\n",
    "\n",
    "def generate_new_color(existing_colors,pastel_factor = 0.5):\n",
    "    max_distance = None\n",
    "    best_color = None\n",
    "    for i in range(0,100):\n",
    "        color = get_random_color(pastel_factor = pastel_factor)\n",
    "        if not existing_colors:\n",
    "            return color\n",
    "        best_distance = min([color_distance(color,c) for c in existing_colors])\n",
    "        if not max_distance or best_distance > max_distance:\n",
    "            max_distance = best_distance\n",
    "            best_color = color\n",
    "    return best_color    \n",
    "    \n",
    "    \n",
    "def get_all_papers_json(year,class_category):\n",
    "    yearint=int(year)\n",
    "    #get right papers:\n",
    "    return dataset_original[(dataset_original['PUBYEAR']==yearint) & (dataset_original[CONSTGrouping]==class_category)].loc[:,['DOI','ARTICLE_TITLE','PUBYEAR','KEYWORD']].drop_duplicates().to_json(orient='records')\n",
    "    \n",
    "def get_all_papers(year,class_category): #html table!\n",
    "    yearint=int(year)\n",
    "    #get right papers:\n",
    "    outputdf=dataset_original[(dataset_original['PUBYEAR']==yearint) & (dataset_original[CONSTGrouping]==class_category)].loc[:,['DOI','ARTICLE_TITLE','PUBYEAR','KEYWORD']].drop_duplicates()\n",
    "    outputdf['DOI']='<a href=\"http://dx.doi.org/' + outputdf['DOI'] + '\" target=\"_blank\">'+ outputdf['DOI'] +'</a>'\n",
    "    #set displaywith to max, as to_html would truncate otherwise:\n",
    "    old_width = pd.get_option('display.max_colwidth')\n",
    "    pd.set_option('display.max_colwidth', -1)    \n",
    "    returnstring=outputdf.to_html(index=False,escape=False)\n",
    "    pd.set_option('display.max_colwidth', old_width)\n",
    "    return returnstring\n",
    "    \n",
    "\n",
    "\n",
    "def make_hover_text(year,class_category):\n",
    "    yearint=int(year)\n",
    "    \n",
    "    returntext='%s\\\n",
    "    <br>Number of Papers: %s \\\n",
    "    <br>Average number of authors: %s  \\\n",
    "    <br>Average number references: %s  \\\n",
    "    <br>Average number of authors\\' countries: %s  \\\n",
    "    <br>Average number of authors\\' institutions: %s  \\\n",
    "    <br>Average number of citations: %s ' \\\n",
    "    % (getvalue(yearint,class_category,CONSTGrouping)\n",
    "    , getvalue(yearint,class_category,'NUM_PAPERS')\n",
    "    , getvalue(yearint,class_category,'AUTHOR_MEAN')\n",
    "    , getvalue(yearint,class_category,'REF_MEAN')\n",
    "    , getvalue(yearint,class_category,'COUNTRY_MEAN')\n",
    "    , getvalue(yearint,class_category,'INST_MEAN')\n",
    "    , getvalue(yearint,class_category,'CIT_MEAN')) \n",
    "    \n",
    "    print(returntext)\n",
    "    return returntext\n",
    "        \n",
    "def getvalue(year,class_category,attribute):\n",
    "    returnval=dataset[(dataset['PUBYEAR']==year) & (dataset[CONSTGrouping]==class_category)][attribute]\n",
    "    if returnval.empty:\n",
    "        return \"\"\n",
    "    else:\n",
    "        if isinstance(returnval.values[0], str):\n",
    "            return returnval.values[0]\n",
    "        else:\n",
    "            return round(returnval.values[0],2)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data from db\n",
    "note that access to the db is restricted to members of the competence centre of bibliometrics (http://www.bibliometrie.info/) and its cooperation partners. However, you can continue with the csv stored at the end of this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Load all existing keywords with the term big data in it (and their corresponding primary keys:\n",
    "\n",
    "command=\"\"\"SELECT kw,pk_kw FROM  \n",
    "(SELECT lower(wos12b.KEYWORDS.KEYWORD) kw,PK_KEYWORDS pk_kw \n",
    "FROM \"\"\"+database+\"\"\".KEYWORDS, \"\"\"+database+\"\"\".ITEMS_KEYWORDS, \"\"\"+database+\"\"\".ITEMS \n",
    " WHERE\n",
    " \"\"\"+database+\"\"\".ITEMS_KEYWORDS.FK_KEYWORDS=\"\"\"+database+\"\"\".KEYWORDS.PK_KEYWORDS\n",
    " AND \"\"\"+database+\"\"\".ITEMS.PK_ITEMS=\"\"\"+database+\"\"\".ITEMS_KEYWORDS.FK_ITEMS  \n",
    " AND lower(\"\"\"+database+\"\"\".KEYWORDS.KEYWORD) LIKE '%\"\"\"+searchterm+\"\"\"%'\n",
    ")\n",
    "GROUP BY kw,pk_kw\n",
    "ORDER BY kw DESC\n",
    "\"\"\"\n",
    "\n",
    "df=read_query(db,command)\n",
    "\n",
    "# we already matched some different forms of writing keywords by merging all \n",
    "# to lcase. Remove \" and ' for further merging:\n",
    "\n",
    "df['KW'].replace(regex=True,inplace=True,to_replace=r'\\'',value=r'')\n",
    "df['KW'].replace(regex=True,inplace=True,to_replace=r'\\\"',value=r'')\n",
    "df= df.sort_values(by=['KW', 'PK_KW'], ascending=[1, 1])\n",
    "df.to_csv(\"keywords.csv\", sep=';')\n",
    "\n",
    "#%% get list of single keywords:\n",
    "\n",
    "kw_unique=df['KW'].unique()\n",
    "# get ids per keyword:\n",
    "indextable ={}\n",
    "for keyword in kw_unique:\n",
    "    arrkeyword_ids=df[df['KW']==keyword]['PK_KW'].unique()\n",
    "    strkeyword_ids=array_to_string(arrkeyword_ids)\n",
    "    indextable[keyword]=arrkeyword_ids\n",
    "\n",
    "#%% now get all papers \n",
    "\n",
    "df2_all_keywords = pd.DataFrame()\n",
    "i=1\n",
    "print('loading papers for keyword:')\n",
    "for keyword in kw_unique:\n",
    "    print('...'+keyword + ' ('+str(i)+' of '+str(len(kw_unique))+')')\n",
    "    arrkeyword_ids=df[df['KW']==keyword]['PK_KW'].unique()\n",
    "    strkeyword_ids=array_to_string(arrkeyword_ids)\n",
    "    command=\"\"\"SELECT ROUND(PUBYEAR,0) as PUBYEAR, CLASSIFICATION, DOI, ARTICLE_TITLE,\n",
    "AUTHOR_CNT, \n",
    "REF_CNT, \n",
    "COUNTRY_CNT, \n",
    "INST_CNT,\n",
    "cc.COUNT AS CIT_CNT \n",
    "FROM \n",
    "\"\"\"+database+\"\"\".ITEMS i, \n",
    "\"\"\"+database+\"\"\".ITEMS_KEYWORDS i_k,\n",
    "\"\"\"+database+\"\"\".CITINGCOUNTS cc,\n",
    "\"\"\"+database+\"\"\".ITEMS_CLASSIFICATIONS i_c,\n",
    "\"\"\"+database+\"\"\".CLASSIFICATIONS c \n",
    "WHERE i.PK_ITEMS=i_k.FK_ITEMS \n",
    "AND i_c.FK_ITEMS=i.PK_ITEMS \n",
    "AND i_c.FK_CLASSIFICATIONS=c.PK_CLASSIFICATIONS \n",
    "AND cc.FK_ITEMS=i.PK_ITEMS \n",
    "AND PUBTYPE='J' \n",
    "AND FK_KEYWORDS IN  \n",
    "\"\"\"+strkeyword_ids+\"\"\" \n",
    "\"\"\"\n",
    "    \n",
    "    df2=read_query(db,command)\n",
    " \n",
    "    df2['KEYWORD']=keyword\n",
    "    df2_all_keywords=df2_all_keywords.append(df2)\n",
    "    i=i+1\n",
    "\n",
    "df2_all_keywords.PUBYEAR=df2_all_keywords.PUBYEAR.astype(int)\n",
    "df2_all_keywords.to_csv(\"datafromdb.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSTGrouping=\"KEYWORD\" #\"CLASSIFICATION\n",
    "dataset_original=pd.read_csv(\"datafromdb.csv\",sep=\";\")\n",
    "dataset_original= dataset_original[dataset_original.PUBYEAR != 2015]\n",
    "dataset_original=dataset_original.drop(dataset_original.columns[[0]], axis=1)\n",
    "#group by to get averages:\n",
    "dataset=dataset_original.drop_duplicates(['PUBYEAR',CONSTGrouping,'DOI','ARTICLE_TITLE'])\n",
    "grouped=dataset.groupby(['PUBYEAR',CONSTGrouping])           \n",
    "                \n",
    "dataset=grouped.agg('mean',)\\\n",
    "             .rename(columns = lambda x: x.replace(\"_CNT\",\"_MEAN\"))\\\n",
    "             .join(pd.DataFrame(grouped.size(), \n",
    "                                columns=['NUM_PAPERS'])).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build plotly grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years_from_col = set(round(dataset['PUBYEAR'],0))\n",
    "years_ints = sorted(list(years_from_col))\n",
    "years = [str(year) for year in years_ints]\n",
    "\n",
    "\n",
    "# make list of class_categories (can be 'KEYWORD' or 'CLASSIFICATION')\n",
    "class_categories = []\n",
    "for class_category in dataset[CONSTGrouping]:\n",
    "    if class_category not in class_categories: \n",
    "        class_categories.append(class_category)\n",
    "\n",
    "columns = []\n",
    "# make grid\n",
    "for year in years:\n",
    "    for class_category in class_categories:\n",
    "        dataset_by_year = dataset[dataset['PUBYEAR'] == int(year)]\n",
    "        dataset_by_year_and_keyw = dataset_by_year[dataset_by_year[CONSTGrouping] == class_category]\n",
    "        for col_name in dataset_by_year_and_keyw:\n",
    "            # each column name is unique\n",
    "            column_name = '{year}_{class_category}_{header}_grid'.format(\n",
    "                year=year, class_category=class_category, header=col_name\n",
    "            )\n",
    "            a_column = Column(list(dataset_by_year_and_keyw[col_name]), column_name)\n",
    "            columns.append(a_column)\n",
    "\n",
    "# upload grid\n",
    "grid = Grid(columns)\n",
    "url = py.grid_ops.upload(grid, 'grid'+str(time.time()), auto_open=False)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare layout, sliderdict and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CONSTxaxis='INST_MEAN'\n",
    "CONSTyaxis='REF_MEAN'\n",
    "CONSTsize='NUM_PAPERS'\n",
    "\n",
    "#AUTHOR_MEAN, REF_MEAN, COUNTRY_MEAN, INST_MEAN, CIT_MEAN \n",
    "\n",
    "\n",
    "CONSTduration=1500\n",
    "\n",
    "#make figure:\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {},\n",
    "    'frames': [],\n",
    "    'config': {'scrollzoom': True}\n",
    "}\n",
    "\n",
    "# fill in most of layout\n",
    "figure['layout']['xaxis'] = {'range': [0, 12], 'title': CONSTxaxis, 'gridcolor': '#FFFFFF'}\n",
    "figure['layout']['yaxis'] = {'range': [-5, 100],'title': CONSTyaxis, 'gridcolor': '#FFFFFF'}\n",
    "figure['layout']['hovermode'] = 'closest'\n",
    "figure['layout']['plot_bgcolor'] = 'rgb(240, 245, 250)'\n",
    "figure['layout']['margin'] = {'r': 290}\n",
    "figure['layout']['slider'] = {\n",
    "    'args': [\n",
    "        'slider.value', {\n",
    "            'duration': CONSTduration,\n",
    "            'ease': 'cubic-in-out'\n",
    "        }\n",
    "    ],\n",
    "    'initialValue': '2009',\n",
    "    'plotlycommand': 'animate',\n",
    "    'values': years,\n",
    "    'visible': True\n",
    "}\n",
    "figure['layout']['showlegend']=True;\n",
    "figure['layout']['legend']={'x':1,'y':1,'font':{'size':10}};\n",
    "figure['layout']['updatemenus'] = [\n",
    "    {\n",
    "        'buttons': [\n",
    "            {\n",
    "                'args': [None, {'frame': {'duration': CONSTduration, 'redraw': True},\n",
    "                         'fromcurrent': True, 'transition': {'duration': CONSTduration, 'easing': 'quadratic-in-out'}}],\n",
    "                'label': 'Play',\n",
    "                'method': 'animate'\n",
    "            },\n",
    "            {\n",
    "                'args': [[None], {'frame': {'duration': 0, 'redraw': True}, 'mode': 'immediate',\n",
    "                'transition': {'duration': 0}}],\n",
    "                'label': 'Pause',\n",
    "                'method': 'animate'\n",
    "            }\n",
    "        ],\n",
    "        'direction': 'left',\n",
    "        'pad': {'r': 10, 't': 87},\n",
    "        'showactive': False,\n",
    "        'type': 'buttons',\n",
    "        'x': 0.1,\n",
    "        'xanchor': 'right',\n",
    "        'y': 0,\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sliders_dict = {\n",
    "    'active': 0,\n",
    "    'yanchor': 'top',\n",
    "    'xanchor': 'left',\n",
    "    'currentvalue': {\n",
    "        'font': {'size': 20},\n",
    "        'prefix': 'Year:',\n",
    "        'visible': True,\n",
    "        'xanchor': 'right'\n",
    "    },\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50},\n",
    "    'len': 0.9,\n",
    "    'x': 0.1,\n",
    "    'y': 0,\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "custom_colors={}\n",
    "for class_category in dataset[CONSTGrouping].unique():\n",
    "    r = lambda: random.randint(0,255)\n",
    "    custom_colors[class_category]='rgb('+str(r())+','+str(r())+','+str(r())+')'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define starting plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_name_template = '{year}_{class_category}_{header}_grid'\n",
    "\n",
    "year = 2009\n",
    "for class_category in class_categories:\n",
    "    data_dict = {\n",
    "        'xsrc': grid.get_column_reference(col_name_template.format(\n",
    "            year=year, class_category=class_category, header=CONSTxaxis\n",
    "        )),\n",
    "        'ysrc': grid.get_column_reference(col_name_template.format(\n",
    "            year=year, class_category=class_category, header=CONSTyaxis\n",
    "        )),\n",
    "        'mode': 'markers',\n",
    "        'text': make_hover_text(year,class_category),\n",
    "        'paper':get_all_papers(year,class_category),\n",
    "        'hoverinfo':'text',\n",
    "        'marker': {\n",
    "            'sizemode': 'area',\n",
    "            'sizeref':  0.02,\n",
    "            'sizesrc': grid.get_column_reference(col_name_template.format(\n",
    "                 year=year, class_category=class_category, header=CONSTsize\n",
    "            )),\n",
    "            'color': custom_colors[class_category]\n",
    "        },\n",
    "        'name': class_category[:50]\n",
    "    }\n",
    "    figure['data'].append(data_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define frames for each later year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for year in years:\n",
    "    frame = {'data': [], 'name': str(year)}\n",
    "    for class_category in class_categories:\n",
    "        data_dict = {\n",
    "            'xsrc': grid.get_column_reference(col_name_template.format(\n",
    "                year=year, class_category=class_category, header=CONSTxaxis\n",
    "            )),\n",
    "            'ysrc': grid.get_column_reference(col_name_template.format(\n",
    "                year=year, class_category=class_category, header=CONSTyaxis\n",
    "            )),\n",
    "            'mode': 'markers',\n",
    "            'text': make_hover_text(year,class_category),\n",
    "            'paper':get_all_papers(year,class_category),\n",
    "             'hoverinfo':'text',\n",
    "            #'textsrc': grid.get_column_reference(col_name_template.format(\n",
    "        #    year=year, class_category=class_category, header=CONSTGrouping\n",
    "       # )),\n",
    "            'marker': {\n",
    "                'sizemode': 'area',\n",
    "                'sizeref': 0.02,\n",
    "                'sizesrc': grid.get_column_reference(col_name_template.format(\n",
    "                    year=year, class_category=class_category, header=CONSTsize\n",
    "                )),\n",
    "                'color': custom_colors[class_category],\n",
    "                'opacity':0.6\n",
    "            },\n",
    "            'name': class_category[:50]\n",
    "        }\n",
    "        frame['data'].append(data_dict)\n",
    "\n",
    "    figure['frames'].append(frame)\n",
    "    slider_step = {'args': [\n",
    "        [year],\n",
    "        {'frame': {'duration': CONSTduration, 'redraw': True},\n",
    "         'mode': 'immediate',\n",
    "       'transition': {'duration': CONSTduration}}\n",
    "     ],\n",
    "     'label': year,\n",
    "     'method': 'animate'}\n",
    "    sliders_dict['steps'].append(slider_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finally, plot/upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "#plot(figure)\n",
    "py.icreate_animations(figure, 'BigDataPapers'+str(time.time()),auto_open=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
