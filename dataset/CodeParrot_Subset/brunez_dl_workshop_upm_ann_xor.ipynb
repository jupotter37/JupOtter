{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning XOR\n",
    "This notebook demonstrates a fundamental motivation of representation learning for machine learning: the XOR function.\n",
    "\n",
    "Learning the XOR function is impossible for a separating-hyperplane based classifier, unless an alternative \n",
    "representation is employed. Neural networks can be viewed as representation learners, and can therefore learn the\n",
    "XOR function (if the architecture is adequate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build data set (XOR truth table)\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a network with w layers: the first one with two neurons, the second with one\n",
    "# Observe that each of these neurons individually looks just like a logistic regression model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=2, input_dim=2,kernel_initializer='random_uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras models need to be compiled once they have been defined\n",
    "# Here we determine the loss function, the optimization algorithm and the\n",
    "# metrics to be computed during optimization\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This call runs the optimization algorithm, as many times as specified by the \"epochs\" arguments\n",
    "# Generally, this network will have a hard time learning the XOR function, even though it can. This illustrates\n",
    "# a common problem with neural networks: they are difficult to train\n",
    "model.fit(X, y, epochs=10, verbose=1, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This call applies the function learned by the network to the input data\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can print the parameters learned by the network\n",
    "weights = model.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also modify them by hand. \n",
    "# By formalizing the problem we can derive a set of inequalities that lead to suitable weights (try it at home!)\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Given a set of weights for the first layer and one weight for the second, \n",
    "# this gives us a range in which we can look for the remaining one\n",
    "for a in range(3):\n",
    "    print sigmoid(a)/sigmoid(2*a)\n",
    "\n",
    "# These ones are correct for the XOR problem\n",
    "weights[0][0][0]=1\n",
    "weights[0][0][1]=2\n",
    "weights[0][1][0]=1\n",
    "weights[0][1][1]=2\n",
    "weights[1][0]=0\n",
    "weights[1][1]=0\n",
    "weights[2][0]=-1\n",
    "weights[2][1]=0.85\n",
    "weights[3] = [0]\n",
    "model.set_weights(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
