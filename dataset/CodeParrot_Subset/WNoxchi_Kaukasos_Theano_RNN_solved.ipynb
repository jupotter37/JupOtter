{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wayne Nixalo - 1 Jul 2017\n",
    "\n",
    "RNN Theano\n",
    "\n",
    "I've been having a problem getting a RNN built in Theano to work. A corpus of\n",
    "Nietzsche is the training data. Done correctly, the model should start with\n",
    "a loss of ~25 and ends at ~14.4, and reasonably predict the next character.\n",
    "Done wrong, the model starts with a loss ~30~29, and ends at ~25, and\n",
    "predicts only empty spaces (obvious easy local minima).\n",
    "\n",
    "I've narrowed down the relevant parts of code, going on a goose-hunt pursuing\n",
    "red herrings, until finally discovering the model works as advertised when\n",
    "copied, but not when I rewrite it. So this is to see where I made errors and\n",
    "how they're responsible.\n",
    "\n",
    "**NOTE:** ohhh my holy fuck. The culprit was the:\n",
    "          from __future__ import division, print_function\n",
    "line. Specifically `import division`. That single import is responsible for\n",
    "the last 2 weeks of tracking down this issue. So why? Well w/o looking into\n",
    "it, it seems like somewhere integer division was supposed to be done where\n",
    "floating-point div was instead done or vice-versa.\n",
    "\n",
    "**NOTE:** okay got it. importing division from __future__ gives you Python3\n",
    "divison: floating-point. My poor RNN's SGD optimizer was forced to use\n",
    "integer division everywhere instead of floating-point. Oof. Well, that's done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Unsuccessful Theano RNN run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 600901)\n",
      "('total chars:', 86)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "# %matplotlib inline\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join('../utils'))\n",
    "# import utils; reload(utils)\n",
    "from utils import *\n",
    "# from __future__ import division#, print_function\n",
    "\n",
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)\n",
    "\n",
    "chars.insert(0, \"\\0\")\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = 8\n",
    "\n",
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-cs, cs)] for n in xrange(cs)]\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "\n",
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)] for n in xrange(cs)]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WayNoxchi/Miniconda3/Theano/theano/tensor/basic.py:5130: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 28.986\n",
      "Error: 25.977\n",
      "Error: 25.761\n",
      "Error: 25.518\n",
      "Error: 25.341\n",
      "Error: 25.490\n",
      "Error: 25.177\n",
      "Error: 25.101\n",
      "Error: 25.151\n",
      "Error: 25.495\n",
      "Error: 24.801\n",
      "Error: 25.009\n",
      "Error: 26.446\n",
      "Error: 25.014\n",
      "Error: 24.888\n",
      "Error: 26.046\n",
      "Error: 25.932\n",
      "Error: 25.714\n",
      "Error: 25.041\n",
      "Error: 24.938\n",
      "Error: 24.872\n",
      "Error: 25.092\n",
      "Error: 25.351\n",
      "Error: 24.953\n",
      "Error: 25.128\n",
      "Error: 25.144\n",
      "Error: 25.317\n",
      "Error: 24.996\n",
      "Error: 25.114\n",
      "Error: 25.300\n",
      "Error: 25.438\n",
      "Error: 25.180\n",
      "Error: 25.548\n",
      "Error: 25.050\n",
      "Error: 25.253\n",
      "Error: 25.591\n",
      "Error: 25.060\n",
      "Error: 25.380\n",
      "Error: 25.277\n",
      "Error: 25.589\n",
      "Error: 24.948\n",
      "Error: 24.953\n",
      "Error: 25.200\n",
      "Error: 25.384\n",
      "Error: 25.643\n",
      "Error: 25.679\n",
      "Error: 25.149\n",
      "Error: 24.073\n",
      "Error: 24.635\n",
      "Error: 24.867\n",
      "Error: 24.429\n",
      "Error: 24.570\n",
      "Error: 24.357\n",
      "Error: 24.355\n",
      "Error: 24.773\n",
      "Error: 24.590\n",
      "Error: 24.631\n",
      "Error: 24.551\n",
      "Error: 24.523\n",
      "Error: 24.688\n",
      "Error: 24.431\n",
      "Error: 24.619\n",
      "Error: 24.658\n",
      "Error: 24.774\n",
      "Error: 24.477\n",
      "Error: 24.342\n",
      "Error: 24.341\n",
      "Error: 24.398\n",
      "Error: 24.153\n",
      "Error: 24.214\n",
      "Error: 24.885\n",
      "Error: 24.407\n",
      "Error: 24.177\n",
      "Error: 24.022\n",
      "Error: 23.951\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 256; n_fac = 42; cs = 8\n",
    "\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size\n",
    "\n",
    "def init_wgts(rows, cols):\n",
    "    scale = math.sqrt(2/rows)\n",
    "    return shared(normal(scale=scale, size=(rows,cols)).astype(np.float32))\n",
    "def init_bias(rows):\n",
    "    return shared(np.zeros(rows, dtype=np.float32))\n",
    "def wgts_and_bias(n_in, n_out):\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n):\n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)\n",
    "\n",
    "# Theano Variables\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]\n",
    "\n",
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))\n",
    "\n",
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both   --   `flatten()` is Theano bug workaround\n",
    "    return h, T.flatten(y, 1)\n",
    "\n",
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp,\n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)\n",
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)\n",
    "\n",
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w - g * lr for (w, g) in zip(wgts, grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)\n",
    "\n",
    "# ready to compile the function:\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)\n",
    "\n",
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "# X.shape, Y.shape\n",
    "\n",
    "# semi-auto SGD loop:\n",
    "err=0.0; l_rate=0.01\n",
    "for i in xrange(len(X)):\n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999:\n",
    "        print (\"Error: {:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'e', 'n', '?', ' ', 'I', 's']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)\n",
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)\n",
    "act = np.argmax(X[6], axis=1)\n",
    "\n",
    "actual = [indices_char[o] for o in act]\n",
    "prediction = [indices_char[o] for o in pred]\n",
    "\n",
    "print(actual)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Restarting Jupyter Kernel between this and bottom runs for full isolation.\n",
    "\n",
    "-----\n",
    "\n",
    "## Successful Theano RNN run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n",
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "# %matplotlib inline # this line doesn't affect result\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join('../utils'))\n",
    "# import utils; reload(utils) # this line doesn't affect result\n",
    "from utils import *\n",
    "from __future__ import division, print_function # <<<--- here's the magical line\n",
    "\n",
    "\n",
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)\n",
    "\n",
    "\n",
    "chars.insert(0, \"\\0\")\n",
    "# ''.join(chars[1:-6])\n",
    "\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "\n",
    "idx = [char_indices[c] for c in text]\n",
    "# the 1st 10 characters:\n",
    "# idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = 8 # use 8 characters to predict the 9th\n",
    "\n",
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "\n",
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WayNoxchi/Miniconda3/Theano/theano/tensor/basic.py:5130: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:25.178\n",
      "Error:21.430\n",
      "Error:20.898\n",
      "Error:19.878\n",
      "Error:18.802\n",
      "Error:19.265\n",
      "Error:19.050\n",
      "Error:18.418\n",
      "Error:17.950\n",
      "Error:18.213\n",
      "Error:17.478\n",
      "Error:17.620\n",
      "Error:18.383\n",
      "Error:17.275\n",
      "Error:16.774\n",
      "Error:17.742\n",
      "Error:17.418\n",
      "Error:17.178\n",
      "Error:16.817\n",
      "Error:16.673\n",
      "Error:16.525\n",
      "Error:16.417\n",
      "Error:16.705\n",
      "Error:16.162\n",
      "Error:16.724\n",
      "Error:16.547\n",
      "Error:16.068\n",
      "Error:16.220\n",
      "Error:16.217\n",
      "Error:16.437\n",
      "Error:16.679\n",
      "Error:16.384\n",
      "Error:16.601\n",
      "Error:16.303\n",
      "Error:15.988\n",
      "Error:16.744\n",
      "Error:15.991\n",
      "Error:16.337\n",
      "Error:16.034\n",
      "Error:16.263\n",
      "Error:15.312\n",
      "Error:15.717\n",
      "Error:15.735\n",
      "Error:16.018\n",
      "Error:15.998\n",
      "Error:15.845\n",
      "Error:15.624\n",
      "Error:16.066\n",
      "Error:15.917\n",
      "Error:16.007\n",
      "Error:15.228\n",
      "Error:15.536\n",
      "Error:14.973\n",
      "Error:14.809\n",
      "Error:15.601\n",
      "Error:15.318\n",
      "Error:14.675\n",
      "Error:15.446\n",
      "Error:15.087\n",
      "Error:14.910\n",
      "Error:15.058\n",
      "Error:15.369\n",
      "Error:15.296\n",
      "Error:15.039\n",
      "Error:14.748\n",
      "Error:14.846\n",
      "Error:14.307\n",
      "Error:14.751\n",
      "Error:15.189\n",
      "Error:14.778\n",
      "Error:15.092\n",
      "Error:14.675\n",
      "Error:14.383\n",
      "Error:14.463\n",
      "Error:14.454\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 256; n_fac = 42; cs = 8\n",
    "\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size\n",
    "\n",
    "def init_wgts(rows, cols): \n",
    "    scale = math.sqrt(2/rows) # 1st calc Glorot number to scale weights\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))\n",
    "def init_bias(rows): \n",
    "    return shared(np.zeros(rows, dtype=np.float32))\n",
    "def wgts_and_bias(n_in, n_out): \n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n): \n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)\n",
    "\n",
    "# Theano variables\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]\n",
    "\n",
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))\n",
    "\n",
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)\n",
    "\n",
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp,\n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)\n",
    "\n",
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)\n",
    "\n",
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)\n",
    "\n",
    "# we're finally ready to compile the function!:\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)\n",
    "\n",
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape\n",
    "\n",
    "err=0.0; l_rate=0.01\n",
    "for i in xrange(len(X)):\n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999:\n",
    "        print (\"Error:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'e', 'n', '?', ' ', 'I', 's']\n",
      "['h', 'e', ' ', ' ', ' ', 'I', 't', ' ']\n"
     ]
    }
   ],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)\n",
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)\n",
    "act = np.argmax(X[6], axis=1)\n",
    "\n",
    "actual = [indices_char[o] for o in act]\n",
    "prediction = [indices_char[o] for o in pred]\n",
    "\n",
    "print(actual)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q E D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
