{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "from imposm.parser import OSMParser\n",
    "import json\n",
    "from matplotlib import collections as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from numpy import nan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import requests\n",
    "import scipy as sp\n",
    "import rtree\n",
    "# import seaborn as sb\n",
    "from scipy import signal\n",
    "# import shapely\n",
    "import shapely.geometry\n",
    "%pylab inline\n",
    "\n",
    "import data_munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride Report Method\n",
    "\n",
    "Here, we use the `match` method from the OSRM API with the code modified to return only the endpoints of segments. This allows us to aggregate over OSM segments since the node IDs are uniquely associated with a lat/lon pair given sufficient precision in the returned coordinates. The API recommends not using every single value for the match method, but I'm giving them regardless because it's easier to code. Down-sampling the ride might actually help to smooth some of the rides. (or perhaps not if we accidentally get a jagged part).\n",
    "\n",
    "Currently, I am unsure how to mark up OSM data with bumpiness information, as we have \n",
    "data that look like this in the raw OSM file:\n",
    "\n",
    "\n",
    "``\n",
    "        <way id=\"23642309\" version=\"25\" timestamp=\"2013-12-26T23:03:24Z\" changeset=\"19653154\" uid=\"28775\" user=\"StellanL\">\n",
    "                <nd ref=\"258965973\"/>\n",
    "                <nd ref=\"258023463\"/>\n",
    "                <nd ref=\"736948618\"/>\n",
    "                <nd ref=\"258023391\"/>\n",
    "                <nd ref=\"736948622\"/>\n",
    "                <nd ref=\"930330659\"/>\n",
    "                <nd ref=\"736861978\"/>\n",
    "                <nd ref=\"930330542\"/>\n",
    "                <nd ref=\"930330544\"/>\n",
    "                <nd ref=\"929808660\"/>\n",
    "                <nd ref=\"736934948\"/>\n",
    "                <nd ref=\"930330644\"/>\n",
    "                <nd ref=\"736871567\"/>\n",
    "                <nd ref=\"619628331\"/>\n",
    "                <nd ref=\"740363293\"/>\n",
    "                <nd ref=\"931468900\"/>\n",
    "                <tag k=\"name\" v=\"North Wabash Avenue\"/>\n",
    "                <tag k=\"highway\" v=\"tertiary\"/>\n",
    "                <tag k=\"loc_ref\" v=\"44 E\"/>\n",
    "        </way>\"\n",
    "``\n",
    "\n",
    "\n",
    "My tentative idea is to match up the lat/lons with OSM id using IMPOSM, then find the `nd refs` in the original data and add a property that contains bumpiness information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rides, readings = data_munging.read_raw_data()\n",
    "readings = data_munging.clean_readings(readings)\n",
    "readings = data_munging.add_proj_to_readings(readings, data_munging.NAD83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using a Dockerized OSRM instance, you can get the IP address by linking up to the Docker container running OSRM and pinging it. Usually though, the url here will be correct since it is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digital_ocean_url = 'http://162.243.23.60/osrm-chi-vanilla/'\n",
    "local_docker_url = 'http://172.17.0.2:5000/'\n",
    "url = local_docker_url\n",
    "nearest_request = url + 'nearest?loc={0},{1}'\n",
    "match_request = url + 'match?loc={0},{1}&t={2}&loc={3},{4}&t={5}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readings_to_match_str(readings):\n",
    "    data_str = '&loc={0},{1}&t={2}'\n",
    "    output_str = ''\n",
    "    elapsed_time = 0\n",
    "    for i, reading in readings.iterrows():\n",
    "        elapsed_time += 1\n",
    "        new_str = data_str.format(str(reading['start_lat']), str(reading['start_lon']), str(elapsed_time))\n",
    "        output_str += new_str\n",
    "    return url + 'match?' + output_str[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small example of how everything should work for troubleshooting and other purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_request = readings_to_match_str(readings.loc[readings['ride_id'] == 128,  :])\n",
    "print(test_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched_ride = requests.get(test_request).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapped_points =  pd.DataFrame(matched_ride['matchings'][0]['matched_points'], columns=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = snapped_points.plot(x='lon', y='lat', kind='scatter')\n",
    "readings.loc[readings['ride_id'] == 128,  :].plot(x='start_lon', y='start_lat', kind='scatter', ax=ax)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_reading = readings.loc[0, :]\n",
    "test_match_request = match_request.format(a_reading['start_lat'],\n",
    "                                      a_reading['start_lon'], \n",
    "                                      0,\n",
    "                                      a_reading['end_lat'],\n",
    "                                      a_reading['end_lon'],\n",
    "                                      1)\n",
    "# This does not work because OSRM does not accept floats as times. \n",
    "# test_map_request = map_request.format(*tuple(a_reading[['start_lat', 'start_lon', 'start_time',\n",
    "#                                                 'end_lat', 'end_lon', 'end_time']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_nearest_request = nearest_request.format(a_reading['start_lat'], a_reading['start_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osrm_response = requests.get(test_match_request).json()\n",
    "osrm_response['matchings'][0]['matched_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osrm_response = requests.get(test_nearest_request).json()\n",
    "osrm_response['mapped_coordinate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readings['snapped_lat'] = 0\n",
    "readings['snapped_lon'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi_readings = data_munging.filter_readings_to_chicago(readings)\n",
    "chi_rides = list(set(chi_readings.ride_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a small list of rides that I think are bad based upon their graphs.\n",
    "# I currently do not have an automatic way to update this.\n",
    "bad_rides = [128, 129, 5.0, 7.0, 131, 133, 34, 169]\n",
    "good_chi_rides = [i for i in chi_rides if i not in bad_rides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ride_id in chi_rides:\n",
    "    if ride_id in bad_rides:\n",
    "        print('ride_id')\n",
    "        try:\n",
    "            print('num readings: ' + str(sum(readings['ride_id'] == ride_id)))\n",
    "        except:\n",
    "            print('we had some issues here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_snapped_points = []\n",
    "readings['snapped_lat'] = np.NaN\n",
    "readings['snapped_lon'] = np.NaN\n",
    "for ride_id in chi_rides:\n",
    "    if pd.notnull(ride_id):\n",
    "        ax = readings.loc[readings['ride_id'] == ride_id, :].plot(x='start_lon', y='start_lat')\n",
    "        try:\n",
    "            matched_ride = requests.get(readings_to_match_str(readings.loc[readings['ride_id'] == ride_id,  :])).json() \n",
    "            readings.loc[readings['ride_id'] == ride_id, ['snapped_lat', 'snapped_lon']] = matched_ride['matchings'][0]['matched_points']\n",
    "            readings.loc[readings['ride_id'] == ride_id, :].plot(x='snapped_lon', y='snapped_lat', ax=ax)\n",
    "        except:\n",
    "            print('could not snap')\n",
    "        plt.title('Plotting Ride ' + str(ride_id))\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = readings.loc[readings['ride_id'] == 2, :].plot(x='snapped_lon', y='snapped_lat', style='r-')\n",
    "for ride_id in good_chi_rides:\n",
    "    print(ride_id)\n",
    "    try:\n",
    "#         readings.loc[readings['ride_id'] == ride_id, :].plot(x='start_lon', y='start_lat', ax=ax)\n",
    "        readings.loc[readings['ride_id'] == ride_id, :].plot(x='snapped_lon', y='snapped_lat', ax=ax, style='b-')\n",
    "    except:\n",
    "        print('bad')\n",
    "ax = readings.loc[readings['ride_id'] == 2, :].plot(x='snapped_lon', y='snapped_lat', style='r-', ax=ax)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(36, 36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code goes through a ride backwards in order to figure out what two endpoints \n",
    "# the bicycle was going between.\n",
    "readings['next_snapped_lat'] = np.NaN\n",
    "readings['next_snapped_lon'] = np.NaN\n",
    "for ride_id in chi_rides:\n",
    "    next_lat_lon = (np.NaN, np.NaN)\n",
    "    for index, row in reversed(list(readings.loc[readings['ride_id'] == ride_id, :].iterrows())):\n",
    "        readings.loc[index, ['next_snapped_lat', 'next_snapped_lon']] = next_lat_lon\n",
    "        if (row['snapped_lat'], row['snapped_lon']) != next_lat_lon:\n",
    "            next_lat_lon = (row['snapped_lat'], row['snapped_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_chi_readings = readings.loc[[ride_id in chi_rides for ride_id in readings['ride_id']], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_chi_readings.to_csv(data_munging.data_dir + 'clean_chi_readings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_chi_readings = pd.read_csv(data_munging.data_dir + 'clean_chi_readings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road_bumpiness = collections.defaultdict(list)\n",
    "for index, reading in clean_chi_readings.iterrows():\n",
    "    if reading['gps_mph'] < 30 and reading['gps_mph'] > 3:\n",
    "        osm_segment = [(reading['snapped_lat'], reading['snapped_lon']),\n",
    "                      (reading['next_snapped_lat'], reading['next_snapped_lon'])]\n",
    "        osm_segment = sorted(osm_segment)\n",
    "        if all([lat_lon != (np.NaN, np.NaN) for lat_lon in osm_segment]):\n",
    "            road_bumpiness[tuple(osm_segment)].append(reading['abs_mean_over_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted_road_bumpiness = sorted(road_bumpiness.items(), key=lambda i: len(i[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_road_readings = dict((osm_segment, len(road_bumpiness[osm_segment])) for osm_segment in road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = dict((osm_segment, np.mean(road_bumpiness[osm_segment])) for osm_segment in road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_path = data_munging.data_dir + 'agg_road_bumpiness.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section here functions as a shortcut if you just want to load up the aggregate bumpiness instead of \n",
    "having to calculate all of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(agg_path, 'w') as f:\n",
    "    f.write(str(agg_road_bumpiness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(agg_path, 'r') as f:\n",
    "    agg_road_bumpiness = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = eval(agg_road_bumpiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def osm_segment_is_null(osm_segment):\n",
    "    return (pd.isnull(osm_segment[0][0])\n",
    "            or pd.isnull(osm_segment[0][1])\n",
    "            or pd.isnull(osm_segment[1][0])\n",
    "            or pd.isnull(osm_segment[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_road_bumpiness = dict((osm_segment, agg_road_bumpiness[osm_segment]) for osm_segment in agg_road_bumpiness if not osm_segment_is_null(osm_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is where we filter out all osm segments that are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_seg_dist(lat_lon):\n",
    "    return data_munging.calc_dist(lat_lon[0][1], lat_lon[0][0], lat_lon[1][1], lat_lon[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seg_dist = dict()\n",
    "for lat_lon in agg_road_bumpiness:\n",
    "    seg_dist[lat_lon] = data_munging.calc_dist(lat_lon[0][1], lat_lon[0][0], lat_lon[1][1], lat_lon[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../dat/chi_agg_info.csv', 'w') as f:\n",
    "    f.write('lat_lon_tuple|agg_road_bumpiness|total_road_readings|seg_dist\\n')\n",
    "    for lat_lon in agg_road_bumpiness:\n",
    "        if data_munging.calc_dist(lat_lon[0][1], lat_lon[0][0], lat_lon[1][1], lat_lon[1][0]) < 200:\n",
    "            f.write(str(lat_lon) + '|' + str(agg_road_bumpiness[lat_lon])\n",
    "                    + '|'  + str(total_road_readings[lat_lon])\n",
    "                    + '|' + str(seg_dist[lat_lon]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seg_dist[lat_lon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(agg_road_bumpiness.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(agg_road_bumpiness.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plasma = cm = plt.get_cmap('plasma')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=1.0)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for osm_segment, bumpiness in agg_road_bumpiness.items():\n",
    "#     lat_lon = osm_segment\n",
    "#     color = (1, 0, 0) if data_munging.calc_dist(lat_lon[0][1], lat_lon[0][0], lat_lon[1][1], lat_lon[1][0]) > 100 else (0, 1, 0)\n",
    "    plt.plot([osm_segment[0][1], osm_segment[1][1]],\n",
    "             [osm_segment[0][0], osm_segment[1][0]],\n",
    "#              color=color)\n",
    "             color=scalarMap.to_rgba(bumpiness))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(24, 48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_agg_bumpiness = dict((lat_lon, agg_road_bumpiness[lat_lon])\n",
    "                               for lat_lon in agg_road_bumpiness if find_seg_dist(lat_lon) < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(data_dir + 'filtered_chi_road_bumpiness.txt', 'w') as f:\n",
    "    f.write(str(filtered_agg_bumpiness))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
