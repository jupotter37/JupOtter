{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): spacy in /Users/johria/anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/johria/anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): thinc<5.1.0,>=5.0.0 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cloudpickle in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): sputnik<0.10.0,>=0.9.2 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): preshed<0.47,>=0.46.1 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cymem<1.32,>=1.30 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): plac in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): murmurhash<0.27,>=0.26 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.7 in /Users/johria/anaconda3/lib/python3.5/site-packages (from spacy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): semver in /Users/johria/anaconda3/lib/python3.5/site-packages (from sputnik<0.10.0,>=0.9.2->spacy)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Spacy Documentation](https://spacy.io/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is an NLP/Computational Linguistics package built from the ground up. It's written in Cython so it's fast!!\n",
    "\n",
    "Let's check it out. Here's some text from [Alice in Wonderland](https://www.gutenberg.org/files/11/11-h/11-h.htm) free on Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"'Please would you tell me,' said Alice, a little timidly, for she was not quite sure whether it was good manners for her to speak first, 'why your cat grins like that?'\n",
    "'It's a Cheshire cat,' said the Duchess, 'and that's why. Pig!'\n",
    "She said the last word with such sudden violence that Alice quite jumped; but she saw in another moment that it was addressed to the baby, and not to her, so she took courage, and went on again:—\n",
    "'I didn't know that Cheshire cats always grinned; in fact, I didn't know that cats could grin.'\n",
    "'They all can,' said the Duchess; 'and most of 'em do.'\n",
    "'I don't know of any that do,' Alice said very politely, feeling quite pleased to have got into a conversation.\n",
    "'You don't know much,' said the Duchess; 'and that's a fact.'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the model. SpaCy has an excellent English NLP processor. It has the following features which we shall explore:\n",
    "- Entity recognition\n",
    "- Dependency Parsing\n",
    "- Part of Speech tagging\n",
    "- Word Vectorization\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "- Noun Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Model, it may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.en.download\n",
    "# spacy.en.download.main()\n",
    "processor = spacy.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please would you tell me,' said Alice, a little timidly, for she was not quite sure whether it was good manners for her to speak first, 'why your cat grins like that?'\n",
       "'It's a Cheshire cat,' said the Duchess, 'and that's why. Pig!'\n",
       "She said the last word with such sudden violence that Alice quite jumped; but she saw in another moment that it was addressed to the baby, and not to her, so she took courage, and went on again:—\n",
       "'I didn't know that Cheshire cats always grinned; in fact, I didn't know that cats could grin.'\n",
       "'They all can,' said the Duchess; 'and most of 'em do.'\n",
       "'I don't know of any that do,' Alice said very politely, feeling quite pleased to have got into a conversation.\n",
       "'You don't know much,' said the Duchess; 'and that's a fact.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text = processor(text)\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the same text? Let's dig a little deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 'Please would you tell me,' said Alice, a little timidly, for she was not quite sure whether it was good manners for her to speak first, 'why your cat grins like that?'\n",
      "'It's a Cheshire cat\n",
      "1 ,' said the Duchess, 'and that's why.\n",
      "2 Pig!'\n",
      "\n",
      "3 She said the last word with such sudden violence that Alice quite jumped; but she saw in another moment that it was addressed to the baby, and not to her, so she took courage, and went on again:—\n",
      "'I didn't know that Cheshire cats always grinned; in fact, I didn't know that cats could grin.'\n",
      "'They all can,' said the Duchess; 'and most of 'em do.'\n",
      "'I don't know of any that do,'\n",
      "4 Alice said very politely, feeling quite pleased to have got into a conversation.\n",
      "'\n",
      "5 You don't know much,' said the Duchess; 'and that's a fact.'\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for sentence in processed_text.sents:\n",
    "    print(n, sentence)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words and Punctuation - Along with POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ' PUNCT '\n",
      "1 Please INTJ please\n",
      "2 would VERB would\n",
      "3 you PRON you\n",
      "4 tell VERB tell\n",
      "5 me PRON me\n",
      "6 , PUNCT ,\n",
      "7 ' PUNCT '\n",
      "8 said VERB say\n",
      "9 Alice PROPN alice\n",
      "10 , PUNCT ,\n",
      "11 a DET a\n",
      "12 little ADJ little\n",
      "13 timidly ADV timidly\n",
      "14 , PUNCT ,\n",
      "15 for ADP for\n",
      "16 she PRON she\n",
      "17 was VERB be\n",
      "18 not ADV not\n",
      "19 quite ADV quite\n",
      "20 sure ADJ sure\n",
      "21 whether ADP whether\n",
      "22 it PRON it\n",
      "23 was VERB be\n",
      "24 good ADJ good\n",
      "25 manners NOUN manner\n",
      "26 for ADP for\n",
      "27 her PRON her\n",
      "28 to PART to\n",
      "29 speak VERB speak\n",
      "30 first ADV first\n",
      "31 , PUNCT ,\n",
      "32 ' PUNCT '\n",
      "33 why ADV why\n",
      "34 your ADJ your\n",
      "35 cat NOUN cat\n",
      "36 grins VERB grin\n",
      "37 like ADP like\n",
      "38 that DET that\n",
      "39 ? PUNCT ?\n",
      "40 ' PUNCT '\n",
      "41 \n",
      " SPACE \n",
      "\n",
      "42 ' PUNCT '\n",
      "43 It PRON it\n",
      "44 's VERB '\n",
      "45 a DET a\n",
      "46 Cheshire PROPN cheshire\n",
      "47 cat NOUN cat\n",
      "48 , PUNCT ,\n",
      "49 ' PUNCT '\n",
      "50 said VERB say\n",
      "51 the DET the\n",
      "52 Duchess PROPN duchess\n",
      "53 , PUNCT ,\n",
      "54 ' PUNCT '\n",
      "55 and CONJ and\n",
      "56 that DET that\n",
      "57 's VERB '\n",
      "58 why ADV why\n",
      "59 . PUNCT .\n",
      "60 Pig PROPN pig\n",
      "61 ! PUNCT !\n",
      "62 ' PUNCT '\n",
      "63 \n",
      " SPACE \n",
      "\n",
      "64 She PRON she\n",
      "65 said VERB say\n",
      "66 the DET the\n",
      "67 last ADJ last\n",
      "68 word NOUN word\n",
      "69 with ADP with\n",
      "70 such ADJ such\n",
      "71 sudden ADJ sudden\n",
      "72 violence NOUN violence\n",
      "73 that ADJ that\n",
      "74 Alice PROPN alice\n",
      "75 quite ADV quite\n",
      "76 jumped VERB jump\n",
      "77 ; PUNCT ;\n",
      "78 but CONJ but\n",
      "79 she PRON she\n",
      "80 saw VERB saw\n",
      "81 in ADP in\n",
      "82 another DET another\n",
      "83 moment NOUN moment\n",
      "84 that ADJ that\n",
      "85 it PRON it\n",
      "86 was VERB be\n",
      "87 addressed VERB address\n",
      "88 to ADP to\n",
      "89 the DET the\n",
      "90 baby NOUN baby\n",
      "91 , PUNCT ,\n",
      "92 and CONJ and\n",
      "93 not ADV not\n",
      "94 to ADP to\n",
      "95 her PRON her\n",
      "96 , PUNCT ,\n",
      "97 so ADV so\n",
      "98 she PRON she\n",
      "99 took VERB take\n",
      "100 courage NOUN courage\n",
      "101 , PUNCT ,\n",
      "102 and CONJ and\n",
      "103 went VERB go\n",
      "104 on ADP on\n",
      "105 again:— PROPN again:—\n",
      "106 \n",
      " SPACE \n",
      "\n",
      "107 ' PUNCT '\n",
      "108 I PRON i\n",
      "109 did VERB do\n",
      "110 n't ADV not\n",
      "111 know VERB know\n",
      "112 that ADP that\n",
      "113 Cheshire PROPN cheshire\n",
      "114 cats NOUN cat\n",
      "115 always ADV always\n",
      "116 grinned VERB grin\n",
      "117 ; PUNCT ;\n",
      "118 in ADP in\n",
      "119 fact NOUN fact\n",
      "120 , PUNCT ,\n",
      "121 I PRON i\n",
      "122 did VERB do\n",
      "123 n't ADV not\n",
      "124 know VERB know\n",
      "125 that ADP that\n",
      "126 cats NOUN cat\n",
      "127 could VERB could\n",
      "128 grin VERB grin\n",
      "129 . PUNCT .\n",
      "130 ' PUNCT '\n",
      "131 \n",
      " SPACE \n",
      "\n",
      "132 ' PUNCT '\n",
      "133 They PRON they\n",
      "134 all DET all\n",
      "135 can VERB can\n",
      "136 , PUNCT ,\n",
      "137 ' PUNCT '\n",
      "138 said VERB say\n",
      "139 the DET the\n",
      "140 Duchess NOUN duchess\n",
      "141 ; PUNCT ;\n",
      "142 ' PUNCT '\n",
      "143 and CONJ and\n",
      "144 most ADJ most\n",
      "145 of ADP of\n",
      "146 'em PRON 'em\n",
      "147 do VERB do\n",
      "148 . PUNCT .\n",
      "149 ' PUNCT '\n",
      "150 \n",
      " SPACE \n",
      "\n",
      "151 ' PUNCT '\n",
      "152 I PRON i\n",
      "153 do VERB do\n",
      "154 n't ADV not\n",
      "155 know VERB know\n",
      "156 of ADP of\n",
      "157 any DET any\n",
      "158 that ADJ that\n",
      "159 do VERB do\n",
      "160 , PUNCT ,\n",
      "161 ' PUNCT '\n",
      "162 Alice PROPN alice\n",
      "163 said VERB say\n",
      "164 very ADV very\n",
      "165 politely ADV politely\n",
      "166 , PUNCT ,\n",
      "167 feeling VERB feel\n",
      "168 quite ADV quite\n",
      "169 pleased ADJ pleased\n",
      "170 to PART to\n",
      "171 have VERB have\n",
      "172 got VERB get\n",
      "173 into ADP into\n",
      "174 a DET a\n",
      "175 conversation NOUN conversation\n",
      "176 . PUNCT .\n",
      "177 \n",
      " SPACE \n",
      "\n",
      "178 ' PUNCT '\n",
      "179 You PRON you\n",
      "180 do VERB do\n",
      "181 n't ADV not\n",
      "182 know VERB know\n",
      "183 much ADJ much\n",
      "184 , PUNCT ,\n",
      "185 ' PUNCT '\n",
      "186 said VERB say\n",
      "187 the DET the\n",
      "188 Duchess NOUN duchess\n",
      "189 ; PUNCT ;\n",
      "190 ' PUNCT '\n",
      "191 and CONJ and\n",
      "192 that DET that\n",
      "193 's VERB '\n",
      "194 a DET a\n",
      "195 fact NOUN fact\n",
      "196 . PUNCT .\n",
      "197 ' PUNCT '\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for sentence in processed_text.sents:\n",
    "    for token in sentence:\n",
    "        print(n, token, token.pos_, token.lemma_)\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities - [Explanation of Entity Types](https://spacy.io/docs#annotation-ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice PERSON\n",
      "first ORDINAL\n",
      "Cheshire GPE\n",
      "Alice PERSON\n",
      "Cheshire GPE\n",
      "Alice PERSON\n"
     ]
    }
   ],
   "source": [
    "for entity in processed_text.ents:\n",
    "    print(entity, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you\n",
      "me\n",
      "Alice\n",
      "she\n",
      "it\n",
      "good manners\n",
      "her\n",
      "your cat\n",
      "It\n",
      "a Cheshire cat\n",
      "the Duchess\n",
      "She\n",
      "the last word\n",
      "such sudden violence\n",
      "Alice\n",
      "she\n",
      "another moment\n",
      "it\n",
      "the baby\n",
      "her\n",
      "she\n",
      "courage\n",
      "again:—\n",
      "I\n",
      "Cheshire cats\n",
      "fact\n",
      "I\n",
      "cats\n",
      "They\n",
      "the Duchess\n",
      "'em\n",
      "I\n",
      "Alice\n",
      "a conversation\n",
      "You\n",
      "the Duchess\n",
      "a fact\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in processed_text.noun_chunks:\n",
    "    print(noun_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Semi Holy Grail - Syntactic Depensy Parsing [See Demo for clarity](https://spacy.io/demos/displacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr_tree(word, level):\n",
    "    if word.is_punct:\n",
    "        return\n",
    "    for child in word.lefts:\n",
    "        pr_tree(child, level+1)\n",
    "    print('\\t'* level + word.text + ' - ' + word.dep_)\n",
    "    for child in word.rights:\n",
    "        pr_tree(child, level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPlease - intj\n",
      "\t\twould - aux\n",
      "\t\tyou - nsubj\n",
      "\ttell - ccomp\n",
      "\t\tme - dobj\n",
      "said - ROOT\n",
      "\tAlice - nsubj\n",
      "\t\t\ta - det\n",
      "\t\tlittle - npadvmod\n",
      "\ttimidly - advmod\n",
      "\t\tfor - mark\n",
      "\t\tshe - nsubj\n",
      "\twas - advcl\n",
      "\t\tnot - neg\n",
      "\t\t\tquite - advmod\n",
      "\t\tsure - acomp\n",
      "\t\t\t\twhether - mark\n",
      "\t\t\t\tit - nsubj\n",
      "\t\t\twas - ccomp\n",
      "\t\t\t\t\tgood - amod\n",
      "\t\t\t\tmanners - attr\n",
      "\t\t\t\t\t\tfor - mark\n",
      "\t\t\t\t\t\ther - nsubj\n",
      "\t\t\t\t\t\tto - aux\n",
      "\t\t\t\t\tspeak - relcl\n",
      "\t\t\t\t\t\tfirst - advmod\n",
      "\t\twhy - advmod\n",
      "\t\t\tyour - poss\n",
      "\t\tcat - nsubj\n",
      "\tgrins - ccomp\n",
      "\t\tlike - prep\n",
      "\t\t\tthat - pobj\n",
      "\t\tIt - nsubj\n",
      "\t's - ccomp\n",
      "\t\t\ta - det\n",
      "\t\t\tCheshire - compound\n",
      "\t\tcat - attr\n",
      "-------------------------------------------\n",
      "said - ROOT\n",
      "\t\tthe - det\n",
      "\tDuchess - nsubj\n",
      "\t\tand - cc\n",
      "\t\tthat - nsubj\n",
      "\t's - conj\n",
      "\t\twhy - ccomp\n",
      "-------------------------------------------\n",
      "Pig - ROOT\n",
      "-------------------------------------------\n",
      "\tShe - nsubj\n",
      "said - ROOT\n",
      "\t\tthe - det\n",
      "\t\tlast - amod\n",
      "\tword - dobj\n",
      "\t\twith - prep\n",
      "\t\t\t\tsuch - amod\n",
      "\t\t\t\tsudden - amod\n",
      "\t\t\tviolence - pobj\n",
      "\t\t\tthat - nsubj\n",
      "\t\t\tAlice - nsubj\n",
      "\t\t\tquite - advmod\n",
      "\t\tjumped - relcl\n",
      "\tbut - cc\n",
      "\t\tshe - nsubj\n",
      "\tsaw - conj\n",
      "\t\tin - prep\n",
      "\t\t\t\tanother - det\n",
      "\t\t\tmoment - pobj\n",
      "\t\t\tthat - mark\n",
      "\t\t\tit - nsubjpass\n",
      "\t\t\twas - auxpass\n",
      "\t\taddressed - ccomp\n",
      "\t\t\tto - prep\n",
      "\t\t\t\t\tthe - det\n",
      "\t\t\t\tbaby - pobj\n",
      "\t\t\tand - cc\n",
      "\t\t\t\tnot - neg\n",
      "\t\t\tto - conj\n",
      "\t\t\t\ther - pobj\n",
      "\t\tso - advmod\n",
      "\t\tshe - nsubj\n",
      "\ttook - conj\n",
      "\t\tcourage - dobj\n",
      "\t\tand - cc\n",
      "\t\twent - conj\n",
      "\t\t\ton - prep\n",
      "\t\t\t\tagain:— - pobj\n",
      "\t\t\t\t\t\n",
      " - \n",
      "\t\t\tI - nsubj\n",
      "\t\t\tdid - aux\n",
      "\t\t\tn't - neg\n",
      "\t\tknow - conj\n",
      "\t\t\t\tthat - mark\n",
      "\t\t\t\t\tCheshire - compound\n",
      "\t\t\t\tcats - nsubj\n",
      "\t\t\t\talways - advmod\n",
      "\t\t\tgrinned - ccomp\n",
      "\t\tin - prep\n",
      "\t\t\tfact - pobj\n",
      "\t\tI - nsubj\n",
      "\t\tdid - aux\n",
      "\t\tn't - neg\n",
      "\tknow - ccomp\n",
      "\t\t\tthat - mark\n",
      "\t\t\tcats - nsubj\n",
      "\t\t\tcould - aux\n",
      "\t\tgrin - ccomp\n",
      "\t\tThey - nsubj\n",
      "\t\t\tall - appos\n",
      "\tcan - ccomp\n",
      "\tsaid - conj\n",
      "\t\t\tthe - det\n",
      "\t\tDuchess - dobj\n",
      "\t\tand - cc\n",
      "\t\t\tmost - nsubj\n",
      "\t\t\t\tof - prep\n",
      "\t\t\t\t\t'em - pobj\n",
      "\t\tdo - conj\n",
      "\t\tI - nsubj\n",
      "\t\tdo - aux\n",
      "\t\tn't - neg\n",
      "\tknow - ccomp\n",
      "\t\tof - prep\n",
      "\t\t\tany - pobj\n",
      "\t\t\t\t\tthat - nsubj\n",
      "\t\t\t\tdo - relcl\n",
      "-------------------------------------------\n",
      "\tAlice - nsubj\n",
      "said - ROOT\n",
      "\t\tvery - advmod\n",
      "\tpolitely - advmod\n",
      "\tfeeling - advcl\n",
      "\t\t\tquite - advmod\n",
      "\t\tpleased - acomp\n",
      "\t\t\t\tto - aux\n",
      "\t\t\t\thave - aux\n",
      "\t\t\tgot - xcomp\n",
      "\t\t\t\tinto - prep\n",
      "\t\t\t\t\t\ta - det\n",
      "\t\t\t\t\tconversation - pobj\n",
      "-------------------------------------------\n",
      "\t\tYou - nsubj\n",
      "\t\tdo - aux\n",
      "\t\tn't - neg\n",
      "\tknow - ccomp\n",
      "\t\tmuch - dobj\n",
      "said - ROOT\n",
      "\t\tthe - det\n",
      "\tDuchess - nsubj\n",
      "\tand - cc\n",
      "\t\tthat - nsubj\n",
      "\t's - conj\n",
      "\t\t\ta - det\n",
      "\t\tfact - attr\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in processed_text.sents:\n",
    "    pr_tree(sentence.root, 0)\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is 'nsubj'? 'acomp'? See [The Universal Dependencies](http://universaldependencies.org/u/dep/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorization - [Word2Vec](http://deeplearning4j.org/word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36491481428\n",
      "0.350866559366\n",
      "0.272271037182\n"
     ]
    }
   ],
   "source": [
    "proc_fruits = processor('''I think green apples are delicious. \n",
    "                            While pears have a strange texture to them. \n",
    "                            The bowls they sit in are ugly.''')\n",
    "apples, pears, bowls = proc_fruits.sents\n",
    "fruit = processed_text.vocab['fruit']\n",
    "print(apples.similarity(fruit))\n",
    "print(pears.similarity(fruit))\n",
    "print(bowls.similarity(fruit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment - In Class\n",
    "Find your favorite news source and grab the article text.\n",
    "\n",
    "1. Show the most common words in the article.\n",
    "2. Show the most common words under a part of speech. (i.e. NOUN: {'Bob':12, 'Alice':4,})\n",
    "3. Find a subject/object relationship through the dependency parser in any sentence.\n",
    "4. Show the most common Entities and their types. \n",
    "5. Find Entites and their dependency (hint: entity.root.head)\n",
    "6. Find the most similar words in the article"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
