{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/bike-sharing-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U kaggle\n",
    "# register the token in you kaggle profile & save it to ~/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  sklearn import linear_model\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prevent warining inside sklearn code\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we need custom score function, described in task.\n",
    "https://www.kaggle.com/c/bike-sharing-demand/overview/evaluation\n",
    "\n",
    "* Why do we need +1 in score function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    y_pred_clipped = np.clip(y_pred, 0., None)\n",
    "    return mean_squared_error(np.log1p(y_true), np.log1p(y_pred_clipped)) ** .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What happens without np.clip?\n",
    "\n",
    "Let's start with the exisiting features and simple linear regression.\n",
    "\n",
    "All that feature extractors and grid search would be more clear further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self    \n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[[\"holiday\", \"workingday\", \"season\", \"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('extractor', SimpleFeatureExtractor()), ('regression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=make_scorer(rmsle, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exctractor = SimpleFeatureExtractor()\n",
    "clf = Pipeline([\n",
    "    (\"extractor\", exctractor),\n",
    "    (\"regression\", linear_model.LinearRegression()),\n",
    "])\n",
    "param_grid = {}\n",
    "scorerer = make_scorer(rmsle, greater_is_better=False)\n",
    "researcher = GridSearchCV(clf, param_grid, scoring=scorerer, cv=5, n_jobs=4, verbose=1, refit=False)\n",
    "researcher.fit(df, df[\"count\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Searcher always maximizes the score function, so if we need to decrease it, it just adds the minus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4687746950336822"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add regularization and grid search the hyperparameters\n",
    "\n",
    "Now it's more clear why we have Grid Searcher ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exctractor = SimpleFeatureExtractor()\n",
    "clf = Pipeline([\n",
    "    (\"extractor\", exctractor),\n",
    "    (\"regression\", linear_model.ElasticNet()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('extractor', SimpleFeatureExtractor()), ('regression', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'regression__alpha': array([1.00000e-03, 3.59381e-03, 1.29155e-02, 4.64159e-02, 1.66810e-01,\n",
       "       5.99484e-01, 2.15443e+00, 7.74264e+00, 2.78256e+01, 1.00000e+02]), 'regression__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=make_scorer(rmsle, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"regression__alpha\": np.logspace(-3, 2, 10),\n",
    "    \"regression__l1_ratio\": np.linspace(0, 1, 10)\n",
    "}\n",
    "scorerer = make_scorer(rmsle, greater_is_better=False)\n",
    "researcher = GridSearchCV(clf, param_grid, scoring=scorerer, cv=5, n_jobs=4, verbose=1, refit=False)\n",
    "researcher.fit(df, df[\"count\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4196641068278841"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regression__alpha': 27.825594022071257,\n",
       " 'regression__l1_ratio': 0.3333333333333333}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to add some custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    categorical_columns = [\"week_day\", \"hour\", \"season\", \"weather\"]\n",
    "    numerical_columns = [\"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
    "    \n",
    "    def _add_features(self, X):\n",
    "        X[\"week_day\"] = X.datetime.apply(lambda dttm: parse(dttm).weekday())\n",
    "        X[\"hour\"] = X.datetime.apply(lambda dttm: parse(dttm).hour)\n",
    "        \n",
    "    def _combine(self, *feature_groups):\n",
    "        return np.hstack(feature_groups)\n",
    "    \n",
    "    def collect_stats(self, X):\n",
    "        self._add_features(X)\n",
    "        self.ohe.fit(X[self.categorical_columns])\n",
    "        self.scaler.fit(X[self.numerical_columns])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self    \n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        self._add_features(X)\n",
    "        custom_binary_features = self.ohe.transform(X[self.categorical_columns])\n",
    "        scaled_features = self.scaler.transform(X[self.numerical_columns])\n",
    "        return self._combine(\n",
    "            custom_binary_features, \n",
    "            scaled_features,\n",
    "            X[[\"holiday\", \"workingday\"]].values\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "exctractor = FeatureExtractor()\n",
    "exctractor.collect_stats(df)\n",
    "clf = Pipeline([\n",
    "    (\"extractor\", exctractor),\n",
    "    (\"regression\", linear_model.ElasticNet()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('extractor', FeatureExtractor()), ('regression', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'regression__alpha': array([1.00000e-03, 3.59381e-03, 1.29155e-02, 4.64159e-02, 1.66810e-01,\n",
       "       5.99484e-01, 2.15443e+00, 7.74264e+00, 2.78256e+01, 1.00000e+02]), 'regression__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=make_scorer(rmsle, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"regression__alpha\": np.logspace(-3, 2, 10),\n",
    "    \"regression__l1_ratio\": np.linspace(0, 1, 10)\n",
    "}\n",
    "pd.options.mode.chained_assignment = None\n",
    "scorerer = make_scorer(rmsle, greater_is_better=False)\n",
    "researcher = GridSearchCV(clf, param_grid, scoring=scorerer, cv=5, n_jobs=4, verbose=1, refit=False)\n",
    "researcher.fit(df, df[\"count\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1171565953466736"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regression__alpha': 0.046415888336127795,\n",
       " 'regression__l1_ratio': 0.7777777777777777}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.66559636027856"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorerer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "scores = cross_val_score(clf, df, df[\"count\"].values, cv=5, n_jobs=4, scoring=scorerer)\n",
    "np.mean((-np.array(scores)) ** .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can theoretically get if we optimize RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('extractor', FeatureExtractor()), ('regression', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'regression__alpha': array([1.00000e-03, 3.59381e-03, 1.29155e-02, 4.64159e-02, 1.66810e-01,\n",
       "       5.99484e-01, 2.15443e+00, 7.74264e+00, 2.78256e+01, 1.00000e+02]), 'regression__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=make_scorer(rmse, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"regression__alpha\": np.logspace(-3, 2, 10),\n",
    "    \"regression__l1_ratio\": np.linspace(0, 1, 10)\n",
    "}\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** .5\n",
    "\n",
    "scorerer = make_scorer(rmse, greater_is_better=False)\n",
    "researcher = GridSearchCV(clf, param_grid, scoring=scorerer, cv=5, n_jobs=4, verbose=1, refit=False)\n",
    "researcher.fit(df, df[\"count\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-129.4953879296039"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regression__alpha': 0.01291549665014884,\n",
       " 'regression__l1_ratio': 0.4444444444444444}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 11 min!!! Now we also learn FeaureExtractor every time and the pipeline becomes heavier. Why? Can you speed it up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What was the point about Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The process is described by possion distribution better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Poisson_distribution\n",
    "\n",
    "In probability theory and statistics, the Poisson distribution (French pronunciation: ​[pwasɔ̃]; in English often rendered /ˈpwɑːsɒn/), named after French mathematician Siméon Denis Poisson, is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.[1] The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.\n",
    "\n",
    "\n",
    "The other point of view: we have 200 people with 3% probability to pick up the bike.\n",
    "\n",
    "What about CLT??? It works when $n \\rightarrow \\inf$. For poisson distribution there is a special case called De Moivre–Laplace theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of different kinds of Generalized Linear Regression methods in sklearn: https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "And there is no Poisson regression there.\n",
    "\n",
    "So, let's write a probabilistic model for poisson distribution and optimize maximum likelihood.\n",
    "\n",
    "Hausaufgaben: try to do it.\n",
    "\n",
    "Hint: \n",
    "\n",
    "start from the assumption $\\hat{y} = \\exp{\\langle x, \\theta \\rangle}$ and find the derivative of log-likelihood by $\\theta$. It's zero + check the sign of the second derivative.\n",
    "\n",
    "The conclusion: we can simulate poisson regression with simple wrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson hierarchical regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have issues with np.log(y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "      <th>week_day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datetime, season, holiday, workingday, weather, temp, atemp, humidity, windspeed, casual, registered, count, week_day, hour]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"count\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonRegression(linear_model.ElasticNet):\n",
    "    \n",
    "    def __init__(self, alpha=1.0, l1_ratio=0.5, fit_intercept=True,\n",
    "                 normalize=False, precompute=False, max_iter=1000,\n",
    "                 copy_X=True, tol=1e-4, warm_start=False, positive=False,\n",
    "                 random_state=None, selection='cyclic'):\n",
    "        super().__init__(alpha, l1_ratio, fit_intercept, normalize, precompute, max_iter,\n",
    "                         copy_X, tol, warm_start, positive, random_state, selection)\n",
    "        \n",
    "    def fit(self, X, y, *args):\n",
    "        return super().fit(X, np.log(y), *args)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.exp(super().predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed: 30.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('extractor', FeatureExtractor()), ('regression', PoissonRegression(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "         max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "         random_state=None, selection='cyclic', tol=0.0001,\n",
       "         warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'regression__alpha': array([1.00000e-05, 2.06914e-05, 4.28133e-05, 8.85867e-05, 1.83298e-04,\n",
       "       3.79269e-04, 7.84760e-04, 1.62378e-03, 3.35982e-03, 6.95193e-03,\n",
       "       1.43845e-02, 2.97635e-02, 6.15848e-02, 1.27427e-01, 2.63665e-01,\n",
       "       5.45559e-01, 1.12884e+00, 2.33572e+00, 4.83293e+00, 1.00000e+01]), 'regression__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=make_scorer(rmsle, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exctractor = FeatureExtractor()\n",
    "exctractor.collect_stats(df)\n",
    "clf = Pipeline([\n",
    "    (\"extractor\", exctractor),\n",
    "    (\"regression\", PoissonRegression()),\n",
    "])\n",
    "param_grid = {\n",
    "    \"regression__alpha\": np.logspace(-5, 1, 20),\n",
    "    \"regression__l1_ratio\": np.linspace(0, 1, 10)\n",
    "}\n",
    "pd.options.mode.chained_assignment = None\n",
    "scorerer = make_scorer(rmsle, greater_is_better=False)\n",
    "researcher = GridSearchCV(clf, param_grid, scoring=scorerer, cv=5, n_jobs=4, verbose=1, refit=False)\n",
    "researcher.fit(df, df[\"count\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regression__alpha': 0.001623776739188721,\n",
       " 'regression__l1_ratio': 0.1111111111111111}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7326059519929896"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of MSE the score is worse. But it doesn't mean MSE is the most relevant metric. At least poisson regression never predicts negative values.\n",
    "\n",
    "* When you expect poisson regression to have better MSE score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193.30622303311725"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorerer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "scores = cross_val_score(clf, df, df[\"count\"].values, cv=5, n_jobs=4, scoring=scorerer)\n",
    "np.mean((-np.array(scores)) ** .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skill vs Education\n",
    "\n",
    "When you need to predict counts, try to use Poisson Regression.\n",
    "You can get good enough results with experience, but you can't handle on just your skills when face a new type of tasks. More complicated tasks you have less your previous experience can help you.\n",
    "\n",
    "The key to success is to have good enough education. With education you can do research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "cols = df_test.columns\n",
    "\n",
    "all_data = pd.concat([df[cols], df_test[cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "exctractor = FeatureExtractor()\n",
    "exctractor.collect_stats(all_data)\n",
    "clf = Pipeline([\n",
    "    (\"extractor\", exctractor),\n",
    "    (\"regression\", PoissonRegression(alpha=0.001623776739188721, l1_ratio=0.1111111111111111)),\n",
    "])\n",
    "clf.fit(df, df[\"count\"].values)\n",
    "df_test[\"count\"] = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[\"datetime\",\"count\"]].set_index(\"datetime\").to_csv(\"linear.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -f linear.csv -m \"linear regression\" bike-sharing-demand\n",
    "# score 0.64265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further steps: use Random Forest Regressor & Catboost to get into top 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.kym-cdn.com/photos/images/original/000/517/111/fbd.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
