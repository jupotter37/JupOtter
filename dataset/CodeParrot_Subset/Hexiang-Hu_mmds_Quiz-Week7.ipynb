{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Quiz Week 7B Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.\n",
    "\n",
    "* Compute the Topic-Specific PageRank for the following link topology. Assume that __pages selected for the teleport set are nodes 1 and 2__ and that in the teleport set, the __weight assigned for node 1 is twice that of node 2__. Assume further that the teleport probability, (1 - beta), is 0.3. Which of the following statements is correct?\n",
    " \n",
    "![alt text](otc_pagerank4.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2   0.45  0.35  0.  ]\n",
      " [ 0.9   0.1   0.    0.  ]\n",
      " [ 0.2   0.1   0.    0.7 ]\n",
      " [ 0.2   0.1   0.7   0.  ]]\n",
      "[ 0.25  0.25  0.25  0.25]\n",
      "iteration#1:\n",
      "r_new = [ 0.375   0.1875  0.2625  0.175 ]\n",
      "iteration#2:\n",
      "r_new = [ 0.33125  0.23125  0.25375  0.18375]\n",
      "iteration#3:\n",
      "r_new = [ 0.361875   0.2159375  0.2445625  0.177625 ]\n",
      "iteration#4:\n",
      "r_new = [ 0.35115625  0.22665625  0.25099375  0.17119375]\n",
      "iteration#5:\n",
      "r_new = [ 0.35865937  0.22290469  0.24274031  0.17569562]\n",
      "iteration#6:\n",
      "r_new = [ 0.35603328  0.22553078  0.24851772  0.16991822]\n",
      "iteration#7:\n",
      "r_new = [ 0.35787155  0.22461165  0.2435544   0.1739624 ]\n",
      "iteration#8:\n",
      "r_new = [ 0.35722815  0.22525504  0.24702872  0.17048808]\n",
      "iteration#9:\n",
      "r_new = [ 0.35767853  0.22502985  0.24437151  0.17292011]\n",
      "iteration#10:\n",
      "r_new = [ 0.3575209   0.22518749  0.24623156  0.17106006]\n",
      "iteration#11:\n",
      "r_new = [ 0.35763124  0.22513231  0.24487435  0.17236209]\n",
      "iteration#12:\n",
      "r_new = [ 0.35759262  0.22517093  0.2458244   0.17141205]\n",
      "iteration#13:\n",
      "r_new = [ 0.35761965  0.22515742  0.24514585  0.17207708]\n",
      "iteration#14:\n",
      "r_new = [ 0.35761019  0.22516688  0.24562083  0.1716021 ]\n",
      "iteration#15:\n",
      "r_new = [ 0.35761682  0.22516357  0.24528503  0.17193458]\n",
      "iteration#16:\n",
      "r_new = [ 0.3576145   0.22516589  0.24552009  0.17169952]\n",
      "iteration#17:\n",
      "r_new = [ 0.35761612  0.22516507  0.24535474  0.17186407]\n",
      "iteration#18:\n",
      "r_new = [ 0.35761555  0.22516564  0.24547049  0.17174832]\n",
      "iteration#19:\n",
      "r_new = [ 0.35761595  0.22516544  0.24538927  0.17182934]\n",
      "iteration#20:\n",
      "r_new = [ 0.35761581  0.22516558  0.24544612  0.17177249]\n",
      "iteration#21:\n",
      "r_new = [ 0.35761591  0.22516553  0.24540627  0.17181228]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate topic specific page\n",
    "\n",
    "M = np.array([[0, 0.5, 0.5, 0],\n",
    "              [1,   0,   0, 0],\n",
    "              [0,   0,   0, 1],\n",
    "              [0,   0,   1, 0]\n",
    "            ])\n",
    "p = 0.7\n",
    "\n",
    "teleport_M = np.array([[2.0/3, 1.0/3, 0, 0],\n",
    "                       [2.0/3, 1.0/3, 0, 0],\n",
    "                       [2.0/3, 1.0/3, 0, 0],\n",
    "                       [2.0/3, 1.0/3, 0, 0]\n",
    "                      ])\n",
    "M_after = M*p + (1 - p)* teleport_M;\n",
    "r_old = np.array([ 0.25 for i in xrange(4)])\n",
    "\n",
    "\n",
    "r_1 = np.dot(M_after.T, r_old)\n",
    "r_2 = np.dot(M_after.T, r_1)\n",
    "print M_after\n",
    "print r_old\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    cnt += 1\n",
    "    r_new = np.dot(M_after.T, r_old)\n",
    "    \n",
    "    print \"iteration#{0}:\".format(cnt)\n",
    "    print \"r_new = \" + str(r_new)\n",
    "    if np.sum( np.abs(r_new - r_old) ) < 10**-4 or cnt > 100:\n",
    "        break\n",
    "    \n",
    "    r_old = r_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q2.\n",
    "* The __spam-farm architecture__ described in Section 5.4.1 suffers from the problem that the target page has many links --- __one to each supporting page__. To avoid that problem, the spammer could use the architecture shown below:\n",
    "\n",
    "![alt text](otc_spamfarm1.gif)\n",
    "\n",
    "* There, k \"second-tier\" nodes act as __intermediaries__. The target page t has only to link to __the k second-tier pages__, and each of those pages links to m/k of the __m supporting pages__. Each of the supporting pages links only to t (although most of these links are not shown). Suppose the __taxation parameter is β = 0.85__, and x is the amount of PageRank supplied __from outside to the target page__. Let n be the total number of pages in the Web. Finally, let y be the __PageRank of target page t__. If we compute the formula for y in terms of k, m, and n, we get a formula with the form\n",
    "\n",
    "$$\n",
    "y = a \\cdot x + \\frac{b \\cdot m}{n} + \\frac{c \\cdot k}{n}\n",
    "$$\n",
    "\n",
    "* Note: __To arrive at this form__, it is necessary at the last step to drop a low-order term that is a fraction of 1/n. Determine coefficients a, b, and c, remembering that β is fixed at 0.85. Then, identify the value, correct to two decimal places, for one of these coefficients.\n",
    "\n",
    "\n",
    "\n",
    "* __Hint__: Here is an outline of the solution. \n",
    "    * Use w as the PageRank of each second-tier page and z as the PageRank of each supporting page. \n",
    "    * You can write three equations, one for y in terms of z, one for w in terms of y, and one for z in terms of w. \n",
    "    * For example, y equals x (the PageRank from outside) plus all the untaxed PageRank of each of the m supporting pages (a total of βzm), plus its share of the tax (which is (1-β)/n). \n",
    "    * Discover the equations for w and z, then substitute these in the equation for y to get an equation for y in terms of itself, from which you can solve for y.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2.\n",
    "* Let w be the PageRank of each of the second-tier pages, and let z be the PageRank of each of the supporting pages. Then the equations relating y, w, and z are:\n",
    "    1. $y = x + \\beta \\cdot z \\cdot m + \\frac{ (1 - \\beta) }{n} $\n",
    "    2. $w = \\frac{\\beta \\cdot y}{k} + \\frac{(1 - \\beta)}{n}$\n",
    "    3. $z = \\frac{\\beta \\cdot w \\cdot k}{m} + \\frac{(1 - \\beta)}{n}$\n",
    "\n",
    "\n",
    "* The first equation says that the PageRank of t is the external contribution x, plus βz (the amount of PageRank not taxed) times the number of supporting pages, plus (1-β)/n, which is the share of \"tax\" that every page gets. The second equation says that each second-tier page gets 1/k-th of the untaxed PageRank of t, plus its share of the tax. The third equation says each supporting page gets 1 part in m/k of the untaxed PageRank of the second-tier page that reaches that supporting page, plus its share of the tax.\n",
    "    * Begin by substituting for z in the first equation:\n",
    "        * $y = x + β2*k*w + \\frac{β*(1-β)*m}{n} + \\frac{(1-β)}{n}$\n",
    "\n",
    "    * Now, substitute for w in the above:\n",
    "        * $y = x + β3*y + \\frac{β*(1-β)*m}{n} + \\frac{β2*(1-β)*k}{n} + \\frac{(1-β)}{n}$\n",
    "    * Neglect the last term (1-β)/n, per the directions in the statement of the problem. If we move the term β3y to the left, and note that β3 = (1-β)(1+β+β2), we get\n",
    "        * $y = \\frac{x}{(1-β3)} + \\frac{β}{(1+β+β2)} \\cdot \\frac{m}{n} + \\frac{β}{1+β+β2} \\cdot \\frac{k}{n}$\n",
    "    * For β = 0.85, these coefficients evaluate to:\n",
    "        * y = 2.59x + 0.33(m/n) + 0.28(k/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz - Week7A Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q1.\n",
    "\n",
    "* Suppose we have an LSH family h of __(d1,d2,.6,.4)__ hash functions. We can use __three functions__ from h and the AND-construction to form a (d1,d2,w,x) family, and we can use __two functions from h__ and the OR-construction to form a (d1,d2,y,z) family. Calculate w, x, y, and z, and then identify the correct value of one of these in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 0.216\n",
      "x = 0.064\n",
      "y= 0.84\n",
      "z= 0.64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# And Construction\n",
    "print \"w = {0}\".format(.6 ** 3)\n",
    "print \"x = {0}\".format(.4 ** 3)\n",
    "\n",
    "# Or Construction\n",
    "print \"y= {0}\".format(1 - (1 - .6)**2)\n",
    "print \"z= {0}\".format(1 - (1 - .4)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q2.\n",
    "* Here are eight strings that represent sets:\n",
    "\n",
    "<pre>\n",
    "                                s1 = abcef\n",
    "                                s2 = acdeg\n",
    "                                s3 = bcdefg\n",
    "                                s4 = adfg\n",
    "                                s5 = bcdfgh\n",
    "                                s6 = bceg\n",
    "                                s7 = cdfg\n",
    "                                s8 = abcd\n",
    "</pre>\n",
    "\n",
    "* Suppose our __upper limit on Jaccard distance is 0.2__, and we use the indexing scheme of Section 3.9.4 based on symbols appearing in the prefix (no position or length information). For each of __s1, s3, and s6__, determine __how many other strings that string will be compared with__, if it is used as the __probe__ string. Then, identify the true count from the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1: ab\n",
      "s2: ac\n",
      "s3: bc\n",
      "s4: a\n",
      "s5: bc\n",
      "s6: b\n",
      "s7: c\n",
      "s8: a\n",
      "===========================\n",
      "So we got the group as: \n",
      "a : [s1, s2, s4, s8]\n",
      "b : [s1, s3, s4, s5]\n",
      "c : [s2, s3, s4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "jDist = 0.2\n",
    "def get_symbol(st):\n",
    "    L = len(st)\n",
    "    pLen = int(math.floor(jDist * L)) + 1\n",
    "    return st[:pLen]\n",
    "\n",
    "print \"s1: \" + get_symbol('abcef')\n",
    "print \"s2: \" + get_symbol('acdeg')\n",
    "print \"s3: \" + get_symbol('bcdefg')\n",
    "print \"s4: \" + get_symbol('adfg')\n",
    "print \"s5: \" + get_symbol('bcdfgh')\n",
    "print \"s6: \" + get_symbol('bceg')\n",
    "print \"s7: \" + get_symbol('cdfg')\n",
    "print \"s8: \" + get_symbol('abcd')\n",
    "\n",
    "\n",
    "print \"===========================\\nSo we got the group as: \"\n",
    "print \"a : [s1, s2, s4, s8]\"\n",
    "print \"b : [s1, s3, s4, s5]\"\n",
    "print \"c : [s2, s3, s4]\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Solution2.\n",
    "* First, we index a string of length L on the symbols appearing in its prefix of length floor(0.2L+1). Thus, strings of length 5 and 6 are indexed on their first two symbols, while strings of length 4 are indexed on their first symbol only. Thus, the index for a consists of {s1, s2, s4, s8}; the index for b consists of {s1, s3, s5, s6}, the index for c consists of {s2, s3, s5, s7}, and no other symbol is indexed at all.\n",
    "* For s1, we examine the indexes for a and b, which contains all strings but s7. Thus, s1 is compared with 6 other strings.\n",
    "\n",
    "* For s3, we examine the indexes for b and c, which together contain s1, s2, s3, s5, s6, and s7. Thus, s3 is compared with five other strings.\n",
    "\n",
    "* For s6, we examine only the index for b. Thus, s6 is compared only with the three other strings s1, s3, and s5.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q3.\n",
    "* Consider the link graph\n",
    "\n",
    "![alt text](otc_pagerank4.gif)\n",
    "* First, construct the L, the link matrix, as discussed in Section 5.5 on the HITS algorithm. Then do the following:\n",
    "\n",
    "1. Start by assuming the hubbiness of each node is 1; that is, the vector h is (the transpose of) [1,1,1,1].\n",
    "2. Compute an estimate of the authority vector a=LTh.\n",
    "3. Normalize a by dividing all values so the largest value is 1.\n",
    "4. Compute an estimate of the hubbiness vector h=La.\n",
    "5. Normalize h by dividing all values so the largest value is 1.\n",
    "6. Repeat steps 2-5.\n",
    "7. Now, identify in the list below the true statement about the final estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3.\n",
    "* Here is the matrix L:\n",
    "<pre>\n",
    "            0\t1\t1\t0\n",
    "            1\t0\t0\t0\n",
    "            0\t0\t0\t1\n",
    "            0\t0\t1\t0\n",
    "</pre>\n",
    "\n",
    "* In what follows, all vectors will be written as rows, i.e., in transposed form. We start with h = [1,1,1,1] and compute LTh = [1,1,2,1]. Since the largest value is 2, we divide all values by 2, giving us the first estimate a = [1/2,1/2,1,1/2].\n",
    "\n",
    "* Next, we compute La = [3/2,1/2,1/2,1] and normalize by multiplying by 2/3 to get h = [1,1/3,1/3,2/3].\n",
    "\n",
    "* The next calculation of a from the estimate of h gives LTh = [1/3,1,5/3,1/3], and normalizing gives a = [1/5,3/5,1,1/5].\n",
    "\n",
    "* For the final estimate of h we compute La = [8/5,1/5,1/5,1], which after normalizing gives h = [1,1/8,1/8,5/8].\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Q4.\n",
    "* Consider an implementation of the __Block-Stripe Algorithm__ discussed in Section 5.2 to compute page rank on a graph of N nodes (i.e., Web pages). Suppose each page has, on average, 20 links, and we divide the new rank vector into k blocks (and correspondingly, the matrix M into k stripes). Each stripe of M has one line per \"source\" web page, in the format:\n",
    "                        [source_id, degree, m, dest_1, ...., dest_m]\n",
    "* Notice that we had to add an additional entry, m, to denote the number of destination nodes in this stripe, which of course is no more than the degree of the node. Assume that all entries (scores, degrees, identifiers,...) are encoded using 4 bytes.\n",
    "\n",
    "* There is an additional detail we need to account for, namely, locality of links. As a very simple model, assume that we divide web pages into two disjoint sets:\n",
    "\n",
    "1. __Introvert__ pages, which link only to other pages within the same host as themselves.\n",
    "2. __Extrovert__ pages, which have links to pages across several hosts.\n",
    "* Assume a fraction x of pages (0 Construct a formula that counts the amount of I/O per page rank iteration in terms of N, x, and k. The 4-tuples below list combinations of N, k, x, and I/O (in bytes). Pick the correct combination.\n",
    "* __Note.__ There are some additional optimizations one can think of, such as striping the old score vector, encoding introvert and extrovert pages using different schemes, etc. For the purposes of working this problem, assume we don't do any optimizations beyond the block-stripe algorithm discussed in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Solution4.\n",
    "* The number of bytes involved in __reading the old pagerank vector__ and __writing the new pagerank vector to disk__ = 4 (k+1) N \n",
    "    * For the M matrix: - The introvert pages will appear xN times and each row will have on average 23 entries (3 metadata and 20 destination links). \n",
    "* __Total number of bytes read__ = 4*23 xN \n",
    "    * The extrovert pages will appear (1-x) kN times and each row will have 3 (metadata) + 20/k (destination links) entries on average. \n",
    "* __Total number of bytes read__ = 4 * (3+20/k) * (1-x) kN \n",
    "* __Total I/O per pagerank iteration__ (in GB, where 1GB ~ 10^9 = N bytes) = 4 [(k+1) N + 23 xN + (3k + 20) (1-x) N] / N = 4 [(k+1) + 23 x + (3k + 20) (1-x)] = 4 [21 + k + 3 (x + (1-x) k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
