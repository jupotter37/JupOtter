{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standar usage of TensoFlow with model class\n",
    "\n",
    "Tipically use 3 files:\n",
    " - data_utils.py: With the data access and batch generator functions\n",
    " - model.py: With the class model. A constructor with the graph definition and method to manage model needs\n",
    " - train.py: With parameters. Access to the data, instance the model and train it. Optionaly add a parameter to train or inference.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Access to the data\n",
    "def get_data(data_dir='/tmp/MNIST_data'):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    return input_data.read_data_sets(data_dir, one_hot=True)\n",
    "\n",
    "\n",
    "#Batch generator\n",
    "def batch_generator(mnist, batch_size=256, type='train'):\n",
    "    if type=='train':\n",
    "        return mnist.train.next_batch(batch_size)\n",
    "    else:\n",
    "        return mnist.test.next_batch(batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_mnist_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class mnistCNN(object):\n",
    "    \"\"\"\n",
    "    A NN for mnist classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, dense=500):\n",
    "    \n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.float32, [None, 784], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, 10], name=\"input_y\")\n",
    "    \n",
    "        # First layer\n",
    "        self.dense_1 = self.dense_layer(self.input_x, input_dim=784, output_dim=dense)\n",
    "\n",
    "        # Final layer\n",
    "        self.dense_2 = self.dense_layer(self.dense_1, input_dim=dense, output_dim=10)\n",
    "\n",
    "        self.predictions = tf.argmax(self.dense_2, 1, name=\"predictions\")\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.dense_2, self.input_y))\n",
    "        \n",
    "        # Accuracy\n",
    "        correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "    \n",
    "\n",
    "    def dense_layer(self, x, input_dim=10, output_dim=10, name='dense'):\n",
    "        '''\n",
    "        Dense layer function\n",
    "        Inputs:\n",
    "          x: Input tensor\n",
    "          input_dim: Dimmension of the input tensor.\n",
    "          output_dim: dimmension of the output tensor\n",
    "          name: Layer name\n",
    "        '''\n",
    "        W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name='W_'+name)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[output_dim]), name='b_'+name)\n",
    "        dense_output = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        return dense_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "BATCH_SIZE=256\n",
      "DATA_DIRECTORY=/tmp/MNIST_data\n",
      "DENSE_SIZE=500\n",
      "LEARNING_RATE=0.001\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NUM_EPOCHS=20\n",
      "\n",
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0 0.91909\n",
      "1 0.881748\n",
      "2 0.777025\n",
      "3 0.937195\n",
      "4 0.783779\n",
      "5 0.353136\n",
      "6 0.256104\n",
      "7 0.28514\n",
      "8 0.277642\n",
      "9 0.225344\n",
      "10 0.301154\n",
      "11 0.249453\n",
      "12 0.324219\n",
      "13 0.202852\n",
      "14 0.244397\n",
      "15 0.211011\n",
      "16 0.199964\n",
      "17 0.246017\n",
      "18 0.289519\n",
      "19 0.280718\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from data_utils import get_data, batch_generator\n",
    "#from model_mnist_cnn import mnistCNN\n",
    "\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "tf.flags.DEFINE_string(\"data_directory\", '/tmp/MNIST_data', \"Data dir (default /tmp/MNIST_data)\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"dense_size\", 500, \"dense_size (default 500)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_float(\"learning_rate\", 0.001, \"learning rate (default: 0.001)\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 256, \"Batch Size (default: 256)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 20, \"Number of training epochs (default: 20)\")\n",
    "\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "#Access to the data\n",
    "mnist_data = get_data(data_dir= FLAGS.data_directory)\n",
    "\n",
    "\n",
    "# Training\n",
    "# ==================================================\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333, allow_growth = True)\n",
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "        gpu_options=gpu_options,\n",
    "        log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        \n",
    "        # Create model\n",
    "        cnn = mnistCNN(dense=FLAGS.dense_size)\n",
    "        \n",
    "        # Trainer\n",
    "        train_op = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cnn.loss)\n",
    "\n",
    "        # Saver\n",
    "        saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Train proccess\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "            for n_batch in range(int(55000/FLAGS.batch_size)):\n",
    "                batch = batch_generator(mnist_data, batch_size=FLAGS.batch_size, type='train')\n",
    "                _, ce = sess.run([train_op, cnn.loss], feed_dict={cnn.input_x: batch[0], cnn.input_y: batch[1]})\n",
    "\n",
    "            print(epoch, ce)\n",
    "        model_file = saver.save(sess, '/tmp/mnist_model')\n",
    "        print('Model saved in', model_file)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
