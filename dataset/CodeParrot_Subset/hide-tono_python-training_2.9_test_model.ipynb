{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25 A = [[ 6.20395088]]\n",
      "Loss = 15.9325\n",
      "Step #50 A = [[ 8.57587433]]\n",
      "Loss = 1.88605\n",
      "Step #75 A = [[ 9.45653248]]\n",
      "Loss = 1.25016\n",
      "Step #100 A = [[ 9.77085876]]\n",
      "Loss = 0.994985\n",
      "MSE on test: 1.27\n",
      "MSE on train: 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.5446017603692408&quot;).pbtxt = 'node {\\n  name: &quot;x/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;A/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;A/random_normal/RandomStandardNormal&quot;\\n  input: &quot;A/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;A/random_normal/mul&quot;\\n  input: &quot;A/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;A/Variable&quot;\\n  input: &quot;A/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;A/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x/Placeholder&quot;\\n  input: &quot;A/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;model/MatMul&quot;\\n  input: &quot;y/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/Square&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/loss/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/loss/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/loss/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/loss/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/loss/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/loss/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/loss/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/loss/Mean_grad/Prod&quot;\\n  input: &quot;gradients/loss/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/loss/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/loss/Mean_grad/Tile&quot;\\n  input: &quot;gradients/loss/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/loss/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/Square_grad/mul/x&quot;\\n  input: &quot;loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/Mean_grad/truediv&quot;\\n  input: &quot;gradients/loss/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;model/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/loss/sub_grad/Shape&quot;\\n  input: &quot;gradients/loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/loss/Square_grad/mul_1&quot;\\n  input: &quot;gradients/loss/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/loss/sub_grad/Sum&quot;\\n  input: &quot;gradients/loss/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/loss/Square_grad/mul_1&quot;\\n  input: &quot;gradients/loss/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/loss/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/loss/sub_grad/Neg&quot;\\n  input: &quot;gradients/loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/loss/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/loss/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/model/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/loss/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;A/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/model/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x/Placeholder&quot;\\n  input: &quot;gradients/loss/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/model/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/model/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/model/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/model/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/model/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/model/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/model/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/model/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/model/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/model/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/model/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.019999999552965164\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_A/Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;A/Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/model/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_A/Variable/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^A/Variable/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.5446017603692408&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorboard_jupyter as tb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import datasets\n",
    "\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#2.6の回帰の例\n",
    "batch_size = 25\n",
    "\n",
    "# 平均1、標準偏差0.1の正規分布を作成\n",
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "with tf.name_scope('x'):\n",
    "    x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "# 10を100個\n",
    "y_vals = np.repeat(10., 100)\n",
    "\n",
    "with tf.name_scope('y'):\n",
    "    y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# データをトレーニングセットとテストセットに8:2で分割\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals) * 0.8), replace= False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "# 予測結果の変数は最初はランダムで初期化\n",
    "with tf.name_scope('A'):\n",
    "    A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# 計算グラフに乗算を追加する。\n",
    "with tf.name_scope('model'):\n",
    "    my_output = tf.matmul(x_data, A)\n",
    "# L2損失関数(最小二乗法)\n",
    "# 平均１のx_dataとAの乗算と10との差分のため、Aは10に収束するはず\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(my_output - y_target))\n",
    "\n",
    "# 変数最適化方法\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate=0.02)\n",
    "# L2損失を最小化するようにする\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# トレーニング\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    # 1行25列から25行1列へ変換\n",
    "    rand_x = np.transpose([x_vals[rand_index]])\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%25 == 0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(loss, feed_dict={x_data:rand_x, y_target: rand_y})))\n",
    "\n",
    "mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})\n",
    "mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})\n",
    "print('MSE on test: ' + str(np.round(mse_test, 2)))\n",
    "print('MSE on train: ' + str(np.round(mse_train, 2)))\n",
    "        \n",
    "tf.summary.FileWriter('./log/', sess.graph)\n",
    "tb.show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200 A = [-0.69047976]\n",
      "Loss = [[ 0.16616148  0.65559411  0.89609718  0.05554588  0.08533639  0.46616307\n",
      "   0.07652663  0.10405916  0.02700546  0.11825523  0.95115638  0.03222379\n",
      "   0.08100253  0.4198207   0.11449566  0.11449566  0.10343304  0.08100253\n",
      "   0.10612128  0.42004126  0.4198207   0.19641592  0.07536426  0.07536426\n",
      "   0.10612128]]\n",
      "Step #400 A = [-0.56424481]\n",
      "Loss = [[ 0.24569601  0.1195773   0.06775134  0.52938318  0.1195773   0.12276029\n",
      "   0.08553281  0.05267632  0.29887959  0.43578029  0.15737741  0.4063105\n",
      "   0.09197678  0.05463177  0.21694562  0.12276029  0.46515566  0.07558858\n",
      "   0.1195773   0.10910847  0.05534232  0.38110635  0.33341065  0.06278943\n",
      "   0.06079619]]\n",
      "Step #600 A = [-0.6002931]\n",
      "Loss = [[ 0.06295894  0.05455804  0.11334316  0.08955632  0.26493016  1.11108971\n",
      "   0.13227196  0.11636318  0.43350312  0.07015296  0.05731658  0.05455804\n",
      "   0.05584619  0.41891679  0.10110906  0.11266427  0.15220828  0.43464652\n",
      "   0.17198761  0.46298206  0.10512213  1.11108971  0.12293167  0.11266427\n",
      "   0.11636318]]\n",
      "Step #800 A = [-0.6427415]\n",
      "Loss = [[ 0.21864513  0.11751396  0.13938749  0.05818432  0.03074447  0.22911347\n",
      "   0.31312305  0.4474602   0.31975704  0.26314947  0.13333322  0.07197441\n",
      "   0.11103227  0.46421763  0.26314947  0.11103227  0.13938749  0.09220471\n",
      "   0.08532066  0.14856726  0.10799613  0.13214977  0.30573937  0.92213017\n",
      "   0.14354172]]\n",
      "Step #1000 A = [-0.53698671]\n",
      "Loss = [[ 0.8597796   0.16384301  0.1226868   0.23965625  0.05172425  0.25046194\n",
      "   0.37254855  0.1054479   0.29190826  0.1226868   0.08428752  0.18035971\n",
      "   0.24031614  0.63877755  0.14716148  0.09382833  0.23212351  0.44505167\n",
      "   0.06498085  0.08332601  0.06598832  0.05389354  0.13658904  0.04105734\n",
      "   0.21168759]]\n",
      "Step #1200 A = [-0.66117775]\n",
      "Loss = [[ 0.4301883   0.37497833  0.03309396  0.47110409  0.13445054  0.05836788\n",
      "   0.13107556  0.18185802  0.40434626  0.4299635   0.18185802  0.93327552\n",
      "   0.04739198  0.07326578  0.30819991  0.93327552  0.11607544  0.05263273\n",
      "   0.14109612  0.02779742  0.58206779  0.93327552  0.11607544  0.30091578\n",
      "   0.23660219]]\n",
      "Step #1400 A = [-0.6949929]\n",
      "Loss = [[ 0.10361405  0.4184956   0.46784705  0.28768548  0.46784705  0.16685373\n",
      "   0.02241759  0.03201102  0.03201102  0.20859651  0.05530255  0.39112297\n",
      "   0.15594549  0.05981818  0.09071283  0.16685373  0.06203062  0.07569257\n",
      "   0.10299046  0.12695804  0.89342856  0.13671103  0.48394245  0.16685373\n",
      "   0.29934195]]\n",
      "Step #1600 A = [-0.75468701]\n",
      "Loss = [[ 0.25704432  0.20718922  0.29018718  0.06390999  0.12164412  0.61209434\n",
      "   0.04804517  0.12002506  0.1025841   0.07309439  0.03018377  0.27744466\n",
      "   0.10375654  0.68698418  0.08140018  0.12164412  0.2842378   0.09074595\n",
      "   0.13056147  0.37218708  0.03432439  0.08725557  0.3030504   0.3218323\n",
      "   0.12004825]]\n",
      "Step #1800 A = [-0.71812469]\n",
      "Loss = [[ 0.11752354  0.02627871  0.31190363  0.07858957  1.03360128  0.07739706\n",
      "   0.31190363  0.29361987  0.07739706  0.21260592  0.41042888  0.19154167\n",
      "   0.24887322  0.12422799  0.37949657  0.21260592  0.40222523  0.09907759\n",
      "   0.4928804   0.34095863  0.28642654  0.27243623  0.10337221  0.40222523\n",
      "   0.12425194]]\n",
      "Accuracy on train set: 0.9625\n",
      "Accuracy on test set: 0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3495609400446765&quot;).pbtxt = 'node {\\n  name: &quot;x_data/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y_target/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 10.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;A/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;A/random_normal/RandomStandardNormal&quot;\\n  input: &quot;A/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;A/random_normal/mul&quot;\\n  input: &quot;A/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;A/Variable&quot;\\n  input: &quot;A/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;A/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;A/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Model/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;x_data/Placeholder&quot;\\n  input: &quot;A/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;Model/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;Model/Add&quot;\\n  input: &quot;logistic_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;Model/Add&quot;\\n  input: &quot;logistic_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;Model/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;logistic_loss/Neg&quot;\\n  input: &quot;Model/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Model/Add&quot;\\n  input: &quot;y_target/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logistic_loss/Select&quot;\\n  input: &quot;logistic_loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;logistic_loss/Select_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss/Log1p&quot;\\n  op: &quot;Log1p&quot;\\n  input: &quot;logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_loss&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logistic_loss/sub&quot;\\n  input: &quot;logistic_loss/Log1p&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_loss/Log1p&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/logistic_loss_grad/Shape&quot;\\n  input: &quot;gradients/logistic_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/logistic_loss_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss_grad/Sum&quot;\\n  input: &quot;gradients/logistic_loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/logistic_loss_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss_grad/Sum_1&quot;\\n  input: &quot;gradients/logistic_loss_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logistic_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss_grad/Reshape_1&quot;\\n  input: &quot;^gradients/logistic_loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Shape&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/logistic_loss_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Sum&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/logistic_loss_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Neg&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logistic_loss/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/logistic_loss/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Log1p_grad/add/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Log1p_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;gradients/logistic_loss/Log1p_grad/add/x&quot;\\n  input: &quot;logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Log1p_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;gradients/logistic_loss/Log1p_grad/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Log1p_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/logistic_loss_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/logistic_loss/Log1p_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;Model/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/logistic_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;gradients/logistic_loss/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logistic_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/logistic_loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/logistic_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Model/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y_target/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Shape&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;y_target/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/mul&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Sum&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Model/Add&quot;\\n  input: &quot;gradients/logistic_loss/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/mul_1&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logistic_loss/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/logistic_loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Exp_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/logistic_loss/Log1p_grad/mul&quot;\\n  input: &quot;logistic_loss/Exp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;logistic_loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;gradients/logistic_loss/Exp_grad/mul&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_loss/GreaterEqual&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/zeros_like&quot;\\n  input: &quot;gradients/logistic_loss/Exp_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logistic_loss/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/logistic_loss/Select_1_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/Select&quot;\\n  input: &quot;^gradients/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/Select_1_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Select_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/Select_1&quot;\\n  input: &quot;^gradients/logistic_loss/Select_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/Select_1_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logistic_loss/Neg_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/logistic_loss/Select_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/logistic_loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/logistic_loss/Select_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/logistic_loss/Neg_grad/Neg&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logistic_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;x_data/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Model/Add_grad/Shape&quot;\\n  input: &quot;gradients/Model/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/Model/Add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Model/Add_grad/Sum&quot;\\n  input: &quot;gradients/Model/Add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/AddN&quot;\\n  input: &quot;gradients/Model/Add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Model/Add_grad/Sum_1&quot;\\n  input: &quot;gradients/Model/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Model/Add_grad/Reshape&quot;\\n  input: &quot;^gradients/Model/Add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Model/Add_grad/Reshape&quot;\\n  input: &quot;^gradients/Model/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Model/Add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Model/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Model/Add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Model/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Model/Add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.05000000074505806\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_A/Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;A/Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/Model/Add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@A/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_A/Variable/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^A/Variable/Assign&quot;\\n}\\nnode {\\n  name: &quot;prediction/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;x_data/Placeholder&quot;\\n  input: &quot;A/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;prediction/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Round&quot;\\n  op: &quot;Round&quot;\\n  input: &quot;prediction/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;prediction/Round&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;prediction/Squeeze&quot;\\n  input: &quot;y_target/Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;prediction/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;prediction/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;prediction/range/start&quot;\\n  input: &quot;prediction/Rank&quot;\\n  input: &quot;prediction/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;prediction/Cast&quot;\\n  input: &quot;prediction/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3495609400446765&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 分類の例 ##\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 平均-1と3のデータを50こずつ\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50),\n",
    "                        np.random.normal(2, 1, 50)))\n",
    "\n",
    "with tf.name_scope('x_data') as scope:\n",
    "    x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)    \n",
    "    \n",
    "y_vals = np.concatenate([np.repeat(0., 50), np.repeat(1., 50)])\n",
    "with tf.name_scope('y_target') as scope:\n",
    "    y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "# データをトレーニングセットとテストセットに8:2で分割\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals) * 0.8), replace= False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "    \n",
    "# 予測値は本来と離れた10で初期化\n",
    "with tf.name_scope('A') as scope:\n",
    "    A = tf.Variable(tf.random_normal(mean=10, shape=[1]))\n",
    "    \n",
    "# モデルは平均移動計算(sigmoid(x + A)だがsigmoidは損失関数が行う)\n",
    "with tf.name_scope('Model') as scope:\n",
    "    my_output = tf.add(x_data, A)\n",
    "\n",
    "# シグモイド誤差エントロピー損失関数\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target)\n",
    "# 最適化関数\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1800):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = [x_vals_train[rand_index]]\n",
    "    rand_y = [y_vals_train[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%200==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))\n",
    "\n",
    "\n",
    "with tf.name_scope('prediction') as scope:\n",
    "    y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))\n",
    "    correct_prediction = tf.equal(y_prediction, y_target)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "acc_value_test = sess.run(accuracy, feed_dict={x_data: [x_vals_test], y_target: [y_vals_test]})\n",
    "acc_value_train = sess.run(accuracy, feed_dict={x_data: [x_vals_train], y_target: [y_vals_train]})\n",
    "print('Accuracy on train set: ' + str(acc_value_train))\n",
    "print('Accuracy on test set: ' + str(acc_value_test))\n",
    "        \n",
    "tf.summary.FileWriter('./log/', sess.graph)\n",
    "tb.show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4bc0b8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可視化\n",
    "A_result = -sess.run(A)\n",
    "bins = np.linspace(-5, 5, 50)\n",
    "plt.hist(x_vals[0:50], bins, alpha = 0.5, label='N(-1,1)', color='gray')\n",
    "plt.hist(x_vals[50:100], bins[0:50], alpha = 0.5, label='N(2,1)', color='red')\n",
    "plt.plot((A_result, A_result), (0,8), 'k--', linewidth=3, label='A = ' + str(np.round(A_result, 2)))\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Binary Classifier Accuracy = ' + str(np.round(acc_value_test, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
