{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import dicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize, rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mlandmarks_v2\u001b[0m/                 min_max_frame_idxs.csv  validate-128x128-data.csv\r\n",
      "\u001b[01;31mlandmarks_v2.zip\u001b[0m              \u001b[01;36mtrain\u001b[0m@                  validate-label.csv\r\n",
      "local_test-128x128-data.csv   train-128x128-data.csv  X_train.npy\r\n",
      "local_test-label.csv          train.csv               y_train.npy\r\n",
      "local_train-128x128-data.csv  train-label.csv\r\n",
      "local_train-label.csv         \u001b[01;36mvalidate\u001b[0m@\r\n"
     ]
    }
   ],
   "source": [
    "# run scripts/distribute_dataset.sh for the train directory\n",
    "# Download min_max_frame_idxs.csv from Slack and put it in ../input directory\n",
    "# Download landmarks_v2.zip from Slack and unpack to ../input\n",
    "# run all cells\n",
    "# files ../input/X_train.npy ../input/Y_train.npy ../input/X_valid.npy ../input/Y_valid.npy should appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minmax = pd.read_csv(\"../input/min_max_frame_idxs.csv\", delim_whitespace=True, index_col=0, \n",
    "                     names=['min', 'max'])\n",
    "labels = pd.read_csv(\"../input/train.csv\", index_col=0)\n",
    "\n",
    "IMG_SIZE = 64\n",
    "MAX_SAXES = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crop_resize(filename, img_shape=(IMG_SIZE, IMG_SIZE)):\n",
    "    \"\"\"\n",
    "    Crop center and resize.\n",
    "    :param img: image to be cropped and resized.\n",
    "    \"\"\"\n",
    "    dcm = dicom.read_file(filename)\n",
    "    scale = map(float, dcm.PixelSpacing)\n",
    "    img = dcm.pixel_array.astype(np.float) / dcm.LargestImagePixelValue\n",
    "    img = rescale(img, scale)\n",
    "    \n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        img = img.T\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    img = crop_img\n",
    "    img = resize(img, img_shape)\n",
    "    return img[np.newaxis]\n",
    "\n",
    "def get_good_saxes(patient):\n",
    "    fname = \"../input/landmarks_v2/%d_contour_areas.csv\" % patient\n",
    "    saxes = []\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            saxes.append(line.split()[0])\n",
    "    return saxes\n",
    "\n",
    "def get_patient_slices(patient, min_idx, max_idx):\n",
    "    mins = [min_idx - 1 if min_idx > 2 else 30 , min_idx, min_idx + 1 if min_idx < 30 else 1]\n",
    "    maxs = [max_idx - 1 if max_idx > 2 else 30 , max_idx, max_idx + 1 if max_idx < 30 else 1]\n",
    "    saxes = get_good_saxes(patient)\n",
    "    sax_slices = []\n",
    "    for sax in saxes:\n",
    "        path = os.path.join('../input/train/', str(patient),'study', sax)\n",
    "        slices_min = map(lambda x: glob.glob(path + \"/IM-*-%.4d*.dcm\" % x)[0], mins)\n",
    "        slices_max = map(lambda x: glob.glob(path + \"/IM-*-%.4d*.dcm\" % x)[0], maxs)\n",
    "        slices_min.extend(slices_min)\n",
    "        sax_slices.append(np.vstack(map(crop_resize, slices_min))[np.newaxis])\n",
    "    return np.vstack(sax_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0 % \n",
      "40.0 % \n",
      "50.0 % \n",
      "60.0 % \n",
      "70.0 % \n",
      "80.0 % \n",
      "90.0 % \n",
      "100.0 % \n",
      "10.0 % \n"
     ]
    }
   ],
   "source": [
    "val_images = []\n",
    "train_images = []\n",
    "val_y = []\n",
    "train_y = []\n",
    "\n",
    "for patient, minidx, max_idx in minmax.itertuples():\n",
    "    if patient > 500:\n",
    "        continue\n",
    "    if (patient % 50) == 0:\n",
    "        print \"%.1f %% \" % (100 * float(patient) / 500)\n",
    "    systole, diastole = labels.loc[patient]\n",
    "    r = get_patient_slices(patient, minidx + 1, max_idx + 1)\n",
    "    n_saxes = r.shape[0]\n",
    "    if n_saxes < MAX_SAXES:\n",
    "        part = r[:(MAX_SAXES - n_saxes)].copy()\n",
    "        r = np.vstack((r, part))\n",
    "    else:\n",
    "        r = r[:MAX_SAXES]\n",
    "    assert r.shape[0] == MAX_SAXES\n",
    "    if np.random.random() < 0.1:\n",
    "        # validation\n",
    "        val_images.append(r[:, :3].reshape(1, -1, IMG_SIZE, IMG_SIZE))\n",
    "        val_images.append(r[:, 3:].reshape(1, -1, IMG_SIZE, IMG_SIZE))\n",
    "        val_y.append(systole)\n",
    "        val_y.append(diastole)\n",
    "    else:\n",
    "        train_images.append(r[:, :3].reshape(1, -1, IMG_SIZE, IMG_SIZE))\n",
    "        train_images.append(r[:, 3:].reshape(1, -1, IMG_SIZE, IMG_SIZE))\n",
    "        train_y.append(systole)\n",
    "        train_y.append(diastole)\n",
    "\n",
    "\n",
    "X_train = np.vstack(train_images).astype(np.float32)\n",
    "Y_train = np.array(train_y)\n",
    "np.save(\"../input/X_train.npy\", X_train)\n",
    "np.save(\"../input/y_train.npy\", Y_train)\n",
    "\n",
    "X_valid = np.vstack(val_images).astype(np.float32)\n",
    "Y_valid = np.array(val_y)\n",
    "np.save(\"../input/X_valid.npy\", X_train)\n",
    "np.save(\"../input/y_valid.npy\", Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
