{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class VariableLengthDataset(data.Dataset):\n",
    "    def __init__(self, manifest, snippet_length=24000, get_sequentially=False, ret_np=False, use_librosa=False):\n",
    "        self.manifest = manifest\n",
    "        self.snippet_length = snippet_length\n",
    "        self.get_sequentially = get_sequentially\n",
    "        self.use_librosa = use_librosa\n",
    "        self.ret_np = ret_np\n",
    "        self.acc = 0\n",
    "        self.snippet_counter = 0\n",
    "        self.audio_idx = 0\n",
    "        self.st = 0\n",
    "        self.data = {}\n",
    "    def __getitem__(self, index):\n",
    "        # load audio data from file or cache\n",
    "        if self.snippet_counter == 0:\n",
    "            self.audio_idx = index - self.acc\n",
    "            apath = self.manifest[self.audio_idx]\n",
    "            if apath not in self.data:\n",
    "                if self.use_librosa:\n",
    "                    sig, sr = librosa.core.load(apath, sr=None)\n",
    "                    sig = torch.from_numpy(sig).unsqueeze(1).float()\n",
    "                else:\n",
    "                    sig, sr = torchaudio.load(apath, normalization=True)\n",
    "                self.data[apath] = (sig, sr)\n",
    "            else:\n",
    "                sig, sr = self.data[apath]\n",
    "\n",
    "            # increase iterations based on length of audio\n",
    "            num_snippets = int(sig.size(0) // self.snippet_length)\n",
    "            self.acc += max(num_snippets-1,0)\n",
    "        else:\n",
    "            apath = self.manifest[self.audio_idx]\n",
    "            sig, sr = self.data[apath]\n",
    "            num_snippets = int(sig.size(0) // self.snippet_length)\n",
    "\n",
    "        # create snippet\n",
    "        if self.get_sequentially:\n",
    "            self.st += self.snippet_length\n",
    "        else:\n",
    "            self.st = random.randrange(int(sig.size(0)-self.snippet_length))\n",
    "        ret_sig = sig[self.st:(self.st+self.snippet_length)]\n",
    "        if self.ret_np:\n",
    "            ret_sig = ret_sig.numpy()\n",
    "\n",
    "        # update counter for current audio file\n",
    "        self.snippet_counter += 1\n",
    "\n",
    "        # label creation\n",
    "        spkr = os.path.dirname(apath).rsplit(\"/\", 1)[-1]\n",
    "        spkr = 0\n",
    "\n",
    "        # check for reset\n",
    "        if self.snippet_counter >= num_snippets:\n",
    "            self.snippet_counter = 0\n",
    "            self.st = 0\n",
    "\n",
    "        return ret_sig, spkr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.manifest) + self.acc\n",
    "\n",
    "    def reset_acc(self):\n",
    "        self.acc = 0\n",
    "\n",
    "class FixedLengthDataset(data.Dataset):\n",
    "    def __init__(self, manifest, transforms = snippet_length=24000, ret_np=False, use_librosa=False):\n",
    "        self.manifest = manifest\n",
    "        self.snippet_length = snippet_length\n",
    "        self.use_librosa = use_librosa\n",
    "        self.ret_np = ret_np\n",
    "        self.num_snippets = 1\n",
    "        self.acc = 0\n",
    "        self.audio_idx = 0\n",
    "        self.st = 0\n",
    "        self.data = {}\n",
    "    def __getitem__(self, index):\n",
    "        # load audio data from file or cache\n",
    "        self.audio_idx = index if self.num_snippets == 1 else index // self.num_snippets\n",
    "        apath = self.manifest[self.audio_idx]\n",
    "        if self.use_librosa:\n",
    "            sig, sr = librosa.core.load(apath, sr=None)\n",
    "            sig = torch.from_numpy(sig).unsqueeze(1).float()\n",
    "        else:\n",
    "            sig, sr = torchaudio.load(apath, normalization=True)\n",
    "\n",
    "        # create snippet\n",
    "        if sig.size(0) < self.snippet_length:\n",
    "            ret_sig = sig\n",
    "        else:\n",
    "            self.st = random.randrange(int(sig.size(0)-self.snippet_length))\n",
    "            ret_sig = sig[self.st:(self.st+self.snippet_length)]\n",
    "        if self.ret_np:\n",
    "            ret_sig = ret_sig.numpy()\n",
    "\n",
    "        # label creation\n",
    "        #spkr = os.path.dirname(apath).rsplit(\"/\", 1)[-1]\n",
    "        spkr = 0 # just using a dummy label now.\n",
    "\n",
    "        return ret_sig, spkr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.manifest) * self.num_snippets\n",
    "\n",
    "def run_dataset():\n",
    "    for epoch in range(1):\n",
    "        all_data = [(x, label) for x, label in ds]\n",
    "        print(epoch, len(all_data))\n",
    "        try:\n",
    "            ds.reset_acc()\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 91.1 ms, sys: 8.62 ms, total: 99.7 ms\n",
      "Wall time: 291 ms\n",
      "0\n",
      "CPU times: user 79 ms, sys: 6.72 ms, total: 85.7 ms\n",
      "Wall time: 69.8 ms\n"
     ]
    }
   ],
   "source": [
    "datadir = \"/home/david/Programming/tests/pcsnpny-20150204-mkj\"\n",
    "audio_manifest = [a for a in glob.glob(datadir+\"/**/*.wav\", recursive=True)]\n",
    "\n",
    "ds = VariableLengthDataset(audio_manifest, 12000, get_sequentially=True, ret_np=False, use_librosa=False)\n",
    "%time run_dataset()\n",
    "ds = VariableLengthDataset(audio_manifest, 12000, get_sequentially=True, ret_np=False, use_librosa=True)\n",
    "%time run_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n",
      "torch.Size([10, 12000, 1]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "ds = VariableLengthDataset(audio_manifest, 12000, get_sequentially=False, ret_np=False, use_librosa=False)\n",
    "dl = data.DataLoader(ds, batch_size=10)\n",
    "print(len(ds), len(dl))\n",
    "for mb, tgts in dl:\n",
    "    print(mb.size(), tgts.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "CPU times: user 18.1 ms, sys: 0 ns, total: 18.1 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "datadir = \"/home/david/Programming/tests/pcsnpny-20150204-mkj\"\n",
    "audio_manifest = [a for a in glob.glob(datadir+\"/**/*.wav\", recursive=True)]\n",
    "ds = FixedLengthDataset(audio_manifest, 12000, ret_np=True, use_librosa=True)\n",
    "%time run_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
