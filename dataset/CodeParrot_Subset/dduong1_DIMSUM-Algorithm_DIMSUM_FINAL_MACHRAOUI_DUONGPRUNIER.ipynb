{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# IMPLEMENTATION DE L'ALGORITHME DIMSUM SOUS PIG\n",
    "## David DUONG PRUNIER - Ismail MACHRAOUI\n",
    "### MASTERE SPECIALISE DATA SCIENCE\n",
    "\n",
    "Pour cette étude, nous allons implémenter l'algorithme DIMSUM décrit par Bosagh-Zadesh en 2012. Cet algorithme propose de trouver toutes les paires d'éléments semblables. \n",
    "La littérature sur cet algorithme nous propose différentes versions du même algorithme, plus ou moins puissantes, plus pou moins flexibles. Il est intéressant de noter que Twitter l'a implémenté dans ses clusters et a rendu publique l'algorithme modifié qu'ils ont utilisé. C'est cet algorithme que nous allons implémenter [2].  \n",
    "Sans entrer dans les détails, le coeur de l'algorithme repose sur le calcul de la matrice $A^tA$ (A transposé x A), et la sélection des paires selon une probabilité donnée. \n",
    "Pour l'implémentation, nous avons choisi de développer l'algorithme sous PIG, dans un cluster Azure. Le jeu de donnée de test sera une base composée des notes données par les utilisateurs à différents films. L'algorithme trouvera les paires de films équivalents. \n",
    "\n",
    "Nous effectuerons notre étude sur un jeu de données composé de 1000208 notes de films basé sur 6040 utilisateurs et 3952 films différents.\n",
    "\n",
    "Une fois les similarités calculées, nous effectuerons un test afin de récupérer les films similaires à un film qu'on passera en input.\n",
    "\n",
    "[1] Bosagh-Zadeh, Reza and Goel, Ashish (2012), Dimension Independent Similarity Computation, arXiv:1206.2082 http://arxiv.org/abs/1206.2082\n",
    "\n",
    "[2] https://blog.twitter.com/2014/all-pairs-similarity-via-dimsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### ETAPE PAR ETAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place des librairies et des modules de connexions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On code en dur afin d'éviter de retaper tout le temps les identifiants. Attention c'est une mauvaise pratique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyensae\n",
    "import os\n",
    "blobstorage = \"hdblobstorage\" #blobhp[\"blob_storage\"]\n",
    "blobpassword = \"jQIPVO/T54w8X49UPIbzAVvaNO3wmuUwI4/o9AJnCaPTHoCQnsaGBUkT4eIyi0BRQavgc/TAQMQwy8eu19CSBQ==\" #blobhp[\"password1\"]#\n",
    "hadoop_server = \"sparkclus2ensae\"#blobhp[\"hadoop_server\"]#\n",
    "hadoop_password = \"ENSAEspark1;\"#blobhp[\"password2\"]#\n",
    "username = \"imdd\" #blobhp[\"username\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ouvre la connexion au cluster et au blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyensae.remote.azure_connection.AzureClient at 0x6f1128>,\n",
       " <azure.storage.blob.blobservice.BlobService at 0x6f1320>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%blob_close\n",
    "cl, bs = %hd_open \n",
    "cl,bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On upload les fichiers qui contient tous les ratings des users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imdd/ratings_mean.csv'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_up data/ratings_mean.csv hdblobstorage/imdd/ratings_mean.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que tous les fichiers sont présents dans le blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>content_type</th>\n",
       "      <th>content_length</th>\n",
       "      <th>blob_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdd/ConfLongDemo_JSI.txt</td>\n",
       "      <td>Sun, 17 Jan 2016 14:44:35 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>21546346</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdd/ConfLongDemo_JSI_small.txt</td>\n",
       "      <td>Sun, 17 Jan 2016 16:47:23 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>638</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdd/dom</td>\n",
       "      <td>Thu, 28 Jan 2016 17:21:25 GMT</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdd/exp_data_final_short.csv</td>\n",
       "      <td>Mon, 25 Jan 2016 22:48:10 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>1704019</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imdd/exp_original.csv</td>\n",
       "      <td>Mon, 25 Jan 2016 23:16:54 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>12553678</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imdd/exp_original_medium.csv</td>\n",
       "      <td>Thu, 28 Jan 2016 07:24:52 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>5086</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>imdd/exp_original_short.csv</td>\n",
       "      <td>Wed, 27 Jan 2016 22:10:26 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>1785</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>imdd/numpyudf.py</td>\n",
       "      <td>Sun, 17 Jan 2016 16:38:30 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>702</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>imdd/ratings_mean.csv</td>\n",
       "      <td>Thu, 28 Jan 2016 22:47:18 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>18589813</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>imdd/ratings_mean_short.csv</td>\n",
       "      <td>Thu, 28 Jan 2016 12:51:01 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>2802</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>imdd/scripts/pig/exptestnumpy.pig</td>\n",
       "      <td>Thu, 28 Jan 2016 23:39:40 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>2367</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imdd/scripts/pig/exptestnumpy.pig.log</td>\n",
       "      <td>Thu, 28 Jan 2016 23:40:31 GMT</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>imdd/scripts/pig/exptestnumpy.pig.log/exit</td>\n",
       "      <td>Thu, 28 Jan 2016 23:40:31 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>3</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>imdd/scripts/pig/exptestnumpy.pig.log/stderr</td>\n",
       "      <td>Thu, 28 Jan 2016 23:40:21 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>6502</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>imdd/scripts/pig/exptestnumpy.pig.log/stdout</td>\n",
       "      <td>Thu, 28 Jan 2016 23:40:21 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>136</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>imdd/testcpython.py</td>\n",
       "      <td>Fri, 15 Jan 2016 21:36:32 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>486</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  \\\n",
       "0                      imdd/ConfLongDemo_JSI.txt   \n",
       "1                imdd/ConfLongDemo_JSI_small.txt   \n",
       "2                                       imdd/dom   \n",
       "3                  imdd/exp_data_final_short.csv   \n",
       "4                          imdd/exp_original.csv   \n",
       "5                   imdd/exp_original_medium.csv   \n",
       "6                    imdd/exp_original_short.csv   \n",
       "7                               imdd/numpyudf.py   \n",
       "8                          imdd/ratings_mean.csv   \n",
       "9                    imdd/ratings_mean_short.csv   \n",
       "10             imdd/scripts/pig/exptestnumpy.pig   \n",
       "11         imdd/scripts/pig/exptestnumpy.pig.log   \n",
       "12    imdd/scripts/pig/exptestnumpy.pig.log/exit   \n",
       "13  imdd/scripts/pig/exptestnumpy.pig.log/stderr   \n",
       "14  imdd/scripts/pig/exptestnumpy.pig.log/stdout   \n",
       "15                           imdd/testcpython.py   \n",
       "\n",
       "                    last_modified              content_type  content_length  \\\n",
       "0   Sun, 17 Jan 2016 14:44:35 GMT  application/octet-stream        21546346   \n",
       "1   Sun, 17 Jan 2016 16:47:23 GMT  application/octet-stream             638   \n",
       "2   Thu, 28 Jan 2016 17:21:25 GMT                                         0   \n",
       "3   Mon, 25 Jan 2016 22:48:10 GMT  application/octet-stream         1704019   \n",
       "4   Mon, 25 Jan 2016 23:16:54 GMT  application/octet-stream        12553678   \n",
       "5   Thu, 28 Jan 2016 07:24:52 GMT  application/octet-stream            5086   \n",
       "6   Wed, 27 Jan 2016 22:10:26 GMT  application/octet-stream            1785   \n",
       "7   Sun, 17 Jan 2016 16:38:30 GMT  application/octet-stream             702   \n",
       "8   Thu, 28 Jan 2016 22:47:18 GMT  application/octet-stream        18589813   \n",
       "9   Thu, 28 Jan 2016 12:51:01 GMT  application/octet-stream            2802   \n",
       "10  Thu, 28 Jan 2016 23:39:40 GMT  application/octet-stream            2367   \n",
       "11  Thu, 28 Jan 2016 23:40:31 GMT                                         0   \n",
       "12  Thu, 28 Jan 2016 23:40:31 GMT  application/octet-stream               3   \n",
       "13  Thu, 28 Jan 2016 23:40:21 GMT  application/octet-stream            6502   \n",
       "14  Thu, 28 Jan 2016 23:40:21 GMT  application/octet-stream             136   \n",
       "15  Fri, 15 Jan 2016 21:36:32 GMT  application/octet-stream             486   \n",
       "\n",
       "    blob_type  \n",
       "0   BlockBlob  \n",
       "1   BlockBlob  \n",
       "2   BlockBlob  \n",
       "3   BlockBlob  \n",
       "4   BlockBlob  \n",
       "5   BlockBlob  \n",
       "6   BlockBlob  \n",
       "7   BlockBlob  \n",
       "8   BlockBlob  \n",
       "9   BlockBlob  \n",
       "10  BlockBlob  \n",
       "11  BlockBlob  \n",
       "12  BlockBlob  \n",
       "13  BlockBlob  \n",
       "14  BlockBlob  \n",
       "15  BlockBlob  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List files in blob storage\n",
    "df=%blob_ls hdblobstorage/imdd/\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On code l'algorithme en PIG. La difficulté est que PIG gère très mal l'imbrication de FOREACH, absolument nécessaire à l'algorithme. Notre solution s'est portée sur la mise à plat totale des données. D'où le FLATTEN puis nous avons effectué un JOIN pour la deuxième boucle. Puis nous avons appliqué les règles définies par l'algorithme.\n",
    "\n",
    "En sortie nous obtenons l'ensemble des paires semblables, avec leur mesure de similarité.\n",
    "On stocke dans un fichier pour l'exploiter ensuite avec un autre script PIG.\n",
    "Pour réduire le nombre de résultats, nous ne retiendrons que les paires de films qui ont une similarité de plus de **0.5** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%PIG_azure dimsum.pig\n",
    "\n",
    "-- Macro de calcul des normes par colonne (movieID)\n",
    "DEFINE computeMatrixNorms(cData,sqrt_gamma) RETURNS Matrix_Norms {\n",
    "    cData_grp = GROUP $cData BY MovieID;\n",
    "    -- On calcule la norme et le gamma sur la norme\n",
    "    $Matrix_Norms = FOREACH cData_grp {\n",
    "        tmp_out = FOREACH $cData GENERATE Rating*Rating;\n",
    "        out = SUM(tmp_out);\n",
    "        GENERATE group as MovieID, SQRT(out) as Norm, ($sqrt_gamma.$0/SQRT(out)>1?1:$sqrt_gamma.$0/SQRT(out)) as Prob_j;\n",
    "    }\n",
    "}\n",
    "\n",
    "cData =  LOAD '$CONTAINER/imdd/ratings_mean.csv'\n",
    "        using PigStorage (',')\n",
    "        AS (UserID:int, MovieID:int, Rating:double) ;\n",
    "        \n",
    "-- On calcule le gamma\n",
    "users = GROUP cData all ;\n",
    "total= FOREACH users GENERATE MAX($1.UserID) as m, MAX($1.MovieID) as n;\n",
    "sqrt_gamma = FOREACH total GENERATE SQRT(4*LOG(n)/0.7) as a;\n",
    "                \n",
    "\n",
    "-- On calcule la norme et le gamma sur la norme\n",
    "Matrix_Norms = computeMatrixNorms(cData,sqrt_gamma);\n",
    "\n",
    "\n",
    "-- On ajoute la colonne Norm et probabilite dans cData\n",
    "C = JOIN cData BY MovieID,Matrix_Norms BY MovieID;\n",
    "D = FOREACH C GENERATE cData::UserID as UserID_f,cData::MovieID as MovieID_f,cData::Rating as Rating_f,\n",
    "                        Matrix_Norms::Norm as Norm_f,Matrix_Norms::Prob_j as Prob_j_f;\n",
    "\n",
    "Matrix_data = GROUP D BY UserID_f;\n",
    "FF = FOREACH Matrix_data GENERATE group as UID, FLATTEN(D.MovieID_f) as MV1;\n",
    "\n",
    "-- Ajout des informations de MV1\n",
    "FFF = JOIN FF BY (UID,MV1), D BY (UserID_f,MovieID_f); \n",
    "\n",
    "-- Condition de validite premier IF\n",
    "FFD = FILTER FFF BY RANDOM()<Prob_j_f;\n",
    "\n",
    "-- Ajout de la seconde loop\n",
    "GG = JOIN FFD BY UID, D BY UserID_f;\n",
    "\n",
    "-- Cleaning du tableau\n",
    "GGG = FOREACH GG GENERATE FFD::FF::UID as UserID,FFD::FF::MV1 as MV_1,FFD::D::Rating_f as Rating_1,FFD::D::Norm_f as Norm_1,\n",
    "                FFD::D::Prob_j_f as Proba_1,D::MovieID_f as MV_2,D::Rating_f as Rating_2,\n",
    "                D::Norm_f as Norm_2,D::Prob_j_f as Proba_2;\n",
    "                                \n",
    "-- Ajout de la deuxieme boucle\n",
    "-- Condition de validite second IF\n",
    "GGD = FILTER GGG BY RANDOM()<Proba_2;\n",
    "\n",
    "-- Generation des similarites\n",
    "HH = FOREACH GGD{\n",
    "    val = Rating_1*Rating_2/(((sqrt_gamma.$0>Norm_1)?Norm_1:sqrt_gamma.$0)*((sqrt_gamma.$0>Norm_2)?Norm_2:sqrt_gamma.$0));\n",
    "    GENERATE MV_1,MV_2,val as VAL;\n",
    "}\n",
    "DESCRIBE HH;\n",
    "-- Ajout d un filtre supplementaire pour reduire la taille des resultats\n",
    "HHH = FILTER HH BY VAL > 0.5;\n",
    "HHHH = DISTINCT HHH;\n",
    "\n",
    "STORE GGD INTO '$CONTAINER/$PSEUDO/dom/matrix_all.txt' USING PigStorage(',');\n",
    "STORE HHH INTO '$CONTAINER/$PSEUDO/dom/similarities.txt' USING PigStorage(',');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la partie de code suivante, nous supprimons les fichiers générés par l'algorithme précédent pour pouvoir les regénérer une deuxième fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.delete_blob(bs, \"hdblobstorage\", 'imdd/dom/matrix_all.txt')\n",
    "cl.delete_blob(bs, \"hdblobstorage\", 'imdd/dom/similarities.txt')\n",
    "df = %blob_ls hdblobstorage/imdd/dom/matrix_all.txt/\n",
    "df\n",
    "for name in df[\"name\"]:\n",
    "    cl.delete_blob(bs, \"hdblobstorage\", name)\n",
    "df = %blob_ls hdblobstorage/imdd/dom/similarities.txt/\n",
    "df\n",
    "for name in df[\"name\"]:\n",
    "    cl.delete_blob(bs, \"hdblobstorage\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload du script **dimsum.pig** et lancement de son exécution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'job_1452664005967_1065'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jid = %hd_pig_submit dimsum.pig\n",
    "jid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('job_1452664005967_1065', '100% complete', 'done', True, 'SUCCEEDED')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = %hd_job_status jid[\"id\"]\n",
    "st[\"id\"],st[\"percentComplete\"],st[\"completed\"],st[\"status\"][\"jobComplete\"],st[\"status\"][\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdd/ConfLongDemo_JSI.txt',\n",
       " 'imdd/ConfLongDemo_JSI_small.txt',\n",
       " 'imdd/dom',\n",
       " 'imdd/dom/matrix_all.txt',\n",
       " 'imdd/dom/matrix_all.txt/_SUCCESS',\n",
       " 'imdd/dom/matrix_all.txt/part-r-00000',\n",
       " 'imdd/dom/matrix_all11.txt',\n",
       " 'imdd/dom/matrix_all11.txt/_SUCCESS',\n",
       " 'imdd/dom/matrix_all11.txt/part-r-00000',\n",
       " 'imdd/dom/matrix_all_f.txt',\n",
       " 'imdd/dom/matrix_all_f.txt/_SUCCESS',\n",
       " 'imdd/dom/matrix_all_f.txt/part-r-00000',\n",
       " 'imdd/dom/recom.txt',\n",
       " 'imdd/dom/recom.txt/_SUCCESS',\n",
       " 'imdd/dom/recom.txt/part-r-00000',\n",
       " 'imdd/dom/similarities.txt',\n",
       " 'imdd/dom/similarities.txt/_SUCCESS',\n",
       " 'imdd/dom/similarities.txt/part-m-00000',\n",
       " 'imdd/dom/similarities11.txt',\n",
       " 'imdd/dom/similarities11.txt/_SUCCESS',\n",
       " 'imdd/dom/similarities11.txt/part-m-00000',\n",
       " 'imdd/dom/similarities_f.txt',\n",
       " 'imdd/dom/similarities_f.txt/_SUCCESS',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00000',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00001',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00002',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00003',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00004',\n",
       " 'imdd/dom/similarities_f.txt/part-m-00005',\n",
       " 'imdd/exp_data_final_short.csv',\n",
       " 'imdd/exp_original.csv',\n",
       " 'imdd/exp_original_medium.csv',\n",
       " 'imdd/exp_original_short.csv',\n",
       " 'imdd/numpyudf.py',\n",
       " 'imdd/ratings_mean.csv',\n",
       " 'imdd/ratings_mean_short.csv',\n",
       " 'imdd/scripts/pig/dimsum.pig',\n",
       " 'imdd/scripts/pig/dimsum.pig.log',\n",
       " 'imdd/scripts/pig/dimsum.pig.log/exit',\n",
       " 'imdd/scripts/pig/dimsum.pig.log/stderr',\n",
       " 'imdd/scripts/pig/dimsum.pig.log/stdout',\n",
       " 'imdd/scripts/pig/exptestnumpy.pig',\n",
       " 'imdd/scripts/pig/exptestnumpy.pig.log',\n",
       " 'imdd/scripts/pig/exptestnumpy.pig.log/exit',\n",
       " 'imdd/scripts/pig/exptestnumpy.pig.log/stderr',\n",
       " 'imdd/scripts/pig/exptestnumpy.pig.log/stdout',\n",
       " 'imdd/scripts/pig/exptestnumpy_f.pig',\n",
       " 'imdd/scripts/pig/exptestnumpy_f.pig.log',\n",
       " 'imdd/scripts/pig/exptestnumpy_f.pig.log/exit',\n",
       " 'imdd/scripts/pig/exptestnumpy_f.pig.log/stderr',\n",
       " 'imdd/scripts/pig/exptestnumpy_f.pig.log/stdout',\n",
       " 'imdd/scripts/pig/load_results.pig',\n",
       " 'imdd/scripts/pig/load_results.pig.log',\n",
       " 'imdd/scripts/pig/load_results.pig.log/exit',\n",
       " 'imdd/scripts/pig/load_results.pig.log/stderr',\n",
       " 'imdd/scripts/pig/load_results.pig.log/stdout',\n",
       " 'imdd/testcpython.py']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=%blob_ls hdblobstorage/imdd/\n",
    "list(df[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test \n",
    "\n",
    "L'algorithme **DimSum** ayant été bien exécuté , nous allons maintenant exploiter notre matrice de similarités à l'aide d'un autre script PIG qui se base sur le fichier de similarités généré par le script PIG vu auparavant.\n",
    "\n",
    "A partir d'un id d'un film, qui existe dans notre base, nous nous attendrons à récupérer les ids des films dont la similarité calculée est maximale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%PIG_azure load_results.pig\n",
    "\n",
    "\n",
    "cData =  LOAD '$CONTAINER/$PSEUDO/dom/similarities.txt'\n",
    "        using PigStorage (',')\n",
    "        AS (MovieID1:int, MovieID2:int, sim:double) ;\n",
    "\n",
    "filtered = FILTER cData BY MovieID1 == $MvID ;\n",
    "ordered = ORDER filtered BY sim DESC;\n",
    "ordered_limit = LIMIT ordered $size;\n",
    "movies = FOREACH ordered_limit GENERATE MovieID2;\n",
    "STORE movies INTO '$CONTAINER/imdd/dom/recom.txt' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous supprimons d'abord le fichier généré par la dernière exécution, ensuite nous lançons le script PIG afin de récupérer les ids des films similaires. Pour cet exemple, nous souhaitons récupérer les 20 films les plus proches à celui dont l'id est 1610."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'job_1452664005967_0843'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cl.exists(bs, cl.account_name, \"$PSEUDO/imdd/dom/recom.txt\"):\n",
    "    r = cl.delete_folder (bs, cl.account_name, \"$PSEUDO/imdd/dom/recom.txt\")\n",
    "jid = cl.pig_submit(bs, blobstorage, \"load_results.pig\",params={\"MvID\":'1610',\"size\":\"20\"})\n",
    "jid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('job_1452664005967_0843', None, 'done', True, 'SUCCEEDED')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = %hd_job_status jid[\"id\"]\n",
    "(st[\"id\"],st[\"percentComplete\"],st[\"completed\"],\n",
    "st[\"status\"][\"jobComplete\"],st[\"status\"][\"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons ensuite le fichier généré *recom.txt*, contenant les ids :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recom.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(\"recom.txt\"):os.remove(\"recom.txt\")\n",
    "%blob_downmerge /imdd/dom/recom.txt recom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nous affichons enfin les résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3255\n",
      "3147\n",
      "380\n",
      "3095\n",
      "3071\n",
      "3068\n",
      "3035\n",
      "3030\n",
      "2943\n",
      "982\n",
      "2858\n",
      "368\n",
      "920\n",
      "356\n",
      "349\n",
      "318\n",
      "2571\n",
      "2501\n",
      "2396\n",
      "2353\n",
      "\n"
     ]
    }
   ],
   "source": [
    " with open('recom.txt', 'r') as f:\n",
    "    ids = f.read()\n",
    "    print(ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
