{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## This notebook shows how to use `grizli` to\n",
    "\n",
    "retrieve and pre-process raw CLEAR G102/F105W and 3D-HST G141/F140W observations for a single CLEAR pointing (GS1).\n",
    "\n",
    "These series of notebooks draw heavily from Gabe Brammer's existing `grizli` notebooks, which are available at https://github.com/gbrammer/grizli/tree/master/examples, but with examples specific for the CLEAR survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grizli\n",
    "\n",
    "try: \n",
    "    from mastquery import query, overlaps\n",
    "    use_mquery = True\n",
    "except: \n",
    "    from hsaquery import query, overlaps\n",
    "    use_mquery = False\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from grizli.pipeline import auto_script\n",
    "import glob\n",
    "from glob import glob\n",
    "import astropy\n",
    "from grizli.prep import process_direct_grism_visit\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Initialize Directories</center></h1>\n",
    "\n",
    "\n",
    "### ***The following paths need to be changed for your filesystem.*** [HOME_PATH] is where the raw data, reduced data, and `grizli` outputs will be stored. [PATH_TO_CATS] is where the catalogs are stored and must include the following:\n",
    "        ###     reference mosaic image (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sci.fits)\n",
    "        ###     segmentation map       (e.g., Goods_S_plus_seg.fits)\n",
    "        ###     source catalog         (e.g., goodss-F105W-astrodrizzle-v4.3_drz_sub_plus.cat)\n",
    "        ###     radec_catalog          (e.g., goodsS_radec.cat)\n",
    "        ###     3DHST Eazy Catalogs    (e.g., goodss_3dhst.v4.1.cats/*)\n",
    "        \n",
    "the [PATH_TO_CATS] files are available on the team archive: https://archive.stsci.edu/pub/clear_team/INCOMING/for_hackday/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field           = 'GS1'\n",
    "ref_filter      = 'F105W'\n",
    "\n",
    "HOME_PATH       = '/Users/rsimons/Desktop/clear/for_hackday/%s'%field\n",
    "PATH_TO_CATS    = '/Users/rsimons/Desktop/clear/Catalogs'\n",
    "\n",
    "# Create [HOME_PATH] and [HOME_PATH]/query_results directories if they do not already exist\n",
    "if not os.path.isdir(HOME_PATH): os.system('mkdir %s'%HOME_PATH)\n",
    "if not os.path.isdir(HOME_PATH + '/query_results'): os.system('mkdir %s/query_results'%HOME_PATH)\n",
    "\n",
    "# Move to the [HOME_PATH] directory\n",
    "os.chdir(HOME_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Query MAST</center></h1>\n",
    "\n",
    "### Run an initial query for all raw G102 data in the MAST archive from the proposal ID 14227 with a target name that includes the phrase 'GS1' (i.e., GS1 pointing of CLEAR). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# proposal_id = [14227] is CLEAR\n",
    "parent = query.run_query(box = None, proposal_id = [14227], instruments=['WFC3/IR', 'ACS/WFC'], \n",
    "                         filters = ['G102'], target_name = 'GS1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, find all G102 and G141 observations that overlap with the pointings found in the initial query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all G102 and G141 observations overlapping the parent query in the archive\n",
    "tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, \n",
    "                              filters=['G102', 'G141'], \n",
    "                              instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], close=False)\n",
    "\n",
    "footprint_fits_file = glob('*footprint.fits')[0]\n",
    "jtargname = footprint_fits_file.strip('_footprint.fits')\n",
    "\n",
    "\n",
    "# A list of the target names\n",
    "fp_fits = fits.open(footprint_fits_file)\n",
    "overlapping_target_names = set(fp_fits[1].data['target'])\n",
    "\n",
    "\n",
    "# Move the footprint figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "os.system('cp %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, 'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n",
    "os.system('cp %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname,  'all_G102_G141'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table summary of query\n",
    "tabs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Retrieve raw data from MAST</center></h1>\n",
    "\n",
    "\n",
    "### We now have a list of G102 and G141 observations in the MAST archive that overlap with the GS1 pointing of CLEAR. \n",
    "\n",
    "### For each, retrieve all associated RAW grism G102/G141 and direct imaging F098M/F105W/F125W/F140W data from MAST.\n",
    "\n",
    "**For GS1, the retrieval step takes about 30 minutes to run and requires 1.9 GB of space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop targ_name by targ_name\n",
    "for t, targ_name in enumerate(overlapping_target_names):\n",
    "    if use_mquery:\n",
    "        extra = {'target_name':targ_name}\n",
    "    else:\n",
    "        extra = query.DEFAULT_EXTRA.copy()\n",
    "        extra += [\"TARGET.TARGET_NAME LIKE '%s'\"%targ_name]\n",
    "    \n",
    "    # search the MAST archive again, this time looking for \n",
    "    # all grism and imaging observations with the given target name\n",
    "    tabs = overlaps.find_overlaps(parent, buffer_arcmin=0.01, \n",
    "                                  filters=['G102', 'G141', 'F098M', 'F105W', 'F125W', 'F140W'], \n",
    "                                  instruments=['WFC3/IR','WFC3/UVIS','ACS/WFC'], \n",
    "                                  extra=extra, close=False)\n",
    "    if False:\n",
    "        # retrieve raw data from MAST\n",
    "        s3_status = os.system('aws s3 ls s3://stpubdata --request-payer requester')\n",
    "        auto_script.fetch_files(field_root=jtargname, HOME_PATH=HOME_PATH, remove_bad=True, \n",
    "                                reprocess_parallel=True, s3_sync=(s3_status == 0))\n",
    "\n",
    "    # Move the figure files to $HOME_PATH/query_results/ so that they are not overwritten\n",
    "    os.system('mv %s/%s_footprint.fits %s/query_results/%s_footprint_%s.fits'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.npy %s/query_results/%s_footprint_%s.npy'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_footprint.pdf %s/query_results/%s_footprint_%s.pdf'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "    os.system('mv %s/%s_info.dat %s/query_results/%s_info_%s.dat'%(HOME_PATH, jtargname, HOME_PATH, jtargname, targ_name))\n",
    "\n",
    "    os.chdir(HOME_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following directories are created from auto_script.fetch_files:\n",
    "        [HOME_PATH]/j0333m2742\n",
    "        [HOME_PATH]/j0333m2742/RAW\n",
    "        [HOME_PATH]/j0333m2742/Prep\n",
    "        [HOME_PATH]/j0333m2742/Extractions\n",
    "        [HOME_PATH]/j0333m2742/Persistance\n",
    "         \n",
    "        \n",
    "RAW/ is where the downloaded raw and pre-processed data are stored.\n",
    "\n",
    "Prep/ is the general working directory for processing and analyses.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW     = glob(HOME_PATH + '/*/RAW')[0]\n",
    "PATH_TO_PREP    = glob(HOME_PATH + '/*/PREP')[0]\n",
    "\n",
    "# Move to the Prep directory\n",
    "os.chdir(PATH_TO_PREP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract exposure information from downloaded flt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all pre-processed flt files in the RAW directory\n",
    "files = glob('%s/*flt.fits'%PATH_TO_RAW)\n",
    "# Generate a table from the headers of the flt fits files\n",
    "info = grizli.utils.get_flt_info(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``info`` table includes relevant exposure details: e.g., filter, instrument, targetname, PA, RA, DEC.\n",
    "    \n",
    "Print the first three rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `grizli` to parse the headers of the downloaded flt files in RAW/ and sort them into \"visits\". Each visit represents a specific pointing + orient + filter and contains the list of its associated exposure files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the table and group exposures into associated \"visits\"\n",
    "visits, filters = grizli.utils.parse_flt_files(info=info, uniquename=True)\n",
    "\n",
    "# an F140W imaging visit\n",
    "print ('\\n\\n visits[0]\\n\\t product: ', visits[0]['product'], '\\n\\t files: ', visits[0]['files'])\n",
    "\n",
    "# a g141 grism visit\n",
    "print ('\\n\\n visits[1]\\n\\t product: ', visits[1]['product'], '\\n\\t files: ', visits[1]['files'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Pre-process raw data</center></h1>\n",
    "\n",
    "We are now ready to pre-process the raw data we downloaded from MAST.\n",
    "\n",
    "\n",
    "### process_direct_grism_visit performs all of the necessary pre-processing:\n",
    "\n",
    "- Copying the flt files from Raw/ to Prep/\n",
    "- Astrometric registration/correction\n",
    "- Grism sky background subtraction and flat-fielding\n",
    "- Extract visit-level catalogs and segmentation images from the direct imaging\n",
    "\n",
    "\n",
    "\n",
    "### The final products are:\n",
    "\n",
    "1. Aligned, background-subtracted FLTS\n",
    "\n",
    "2. Drizzled mosaics of direct and grism images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'N' in field.upper(): radec_catalog = PATH_TO_CATS + '/goodsN_radec.cat'\n",
    "if 'S' in field.upper(): radec_catalog = PATH_TO_CATS + '/goodsS_radec.cat'                    \n",
    "\n",
    "product_names = np.array([visit['product'] for visit in visits])\n",
    "filter_names = np.array([visit['product'].split('-')[-1] for visit in visits])\n",
    "basenames = np.array([visit['product'].split('.')[0]+'.0' for visit in visits])\n",
    "\n",
    "# First process the G102/F105W visits, then G141/F140W\n",
    "for ref_grism, ref_filter in [('G102', 'F105W'), ('G141', 'F140W')]:\n",
    "    print ('Processing %s + %s visits'%(ref_grism, ref_filter))\n",
    "    for v, visit in enumerate(visits):\n",
    "        product = product_names[v]\n",
    "        basename = basenames[v]\n",
    "        filt1 = filter_names[v]\n",
    "        field_in_contest = basename.split('-')[0]\n",
    "        if (ref_filter.lower() == filt1.lower()):\n",
    "            #Found a direct image, now search for grism counterpart\n",
    "            grism_index= np.where((basenames == basename) & (filter_names == ref_grism.lower()))[0][0]\n",
    "            if True:\n",
    "                # run the pre-process script\n",
    "                status = process_direct_grism_visit(direct = visit,\n",
    "                                                    grism = visits[grism_index],\n",
    "                                                    radec = radec_catalog, \n",
    "                                                    align_mag_limits = [14, 23])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Examining outputs from the pre-processing steps</center></h1>\n",
    "\n",
    "## Astrometric Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_TO_PREP)\n",
    "!cat gs1-cxt-09-227.0-f105w_wcs.log\n",
    "Image(filename = PATH_TO_PREP + '/gs1-cxt-09-227.0-f105w_wcs.png', width = 600, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grism sky subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_TO_PREP)\n",
    "Image(filename = PATH_TO_PREP + '/gs1-cxt-09-227.0-g102_column.png', width = 600, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
