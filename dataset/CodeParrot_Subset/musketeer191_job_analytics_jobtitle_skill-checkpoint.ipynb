{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building JobTitle-Skill matrix\n",
    "\n",
    "Running LDA on document-skill matrix, where each document is a job post, still does not give good results!!! What is the problem here?\n",
    "\n",
    "It seems that the job post level has too many noises:\n",
    "+ other info not relating to skills i.e. salary, location, working time, required experience.\n",
    "\n",
    "Thus, we now try putting all posts of the same job title together so that the aggregated skill info can win over the noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cluster_skill_helpers as cluster_skill_helpers\n",
    "\n",
    "from cluster_skill_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = 'd:/larc_projects/job_analytics/'; DATA_DIR = HOME_DIR + 'data/clean/'\n",
    "SKILL_DIR = DATA_DIR + 'skill_cluster/'; RES_DIR = HOME_DIR + 'results/reports/skill_cluster/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(DATA_DIR + 'jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill_df = pd.read_csv(SKILL_DIR + 'skill_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapse all posts of the same job title into a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_job_title = jobs.groupby('title')\n",
    "job_title_df = by_job_title.agg({'job_id': lambda x: ','.join(x), 'doc': lambda x: 'next_doc'.join(x)})\n",
    "\n",
    "job_title_df = job_title_df.add_prefix('agg_').job_title_dfet_index()\n",
    "job_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_job_title = by_job_title.ngroups\n",
    "print('# job titles: %d' %n_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(cluster_skill_helpers)\n",
    "from cluster_skill_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jd_docs = job_title_df['agg_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This version of skills still contain stopwords\n",
    "doc_skill = buildDocSkillMat(jd_docs, skill_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Concat matrices doc_unigram, doc_bigram and doc_trigram to get occurrences of all skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "jobtitle_skill = hstack([doc_unigram, doc_bigram, doc_trigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with(open(SKILL_DIR + 'jobtitle_skill.mtx', 'w')) as f:\n",
    "    mmwrite(f, jobtitle_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobtitle_skill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobtitle_skill = jobtitle_skill.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular skills by job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job_title_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_of_top_skill = np.apply_along_axis(np.argmax, 1, jobtitle_skill)\n",
    "\n",
    "# skill_df = skills\n",
    "skills = skill_df['skill']\n",
    "top_skill_by_job_title = pd.DataFrame({'job_title': job_titles, 'idx_of_top_skill': idx_of_top_skill})\n",
    "top_skill_by_job_title['top_skill'] = top_skill_by_job_title['idx_of_top_skill'].apply(lambda i: skills[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_skill_by_job_title.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with(open(SKILL_DIR + 'jobtitle_skill.mtx', 'r')) as f:\n",
    "    jobtitle_skill = mmread(f)\n",
    "\n",
    "jobtitle_skill = jobtitle_skill.tocsr()\n",
    "jobtitle_skill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_titles = job_title_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each row (corresponding to a jobtitle) in matrix jobtitle_skill, get non-zero freqs\n",
    "global k\n",
    "k = 3\n",
    "\n",
    "def getTopK_Skills(idx):\n",
    "    title = job_titles[idx]\n",
    "    print('Finding top-{} skills of job title {}...'.format(k, title))\n",
    "    \n",
    "    skill_occur = jobtitle_skill.getrow(idx)\n",
    "    tmp = find(skill_occur)\n",
    "    nz_indices = tmp[1]\n",
    "    values = tmp[2]\n",
    "    res = pd.DataFrame({'job_title': title, 'skill_found_in_jd': skills[nz_indices], 'occur_freq': values})\n",
    "\n",
    "    res.sort_values('occur_freq', ascending=False, inplace=True)\n",
    "    return res.head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getTopK_Skills(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = map(getTopK_Skills, range(n_job_title))\n",
    "res = pd.concat(frames) # concat() is great as it can concat as many df as possible\n",
    "res.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.to_csv(RES_DIR + 'top3_skill_by_jobtitle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
