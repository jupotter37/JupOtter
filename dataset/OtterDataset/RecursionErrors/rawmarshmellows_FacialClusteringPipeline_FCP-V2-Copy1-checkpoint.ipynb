{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the paths that facenet is in\n",
    "sys.path.insert(0, \"/Users/kevinlu/Documents/Facial-Recognition/custom_facenet/src\")\n",
    "sys.path.insert(0, \"/Users/kevinlu/Documents/Facial-Recognition/custom_facenet/src/align\")\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import detect_face\n",
    "import facenet\n",
    "import tensorflow as tf # NOTE: this has to use Tensorflow version 1.x\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy as sp\n",
    "import glob\n",
    "import copy\n",
    "import dlib\n",
    "import math\n",
    "import time\n",
    "import uuid\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"20170216-091149\"\n",
    "image_paths = glob.glob(\"/Users/kevinlu/Documents/datasets/allfaces/**/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Face:\n",
    "    \"\"\"\n",
    "    This is a data structure to store the faces and the relevant information to cluster it later on\n",
    "    \n",
    "    :: face_image is the image of the resized face\n",
    "    :: image_path is the image path of the photo that the face was extracted from\n",
    "    :: name is the name of the face and used to test our accuracy\n",
    "    :: original_image_with_bounding_box is the original image with a box drawn around the face\n",
    "    :: embedding is the 128 dimension embedding in the a unit sphere\n",
    "    :: label is the cluster label that was assigned to this face\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_path, resized_image_path, name, absolute_distance_neighbours = None,\\\n",
    "                  embedding = None, label = None):\n",
    "        \n",
    "        self.image_path = image_path # this is the image path that contains the photo \n",
    "                                     # this face is located in            \n",
    "        \n",
    "        self.resized_image_path = resized_image_path\n",
    "        self.absolute_distance_neighbours = absolute_distance_neighbours\n",
    "        self.name = name\n",
    "        self.embedding = embedding\n",
    "        self.label = label\n",
    "    \n",
    "    def __str__(self):\n",
    "        return(\"Name: {}\\nLabel: {}\".format(self.name_of_face, self.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_faces = pickle.load(open(\"allfaces copy.p\", \"rb\"))\n",
    "faces = pickle_faces[\"faces\"]\n",
    "faces_dict = pickle_faces[\"face_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_faces(image_paths):\n",
    "    \n",
    "    # Set the parameter values needed for MTCNN\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor used for the pyramid\n",
    "    margin = 20 # the margin around the bboxes\n",
    "    output_image_size = 160 # 160 x 160 is the image size that facenet requires\n",
    "    \n",
    "    # Get the image size\n",
    "    sample_image = mpimg.imread(image_paths[0])\n",
    "    img_size = sample_image.shape\n",
    "    \n",
    "    # Storage of all the faces \n",
    "    faces = []\n",
    "    \n",
    "    # Storage of the number of faces from each individual\n",
    "    faces_dict = {}\n",
    "    \n",
    "    # Initialize the MTCNN networks\n",
    "    with tf.Graph().as_default():\n",
    "        ## TODO: GPU options\n",
    "        # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<gpu_memory_fraction>)\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "        print(\"Total images: {}\".format(len(image_paths)))\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            # Read in the image\n",
    "            image = mpimg.imread(image_path)\n",
    "            \n",
    "            # Now find the bboxes\n",
    "            bboxes,_ = detect_face.detect_face(image, minsize, pnet, rnet, onet, threshold, factor)\n",
    "#             bboxes = bboxes[:, 0:4] # get the x1, y1, x2, y2 for the corners\n",
    "            bboxes = bboxes[:1, 0:4] # only get the first bboxes for easier evaluation\n",
    "\n",
    "\n",
    "            for j, bbox in enumerate(bboxes):\n",
    "\n",
    "                # Apply margins while confining the bboxes to be contained \n",
    "                # within the dimensions of the image\n",
    "                bbox[0] = np.maximum(bbox[0]-margin/2, 0)\n",
    "                bbox[1] = np.maximum(bbox[1]-margin/2, 0)\n",
    "                bbox[2] = np.minimum(bbox[2]+margin/2, img_size[1])\n",
    "                bbox[3] = np.minimum(bbox[3]+margin/2, img_size[0])\n",
    "                bbox = bbox.astype(np.int32)\n",
    "\n",
    "                # Get the face\n",
    "                face_image = image[bbox[1]:bbox[3], bbox[0]:bbox[2],:]\n",
    "\n",
    "                # Resize the face to a size that facenet can use\n",
    "                face_resized = sp.misc.imresize(face_image, (output_image_size, output_image_size), interp = 'bilinear')\n",
    "                \n",
    "                \n",
    "                # Get the name of the face (for evaluation purposes)\n",
    "                name = image_path.split(\"/\")[6] \n",
    "                \n",
    "                # Create the path to save the resized image for later use\n",
    "                resized_image_file_path = image_path.split(\"/\")\n",
    "                resized_image_file_path[7] = image_path.split(\"/\")[7].split(\".\")[0] + \"_resized_face_{}.jpg\".format(j+1)\n",
    "                \n",
    "                resized_image_file_path[5] = image_path.split(\"/\")[5] + \"_resized\"\n",
    "                \n",
    "                resized_image_file_path = \"/\".join(resized_image_file_path)\n",
    "                \n",
    "                path = Path(resized_image_file_path)\n",
    "                path.parent.mkdir(parents=True, exist_ok=True) \n",
    "                \n",
    "                # Save the resized image\n",
    "                sp.misc.imsave(resized_image_file_path, face_resized) \n",
    "                \n",
    "                face = Face(image_path, resized_image_file_path, name)\n",
    "               \n",
    "                # Save the face for later to be used in evaluation of our algorithm\n",
    "                if name not in faces_dict:\n",
    "                    faces_dict[name] = [face]\n",
    "                else:\n",
    "                    faces_dict[name].append(face)\n",
    "                    \n",
    "                \n",
    "                faces.append(face)\n",
    "                \n",
    "            \n",
    "            print(\"Processed {}/{} images\".format(i + 1, len(image_paths)), end = \"\\r\")            \n",
    "    return(np.array(faces), faces_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# faces, faces_dict = find_faces(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_embedding_layer_for_facenet():\n",
    "    # Now utilize facenet to find the embeddings of the faces\n",
    "    # Get the save files for the models \n",
    "    meta_file, ckpt_file = facenet.get_model_filenames(MODEL_DIR)\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session().as_default() as sess:\n",
    "            model_dir_exp = os.path.expanduser(MODEL_DIR)\n",
    "            print(\"importing graph\")\n",
    "            saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\n",
    "            print(\"restoring session\")\n",
    "            saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_layer = lambda img : sess.run(embeddings, feed_dict = {images_placeholder : img, phase_train_placeholder : False})\n",
    "    return(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# embedding_layer = load_embedding_layer_for_facenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    # just normalizing the image\n",
    "    mean = np.mean(x) # mean of all elements\n",
    "    std = np.std(x) # std of all elements\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size)) # get the max between the std, and 1/sqrt(number_of_all_elements)\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return(y)\n",
    "\n",
    "def assign_embeddings(embedding_layer, faces, batch_size = 32):\n",
    "    \n",
    "    # Get the save files for the models\n",
    "    n_images = len(faces)\n",
    "    n_batches = int(np.ceil(float(n_images)/batch_size))\n",
    "    embeddings = np.zeros((n_images, 128))\n",
    "    face_images = []\n",
    "    \n",
    "    # First preprocess the faces\n",
    "    for face in faces:\n",
    "        face_image = mpimg.imread(face.resized_image_path)\n",
    "        prewhitened_face_image = prewhiten(face_image)\n",
    "        face_images.append(prewhitened_face_image)\n",
    "\n",
    "    print(\"{} batch(es) of size {}\".format(n_batches, batch_size))\n",
    "    \n",
    "    # Find the embeddings\n",
    "    for i in range(n_batches):\n",
    "        print(\"Processing batch {}/{}\".format(i+1, n_batches), end = \"\\r\")\n",
    "        start = i * batch_size\n",
    "        end = min((i + 1) * batch_size, n_images)\n",
    "\n",
    "        # Get the embeddings\n",
    "        embeddings[start:end, :] = embedding_layer(face_images[start:end])\n",
    "        \n",
    "    # Assign the embeddings \n",
    "    for i, face in enumerate(faces):\n",
    "        face.embedding = embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# assign_embeddings(embedding_layer, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def assign_absolute_distance_neighbours_for_faces(faces, K = 9):\n",
    "    for i, face1 in enumerate(faces):\n",
    "        nearest_neighbour = []\n",
    "        print(\"Calculating absolute distance for face {}/{}\".format(i + 1, len(faces)), end = \"\\r\")\n",
    "\n",
    "        for j, face2 in enumerate(faces):\n",
    "#             print(\"Calculating neighbour {}/{} for face {}\".format(j + 1, len(faces), i + 1), end = \"\\r\")\n",
    "            distance = np.linalg.norm(face1.embedding - face2.embedding, ord = 1)\n",
    "            neighbour = Neighbour(face2, distance)\n",
    "            nearest_neighbour.append(neighbour)\n",
    "        nearest_neighbour.sort(key = lambda x: x.distance)\n",
    "        face1.absolute_distance_neighbours = nearest_neighbour[0:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "class Neighbour:\n",
    "    def __init__(self, entity, distance):\n",
    "        self.entity = entity\n",
    "        self.distance = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating absolute distance for face 13233/13233\r"
     ]
    }
   ],
   "source": [
    "assign_absolute_distance_neighbours_for_faces(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while pickling an object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1786f6686bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetrecursionlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfaces_info_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"faces\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"face_dict\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfaces_dict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces_info_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allfaces.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while pickling an object"
     ]
    }
   ],
   "source": [
    "# faces_info_dict = {\"faces\" : faces, \"face_dict\" : faces_dict}\n",
    "# pickle.dump(faces_info_dict, open(\"allfaces.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bd755371744c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allfaces.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "pickle.dump(faces, open(\"allfaces.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self):\n",
    "        self.faces = list()\n",
    "        self.absolute_distance_neighbours = None\n",
    "        \n",
    "    def faces_in_cluster(self):\n",
    "        faces_dict = {}\n",
    "        for face in self.faces:\n",
    "            if face.name not in faces_dict.keys():\n",
    "                faces_dict[face.name] = 1\n",
    "            else:\n",
    "                faces_dict[face.name] += 1\n",
    "        \n",
    "        return(faces_dict)\n",
    "                \n",
    "    def debug(self):\n",
    "        print(\"Faces in cluster:\")\n",
    "        for face in self.faces:\n",
    "            print(face.name)\n",
    "        \n",
    "#         print(\"Absolute distance neighbours:\")\n",
    "#         for neighbour in self.absolute_distance_neighbours:\n",
    "#             print(absolute_distance_neighbours.)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_distance_between_clusters(cluster1, cluster2):\n",
    "    nearest_distance = sys.float_info.max\n",
    "    for face1 in cluster1.faces:\n",
    "        for face2 in cluster2.faces:\n",
    "            distance = np.linalg.norm(face1.embedding - face2.embedding, ord = 1)\n",
    "            \n",
    "            if distance < nearest_distance: \n",
    "                nearest_distance = distance\n",
    "                \n",
    "            # If there is a distance of 0 then there is no need to continue\n",
    "            if distance == 0:\n",
    "                return(0)\n",
    "    return(nearest_distance)\n",
    "            \n",
    "            \n",
    "def assign_absolute_distance_neighbours_for_clusters(clusters, N = 9):\n",
    "    for i, cluster1 in enumerate(clusters):\n",
    "        nearest_neighbours = []\n",
    "        print(\"Absolute distance for cluster {}/{}\".format(i + 1, len(clusters)), end = \"\\r\")\n",
    "        for j, cluster2 in enumerate(clusters):\n",
    "            distance = find_nearest_distance_between_clusters(cluster1, cluster2)\n",
    "#             print(\"Calculating neighbour {}/{} for cluster {}\".format(j + 1, len(faces), i + 1), end = \"\\r\")\n",
    "\n",
    "            neighbour = Neighbour(cluster2, distance)\n",
    "            nearest_neighbours.append(neighbour)\n",
    "        nearest_neighbours.sort(key = lambda x: x.distance)\n",
    "        cluster1.absolute_distance_neighbours = nearest_neighbours[0:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assigning each face to a cluster\n",
    "def initial_cluster_creation(faces):\n",
    "    clusters = []\n",
    "    for face in faces:\n",
    "        cluster = Cluster() \n",
    "        cluster.faces.append(face)\n",
    "        clusters.append(cluster)\n",
    "    return(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clusters = initial_cluster_creation(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute distance for cluster 13233/13233\r"
     ]
    }
   ],
   "source": [
    "assign_absolute_distance_neighbours_for_clusters(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters[0].absolute_distance_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_normalized_distance_between_clusters(cluster1, cluster2, K = 9):\n",
    "    all_faces_in_clusters = cluster1.faces + cluster2.faces\n",
    "    normalized_distance = 0\n",
    "\n",
    "    for face in all_faces_in_clusters:\n",
    "        total_absolute_distance_for_top_K_neighbours = sum([neighbour.distance for neighbour in face.absolute_distance_neighbours[0:K]]) \n",
    "#         print(\"Face: {}\".format(face.name))\n",
    "#         print(\"Total distance to top {}: {}\".format(K, total_absolute_distance_for_top_K_neighbours))\n",
    "        normalized_distance += total_absolute_distance_for_top_K_neighbours\n",
    "    \n",
    "#     print(\"Normalized distance: {}\".format(normalized_distance))\n",
    "    # Now average the distance\n",
    "    K = min(len(face.absolute_distance_neighbours), K)\n",
    "    normalized_distance = normalized_distance/K\n",
    "    \n",
    "    # then divide by all the faces in the cluster\n",
    "    normalized_distance = normalized_distance/len(all_faces_in_clusters)\n",
    "    normalized_distance = (1/normalized_distance) * find_nearest_distance_between_clusters(cluster1, cluster2)\n",
    "    return(normalized_distance)\n",
    "\n",
    "def find_rank_order_distance_between_clusters(cluster1, cluster2):\n",
    "    return(find_rank_order(cluster1, cluster2))            \n",
    "\n",
    "def find_rank_order(entity1, entity2):\n",
    "    distance_entity1_entity2, num_neighbours_entity1 = find_asym_rank_order(entity1, entity2)\n",
    "    distance_entity2_entity1, num_neighbours_entity2 = find_asym_rank_order(entity2, entity1)\n",
    "    min_neighbours = min(num_neighbours_entity1, num_neighbours_entity2)\n",
    "    return((distance_entity1_entity2 + distance_entity2_entity1)/min_neighbours)\n",
    "\n",
    "def find_asym_rank_order(entity1, entity2):\n",
    "    penalty = 0\n",
    "    for i, neighbour1 in enumerate(entity1.absolute_distance_neighbours):\n",
    "#         print(\"i is: {}\".format(i))\n",
    "        for j, neighbour2 in enumerate(entity2.absolute_distance_neighbours):\n",
    "#             print(\"j is: {}\".format(j))\n",
    "            if neighbour1.entity is neighbour2.entity:\n",
    "#                 print(\"found match\")\n",
    "#                 print(\"add penalty: {}\".format(j))\n",
    "                if j == 0: # this means that we found the rank of entity2 in entity1's neighbouts\n",
    "                    return(penalty, i + 1)\n",
    "                else:\n",
    "                    penalty += j\n",
    "#         print(\"penalty is: {}\".format(penalty))\n",
    "    return(penalty, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def find_clusters(faces):\n",
    "    clusters = initial_cluster_creation(faces) # makes each face a cluster\n",
    "    assign_absolute_distance_neighbours_for_clusters(clusters)\n",
    "    t = 14 # threshold number for rank-order clustering\n",
    "    prev_cluster_number = len(clusters)\n",
    "    num_created_clusters = prev_cluster_number\n",
    "    is_initialized = False\n",
    "\n",
    "    while (not is_initialized) or (num_created_clusters):\n",
    "        print(\"Number of clusters in this iteration: {}\".format(len(clusters)))\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for cluster in clusters:\n",
    "            G.add_node(cluster)\n",
    "            \n",
    "        processed_pairs = 0\n",
    "        \n",
    "        # Find the candidate merging pairs\n",
    "        for i, cluster1 in enumerate(clusters):\n",
    "            \n",
    "            # Only get the top 20 nearest neighbours for each cluster\n",
    "            for j, cluster2 in enumerate([neighbour.entity for neighbour in \\\n",
    "                                          cluster1.absolute_distance_neighbours]):\n",
    "                processed_pairs += 1\n",
    "                print(\"Processed {}/{} pairs\".format(processed_pairs, len(clusters) * 20), end=\"\\r\")\n",
    "                # No need to merge with yourself \n",
    "                if cluster1 is cluster2:\n",
    "                    continue\n",
    "                else: \n",
    "                    normalized_distance = find_normalized_distance_between_clusters(cluster1, cluster2)\n",
    "                    if (normalized_distance >= 1):\n",
    "                        continue\n",
    "                    rank_order_distance = find_rank_order_distance_between_clusters(cluster1, cluster2)\n",
    "                    if (rank_order_distance >= t):\n",
    "                        continue\n",
    "                    G.add_edge(cluster1, cluster2)\n",
    "        \n",
    "        # Create the new clusters            \n",
    "        clusters = []\n",
    "        for _clusters in nx.connected_components(G):\n",
    "            new_cluster = Cluster()\n",
    "            for cluster in _clusters:\n",
    "                for face in cluster.faces:\n",
    "                    new_cluster.faces.append(face)\n",
    "            clusters.append(new_cluster)\n",
    "\n",
    "\n",
    "        current_cluster_number = len(clusters)\n",
    "        num_created_clusters = prev_cluster_number - current_cluster_number\n",
    "        prev_cluster_number = current_cluster_number\n",
    "\n",
    "        \n",
    "        # Recalculate the distance between clusters\n",
    "        assign_absolute_distance_neighbours_for_clusters(clusters)\n",
    "        \n",
    "\n",
    "        is_initialized = True\n",
    "\n",
    "    # Now that the clusters have been created, separate them into clusters that have one face\n",
    "    # and clusters that have more than one face\n",
    "    unmatched_clusters = []\n",
    "    matched_clusters = []\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if len(cluster.faces) == 1:\n",
    "            unmatched_clusters.append(cluster)\n",
    "        else:\n",
    "            matched_clusters.append(cluster)\n",
    "            \n",
    "    matched_clusters.sort(key = lambda x: len(x.faces), reverse = True)\n",
    "            \n",
    "    return(matched_clusters, unmatched_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters in this iteration: 13233\n",
      "Processed 119097/119097 pairs\n",
      "Absolute distance for cluster 40/9181\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1bfb0fc3b253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatched_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmatched_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-473ebfa65163>\u001b[0m in \u001b[0;36mfind_clusters\u001b[0;34m(faces, clusters)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Recalculate the distance between clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#         print(\"assigning absolute distances\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0massign_absolute_distance_neighbours_for_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-cbcbfa228954>\u001b[0m in \u001b[0;36massign_absolute_distance_neighbours_for_clusters\u001b[0;34m(clusters, K)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Absolute distance for cluster {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nearest_distance_between_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#             print(\"Calculating neighbour {}/{} for cluster {}\".format(j + 1, len(faces), i + 1), end = \"\\r\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-cbcbfa228954>\u001b[0m in \u001b[0;36mfind_nearest_distance_between_clusters\u001b[0;34m(cluster1, cluster2)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mface1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mface2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mface2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnearest_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matched_clusters, unmatched_cluster = find_clusters(faces, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Show the faces in each cluster\n",
    "def peek_at_biggest_k_clusters(clusters, num_clusters, num_faces):\n",
    "    num_clusters = num_clusters if num_clusters < len(clusters) else len(clusters)\n",
    "    num_faces = num_faces if 1 < num_faces else 2\n",
    "    f, ax = plt.subplots(num_clusters, num_faces, figsize = (15, 15))\n",
    "    for i, cluster in enumerate(matched_clusters[0:num_clusters]):\n",
    "        for j, face in enumerate(cluster.faces[0:num_faces]):\n",
    "            ax[i][j].set_title(\"Faces in cluster: {}\".format(len(cluster.faces)))\n",
    "            ax[i][j].imshow(mpimg.imread(face.resized_image_path))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "peek_at_biggest_k_clusters(matched_clusters, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
