{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1c75a9-71ff-44fb-9a20-30b4def0de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create a local database of your personal film profile by scraping letterboxd\n",
    "#1a. We're going to implement a tree search to do this. Starting from my user_id, and branching out using a defined formula.\n",
    "#1b. For each user_id, we will find a list of films from their diary.\n",
    "#1c. For each film that they rated 5 stars, we'll add that to our 'good_films_set'\n",
    "#1d. For each film in the 'good_films_list', we'll find a list of users who rated it 5 stars, and add them to our 'users_set'\n",
    "#1e. Then, iterate the search.\n",
    "#1f. We're planning on building a 'total_space_of_films_users_etc.', but focussing on 'good_users' first in case our IP address gets blocked.\n",
    "\n",
    "#2. Create a Recommender Engine that takes my letterbox ratings and finds the users with the closest ratings\n",
    "#2a.\n",
    "\n",
    "#3. Create a simple interface (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f104cc0-6c67-4c97-bbde-e904a5ebe4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "import re\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16aaf3e2-7fef-4d4f-a5e0-825061086f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_user(user_id):\n",
    "    # returns one of [error, FilmObject[] ]\n",
    "    page = 1 # TODO - ITERATE THROUGH PAGES\n",
    "    url = f'https://letterboxd.com/{user_id}/films/diary/page/{page}' \n",
    "    req = request.Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'})\n",
    "    c = request.urlopen(req)\n",
    "    r = c.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(r,'html.parser')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "def scrape_film(film_id):\n",
    "    # returns one of [error, UserObject[] ]\n",
    "    rating = 5\n",
    "    page = 1 # TODO - ITERATE THROUGH PAGES\n",
    "    url = f'https://letterboxd.com/film/{film_id}/members/rated/{rating}/page/{page}'\n",
    "    req = request.Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'})\n",
    "    c = request.urlopen(req)\n",
    "    r = c.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(r,'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9b26ba6-3615-4bbc-b454-dc676308a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_diary(user_id):\n",
    "    page = 1\n",
    "    while True:\n",
    "        try:\n",
    "            data = scrape_user(user_id)\n",
    "            page += 1\n",
    "            sleep(1)\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6c821a0-e592-4943-96b0-c521fb977119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_film_raters(film_id, rating):\n",
    "    page = 1\n",
    "    while True:\n",
    "        try:\n",
    "            rating = 10\n",
    "            data = scrape_film(film_id)\n",
    "            page += 1\n",
    "            sleep(1)\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "244e3812-41e1-46db-b140-acb6b926a452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nUsers: user_id[]\\n\\nFilmObject: {\\n    film_id: string,\\n    rating: int<1-10>,\\n    ...\\n}\\n\\ndata = {\\n    user_id: {\\n        films: FilmObject[],\\n    }\\n}\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Users: user_id[]\n",
    "\n",
    "FilmObject: {\n",
    "    film_id: string,\n",
    "    rating: int<1-10>,\n",
    "    ...\n",
    "}\n",
    "\n",
    "data = {\n",
    "    user_id: {\n",
    "        films: FilmObject[],\n",
    "    }\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0c09517-f84e-4255-8b3c-b7a54a18ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oppenheimer-2023\n",
      "10\n",
      "moneyball\n",
      "9\n",
      "chronicle\n",
      "5\n",
      "shutter-island\n",
      "10\n",
      "role-models\n",
      "6\n",
      "jerry-maguire\n",
      "9\n",
      "spider-man-across-the-spider-verse\n",
      "9\n",
      "theres-no-place-like-home\n",
      "8\n",
      "el-camino-a-breaking-bad-movie\n",
      "8\n",
      "white-chicks\n",
      "8\n",
      "ant-man-and-the-wasp-quantumania\n",
      "5\n",
      "boyz-n-the-hood\n",
      "9\n",
      "hustle-2022\n",
      "9\n",
      "warrior\n",
      "10\n",
      "stand-by-me\n",
      "3\n",
      "abraham-lincoln-vampire-hunter\n",
      "3\n",
      "the-departed\n",
      "10\n",
      "bullet-train\n",
      "9\n",
      "the-martian\n",
      "8\n",
      "shrek\n",
      "8\n",
      "monty-python-and-the-holy-grail\n",
      "10\n",
      "friday\n",
      "9\n",
      "speed\n",
      "7\n",
      "up\n",
      "8\n",
      "the-grand-budapest-hotel\n",
      "8\n",
      "catch-me-if-you-can-2002\n",
      "7\n",
      "ready-player-one\n",
      "8\n",
      "uncut-gems\n",
      "8\n",
      "walle\n",
      "9\n",
      "shaun-of-the-dead\n",
      "8\n",
      "guardians-of-the-galaxy\n",
      "9\n",
      "john-wick\n",
      "8\n",
      "spider-man-no-way-home\n",
      "8\n",
      "rio-2011\n",
      "7\n",
      "the-wolf-of-wall-street\n",
      "7\n",
      "the-intouchables\n",
      "9\n",
      "casablanca\n",
      "9\n",
      "kong-skull-island\n",
      "5\n",
      "avatar\n",
      "5\n",
      "shazam\n",
      "7\n",
      "the-batman\n",
      "9\n",
      "donnie-darko\n",
      "7\n",
      "birdemic-shock-and-terror\n",
      "0\n",
      "the-suicide-squad\n",
      "6\n",
      "the-social-network\n",
      "9\n",
      "the-good-the-bad-and-the-ugly\n",
      "10\n",
      "fantastic-mr-fox\n",
      "8\n",
      "back-to-the-future\n",
      "5\n",
      "no-country-for-old-men\n",
      "9\n",
      "the-usual-suspects\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "user_id = 'ncklake'\n",
    "\n",
    "soup = scrape_user(user_id)\n",
    "films = soup.find_all('tr', class_='diary-entry-row')\n",
    "\n",
    "pattern = r'/film/(.*?)/'\n",
    "\n",
    "for film in films:\n",
    "    # Find the film-slug using a pattern in class name\n",
    "    film_details = film.find('div', class_=re.compile('^really-lazy-load poster film-poster film-poster-\\d+ linked-film-poster$'))\n",
    "    film_slug = film_details['data-film-slug']\n",
    "    \n",
    "    match = re.search(pattern, film_slug)\n",
    "    film_id = match.group(1) if match else None\n",
    "    \n",
    "    print(film_id)\n",
    "\n",
    "    # Find the rating using a pattern in class name\n",
    "    rating_details = film.find('input', class_=re.compile('^rateit-field diary-rating-\\d+$'))\n",
    "    rating = int(rating_details['value'])\n",
    "    print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1af07353-f8aa-4d62-8ed3-32e28a836400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"really-lazy-load poster film-poster film-poster-6286 linked-film-poster\" data-cache-busting-key=\"0880b9ae\" data-film-id=\"6286\" data-film-slug=\"/film/moneyball/\" data-hide-tooltip=\"true\" data-image-height=\"52\" data-image-width=\"35\" data-linked=\"linked\" data-poster-url=\"/film/moneyball/image-150/\" data-target-link=\"/ncklake/film/moneyball/\" data-target-link-target=\"\"> <img alt=\"Moneyball\" class=\"image\" height=\"52\" src=\"https://s2.ltrbxd.com/static/img/empty-poster-35.9df54d4d.png\" width=\"35\"/> <span class=\"frame\"><span class=\"frame-title\"></span></span> </div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films[1].find('div', class_=re.compile('^really-lazy-load poster film-poster film-poster-\\d+ linked-film-poster$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7eaab167-fb5b-4853-a3d0-d5f335e04663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carterk2\n",
      "ampre\n",
      "daltonisafraid\n",
      "laraelias\n",
      "carmainz\n",
      "ramikfd\n",
      "brendan_clotz\n",
      "captaintony\n",
      "ashtenwickham\n",
      "maiquell\n",
      "lorene21\n",
      "ranvirbhaya\n",
      "brunolcs\n",
      "floptrs\n",
      "ezio_altair\n",
      "merecatta\n",
      "badhampreschool\n",
      "katiespeedd\n",
      "daysofheaven\n",
      "joshlim\n",
      "amen80\n",
      "stijntr\n",
      "scenesofnoir\n",
      "lassebask\n",
      "angussheldon\n"
     ]
    }
   ],
   "source": [
    "film_id = 'oppenheimer-2023'\n",
    "\n",
    "soup = scrape_film(film_id)\n",
    "\n",
    "pattern = r'/([^/]*)/'\n",
    "\n",
    "user_table = soup.find('table', class_='person-table film-table').find('tbody').find_all('tr')\n",
    "\n",
    "users = []\n",
    "\n",
    "for user in user_table:\n",
    "\n",
    "    user_id = user.find('td').find('a')['href']\n",
    "\n",
    "    match = re.search(pattern, user_id)\n",
    "    user_id = match.group(1) if match else None\n",
    "    \n",
    "    users.append(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9a7e6c75-8164-46d8-82f1-df0df50a2401",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/1872260138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user_table-10.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Pickle the data dictionary using the highest protocol available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, tag)\u001b[0m\n\u001b[0;32m   1519\u001b[0m         \u001b[1;34m\"\"\"Calling tag.subtag is the same as calling tag.find(name=\"subtag\")\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m         \u001b[1;31m#print(\"Getattr %s.%s\" % (self.__class__, tag))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[1;31m# BS3: soup.aTag -> \"soup.find(\"a\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[0mtag_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# Open a file for writing\n",
    "with open(\"user_table-10.pkl\", \"wb\") as f:\n",
    "    # Pickle the data dictionary using the highest protocol available\n",
    "    pickle.dump(user_table, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b56a0391-4612-4c7b-9f57-07f5aec9c286",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/2914896534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user_table-10.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Load the pickled data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"user_table-10.pkl\", \"rb\") as f:\n",
    "    # Load the pickled data\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc4ace-0a9f-4619-8b46-ccc1b851edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
