{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downlaod chromedrive and install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linkden url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.linkedin.com/jobs/search/?currentJobId=4071452622&f_TPR=r604800&geoId=102713980&keywords=data%20analyst&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to chromedriver\n",
    "service = Service(r\"C:\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "\n",
    "# Pass the service to the Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get(\"https:\\\\www.linkedin.com\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Corrected CSS selector with escaping special characters\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, \".sign-in-form__sign-in-cta.my-2.py-1.btn-md.btn-secondary.block.min-h-\\\\[40px\\\\].babybear\\\\:w-full\")\n",
    "\n",
    "# Click the login button\n",
    "login_button.click()\n",
    "\n",
    "# Wait for the login page to load after clicking\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "password and user id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the username and password fields and input the credentials\n",
    "\n",
    "# Updated ID for the username input field\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "username.send_keys(\"Gmail_id\")\n",
    "\n",
    "# Updated ID for the password input field\n",
    "password = driver.find_element(By.ID, \"password\")\n",
    "password.send_keys(\"Password\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Sign in\" button and click it\n",
    "login_button = driver.find_element(By.CSS_SELECTOR, \".btn__primary--large.from__button--floating\")\n",
    "login_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job page\n",
    "# Data Analyst\n",
    "# driver.get(\"https://www.linkedin.com/jobs/search/?currentJobId=4071452622&distance=25&f_TPR=r604800&geoId=102713980&keywords=data%20analyst&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true\")\n",
    "# ML\n",
    "driver.get(\"https://www.linkedin.com/jobs/search/?currentJobId=4071440106&f_E=1%2C2&f_TPR=r86400&f_WT=1&geoId=102713980&keywords=data%20science&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true\")\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to linkedin_jobs_26-11-2024.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "# driver = webdriver.Chrome()  # Ensure you have the Chrome WebDriver installed\n",
    "# driver.get(\"https://www.linkedin.com/jobs/\")  # Replace with the actual LinkedIn Jobs URL\n",
    "\n",
    "# Lists to store the scraped data\n",
    "job_titles = []\n",
    "companies = []\n",
    "locations = []\n",
    "links = []\n",
    "\n",
    "# Function to safely find elements\n",
    "def safe_find_element(by, value, retries=3):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            return WebDriverWait(driver, 10).until(EC.presence_of_element_located((by, value)))\n",
    "        except Exception:\n",
    "            time.sleep(2)\n",
    "    raise Exception(f\"Element not found: {value}\")\n",
    "\n",
    "# Scraping job cards across multiple pages\n",
    "for i in range(1,20):  # Page range for pagination (e.g., 2 pages)\n",
    "    try:\n",
    "        # Wait for job cards to load\n",
    "        job_cards = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, 'job-card-container'))\n",
    "        )\n",
    "\n",
    "        # Extract data from each job card\n",
    "        for job_card in job_cards[:20]:  # Limit to first 20 job posts on each page\n",
    "            try:\n",
    "                # Job Title\n",
    "                role_element = job_card.find_element(By.XPATH, \".//a[contains(@class, 'job-card-list__title--link')]//span[@aria-hidden='true']/strong\")\n",
    "                role = role_element.text.strip()\n",
    "                job_titles.append(role)\n",
    "\n",
    "                # Company Name\n",
    "                company_element = job_card.find_element(By.XPATH, \".//div[contains(@class, 'artdeco-entity-lockup__subtitle')]//span\")\n",
    "                company = company_element.text.strip()\n",
    "                companies.append(company)\n",
    "\n",
    "                # Location\n",
    "                try:\n",
    "                    location_element = job_card.find_element(By.XPATH, \".//li[contains(@class, 'jkzqabuSPrVlSLarrvhTLSKXklZALcWZXBMHTIKw')]//span\")\n",
    "                    location = location_element.text.strip()\n",
    "                except Exception:\n",
    "                    location = \"Not Available\"  # Default if location is not found\n",
    "                locations.append(location)\n",
    "\n",
    "                # Job Link\n",
    "                job_link_element = job_card.find_element(By.XPATH, \".//a[contains(@class, 'job-card-list__title--link')]\")\n",
    "                job_link = job_link_element.get_attribute('href')\n",
    "                links.append(job_link)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data for a job card: {e}\")\n",
    "\n",
    "        # Short delay before navigating to the next page\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Attempt to click the next page button\n",
    "        try:\n",
    "            next_button = safe_find_element(By.XPATH, f\"//button[@aria-label='Page {i + 1}']\")\n",
    "            next_button.click()\n",
    "        except Exception:\n",
    "            try:\n",
    "                # If page number not found, locate and click the \"...\" button\n",
    "                next_button = safe_find_element(By.XPATH, \"//button[span[text()='â€¦']]\")\n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not navigate to the next page: {e}\")\n",
    "                break  # Stop if unable to navigate further\n",
    "\n",
    "        # Allow the page to load after navigation\n",
    "        time.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {i}: {e}\")\n",
    "        break\n",
    "\n",
    "# Close the WebDriver\n",
    "# driver.quit()\n",
    "\n",
    "# Save the scraped data to a CSV file\n",
    "csv_file = \"linkedin_jobs_29-11-2024.csv\"\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Job Title\", \"Company\", \"Location\", \"Link\"])  # Write header\n",
    "    for job in zip(job_titles, companies, locations, links):\n",
    "        writer.writerow(job)\n",
    "\n",
    "print(f\"Data has been saved to {csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('linkedin_jobs_29-11-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/view/4074094841/?eBP=CwEAAAGTH2cAe-SYRL_wWae_dDB6IlUFTrfpgY-f8vwDzMiIRPhljNIzOGdOYIvG6T7KGH_XhxpwMDagdA9Qe63Kng4xR3SReUj_LlUvXWg9KGQteDaJk7GL-atrIUkG68B5Ldo8FNCFJS627EhT2dYB8QMLJDoqouUPswTbhOGH88Cis5dGVFHpBRzfERN9Z96q77AXSrFiJj2ap1z21P_dKZt707d1-9ep4gnGHhvj_eRhzeBu-0LFD1BACd_yVcdBC9yWb7IoOOU-bdGzrM8ED6mrJlpjlBRKJlCKnjwVIT0D_Ap50ByYEB2kU4mKCJ20PxYWrVNSrFrNT7Qy83Xm9HVi0L3368k58SLYI4pRDHgWFhpTcDRSmaQsShs61nO5nVolJACv_j_VG4sEeVcFSSlhTD_YhrFyXq-6J2Mr3f4JCBsUJbI2ZnH9oCejzNAdHh919LtWfgdtBpTynu13Gha_m7v0zYPxTKEaOeXGP5iJOKMNYS-6aksr5Xv46U2F8KeKrvlcqW9oerv-6fdWAjmb&refId=19AJKmWYEqImdPRK7rrDHA%3D%3D&trackingId=V2FKIEYc92Y3%2BsngcY6oyw%3D%3D&trk=flagship3_search_srp_jobs'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get(df['Link'][0])\n",
    "time.sleep(5)  # Wait for page load\n",
    "\n",
    "# Scroll to the \"See more\" button before clicking\n",
    "see_more_button = driver.find_element(By.CLASS_NAME, \"jobs-description__footer-button\")\n",
    "driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description for Link 0:\n",
      " Skills:\n",
      "Data Analysis, SQL, Excel, Statistics, Data Visualization, Python, Critical Thinking, Problem Solving,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "At Innovateshield Solutions, we offer a wide range of services to help businesses of all sizes succeed. Our services include enterprise software development, web development, digital marketing, eCommerce development, API and framework development, and game development. We work closely with our clients to understand their unique needs and deliver custom solutions that meet their specific requirements. Our company is headquartered in Bangalore and has a diverse and talented team of 51-200 employees.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a Data Analyst Trainee to join our growing team at Innovateshield Solutions. This is a full-time position suitable for freshers, located in multiple cities including Bangalore, Chennai, Hyderabad, Pune, and Delhi. As a Data Analyst Trainee, you will be responsible for assisting with data analysis projects, performing data visualization tasks, and supporting senior data analysts in various tasks. This role requires 0-1 years of work experience in the relevant field.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in data analysis (Mandatory skill)\n",
      "Experience with data visualization tools (Mandatory skill)\n",
      "Strong problem-solving skills (Mandatory skill)\n",
      "Basic knowledge of SQL for querying databases\n",
      "Proficiency in Excel for data manipulation and analysis\n",
      "Understanding of basic statistical concepts\n",
      "Familiarity with Python for data analysis tasks\n",
      "Ability to think critically and analytically\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and interpreting data from various sources to support business decision-making\n",
      "Create data visualizations, such as charts and graphs, to communicate insights effectively\n",
      "Support senior data analysts in performing detailed data analyses and generating reports\n",
      "Work on identifying trends and patterns in data sets, and report key findings\n",
      "Coordinate with various departments to understand their data needs and provide relevant support\n",
      "Document data analysis processes and procedures for future reference\n",
      "Contribute to the development of new data analysis methodologies\n",
      "Stay updated with the latest developments in data analysis tools and techniques\n",
      "Job Description for Link 1:\n",
      " Skills:\n",
      "Statistical Analysis, Machine Learning, Data Visualization, Python Programming, Big Data, Predictive Modeling, Data Mining, Quantitative Analysis,\n",
      "\n",
      "About Websecure AI\n",
      "\n",
      "Websecure AI is a leading company dedicated to advancing artificial intelligence (AI) solutions in the field of web security. We specialize in using cutting-edge AI techniques to develop intelligent, secure, and scalable web applications. As part of our commitment to innovation and growth, we are looking for a Data Science Intern to join our team. This internship offers a unique opportunity to work on exciting data-driven projects and gain hands-on experience in the field of AI and data science.\n",
      "\n",
      "Position Overview\n",
      "\n",
      "As a Data Science Intern at Websecure AI, you will be exposed to real-world applications of data science and AI, particularly in the context of web security. You will assist our team in analyzing large datasets, building predictive models, and leveraging AI algorithms to drive business insights and enhance security solutions. This is a great opportunity for aspiring data scientists to build their skills and contribute to meaningful projects.\n",
      "\n",
      "Key Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and preprocessing large datasets for analysis\n",
      "\n",
      "Help build and evaluate predictive models and machine learning algorithms\n",
      "\n",
      "Conduct exploratory data analysis (EDA) to identify trends, patterns, and insights\n",
      "\n",
      "Collaborate with the AI and engineering teams to develop data-driven solutions\n",
      "\n",
      "Contribute to the design and implementation of data pipelines and automated processes\n",
      "\n",
      "Assist in visualizing and presenting data findings to stakeholders\n",
      "\n",
      "Research and experiment with new data science methodologies, techniques, and tools\n",
      "\n",
      "Learn and apply AI-based techniques to improve web security applications\n",
      "\n",
      "Skills & Qualifications\n",
      "\n",
      "Strong foundation in statistics, data analysis, and machine learning\n",
      "\n",
      "Proficiency in programming languages such as Python (preferred), R, or similar\n",
      "\n",
      "Experience with data analysis and visualization libraries (e.g., Pandas, NumPy, Matplotlib, Seaborn, etc.)\n",
      "\n",
      "Familiarity with machine learning frameworks such as TensorFlow, Keras, or Scikit-learn\n",
      "\n",
      "Understanding of databases and SQL\n",
      "\n",
      "Strong problem-solving skills and ability to work with large, complex datasets\n",
      "\n",
      "Ability to learn quickly and adapt to new tools and technologies\n",
      "\n",
      "Excellent communication skills and ability to present data-driven insights\n",
      "\n",
      "Currently pursuing or recently graduated with a degree in Data Science, Computer Science, Mathematics, or a related field\n",
      "\n",
      "Benefits\n",
      "\n",
      "Internship Certificate\n",
      "\n",
      "Letter of Recommendation\n",
      "\n",
      "Performance-Based Stipend\n",
      "\n",
      "Part-time work from home (2-3 hours per day)\n",
      "\n",
      "5 days a week, fully flexible shift\n",
      "Job Description for Link 2:\n",
      " Skills:\n",
      "Python, Tableau, SQL,\n",
      "\n",
      "Key Skills\n",
      "\n",
      " Advanced Excel, word, PDF skills\n",
      " Ability to work quickly manipulating and analyzing data\n",
      " Ideally from a STEM background\n",
      " Genuine interest in Data and Artificial intelligence\n",
      " Python, C++ or VBA or SQL server experience is beneficial\n",
      " Keen interest in automation artificial intelligence or data science essentially.\n",
      " 0-2 years experience\n",
      " Until the Covid situation settles Work location is going to be remote .\n",
      " Candidates must have ability to work from home and also in a position to use their personal laptop during this period.\n",
      "Job Description for Link 3:\n",
      " Skills:\n",
      "Python, Machine Learning, Statistical Analysis, Data Visualization, SQL, Data Cleaning, Predictive Modeling, Data Interpretation,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "TwiLearn Pay After Placement is an innovative online learning platform that equips IT aspirants in India with essential skills to secure high-paying jobs. The company collaborates with Promentix Software Solutions Pvt Ltd to provide internships and offers placement assistance before course completion. Located in Pune, TwiLearn focuses on digitization trends, delivering live classes, hands-on exercises, and industry-grade projects, ensuring learners are well-prepared for the corporate world.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a motivated and enthusiastic Data Science Intern to join our team. This is a fresher-level internship position available across Pune, Mumbai, Bangalore, Kolkata, Delhi, Noida, and Gurgaon. The role is ideal for candidates with 0 to 1 year of work experience who aspire to gain practical data science experience. This internship offers exposure to real-world projects and provides candidates with opportunities to develop their technical skills in a supportive and dynamic environment.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in Python, enabling candidates to execute data manipulation tasks efficiently (Mandatory skill).\n",
      "Expertise in data visualization techniques to transform data into insightful visual reports (Mandatory skill).\n",
      "Ability to write and execute SQL queries for maintaining and analyzing data within relational databases (Mandatory skill).\n",
      "Familiarity with machine learning algorithms and methods to design intelligent systems and predictive models.\n",
      "A strong background in statistical analysis to interpret data patterns and deliver actionable insights.\n",
      "Experience in data cleaning procedures, ensuring dataset accuracy and reliability for analysis.\n",
      "Proficiency in predictive modeling techniques to forecast trends and patterns in data.\n",
      "Excellent data interpretation skills, allowing candidates to draw meaningful conclusions from complex datasets.\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and preparing data for analysis to support decision-making processes.\n",
      "Collaborate with the data science team to apply machine learning models to real-world datasets.\n",
      "Contribute to the design and development of data visualizations to communicate insights to stakeholders.\n",
      "Conduct exploratory data analysis to identify patterns, anomalies, and relationships within datasets.\n",
      "Support the team in creating comprehensive reports presenting findings and actionable recommendations.\n",
      "Participate in team meetings to discuss project progress, challenges, and future direction.\n",
      "Engage in continuous learning to remain updated with the latest trends and techniques in data science.\n",
      "Assist in deploying models and solutions in collaboration with software development teams where applicable.\n",
      "Job Description for Link 4:\n",
      " Skills:\n",
      "Python programming, Statistical analysis, Machine learning, Data visualization, SQL database management, Data cleaning, Critical thinking, Problem-solving,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Zen Consultancy is dedicated to providing technology solutions for operational excellence in the IT Services and IT Consulting industry. They help clients navigate the technology landscape and achieve success in their core businesses.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "Data Science Intern position with Zen Consultancy, a Tailor Made IT-Service company based in Delhi. This is an internship role suitable for candidates with less than 1 year of experience. Job location options include Bangalore Urban, Gurgaon, Noida, and Mumbai Suburban. Employment type varies from Full-Time to Freelance.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Python programming proficiency\n",
      "Experience in statistical analysis and machine learning\n",
      "Ability to create impactful data visualizations\n",
      "Knowledge of SQL database management\n",
      "Strong data cleaning skills\n",
      "Critical thinking and problem-solving abilities\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in data collection, cleaning, and analysis\n",
      "Utilize Python for statistical analysis and machine learning tasks\n",
      "Create data visualizations to communicate insights\n",
      "Manage SQL databases and ensure data integrity\n",
      "Apply critical thinking and problem-solving skills to optimize data processes\n",
      "Job Description for Link 5:\n",
      " Skills:\n",
      "Data Analysis, SQL, Excel, Statistics, Data Visualization, Python, Critical Thinking, Problem Solving,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "At Innovateshield Solutions, we offer a wide range of services to help businesses of all sizes succeed. Our services include enterprise software development, web development, digital marketing, eCommerce development, API and framework development, and game development. We work closely with our clients to understand their unique needs and deliver custom solutions that meet their specific requirements. Our company is headquartered in Bangalore and has a diverse and talented team of 51-200 employees.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a Data Analyst Trainee to join our growing team at Innovateshield Solutions. This is a full-time position suitable for freshers, located in multiple cities including Bangalore, Chennai, Hyderabad, Pune, and Delhi. As a Data Analyst Trainee, you will be responsible for assisting with data analysis projects, performing data visualization tasks, and supporting senior data analysts in various tasks. This role requires 0-1 years of work experience in the relevant field.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in data analysis (Mandatory skill)\n",
      "Experience with data visualization tools (Mandatory skill)\n",
      "Strong problem-solving skills (Mandatory skill)\n",
      "Basic knowledge of SQL for querying databases\n",
      "Proficiency in Excel for data manipulation and analysis\n",
      "Understanding of basic statistical concepts\n",
      "Familiarity with Python for data analysis tasks\n",
      "Ability to think critically and analytically\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and interpreting data from various sources to support business decision-making\n",
      "Create data visualizations, such as charts and graphs, to communicate insights effectively\n",
      "Support senior data analysts in performing detailed data analyses and generating reports\n",
      "Work on identifying trends and patterns in data sets, and report key findings\n",
      "Coordinate with various departments to understand their data needs and provide relevant support\n",
      "Document data analysis processes and procedures for future reference\n",
      "Contribute to the development of new data analysis methodologies\n",
      "Stay updated with the latest developments in data analysis tools and techniques\n",
      "Job Description for Link 6:\n",
      " Skills:\n",
      "Python, Machine Learning, Statistical Analysis, Data Visualization, SQL, Data Cleaning, Predictive Modeling, Data Interpretation,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "TwiLearn Pay After Placement is an innovative online learning platform that equips IT aspirants in India with essential skills to secure high-paying jobs. The company collaborates with Promentix Software Solutions Pvt Ltd to provide internships and offers placement assistance before course completion. Located in Pune, TwiLearn focuses on digitization trends, delivering live classes, hands-on exercises, and industry-grade projects, ensuring learners are well-prepared for the corporate world.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a motivated and enthusiastic Data Science Intern to join our team. This is a fresher-level internship position available across Pune, Mumbai, Bangalore, Kolkata, Delhi, Noida, and Gurgaon. The role is ideal for candidates with 0 to 1 year of work experience who aspire to gain practical data science experience. This internship offers exposure to real-world projects and provides candidates with opportunities to develop their technical skills in a supportive and dynamic environment.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in Python, enabling candidates to execute data manipulation tasks efficiently (Mandatory skill).\n",
      "Expertise in data visualization techniques to transform data into insightful visual reports (Mandatory skill).\n",
      "Ability to write and execute SQL queries for maintaining and analyzing data within relational databases (Mandatory skill).\n",
      "Familiarity with machine learning algorithms and methods to design intelligent systems and predictive models.\n",
      "A strong background in statistical analysis to interpret data patterns and deliver actionable insights.\n",
      "Experience in data cleaning procedures, ensuring dataset accuracy and reliability for analysis.\n",
      "Proficiency in predictive modeling techniques to forecast trends and patterns in data.\n",
      "Excellent data interpretation skills, allowing candidates to draw meaningful conclusions from complex datasets.\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and preparing data for analysis to support decision-making processes.\n",
      "Collaborate with the data science team to apply machine learning models to real-world datasets.\n",
      "Contribute to the design and development of data visualizations to communicate insights to stakeholders.\n",
      "Conduct exploratory data analysis to identify patterns, anomalies, and relationships within datasets.\n",
      "Support the team in creating comprehensive reports presenting findings and actionable recommendations.\n",
      "Participate in team meetings to discuss project progress, challenges, and future direction.\n",
      "Engage in continuous learning to remain updated with the latest trends and techniques in data science.\n",
      "Assist in deploying models and solutions in collaboration with software development teams where applicable.\n",
      "Job Description for Link 7:\n",
      " Skills:\n",
      "Microsoft Power BI, Python, Advance Excel, SQL, Automation, Machine learning, Data Visualization, Programming,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "FuelBuddy is India's leading doorstep fuel delivery service, focused on safety, control, and convenience. Our goal is to democratize and digitalize energy delivery, empowering customers nationwide with quality fuel at their fingertips.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "Data Analyst Intern at FuelBuddy, an internship opportunity in Gurgaon. Ideal for freshers with less than 1 year of experience. Join a team revolutionizing doorstep fuel delivery leveraging advanced technology and IoT. Develop key analytical skills in a dynamic work environment.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in Microsoft Power BI, Python, Advance Excel, SQL, and data visualization\n",
      "Knowledge of automation, machine learning, and programming concepts\n",
      "Strong analytical and problem-solving abilities\n",
      "Effective communication and team collaboration skills\n",
      "Passion for data-driven decision-making and learning\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Work closely with data analysts to gather and analyze data for business insights\n",
      "Assist in developing reports and visualizations using tools like Power BI and Excel\n",
      "Support data cleansing, transformation, and validation processes\n",
      "Contribute to database management and data modeling tasks\n",
      "Collaborate on projects involving SQL queries and data automation\n",
      "Job Description for Link 8:\n",
      " Skills:\n",
      "Python, Machine Learning, Statistical Analysis, Data Visualization, SQL, Data Cleaning, Predictive Modeling, Data Interpretation,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "TwiLearn Pay After Placement is an innovative online learning platform that equips IT aspirants in India with essential skills to secure high-paying jobs. The company collaborates with Promentix Software Solutions Pvt Ltd to provide internships and offers placement assistance before course completion. Located in Pune, TwiLearn focuses on digitization trends, delivering live classes, hands-on exercises, and industry-grade projects, ensuring learners are well-prepared for the corporate world.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a motivated and enthusiastic Data Science Intern to join our team. This is a fresher-level internship position available across Pune, Mumbai, Bangalore, Kolkata, Delhi, Noida, and Gurgaon. The role is ideal for candidates with 0 to 1 year of work experience who aspire to gain practical data science experience. This internship offers exposure to real-world projects and provides candidates with opportunities to develop their technical skills in a supportive and dynamic environment.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in Python, enabling candidates to execute data manipulation tasks efficiently (Mandatory skill).\n",
      "Expertise in data visualization techniques to transform data into insightful visual reports (Mandatory skill).\n",
      "Ability to write and execute SQL queries for maintaining and analyzing data within relational databases (Mandatory skill).\n",
      "Familiarity with machine learning algorithms and methods to design intelligent systems and predictive models.\n",
      "A strong background in statistical analysis to interpret data patterns and deliver actionable insights.\n",
      "Experience in data cleaning procedures, ensuring dataset accuracy and reliability for analysis.\n",
      "Proficiency in predictive modeling techniques to forecast trends and patterns in data.\n",
      "Excellent data interpretation skills, allowing candidates to draw meaningful conclusions from complex datasets.\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and preparing data for analysis to support decision-making processes.\n",
      "Collaborate with the data science team to apply machine learning models to real-world datasets.\n",
      "Contribute to the design and development of data visualizations to communicate insights to stakeholders.\n",
      "Conduct exploratory data analysis to identify patterns, anomalies, and relationships within datasets.\n",
      "Support the team in creating comprehensive reports presenting findings and actionable recommendations.\n",
      "Participate in team meetings to discuss project progress, challenges, and future direction.\n",
      "Engage in continuous learning to remain updated with the latest trends and techniques in data science.\n",
      "Assist in deploying models and solutions in collaboration with software development teams where applicable.\n",
      "Job Description for Link 9:\n",
      " Skills:\n",
      "Python, Machine Learning, Statistical Analysis, Data Visualization, SQL, Data Cleaning, Predictive Modeling, Data Interpretation,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "TwiLearn Pay After Placement is an innovative online learning platform that equips IT aspirants in India with essential skills to secure high-paying jobs. The company collaborates with Promentix Software Solutions Pvt Ltd to provide internships and offers placement assistance before course completion. Located in Pune, TwiLearn focuses on digitization trends, delivering live classes, hands-on exercises, and industry-grade projects, ensuring learners are well-prepared for the corporate world.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking a motivated and enthusiastic Data Science Intern to join our team. This is a fresher-level internship position available across Pune, Mumbai, Bangalore, Kolkata, Delhi, Noida, and Gurgaon. The role is ideal for candidates with 0 to 1 year of work experience who aspire to gain practical data science experience. This internship offers exposure to real-world projects and provides candidates with opportunities to develop their technical skills in a supportive and dynamic environment.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Proficiency in Python, enabling candidates to execute data manipulation tasks efficiently (Mandatory skill).\n",
      "Expertise in data visualization techniques to transform data into insightful visual reports (Mandatory skill).\n",
      "Ability to write and execute SQL queries for maintaining and analyzing data within relational databases (Mandatory skill).\n",
      "Familiarity with machine learning algorithms and methods to design intelligent systems and predictive models.\n",
      "A strong background in statistical analysis to interpret data patterns and deliver actionable insights.\n",
      "Experience in data cleaning procedures, ensuring dataset accuracy and reliability for analysis.\n",
      "Proficiency in predictive modeling techniques to forecast trends and patterns in data.\n",
      "Excellent data interpretation skills, allowing candidates to draw meaningful conclusions from complex datasets.\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in collecting, cleaning, and preparing data for analysis to support decision-making processes.\n",
      "Collaborate with the data science team to apply machine learning models to real-world datasets.\n",
      "Contribute to the design and development of data visualizations to communicate insights to stakeholders.\n",
      "Conduct exploratory data analysis to identify patterns, anomalies, and relationships within datasets.\n",
      "Support the team in creating comprehensive reports presenting findings and actionable recommendations.\n",
      "Participate in team meetings to discuss project progress, challenges, and future direction.\n",
      "Engage in continuous learning to remain updated with the latest trends and techniques in data science.\n",
      "Assist in deploying models and solutions in collaboration with software development teams where applicable.\n",
      "Job Description for Link 10:\n",
      " Skills:\n",
      "Data Analysis, Excel, SQL, Problem Solving, Critical Thinking, Communication, Attention to Detail, Research Skills,\n",
      "\n",
      "Job Description\n",
      "\n",
      "Should be willing to work in US Shift.\n",
      "\n",
      "Responsible for calling Insurance companies (in US) on behalf of doctors/physicians and follow up on outstanding Accounts Receivable.\n",
      "\n",
      "Strong written and verbal communication skills.\n",
      "\n",
      "Good computer skills including Microsoft Office suite.\n",
      "\n",
      "Ability to prioritize and manage work queue.\n",
      "\n",
      "Ability to work independently as well as in a team environment.\n",
      "\n",
      "Should be a result-oriented person and works towards solving the issues instead of dragging the issues.\n",
      "\n",
      "Strong analytical and problem-solving skills.\n",
      "\n",
      "Good typing skills with a speed of min 30-35 words /min.\n",
      "Job Description for Link 11:\n",
      " Skills:\n",
      "Artificial Intelligence (AI), Machine Learning, Deep Learning, Python (Programming Language), NLP, Generative AI,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "IDC India, supported by the MSME Promotion Council, fosters innovation and entrepreneurship by empowering future leaders through intellectual growth and a proactive entrepreneurial mindset. We nurture creativity and critical thinking to shape visionary leaders who drive transformative change.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "Join IDC India as an AI Research Trainee in New Delhi on a Full-Time basis. Ideal for Fresher with less than 1 year experience. Explore the intersection of innovation and entrepreneurship in a dynamic and supportive environment at IDC India.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "MTech , MCA , MSc (Physics)\n",
      "Strong knowledge of Artificial Intelligence (AI), Machine Learning, and Deep Learning\n",
      "Proficiency in Python programming language\n",
      "Passionate about innovation and entrepreneurship\n",
      "Strong analytical and problem-solving skills\n",
      "Excellent communication and teamwork abilities\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Conduct research on Artificial Intelligence, Machine Learning, and Deep Learning\n",
      "Collaborate with the team on AI projects and initiatives\n",
      "Assist in data collection, preprocessing, and analysis for AI models\n",
      "Stay updated on the latest AI trends and technologies\n",
      "Support in implementing AI solutions and algorithms\n",
      "Job Description for Link 12:\n",
      " Skills:\n",
      "SQL, power bi, Tableau, python, Data Analysis, Data Science, Data Visualization,\n",
      "\n",
      "Job Title: Data Analyst Internship (Unpaid)\n",
      "\n",
      "Company: Unified Mentor\n",
      "\n",
      "Location: Remote\n",
      "\n",
      "Duration: 1 to 6 months\n",
      "\n",
      "About Us\n",
      "\n",
      "Unified Mentor is a forward-thinking educational platform dedicated to empowering individuals through mentorship and practical learning experiences. We are committed to providing opportunities for growth and development, shaping the leaders of tomorrow in various fields.\n",
      "\n",
      "Position Overview\n",
      "\n",
      "Unified Mentor is seeking a driven and enthusiastic Data Analyst Intern to join our team. This internship offers hands-on experience in data analysis within an educational setting. Under the guidance of seasoned professionals, you will have the chance to work on meaningful projects and enhance your analytical skills.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Assist in data collection, cleaning, and analysis from multiple sources.\n",
      "\n",
      "Develop and maintain reports, dashboards, and visualizations to convey insights.\n",
      "\n",
      "Support in identifying patterns, trends, and opportunities for improvement.\n",
      "\n",
      "Collaborate with team members to understand project objectives and requirements.\n",
      "\n",
      "Participate in training sessions to enhance technical skills in data analysis tools.\n",
      "\n",
      "Duration And Compensation\n",
      "\n",
      "This internship is unpaid and will last for a duration of 1 to 6 months, with the potential for extension based on performance and business needs. While compensation is not provided, we offer valuable training and mentorship opportunities to support your professional growth in data analysis.\n",
      "\n",
      "Fill out the apply form given below\n",
      "\n",
      "Note: Unified Mentor is committed to fostering diversity and inclusion. We welcome applicants from all backgrounds and are an equal opportunity employer.\n",
      "\n",
      "Application Deadline: 01 April 2024\n",
      "\n",
      "Embark on a rewarding journey of learning and development as a Data Analyst Intern at Unified Mentor. Join us in shaping the future of education through data-driven insights and innovation!\n",
      "Job Description for Link 13:\n",
      " Skills:\n",
      "Python programming, Statistical analysis, Machine learning, Data visualization, SQL database management, Data cleaning, Critical thinking, Problem-solving,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Zen Consultancy is dedicated to providing technology solutions for operational excellence in the IT Services and IT Consulting industry. They help clients navigate the technology landscape and achieve success in their core businesses.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "Data Science Intern position with Zen Consultancy, a Tailor Made IT-Service company based in Delhi. This is an internship role suitable for candidates with less than 1 year of experience. Job location options include Bangalore Urban, Gurgaon, Noida, and Mumbai Suburban. Employment type varies from Full-Time to Freelance.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Python programming proficiency\n",
      "Experience in statistical analysis and machine learning\n",
      "Ability to create impactful data visualizations\n",
      "Knowledge of SQL database management\n",
      "Strong data cleaning skills\n",
      "Critical thinking and problem-solving abilities\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Assist in data collection, cleaning, and analysis\n",
      "Utilize Python for statistical analysis and machine learning tasks\n",
      "Create data visualizations to communicate insights\n",
      "Manage SQL databases and ensure data integrity\n",
      "Apply critical thinking and problem-solving skills to optimize data processes\n",
      "Job Description for Link 14:\n",
      " Skills:\n",
      "Artificial Intelligence (AI), machine language, python, SQL,\n",
      "\n",
      "Job Title: AI/ML Engineer\n",
      "\n",
      "Job Summary: As an AI/ML Engineer, you will be responsible for assisting the development of machine learning models and algorithms. You will work closely with senior data scientists and software developers to build, test, and deploy machine learning models and applications. Your role will also include analysing and interpreting data, creating visualizations, and presenting findings to stakeholders.\n",
      "\n",
      "Key Responsibilities\n",
      "\n",
      "Assisting in the development of machine learning models and algorithms\n",
      "Collecting, cleaning, and organizing data for analysis\n",
      "Analyzing and interpreting data using statistical techniques\n",
      "Creating visualizations and reports to communicate insights to stakeholders\n",
      "Collaborating with software developers to integrate machine learning models into software applications\n",
      "Develop and deploy AI/ML models to production environments\n",
      "Continuously monitor and evaluate the performance of deployed models, and provide feedback for improvement\n",
      "Keep up-to-date with the latest AI/ML technologies and trends, and share knowledge and best practices with the team\n",
      "\n",
      "Requirements\n",
      "\n",
      "Bachelor's degree in Computer Science, Mathematics, Statistics, or a related field\n",
      "Strong knowledge of programming languages such as Python, R, and SQL\n",
      "Familiarity with machine learning libraries such as NumPy, Pandas, Scikit-learn, TensorFlow, and Keras\n",
      "Experience with data preprocessing, feature engineering, model training, and evaluation\n",
      "Knowledge of data visualization tools such as Matplotlib, Seaborn, Tableau or Power BI\n",
      "Strong problem-solving skills and attention to detail\n",
      "Excellent written and verbal communication skills\n",
      "Ability to work independently and in a team environment\n",
      "\n",
      "Working Conditions: This is an office-based position, and you will be working with a team of data scientists and software developers.\n",
      "Job Description for Link 15:\n",
      " Skills:\n",
      "English, computer litracy, data science, data, Data Analysis, Statistical Data Analysis,\n",
      "\n",
      "About The Job\n",
      "\n",
      "Solar Secure Solutions is a Web Development & Designing company with its headquarter in New Delhi India and started it's operation in 2018. We provide a variety of tools to the businesses to grow and increase their productivity like Web Designing, SEO, Digital Marketing and promotion, Logo Design, Content writing etc. We are a fast growing company so opportunities are more.\n",
      "\n",
      "Currently offering \"Data Science Internship\" for 2 months.\n",
      "\n",
      "Data Science Projects details In which Interns Will Work :\n",
      "\n",
      "Project 01 : Image Caption Generator Project in Python\n",
      "\n",
      "Project 02 : Credit Card Fraud Detection Project\n",
      "\n",
      "Project 03 : Movie Recommendation System\n",
      "\n",
      "Project 04 : Customer Segmentation\n",
      "\n",
      "Project 05 : Brain Tumor Detection with Data Science\n",
      "\n",
      "Eligibility\n",
      "\n",
      "A PC or Laptop with decent internet speed.\n",
      "\n",
      "Good understanding of English language.\n",
      "\n",
      "Any Graduate with a desire to become a web developer. Freshers are welcomed.\n",
      "\n",
      "Knowledge of HTML, CSS and JavaScript is a plus but NOT mandatory.\n",
      "\n",
      "Fresher are welcomed. You will get proper training also, so don't hesitate to apply if you don't have any coding background.\n",
      "\n",
      "Duration : 02 Months \n",
      "\n",
      "MODE: Work From Home (Online)\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Manage reports and sales leads in salesforce.com, CRM.\n",
      "\n",
      "Develop content, manage design, and user access to SharePoint sites for customers and employees.\n",
      "\n",
      "Build data driven reports, store procedures, query optimization using SQL and PL/SQL knowledge.\n",
      "\n",
      "Learned the essentials to C++ and Java to refine code and build the exterior layer of web pages.\n",
      "\n",
      "Configure and load xml data for the BVT tests.\n",
      "\n",
      "Set up a GitHub page.\n",
      "\n",
      "Develop spark scripts by using Scala shell as per requirements.\n",
      "\n",
      "Develop and A/B test improvements to business survey questions on iOS.\n",
      "\n",
      "Deploy statistical models to various company data streams using Linux shells.\n",
      "\n",
      "Create monthly performance-base client billing reports using MySQL and NoSQL databases.\n",
      "\n",
      "Utilize Hadoop and MapReduce to generate dynamic queries and extract data from HDFS.\n",
      "\n",
      "Create source code utilizing JavaScript and PHP language to make web pages functional.\n",
      "\n",
      "Benefits\n",
      "\n",
      "Internship Certificate\n",
      "\n",
      "Letter of recommendation\n",
      "\n",
      "Stipend Performance Based\n",
      "\n",
      "Part time work from home (2-3 Hrs per day)\n",
      "\n",
      "5 days a week, Fully Flexible Shift\n",
      "Job Description for Link 16:\n",
      " Skills:\n",
      "Machine Learning, Natural Language Processing (NLP), Robotics, Artificial Intelligence (AI), python, Python (Programming Language),\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Welcome to the Innovation and Entrepreneurship Development Centre (IDC) supported by the MSME Promotion Council, where the seeds of innovation and entrepreneurship find fertile ground to flourish. Established with a vision to catalyze intellectual growth and empower future leaders, our center is a dynamic hub committed to nurturing creativity, critical thinking, and a proactive entrepreneurial mindset. As a support of the MSME Promotion Council, we carry forward a legacy of fostering innovation across diverse sectors.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are currently seeking a highly motivated and talented Artificial Intelligence Intern to join our team at IDC India. As an AI Intern, you will work closely with our experienced AI professionals and contribute to the development and implementation of cutting-edge AI solutions. This is a great opportunity for individuals who are passionate about AI and eager to gain hands-on experience in the field.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Fresher: Less than 1 year of experience in AI or related fields\n",
      "Solid understanding of machine learning concepts and algorithms\n",
      "Proficiency in programming languages such as Python or Java\n",
      "Knowledge of natural language processing (NLP) techniques\n",
      "Experience with robotics and sensor systems is a plus\n",
      "Strong analytical and problem-solving skills\n",
      "Effective communication and teamwork abilities\n",
      "Ability to adapt to a fast-paced and dynamic work environment\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Collaborate with the AI team to develop and implement AI models and algorithms\n",
      "Assist in data collection, preprocessing, and analysis\n",
      "Conduct research to stay up-to-date with the latest AI technologies and techniques\n",
      "Contribute to the design and development of AI-powered applications and systems\n",
      "Support in testing, evaluating, and fine-tuning AI models\n",
      "Assist in documenting and presenting the research findings and project updates\n",
      "Job Description for Link 17:\n",
      " Skills:\n",
      "English, Microsoft Excel, Pyhton, SQL, Data Analysis, Data Visualization,\n",
      "\n",
      "Job Title: Data Analyst Internship (Unpaid)\n",
      "\n",
      "Location: Remote\n",
      "\n",
      "Duration: 1 to 6 months\n",
      "\n",
      "To Apply Fill Out The Form Given Below\n",
      "\n",
      "https://forms.gle/a9Xo3E3NY2Den5o77\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Assist in data collection, cleaning, and analysis from multiple sources.\n",
      "\n",
      "Develop and maintain reports, dashboards, and visualizations to convey insights.\n",
      "\n",
      "Support in identifying patterns, trends, and opportunities for improvement.\n",
      "\n",
      "Collaborate with team members to understand project objectives and requirements.\n",
      "\n",
      "Participate in training sessions to enhance technical skills in data analysis tools.\n",
      "\n",
      "Fill out the apply form given below & Compulsory join WhatsApp group\n",
      "\n",
      "https://forms.gle/a9Xo3E3NY2Den5o77\n",
      "\n",
      "Application Deadline: 01 April 2024\n",
      "Job Description for Link 18:\n",
      " Skills:\n",
      "sql, Tableau, Microsoft Power BI, visualization, python, Data Analytics,\n",
      "\n",
      "Job Title: Data Science Internship (Remote)\n",
      "\n",
      "Company: Unified Mentor Pvt. Ltd.\n",
      "\n",
      "Application Deadline: 01 April 2024\n",
      "\n",
      "Application Link: https://forms.gle/BsUwF3HT7vaJMX7JA\n",
      "\n",
      "Duration: 1 to 6 months\n",
      "\n",
      "About Us\n",
      "\n",
      "Unified Mentor is a forward-thinking educational platform dedicated to empowering individuals through mentorship and practical learning experiences. We are committed to providing opportunities for growth and development, shaping the leaders of tomorrow in various fields.\n",
      "\n",
      "Position Overview\n",
      "\n",
      "Unified Mentor is seeking a driven and enthusiastic Data Analyst Intern to join our team. This internship offers hands-on experience in data analysis within an educational setting. Under the guidance of seasoned professionals, you will have the chance to work on meaningful projects and enhance your analytical skills.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Assist in data collection, cleaning, and analysis from multiple sources.\n",
      "\n",
      "Develop and maintain reports, dashboards, and visualizations to convey insights.\n",
      "\n",
      "Support in identifying patterns, trends, and opportunities for improvement.\n",
      "\n",
      "Collaborate with team members to understand project objectives and requirements.\n",
      "\n",
      "Participate in training sessions to enhance technical skills in data analysis tools.\n",
      "\n",
      "Duration And Compensation\n",
      "\n",
      "This internship is unpaid and will last for a duration of 1 to 6 months, with the potential for extension based on performance and business needs. While compensation is not provided, we offer valuable training and mentorship opportunities to support your professional growth in data analysis.\n",
      "\n",
      "Fill out the apply form given below\n",
      "\n",
      "Note: Unified Mentor is committed to fostering diversity and inclusion. We welcome applicants from all backgrounds and are an equal opportunity employer.\n",
      "\n",
      "Embark on a rewarding journey of learning and development as a Data Analyst Intern at Unified Mentor. Join us in shaping the future of education through data-driven insights and innovation!\n",
      "Job Description for Link 19:\n",
      " Skills:\n",
      "SQL querying, Database management, Data analysis, Data modeling, Data manipulation, Understanding of relational databases, Basic knowledge of SQL functions, Ability to write SQL scripts,\n",
      "\n",
      "We are looking for a SQL developer to develop MS-SQL queries and procedures, create custom reports, and modify user forms to enhance organizational productivity. You will be responsible for designing databases and ensuring their stability, reliability and performance.\n",
      "\n",
      "Role\n",
      "\n",
      "Back End Developer\n",
      "\n",
      "Experience\n",
      "\n",
      "Fresher\n",
      "\n",
      "Desired Candidate Profile\n",
      "\n",
      "Maintain the SQL database\n",
      "\n",
      "Able to create DB schema based on requirement provided\n",
      "\n",
      "Help create Tables, SQL statements for data presentation and further automation\n",
      "\n",
      "Setting up and monitoring routine maintenance SQL jobs and developing / maintaining an alert strategy(s) for failed jobs and database problems and/or failures\n",
      "\n",
      "Modify / update T-SQL scripts for importing and organizing data\n",
      "\n",
      "Work closely with analysts and other department personnel in advising best SQL coding practices\n",
      "\n",
      "Ability to manage multiple projects simultaneously within time and budget constraints\n",
      "\n",
      "Responsible for data profiling, source-target mappings, ETL development, SQL tunings and optimization, testing and implementation\n",
      "\n",
      "MS SQL, data modelling, including an understanding of all normalized forms, design and development of stored procedures, views and triggers\n",
      "\n",
      "Deep understanding on improving performance of the procedures and design\n",
      "\n",
      "Excellent attention to detail, ability to detect and correct problems within SQL scripts\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Designing, testing, and debugging software applications using Sql Server\n",
      "\n",
      "Collaborating with cross-functional teams to gather and analyse requirements\n",
      "\n",
      "Developing technical specifications and design documents\n",
      "\n",
      "Implementing software solutions that adhere to coding standards and best practices\n",
      "\n",
      "Writing clean, efficient, and maintainable code\n",
      "\n",
      "We are looking for a highly motivated MS SQL Developer to join our team\n",
      "\n",
      "The ideal candidate will have a strong understanding of MS SQL Server\n",
      "Job Description for Link 20:\n",
      " The Data Scientist will work with the Product and Data teams to clean, organize, and analyze large volumes of data and produce innovative models, datasets, and visualizations that address our clientsâ€™ most pressing problems about the future of work. The successful candidate will have keen statistical thinking ability, be proficient in data visualization, large data set processing, and solid programming capabilities in Python, SQL, statistical or machine learning methods. The Data Scientist will contribute to projects under the guidance of more senior data scientists and make business/technology trade-off recommendations when appropriate. The Data Scientist will keep abreast of advancements in the field and deliver state-of-the-art solutions.\n",
      "\n",
      "Major Responsibilities: \n",
      "\n",
      "Use SQL, Python, or other related analytical tools and programming languages to query, organize, clean, and analyze large datasets.\n",
      "Build pragmatic, scalable, and rigorous solutions to large-scale labor market data problems by leveraging or developing state-of-the-art statistical and machine learning methodologies on top of Lightcastâ€™s data infrastructure.\n",
      "Work cross-functionally to define problem statements, collect data, build models, and make recommendations to stakeholders and technical leaders.\n",
      "Contribute to projects under the guidance of more senior data scientists. Make business/technology trade-off recommendations when appropriate.\n",
      "Keep abreast of advancements in the field and deliver state-of-the-art solutions. \n",
      "Communicate key insights and recommendations to internal and external stakeholders across the organization.\n",
      "\n",
      "Skills: \n",
      "\n",
      "Algorithms\n",
      "Applied Mathematics\n",
      "Computer Science\n",
      "Python (Programming Language)\n",
      "Machine Learning\n",
      "Natural Language Processing (NLP)\n",
      "SciPy\n",
      "SQL (Programming Language)\n",
      "Statistics\n",
      "Data Science\n",
      "\n",
      "Abilities:\n",
      "\n",
      "Keen statistical thinking ability and excels at turning data into information\n",
      "Likes to showcase strong technical acumen yet also flexible to adapt new ways of doing things. \n",
      "Excellent interpersonal, written and verbal communication skills, with particular ability to convey technical information to a variety of technical and non-technical audiences\n",
      "Thrives in a positive team culture by participating in team-building activities and being a supportive and empathetic colleague\n",
      "Data visualization \n",
      "Large Data Set Processing\n",
      "Solid Programming capabilities in Python, SQL\n",
      "Statistical or Machine Learning Methods \n",
      "Proficient understanding of business technology tools incl Google Suite, Microsoft Office Suite, project management, timekeeping, travel, expense reporting other tools as needed.\n",
      "\n",
      "Education and Experience:\n",
      "\n",
      "2 years of industry or graduate research experience solving analytical problems and building models using quantitative, statistical or machine learning approaches.\n",
      "Bachelor's or Masterâ€™s degree in Data Science, or a field with a strong quantitative and analytic focus such as Computer Science, Engineering, Mathematics, Statistics, Economics, Operations Research, or other related field.\n",
      "\n",
      "Lightcast is a global leader in labor market insights with headquarters in Moscow (ID) and Boston (MA) and offices in the United Kingdom, Europe, and India. We work with partners across six continents to help drive economic prosperity and mobility by providing the insights needed to build and develop our people, our institutions and companies, and our communities.\n",
      "\n",
      "Lightcast is proud to be an equal opportunity workplace and is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Lightcast has always been, and always will be, committed to diversity, equity and inclusion. We seek dynamic professionals from all backgrounds to join our teams, and we encourage our employees to bring their authentic, original, and best selves to work.\n",
      "Job Description for Link 21:\n",
      " Skills:\n",
      "Python, django, Mobile Applications, Dart, Mobile Application Development, API,\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Teiox IT Solutions is a leading provider of innovative IT solutions for businesses. With a focus on excellence, Teiox leverages cutting-edge technology to drive growth, enhance efficiency, and revolutionize operations. Our comprehensive services include software development, infrastructure management, cybersecurity, and business process automation. With a team of skilled professionals, Teiox delivers tailored solutions that meet the unique needs of clients. By combining expertise, creativity, and industry knowledge, Teiox empowers businesses to thrive in the digital era.\n",
      "\n",
      "Job Overview\n",
      "\n",
      "We are seeking an enthusiastic and motivated Intern Python to join our team at Teiox IT Solutions. As an Intern Python, you will have the opportunity to work on exciting projects and gain hands-on experience in software development. This is a full-time internship in Gandhinagar, Gujarat, India. We are looking for a fresher with less than 1 year of experience who is passionate about Python and eager to learn.\n",
      "\n",
      "Qualifications And Skills\n",
      "\n",
      "Fresher with less than 1 year of experience in Python development\n",
      "Strong understanding of Python programming language\n",
      "Knowledge of web development frameworks like Django\n",
      "Experience or familiarity with mobile application development using Dart and Flutter is a plus\n",
      "Familiarity with API integrations and RESTful services\n",
      "Good problem-solving skills and attention to detail\n",
      "Excellent written and verbal communication skills\n",
      "Ability to work collaboratively in a team environment\n",
      "Passion for learning and eagerness to contribute to the success of the team\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Collaborate with the development team to design, develop, and test Python applications\n",
      "Assist in troubleshooting and resolving software defects\n",
      "Participate in code reviews to ensure code quality\n",
      "Learn and apply best practices in software development\n",
      "Work on projects with defined deadlines and deliver high-quality code\n",
      "Contribute to the overall improvement of the software development processes\n",
      "Stay updated with the latest trends and technologies in Python development\n",
      "Job Description for Link 22:\n",
      " Skills:\n",
      "Microsoft SQL Server, Transact-SQL (T-SQL), Help create Tables, SQL statements for data presentation and further automation, MS SQL, data modelling, including an understanding of all normalized forms, design and development of stored procedures, views and triggers, Designing, testing, and debugging software applications using Sql Server, Implementing software solutions that adhere to coding standards and best practices,\n",
      "\n",
      "We are looking for a SQL developer to develop MS-SQL queries and procedures, create custom reports, and modify user forms to enhance organizational productivity. You will be responsible for designing databases and ensuring their stability, reliability and performance.\n",
      "\n",
      "Role\n",
      "\n",
      "Back End Developer\n",
      "\n",
      "Experience\n",
      "\n",
      "Fresher\n",
      "\n",
      "Desired Candidate Profile\n",
      "\n",
      "Maintain the SQL database\n",
      "\n",
      "Able to create DB schema based on requirement provided\n",
      "\n",
      "Help create Tables, SQL statements for data presentation and further automation\n",
      "\n",
      "Setting up and monitoring routine maintenance SQL jobs and developing / maintaining an alert strategy(s) for failed jobs and database problems and/or failures\n",
      "\n",
      "Modify / update T-SQL scripts for importing and organizing data\n",
      "\n",
      "Work closely with analysts and other department personnel in advising best SQL coding practices\n",
      "\n",
      "Ability to manage multiple projects simultaneously within time and budget constraints\n",
      "\n",
      "Responsible for data profiling, source-target mappings, ETL development, SQL tunings and optimization, testing and implementation\n",
      "\n",
      "MS SQL, data modelling, including an understanding of all normalized forms, design and development of stored procedures, views and triggers\n",
      "\n",
      "Deep understanding on improving performance of the procedures and design\n",
      "\n",
      "Excellent attention to detail, ability to detect and correct problems within SQL scripts\n",
      "\n",
      "Roles and Responsibilities\n",
      "\n",
      "Designing, testing, and debugging software applications using Sql Server\n",
      "\n",
      "Collaborating with cross-functional teams to gather and analyse requirements\n",
      "\n",
      "Developing technical specifications and design documents\n",
      "\n",
      "Implementing software solutions that adhere to coding standards and best practices\n",
      "\n",
      "Writing clean, efficient, and maintainable code\n",
      "Job Description for Link 23:\n",
      " Skills:\n",
      "Data Analysis, Requirement Gathering, Process Mapping, Problem Solving, Communication, Critical Thinking, Documentation, Stakeholder Management,\n",
      "\n",
      "Role: Business Analyst\n",
      "\n",
      "Industry Type: IT Services & Consulting\n",
      "\n",
      "Functional Area: Sales & Business Development\n",
      "\n",
      "Employment Type: Full Time, Permanent\n",
      "\n",
      "Role Category: BD / Pre Sales\n",
      "\n",
      "Education: B.Sc in Computers, BCA in Computers\n",
      "\n",
      "Key Skills: guru, upwork, pph, freelancing, lead generation, negotiation, business analysis, online bidding,\n",
      "\n",
      "communication\n",
      "\n",
      "Roles And Responsibilities\n",
      "\n",
      "Understanding project requirement & client relations\n",
      "\n",
      "Good verbal and written skills.\n",
      "\n",
      "Fast learner and passion for sales.\n",
      "\n",
      "Must be good in academics\n",
      "\n",
      "Must be Self Motivated, Team handling ,Target Oriented, Business Development.\n",
      "Job Description for Link 24:\n",
      " Skill required: Marketing Operations - Content management\n",
      "\n",
      "Designation: Digital Content Management Analyst\n",
      "\n",
      "Qualifications:Any Graduation\n",
      "\n",
      "Years of Experience:3 to 5 years\n",
      "\n",
      "About Accenture\n",
      "\n",
      "Accenture is a global professional services company with leading capabilities in digital, cloud and security.Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Songâ€” all powered by the worldâ€™s largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities.Visit us at www.accenture.com\n",
      "\n",
      "What would you do? Help balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services. Role requires Digital Marketing Ads & Promotion creation/design The Content Management team focuses on organizing, categorizing, auditing and publishing content and information with the help of specific tools and channels, for use by different groups and individuals. They are also responsible for auditing and ensuring quality of online content by flagging risks and providing clear feedbacks on errors. The team is responsible for managing the content on websites, social media pages, email campaigns, and responses.\n",
      "\n",
      "What are we looking for?\n",
      "\n",
      " Coordinate with concerned stakeholders for ensuring complete understanding of requests, requesting new/additional information, mockup approvals, request closures etc.\n",
      " Be able to perform basic to medium complexity HTML coding and photoshop activities like image re-sizing, in-image text editing, re-encoding etc.\n",
      " Ensure proper deployment of content in production system across platforms\n",
      " Coordinate with third party technical teams for issue resolution when needed\n",
      " Adhere to various operational processes\n",
      " Identify gaps and areas for improvement in the processes and proposing solution improvements\n",
      " Apply learnings and Industry standard best practices from experience\n",
      " Ensure timely completion of tasks and requests\n",
      " Ensure high quality closures of all requests with zero margin of error\n",
      " Strong Interpersonal and communication skills including ability to interact with senior members in the project board.\n",
      " Ability to work independently with minimal supervision as a self-starter and chase down people/teams to achieve closure when required.\n",
      " Ability to take end-to-end ownership of success of delivery by collaborating across teams and individuals.\n",
      " An organized and planned approach to work with the ability to move things swiftly despite several dependencies. Appreciation of the need for documentation. Roles and Responsibilities:\n",
      "In this role you are required to do analysis and solving of lower-complexity problems\n",
      " Your day to day interaction is with peers within Accenture before updating supervisors\n",
      " In this role you may have limited exposure with clients and/or Accenture management\n",
      " You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments\n",
      " The decisions you make impact your own work and may impact the work of others\n",
      " You will be an individual contributor as a part of a team, with a focused scope of work\n",
      " Please note that this role may require you to work in rotational shifts\n",
      "\n",
      "\n",
      "Any Graduation\n",
      "Job Description for Link 25:\n",
      " Key Responsibilities:\n",
      "\n",
      "Manage business data using above tools optimize the reporting at working level management â€“ Mid management & Top-level management\n",
      "Coordinate data across cross-functional teams and maintain status sheets across all departments of Business development\n",
      "Develop and implement project plans and monitor performance. \n",
      "Engage with stakeholders to align project goals and expectations. \n",
      "Responsible for managing the Bids portal & traceability\n",
      "Provide regular updates to senior management on program status and performance. \n",
      "\n",
      "Requirements:\n",
      "\n",
      "Excellent communication and leadership skills. \n",
      "Ability to work effectively in a fast-paced, dynamic environment. \n",
      "Proficiency in Power Query, Power Bi and VBA. \n",
      "\n",
      "Qualifications:\n",
      "\n",
      "Any Graduate Engineer qualification is acceptable as long as the candidate is certified to VBA (Excel), POWER QUERY (Excel), Power BI and demonstrates practical experience in using these tools to achieve the above results in excel.\n",
      "Job Description for Link 26:\n",
      " Skills:\n",
      "primary market research, competitor analysis, lead generation, data collection, customer insights, Market forecasting,\n",
      "\n",
      "We Are Looking For\n",
      "\n",
      "Exciting opportunities await! Collegedunia, a prominent educational portal, is actively seeking\n",
      "\n",
      "a skilled Market Research Associate to join our dynamic and enthusiastic team. This is a\n",
      "\n",
      "full-time position offering more than just employment; it's a gateway to personal and\n",
      "\n",
      "professional development.\n",
      "\n",
      "Responsibilities And Duties\n",
      "\n",
      "Market Research: Conduct research to understand market trends, customer preferences, and\n",
      "\n",
      "competitor activities.\n",
      "\n",
      "Data Collection: Gather data through surveys, interviews, focus groups, and secondary research.\n",
      "\n",
      "Data Analysis: Analyze data using statistical tools to identify patterns and trends.\n",
      "\n",
      "Report Writing: Prepare detailed market research reports, including findings and recommendations.\n",
      "\n",
      "Competitive Analysis: Monitor competitors' activities and analyze their strengths and weaknesses.\n",
      "\n",
      "Customer Insights: Analyze customer feedback to understand their needs and preferences.\n",
      "\n",
      "Market Segmentation: Divide the market into segments to tailor marketing strategies.\n",
      "\n",
      "Data Visualization: Create visualizations (charts, graphs) to present findings effectively.\n",
      "\n",
      "Primary Research:Design and execute surveys and interviews to collect primary data, which would involve visiting in and around areas of Hyderabad.\n",
      "\n",
      "Secondary Research: Utilize online databases and industry reports to gather secondary data.\n",
      "\n",
      "Data Mining: Extract relevant information from large datasets using data mining techniques.\n",
      "\n",
      "Market Forecasting: Develop models to predict future market trends and demand.\n",
      "\n",
      "Our Wish List Your Skills\n",
      "\n",
      "Strong analytical and problem-solving skills.\n",
      "\n",
      "Extensive traveling within Hyderabad location.\n",
      "\n",
      "Proficiency in data analysis tool (Excel)\n",
      "\n",
      "Excellent communication and presentation skills\n",
      "\n",
      "Strong attention to detail\n",
      "\n",
      "Ability to work independently and as part of a team\n",
      "\n",
      "About your new company!! \n",
      "\n",
      "Collegedunia is an education portal, matching students with the best colleges in India abroad.\n",
      "\n",
      "We help in college research, exam prep tips, application process & also provide insights\n",
      "\n",
      "on-campus life. Launched in 2014, we are the highest ranked portal by Similar Web in education.\n",
      "\n",
      "We have also been awarded as - Best Educational Portal by IAMAI in 2017, and listed by\n",
      "\n",
      "TechinAsia as Top 100 Startups in Asia. Collegedunia is fuelled by the energy of over a 1000\n",
      "\n",
      "individuals having an average age around 25 years. The talent pool comprises data analysts,\n",
      "\n",
      "engineers, designers, writers, managers, marketers, which is increasing at 10% every month.\n",
      "\n",
      "Only Candidates from Hyderabad will be considered for this role.\n",
      "\n",
      "Candidates must be available for 1 month of internship.\n",
      "\n",
      "This internship involves 80% travelling within the Hyderabad City\n",
      "\n",
      "Stipend- 10k\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "# Sample DataFrame\n",
    "# df = pd.DataFrame({'Link': ['link1', 'link2', ...]})\n",
    "\n",
    "# Initialize a new column for job descriptions\n",
    "df['Job_Description'] = ''\n",
    "\n",
    "for index, link in enumerate(df['Link']):\n",
    "    try:\n",
    "        # Open each job URL\n",
    "        driver.get(link)\n",
    "        time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "        try:\n",
    "            # Wait until the \"See more\" button is clickable and then click it\n",
    "            see_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"jobs-description__footer-button\"))\n",
    "            )\n",
    "            # Scroll to the \"See more\" button and click it\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", see_more_button)\n",
    "            driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "            time.sleep(2)  # Wait for the description to expand\n",
    "        except:\n",
    "            # If the \"See more\" button is not present, proceed with the current description\n",
    "            pass\n",
    "        \n",
    "        # Extract the job description text\n",
    "        job_description = driver.find_element(By.XPATH, \"//p\").text\n",
    "        df.at[index, 'Job_Description'] = job_description  # Store in the DataFrame\n",
    "\n",
    "        print(f\"Job Description for Link {index}:\\n\", job_description)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(f\"See more button or job description not found for Link {index}.\")\n",
    "        df.at[index, 'Job_Description'] = None  # Store None if not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Link</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Trainee</td>\n",
       "      <td>Innovateshield Solutions</td>\n",
       "      <td>Pune, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081982274/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Web Secure AI</td>\n",
       "      <td>Bengaluru, Karnataka, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081974705/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analytics Trainee</td>\n",
       "      <td>Ovid Metrics</td>\n",
       "      <td>Nashik, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081908212/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>TwiLearn</td>\n",
       "      <td>Bengaluru East, Karnataka, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081983246/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data science interns</td>\n",
       "      <td>Zen Consultancy</td>\n",
       "      <td>Mumbai, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4082176673/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Job Title                   Company  \\\n",
       "0    Data Analyst Trainee  Innovateshield Solutions   \n",
       "1          Data Scientist             Web Secure AI   \n",
       "2  Data Analytics Trainee              Ovid Metrics   \n",
       "3     Data Science Intern                  TwiLearn   \n",
       "4    Data science interns           Zen Consultancy   \n",
       "\n",
       "                                     Location  \\\n",
       "0          Pune, Maharashtra, India (On-site)   \n",
       "1       Bengaluru, Karnataka, India (On-site)   \n",
       "2        Nashik, Maharashtra, India (On-site)   \n",
       "3  Bengaluru East, Karnataka, India (On-site)   \n",
       "4        Mumbai, Maharashtra, India (On-site)   \n",
       "\n",
       "                                                Link Job_Description  \n",
       "0  https://www.linkedin.com/jobs/view/4081982274/...                  \n",
       "1  https://www.linkedin.com/jobs/view/4081974705/...                  \n",
       "2  https://www.linkedin.com/jobs/view/4081908212/...                  \n",
       "3  https://www.linkedin.com/jobs/view/4081983246/...                  \n",
       "4  https://www.linkedin.com/jobs/view/4082176673/...                  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove repeated job titles\n",
    "df['Job Title'] = df['Job Title'].apply(lambda x: x.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Link</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Trainee</td>\n",
       "      <td>Innovateshield Solutions</td>\n",
       "      <td>Pune, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081982274/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Web Secure AI</td>\n",
       "      <td>Bengaluru, Karnataka, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081974705/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analytics Trainee</td>\n",
       "      <td>Ovid Metrics</td>\n",
       "      <td>Nashik, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081908212/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>TwiLearn</td>\n",
       "      <td>Bengaluru East, Karnataka, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4081983246/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data science interns</td>\n",
       "      <td>Zen Consultancy</td>\n",
       "      <td>Mumbai, Maharashtra, India (On-site)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4082176673/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Job Title                   Company  \\\n",
       "0    Data Analyst Trainee  Innovateshield Solutions   \n",
       "1          Data Scientist             Web Secure AI   \n",
       "2  Data Analytics Trainee              Ovid Metrics   \n",
       "3     Data Science Intern                  TwiLearn   \n",
       "4    Data science interns           Zen Consultancy   \n",
       "\n",
       "                                     Location  \\\n",
       "0          Pune, Maharashtra, India (On-site)   \n",
       "1       Bengaluru, Karnataka, India (On-site)   \n",
       "2        Nashik, Maharashtra, India (On-site)   \n",
       "3  Bengaluru East, Karnataka, India (On-site)   \n",
       "4        Mumbai, Maharashtra, India (On-site)   \n",
       "\n",
       "                                                Link Job_Description  \n",
       "0  https://www.linkedin.com/jobs/view/4081982274/...                  \n",
       "1  https://www.linkedin.com/jobs/view/4081974705/...                  \n",
       "2  https://www.linkedin.com/jobs/view/4081908212/...                  \n",
       "3  https://www.linkedin.com/jobs/view/4081983246/...                  \n",
       "4  https://www.linkedin.com/jobs/view/4082176673/...                  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a CSV file\n",
    "df.to_csv('new_jd_26-11-2024.csv', index=False)\n",
    "print(\"Data saved to linkedin_jobs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonForDataAnlysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
