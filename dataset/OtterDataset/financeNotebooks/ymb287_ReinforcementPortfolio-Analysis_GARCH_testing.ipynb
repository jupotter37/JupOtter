{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(40)  # Set the seed for reproducibility\n",
    "\n",
    "# Check if the original directory is already saved in a variable\n",
    "if 'original_directory' not in globals():\n",
    "    # Save the original working directory the first time\n",
    "    original_directory = os.getcwd()\n",
    "\n",
    "# Change back to the original directory whenever the cell is executed\n",
    "os.chdir(original_directory)\n",
    "\n",
    "# Go to mother directory\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "\n",
    "np.random.seed(40) \n",
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "num_simulation_episodes = 500\n",
    "num_simulation_days = 750\n",
    "\n",
    "train_simulations = int(num_simulation_episodes * (1 - 0.2))\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "initial_price = 100\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    sim_df_train = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(test_simulations))\n",
    "\n",
    "\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2020-01-01\")['Adj Close']\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "    garch = arch_model(log_returns, p=1, q=1, dist='normal')\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    for i in range(num_simulation_episodes):\n",
    "        simulated_log_returns = garch.simulate(res.params, num_simulation_days)\n",
    "        simulated_log_returns = simulated_log_returns['data']# - res.params['mu']  # Set drift to zero for simulation\n",
    "\n",
    "        # simulated_returns = np.exp(simulated_log_returns) - 1\n",
    "        # simulated_prices = initial_price * (1 + simulated_returns).cumprod()\n",
    "\n",
    "        cumsum = np.cumsum(simulated_log_returns)\n",
    "        simulated_prices = initial_price * np.exp(cumsum)\n",
    "\n",
    "        simulated_prices_with_initial = pd.concat([pd.Series([initial_price]), pd.Series(simulated_prices)], ignore_index=True)\n",
    "\n",
    "        # Split the simulations into training and testing sets\n",
    "        if i < train_simulations:\n",
    "            sim_df_train[i] = simulated_prices_with_initial\n",
    "        else:\n",
    "            sim_df_test[i - train_simulations] = simulated_prices_with_initial\n",
    "    print(ticker)\n",
    "\n",
    "    sim_df_train.to_csv(\"data/2_sim_train_\" + ticker + \".csv\")\n",
    "    sim_df_test.to_csv(\"data/2_sim_test_\" + ticker + \".csv\")\n",
    "\n",
    "    sim_df_train, sim_df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "\n",
    "# Suppress DataScaleWarning only\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "num_simulation_episodes = 500\n",
    "num_simulation_days = 750\n",
    "\n",
    "train_simulations = int(num_simulation_episodes * 0.8)\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "initial_price = 100\n",
    "\n",
    "for ticker in tickers:\n",
    "    sim_df_train = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(test_simulations))\n",
    "\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2020-01-01\")['Adj Close']\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "    \n",
    "    # Fit GARCH(1,1) model\n",
    "    garch = arch_model(log_returns, p=1, q=1, dist='normal')\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    garch_mu = res.params['mu']\n",
    "    \n",
    "    mean_returns = []  # Store the mean log return of each episode\n",
    "    \n",
    "    for i in range(num_simulation_episodes):\n",
    "        # Simulate log returns using the GARCH model\n",
    "        simulated_log_returns = garch.simulate(res.params, num_simulation_days)\n",
    "        simulated_log_returns = simulated_log_returns['data'] # Set drift to zero for simulation\n",
    "        \n",
    "        # Calculate cumulative sum to get log prices\n",
    "        cumsum = np.cumsum(simulated_log_returns)\n",
    "        simulated_prices = initial_price * np.exp(cumsum)\n",
    "        \n",
    "        # Store the price paths with the initial price\n",
    "        simulated_prices_with_initial = pd.concat([pd.Series([initial_price]), pd.Series(simulated_prices)], ignore_index=True)\n",
    "        \n",
    "        # Calculate the mean log return for this episode\n",
    "        episode_log_returns = np.diff(np.log(simulated_prices_with_initial))\n",
    "        mean_returns.append(np.mean(episode_log_returns))\n",
    "        \n",
    "        # Split into training and testing sets\n",
    "        if i < train_simulations:\n",
    "            sim_df_train[i] = simulated_prices_with_initial\n",
    "        else:\n",
    "            sim_df_test[i - train_simulations] = simulated_prices_with_initial\n",
    "\n",
    "    # Calculate the average of the mean log returns across all episodes\n",
    "    estimated_mu = np.mean(mean_returns)\n",
    "    \n",
    "    # Compare with GARCH model's mu\n",
    "    comparison = pd.DataFrame({\n",
    "        'GARCH_Mu': [garch_mu],\n",
    "        'Estimated_Mu': [estimated_mu],\n",
    "        'Difference': [estimated_mu - garch_mu],\n",
    "        'Percent_Error': [(estimated_mu - garch_mu) / garch_mu * 100]\n",
    "    })\n",
    "\n",
    "    print(f\"Comparison for {ticker}:\")\n",
    "    print(comparison)\n",
    "\n",
    "    # Save simulations as CSV files\n",
    "    sim_df_train.to_csv(f\"data/3_sim_train_{ticker}.csv\")\n",
    "    sim_df_test.to_csv(f\"data/3_sim_test_{ticker}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "\n",
    "# Load and plot each CSV for training and testing sets\n",
    "for ticker in tickers:\n",
    "    # Load training and testing data\n",
    "    sim_df_train = pd.read_csv(f\"data/3_sim_train_{ticker}.csv\", index_col=0)\n",
    "    sim_df_test = pd.read_csv(f\"data/3_sim_test_{ticker}.csv\", index_col=0)\n",
    "    \n",
    "    # Plot training simulations\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sim_df_train, color=\"blue\", alpha=0.1)\n",
    "    plt.title(f\"{ticker} - Training Simulations\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot testing simulations\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sim_df_test, color=\"red\", alpha=0.1)\n",
    "    plt.title(f\"{ticker} - Testing Simulations\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress DataScaleWarning only\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "tickers = ['MSFT'] #, 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "num_simulation_episodes = 500\n",
    "num_simulation_days = 750\n",
    "\n",
    "train_simulations = int(num_simulation_episodes * 0.8)\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "initial_price = 100\n",
    "\n",
    "# Create a directory to save plots if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.makedirs(\"plots\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    sim_df_train = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(test_simulations))\n",
    "\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2020-01-01\")['Adj Close']\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "    \n",
    "    # Calculate Realized Volatility (e.g., 30-day rolling standard deviation)\n",
    "    rolling_window = 30\n",
    "    realized_vol = log_returns.rolling(window=rolling_window).std() * np.sqrt(252)  # Annualize\n",
    "    \n",
    "    # Fit GARCH(1,1) model\n",
    "    garch = arch_model(log_returns, p=1, q=1, dist='normal')\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    garch_mu = res.params['mu']\n",
    "    \n",
    "    # Obtain GARCH model's conditional volatility\n",
    "    garch_vol = res.conditional_volatility * np.sqrt(252)  # Annualize\n",
    "    \n",
    "    mean_returns = []  # Store the mean log return of each episode\n",
    "\n",
    "    for i in range(num_simulation_episodes):\n",
    "        # Simulate log returns using the GARCH model\n",
    "        simulated_log_returns = garch.simulate(res.params, num_simulation_days)\n",
    "        simulated_log_returns = simulated_log_returns['data']  # Set drift to zero for simulation\n",
    "        \n",
    "        # Calculate cumulative sum to get log prices\n",
    "        cumsum = np.cumsum(simulated_log_returns)\n",
    "        simulated_prices = initial_price * np.exp(cumsum)\n",
    "        \n",
    "        # Store the price paths with the initial price\n",
    "        simulated_prices_with_initial = pd.concat([pd.Series([initial_price]), pd.Series(simulated_prices)], ignore_index=True)\n",
    "        \n",
    "        # Calculate the mean log return for this episode\n",
    "        episode_log_returns = np.diff(np.log(simulated_prices_with_initial))\n",
    "        mean_returns.append(np.mean(episode_log_returns))\n",
    "        \n",
    "        # Split into training and testing sets\n",
    "        if i < train_simulations:\n",
    "            sim_df_train[i] = simulated_prices_with_initial\n",
    "        else:\n",
    "            sim_df_test[i - train_simulations] = simulated_prices_with_initial\n",
    "\n",
    "    # Calculate the average of the mean log returns across all episodes\n",
    "    estimated_mu = np.mean(mean_returns)\n",
    "    \n",
    "    # Compare with GARCH model's mu\n",
    "    comparison = pd.DataFrame({\n",
    "        'GARCH_Mu': [garch_mu],\n",
    "        'Estimated_Mu': [estimated_mu],\n",
    "        'Difference': [estimated_mu - garch_mu],\n",
    "        'Percent_Error': [(estimated_mu - garch_mu) / garch_mu * 100]\n",
    "    })\n",
    "\n",
    "    print(f\"Comparison for {ticker}:\")\n",
    "    # print(comparison)\n",
    "\n",
    "    # Plotting Volatility\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Realized Volatility\n",
    "    plt.plot(realized_vol.index, realized_vol, label='Realized Volatility (30-day Rolling)', color='blue')\n",
    "    \n",
    "    # Plot GARCH Conditional Volatility\n",
    "    plt.plot(garch_vol.index, garch_vol, label='GARCH(1,1) Conditional Volatility', color='red')\n",
    "    \n",
    "    plt.title(f\"Volatility Comparison for {ticker}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Annualized Volatility\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Suppress DataScaleWarning only\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "num_simulation_episodes = 2\n",
    "num_simulation_days = 750\n",
    "\n",
    "train_simulations = int(num_simulation_episodes * 0.8)\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "initial_price = 100\n",
    "\n",
    "# Create directories to save plots and data if they don't exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for ticker in tickers:\n",
    "    sim_df_train = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(test_simulations))\n",
    "\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2020-01-01\")['Adj Close']\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "    # Calculate Realized Volatility (e.g., 30-day rolling standard deviation)\n",
    "    rolling_window = 2\n",
    "    realized_vol = log_returns.rolling(window=rolling_window).std() * np.sqrt(252)  # Annualize\n",
    "\n",
    "    # Fit GARCH(1,1) model\n",
    "    garch = arch_model(log_returns, p=1, q=1, dist='normal')\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    garch_mu = res.params['mu']\n",
    "\n",
    "    # Obtain GARCH model's conditional volatility\n",
    "    garch_vol = res.conditional_volatility * np.sqrt(252)  # Annualize\n",
    "\n",
    "\n",
    "    # Initialize a matrix to store simulated log returns\n",
    "    simulated_log_returns_matrix = np.zeros((num_simulation_days, num_simulation_episodes))\n",
    "\n",
    "    for i in range(num_simulation_episodes):\n",
    "        # Simulate log returns using the GARCH model\n",
    "        simulated = garch.simulate(res.params, num_simulation_days)\n",
    "        simulated_log_returns = simulated['data'].values.flatten()\n",
    "        #simulated_log_returns = simulated['volatility'].values.flatten()\n",
    "\n",
    "\n",
    "        # Store simulated log returns for volatility calculation\n",
    "        simulated_log_returns_matrix[:, i] = simulated_log_returns\n",
    "\n",
    "    # Convert simulated_log_returns_matrix to daily returns in percentage terms\n",
    "    simulated_returns = pd.DataFrame(simulated_log_returns_matrix)\n",
    "    simulated_vol = simulated_returns.std(axis=1) * np.sqrt(252)  # Annualize\n",
    "\n",
    "    # Align the simulated_vol index to start from the laast date in historical data\n",
    "    last_date = data.index[-1]\n",
    "    simulation_dates = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=num_simulation_days)\n",
    "    simulated_vol.index = simulation_dates\n",
    "\n",
    "    # For plotting, we need to extend the historical data to include simulation period\n",
    "    combined_realized_vol = pd.concat([realized_vol, simulated_vol])\n",
    "\n",
    "    # Plotting Volatility\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot Realized Volatility\n",
    "    plt.plot(realized_vol.index, realized_vol, label='Realized Volatility (30-day Rolling)', color='blue')\n",
    "\n",
    "    # Plot GARCH Conditional Volatility\n",
    "    plt.plot(garch_vol.index, garch_vol, label='GARCH(1,1) Conditional Volatility', color='red')\n",
    "\n",
    "    # Plot Simulated Volatility\n",
    "    plt.plot(simulated_vol.index, simulated_vol, label='Simulated Volatility (Average across Simulations)', color='green')\n",
    "\n",
    "    plt.title(f\"Volatility Comparison for {ticker}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Annualized Volatility\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Volatility plot saved for {ticker}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Suppress only specific warnings if necessary\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "num_simulation_episodes = 1  # Adjusted for demonstration; set to 500 for full simulations\n",
    "num_simulation_days = 1750\n",
    "\n",
    "train_simulations = int(num_simulation_episodes * 0.8)\n",
    "test_simulations = num_simulation_episodes - train_simulations\n",
    "initial_price = 100\n",
    "\n",
    "# Create directories to save plots and data if they don't exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Initialize DataFrames to store simulations (adjust indices as needed)\n",
    "    sim_df_train = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(train_simulations))\n",
    "    sim_df_test = pd.DataFrame(index=range(num_simulation_days + 1), columns=range(test_simulations))\n",
    "\n",
    "    # Download historical data\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2020-01-01\")['Adj Close']\n",
    "    log_returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "    # Fit GARCH(1,1) model\n",
    "    garch = arch_model(log_returns, p=1, q=1, mean='Constant', vol='GARCH', dist='normal')\n",
    "    res = garch.fit(disp=\"off\")\n",
    "    garch_mu = res.params['mu']\n",
    "\n",
    "    # Obtain GARCH model's conditional volatility\n",
    "    garch_vol = res.conditional_volatility * np.sqrt(252)  # Annualize\n",
    "\n",
    "    # Demean historical returns by subtracting mu\n",
    "    demeaned_returns = log_returns - garch_mu\n",
    "\n",
    "    # Calculate Realized Volatility (e.g., 30-day rolling standard deviation) from demeaned returns\n",
    "    rolling_window = 30\n",
    "    realized_vol = demeaned_returns.rolling(window=rolling_window).std() * np.sqrt(252)  # Annualize\n",
    "\n",
    "    # Initialize a matrix to store simulated log returns\n",
    "    simulated_log_returns_matrix = np.zeros((num_simulation_days, num_simulation_episodes))\n",
    "\n",
    "    for i in range(num_simulation_episodes):\n",
    "        # Simulate log returns using the GARCH model\n",
    "        simulated = garch.simulate(res.params, num_simulation_days)\n",
    "        \n",
    "        # Extract simulated returns and volatility separately\n",
    "        simulated_returns = simulated['data'].values.flatten()\n",
    "        simulated_volatility = simulated['volatility'].values.flatten()\n",
    "\n",
    "        # Demean simulated returns by subtracting mu\n",
    "        demeaned_simulated_returns = simulated_returns - garch_mu\n",
    "\n",
    "        # Store demeaned simulated log returns for volatility calculation\n",
    "        simulated_log_returns_matrix[:, i] = demeaned_simulated_returns\n",
    "\n",
    "        # Optional: If you want to store simulated price paths\n",
    "        # Calculate cumulative sum to get log prices\n",
    "        cumsum = np.cumsum(demeaned_simulated_returns)\n",
    "        simulated_prices = initial_price * np.exp(cumsum)\n",
    "\n",
    "        # Store the price paths with the initial price\n",
    "        simulated_prices_with_initial = pd.concat([pd.Series([initial_price]), pd.Series(simulated_prices)], ignore_index=True)\n",
    "\n",
    "        # Split into training and testing sets\n",
    "        if i < train_simulations:\n",
    "            sim_df_train[i] = simulated_prices_with_initial\n",
    "        else:\n",
    "            sim_df_test[i - train_simulations] = simulated_prices_with_initial\n",
    "\n",
    "    # Calculate Simulated Volatility from Simulated (Demeaned) Returns\n",
    "    simulated_returns_df = pd.DataFrame(simulated_log_returns_matrix)\n",
    "    simulated_vol = simulated_returns_df.rolling(window=rolling_window).std() * np.sqrt(252)  # Annualize\n",
    "    simulated_vol_mean = simulated_vol.mean(axis=1)  # Average across simulations\n",
    "\n",
    "    # Align the simulated_vol index to start from the last date in historical data\n",
    "    last_date = data.index[-1]\n",
    "    simulation_dates = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=num_simulation_days)\n",
    "    simulated_vol_mean.index = simulation_dates\n",
    "\n",
    "    # For plotting, align the historical realized volatility to the simulation period\n",
    "    combined_realized_vol = pd.concat([realized_vol, simulated_vol_mean])\n",
    "\n",
    "    # Plotting Volatility\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot Realized Volatility from Demeaned Returns\n",
    "    plt.plot(realized_vol.index, realized_vol, label='Realized Volatility (30-day Rolling)', color='blue')\n",
    "\n",
    "    # Plot GARCH Conditional Volatility\n",
    "    plt.plot(garch_vol.index, garch_vol, label='GARCH(1,1) Conditional Volatility', color='red')\n",
    "\n",
    "    # Plot Simulated Volatility from Demeaned Returns\n",
    "    plt.plot(simulated_vol_mean.index, simulated_vol_mean, label='Simulated Volatility (Mean across Simulations)', color='green')\n",
    "\n",
    "    plt.title(f\"Volatility Comparison for {ticker}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Annualized Volatility\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.show()  # Use plt.savefig(...) to save instead of showing if needed\n",
    "\n",
    "    print(f\"Volatility plot displayed for {ticker}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "\n",
    "all_returns = []\n",
    "log_returns = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    returns = []\n",
    "    sim_df = pd.read_csv(f'data/sim_test_{ticker}.csv')\n",
    "    sim_df = sim_df.drop(columns=['Unnamed: 0'])\n",
    "    for col in sim_df.columns:\n",
    "        # Tota return\n",
    "        return_col = sim_df[col].iloc[-1] / sim_df[col].iloc[0] - 1\n",
    "\n",
    "        returns.append(return_col)\n",
    "\n",
    "    all_returns.append(returns)\n",
    "\n",
    "print(\"Mean returns for each stock\")\n",
    "for i, ticker in enumerate(tickers):\n",
    "    print(f\"{ticker}: {np.mean(all_returns[i])}\")\n",
    "\n",
    "print(\"Mean returns for the portfolio\")\n",
    "print(np.mean(np.mean(all_returns, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean returns for each stock\")\n",
    "for i, ticker in enumerate(tickers):\n",
    "    print(f\"{ticker}: {np.mean(all_returns[i])}\")\n",
    "\n",
    "print(\"Mean returns for the portfolio\")\n",
    "print(np.mean(np.mean(all_returns, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2020-01-01\"\n",
    "\n",
    "# Download and plot closing prices for each ticker\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)['Adj Close']\n",
    "    # Plot data\n",
    "    plt.plot(data, label=ticker)\n",
    "    \n",
    "    # Calculate and print first, last values and number of years\n",
    "    first_value = data.iloc[0]\n",
    "    last_value = data.iloc[-1]\n",
    "    num_years = (data.index[-1] - data.index[0]).days / 252\n",
    "    annual_return = (last_value / first_value) ** (1 / num_years) - 1\n",
    "    print(f\"{ticker}: First Value = {first_value:.2f}, Last Value = {last_value:.2f}, Number of Years = {num_years:.2f}, Annual Return = {annual_return:.2%}\")\n",
    "\n",
    "# Display plot\n",
    "plt.title(\"Closing Prices of Stocks (2000 - 2020)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Closing Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "tickers = ['MSFT', 'TGT', 'QCOM', 'MU', 'CAT']\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "returns = []\n",
    "# Download and plot closing prices for each ticker, scaled to start at 100\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)['Adj Close']\n",
    "    \n",
    "    # Scale prices to start at 100\n",
    "    scaled_data = (data / data.iloc[0]) * 100\n",
    "    \n",
    "    # Plot scaled data\n",
    "    plt.plot(scaled_data, label=ticker)\n",
    "    \n",
    "    # Calculate first, last values, number of years, and annual return\n",
    "    first_value = data.iloc[0]\n",
    "    last_value = data.iloc[-1]\n",
    "    num_years = (data.index[-1] - data.index[0]).days / 365  # Trading days in a year\n",
    "    annual_return = (last_value / first_value) ** (1 / num_years) - 1\n",
    "    print(f\"{ticker}: First Value = {first_value:.2f}, Last Value = {last_value:.2f}, Number of Years = {num_years:.2f}, Annual Return = {annual_return:.2%}\")\n",
    "    returns.append((last_value / first_value )-1)\n",
    "\n",
    "print(\"Mean returns for the portfolio\")\n",
    "print(np.mean(returns))\n",
    "\n",
    "# Display plot\n",
    "plt.title(\"Closing Prices of Stocks (Scaled to 100 on First Day, 2020 - 2023)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Scaled Closing Price (Starting at 100)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
