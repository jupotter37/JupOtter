{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYaV4DxCoX9B"
   },
   "source": [
    "# Predicting Bitcoin Price Movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W6n4K9VoTma"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In 2021, I decided to make small investments in [Bitcoin](https://www.investopedia.com/terms/b/bitcoin.asp) and [Ethereum](https://www.investopedia.com/terms/e/ethereum.asp), the two major cryptocurrencies today. In addition to exploring the major cryptocurrencies as long-term stores of value, I am working to develop systematic approaches to make modest short-term returns for reinvestment.\n",
    "\n",
    "One strategy to is to: <br>\n",
    "(1) buy a cryptocurrency on days when the price will go up, <br>\n",
    "(2) sell a cryptocurrency on days when the price will go down, and <br>\n",
    "(3) do nothing otherwise\n",
    "\n",
    "__Here, I use machine learning and deep learning algorithms to predict day-to-day Bitcoin price increases and decreases in the closing price.__\n",
    "\n",
    "While none of the machine/deep learning algorithms presented here outperform the [buy-and-hold](https://www.investopedia.com/articles/investing/100215/statistical-proof-buyandhold-investing-pays.asp) strategy (please see the [Conclusion](#conclusion)), this framework (with code [here](https://github.com/aguron/Bitcoin_Price_Movement_Prediction)) allows one to rapidly evaluate strategy candidates.\n",
    "\n",
    "([The Coinbase Pro cryptocurrency exchange platform](https://en.wikipedia.org/wiki/Coinbase) is one place where one can buy and sell a variety of cryptocurriences. `cbpro` is an unofficial Python client for the Coinbase Pro API that can be used to automate trades based on predictive modeling.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sev13oSFpufF"
   },
   "source": [
    "## Installing and Importing Libraries\n",
    "\n",
    "`yfinance` is used to download market data from [Yahoo! Finance](https://finance.yahoo.com/) <br>\n",
    "`pytrends` is an unofficial API that is used to download data from [Google Trends](https://trends.google.com) <br>\n",
    "`talib-binary` is a Python wrapper for TA-Lib that is used to compute technical indicators used in financial market data analysis <br>\n",
    "`backtrader` and `pyfolio` are used in the analyses and visualizations of trading strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47158,
     "status": "ok",
     "timestamp": 1645759288176,
     "user": {
      "displayName": "Akinyinka Omigbodun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04675614761321408788"
     },
     "user_tz": 480
    },
    "id": "J_KAxvzNPPYn",
    "outputId": "88cffcbe-0eae-4842-ec8a-42c07f604ea3"
   },
   "outputs": [],
   "source": [
    "# Installing Python packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install yfinance\n",
    "!{sys.executable} -m pip install pytrends\n",
    "!{sys.executable} -m pip install talib-binary # TA-Lib\n",
    "!{sys.executable} -m pip install backtrader\n",
    "!{sys.executable} -m pip install pyfolio\n",
    "\n",
    "# File management\n",
    "import os\n",
    "\n",
    "# Working with DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# For manipulating numbers and datetime objects\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "altround = \\\n",
    "    lambda num, prec=0: \\\n",
    "    np.floor(num*(10**prec))/(10**prec) \\\n",
    "    + (10**-prec)*((np.mod(num,10**-prec) >= 0.5*(10**-prec)))\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For downloading, analyzing, and visualizing financial data\n",
    "import yfinance as yf\n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq()\n",
    "from talib import RSI, BBANDS, MACD\n",
    "import backtrader as bt\n",
    "from backtrader.feeds import PandasData\n",
    "import pyfolio as pf\n",
    "\n",
    "# For machine learning modeling\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, Conv1D\n",
    "from keras.layers import BatchNormalization, ReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K47OvhzUOcc"
   },
   "source": [
    "## Downloading Bitcoin Price and Volume Data (in USD)\n",
    "`Open` price at 12:01 AM UTC <br>\n",
    "`High` highest price of 24-hour period <br>\n",
    "`Low` lowest price of 24-hour period <br>\n",
    "`Close` price at 11:59PM UTC of a given day <br>\n",
    "`Volume` amount traded in 24-hour period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker symbol for Bitcoin\n",
    "ticker_symbol = 'btc-usd'\n",
    "\n",
    "# For saving data in CSV format\n",
    "data_path = 'working_data'\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "data_path = os.path.join(data_path, f'{ticker_symbol.upper()}.csv')\n",
    "\n",
    "# Price history range of dates\n",
    "start = dt.datetime(2010, 1, 1)\n",
    "end = dt.datetime(2022, 2, 24) # dt.datetime.now()\n",
    "\n",
    "# Specify if data should be read from a file if already downloaded\n",
    "new_download = False\n",
    "if not new_download and os.path.exists(data_path):\n",
    "    with open(data_path) as f:\n",
    "        ticker_hist = pd.read_csv(data_path, index_col='Date')\n",
    "        ticker_hist.index = pd.to_datetime(ticker_hist.index)\n",
    "else:\n",
    "    # Download data\n",
    "    ticker_hist = yf.download(ticker_symbol,\n",
    "                              progress=False,\n",
    "                              actions=True,\n",
    "                              start=start,\n",
    "                              end=end)\n",
    "\n",
    "    # Save file for later use\n",
    "    ticker_hist.to_csv(data_path)\n",
    "\n",
    "# Display the price history for the first and last few dates\n",
    "num_dates_disp = 5\n",
    "display(ticker_hist.head(num_dates_disp))\n",
    "display(ticker_hist.tail(num_dates_disp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp2C0x701BrG"
   },
   "source": [
    "## Downloading Bitcoin [Google Trends](https://trends.google.com) Data\n",
    "\n",
    "A score between 0 and 100 is assigned to time periods based on the degree of Google search interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ticker_symbol in ['btc-usd']:\n",
    "    # Assign an appropriate Google search term to the ticker symbol\n",
    "    if ticker_symbol == 'btc-usd':\n",
    "        term = 'Bitcoin'\n",
    "\n",
    "    data_path = 'working_data'\n",
    "    data_path = os.path.join(data_path, f'{term}_google_trends.csv')\n",
    "\n",
    "    # Specify if data should be read from a file if already downloaded\n",
    "    new_download = False\n",
    "    if not new_download and os.path.exists(data_path):\n",
    "        # Read from file if downloaded already\n",
    "        with open(data_path) as f:\n",
    "            ttrends = pd.read_csv(data_path, index_col='date')\n",
    "            ttrends.index = pd.to_datetime(ttrends.index)\n",
    "    else:\n",
    "        # Create an empty dataframe and update it with downloaded data\n",
    "        ttrends = pd.DataFrame()\n",
    "\n",
    "        # The data needs to be downloaded in approximately 9-month\n",
    "        # batches in order to access daily Google Trends scores;\n",
    "        # otherwise, the scores are weekly\n",
    "        DAYS_IN_YEAR = 365.25\n",
    "        MAX_RANGE_FOR_DAILY_INFO = 0.73 # 0.73 years\n",
    "                                        # (approximately 9 months)\n",
    "        num_yrs = (end - start).days / DAYS_IN_YEAR\n",
    "\n",
    "        utc = dt.datetime.utcnow()\n",
    "\n",
    "        for i in range(int(np.ceil(num_yrs/MAX_RANGE_FOR_DAILY_INFO))):\n",
    "            start_  = utc - dt.timedelta(\n",
    "                days=DAYS_IN_YEAR*min((i+1)*MAX_RANGE_FOR_DAILY_INFO,\n",
    "                                      num_yrs))\n",
    "            start_  = start_.date()\n",
    "            end_    = utc - dt.timedelta(\n",
    "                days=DAYS_IN_YEAR*i*MAX_RANGE_FOR_DAILY_INFO)\n",
    "            end_    = end_.date()\n",
    "\n",
    "            kw_list = [term]\n",
    "            pytrends.build_payload(kw_list, timeframe=f'{start_} {end_}')\n",
    "            try:\n",
    "                df  = pytrends.interest_over_time()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('This is probably because the ' \\\n",
    "                      'data limit has been reached.')\n",
    "                break\n",
    "            ttrends = pd.concat([df.dropna(), ttrends])\n",
    "\n",
    "        ttrends[term] = ttrends[term].apply(lambda x: x+1)\n",
    "        rows_to_delete = []\n",
    "        date_counts = Counter(ttrends.index)\n",
    "        for k, v in date_counts.items():\n",
    "            if v == 2:\n",
    "                p = np.where(ttrends.index == k)[0]\n",
    "                rows_to_delete.append(p[1])\n",
    "                ttrends.loc[ttrends.index[:p[1]], (term)] =\\\n",
    "                    ttrends.loc[ttrends.index[:p[1]], (term)]\\\n",
    "                    * (ttrends[term][p[1]]/ttrends[term][p[0]])\n",
    "\n",
    "        ttrends = ttrends[~ttrends.index.duplicated(keep='first')]\n",
    "        ttrends[term] = ttrends[term] * (100/max(ttrends[term]))\n",
    "        ttrends[term] = ttrends[term].apply(lambda x: int(altround(x)))\n",
    "        \n",
    "        # Save file for later use\n",
    "        ttrends.to_csv(data_path)\n",
    "\n",
    "    # Remove partial data\n",
    "    ttrends = ttrends[~ttrends['isPartial']]\n",
    "\n",
    "    # Approximate the scores of the last few dates (present in the price\n",
    "    # data) with the score of the most recent available Google Trends date\n",
    "    while ttrends.tail(1).index[0] + dt.timedelta(1) <= end.date():\n",
    "        ttrends = ttrends.append(\n",
    "                      pd.DataFrame(\n",
    "                          np.array(ttrends.tail(1)),\n",
    "                          columns=ttrends.columns,\n",
    "                          index=[ttrends.tail(1).index[0] + dt.timedelta(1)]\n",
    "                      )\n",
    "                  )\n",
    "\n",
    "# Display the data for the first and last few dates\n",
    "display(ttrends.head(num_dates_disp))\n",
    "display(ttrends.tail(num_dates_disp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SwmHCZ6WY01"
   },
   "source": [
    "## Visualizing Bitcoin Price and Volume Data in Interactive Plot\n",
    "\n",
    "Use the range selector below the main plot to control the range of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# include candlestick with range selector\n",
    "fig.add_trace(go.Candlestick(x=ticker_hist.index,\n",
    "                             open=ticker_hist['Open'],\n",
    "                             high=ticker_hist['High'],\n",
    "                             low=ticker_hist['Low'],\n",
    "                             close=ticker_hist['Adj Close'],\n",
    "                             name='price'),\n",
    "              secondary_y=True)\n",
    "\n",
    "# include a go.Bar trace for volumes\n",
    "fig.add_trace(go.Bar(x=ticker_hist.index,\n",
    "                     y=ticker_hist['Volume'],\n",
    "                     marker_color='purple',\n",
    "                     name='volume'),\n",
    "               secondary_y=False)\n",
    "\n",
    "fig.layout.yaxis2.showgrid=False\n",
    "\n",
    "# Set y-axes labels\n",
    "fig.update_yaxes(title_text='price', secondary_y=True)\n",
    "fig.update_yaxes(title_text='volume', secondary_y=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{ticker_symbol.upper()}'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FUBsj0aIXLP"
   },
   "source": [
    "## Visualizing Bitcoin Google Trends Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "ax = ttrends.plot.line(y=term, use_index=True, title='Google Trends')\n",
    "ax.set_ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPIOMViHo_5_"
   },
   "source": [
    "## Preparing the Data for Analysis\n",
    "\n",
    "The daily log ratio and direction (sign) of change for the __opening price__, __higest price__, __lowest price__, __closing price__, __volume__, and __Google Trends score__ are calculated.\n",
    "\n",
    "Rolling averages (up to a period of 10 days) of the directional change of the __closing price__ are also calculated.\n",
    "\n",
    "Finally, information from [technical indicators](https://www.investopedia.com/terms/t/technicalindicator.asp) such as the:\n",
    "* Relative Strength Index ([RSI](https://www.investopedia.com/terms/r/rsi.asp))\n",
    "* daily log ratio of [Bollinger Band](https://www.investopedia.com/terms/b/bollingerbands.asp) width\n",
    "* Moving Average Convergence Divergence ([MACD](https://www.investopedia.com/terms/m/macd.asp)) Histogram\n",
    "\n",
    "are calculated.\n",
    "\n",
    "The __RSI__ has a value between 0 and 100, and measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of an asset.\n",
    "\n",
    "The __Bollinger Band__ is typically 2 standard deviations +/- from a 20-day simple moving average, and captures periods of increased and decreased volatility.\n",
    "\n",
    "The __MACD__ is calculated by subtracting the 26-period exponential moving average from the 12-period exponential moving average. A 9-day exponential moving average of the __MACD__ called the `signal line` is subtracted from the __MACD__ to get the `histogram`. The __MACD__ falling or rising above the `signal line` can be indicative of bearish (falling price) and bullish (rising price) signals respectively.\n",
    "\n",
    "5 prior days' worth of each selected feature (predictor) is used in predicting the closing price changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of price and volume data\n",
    "data = ticker_hist.copy()\n",
    "\n",
    "# Specify if Google Trends data should be combined with\n",
    "# price and volume data\n",
    "include_Google_Trends = True\n",
    "if include_Google_Trends:\n",
    "    data = data.join(ttrends[[term]], how='inner')\n",
    "    data = data.rename(columns = {term: 'Google Trends Score'})\n",
    "\n",
    "# Drop columns and rename others for the analysis\n",
    "data.drop(['Close','Dividends','Stock Splits'], inplace=True, axis=1)\n",
    "data.rename(columns = {'Open':'open',\n",
    "                       'High':'high',\n",
    "                       'Low':'low',\n",
    "                       'Adj Close':'close',\n",
    "                       'Volume':'volume'},\n",
    "            inplace=True)\n",
    "\n",
    "orig_cols = data.columns\n",
    "for asset_info in orig_cols:\n",
    "    # Calculate daily log ratio for:\n",
    "    #   * opening price\n",
    "    #   * highest price\n",
    "    #   * lowest price\n",
    "    #   * closing price\n",
    "    #   * volume\n",
    "    #   * Google Trends score\n",
    "    col_log_ratio = f'{asset_info[0].lower()}_log_ratio'\n",
    "\n",
    "    if asset_info == 'Google Trends Score':\n",
    "        data[col_log_ratio] = \\\n",
    "            data[asset_info].apply(\n",
    "                lambda x: x+1 if x==0 else x\n",
    "            )\n",
    "    else:\n",
    "        data[col_log_ratio] = data[asset_info]\n",
    "        \n",
    "    data[col_log_ratio] = \\\n",
    "        np.log(\n",
    "            data[col_log_ratio] / \n",
    "            data[col_log_ratio].shift(1)\n",
    "        )\n",
    "    # Calculate direction (sign) of change for:\n",
    "    #   * opening price\n",
    "    #   * highest price\n",
    "    #   * lowest price\n",
    "    #   * closing price\n",
    "    #   * volume\n",
    "    #   * Google Trends score\n",
    "    col_dir = f'{asset_info[0].lower()}_dir'\n",
    "    data[col_dir] = 0\n",
    "    data[col_dir].iloc[1:] = \\\n",
    "        np.sign(\n",
    "            data[col_log_ratio].iloc[1:]\n",
    "        ).astype(int)\n",
    "\n",
    "# Investment strategy:\n",
    "#  * Buy if positive day-to-day return is predicted (1)\n",
    "#  * Sell if a loss is predicted (-1)\n",
    "#  * Otherwise maintain current position (0)\n",
    "asset_info_tgt = 'close'\n",
    "col_log_ratio = f'{asset_info_tgt[0].lower()}_log_ratio'\n",
    "col_dir = f'{asset_info_tgt[0].lower()}_dir'\n",
    "\n",
    "return_threshold = 0 # between 0 and 1 inclusive\n",
    "data['strategy'] = data[col_dir]\n",
    "if return_threshold > 0:\n",
    "    data['strategy'][\n",
    "        ((data[col_log_ratio]>0)&\n",
    "         (data[col_log_ratio]<=np.log(1+return_threshold))\n",
    "        )\n",
    "    ] = 0\n",
    "\n",
    "# Simplify {1,-1,0}-strategy (action-based representation) \n",
    "# to {1,-1}-strategy (state-based representation) by mapping\n",
    "# 0 to 1 or to -1 based on the previous trading position\n",
    "def simplify_strategy(df, col):\n",
    "    ''' simplified strategy format for Machine Learning modeling\n",
    "    '''\n",
    "    pos = -1\n",
    "    for i, p in enumerate(df[col]):\n",
    "        if p == 0:\n",
    "            df[col].iloc[i] = pos\n",
    "        else:\n",
    "            pos = p\n",
    "simpl_strat = True\n",
    "if simpl_strat:\n",
    "    data['sstrategy'] = data['strategy']\n",
    "    simplify_strategy(data, 'sstrategy')\n",
    "\n",
    "# Specify data lags\n",
    "max_roll_avg = 10\n",
    "roll_avg_spacing = 1\n",
    "min_roll_avg = roll_avg_spacing\n",
    "roll_avgs = list(range(min_roll_avg, max_roll_avg+1, roll_avg_spacing))\n",
    "\n",
    "# Include rolling averages of closing price trends\n",
    "for r in roll_avgs:\n",
    "    col = f'{asset_info_tgt[0].lower()}_{r}_day_trend'\n",
    "    data[col] = data[col_dir].rolling(r).mean()\n",
    "\n",
    "# Include technical indicators\n",
    "#\n",
    "# Compute Relative Strength Index (RSI)\n",
    "rsi_period = 14\n",
    "data['rsi'] = RSI(\n",
    "                data[asset_info_tgt],\n",
    "                timeperiod=rsi_period\n",
    "              )\n",
    "\n",
    "# Compute Bollinger Bands\n",
    "bband_period = 20\n",
    "high, mid, low = BBANDS(\n",
    "                    data[asset_info_tgt],\n",
    "                    timeperiod=bband_period\n",
    "                 )\n",
    "data = data.join(pd.DataFrame({'bb_high': high,\n",
    "                               'bb_mid': mid,\n",
    "                               'bb_low': low},\n",
    "                              index=data.index))\n",
    "data['bb_width'] = data['bb_high'] - data['bb_low']\n",
    "\n",
    "asset_info = 'bb_width'\n",
    "col_log_ratio = 'bbw_log_ratio'\n",
    "data[col_log_ratio] = data[asset_info]\n",
    "data[col_log_ratio] = \\\n",
    "    np.log(\n",
    "        data[col_log_ratio] /\n",
    "        data[col_log_ratio].shift(1)\n",
    "    )\n",
    "col_dir = 'bbw_dir'\n",
    "data[col_dir] = 0\n",
    "data[col_dir].iloc[bband_period:] = \\\n",
    "    np.sign(\n",
    "        data[col_log_ratio].iloc[bband_period:]\n",
    "    ).astype(int)\n",
    "\n",
    "# Compute Moving Average Convergence Divergence (MACD)\n",
    "macd_periods = [12, 26, 9]\n",
    "\n",
    "data['macd'], data['macd_signal'], data['macd_hist'] = \\\n",
    "    MACD(data[asset_info_tgt],\n",
    "         fastperiod=macd_periods[0],\n",
    "         slowperiod=macd_periods[1],\n",
    "         signalperiod=macd_periods[2]\n",
    "    )\n",
    "\n",
    "tech_ind_info = ['rsi', 'bbw_log_ratio', 'macd_hist']\n",
    "\n",
    "# Specify data lags\n",
    "max_lag = 5\n",
    "lag_spacing = 1\n",
    "min_lag = lag_spacing\n",
    "lags = list(range(min_lag, max_lag+1, lag_spacing))\n",
    "\n",
    "# Lagged log ratios\n",
    "for lag in lags:\n",
    "    for asset_info in orig_cols:\n",
    "        for chg_info in ['log_ratio', 'dir']:\n",
    "            col = f'{asset_info[0].lower()}_{chg_info}'\n",
    "            data[f'{col}_lag{lag}'] = data[col].shift(lag)\n",
    "    for r in roll_avgs:\n",
    "        col = f'{asset_info_tgt[0].lower()}_{r}_day_trend'\n",
    "        data[f'{col}_lag{lag}'] = data[col].shift(lag)\n",
    "    for col in tech_ind_info:\n",
    "        data[f'{col}_lag{lag}'] = data[f'{col}'].shift(lag)\n",
    "\n",
    "# Remove NaN's\n",
    "valid_days = max(1,\n",
    "                 max(roll_avgs)-1,\n",
    "                 max(rsi_period,\n",
    "                     bband_period,\n",
    "                     macd_periods[1]+macd_periods[2]-2)) \\\n",
    "             + max(lags)\n",
    "data            = data.iloc[valid_days:]\n",
    "for lag in lags:\n",
    "    for asset_info in orig_cols:\n",
    "        col = f'{asset_info[0].lower()}_dir'\n",
    "        data[f'{col}_lag{lag}'] =\\\n",
    "            data[f'{col}_lag{lag}'].astype(int)\n",
    "\n",
    "# Display the data for the first and last few dates\n",
    "display(data.head(num_dates_disp))\n",
    "display(data.tail(num_dates_disp))\n",
    "\n",
    "# Directory for saving results\n",
    "if not os.path.isdir('results'):\n",
    "    os.mkdir('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFB20MUgXKsY"
   },
   "source": [
    "## Visualizing Daily Returns, Google Trends Changes, and Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Daily Returns, Google Trends Changes, and Technical Indicators\n",
    "fig, ax = plt.subplots(4+include_Google_Trends, 1,\n",
    "                       sharex=True,\n",
    "                       figsize = (12,12))\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "col_log_ratio = f'{asset_info_tgt[0].lower()}_log_ratio'\n",
    "i = 0\n",
    "ax[i].plot(data[col_log_ratio])\n",
    "ax[i].set(title = 'Daily Returns',\n",
    "          ylabel = 'log(returns)')\n",
    "ax[i].grid(True)\n",
    "\n",
    "if include_Google_Trends:\n",
    "    i += 1\n",
    "    asset_info = 'Google Trends Score'\n",
    "    col_log_ratio = f'{asset_info[0].lower()}_log_ratio'\n",
    "    ax[i].plot(data[col_log_ratio])\n",
    "    ax[i].set(title = f'{term} Daily Google Trends Changes',\n",
    "              ylabel = 'log(ratio)')\n",
    "    ax[i].grid(True)\n",
    "\n",
    "i += 1\n",
    "ax[i].plot(data['rsi'])\n",
    "ax[i].set(title = 'Relative Strength Index',\n",
    "          ylabel = 'RSI')\n",
    "ax[i].grid(True)\n",
    "\n",
    "i += 1\n",
    "ax[i].plot(data['bb_mid'])\n",
    "ax[i].fill_between(data['bb_mid'].index,\n",
    "                 data['bb_low'],\n",
    "                 data['bb_high'],\n",
    "                 color='blue',\n",
    "                 alpha=0.1)\n",
    "ax[i].set(title = 'Bollinger Bands',\n",
    "          ylabel = 'price')\n",
    "ax[i].grid(True)\n",
    "\n",
    "i += 1\n",
    "ax[i].plot(data['macd'], label='MACD')\n",
    "ax[i].plot(data['macd_signal'], label='Signal')\n",
    "ax[i].plot(data['macd_hist'], label='Hist')\n",
    "ax[i].set(title = 'Moving Average Convergence Divergence',\n",
    "          xlabel = 'date')\n",
    "ax[i].legend(loc='upper left')\n",
    "ax[i].grid(True)\n",
    "\n",
    "fig.suptitle(f'{ticker_symbol.upper()} ' + \\\n",
    "             f'({asset_info_tgt.capitalize()})',\n",
    "             x=0.1, y=1, fontsize=18);\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'results/{ticker_symbol}_day_to_day', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezztsErzsexR"
   },
   "source": [
    "## Predicting Bitcoin Closing Price Changes\n",
    "\n",
    "The predictors selected for modeling are:\n",
    "* lagged (up to 5 days) daily log ratios for:<br>\n",
    "    * opening price\n",
    "    * higest price\n",
    "    * lowest price\n",
    "    * closing price\n",
    "    * volume\n",
    "    * Google Trends score\n",
    "* lagged (up to 5 days) technical indicator information:\n",
    "    * Relative Strength Index (RSI)\n",
    "    * daily log ratio of Bollinger Band width\n",
    "    * Moving Average Convergence Divergence (MACD) Histogram\n",
    "\n",
    "Training-validation-test splits of 0.6-0.2-0.2 are used for the deep learning models while training-test splits of 0.8-0.2 are used for the other machine learning models. In all cases, the training data points come before the validation and test data points, and the validation data points come before the test data points. A probability decision threshold of 0.51 was used in each model decision for a price increase prediction in the test data.\n",
    "\n",
    "The Fully Convolutional Neural Network proposed [here](https://arxiv.org/abs/1611.06455) and defined [here](https://keras.io/examples/timeseries/timeseries_classification_from_scratch/) is used for the deep neural network (DNN). A long short-term memory ([LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory))-based architecture is used for the recurrent neural network (RNN).\n",
    "\n",
    "The following models from `scikit-learn` were also used:\n",
    "* [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "* [Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [Multi-layer Perceptron Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    "The following feature scaling approach selections are based on model properties (for instance, random forest classifiers are unaffected by feature scaling) as well as preliminary experiments:\n",
    "* Logistic Regression\n",
    "    * Normalization (between 0 and 1)\n",
    "* Gaussian Naive Bayes\n",
    "    * None\n",
    "* Support Vector Classification\n",
    "    * Standardization (mean center and scale to unit variance)\n",
    "* Random Forest Classifier\n",
    "    * None\n",
    "* Multi-layer Perceptron Classifier\n",
    "    * Standardization (mean center and scale to unit variance)\n",
    "* Deep Neural Network\n",
    "    * Normalization (between 0 and 1)\n",
    "* Recurrent Neural Network\n",
    "    * None\n",
    "\n",
    "The models are fit with the training (and validation) data and evaluated on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68319,
     "status": "ok",
     "timestamp": 1645759746448,
     "user": {
      "displayName": "Akinyinka Omigbodun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04675614761321408788"
     },
     "user_tz": 480
    },
    "id": "8IJjBLFxu26N",
    "outputId": "1898d15c-a55b-4782-f3f0-3251005def5c"
   },
   "outputs": [],
   "source": [
    "# Selecting predictors\n",
    "predictors = []\n",
    "for lag in lags:\n",
    "    for asset_info in orig_cols:\n",
    "        for chg_info in ['log_ratio', 'dir']:\n",
    "            if chg_info == 'dir':\n",
    "                continue\n",
    "            col = f'{asset_info[0].lower()}_{chg_info}'\n",
    "            predictor = f'{col}_lag{lag}'\n",
    "            predictors.append(predictor)\n",
    "    for r in roll_avgs:\n",
    "        col = f'{asset_info_tgt[0].lower()}_{r}_day_trend'\n",
    "        predictor = f'{col}_lag{lag}'\n",
    "        predictors.append(predictor)\n",
    "    for col in tech_ind_info:\n",
    "        predictor = f'{col}_lag{lag}'\n",
    "        predictors.append(predictor)\n",
    "\n",
    "print(f'predictors: {predictors}')\n",
    "\n",
    "# For seeding random number generators\n",
    "seed = 0\n",
    "\n",
    "# Split the data into training and test sets\n",
    "test_size = 0.2\n",
    "train, test = train_test_split(data,\n",
    "                               test_size=test_size,\n",
    "                               shuffle=False,\n",
    "                               random_state=seed\n",
    "              )\n",
    "print(f'\\nNumber of trading days in training dataset: {len(train)}')\n",
    "print(f'Number of trading days in test dataset: {len(test)}')\n",
    "\n",
    "# Accounting for simplified strategy format\n",
    "if simpl_strat:\n",
    "    strat_str = 'sstrategy'\n",
    "else:\n",
    "    strat_str = 'strategy'\n",
    "\n",
    "# For mapping strategy labels to and from non-negative integers\n",
    "num_outputs = len(list(set(data[strat_str])))\n",
    "def labeltoindex(labels):\n",
    "    labels_ = labels.copy()\n",
    "    unique_labels = sorted(list(set(labels_)))\n",
    "    labeltoindexmap = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        labeltoindexmap[label] = i\n",
    "    for i, label in enumerate(labels_):\n",
    "        labels_[i] = labeltoindexmap[label]\n",
    "    indextolabelmap = {value : key for (key, value) in labeltoindexmap.items()}\n",
    "    return labels_, indextolabelmap\n",
    "\n",
    "def indextolabel(indices, indextolabelmap):\n",
    "    indices_ = indices.copy()\n",
    "    for i, index in enumerate(indices_):\n",
    "        indices_[i] = indextolabelmap[index]\n",
    "    indices_ = indices_.astype(int)\n",
    "    return indices_\n",
    "\n",
    "indextolabelmap = labeltoindex(train[strat_str])[1]\n",
    "\n",
    "# Setting model decision thresholds\n",
    "if num_outputs == 2:\n",
    "    prob_thr = {1:0.51}\n",
    "elif num_outputs == 3:\n",
    "    prob_thr = {1:0.6, 2:0.6}\n",
    "default_class = 0\n",
    "def prob_to_class(class_prob,\n",
    "                  prob_thr=prob_thr,\n",
    "                  default_class=default_class):\n",
    "    if prob_thr is None or default_class is None:\n",
    "        return np.argmax(class_prob, axis=1)\n",
    "    else:\n",
    "        pred = np.empty(len(class_prob))\n",
    "        pred[:] = np.nan\n",
    "        for i, c_p in enumerate(class_prob):\n",
    "            for c in sorted(prob_thr.items(),\n",
    "                            key=lambda kv: kv[1],\n",
    "                            reverse=True):\n",
    "                if c_p[c[0]] >= prob_thr[c[0]]:\n",
    "                    pred[i] = c[0]\n",
    "                    break\n",
    "                else:\n",
    "                    pred[i] = default_class\n",
    "        return pred\n",
    "\n",
    "\n",
    "# Define functions to create neural networks\n",
    "#\n",
    "# Seeding random number generators\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "def Fully_Convolutional_Network(input_shape):\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "\n",
    "    conv2 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "\n",
    "    conv3 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "\n",
    "    gap = GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = Dense(num_outputs, activation=\"softmax\")(gap)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "def simple_DNN():\n",
    "    model = Fully_Convolutional_Network(\n",
    "              input_shape=(len(lags), data[predictors].shape[1] // len(lags))\n",
    "            )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def simple_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True,\n",
    "                   input_dim=len(predictors) // len(lags)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a dictionary of selected models\n",
    "models = {\n",
    " 'log_reg': linear_model.LogisticRegression(random_state=seed),\n",
    " 'gauss_nb': GaussianNB(),\n",
    " 'svm': SVC(random_state=seed, probability=True),\n",
    " 'random_forest': RandomForestClassifier(random_state=seed),\n",
    " 'MLP' : MLPClassifier(random_state=seed),\n",
    " 'dnn': simple_DNN(),\n",
    " 'rnn': simple_RNN(),\n",
    "}\n",
    "\n",
    "feature_scaling = {\n",
    " 'log_reg': 'normalization',\n",
    " 'gauss_nb': None,\n",
    " 'svm': 'standardization',\n",
    " 'random_forest': None,\n",
    " 'MLP' : 'standardization',\n",
    " 'dnn': 'normalization',\n",
    " 'rnn': None,\n",
    "}\n",
    "\n",
    "\n",
    "# Function that fits all models\n",
    "def fit_models(data):\n",
    "    # Fit scalers and transform training data\n",
    "    feat_sclr_specs = list(set(feature_scaling.values()))\n",
    "    feat_sclr = {}\n",
    "    data_ = {}\n",
    "    for feat_sclr_spec in feat_sclr_specs:\n",
    "        if feat_sclr_spec == 'normalization':\n",
    "            feat_sclr[feat_sclr_spec] =\\\n",
    "                MinMaxScaler().fit(data[predictors])\n",
    "        elif feat_sclr_spec == 'standardization':\n",
    "            feat_sclr[feat_sclr_spec] =\\\n",
    "                StandardScaler().fit(data[predictors])\n",
    "            \n",
    "        if feat_sclr_spec in ['normalization', 'standardization']:\n",
    "            data_[feat_sclr_spec] = \\\n",
    "                feat_sclr[feat_sclr_spec]\\\n",
    "                .transform(data[predictors])\n",
    "        else:\n",
    "            data_[feat_sclr_spec] = np.array(data[predictors])\n",
    "\n",
    "    if 'rnn' in models.keys() or 'dnn' in models.keys():\n",
    "        shape = data[predictors].shape\n",
    "        shape = (shape[0], len(lags), shape[1] // len(lags))\n",
    "\n",
    "        global history\n",
    "        history = {}\n",
    "\n",
    "    for model in models.keys():\n",
    "        if model in ['dnn', 'rnn']:\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(\n",
    "                    f\"best_{model}_model.h5\",\n",
    "                    save_best_only=True,\n",
    "                    monitor=\"val_loss\",\n",
    "                    verbose=False\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\",\n",
    "                    factor=0.5,\n",
    "                    patience=20,\n",
    "                    min_lr=0.0001\n",
    "                ),\n",
    "                EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=50,\n",
    "                    verbose=False\n",
    "                ),\n",
    "            ]\n",
    "            history[model] = models[model].fit(\n",
    "                              data_[feature_scaling[model]].reshape(shape),\n",
    "                              to_categorical(\n",
    "                                  labeltoindex(data[strat_str])[0],\n",
    "                                  num_outputs\n",
    "                              ),\n",
    "                              batch_size=32,\n",
    "                              epochs=500,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_split=min(0.5,test_size/(1-test_size)),\n",
    "                              verbose=False\n",
    "                             )\n",
    "            models[model] = load_model(f\"best_{model}_model.h5\")\n",
    "            print('')\n",
    "        else:\n",
    "            models[model].fit(\n",
    "                data_[feature_scaling[model]],\n",
    "                labeltoindex(data[strat_str])[0]\n",
    "            )\n",
    "    return feat_sclr\n",
    "\n",
    "# Function that predicts (derives all\n",
    "# position values) from the fitted models\n",
    "def derive_positions(data, feat_sclr):\n",
    "    # Transform testing data\n",
    "    feat_sclr_specs = list(set(feature_scaling.values()))\n",
    "    data_ = {}\n",
    "\n",
    "    for feat_sclr_spec in feat_sclr_specs:\n",
    "        if feat_sclr_spec in ['normalization', 'standardization']:\n",
    "            data_[feat_sclr_spec] = \\\n",
    "                feat_sclr[feat_sclr_spec]\\\n",
    "                .transform(data[predictors])\n",
    "        else:\n",
    "            data_[feat_sclr_spec] = np.array(data[predictors])\n",
    "\n",
    "    if 'rnn' in models.keys() or 'dnn' in models.keys():\n",
    "        shape = data[predictors].shape\n",
    "        shape = (shape[0], len(lags), shape[1] // len(lags))\n",
    "\n",
    "    for model in models.keys():\n",
    "        if model in ['dnn', 'rnn']:\n",
    "            # Make predictions\n",
    "            data['pred_' + model] = \\\n",
    "                indextolabel(\n",
    "                    prob_to_class(\n",
    "                        models[model].predict(\n",
    "                            data_[feature_scaling[model]].reshape(shape)\n",
    "                        )\n",
    "                    ),\n",
    "                    indextolabelmap\n",
    "                )\n",
    "\n",
    "            # Evaluate deep learning model predictions\n",
    "            models[model].summary()\n",
    "            print(f'\\nNumber of features (predictors): \\\n",
    "                  {models[model].inputs[0].shape[2]}')\n",
    "            print(f'\\nNumber of time steps (lags): {len(lags)}')\n",
    "            print('Evaluate:')\n",
    "            models[model].evaluate(\n",
    "                data_[feature_scaling[model]].reshape(shape),\n",
    "                to_categorical(\n",
    "                    labeltoindex(data[strat_str])[0],\n",
    "                    num_outputs\n",
    "                )\n",
    "            );\n",
    "            print(f'Number of classes: \\\n",
    "                  {models[model].outputs[0].shape[1]}')\n",
    "        else:\n",
    "            # Make predictions\n",
    "            data['pred_' + model] = \\\n",
    "                indextolabel(\n",
    "                    prob_to_class(\n",
    "                        models[model].predict_proba(\n",
    "                            data_[feature_scaling[model]]\n",
    "                        )\n",
    "                    ),\n",
    "                    indextolabelmap\n",
    "                )\n",
    "\n",
    "            # Evaluate model predictions\n",
    "            print(f'{models[model]}')\n",
    "            print(f'Number of features (predictors): \\\n",
    "                  {models[model].n_features_in_}')\n",
    "            print(f'Accuracy: \\\n",
    "                  {accuracy_score(data[{strat_str}], \\\n",
    "                                  data[\"pred_\" + model])}')\n",
    "            print(f'Classes: \\\n",
    "                  {[indextolabelmap[_] \\\n",
    "                   for _ in models[model].classes_]}')\n",
    "        print(f'Confusion Matrix: \\\n",
    "              \\n{confusion_matrix(data[{strat_str}], \\\n",
    "                                  data[\"pred_\" + model])}\\n')\n",
    "\n",
    "# Fit the models\n",
    "feature_scaler = fit_models(train)\n",
    "\n",
    "# Derives all position values\n",
    "derive_positions(test, feature_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LEX7XbbrSyc"
   },
   "source": [
    "## Vectorized Backtesting\n",
    "\n",
    "[Vectorized backtesting](https://www.oreilly.com/library/view/python-for-algorithmic/9781492053347/ch04.html) allows for a quick comparison of the trading strategies generated by the models (without eliminating [short selling](https://www.investopedia.com/terms/s/shortselling.asp) and without incorporating a trading commission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2241,
     "status": "ok",
     "timestamp": 1645759832235,
     "user": {
      "displayName": "Akinyinka Omigbodun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04675614761321408788"
     },
     "user_tz": 480
    },
    "id": "RBcqE1GtqMty",
    "outputId": "bc4f280b-0eec-4aa8-9474-609ab2247b03",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate trading strategies\n",
    "def evaluate_strategies(data):\n",
    "    global strategy_rtn, pos_strategy\n",
    "    strategy_rtn, pos_strategy = [], []\n",
    "\n",
    "    # Trades are made on the open\n",
    "    asset_info_trd = 'open'\n",
    "    col_log_ratio =\\\n",
    "        f'{asset_info_trd[0].lower()}_log_ratio'\n",
    "    for model in models.keys():\n",
    "        col_pred = 'pred_' + model\n",
    "        col_pos = 'pos_' + model\n",
    "        col_strat = 'strategy_' + model\n",
    "        data[col_pos] = data[col_pred]\n",
    "        simplify_strategy(data, col_pos)\n",
    "        data[col_strat] =\\\n",
    "            data[col_pos].shift(1) * data[col_log_ratio]\n",
    "        strategy_rtn.append(col_strat)\n",
    "        pos_strategy.append(col_pos)\n",
    "    data['returns'] = data[col_log_ratio]\n",
    "    strategy_rtn.insert(0, 'returns')\n",
    "\n",
    "# Evaluate all trading strategies by multiplying\n",
    "# predicted positions by actual daily returns\n",
    "evaluate_strategies(test)\n",
    "\n",
    "# calculate total return and annualized volatility\n",
    "# of each strategy\n",
    "print('\\nTotal Return: \\n')\n",
    "print(test[strategy_rtn].sum().apply(np.exp))\n",
    "print('\\nAnnualized Volatility: \\n')\n",
    "if ticker_symbol in ['btc-usd']:\n",
    "    print(test[strategy_rtn].std() * 365 ** 0.5)\n",
    "\n",
    "# Number of trades over time\n",
    "print('\\nNumber of trades: \\n')\n",
    "print(((test[pos_strategy].diff()[1:]!=0).sum())\n",
    "     +(np.sum(test[pos_strategy]) == len(test[pos_strategy])))\n",
    "\n",
    "# Visualize performance of trading strategies over time\n",
    "ax = test[strategy_rtn].cumsum().apply(np.exp).plot(\n",
    "        figsize=(12, 6),\n",
    "        title = f'{ticker_symbol.upper()} ' \\\n",
    "                'Comparison of Returns for each Strategy')\n",
    "ax.set_ylabel('Cumulative Returns')\n",
    "ax.grid(True);\n",
    "plt.tight_layout();\n",
    "plt.savefig(f'results/{ticker_symbol}_vectorized_backtesting', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0deMG8KWtqQA"
   },
   "source": [
    "## Backtesting with Backtrader\n",
    "\n",
    "[Backtrader](https://www.backtrader.com/) allows a more in-depth analysis of each trading strategy. There is no [short selling](https://www.investopedia.com/terms/s/shortselling.asp) in the setup here. The initial amount invested is 1000 USD. The trading commission is 0.5 percent, which is the maximum [fee](https://help.coinbase.com/en/pro/trading-and-funding/trading-rules-and-fees/fees) for each transaction on Coinbase.\n",
    "\n",
    "The focus here in on the Deep Neural Network (DNN) strategy, which is the best-performing non-[buy-and-hold](https://www.investopedia.com/articles/investing/100215/statistical-proof-buyandhold-investing-pays.asp) strategy. There is a timeline and figure showing trading information for the DNN strategy.\n",
    "\n",
    "Additionally, there is some groundwork for a comparison between the DNN and buy-and-hold strategies in a subsequent analysis with [pyfolio](#pyfolio_analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ticker_symbol in ['btc-usd']:\n",
    "    asset_type = 'crypto'\n",
    "    if ticker_symbol == 'btc-usd':\n",
    "        vol_prec = 8 # Bitcoin decimal place precision\n",
    "\n",
    "# Class to include columns in addition to price and volume data\n",
    "class SignalData(PandasData):\n",
    "    \"\"\"\n",
    "    Define pandas DataFrame structure\n",
    "    \"\"\"\n",
    "    cols   = ['predicted']\n",
    "    \n",
    "    # create lines\n",
    "    lines  = tuple(cols)\n",
    "\n",
    "    # define parameters\n",
    "    params = {c: -1 for c in cols}\n",
    "    params.update({'datetime': None})\n",
    "    params = tuple(params.items())\n",
    "\n",
    "# Define backtesting strategy class\n",
    "class Strategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('verbose', True),\n",
    "        ('logging', False),\n",
    "        ('show_tech_ind', False),\n",
    "        ('rsi_period', 14),\n",
    "        ('bband_period', 20),\n",
    "        ('macd_periods', (12, 26, 9)),\n",
    "        ('atr_period', 14),\n",
    "        ('wma_period', 30),\n",
    "        ('ema_period', 30),\n",
    "        ('pfast', 50),\n",
    "        ('pslow', 200),\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # keep track of open, closing prices and predicted value in the series\n",
    "        self.data_predicted = self.datas[0].predicted\n",
    "        self.data_open = self.datas[0].open\n",
    "        self.data_close = self.datas[0].close\n",
    "\n",
    "        # keep track of pending orders/buy price/buy commission\n",
    "        self.order = None\n",
    "        self.price = None\n",
    "        self.comm = None\n",
    "\n",
    "        # For logging profit and loss\n",
    "        if self.params.logging:\n",
    "            self.log_pnl = []\n",
    "\n",
    "        # Technical indicators to be plotted\n",
    "        if self.params.show_tech_ind:\n",
    "            # Relative Strength Index (RSI)\n",
    "            rsi = bt.indicators.RSI(\n",
    "                    self.datas[0],\n",
    "                    period=self.params.rsi_period,\n",
    "                    plotname='Relative Strength Index'\n",
    "                  )\n",
    "            bt.indicators.SmoothedMovingAverage(\n",
    "                rsi,\n",
    "                period=10,\n",
    "                plotname='Smoothed Relative Strength Index'\n",
    "            )\n",
    "            # Bollinger Bands\n",
    "            bt.indicators.BollingerBands(\n",
    "                self.datas[0],\n",
    "                period=self.params.bband_period,\n",
    "                plotname='Bollinger Bands',\n",
    "                subplot=True\n",
    "            )\n",
    "            # Moving Average Convergence Divergence\n",
    "            bt.indicators.MACDHisto(\n",
    "                self.datas[0],\n",
    "                period_me1=self.params.macd_periods[0],\n",
    "                period_me2=self.params.macd_periods[1],\n",
    "                period_signal=self.params.macd_periods[2],\n",
    "                plotname='Moving Average Convergence Divergence'\n",
    "            )\n",
    "            # Average True Range\n",
    "            bt.indicators.ATR(\n",
    "                self.datas[0],\n",
    "                period=self.params.atr_period,\n",
    "                plotname='Average True Range'\n",
    "            )\n",
    "            # Stochastic Oscillator\n",
    "            bt.indicators.StochasticSlow(\n",
    "                self.datas[0]\n",
    "            )\n",
    "            # Weighted and Exponential Moving Averages\n",
    "            bt.indicators.WeightedMovingAverage(\n",
    "                self.datas[0],\n",
    "                period=self.params.wma_period,\n",
    "                subplot=True\n",
    "            )\n",
    "            bt.indicators.ExponentialMovingAverage(\n",
    "                self.datas[0],\n",
    "                period=self.params.ema_period,\n",
    "                subplot=True\n",
    "            )\n",
    "            # Moving Average Crossovers\n",
    "            self.slow_sma = bt.indicators.SimpleMovingAverage(\n",
    "                                self.datas[0],\n",
    "                                period=self.params.pslow\n",
    "                            )\n",
    "            self.fast_sma = bt.indicators.SimpleMovingAverage(\n",
    "                                self.datas[0],\n",
    "                                period=self.params.pfast\n",
    "                            )\n",
    "            self.crossover = bt.indicators.CrossOver(\n",
    "                                self.fast_sma,\n",
    "                                self.slow_sma\n",
    "                            )\n",
    "\n",
    "    # logging function\n",
    "    def log(self, txt, dt=None):\n",
    "        '''Logging function'''\n",
    "        if self.params.verbose:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print(f'{dt.isoformat()} {txt}')\n",
    "\n",
    "        if self.params.logging:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            self.log_pnl.append(f'{dt.isoformat()} {txt}')\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # order already submitted/accepted - no action required\n",
    "            return\n",
    "\n",
    "        # report executed order\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(f'BUY EXECUTED --- \\\n",
    "                         Price: {order.executed.price:.2f}, \\\n",
    "                         Cost: {order.executed.value:.2f}, \\\n",
    "                         Commission: {order.executed.comm:.2f}')\n",
    "                self.price = order.executed.price\n",
    "                self.comm = order.executed.comm\n",
    "            else:\n",
    "                self.log(f'SELL EXECUTED --- \\\n",
    "                         Price: {order.executed.price:.2f}, \\\n",
    "                         Cost: {order.executed.value:.2f}, \\\n",
    "                         Commission: {order.executed.comm:.2f}')\n",
    "            \n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        # report failed order\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Failed')\n",
    "\n",
    "        # set no pending order\n",
    "        self.order = None\n",
    "        \n",
    "    def notify_trade(self, trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "        self.log(f'OPERATION RESULT --- \\\n",
    "                 Gross: {trade.pnl:.2f}, \\\n",
    "                 Net: {trade.pnlcomm:.2f}')\n",
    "\n",
    "    # We have set cheat_on_open = True. This means that we\n",
    "    # calculate the signals on day t's close price, but \n",
    "    # calculate the number of shares we wanted to buy\n",
    "    # based on day t+1's open price.\n",
    "    def next_open(self):\n",
    "        # Check if an order is pending.\n",
    "        # If yes, we cannot send a 2nd one\n",
    "        if self.order:\n",
    "            return\n",
    "        \n",
    "        # Check if we are in the market\n",
    "        if not self.position:\n",
    "            # Not yet ... we MIGHT BUY if ...\n",
    "            if self.data_predicted > 0:\n",
    "                # calculate the max number of shares ('all-in')\n",
    "                if asset_type == 'stocks':\n",
    "                    size = \\\n",
    "                        int(\n",
    "                            (1 - self.broker.comminfo[None].p.commission) * \\\n",
    "                            self.broker.getcash() /\n",
    "                            self.datas[0].open\n",
    "                        )\n",
    "                elif asset_type == 'crypto':\n",
    "                    size = \\\n",
    "                        int(\n",
    "                          (1 - self.broker.comminfo[None].p.commission) * \\\n",
    "                          self.broker.getcash() * (10**vol_prec) /\n",
    "                          self.datas[0].open\n",
    "                        ) / (10**vol_prec)\n",
    "\n",
    "                # buy order\n",
    "                self.log(f'BUY CREATED --- \\\n",
    "                         Size: {size}, \\\n",
    "                         Cash: {self.broker.getcash():.2f}, \\\n",
    "                         Open: {self.data_open[0]}, \\\n",
    "                         Close: {self.data_close[0]}')\n",
    "                self.order = self.buy(size=size)\n",
    "        else:\n",
    "            if self.data_predicted < 0:\n",
    "                # sell order\n",
    "                self.log(f'SELL CREATED --- \\\n",
    "                         Size: {self.position.size}')\n",
    "                self.order = self.sell(size=self.position.size)\n",
    "\n",
    "    def stop(self):\n",
    "        if self.params.logging:\n",
    "            with open(\n",
    "                    f'results/{ticker_symbol}_' +\n",
    "                    f'{selected_model}_log.csv',\n",
    "                    'w'\n",
    "                 ) as e:\n",
    "                for line in self.log_pnl:\n",
    "                    e.write(line + '\\n')\n",
    "\n",
    "strategies = {0: 'log_reg',\n",
    "              1: 'gauss_nb',\n",
    "              2: 'svm',\n",
    "              3: 'random_forest',\n",
    "              4: 'MLP',\n",
    "              5: 'dnn',\n",
    "              6: 'rnn',\n",
    "              7: 'buy_and_hold',\n",
    "              8: 'tgt_strategy'\n",
    "}\n",
    "strategy_info = {}\n",
    "strategy_vs_benchmark = [7, 5] # This order is important\n",
    "                               # for future results\n",
    "for s in strategy_vs_benchmark:\n",
    "    selected_model = strategies[s]\n",
    "    if selected_model == 'tgt_strategy':\n",
    "        test['predicted'] = test[strat_str]\n",
    "    elif selected_model == 'buy_and_hold':\n",
    "        test['predicted'] = np.ones(len(test))\n",
    "    else:\n",
    "        test['predicted'] = test['pred_' + selected_model]\n",
    "\n",
    "    if selected_model != 'buy_and_hold':\n",
    "        display(test.head(num_dates_disp))\n",
    "        display(test.tail(num_dates_disp))\n",
    "\n",
    "    # instantiate SignalData class\n",
    "    bttest = SignalData(dataname=test)\n",
    "\n",
    "    # instantiate Cerebro,\n",
    "    # add strategy, data, initial cash, commission\n",
    "    # and pyfolio for performance analysis\n",
    "    cerebro = bt.Cerebro(stdstats=True, cheat_on_open=True)\n",
    "    if selected_model == 'buy_and_hold':\n",
    "        verbose = False\n",
    "        logging = False\n",
    "    else:\n",
    "        verbose = True\n",
    "        logging = True\n",
    "    cerebro.addstrategy(Strategy,\n",
    "                        verbose=verbose,\n",
    "                        logging=logging,\n",
    "                        show_tech_ind=False)\n",
    "    cerebro.adddata(bttest, name=ticker_symbol.upper())\n",
    "    cerebro.broker.setcash(1000.0)\n",
    "    cerebro.broker.setcommission(commission=0.005) # At most\n",
    "                                                   # 0.5 percent\n",
    "                                                   # for trading\n",
    "                                                   # commission\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "    \n",
    "    if selected_model != 'buy_and_hold':\n",
    "        cerebro.addwriter(\n",
    "          bt.WriterFile,\n",
    "          csv=True,\n",
    "          out=f'results/{ticker_symbol}_{selected_model}_log.csv')\n",
    "\n",
    "    # run the backtest\n",
    "    if selected_model != 'buy_and_hold':\n",
    "        print(f'Starting Portfolio Value: {cerebro.broker.getvalue():.2f}')\n",
    "    backtest_result = cerebro.run()\n",
    "    strategy_info[selected_model] = backtest_result[0]\n",
    "    if selected_model != 'buy_and_hold':\n",
    "        print(f'Final Portfolio Value: {cerebro.broker.getvalue():.2f}')\n",
    "\n",
    "        plt.rcParams['font.sans-serif'] = \\\n",
    "            ['Tahoma', 'DejaVu Sans', 'Lucida Grande', 'Verdana']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        plt.rcParams['figure.figsize'] = (18, 16)\n",
    "        plt.rcParams['figure.dpi'] = 300\n",
    "        plt.rcParams['figure.facecolor'] = 'w'\n",
    "        plt.rcParams['figure.edgecolor'] = 'k'\n",
    "\n",
    "        btimagefile = f'results/{ticker_symbol}_backtrader_backtesting_{selected_model}.png'\n",
    "        cerebro.plot()[0][0].savefig(btimagefile, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pyfolio_analysis'></a>\n",
    "## Analyzing and Visualizing Backtrader Backtesting Results with [pyfolio](https://notebook.community/d00d/quantNotebooks/Notebooks/PortfolioAnalysis)\n",
    "\n",
    "`pyfolio` is used here to flesh out the picture of the performance and risk of the Deep Neural Network (DNN) trading strategy. There are statistics and plots showing:\n",
    "* top [drawdown](https://www.investopedia.com/terms/d/drawdown.asp) (peak-to-trough declines)\n",
    "* rolling, annual, and monthly returns from the investment strategy\n",
    "* the [Sharpe Ratio](https://www.investopedia.com/terms/s/sharperatio.asp), which is the ratio is the average return earned in excess of the risk-free rate per unit of volatility or total risk\n",
    "* rolling [Volatility](https://www.investopedia.com/terms/v/volatility.asp) (standard deviation of returns) and [Beta](https://www.investopedia.com/terms/b/beta.asp) (volatility in a strategy relative to a benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (and other information) from\n",
    "# selected strategy and buy-and-hold strategy\n",
    "returns = {}\n",
    "positions = {}\n",
    "transactions = {}\n",
    "gross_lev = {}\n",
    "for s in strategy_vs_benchmark:\n",
    "    selected_model = strategies[s]\n",
    "    pyfoliozer =\\\n",
    "      strategy_info[selected_model].analyzers.getbyname('pyfolio')\n",
    "    returns[selected_model],\\\n",
    "    positions[selected_model],\\\n",
    "    transactions[selected_model],\\\n",
    "    gross_lev[selected_model] =\\\n",
    "        pyfoliozer.get_pf_items()\n",
    "    if selected_model == 'buy_and_hold':\n",
    "        returns[selected_model].name = 'Benchmark'\n",
    "        benchmark_returns = returns[selected_model]\n",
    "    else:\n",
    "        returns[selected_model].name = 'Strategy'\n",
    "    returns[selected_model]\\\n",
    "    .to_csv(f'results/{ticker_symbol}_{selected_model}_returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance statistics for selected strategy\n",
    "pf.show_perf_stats(returns[selected_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected strategy versus buy-and-hold\n",
    "#\n",
    "# First plot\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2,\n",
    "                       figsize=(16, 9),\n",
    "                       constrained_layout=True)\n",
    "axes = ax.flatten()\n",
    "\n",
    "# Top drawdown periods\n",
    "pf.plot_drawdown_periods(returns=returns[selected_model],\n",
    "                         fontsize=16,\n",
    "                         ax=axes[0])\n",
    "# Rolling returns\n",
    "pf.plot_rolling_returns(returns=returns[selected_model],\n",
    "                        factor_returns=benchmark_returns,\n",
    "                        fontsize=16,\n",
    "                        ax=axes[1],\n",
    "                        title='Rolling returns')\n",
    "\n",
    "# Drawdown underwater plot\n",
    "pf.plot_drawdown_underwater(returns=returns[selected_model],\n",
    "                            fontsize=16,\n",
    "                            ax=axes[2])\n",
    "\n",
    "# Rolling Sharpe ratio\n",
    "pf.plot_rolling_sharpe(returns=returns[selected_model],\n",
    "                       fontsize=16,\n",
    "                       ax=axes[3])\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].grid(True)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel(axes[i].get_ylabel(), fontsize=16)\n",
    "    if i == 0:\n",
    "        axes[i].legend(\n",
    "            axes[i].get_legend_handles_labels()[0],\n",
    "            [f'{selected_model.upper()}'],\n",
    "            loc='upper left'\n",
    "        )\n",
    "    elif i == 1:\n",
    "        axes[i].legend(\n",
    "            axes[i].get_legend_handles_labels()[0],\n",
    "            ['Buy-and-Hold', f'{selected_model.upper()}'],\n",
    "            loc='upper left',\n",
    "            fontsize=13\n",
    "        )\n",
    "    axes[i].set_title(axes[i].get_title(), fontsize=18)\n",
    "\n",
    "fig.suptitle(f'{selected_model.upper()} vs '\\\n",
    "             f'Buy-and-Hold Strategy '\\\n",
    "             f'({ticker_symbol.upper()})',\n",
    "             fontsize=20)\n",
    "plt.tight_layout(pad=4)\n",
    "plt.savefig(f'results/{ticker_symbol}_{selected_model}_pyfolio1',\n",
    "            dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected strategy versus buy-and-hold\n",
    "#\n",
    "# Second plot\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2,\n",
    "                       figsize=(16, 9),\n",
    "                       constrained_layout=True)\n",
    "axes = ax.flatten()\n",
    "\n",
    "# Rolling Beta\n",
    "pf.plot_rolling_beta(returns=returns[selected_model],\n",
    "                     factor_returns=benchmark_returns,\n",
    "                     fontsize=16,\n",
    "                     ax=axes[0])\n",
    "\n",
    "# Rolling Volatility\n",
    "pf.plot_rolling_volatility(returns=returns[selected_model],\n",
    "                           factor_returns=benchmark_returns,\n",
    "                           fontsize=16,\n",
    "                           ax=axes[1])\n",
    "\n",
    "# Annual Returns\n",
    "pf.plot_annual_returns(returns=returns[selected_model],\n",
    "                       fontsize=16,\n",
    "                       ax=axes[2])\n",
    "\n",
    "# Monthly Returns\n",
    "pf.plot_monthly_returns_heatmap(returns=returns[selected_model],\n",
    "                                ax=axes[3])\n",
    "\n",
    "for i in range(4):\n",
    "    if i < 3:\n",
    "        if i < 2:\n",
    "            axes[i].set_xticklabels(axes[i].get_xticklabels(),\n",
    "                                    fontsize=14)\n",
    "        axes[i].grid(True)\n",
    "    axes[i].set_xlabel(axes[i].get_xlabel(), fontsize=16)\n",
    "    axes[i].set_ylabel(axes[i].get_ylabel(), fontsize=16)\n",
    "    axes[i].set_title(axes[i].get_title(), fontsize=18)\n",
    "    \n",
    "fig.suptitle(f'{selected_model.upper()} vs '\\\n",
    "             f'Buy-and-Hold Strategy '\\\n",
    "             f'({ticker_symbol.upper()})',\n",
    "             fontsize=20, y=0.94)\n",
    "plt.tight_layout(pad=0.94)\n",
    "plt.savefig(f'results/{ticker_symbol}_{selected_model}_pyfolio2',\n",
    "            dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "In preliminary analyses shown here, each of the approaches performed at about [chance level](https://www.igi-global.com/dictionary/chance-level/40596) (50%) in predicting Bitcoin price movements.\n",
    "\n",
    "| Model | Accuracy |\n",
    "| --- | --- |\n",
    "| Logistic Regression | 53% |\n",
    "| Gaussian Naive Bayes | 49% |\n",
    "| Support Vector Classification | 53% |\n",
    "| Random Forest Classifier | 47% |\n",
    "| Multi-layer Perceptron Classifier | 49% |\n",
    "| Deep Neural Network (DNN) | 54% |\n",
    "| Recurrent Neural Network (RNN) | 51% |\n",
    "\n",
    "Additionally, none the machine/deep learning algorithms presented here outperform the [buy-and-hold](https://www.investopedia.com/articles/investing/100215/statistical-proof-buyandhold-investing-pays.asp) strategy (267%). The DNN strategy (245%) comes closest.\n",
    "\n",
    "| Strategy | Vectorized Backtesting (Returns) | Backtesting with Backtrader (Returns) |\n",
    "| --- | --- | --- |\n",
    "| Logistic Regression | 90% | 17% |\n",
    "| Gaussian Naive Bayes | -5% | 26% |\n",
    "| Support Vector Classification | 207% | 155% |\n",
    "| Random Forest | -55% | -54% |\n",
    "| Multi-layer Perceptron | -17% | -41% |\n",
    "| Deep Neural Network | 233% | 245% |\n",
    "| Recurrent Neural Network | 156% | 120% |\n",
    "| Buy-and-hold |  | 267% |\n",
    "| Optimal |  | 84339% |\n",
    "\n",
    "Introducing features from the other information streams such as:\n",
    "* Major Stock Market Indexes\n",
    "    * S&P 500 (^GSPC)\n",
    "    * Dow Jones Industrial Average (^DJI)\n",
    "    * NASDAQ Composite (^IXIC)\n",
    "    * Russell 2000 (^RUT)\n",
    "    * New York Stock Exchange Composite (^NYA)\n",
    "    * Shanghai Stock Exchange Composite (000001.SS)\n",
    "    * China Securities Index (CSI) 300 Index (000300.SS)\n",
    "    * Euronext 100 Index (^N100)\n",
    "    * Nikkei 225 (^N225)\n",
    "    * Shenzhen Stock Exchange Composite Index (399106.SZ)\n",
    "    * NIFTY 50 (^NSEI)\n",
    "    * S&P Bombay Stock Exchange SENSEX (^BSESN)\n",
    "    * HANG SENG Index (^HSI)\n",
    "    * S&P/TSX Composite index (^GSPTSE)\n",
    "    * S&P/TSX 60 Index (TX60.TS)\n",
    "    * S&P/ASX 200 (^AXJO)\n",
    "    * OMX Nordic 40 (^OMXN40)\n",
    "    * Tadawul All Shares Index (^TASI.SR)\n",
    "    * FTSE 100 (^FTSE)\n",
    "* United States Treasury Yield Rates\n",
    "    * Treasury Yield 5 Years (^FVX)\n",
    "    * Treasury Yield 10 Years (^TNX)\n",
    "    * Treasury Yield 30 Years (^TYX)\n",
    "* Other crytocurrencies\n",
    "    * Ethereum (ETH-USD)\n",
    "* Commodities\n",
    "    * Gold Apr 22 (GC=F)\n",
    "    * Silver Mar 22 (SI=F)\n",
    "* Interest in major Crypto Exchanges\n",
    "    * Binance\n",
    "    * Coinbase\n",
    "    * FTX\n",
    "    * Kraken\n",
    "\n",
    "may help with identifying strategies that do better than the buy-and-hold strategy.\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. [Dataquest](https://www.dataquest.io/)\n",
    "\n",
    "2. [Chapter 4. Mastering Vectorized Backtesting](https://www.oreilly.com/library/view/python-for-algorithmic/9781492053347/ch04.html)\n",
    "\n",
    "3. [ML Classification Algorithms to Predict Market Movements and Backtesting](https://medium.com/analytics-vidhya/ml-classification-algorithms-to-predict-market-movements-and-backtesting-2382fdaf7a32)\n",
    "\n",
    "4. [Keras & TensorFlow to Predict Market Movements and Backtest using Backtrader](https://medium.com/analytics-vidhya/keras-tensorflow-to-predict-market-movements-and-backtest-using-backtrader-d51b0b3e9070)\n",
    "\n",
    "5. [Backtrader for Backtesting (Python) – A Complete Guide](https://algotrading101.com/learn/backtrader-for-backtesting/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0Ia63Hxv2x/5V2M87REA5",
   "collapsed_sections": [],
   "name": "CryptoPriceMovementPrediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
