{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **I HAVE CREATED StockPredDemo_v.3.0.ipynb AND SHARED IT WITH YOU. LET'S KEEP THE NEXT BIG UPDATES IN VERSION 3. ALL I COULD THINK WE COULD ADD TO THIS ONE IS WHAT I LEFT IN BOLD UNDER BRACKETS.**"
      ],
      "metadata": {
        "id": "GGb7rK-R68GR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XURlZyX4Jw4J"
      },
      "source": [
        "# AI-aid Investment analysis WebApp v2.0\n",
        "## Ethan Aug***usto Gonzalez Bonorino***\n",
        "### Status report \n",
        "\n",
        "- Designed structured of the WebApp\n",
        "- Aesthetics improved and description provided\n",
        "- Main structure and components of the EDA section have been coded [***replace line chart for time series***]\n",
        "- Tweet scraping functionality added \n",
        "- Sentiment analysis pipeline implemented\n",
        "- Entire program linked to dates instead of periods of time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi6PHK5VKLSy"
      },
      "source": [
        "## **Technologies** 📋\n",
        "\n",
        "* **Twint** -> Tweets scraper\n",
        "* **Streamlit** -> To build and share our WebApp\n",
        "* **Python** -> Programming language of choice\n",
        "* **Tensorflow** -> For optimizing and implementing models\n",
        "* **Yfinance** -> For historical and technical stock data\n",
        "* **BERT/VADER** -> To compute tweets sentiment scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCnvTIqfkA00"
      },
      "source": [
        "## Install and Import dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDDX-1UpLxak"
      },
      "source": [
        "## Twint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK5MPZ8Aj_p9",
        "outputId": "8db0713e-694b-48b6-8149-c01ab7d1d5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'twint'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 47 (delta 3), reused 14 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ]
        }
      ],
      "source": [
        "# Twint\n",
        "\n",
        "!git clone --depth=1 https://github.com/twintproject/twint.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhM7psbjkO7R",
        "outputId": "8325d12e-cd28-4d92-99a0-706f03db59bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 30.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 263 kB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 372 kB 57.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 291 kB 61.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for googletransx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "## must update requirements.txt for compatibility aiohttp==3.7.0\n",
        "\n",
        "!cd /content/twint && pip3 install . -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u6P950GkdxE",
        "outputId": "abe3dbcf-1513-4ae8-fee9-033f8433c4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.4 MB 33.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Yahoo Finance API\n",
        "\n",
        "!pip install yfinance --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgFy4edPky-M",
        "outputId": "5174e1f0-21c4-4e8a-8ffd-8955835320e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.1 MB 14.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 35.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 29.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 40.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 30.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 380 kB 44.8 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\u001b[0m\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "## Pyngrok\n",
        "\n",
        "!pip install streamlit --quiet\n",
        "!pip install pyngrok==4.1.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GdG3cSM6psz3"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odb_8NA3d4dy",
        "outputId": "6c97546e-691d-4b67-d99c-21b15e7f086b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 28.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XATddYmwsGE",
        "outputId": "895b584c-d86e-41c7-aa48-e4bb6d23eaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 153 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 163 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 184 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 194 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 204 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 215 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 235 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 256 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 266 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 276 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 286 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 296 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 307 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 327 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 337 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 358 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 368 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 378 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 389 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 399 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 409 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 419 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 430 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 440 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 450 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 460 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 462 kB 15.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "E7DF09fDwwq1",
        "outputId": "8871d25f-8ea6-4eb6-cd22-630d0450ca55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 22.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jLAGqAoKxBs4"
      },
      "outputs": [],
      "source": [
        "import twint\n",
        "import pandas as pd\n",
        "\n",
        "def get_tweets_test(ticker, num_tweets):\n",
        "\n",
        "    config = twint.Config()\n",
        "\n",
        "    config.Search = \"$\" + ticker\n",
        "    config.Lang = \"en\"\n",
        "    config.Limit = num_tweets\n",
        "\n",
        "    config.Pandas = True\n",
        "\n",
        "    twint.run.Search(config)\n",
        "\n",
        "    tweets_df = twint.storage.panda.Tweets_df.head(num_tweets)\n",
        "\n",
        "    data = pd.DataFrame(tweets_df)\n",
        "\n",
        "    tweets = [line for line in data['tweet']]\n",
        "\n",
        "    return tweets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tweets_test(\"AAPL\", 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cgSzcVZdmYA",
        "outputId": "d2ab40d1-55c4-4a84-c33c-dae1f307beac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1507504333637943296 2022-03-25 23:46:55 +0000 <investorVGT> おはようございます☁️ 米株myPF+3.51%😳 寄り付き新規買い $FLNG cash4%😅  🚀🚀 $SWN $FLNG ⤴︎ $CF $XOM $LLY $GOLD → $DAC ⤵︎ $CCJ  3指数まちまちも相場は回復基調維持。 $AAPL 9連騰でS&amp;P500を牽引。PFは今年1番の爆騰❗️我慢強いエネルギー資源株の保有が報われた日になりました😆 #米国株  https://t.co/KbJMK1RoYi\n",
            "1507504300024549385 2022-03-25 23:46:47 +0000 <ObservationDesk> @Convertbond #shotoniphonewithslavelaboranddirtycoal 😬 &lt;—- Hashtag doesn’t market as well 🤔  Apple’s Virtue Signals are the best! 🤷‍♂️  $AAPL\n",
            "1507503947010953219 2022-03-25 23:45:23 +0000 <DeLLiDayTrader> @Penny_Lane_BBM So happy for you! I’m gonna have try this $AAPL challenge next week… I’ve been all over the place lately 🤕  https://t.co/zlbwub3SPQ\n",
            "1507503798226460675 2022-03-25 23:44:48 +0000 <LlcBillionaire> Multibagger Stocks Definition and How to Trade Them  https://t.co/9j8Ee6o63j $NVDA $TSLA $SHOP $AAPL  $SPY\n",
            "1507503734896615427 2022-03-25 23:44:33 +0000 <Icon00007> PUTS All Day  Short Everything  $AAPL $SPY $QQQ $IWM $TLT @CramerTracker\n",
            "1507503518734766081 2022-03-25 23:43:41 +0000 <PetruGabriel> @TLPrivate_ B- Traded $AAPL $ANET and $NVDA and $UPST today. -1% all day due to the fact i did not sell upst when the market broke out in the last half an hour. i saw $qqq $spy and $arkk broke out and i could exited $upst on break even. took a 80c loss.\n",
            "1507503348244570114 2022-03-25 23:43:00 +0000 <mrmmonroe> @TicTocTick I think you're thinking about $AAPL\n",
            "1507503191583301632 2022-03-25 23:42:23 +0000 <JUP1TER_2> limit down Monday  this clown had to open his cursed mouth $SPY $QQQ $AAPL $TSLA\n",
            "1507502897256312834 2022-03-25 23:41:13 +0000 <PeterTrader99> YTD  $SPX -5% $QQQ -10% $ARKK -32%  -1% $AMZN $WMT -2% $AAPL $GOOGL -4% $TSLA -6% $NVDA -10% $JPM $MSFT -17% $AMD -19% $SQ $Z -25% $HD $SBUX -29% $TTD $PLTR -31% $UPST -34% $FB $U -38% $NFLX $ZM -40% $PYPL $W -41% $BIGC $TWLO -46% $ROKU -48% $SE -51% $SHOP -54% $RBLX -58% $AFRM\n",
            "1507502723423342593 2022-03-25 23:40:31 +0000 <yangruanliang> $AAPL I guess people heard of food shortages and went long apple.😆 😆 ⏩\n",
            "1507502458582405122 2022-03-25 23:39:28 +0000 <TEEELAZER> @_d3f4ult @PatTrades_ Obviously not advocating holding away from the money credit spreads either. I mean look at the peanuts you get for STO next week’s $AAPL puts 😆\n",
            "1507502124153729024 2022-03-25 23:38:09 +0000 <MacHashNews> Apple Closes Loophole That Allowed Mir Cardholders to Use Apple Pay in Russia  https://t.co/hGh2xUsT1b $AAPL  https://t.co/AJY5NLYwj0\n",
            "1507502112401362945 2022-03-25 23:38:06 +0000 <MacHashNews> Dutch watchdog fines Apple $5.7 million for ninth straight week  https://t.co/BhEBiYsTW4 $AAPL  https://t.co/dQ1XEwgNrK\n",
            "1507502102490202114 2022-03-25 23:38:03 +0000 <MacHashNews> MacStories Unwind: The Valve Steam Deck, Spider-Man: No Way Home, and Dune  https://t.co/i2pDnTXncK $AAPL\n",
            "1507502080633839617 2022-03-25 23:37:58 +0000 <ErikSteiner8> S&amp;P 500 Map at close @FINVIZ_com  #SP500 #SPX500 #SPX $MSFT $AAPL $GOOGL $FB $AMZN $DIS $V $TSLA $JPM $KO $T $ORCL $VZ $MMM  $SPY $UNH $DHR $TMO $MU $CAT $PG $TMO $CVX $NKE $D $CRM $MRK $ABBV $DWAC $XOM $COST $DG $LOW $CSCO $BA $DUK $HD $MA $NFLX $WMT $JNJ $PFE $ABT $PYPL $BAC  https://t.co/9b9ZGjbgex\n",
            "1507501381938458624 2022-03-25 23:35:12 +0000 <diadld2> $AAPL will this hold??? 💟\n",
            "1507501255068848130 2022-03-25 23:34:41 +0000 <AcdeDesenvolvi1> $SPY $AAPL will keep going to $300 without a single red day just because. 😎 very cool, very healthy ✌️ 💢  https://t.co/RjUo5zXXPD\n",
            "1507500712036610058 2022-03-25 23:32:32 +0000 <LjonesMotors> @TheStreet $MSFT | $AAPL | $BRKA | $AMZN\n",
            "1507500461963755522 2022-03-25 23:31:32 +0000 <RealHotTakesBot> Twitter's on the Rise:   $QQQ  Price: $359.35  Mentions: 47 $AAPL  Price: $174.72  Mentions: 43 $GNLN  Price: $0.70  Mentions: 43 $GME  Price: $151.95  Mentions: 35 $CLVR  Price: $3.84  Mentions: 33  #stocks #investing #trading\n",
            "1507500039182163968 2022-03-25 23:29:51 +0000 <DCataneo> /VX Futures, CBOE Volatility Index (VIX) March, 2022:  “In like a Lion --&gt; out like a lamb…“Don’t Look Up”  Complacency has again returned in force, boldly indifferent to the likelihood of a reversion.  $NDX $SPX $RUT $QQQ $SPY $IWM $TLT $VIX $AAPL #ES_F #NQ_F #RTY_F #ZB_F #VX_F  https://t.co/7gmWBV77X1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['おはようございます☁️ 米株myPF+3.51%😳 寄り付き新規買い $FLNG cash4%😅  🚀🚀 $SWN $FLNG ⤴︎ $CF $XOM $LLY $GOLD → $DAC ⤵︎ $CCJ  3指数まちまちも相場は回復基調維持。 $AAPL 9連騰でS&amp;P500を牽引。PFは今年1番の爆騰❗️我慢強いエネルギー資源株の保有が報われた日になりました😆 #米国株  https://t.co/KbJMK1RoYi',\n",
              " '@Convertbond #shotoniphonewithslavelaboranddirtycoal 😬 &lt;—- Hashtag doesn’t market as well 🤔  Apple’s Virtue Signals are the best! 🤷\\u200d♂️  $AAPL',\n",
              " '@Penny_Lane_BBM So happy for you! I’m gonna have try this $AAPL challenge next week… I’ve been all over the place lately 🤕  https://t.co/zlbwub3SPQ',\n",
              " 'Multibagger Stocks Definition and How to Trade Them  https://t.co/9j8Ee6o63j $NVDA $TSLA $SHOP $AAPL  $SPY',\n",
              " 'PUTS All Day  Short Everything  $AAPL $SPY $QQQ $IWM $TLT @CramerTracker',\n",
              " '@TLPrivate_ B- Traded $AAPL $ANET and $NVDA and $UPST today. -1% all day due to the fact i did not sell upst when the market broke out in the last half an hour. i saw $qqq $spy and $arkk broke out and i could exited $upst on break even. took a 80c loss.',\n",
              " \"@TicTocTick I think you're thinking about $AAPL\",\n",
              " 'limit down Monday  this clown had to open his cursed mouth $SPY $QQQ $AAPL $TSLA',\n",
              " 'YTD  $SPX -5% $QQQ -10% $ARKK -32%  -1% $AMZN $WMT -2% $AAPL $GOOGL -4% $TSLA -6% $NVDA -10% $JPM $MSFT -17% $AMD -19% $SQ $Z -25% $HD $SBUX -29% $TTD $PLTR -31% $UPST -34% $FB $U -38% $NFLX $ZM -40% $PYPL $W -41% $BIGC $TWLO -46% $ROKU -48% $SE -51% $SHOP -54% $RBLX -58% $AFRM',\n",
              " '$AAPL I guess people heard of food shortages and went long apple.😆 😆 ⏩']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUUBHO-vd4g3",
        "outputId": "17a3e13c-0104-4843-d9ed-32563327e0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emojis\n",
            "  Downloading emojis-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: emojis\n",
            "Successfully installed emojis-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emojis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ_5aTfSL_K0"
      },
      "source": [
        "## Streamlit WebApp design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQDj4caUgXeF",
        "outputId": "91952810-ba94-4484-c3f1-2db962bc93b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import twint\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "#import plotly.express as px\n",
        "\n",
        "import os\n",
        "import re\n",
        "import emojis\n",
        "\n",
        "import streamlit as st\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from transformers import pipeline\n",
        " \n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "import datetime\n",
        "\n",
        "timestr = time.strftime(\"%Y%m%d\")\n",
        "\n",
        "######## FUNCTIONS ########\n",
        "\n",
        "def get_ticker(name):\n",
        "\n",
        "    ticker = yf.Ticker(name)  \n",
        "    return ticker\n",
        "\n",
        "@st.cache\n",
        "def get_hist_data(ticker, start, end):\n",
        "\n",
        "    data = yf.download(ticker, start=start, end=end)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def make_line_chart(prices):\n",
        "\n",
        "    return st.line_chart(prices.values)\n",
        "\n",
        "def make_candlestick(company, ticker_name):\n",
        "    fig = go.Figure(data=[go.Candlestick(\n",
        "                x=company.index,\n",
        "                open=company['Open'],\n",
        "                high=company['High'],\n",
        "                low=company['Low'],\n",
        "                close=company['Close'])])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title= str(ticker_name) + ' data',\n",
        "        yaxis_title= str(ticker_name) + ' Stock price')\n",
        "    \n",
        "    config={\n",
        "        'modeBarButtonsToAdd': ['drawline']\n",
        "    }\n",
        "    \n",
        "    return st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def get_tweets(ticker, num_tweets):\n",
        "\n",
        "    config = twint.Config()\n",
        "\n",
        "    config.Search = \"$\" + ticker\n",
        "    config.Lang = \"en\"\n",
        "    config.Limit = num_tweets\n",
        "\n",
        "    config.Pandas = True\n",
        "\n",
        "    twint.run.Search(config)\n",
        "\n",
        "    tweets_df = twint.storage.panda.Tweets_df.head(num_tweets)\n",
        "\n",
        "    data = pd.DataFrame(tweets_df)\n",
        "\n",
        "    tweets = [line for line in data['tweet']]\n",
        "\n",
        "    return tweets\n",
        "\n",
        "def compute_sentiment(model_name):\n",
        " \n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    return classifier\n",
        "\n",
        "######## MAIN BODY ########\n",
        "\n",
        "st.title('AI-aid investment analysis tool')\n",
        "st.subheader(\"by Augusto Gonzalez-Bonorino and Ethan Aug\")\n",
        "\n",
        "# Containers help separate content. \n",
        "# Make sure to assign relevant names to distinguish containers\n",
        "description = st.container()\n",
        "description.write(\"\"\"The objective of this Webapp is to provide informative data and models of the stock market while empowering the user.\n",
        "                    This app provides a lot of flexibility in terms of input: Choose your own ticker and time range to investigate and gain insight\n",
        "                    on key metrics. With the everincreasing influence of technology, we felt it was important to include a social media sentiment score.\n",
        "                    Scraping Twitter in real time, the app outputs tweets containing your selected ticker, calculates a daily sentiment score and uses\n",
        "                    this alongside historical data in the models. There is also flexibility in model selection and hyperparameter tuning. \n",
        "                    Investigate different stocks, dates, models and hyperparamters to come to a data driven solution. Power to the user. \"\"\")\n",
        "\n",
        "######### SIDEBAR MENU ########\n",
        "st.sidebar.header(\"Data Science Capping \\n Financial Engineering\")\n",
        "\n",
        "######### MAIN BODY ##########\n",
        "ticker_name = st.text_input(\"Enter ticker to analyze\")\n",
        "\n",
        "company = get_ticker(ticker_name)\n",
        "\n",
        "st.text('Specify range of time:')\n",
        "\n",
        "today = datetime.date.today()\n",
        "tomorrow = today + datetime.timedelta(days=1)\n",
        "\n",
        "start_date = st.date_input('Start date', today)\n",
        "end_date = st.date_input('End date', tomorrow)\n",
        "\n",
        "stock_prices = company.history(start=start_date, end=end_date)\n",
        "\n",
        "\n",
        "######## COMPANY SUMMARY ########\n",
        "\n",
        "# detailed summary on Ticker\n",
        "if st.checkbox('Show company summary'):\n",
        "\n",
        "    st.subheader('Company summary on: ' + str(ticker_name))\n",
        "    st.write(company.info['longBusinessSummary']) \n",
        "\n",
        "######## RAW DATA DATAFRAME ########\n",
        "\n",
        "# Raw data for Ticker\n",
        "if st.checkbox('Show raw data'):\n",
        "\n",
        "    if start_date < end_date:\n",
        "        st.success('Start date: `%s`\\n\\nEnd date:`%s`' % (start_date, end_date))\n",
        "    else:\n",
        "        st.error('Error: End date must fall after start date.')\n",
        "\n",
        "    st.subheader('Raw data from ' + str(start_date) + ' to ' + str(end_date))\n",
        "\n",
        "    # fetches the data: Open, Close, High, Low and Volume\n",
        "    company = get_hist_data(ticker_name, start_date, end_date)\n",
        "\n",
        "    st.write(company)\n",
        " \n",
        "######## CHARTS ########\n",
        "\n",
        "# plots the graph\n",
        "if st.checkbox('Show chart for Start date: `%s`\\n\\nEnd date:`%s`' % (start_date, end_date)):\n",
        "\n",
        "    if st.checkbox('Show line chart'):\n",
        "        st.subheader('Line chart for ' + str(ticker_name) + ' price')\n",
        "        make_line_chart(stock_prices)\n",
        "    \n",
        "    elif st.checkbox('Show candlestick'):\n",
        "\n",
        "        st.subheader('Candlestick chart for ' + str(ticker_name) + ' price')\n",
        "\n",
        "        make_candlestick(stock_prices, ticker_name)\n",
        "  \n",
        "######## TWEETS ########\n",
        "\n",
        "# input bars to select ticker and num_tweets\n",
        "\n",
        "if st.checkbox(\"Show tweets\"):\n",
        "    num_tweets = st.slider(\"Number of tweets\", 1, 100)\n",
        "    tweets = get_tweets(ticker_name, num_tweets)\n",
        "    st.write(tweets)\n",
        "\n",
        "    if st.checkbox(\"Build Sentiment Analysis Pipeline...\"):\n",
        "\n",
        "        # Here we can have an input box for the user to select a model\n",
        "        model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "        # Load models\n",
        "        with st.spinner(\"Loading...\"):\n",
        "\n",
        "            classifier = compute_sentiment(model_name)\n",
        "        \n",
        "        st.success(\"Ready!\")\n",
        "\n",
        "        st.write(\"Here are our predictions. NOTE: scores range from 1 = very bad to 5 = very good\")\n",
        "\n",
        "        scores = classifier(tweets)\n",
        "\n",
        "        scores_df = pd.DataFrame(scores)\n",
        "\n",
        "        labels = []\n",
        "\n",
        "        for i in range(len(scores_df['label'])):\n",
        "\n",
        "            label = float(scores_df['label'][i][0])\n",
        "            labels.append(label)\n",
        "\n",
        "        sentiment_score = ( labels * scores_df['score'] )\n",
        "\n",
        "        scores_df[\"sent_score\"] = sentiment_score\n",
        "\n",
        "        scores_df['Tweet'] = tweets\n",
        "\n",
        "        st.write(scores_df)\n",
        "\n",
        "        sentiment_avg = sum(scores_df['sent_score']) / len(scores_df)\n",
        "\n",
        "        st.write(\"Average Sentiment\")\n",
        "        st.write(sentiment_avg)\n",
        "\n",
        "        if sentiment_avg < 3:\n",
        "            st.write(emojis.encode(\"NEGATIVE :chart_with_downwards_trend:\"))\n",
        "\n",
        "        elif sentiment_avg == 3:\n",
        "            st.write(emojis.encode(\"NEUTRAL :neutral_face:\"))\n",
        "        \n",
        "        else:\n",
        "            st.write(emojis.encode(\"POSITIVE :chart_with_upwards_trend:\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJbmhCm3lr8Z"
      },
      "source": [
        "## Server set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E3uSaXvlYj0",
        "outputId": "759e69cc-7522-427f-9cb0-2d8aee43ef9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "## Authtoken needed to connect to server\n",
        "\n",
        "!ngrok authtoken 267bF5z4JLHYkOC3tXZj4e2GYW5_7hYxKXE8fRwrYw1niAjUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvKW2vQWYQSR",
        "outputId": "21067353-6704-4d77-c620-04bdd34657a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "## Ethan's authtoken\n",
        "\n",
        "!ngrok authtoken 267VI2IlYQ7qjTsTsmHARZz2MHR_79trKA5RCS7okVhz6d31Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y331Eg1dglo7",
        "outputId": "bc258f4c-dec3-4a25-d643-750db8952211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "http://378d-34-86-220-152.ngrok.io\n"
          ]
        }
      ],
      "source": [
        "!nohup streamlit run app.py &\n",
        "url = ngrok.connect(port = '8501')\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8RBLwlYHnQ49"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAxTDkOzndBH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "StockPredDemo_v.2.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}