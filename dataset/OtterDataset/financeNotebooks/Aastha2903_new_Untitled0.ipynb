{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKvGJS6rdcC+j2SZbCFi13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aastha2903/new/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDI_kfoNURVZ",
        "outputId": "503ca4e9-b835-440c-ae5a-65e00853a299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "API_KEY = 'JK1QwYhKWFOk5mBbUQtPgQRMv'\n",
        "API_SECRET = 'LbnconRJ85x89iXa6wuwNAjTihHjyETB654zYZxZyrzJG0ynCy'\n",
        "ACCESS_TOKEN = '1862031402570485760-0sVker5Vch7FRlK0fkNVGDPpVfB3GU'\n",
        "ACCESS_TOKEN_SECRET = 'DgildeA9mK5OX8zNzucrRsfRoGmFxuGCvQ9Omh0IiV5ba'\n",
        "\n",
        "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)\n"
      ],
      "metadata": {
        "id": "6geL5P-BUePE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = \"stocks OR investing -filter:retweets\"  # Filter out retweets\n",
        "language = \"en\"\n",
        "since_date = \"2024-11-01\"\n",
        "\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=query, lang=language, since=since_date).items(100)  # Number of tweets\n"
      ],
      "metadata": {
        "id": "cdReuJ9EVF7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tweepy\n",
        "\n",
        "# BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAAbpxAEAAAAApVDTKZd6UBrkLzKtJzRuco0OmDY%3DXOwRKFZ9kIynKfg51IrJo0DKsUOPTSEKub3IUASI58ofpLx5zz'\n",
        "\n",
        "# client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "# query = \"(stocks OR investing OR stock market OR finance OR trading OR shares OR mutual funds OR ETFs OR dividends OR IPO OR portfolio) lang:en -is:retweet has:links\"\n",
        "\n",
        "# tweets = client.search_recent_tweets(query=query, max_results=10, tweet_fields=['author_id', 'created_at'])\n",
        "\n",
        "# tweet_data = []\n",
        "# if response.data:\n",
        "#         for tweet in response.data:\n",
        "#             tweet_data.append({\n",
        "#                 'id': tweet.id,\n",
        "#                 'text': tweet.text,\n",
        "#                 'created_at': tweet.created_at\n",
        "#             })\n",
        "#         print(\"\\n--- Retrieved Tweet Data ---\")\n",
        "#         print(tweet_data)\n",
        "#     else:\n",
        "#         print(\"\\nNo tweets found for the given query.\")\n",
        "\n",
        "# except tweepy.TooManyRequests:\n",
        "#     print(\"Rate limit exceeded. Please try again later.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred: {e}\")\n",
        "import tweepy\n",
        "\n",
        "BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAAbpxAEAAAAApVDTKZd6UBrkLzKtJzRuco0OmDY%3DXOwRKFZ9kIynKfg51IrJo0DKsUOPTSEKub3IUASI58ofpLx5zz'\n",
        "\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "query = \"(stocks OR investing OR stock market OR finance OR trading OR shares OR mutual funds OR ETFs OR dividends OR IPO OR portfolio) lang:en -is:retweet has:links\"\n",
        "\n",
        "try:\n",
        "\n",
        "    response = client.search_recent_tweets(query=query, max_results=1, tweet_fields=['author_id', 'created_at'])\n",
        "\n",
        "    tweet_data = []\n",
        "\n",
        "    if response.data:\n",
        "        for tweet in response.data:\n",
        "            tweet_data.append({\n",
        "                'id': tweet.id,\n",
        "                'text': tweet.text,\n",
        "                'created_at': tweet.created_at\n",
        "            })\n",
        "        print(\"\\n--- Retrieved Tweet Data ---\")\n",
        "        print(tweet_data)\n",
        "    else:\n",
        "        print(\"\\nNo tweets found for the given query.\")\n",
        "\n",
        "except tweepy.TooManyRequests:\n",
        "    print(\"Rate limit exceeded. Please try again later.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPEPd883VVLc",
        "outputId": "2a6dacb8-8134-4128-eacb-e196f94532d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit exceeded. Please try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = re.sub(r\"http\\S+|@\\S+|#\\S+|[^A-Za-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_tweets =[]\n",
        "\n",
        "\n",
        "for tweet in tweet_data:\n",
        "\n",
        "    cleaned_text = clean_text(tweet['text'])\n",
        "\n",
        "    if len(cleaned_text) > 0:\n",
        "        cleaned_tweets.append({\n",
        "            'id': tweet['id'],\n",
        "            'cleaned_text': cleaned_text,\n",
        "            'original_text': tweet['text'],\n",
        "            'created_at': tweet['created_at']\n",
        "        })\n",
        "\n",
        "\n",
        "print(\"\\n--- Cleaned Tweet Data ---\")\n",
        "for tweet in cleaned_tweets:\n",
        "    print(tweet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "UTg_upmjsnz1",
        "outputId": "64d2aa47-87cf-4e37-8564-a45d2d36c93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tweet_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-79c11aef6319>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweet_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "keywords = [\"stocks\", \"investing\", \"finance\", \"trading\", \"shares\", \"mutual funds\", \"ETFs\", \"dividends\", \"IPO\", \"portfolio\"]\n",
        "\n",
        "analysis_data = []\n",
        "mention_counter = Counter()\n",
        "\n",
        "for tweet in cleaned_tweets:\n",
        "    cleaned_text = tweet['cleaned_text']\n",
        "\n",
        "    analysis = TextBlob(cleaned_text)\n",
        "    sentiment_polarity = analysis.sentiment.polarity  # Sentiment score (-1 to 1)\n",
        "\n",
        "\n",
        "    mentions = [word.lower() for word in cleaned_text.split() if word.lower() in keywords]\n",
        "    mention_counter.update(mentions)\n",
        "\n",
        "    analysis_data.append({\n",
        "        'id': tweet['id'],\n",
        "        'cleaned_text': cleaned_text,\n",
        "        'original_text': tweet['original_text'],  # Retain the original text for reference\n",
        "        'created_at': tweet['created_at'],\n",
        "        'sentiment_polarity': sentiment_polarity,\n",
        "        'mentions': mentions\n",
        "    })\n",
        "\n",
        "mention_summary = dict(mention_counter)\n",
        "\n",
        "print(\"\\n--- Analyzed Tweet Data ---\")\n",
        "for tweet in analysis_data:\n",
        "    print(tweet)\n",
        "\n",
        "print(\"\\n--- Keyword Mention Summary ---\")\n",
        "print(mention_summary)\n"
      ],
      "metadata": {
        "id": "k6_yGGMYtyup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4e9b41-3b21-4f58-f393-a382c3489638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Analyzed Tweet Data ---\n",
            "\n",
            "--- Keyword Mention Summary ---\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(tweet_data)\n",
        "df.to_csv('tweets.csv', index=False)\n",
        "print(\"tweets.csv\")\n"
      ],
      "metadata": {
        "id": "qB0J6LpfnjAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHCSmCIiGzHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "for tweet in tweet_data:\n",
        "    analysis = TextBlob(tweet['text'])\n",
        "    tweet['sentiment'] = analysis.sentiment.polarity\n",
        "\n",
        "print(tweet_data)\n"
      ],
      "metadata": {
        "id": "IZ3ZjXawn58L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}