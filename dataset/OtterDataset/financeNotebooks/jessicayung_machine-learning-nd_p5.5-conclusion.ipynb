{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Free-Form Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation 1: Plotting predictions compared with actual prices\n",
    "\n",
    "This graph visualises the 7th-day predictions compared with the actual adjusted close prices.\n",
    "By 7th-day predictions, I am referring to the price predicted for e.g. Sept 7 if we are given training data up till Aug 30th. The purpose is to see how predictions vary with actual prices. I picked 200 datapoints to visualise because visualising all the points at once does not provide much insight.\n",
    "\n",
    "<img src=\"images/freeform-viz-200-points.png\" />\n",
    "\n",
    "Here is the visualisation with all points for reference:\n",
    "\n",
    "<img src=\"images/freeform-viz-all-points.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this project, we predicted BP's stock price. \n",
    "\n",
    "Initially we used a linear regression only on BP stock prices from the past 7 days, which produced impressive results, with 7-day predictions having a root mean squared percentage error of 5.4%.\n",
    "\n",
    "In this initial iteration, we perfomed the following steps:\n",
    "1. Import data (CSV) and format it as a Pandas Dataframe\n",
    "2. Create features  dataframe: Select features we wanted to use and put it into a separate dataframe\n",
    "3. Create target dataframe (Prices for 7 days following the last date provided in the features).\n",
    "4. Split into training and testing sets. (No shuffle because we are dealing with time series data.)\n",
    "5. Train chosen classifier.\n",
    "6. Predict test target.\n",
    "7. Evaluate test target and print evaluation metrics.\n",
    "\n",
    "After the initial iteration, I then repeated the process firstly with different classifiers (altering parameters, tried SVM regression) and then with new features (more days' worth of data, GAIA data, FTSE data). \n",
    "\n",
    "I then chose the model with the lowest mean root mean squared percentage error, which was a Linear Regression classifier trained on 7 days of BP and FTSE data (Close, max High and min Low prices. Adjusted for BP, not adjusted for FTSE).\n",
    "\n",
    "### Interesting Aspects of the Project\n",
    "1. **Coming up with new features from scratch as opposed to selecting them from a given set**. This resulted in much analysis paralysis because the universe of possible features is so large.\n",
    "2. **Collating data from different sources.** I wanted to use FTSE prices that weren't in the Quandl database I downloaded, so I wrote a Python script to scrape the data from Google Finance. I then had to combine this data with the BP price data. This was made more tedious because there were missing data values when I joined the two dataframes by dates, so I also had to **proxy data values**.\n",
    "2. **A simple model turned out to be better than several more complex models.** E.g. Linear Regression did better than SVM regression, and adding GAIA features or increasing the number of days' worth of data we considered both made increased RMS percentage error.\n",
    "\n",
    "### Difficult Aspects of the Project\n",
    "1. It was hard **selecting the algorithm** to use for this problem. \n",
    "    - It seemed as though any regression algorithm could work - and there are so many of them! I dealt with this by (1) first implementing an SVM regression to get the code to implement the algorithm down on the page so things would feel more concrete. Then I (2) chose the simplest algorithm that seemed to fit the problem and tried that.\n",
    "    - I was also conflicted as to whether or not I should use reinforcement learning. On the one hand there are profits that can act as rewards, but on the other hand trading would not impact the environment.\n",
    "2. **Putting different features together** in a dataframe took effort. \n",
    "    - Different stocks or indices had data for different dates (e.g. some had data for 1984-04-20, some didn't). I had to find these differences and decide what to do with missing data. \n",
    "3. There were **many possible features**. \n",
    "    - The project just got longer and longer and I hadn't even looked through half of the features I wanted to investigate or tried different algorithms. I decided to test out only a few features in this exploratory study and leave the rest for another study.\n",
    "    \n",
    "It is worth noting that the interesting and difficult parts of this project overlapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "<table>\n",
    "<th>Improvement</th><th>Expected Change</th>\n",
    "<tr><td>1. Try a wider selection of features.\n",
    "    - Stocks from other stock markets (e.g. NYSE)\n",
    "    - Company-specific figures such as P/E ratios</td><td>More accurate model</td></tr>\n",
    "<tr><td>2. Obtain and combine data from different data sources to minimise missing data\n",
    "    - e.g. FTSE100 prices because they must exist somewhere.</td><td>Increase number of datapoints with accurate data and so improve predictive range and capabilities</td></tr>\n",
    "<tr><td>3. Add measure of confidence for predictions (Probabilities)</td><td>Better idea of how reliable each prediction is so we can then recommend trades for high-confidence, postive-profit predictions.</td></tr>\n",
    "</table>\n",
    "\n",
    "### Things to Explore\n",
    "1. Try more algorithms (different classes).\n",
    "    - Different types of regressions\n",
    "    - Reinforcement Learning\n",
    "    - Deep Learning, Ensembles</td><td>Generically \n",
    "\n",
    "2. It would also be interesting to try this as a binary classification problem (predicting whether the price would go up or down) as opposed to predicting the exact price.\n",
    "\n",
    "### A Better Solution?\n",
    "Given the openness of this problem and the large universe it is contained in, I am confident that better solutions exist. That is a beautiful characteristic of this problem - than many things (even things which are beyond the scope of financial figures and stock prices, such as Wikipedia page views) can be used as features or proxies for stock prices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
