{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogdanbabych/-0945BUT10211-lex-term/blob/main/Autogen_Oct30_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2gNTdhADRhx",
        "outputId": "be256348-5985-4e59-cb34-8e03edf4b02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.1.14-py3-none-any.whl (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\n",
            "Collecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<1 (from pyautogen)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen) (3.8.6)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.10/dist-packages (from flaml->pyautogen) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen) (1.3.1)\n",
            "Installing collected packages: python-dotenv, flaml, openai, pyautogen\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flaml-2.1.1 openai-0.28.1 pyautogen-0.1.14 python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "#Multiagent conversation to solve a problem using Microsoft's Autogen and OpenApi's GPT4.\n",
        "\n",
        "!pip install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/microsoft/autogen"
      ],
      "metadata": {
        "id": "VxNrWl8Pk3l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen"
      ],
      "metadata": {
        "id": "OI2J3FlNDrvm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "WBK1r_4Hi1Xg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p-cr-0Zi3Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_list = [\n",
        "{\n",
        "'model': 'gpt-4',\n",
        "'api_key': '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',\n",
        "}\n",
        "]"
      ],
      "metadata": {
        "id": "zd9wcpK5EW2b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config1={\n",
        "    \"config_list\": config_list,\n",
        "    \"seed\": 42,\n",
        "    \"temperature\": 0.5,\n",
        "    \"timeout\": 45000\n",
        "}"
      ],
      "metadata": {
        "id": "Ns-hPq02f1ez"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Admin agent\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "   name=\"Admin\",\n",
        "   system_message='''You are the founder of this $10 billion AUM hedge fund named Vasuda Capital specializing in biotechnology and pharmaceutical investments in public companies.\n",
        "   You have a MBA in finance from Wharton Business School and you were a portfolio manager at a Goldman Sachs biotech/pharma hedge fund for 10 years.\n",
        "   Interact with the Portfolio Manager to select investments for the hedge fund.\n",
        "   All investments needs to be approved by this admin.''',\n",
        "   code_execution_config=False,\n",
        ")"
      ],
      "metadata": {
        "id": "t6EgeWbJgZaT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6ZA737_ghdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyst agent\n",
        "analyst = autogen.AssistantAgent(\n",
        "    name=\"Analyst\",\n",
        "    llm_config=llm_config1,\n",
        "    system_message='''Analyst.\n",
        "    You have a MBA degree in finance from University of Chicago and also hold a CFA designation.\n",
        "    You will run a scanner for finding biotechnology or pharmaceutical stocks which have more than 30% annual growth in revenue. Use finviz.com screener.\n",
        "    You will focus on small or mid cap companies.\n",
        "    From the scanning results, you will closely analyze the marketed products for each company, find their competition, check the product's competitive advantage over the competition.\n",
        "    Then, you will model the revenue growth to estimate future free cash flows, and find the discounted value of free cash flows for the next 10 years.\n",
        "    Use a discount rate or weighted average cost of capital of 10%.\n",
        "    Use McKinsey's textbook of valuation as your resource for valuing stocks.\n",
        "    You will also check your fair value of per share from the average analyst price target from Tipranks website at tipranks.com.\n",
        "    If the stock is at least 50% undervalued from your estimation of its fair value (using ratio of current stock price/fair value estiamte <=50%).\n",
        "    If the stock meets this criteria of being undervalued, you will assign a Buy rating and propose the company to the portfolio manager as a potential investment.\n",
        "\n",
        "''',\n",
        ")"
      ],
      "metadata": {
        "id": "RDu5v8mXhgRq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Risk manager agent\n",
        "risk_manager = autogen.AssistantAgent(\n",
        "    name=\"Risk_manager\",\n",
        "    system_message='''Risk manager.\n",
        "    You worked for 10 years at a JP Morgan hedge fund as a risk analyst.\n",
        "    You will analyze the portfolio daily for risk like margin violation or short-squeeze for short positions.\n",
        "    You will also analyze the macroeconomic and geopolitical environment using news websites like CNN.com and Bloomberg.com.\n",
        "    You will also analyze the market direction using the signal for Buy, sell or hold for SPY, SPDR S&P 500 ETF from Tradingview, Tradingview.com.\n",
        "    If the signal for SPY ETF is down, you will suggest the portfolio manager to hedge the hedge fund's long positions using put options.\n",
        "    You will also create a hedging plan and submit it to the portfolio manager.\n",
        "    ''',\n",
        "    llm_config=llm_config1,\n",
        ")"
      ],
      "metadata": {
        "id": "zjPCm-1th3Zr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Portfolio manager agent\n",
        "\n",
        "portfolio_manager = autogen.AssistantAgent(\n",
        "    name=\"Portfolio_Manager\",\n",
        "    system_message='''\n",
        "    Portfolio Manager.\n",
        "    You have an MBA degree in finance from New York University.\n",
        "    You have over 10 years of experience managing portfolios in healthcare including biotech and pharma investments at Fidelity.\n",
        "    Analyze the investments suggested by the analyst and propose them to the admin if you think they are good investments for the hedge fund.\n",
        "    Also consider the suggestions by the risk manager.\n",
        "    Create an optimum portfolio using the principles of portfolio management to maximize the portfolio returns while minimizing the risk and drawdown.\n",
        "\n",
        "''',\n",
        "    llm_config=llm_config1,\n",
        ")"
      ],
      "metadata": {
        "id": "uit-W-ct5BlI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Marketing manager agent\n",
        "marketing_manager = autogen.AssistantAgent(\n",
        "    name=\"Marketing_manager\",\n",
        "    system_message='''Marketing manager.\n",
        "    You worked for 10 years at RA Capital, a Boston-based biotech and pharma hedge fund as a marketing manager helping to raise over $10 billion in AUM.\n",
        "    You will prepare a slide deck to market the fund to potential investors and show it to the admin.\n",
        "    ''',\n",
        "    llm_config=llm_config1,\n",
        ")"
      ],
      "metadata": {
        "id": "aq-jF1qayK44"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupchat = autogen.GroupChat(agents=[user_proxy,portfolio_manager, analyst, risk_manager, marketing_manager], messages=[], max_round=50)"
      ],
      "metadata": {
        "id": "A5IhWtykiIBp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partner = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config1)"
      ],
      "metadata": {
        "id": "cjFhPwf9idDd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_proxy = autogen.UserProxyAgent(name = \"user_proxy\")"
      ],
      "metadata": {
        "id": "ykQigx2D6WSU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "metadata": {
        "id": "dp_25cG260Fh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiate chat between agents\n",
        "\n",
        "user_proxy.initiate_chat(\n",
        "    partner,\n",
        "    message='''\n",
        "Let us create a portfolio of potential investments in biotechnology and pharmaceuticals sector for our hedge fund.\n",
        "''',\n",
        "  llm_config=llm_config1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aVv5JcBxaVn1",
        "outputId": "e748ad77-0d14-40c6-cd7d-ad80e9be186c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>table.dataframe td{white-space: nowrap;}</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to chat_manager):\n",
            "\n",
            "\n",
            "Let us create a portfolio of potential investments in biotechnology and pharmaceuticals sector for our hedge fund.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.completion: 11-01 10:10:09] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.completion: 11-01 10:10:19] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.completion: 11-01 10:10:29] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 224, in _get_response\n",
            "    response = openai_completion.create(request_timeout=request_timeout, **config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJEYs6gZdPOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}