{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IM63WNBw9SQ"
      },
      "source": [
        "\n",
        "# **Extracting Structured Data from Unstructured Text with LLMs**\n",
        "\n",
        "This notebook demonstrates how to extract data in JSON, YAML, or other structured formats from long text documents, such as transcripts, PDFs, HTML, etc. Not only that, but I demonstrate how to perform data extraction efficiently and scalably, with support for concurrent processing and schema-based validation to ensure accuracy and consistency of the extracted data.  \n",
        "\n",
        "## Motivation\n",
        "\n",
        "It can be challenging to extract specific information from a large body of text. For example, suppose you wanted to get a list of all the names mentioned in a long transcript. Writing a Python script to do this would be challenging. You could try a simple keyword search for common names or invent some heuristic, but these method are unlikely to yield consistent results. You could also try creating [embeddings](/handbook/embeddings) for the transcript and list of names, then doing a vector similarity search, but again, this is difficult to do well, especially without missing any names.  \n",
        "\n",
        "Large language models (LLMs), however, are well-suited for this task since they possess a robust world model, whereby we can ask for just \"names\" without having to be too specific. They are also flexible in allowing us to ask for the results in a variety of formats, like JSON or YAML. From there, we can use these structured outputs much more easily in other programs.  \n",
        "\n",
        "## Example output\n",
        "\n",
        "Given the transcript for the Berkshire Hathaway annual shareholders meeting, we'll use an LLM and the code in this notebook to extract the names and organizations mentioned, as follows:  \n",
        "\n",
        "```\n",
        "{\n",
        "    \"names\": [\n",
        "        \"Judd Zaberski\",\n",
        "        \"Sue Decker\",\n",
        "        \"Charlie Munger\",\n",
        "        \"Jane Frazier\",\n",
        "        \"Randy Jeffs\",\n",
        "        \"Ken Chenault\",\n",
        "        \"Wally Weiss\",\n",
        "        \"Ron Olson\",\n",
        "        \"Warren Buffett\",\n",
        "        ...\n",
        "    ],\n",
        "    \"organisations\": [\n",
        "        \"Apple\",\n",
        "        \"BNSF\",\n",
        "        \"Berkshire\",\n",
        "        \"Berkshire Hathaway\",\n",
        "        \"Gap\",\n",
        "        \"Travelers\",\n",
        "        \"Kelly Toys\",\n",
        "        \"Allstate\",\n",
        "        ...\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "## Why should you read this notebook?\n",
        "\n",
        "You want to:\n",
        "- Extract data from long bodies of text  \n",
        "- Ensure the data results are in a useful format such as JSON or YAML, which you can then use as input to another process or application.  \n",
        "- Perform data extraction efficiently and scalably, with support for concurrent processing and schema-based validation to ensure accuracy and consistency of the extracted data.  \n",
        "\n",
        "## Source Code\n",
        "\n",
        "The Python scripts used in this notebook are available in the [`ai-cookbook`](https://github.com/gadkins/ai-cookbook/tree/main/data-processing/data-extraction) repo on my GitHub.\n",
        "\n",
        "**Attribution:** Much of the code here is based on the work of [Trelis Research](https://www.youtube.com/watch?v=zmf1Kujygt8), with modifications for my needs. I've also rewritten parts, so it can be run interatively in a Jupyter Notebook.\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "- Access to an LLM, such as OpenAI or an open-source model like OpenChat 3.5.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpuIUNHzhbo4"
      },
      "source": [
        "# Get Started\n",
        "\n",
        "The following code allows for the extraction of structured data (JSON or YAML) from unstructured text in an efficient and scalable manner, with support for concurrent processing and schema-based validation to ensure accuracy and consistency of the extracted data.\n",
        "\n",
        "It starts by:  \n",
        "- Parsing command-line arguments to configure the extraction process  \n",
        "- Reads the input text file and splits it into manageable chunks.   - For each chunk, generate a prompt based on a predefined schema  \n",
        "- Send these prompts to a model via an API (in this example OpenChat 3.5 hosted on Runpod.io).  \n",
        "- Responses are validated and aggregated according to the schema, then compiled into a final output file in the desired format (JSON or YAML).  \n",
        "\n",
        "This process allows for the extraction of structured data from unstructured text in an efficient and scalable manner, with support for concurrent processing and schema-based validation to ensure accuracy and consistency of the extracted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnrWNInFj9vD"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnFjYhXXj3cm"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -U transformers tqdm jsonschema pyyaml termcolor dotenv tenacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvVZ9z3SkIzc"
      },
      "source": [
        "## If using Google Drive to store input/output files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3S-Cev0kNnt",
        "outputId": "700b3960-6588-40f6-8bc5-ae243d60d86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyCUGAJUkR03"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "76JwqRmHkTX2"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import json\n",
        "import os\n",
        "import argparse\n",
        "from termcolor import colored\n",
        "import subprocess\n",
        "import time\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import jsonschema\n",
        "from jsonschema import validate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-6Xwgh_67Ma"
      },
      "source": [
        "## If using a private model on Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPyUqIXcbN1R"
      },
      "outputs": [],
      "source": [
        "## Authenticate to Hugging Face to pull and push models\n",
        "# !pip install huggingface_hub -q\n",
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9u4O2skouZ"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G9Di0vazklIe"
      },
      "outputs": [],
      "source": [
        "# Here I'm using a self-hosted model, but you could swap this for gpt-3.5-turbo, etc.\n",
        "# I've made available a one-click deployment template for Runpod here:  \n",
        "# https://runpod.io/console/gpu-cloud?template=t6sgcn049x&ref=n2u8jwou\n",
        "model = \"openchat/openchat_3.5\" # for extraction\n",
        "api_endpoint = \"https://xd3lef1do5g8d0-8080.proxy.runpod.net\" # where its being served\n",
        "\n",
        "\n",
        "# Towards the end of this notebook, we'll instantiate this class and use it to\n",
        "# perform extraction on a text file\n",
        "class Config:\n",
        "    def __init__(self, chunk_length=8000, output_format=\"json\", output_file_name=\"output\",\n",
        "                 batching=True, input_file_name=\"input.txt\"):\n",
        "        self.chunk_length = chunk_length\n",
        "        self.output_format = output_format\n",
        "        self.output_file_name = output_file_name\n",
        "        self.batching = batching\n",
        "        self.input_file_name = input_file_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsZ0LJbYl_-s"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ILOdflG8mC3j"
      },
      "outputs": [],
      "source": [
        "# utils.py\n",
        "from termcolor import colored\n",
        "import os\n",
        "\n",
        "\n",
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"tool\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(\n",
        "                colored(\n",
        "                    f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]\n",
        "                )\n",
        "            )\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(\n",
        "                colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]])\n",
        "            )\n",
        "            with open(\"user_request.txt\", \"w\") as file:\n",
        "                file.write(message[\"content\"] + \"\\n\")\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(\n",
        "                colored(\n",
        "                    f\"assistant: {message['function_call']}\\n\",\n",
        "                    role_to_color[message[\"role\"]],\n",
        "                )\n",
        "            )\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(\n",
        "                colored(\n",
        "                    f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]\n",
        "                )\n",
        "            )\n",
        "        elif message[\"role\"] == \"tool\":\n",
        "            print(\n",
        "                colored(\n",
        "                    f\"function ({message['name']}): {message['content']}\\n\",\n",
        "                    role_to_color[message[\"role\"]],\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "def read_text_file(text_file):\n",
        "    with open(text_file, \"r\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "\n",
        "def check_output_file_format(output_file_name, output_format):\n",
        "    # Check if output_file has an extension\n",
        "    _, file_extension = os.path.splitext(output_file_name)\n",
        "    if not file_extension:\n",
        "        # If not, add extension based on output_format\n",
        "        output_file_name = f\"{output_file_name}.{output_format}\"\n",
        "\n",
        "    return output_file_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grRvMYdVBkWQ"
      },
      "source": [
        "## Prompt\n",
        "\n",
        " This code is generates prompts that guide the extraction of structured data (like names and organizations) from unstructured text. It supports handling JSON and YAML schemas to define the structure of the data to be extracted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VImwdWqWB5as"
      },
      "outputs": [],
      "source": [
        "# prompts.py\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "def read_schema(file_path):\n",
        "    \"\"\"Reads a JSON or YAML schema from a given file path.\"\"\"\n",
        "    try:\n",
        "        if file_path.endswith('.json'):\n",
        "            with open(file_path, \"r\") as f:\n",
        "                return json.load(f)\n",
        "        elif file_path.endswith('.yaml') or file_path.endswith('.yml'):\n",
        "            with open(file_path, \"r\") as f:\n",
        "                return yaml.safe_load(f)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format. Please use '.json' or '.yaml/.yml'.\")\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Error reading file: {e}\")\n",
        "\n",
        "def generate_example(schema):\n",
        "    \"\"\"Generates an example object based on the provided schema.\"\"\"\n",
        "    example = {}\n",
        "    for key, value in schema[\"properties\"].items():\n",
        "        data_type = value.get(\"type\", \"string\")\n",
        "        if isinstance(data_type, list):\n",
        "            data_type = data_type[0]\n",
        "\n",
        "        example[key] = {\n",
        "            \"string\": f\"sample_string\",\n",
        "            \"integer\": 1,\n",
        "            \"boolean\": True,\n",
        "            \"array\": generate_array_example(value)\n",
        "        }.get(data_type, \"sample_value\")\n",
        "\n",
        "    return example\n",
        "\n",
        "def generate_array_example(value):\n",
        "    \"\"\"Generates an example array based on the array type in schema.\"\"\"\n",
        "    item_type = value.get(\"items\", {}).get(\"type\", \"string\")\n",
        "    if isinstance(item_type, list):\n",
        "        item_type = item_type[0]\n",
        "\n",
        "    return {\n",
        "        \"string\": [f\"sample_string_{i+1}\" for i in range(2)],\n",
        "        \"integer\": [i+1 for i in range(2)],\n",
        "        \"boolean\": [True, False]\n",
        "    }.get(item_type, [\"sample_value\"])\n",
        "\n",
        "def create_extract_prompt(schema, data_format):\n",
        "    \"\"\"Creates an extraction prompt based on the provided schema and data format.\"\"\"\n",
        "    example = generate_example(schema)\n",
        "    if data_format.lower() == \"json\":\n",
        "        schema_str = json.dumps(schema, indent=4)\n",
        "        example_str = json.dumps(example, indent=4)\n",
        "    elif data_format.lower() == \"yaml\":\n",
        "        schema_str = yaml.dump(schema, default_flow_style=False, indent=4)\n",
        "        example_str = yaml.dump(example, default_flow_style=False, indent=4)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported data format. Please use 'JSON' or 'YAML'.\")\n",
        "\n",
        "    prompt = (\n",
        "        f\"Extract names and organizations from the provided text, and return them in {data_format} format. \"\n",
        "        f\"Use the following schema:\\n\\n{schema_str}\\n\\n\"\n",
        "        f\"Here's an example of a response in {data_format} format:\\n\\n{example_str}\\n\\n\"\n",
        "        f\"Do not include anything that is not explicitly mentioned in the text. \"\n",
        "        f\"Analyse the text carefully to ensure all requested data is extracted. \"\n",
        "        f\"Include each name and organization only once. \"\n",
        "        f\"Adhere strictly to the response format without adding extra spaces or text.\"\n",
        "    )\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGwRJPm3odhO"
      },
      "source": [
        "## Aggregate (JSON)\n",
        "\n",
        "This code defines a Python class named JSONAggregator that performs several operations on JSON data based on a provided schema. The class is designed to aggregate data from multiple JSON documents into a single structured format, ensuring that the aggregated data conforms to a predefined schema.\n",
        "\n",
        "#### `json_schema.json`\n",
        "```json\n",
        "{\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"names\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"string\"\n",
        "            }\n",
        "        },\n",
        "        \"organisations\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"string\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\n",
        "        \"names\",\n",
        "        \"organisations\"\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJmdmQ4IrHfX"
      },
      "source": [
        "The primary method `aggregate_json()` attempts to validate the provided JSON data using the `validate_json` method. If the data is valid, it aggregates the data into `self.aggregated_data`. For each key in the input data, if the corresponding value is a list, the method updates the set associated with that key in the aggregated data (to ensure uniqueness and handle the aggregation of list values). This method increments the self.success counter if the data is valid; otherwise, it increments the `self.fail counter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zWxBXIbdohrv"
      },
      "outputs": [],
      "source": [
        "# json_validation_aggregation.py\n",
        "import json\n",
        "import jsonschema\n",
        "from jsonschema import validate\n",
        "from typing import Dict, Any\n",
        "\n",
        "class JsonAggregator:\n",
        "    def __init__(self, schema_file: str):\n",
        "        self.schema = self.load_schema(schema_file)\n",
        "        self.aggregated_data = {key: set() for key in self.schema[\"properties\"].keys()}\n",
        "        self.success = 0\n",
        "        self.fail = 0\n",
        "\n",
        "    def load_schema(self, schema_file: str) -> Dict[str, Any]:\n",
        "        with open(schema_file, \"r\") as file:\n",
        "            return json.load(file)\n",
        "\n",
        "    def validate_json(self, data: Dict[str, Any]) -> bool:\n",
        "        try:\n",
        "            validate(instance=data, schema=self.schema)\n",
        "            return True\n",
        "        except jsonschema.exceptions.ValidationError:\n",
        "            return False\n",
        "\n",
        "    def aggregate_json(self, json_data: Dict[str, Any]):\n",
        "        if self.validate_json(json_data):\n",
        "            self.success += 1\n",
        "            for key, values in json_data.items():\n",
        "                if isinstance(values, list):\n",
        "                    self.aggregated_data[key].update(values)\n",
        "        else:\n",
        "            self.fail += 1\n",
        "\n",
        "    def write_aggregated_data(self, output_file: str):\n",
        "        final_data = {key: list(value) for key, value in self.aggregated_data.items()}\n",
        "        with open(output_file, \"w\") as file:\n",
        "            json.dump(final_data, file, indent=4)\n",
        "        print(f\"Aggregation complete! The aggregated data has been written to '{output_file}'.\")\n",
        "\n",
        "# Example usage\n",
        "# aggregator = JsonAggregator(\"your_schema_file.json\")\n",
        "# aggregator.aggregate_json(your_json_data)\n",
        "# aggregator.write_aggregated_data(\"output_file.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlzb7Amppfr6"
      },
      "source": [
        "## Aggregate (YAML)\n",
        "\n",
        "This code defines a Python class named YamlAggregator that performs several operations on YAML data based on a provided schema. The class is designed to aggregate data from multiple YAML documents into a single structured format, ensuring that the aggregated data conforms to a predefined schema.\n",
        "\n",
        "#### `yaml_schema.yaml`\n",
        "\n",
        "```yaml\n",
        "type: object\n",
        "properties:\n",
        "  names:\n",
        "    type: array\n",
        "    items:\n",
        "      type: string\n",
        "  organisations:\n",
        "    type: array\n",
        "    items:\n",
        "      type: string\n",
        "required: [names, organisations]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AUTRMzdqSeQ"
      },
      "source": [
        "The primary method `aggregate_yaml()`, attempts to validate a piece of YAML data using the `validate_yaml` method. If the data is valid, it proceeds to aggregate it into the `aggregated_data` dictionary. For each key in the input data that matches a key in the schema, it either appends the value to a list (if the schema expects an array) or updates the value directly (if the schema expects a single value). If the schema specifies an array, the method also de-duplicates and sorts the list. The method increments the success or fail counter based on whether the data was valid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1rlbO5EvpnSY"
      },
      "outputs": [],
      "source": [
        "# yaml_validation_aggregation\n",
        "import yaml\n",
        "from jsonschema import validate\n",
        "from typing import Dict, Any\n",
        "import jsonschema\n",
        "\n",
        "class YamlAggregator:\n",
        "    \"\"\"\n",
        "    A class used to aggregate YAML data based on a provided schema.\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    schema : Dict[str, Any]\n",
        "        a dictionary representing the YAML schema\n",
        "    aggregated_data : Dict[str, Any]\n",
        "        a dictionary to store the aggregated data\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    load_schema(schema_file: str)\n",
        "        Loads the YAML schema from a file.\n",
        "    validate_yaml(data: Dict[str, Any])\n",
        "        Validates the YAML data against the schema.\n",
        "    aggregate_yaml(yaml_data: Dict[str, Any])\n",
        "        Aggregates the YAML data.\n",
        "    write_aggregated_data(output_file: str)\n",
        "        Writes the aggregated data to a file.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, schema_file: str):\n",
        "        self.schema = self.load_schema(schema_file)\n",
        "        self.aggregated_data = {\n",
        "            key: [] if self.schema[\"properties\"][key][\"type\"] == \"array\" else None\n",
        "            for key in self.schema[\"properties\"].keys()\n",
        "        }\n",
        "        self.success = 0\n",
        "        self.fail = 0\n",
        "\n",
        "    def load_schema(self, schema_file: str) -> Dict[str, Any]:\n",
        "        \"\"\"Loads the YAML schema from a file.\"\"\"\n",
        "        with open(schema_file, \"r\") as file:\n",
        "            return yaml.safe_load(file)\n",
        "\n",
        "    def validate_yaml(self, data: Dict[str, Any]) -> bool:\n",
        "        \"\"\"Validates the YAML data against the schema.\"\"\"\n",
        "        try:\n",
        "            validate(instance=data, schema=self.schema)\n",
        "            print(\"YAML validation successful!\")\n",
        "            return True\n",
        "        except jsonschema.exceptions.ValidationError as ve:\n",
        "            print(f\"Invalid yaml error - {ve}\")\n",
        "            return False\n",
        "\n",
        "    def aggregate_yaml(self, yaml_data: Dict[str, Any]):\n",
        "        \"\"\"Aggregates the YAML data.\"\"\"\n",
        "        # Validate the YAML data\n",
        "        is_valid = self.validate_yaml(yaml_data)\n",
        "        if is_valid:\n",
        "            self.success += 1\n",
        "            # Aggregate the data\n",
        "            for key, value in yaml_data.items():\n",
        "                if key in self.aggregated_data:\n",
        "                    # If the key is in the aggregated data, append or update the value based on its type\n",
        "                    if self.schema[\"properties\"][key][\"type\"] == \"array\":\n",
        "                        # If the value is a list, extend the existing list\n",
        "                        self.aggregated_data[key].extend(value)\n",
        "                        # De-duplicate and sort the list\n",
        "                        self.aggregated_data[key] = sorted(set(self.aggregated_data[key]))\n",
        "                    else:\n",
        "                        # If the value is not a list, update the existing value\n",
        "                        self.aggregated_data[key] = value\n",
        "        else:\n",
        "            self.fail += 1\n",
        "\n",
        "    def write_aggregated_data(self, output_file: str):\n",
        "        \"\"\"Writes the aggregated data to a file.\"\"\"\n",
        "        with open(output_file, \"w\") as file:\n",
        "            yaml.dump(self.aggregated_data, file)\n",
        "        print(\n",
        "            f\"Aggregation complete! The aggregated data has been written to '{output_file}'.\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GweVw4rBpl1"
      },
      "source": [
        "## Chat completion request\n",
        "\n",
        "Make a request to the chat completions API (In my example, I'm using OpenChat 3.5 deploy on Runpod.io.)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "cb45c07b448d455faf96d6b6897fe766",
            "d54aaeef5c38452a86d7b81f867caff9",
            "402261f24f024eaa85fd7c0469bb1077",
            "6414daccd3ae4864996a747f49fda63f",
            "7ac2d228faa544f5b703e89b26f4dba3",
            "df04369e655c4d8e9444750cacbdcd8f",
            "9c38de8c2b65445ab5b6b1c7a1be3e2e",
            "fc0fb363aef844ed9cb6ceadfbdf12ed",
            "b4d2c0bf8d0b4abb98c3988172d90dcf",
            "c4031064a4984d498c5b924173fc56c5",
            "afa138865b9f4698ad95591b684d4257",
            "0eb4170ed52f4018bd2facf0b76c9b4c",
            "b662d40af09f425dae6f76e73218f19b",
            "4f4ed9024e1142afa386754420147f14",
            "a55d73ff630d401db83c26ddb36df6ad",
            "a2c56d53affb422c8d2dabfe07ec24be",
            "f251d5638f4f4421aa9f324424551801",
            "4c40fe7b85ff4453ac7d26f8635e1c63",
            "f52c6119f104434496a3e304a567cc08",
            "885b99a0b7ba49268baa88a5cf877b44",
            "b4cb6c094060419385cf137430852e1c",
            "d934ca2ba17848d9a64c16e7b4eaf6a1",
            "e73b312458c2454fab00725262dcde1b",
            "28b02e64e7bf4f90bfba96395b836f92",
            "3805dbb5b5a7457b8cfcc9971b56a7e2",
            "344676a4f22c4165a325f3ebb0c9cff3",
            "5a1b914afb024aa0a1ece0a2032b326c",
            "23259602084247449618bf8304dd4c5f",
            "ef4b7aa0dd344a7b80ecf42b925a7f77",
            "dd387390fd904d6b9500c2358962b1a3",
            "baa6ce4d6b514882a8d6ca4bf2d8145b",
            "cd424d7420744325a71ba51e5680a19d",
            "46f143fdb9d7454d8ffd960eae4261f8",
            "279dba7f7cac4bc298cbd2dbca355b33",
            "f2837249c0544c2394669328f77bb16e",
            "13dd4083c39a4e758df4a3b5df84ae30",
            "5134b7123f2344c585d535e6fcb8fc56",
            "a279cc9d946d49debb3fa50bbbbc38d8",
            "e7cc67e0414146f7bf49042acceb5c02",
            "e1a0389cf96e43f29c272792c1113c05",
            "c2f6f1b0bd1948029c9b7209ff2eaf8a",
            "538fb1441c384786888058973a181e9d",
            "9ca6a0cfb69f48c4af74ef6bae38dbeb",
            "bb2576cad33f41c984e533819f6056b5",
            "17cfd05cc5d84e65a02e34664c6ba2a1",
            "5080fa1486f24bb4845e8378e4e5e713",
            "f4b5857c5724444193c77a637591f2f3",
            "2eb154bca5874a4faad27da28ad87467",
            "99ea50e74b1248708b87f29adbfc5584",
            "77b8602622b1430a89a1156a31fcccc3",
            "2a5f484e6d894766b48822e1f58c3c4a",
            "df30e47bc1794233ade6d6e5af9db703",
            "a27385058e31486eb04b3264005ec983",
            "47d7a1022f064c97ae0739057f7c489a",
            "6d5d80b3f9414e50b0559014c626f815"
          ]
        },
        "id": "_bUjw06ZAyrB",
        "outputId": "187f224c-21c0-4f9a-b2af-c010e9142a15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb45c07b448d455faf96d6b6897fe766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eb4170ed52f4018bd2facf0b76c9b4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73b312458c2454fab00725262dcde1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "279dba7f7cac4bc298cbd2dbca355b33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17cfd05cc5d84e65a02e34664c6ba2a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import time\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# model = \"openchat/openchat_3.5\" # for extraction\n",
        "# api_endpoint = \"https://xd3lef1do5g8d0-8080.proxy.runpod.net\" # model endpoint\n",
        "\n",
        "tgi_api_base = api_endpoint + \"/generate\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n",
        "\n",
        "# # Manual chat template\n",
        "# tokenizer.chat_template = '''{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{%- set ns = namespace(found=false) -%}{%- for message in messages -%}{%- if message['role'] == 'system' -%}{%- set ns.found = true -%}{%- endif -%}{%- endfor -%}{{bos_token}}{%- if not ns.found -%}{# Suppressed System Message #}{%- endif %}{%- for message in messages %}{%- if message['role'] != 'system' %}{%- if message['role'] == 'user' %}{{'### Instruction:\\\\n' + message['content'] + '\\\\n'}}{%- else %}{{'### Response:\\\\n' + message['content'] + '\\\\n\\\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt %}{{'### Response:'}}{% endif %}'''\n",
        "\n",
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request_runpod(messages):\n",
        "    # formatted_messages = format_messages(messages)\n",
        "\n",
        "    formatted_messages = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    print(formatted_messages)\n",
        "\n",
        "    # Properly escape the string for JSON and for shell execution\n",
        "    json_payload = json.dumps(\n",
        "        {\n",
        "            \"inputs\": formatted_messages,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": 500,\n",
        "                \"do_sample\": False,\n",
        "                # \"repetition_penalty\": 1.1, #can be useful for json, less so for yaml.\n",
        "            },\n",
        "        }\n",
        "    )\n",
        "    escaped_json_payload = json_payload.replace(\n",
        "        \"'\", \"'\\\\''\"\n",
        "    )  # Escape single quotes for shell\n",
        "\n",
        "    start_time = time.time()  # Start timing\n",
        "\n",
        "    try:\n",
        "        # Execute the curl command\n",
        "        curl_command = f\"curl -s {tgi_api_base} -X POST -d '{escaped_json_payload}' -H 'Content-Type: application/json'\"\n",
        "\n",
        "        response = subprocess.run(\n",
        "            curl_command, shell=True, check=True, stdout=subprocess.PIPE\n",
        "        )\n",
        "        response_time = time.time() - start_time  # Calculate response time\n",
        "\n",
        "        response = response.stdout.decode()\n",
        "\n",
        "        # print(response)\n",
        "\n",
        "        response = json.loads(response).get(\"generated_text\", \"No generated text found\")\n",
        "\n",
        "        # Calculate tokens per second\n",
        "        tokens_generated = len(response) / 4  # assuming 4 characters per word\n",
        "        tokens_per_second = tokens_generated / response_time if response_time > 0 else 0\n",
        "\n",
        "        # Print time taken and tokens per second\n",
        "        print(f\"Tokens generated: {tokens_generated:.2f}\")\n",
        "        print(f\"Total Time Taken: {response_time:.2f} seconds\")\n",
        "        print(f\"Tokens per Second: {tokens_per_second:.2f}\")\n",
        "        print(response)\n",
        "\n",
        "        return response\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return str(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbgr4gh9tddO"
      },
      "source": [
        "## Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "CcHjUE4bto-Y"
      },
      "outputs": [],
      "source": [
        "## Instatiate a new configuration\n",
        "project_dir = \"/content/drive/My Drive/data_extraction\" # Adjust if using Google Drive\n",
        "output_dir = \"/outputs\"\n",
        "\n",
        "config = Config(\n",
        "    chunk_length=8000, # Customize this as needed\n",
        "    output_format=\"json\", # or \"yaml\"\n",
        "    output_file_name=\"output.json\", # Adjust based on your preference\n",
        "    batching=True,\n",
        "    input_file_name=f\"{project_dir}/input_files/berkshire23_60k.txt\"\n",
        ")\n",
        "\n",
        "# Define schema\n",
        "json_schema_file = f\"{project_dir}/json_files/json_schema.json\"\n",
        "yaml_schema_file = f\"{project_dir}/yaml_files/yaml_schema.yaml\"\n",
        "json_schema = read_schema(json_schema_file) # Adjust location as necessary\n",
        "yaml_schema = read_schema(yaml_schema_file) # Adjust location as necessary\n",
        "\n",
        "# Create prompts\n",
        "json_extract_prompt = create_extract_prompt(json_schema, \"JSON\")\n",
        "yaml_extract_prompt = create_extract_prompt(yaml_schema, \"YAML\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EDwBmdrmsFTe"
      },
      "outputs": [],
      "source": [
        "# Read input file\n",
        "text = read_text_file(config.input_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VNdpGOgasOaz"
      },
      "outputs": [],
      "source": [
        "# Prepare prompts\n",
        "prompt = json_extract_prompt if config.output_format == \"json\" else yaml_extract_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nEIk2c5Y0VJ3"
      },
      "outputs": [],
      "source": [
        "# Split text into chunks\n",
        "block_size = config.chunk_length\n",
        "chunks = [text[i : i + block_size] for i in range(0, len(text), block_size)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjBLtzjX0cNy",
        "outputId": "8e087deb-254b-4f2f-c5e4-6eeeb288e48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...we are here live in Omaha Nebraska good morning everybody I'm Becky quick\n",
            "along with Mike santoli and in just 30 minutes time Berkshire Hathaway chairman and CEO Warren Buffett's going to be\n",
            "taking the stage with his vice chair Charlie Munger the legendary duo will also be joined by berkshire's two other\n",
            "Vice chairs Greg Abel who manages the non-insurance operations for the company and Ajit Jain who runs all of the\n",
            "insurance businesses and as always it's pretty big crowd here lots and lots of people and a few people you might notice\n",
            "too Tim Cook is here Apple of course is still berkshire's largest holding big big part of its portfolio there you see\n",
            "him backstage getting ready to go out and take his seat he gets to sit down in the special seats by the way that's\n",
            "Debbie pasonic Warren's assistant who's standing by just went bite beside him also in the crowd Bill Murray he has\n",
            "been here for a couple of days been hanging around you can check out he is taking a seat right now too some other\n",
            "big people who are expected to be here some well-known names Jane Frazier who's the city CEO Ruth parat of alphabet\n",
            "she's actually here I did and see her a little earlier and by the way this was a scene just a short time ago as the\n",
            "Berkshire shareholders who were first in line started streaming onto the floor Mike this is like um Black Friday used\n",
            "to be yeah day after Thanksgiving people waiting lining up these were the doors\n",
            "um yeah it was a big rush they opened and everybody comes running in and it's not just because of the rain outside absolutely if it's a massive Arena\n",
            "Convention Center so people know and uh I don't know what time do they start lining up I looked out the window at 5\n",
            "30 and I thought huh that's not as big of a crowd as I've seen in years past but then I realized it's because they\n",
            "changed the setup for this people used to stand about 10 Deep right at the door this year they pushed everybody the\n",
            "crowds down the the block because they I guess they didn't want too much of a mob scene in one place if you watched it\n",
            "went for blocks I didn't realize it till I went to the other side of the hotel to see it went for blocks and blocks and I've honestly never seen a line this\n",
            "long a lot of people around the convention center talking about how it's it's buzzier and more crowded in the\n",
            "exhibit all this year versus last year which was the first after the pandemic of course they broke for two years so it\n",
            "seems like there is a little more of a interest in uh in being here in person well they know how to time it there's a lot of news that's happening um usually\n",
            "you get about 40 000 people who are here this year they've been running ahead just in terms of the number of tickets\n",
            "that they gave out and I talked to Warren Buffett briefly last night he said that they had 6 000 people who\n",
            "showed up at will call yesterday to try and get last minute tickets they ran out of tickets they had to go print more to\n",
            "try and get people in the doors and they've never seen anything like that and as you mentioned the stuff sold out\n",
            "if you if you look at some of the places that are back here we're going to talk about some of these companies but he's been running the numbers and seeing what\n",
            "happened I I won't say too much now but he's been tabulating all of this up to see exactly what their sales are running\n",
            "like here versus uh years fast obviously this is sort of a weird microcosm of the\n",
            "of the business in the company as a whole and it's uh it's it's not Revenue neutral as he always talks about it\n",
            "looks you're paying you're paying to play here you are in fact it is going to be a big day here first though we should\n",
            "talk about the news at hand Berkshire is out with first quarter earnings and that came just moments ago Mike has been\n",
            "digging through all the numbers on this and there's some stories to be told here there are first of all a big swing to the upside in the overall reported\n",
            "earnings number uh from about five and a half billion uh dollars in the first quarter last year to 35 and a half\n",
            "billion but almost all that swing was the The Mark to Market on the Investment Portfolio operating earnings though is\n",
            "still a good story up almost 13 percent you know over a year up to about a little more than eight billion dollars\n",
            "um it seems like the insurance business specifically Geico swinging to a fatter\n",
            "underwriting profit from last year we could talk about exactly how they got there but it seems as if higher pricing\n",
            "less advertising Revenue they they went from margin as opposed to Pure market share it seems at this point also on the\n",
            "investment side uh seems like there was a reduction in the Chevron stake uh over\n",
            "the course of the quarter you have to back into the numbers based on the dollar value of the stakes that they give you in the share prices at the time\n",
            "but essentially it seems like he Berkshire was a seller of about 20 percent of that stake it's like oh\n",
            "that's a big six or seven billion uh dollars worth okay and um so it's still a significant holding I think it's also\n",
            "keep worth keeping in mind Chevron stock was up over 50 last year so simply by the market appreciating the the dollar\n",
            "value went up fair bit well it's interesting though if they were selling some of that steak while they were building the oxy stake uh the accident\n",
            "petroleum stake um not a call necessarily on oil overall just maybe\n",
            "picking exactly relative value or or positioning uh within that uh also\n",
            "Berkshire a net seller of overall Equity uh Securities in the quarter but the\n",
            "majority of that net reduction seems to be the Chevron I think the rest of it's hard to know Apple pretty much unchanged\n",
            "of course the Stock's up a lot but the position is unchanged uh Bank of America also seems unchanged too so those are\n",
            "two not a lot of change in terms of the key core holder for Bank of America that's the one bank that he has kept he\n",
            "sold out of a handful of other Banks Banks some of them that he's held for a very long time so Bank of America still\n",
            "seems to be his favorite maybe we'll hear more about that today you would hope yeah and just maybe General thoughts about his assessment of the\n",
            "banking system and uh whether it needs help whether it looks like it's an opportunity you have all these\n",
            "valuations that have been crushed another thing to keep in mind uh for the quarter there was four and a half\n",
            "billion dollars of shares bought back by Berkshire so that was up from 3.2\n",
            "billion in the year ago quarter it's not an enormous number in terms of the market value of Berkshire which is 700\n",
            "billion dollars it's like a you know what 18 billion dollar annual run rate of share buyback but they do reduce the\n",
            "outstanding shares a net reduction of shares down about 1.2 percent uh year over year so you know there were\n",
            "questions that came in that I've been looking through shareholder questions for a couple of months now that have been coming in on this and some of the\n",
            "questions that came in is do you still like Berkshire Hathaway do you still like the stock at this price are you\n",
            "going to be as aggressive as a buyer and I guess this answers some of that question some of it yeah it's it's absolutely not super aggressive uh but\n",
            "it's it's it's sort of soaking up some of the shares that are out there and of course Buffett in his shareholder letter\n",
            "was very vociferous about defending the practice of of being able to buy back\n",
            "stocks so he does it in a disciplined way he wants to be careful about why he's doing it and what the valuation is\n",
            "but uh clearly he's willing to use that tool oh the cash went up to 130 billion\n",
            "dollars so up marginally total cash holder nice Pocket Change um there had been a lot of questions\n",
            "that came into about the insurance company specifically Geico and you can see the gecko right now that's right shoulder uh people just wondering um\n",
            "what's happening and I guess we'll dig into that a little deeper today and we've got some numbers that you've been going through be very interested to hear\n",
            "the color on the strategy behind i...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...t because there was a little bit of uh you know an issue last year where it seemed\n",
            "like profitability was done now pricing is up across the industry yeah so policies are able to be written at\n",
            "higher prices and so that's happening across the board but it does seem you know as I say in the commentary within the the 10q that they did reduce\n",
            "advertising expense and it was a big swing to the upside and underwriting earnings I mean with insurance it takes\n",
            "a while to raise pricing for anybody in the industry because you have to go state by state and get Regulators approvals before approvals before you\n",
            "can actually raise any of it so there is a delay we saw some a huge hit to the profitability of all the insurers as you\n",
            "know prices to replace cars prices to fix things construction all of that went up right and they couldn't raise their prices as quickly exactly so it is an\n",
            "industry-wide phenomena but it seems as if uh Geico is trying to decide they want to skew toward more profitable\n",
            "customers we'll see if that's a theme that's going to continue another couple of tidbits are building products and\n",
            "consumers margin squeeze that's happening across the industry railroads pretty flat okay the BNSF pretty flat\n",
            "year over year and a pretty big reduction in consumer related Freight uh loading who needs an analyst you've\n",
            "already done all the work wow did the highlights I got my little you know tape bookmarks yeah that's good it works okay\n",
            "we have a lot more to get to this morning we want to give you a quick look at today's schedule though Mike and I are going to be here with you until 10\n",
            "15 a.m eastern time that is when Buffett Munger and the vice chairman Greg Abel and Ajit Jane are going to be taking the\n",
            "stage you get to watch all of this the annual meeting you can see it exclusively here on CNBC and cnbc.com\n",
            "Buffett's going to begin the meeting with the summary of the past quarters results but like we said Mike's already\n",
            "done that for you so that's your bathroom break time then he's going to open the stage to shareholder questions\n",
            "and I'll be asking some that have been emailed into me again we've gotten lots and lots of emails this year more than\n",
            "I've ever seen Buffett's also going to rotate through the 11 microphone microphone positions that are in the\n",
            "audience too so you'll see a lot of questions being asked around 1pm Buffett will break for lunch but you get to\n",
            "stick around with us Mike and I will be joined right here by Berkshire board members Ron Olson and Howard Buffett we'll also be talking to Tech investor\n",
            "Ann widblad and Activision Blizzard CEO Bobby kodek who has been coming to this meeting for years he was here last year\n",
            "but had to leave early because he was going to a birthday party so he left I think at the lunch break after that is\n",
            "when Buffett revealed to the crowd that he had taken a stake in Activision Blizzard so Bobby found out when he was\n",
            "on a plane on his way back home so he's here this year too and we'll find out if there's any new news on that at the time\n",
            "of course it was viewed as an Arbitrage position because Activision agreed to be sold to Microsoft for cash and Buffett\n",
            "said it was an Arbitrage position yeah exactly the spread was very wide it seemed just like the market was leaving money on the table now that it looks\n",
            "like perhaps Regulators in the UK might block that deal the question is does it remain you know on a fundamental basis\n",
            "yeah that would be fascinating to hear the commentary on that and then at 2 p.m Eastern Buffett and Munger will be back\n",
            "on stage for another two and a half hours of shareholder q a after the afternoon session wraps we'll be back\n",
            "with you to recap all of the day's action while the Market's staging a big rally\n",
            "to close the week after a strong job support and revisions to the February and March employment numbers Apple a\n",
            "major Berkshire holding which was unchanged in the quarter a key driver for yesterday's rally the stock closing\n",
            "Higher by about four and a half percent uh on the day after posting better than expected earnings Apple now up nearly 34\n",
            "percent so far this year here to help us navigate the current market environment and look at opportunities right now as\n",
            "John Rogers he's the chairman and co-ceo of aerial Investments and a long time Berkshire meeting attendee John good to\n",
            "see you thanks for stopping by here great to be here um what's your uh I guess what you what are you looking to hear from Mr Buffett\n",
            "and Munger uh both about I mean we know that the principles are going to accentuate that they always do about how\n",
            "they do their business and and what matters and doesn't matter in the uh in the earnings and how they approach things but what about the moment right\n",
            "now where it seems like there's big big questions about financial system stability whether there's value in in\n",
            "Bank stocks whether the economy can handle these rate hikes a couple things that I'm going to be looking for one you\n",
            "know when Becky interviewed Warren when he was in Asia and there was talk and Warren talked about how certain of his\n",
            "companies were not meeting expectations earnings were going to be less than expected and profits were lower than expected and so I want to see if that\n",
            "trend has continued are is he still seeing weakness in the overall economy and the second thing you know Becky\n",
            "followed up the question about Paramount Global and he was kind of a little bit soft and not as aggressively supporting\n",
            "his position as I had expected so I'm curious to see what he has to say today about it especially after the stock just\n",
            "located this week and you are an owner of Paramount correct we are an owner of Paramount Global assist it's not been a\n",
            "fun week yeah how do you feel about things I mean Paramount slashing the dividend um I I think it caught some people by\n",
            "surprise but Mario gabelli was here yesterday and he said it didn't catch him by surprise he wanted them to do that because he wanted them to shore up\n",
            "their cast position and put it back into their business at this point but I think it was the right decision and I watched\n",
            "Mario yesterday morning and then we did a panel and he has been very positive about the future\n",
            "for Paramount Global so we're still very very optimistic we think they have so many assets around the world they've got\n",
            "that great Paramount Library they've got Mission Impossible coming out this year all the great Sports entertainment that\n",
            "they have and all-time favorites like 60 minutes so I think there's more there than just the streaming and I think\n",
            "sometimes people are more worried than they need to be is it more there as a standalone business or do you think that this is an acquisition an acquisition\n",
            "Target and that I mean Mario belly has always been about you know business of Love Making with mergers and\n",
            "acquisitions you're right I think that everyone as we talk to experts in in the industry everyone says there's way too many\n",
            "streaming services we've got to get it down to three four at the maximum so I think it's very possible that Paramount\n",
            "Global will be bought at some point as a value manager do you look at the Carnage\n",
            "in things like Regional Banks and anything that seems like it's it's connected to a commercial real estate and view that as uh more of a core risk\n",
            "to the economic Outlook or is there actual value being being surfaced in the process well I think the stocks have\n",
            "gotten crushed there's a lot of pessimism and Warren often says you want to be greedy when others are fearful so I think if you're going to buy the\n",
            "banking stocks you'd buy a whole basket of them not try to pick one but really be Diversified we've been also adding to\n",
            "our favorite Northern Trust is our favorite Bank stock so I I think we're going to be okay uh it's going to be\n",
            "some pain and anguish here and of course commercial real estate is getting harmed and it doesn't help having the banks and\n",
            "the problems they are but yeah down the road we'll be fine I've been talking to folks who here in the last day and there is a little bit of s...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...uspense as to\n",
            "whether in fact clearly we'll get some questions on this whether uh Buffett himself sees there to be any\n",
            "opportunities here to provide capital in areas where it's like I mean it's worth going back to how he acquired a lot of\n",
            "his financial positions right American Express 60 years ago coming off a crisis that he needed Capital Bank of America\n",
            "clearly Solomon Brothers in the early 90s uh Goldman Sachs back around the crisis too so in other words he's been\n",
            "there as a source of stable Capital at times when the financial system seemed like it was in trouble would you want to\n",
            "see him make a move like that that would bring a lot of confidence to the economy and to the financial system whenever he\n",
            "steps up all of us believe in him so much so I think it would be great if he was able to be helpful during this\n",
            "period and get a great return for Berkshire shareholders\n",
            "involved with conversations on these things are there deals that he saw and passed up on you know maybe we'll get a\n",
            "little color into some of that today I'm hoping that you know maybe that's why there's so many people that are here\n",
            "today too John we're going to welcome our television audience in in just a second but we want you to stay with us\n",
            "and I'm doing this because literally the TV clicked so I'm just hold your thought for just a second we want to make sure\n",
            "we are welcoming our audience in fact you're going to hear a bell in just a second yeah ding ding ding there it goes that\n",
            "sound that you're hearing right now me doing ding ding ding it means that it's 10 a.m eastern time and that means that\n",
            "it is time to welcome our television audience as well we are again at the Berkshire Hathaway annual meeting and uh\n",
            "yeah okay want to welcome our television audience here and around the world I'm Becky quick I'm here with Mike santoli\n",
            "and this is our live all-day coverage of the 2023 Berkshire Hathaway annual meeting we are just 15 minutes away from\n",
            "the start of the action I want to get back to our conversation with John Rogers he's the chairman the co-ceo and\n",
            "the co and the CIO of aerial Investments and for everybody on television this is a conversation we've been having with\n",
            "our streaming audience at cnbc.com so let's just pick it up with where we left off John you were just talking about how if you saw Buffett step in and do some\n",
            "sort of a deal whether it be in the banking system whether it be something that kind of showed some confidence in\n",
            "the system that would mean a big deal for investors everywhere I think it would be he is so revered as we know\n",
            "around the world and I know that the by the Administration has been talking with him and I know you know other leaders\n",
            "are and you can bet that he's the First Call of Many of the major banking Giants on Wall Street to make sure they're\n",
            "getting his best advice and including him in these important conversations it's probably also worth keeping in mind that what he says about his take on\n",
            "whether in fact the banking system is sound whether whether the market is over\n",
            "overshooting and it's uh attack on some of these Regional Bank valuations it's worth listening to as well if he thinks\n",
            "the FED has it right we have this deposit backstop facility and you know let's keep in mind one of the reasons\n",
            "that the bank stocks are going down is consumers are in great shape they got a lot of cheap mortgages unprofitable for\n",
            "the banks they're looking at five percent money market yields they can move their cash there so it's it's it'll\n",
            "be interesting to hear whether he thinks it's an economic risk or it's just kind of a sector that's upside down for the\n",
            "moment well as you know he's such a long-term investor and I think he's going to uh you believe as he always\n",
            "talks about on at the annual meeting about how last century all the problems that confronted our country we always\n",
            "resolve him our capitalist democracy is the best system ever invented so this crisis will pass also I also noticed\n",
            "when I love watching CNBC in the morning when you have those special boxes showing returns like now even showing them Regional Banks how they're doing\n",
            "that's a sign that you're getting toward a period where you know six months from now that'll be a old forgotten story and\n",
            "we'll be on to something new but I love seeing that because it gives you a sense of what's important today John you our\n",
            "long-term investor too you're a value investor you don't often get swayed by things that are happening in the\n",
            "immediate but I have to think that some of the things you've seen recently have been enough to make you sit up and take\n",
            "notice is there anything you've changed in the portfolio as a result of the potential credit crunch as the result of\n",
            "just watching money move quickly out of places does it change your mind or change your investors thesis at all for\n",
            "the short term the only thing that sometimes happens like right now the housing the markets have been very weak higher interest rates have been\n",
            "Troublesome and problematic for the Housing Industry so we've been leaning in in some of the suppliers to the\n",
            "Housing Industry some of our favorites like Leslie's pools for example and residio and people that are creating\n",
            "products for the Housing Industry we think it's been overdone and there's real Bargains there you know there's been a lot of commentary and to some\n",
            "degree a bit of angst about how uh narrow the index performance has been at\n",
            "least recently for times this year we talked about Apple's performance a huge sway on the index is a handful of stocks\n",
            "really carrying the S P 500 where does that leave you as somebody who looks you know for smaller and and less expensive\n",
            "less popular stocks at the moment you know you know I've been fishing in the small and mid-cap Value World for 40\n",
            "years and I really think there's more opportunity than ever there's these orphan stocks neglected stocks and no\n",
            "one's looking at because they've been so focused on these giant great giant companies that have done so well\n",
            "what about Berkshire itself in terms of How It's positioned I mean on the one hand it's kind of Eternal right the way\n",
            "it's structured and who it's managed by but on the other I mean if you look at what's in favor right now you know aside\n",
            "from Apple which is you know 20 of the market value of Berkshire right now uh it's taken it is uh you have you know\n",
            "Consumer Staples exposure you have real Capital assets that people seem to be wanting to have pricing power\n",
            "um and even on the insurance side they're able to actually make a profit interest rates being up perhaps a help to them do you see value in the shares\n",
            "themselves at this level we do you know when Warren makes the decision to buy back stock the way he has he's so\n",
            "conservative and so for him to make that bet it gives you a really great sense that he sees the company as really\n",
            "undervalued and we would agree we think it's a great bargain here today do you have you been buying I own it\n",
            "personally and I was too big for my small and mid cap value uh portfolios at aerial fund but uh I haven't added to it\n",
            "in a while but that's a good suggestion John thank you very much we always enjoy\n",
            "seeing you here and we really appreciate your time this morning John Rogers from aerial Investments\n",
            "all right Berkshire Hathaways 11.6 billion dollar acquisition a year ago of the property and casually ensure\n",
            "Allegheny brought another diverse portfolio of Brands Under The Berkshire umbrella including one of the fastest\n",
            "growing toy makers in the U.S that's Jazz Wares they make all those viral squishmallows and here at the meeting\n",
            "they're actually selling special Warren Buffett and Charlie Munger squish millos this weekend they come in eight inch\n",
            "size and 16 inch versions this is the first time they've ever made squishmallows with a real human space on\n",
            "them we actually caught up with the company CEO and chief commercial officer Judd and Laura zaberski\n",
            "we acquired a company called kelly toys okay and they were making squish Mallows it's been around since 2017 and we were\n",
            "fortunate...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "... enough to build the brand once we acquired Kelly toys because the I mean people compare this to things like\n",
            "beanie babies or to the Cabbage Patch Kids where each of these dolls has a story that comes with it\n",
            "um and you guys are holding the special ones you have for this meeting of Warren and Charlie the first time you've ever\n",
            "put a human face on one of this yeah that's the first time so what they worked out pretty good okay but the story lines was that part of it too or\n",
            "did you guys add to that yeah so every squishmallow has their own individual story and when we acquired Kelly toy we\n",
            "saw that they had this almost diamond in the rough they were people were passionate about it it wasn't available\n",
            "everywhere it wasn't available globally and then um the BIOS were always part of it and\n",
            "what made them really special because kids and adults all identified with something in the bio and so Charlie and\n",
            "Warren both got their own bio that represented them as people not just business people but the really\n",
            "interesting individuals they are one of the things that I think is so amazing I mean these are cool plush toys but\n",
            "they're plush toys they're squishy they have become the most popular toy brand in 21 states they beat out Nerf Plato\n",
            "they beat out Nintendo switch and Hot Wheels how does that happen with the plush and have you guys been surprised\n",
            "by how they've taken off of course yes it struck a nerve during covet um it was\n",
            "this palliative type of feel so people that were sitting at home they bought more and more squish mouths and they\n",
            "fell in love with the product we're the number one best-selling toy in the US and in many many markets and I think\n",
            "what's interesting about it is our demographic it's not just kids it's adults it's grown women it we did a\n",
            "squish Squad tour and we went to major cities and we looked at the line and we said wow there's not that many children\n",
            "in the line and that's the interesting part people find it emotionally supportive [Music]\n",
            "um and that was a big surprise to us yeah people in their 50s are buying our squish Mellows wow that that's very\n",
            "unusual in the greatest and when you found out you were being acquired by Berkshire Hathaway your thought was\n",
            "wow wow and and what's happening uh dream come true yeah if you would have\n",
            "asked us 26 years ago if this would ever ever happen we would say no way but\n",
            "anything's possible in America well the interesting part is Berkshire didn't keep all the companies I think there\n",
            "were some they kind of got rid of they saw you guys and they chose to keep you which we were you know we I remember\n",
            "last year we were watching we knew the transaction was happening we watched the\n",
            "annual shareholders meeting and we said are we going to be there next year\n",
            "well in fact um I think they probably are going to be here next year I think the question is how much of the floor space they're\n",
            "going to get to negotiate because those have been hot cells yeah they do um we weren't the only ones who caught\n",
            "up with them though we were actually there a little later when Warren Buffett and Charlie Munger came by to visit the Jazz Wares Booth right here in the\n",
            "exhibition Hall and here's a funny coincidence for you both of them both Laura and Judd were lawyers before they\n",
            "had this career that's something they had in common with Charlie Munger too and by the way\n",
            "um they were sick of it too they wanted a job that was a little more fun\n",
            "did you know they're both reformed lawyers yes they both started out as lawyers well I'm ready to see a reform\n",
            "lawyer every time\n",
            "going through purchase orders yes Charlie I would like to see about 90 of\n",
            "the lawyers being reported this is a pinch me moment for us because we remember you know Judd started the\n",
            "company by himself no financing no money no backing and just did it and worked\n",
            "hard and of course we had many bumps in the road many many and it makes it that\n",
            "much sweeter and we appreciate it and we never forget how hard it was and we're much smarter today than we were\n",
            "yesterday I learned a lot I'm glad you were part of alligators\n",
            "you can catch more of our interview with Judd and Laura zaberski of jazz Wares and some other sounds from inside the\n",
            "Berkshire Hathaway annual meeting in a special series of cnbc's daily podcast it's called squawk pod and you can just\n",
            "scan the QR code on your screen to go ahead and follow squawkpod you can check it out and listen anytime\n",
            "all right well joining us now is the CEO of Benjamin Moore Dan Calkins Benjamin Moore has been part of the Berkshire\n",
            "portfolio for more than 20 years Dan uh good to have you great to be back I hope\n",
            "you're enjoying the weekend so far um eventful few years since you've been running the business yes uh for\n",
            "Berkshire for at Benjamin Moore uh housing boom in conjunction with the pandemic then a little a downturn in in\n",
            "home related investment uh and Improvement where do things stand right now we got the inflationary pressures\n",
            "you've had to kind of deal with and and pass through so what's your kind of snapshot of the business right now well\n",
            "we're in a great spot we're actually celebrating our 140th anniversary this year at Benjamin Moore so we've been\n",
            "through Cycles like this before obviously we'll be through this cycle but it has been uh what we call Benjamin\n",
            "Moore Chasing The New Normal because we had explosive growth in 20 and 21 took a\n",
            "little bit of a step back in the fourth quarter last year got off to a slow start this year but at the end of March\n",
            "we start to see light we're going into the paint season and people people are seeing starting to paint again and we're\n",
            "seeing that in our numbers on a regular basis obviously Big Driver for us is housing turnover and with interest rates\n",
            "High people not moving as much that has an impact on our business so as as mortgage rates hopefully start to come\n",
            "down we'll see more active moving and that drives to more sales for us and and just fixing things up when you cut a\n",
            "paint we can't or we can't move so yeah exactly yeah you'll have people doing some remodeling if they're not going anywhere but the Big Driver is the churn\n",
            "somebody moves they pay every room every room and in terms of supply chain I mean\n",
            "Paint and Coatings were particularly dramatically impacted yes you know during the the pandemic with a lot of\n",
            "the components there short supply where does it sit right now and if you retain pricing I was just looking in aggregate\n",
            "in the in the quarterly report that you know there has been some margins Queens across the building products uh\n",
            "businesses in total which is not suspicious right no we we definitely felt that we're in a good spot now\n",
            "um early last year we had about 65 days of inventory on end our historical average is about 95 days on hand I'm\n",
            "happy to say at the end of March we're at 96 days on hand so we're back to our historical Norms from an inventory\n",
            "perspective we have been able to take pricing over both 21 and 22. so uh while\n",
            "we've felt some of the pressure and compression last year that's evening out now we're recognizing the pricing we\n",
            "took last year in our sales this year so things are good and so that implies that you haven't seen consumers sort of trading down or\n",
            "anything like that when it comes to pain yeah no we have we have some particularly on the DIY side we've seen\n",
            "some of our product mix shift from some of our more premium products to more of our mid-range products uh but we have a\n",
            "full assortment full of portfolio that can meet all those price points that are out there and so we're we're seeing some\n",
            "of that happening right now and with margin shrinks when somebody trades down how much does it's maybe six seven\n",
            "points on from a you know premium product to more of a commercial type product but we have healthy margins at\n",
            "Benjamin Moore we have one of the things Warren life's best about Benjamin Moore is that premium position we carry you\n",
            "know there there's a big picture uh sort of long-term structural bullish story about home ownership actually\n",
            "homeownership rates uh ticking highe...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...r still even through this tough period of the economy and this demographic wave\n",
            "that's washing over but how are you thinking about you know expansion plans your ability to capture a lot of that\n",
            "yeah so we have been growing and expanding banding not just here in North America we've been very aggressive\n",
            "particularly in the UK and then moving into Western Europe which is still a small part of our business but we\n",
            "haven't felt the impact over there because it's New Territory for us so we have explosive growth going on over\n",
            "there right now um very exciting and then here long term you know you to your point about families being formed that's\n",
            "happening with this generation that's coming into the housing market and we just think this is a blip through this period of time and as that changes we're\n",
            "prepared to to service what we need to guys if you take a look you'll see this is live footage Warren Buffett is making\n",
            "his way out to the stage right now Charlie Munger will be joining him as well that means they're getting about to\n",
            "the end of the movie they have a long movie 45 minute movie that they show to the shareholders that's what they're\n",
            "seeing right now and there you see Charlie Munger as well so they're being taken out the stage that means things are about to kick off there so I'm going\n",
            "to take my lead that also means you need you have a place to go okay Mike thank you I'll see you back in just a little\n",
            "bit thanks so much thank you all right\n",
            "well Insurance of course one of the big story lines in berkshire's earnings this morning joining me now to discuss is\n",
            "evercore's David modematan he has got a buy rating by ratings on the likes of\n",
            "Travelers Progressive and Chubb uh uh from evercore isi and uh and Dave thanks\n",
            "for joining us uh this morning we were just talking about how over the first quarter berkshire's Insurance businesses\n",
            "specifically Geico did make some moves on pricing uh kind of fattened up the margins reducing advertising spend uh it\n",
            "seems like maybe an industry-wide Trend but what's been happening overall in the competitive uh landscape when it comes\n",
            "to those Insurance lines yeah thanks for having me um so you are seeing just a massive hard\n",
            "Market in the personal auto insurance space and Geico has actually taken you\n",
            "know fairly aggressive action on that front um and you can see that you know the focus on profitability is really\n",
            "coming through in in these results where their policies enforce shrank 13 and you\n",
            "know that's partly because you know there are premium per policy which is a good proxy for their price increases you\n",
            "know is up 15 uh which is you know among the highest that I've seen you know\n",
            "Allstate was up 16 Progressive was up you know close to that level so the entire industry is Raising price\n",
            "um for guy for Geico it looks like they've actually seen you know the their\n",
            "units come down quite a bit and that's resulted in them having better frequency Dynamics which is you know really help\n",
            "their earnings and you know another thing I've noticed is um you know they really cut their ad spend to really\n",
            "focusing on you know what what people they're underwriting to focus on profitability\n",
            "I appreciate that color uh David that was uh that's great we're going to hear a lot more about that in the Q a in the\n",
            "shareholder meeting and we're going to actually get to Becky and Warren Buffett and Charlie Munger for Q a we'll see you\n",
            "back here at 1pm Eastern time when Buffett and Munger break for lunch ahead of their afternoon q a session and the\n",
            "official shareholder meeting they are taking the stage uh right now as you can see and we go there live morning good\n",
            "morning and thanks for coming I love it Charlie loves it we're glad to\n",
            "have you here we're going to make this this uh\n",
            "preliminary before the question is very short because we want to get in at least\n",
            "60 Questions half divided by the the audience outside this\n",
            "Arena and half from you so I would just\n",
            "like to get right to the to the directors and the earnings that\n",
            "have been put up on the uh on our webpage this morning but we'll\n",
            "cover those very fast and we'll get to the questions now I\n",
            "when I woke up this morning I realized that\n",
            "we had a competitive broadcast going out\n",
            "uh somewhere in the UK and and\n",
            "they were they were celebrating a King Charles and we've got our own\n",
            "King Charles here today [Applause]\n",
            "and next to him we have Greg Abel we was in charge of all the\n",
            "operations except for insurance next\n",
            "[Applause] [Music] [Applause]\n",
            "and next to Greg we have uh a man I ran into a 1986 and\n",
            "has made us look good ever since we have the man in charge of insurance Ajit Jane Jaden\n",
            "and now we have our our directors here in front and if they would just stand briefly and then I'll go on\n",
            "to the next one and and uh they're all here today first of all\n",
            "doing alphabetically there's Howard Buffett\n",
            "there's Suzy Buffett\n",
            "there's Steve Burke\n",
            "Ken Chenal\n",
            "Chris Davis\n",
            "Sue Decker Charlotte Diamond\n",
            "Tom Murphy Jr Ron Olsen\n",
            "Wally Weiss and Merle Whitburn\n",
            "that's as good as you can get and there's one other person I would like to mention before we\n",
            "get onto the earnings that were put on the uh in the press release this morning and\n",
            "uh uh that's uh uh\n",
            "well let's see who we have here we've got this is hard to believe\n",
            "can you imagine a name Melissa Shapiro Shapiro\n",
            "and she was uh Melissa Shapiro Joseph married another Shapiro and she put this\n",
            "whole thing together with no help from me no help from Charlie and a lot of\n",
            "help from the people of the other room Melissa\n",
            "yeah it's very easy if you can remember her second name you can remember her third name so Melissa shabiro Shapiro\n",
            "and with that I would like to next move on to the\n",
            "earnings and a couple small slides that that explain what\n",
            "we're all about and then we're going to get to the Q a and uh the slide is up behind me yeah there it\n",
            "is we reported in the first quarter\n",
            "operating earnings a little over 8 billion and when we talk about operating\n",
            "earnings we're basically referring to the earnings\n",
            "of Berkshire Hathaway as generally well as required under gaap excluding however\n",
            "capital gains both realized and unrealized there's a few other very minor items but basically\n",
            "we expect to make capital gains over time why would we own the stocks otherwise uh doesn't always work out but\n",
            "overall it works out pretty well over time but in any day any quarter any year\n",
            "even occasionally over a five-year period uh the stock prices move around\n",
            "capriciously now we own a lot of other businesses we consider those stocks businesses we own a lot of other\n",
            "businesses where they get Consolidated and they don't move around in value now if we had a little bit of Burlington\n",
            "stock outstanding if we had a little bit of the energy stock trading those stocks\n",
            "would move around a lot but the businesses are what count so the\n",
            "operating earnings as you'll see in the first quarter came in at about 8 billion\n",
            "and I would say that in the general economy\n",
            "the feedback we get is that uh I would say perhaps the majority of our\n",
            "businesses will actually report lower earnings this year\n",
            "than last year the in various degrees in the last six months or so at various times\n",
            "uh the the businesses have left the incredible\n",
            "period which is about as extraordinaries I've seen in business since World War II\n",
            "uh with the government would pour out a lot of money to people who couldn't get\n",
            "Goods it was more extreme in World War II but this was extreme this time and it was just a question\n",
            "of getting Goods the deliverer and people bought and they didn't wait for sales and if\n",
            "you couldn't sell them one thing they would put another thing in their backlog it was an extraordinary period and that\n",
            "period uh has ended it hasn't ended with as you\n",
            "know it isn't that employment's fault or off a cliff or anything in the least but\n",
            "but uh it is a different climate than it was six months ago and and a\n",
            "number of our managers uh were surprised some of them had too much inventory on order and then all of\n",
            "a sudden it got delivered and people weren't in the same frame of mind as earli...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...er\n",
            "and now we'll start having sales at places where we didn't need to have sales before but\n",
            "uh despite the fact that this year I think in general will\n",
            "be slower than last year we actually are\n",
            "situated so that I would expect and believe me when I say accept expect\n",
            "it's nothing is sure nothing sure tomorrow nothing sure next year and nothing is\n",
            "ever sure either in markets or in business forecasts or anything else and we don't\n",
            "pay much attention to markets or forecasts unless the markets happen to offer something interesting to do but\n",
            "nevertheless we are positioned in two respects as you'll see from from this uh first report our investment\n",
            "income is going to be a lot larger uh this year than last year and that's\n",
            "that's built in I mean we have as you'll see in a minute we've had 125\n",
            "billion or so and very short term investments and\n",
            "and believe it or not uh not that long ago\n",
            "we were getting four basis points which is next to nothing\n",
            "on that 100 125 billion which means we were getting 50 million a year\n",
            "and now the same money the other just day or day before yesterday we\n",
            "actually bought because of some of the funny twist in the market because of doubts about the\n",
            "deficit ceiling of the debt ceiling uh we bought three billion of bills of the\n",
            "590 that's 5.9 there's a 5.92 bond\n",
            "equivalent yield so we will have what produced us not that\n",
            "long ago on a 12-month basis was producing 50 million a year producing uh something in the area of 5 billion\n",
            "here so we're in a position where the investment income is essentially well it\n",
            "is certain to increase quite a bit and insurance underwriting\n",
            "is not it uh it does not correlate\n",
            "with business activity it depends on things like hurricanes and earthquakes\n",
            "and and other events so on a prospective basis on a probability\n",
            "basis we're likely to have a a better year\n",
            "uh this year in Insurance underwriting than we had last year uh it just isn't\n",
            "affected by what you might call the business cycle or uh what applies to generally an\n",
            "industry detailing you name it uh so I would expect\n",
            "and one massive earthquake or one one hurricane that came into just\n",
            "the wrong place uh would can affect that prediction but on a\n",
            "probabilistic basis our insurance looks better this year so if you get two of those\n",
            "two of the elements there of our main office of earnings that look like they\n",
            "will swing in our Direction I would expect but I can't promise that our operating and earnings will be\n",
            "greater than last year and if we'll move to\n",
            "the second slide uh I give you those operating earnings\n",
            "figures just to give you a overview of what has happened\n",
            "uh since the pandemic started and off of the year\n",
            "the yearbook before as a base and we retain all our earnings as you know\n",
            "so if we're retaining 30 or 35 billion or whatever but maybe a year you should\n",
            "expect more operating earnings over time I mean this this number should be\n",
            "significantly higher five or ten or fifteen years from now because we have the advantage of retaining earnings and\n",
            "that's what got us to these figures because they were essentially nothing when we started and they got there by\n",
            "retaining earnings and we'll keep retaining earnings so it's no great Triumph if these numbers move up and\n",
            "what we hope is that they move up at a reasonable rate historically\n",
            "they moved up at an unreasonable rate sometimes but we're working with a much smaller sums then and that can't be\n",
            "repeated with our present Capital base because I note there I believe it's on this slide let's take\n",
            "a look uh now that'll be\n",
            "see it's on the while on the on the next on the next\n",
            "place paid and let's move to the next slide we showed that we had on March 31st\n",
            "now 500 and was it five hundred and four billion\n",
            "of Gap net worth now what might surprise you\n",
            "is that there's no other company in the United States no other company that has a number\n",
            "that is that large now that isn't because we've got the most valuable\n",
            "company in the United States other companies have used their money to repurchase\n",
            "shares they could have accumulated 504 billion in gap but basically we have more\n",
            "under Gap accounting now than any other company in the U.S and of course if you\n",
            "measure return on on Equity that becomes a very big number to increase\n",
            "at a rapid rate but we hope to do so uh not a rapid rate additional rate\n",
            "um and right below that you see something called float\n",
            "and float is money that uh is left in our hands\n",
            "uh somewhat Akin but very importantly different\n",
            "than a bank deposit but it uh you have to pay interest to get a bank deposit and you have to pay more\n",
            "interest these days and you have to run a bank and do a lot of things and basically this is money that represents\n",
            "unpaid losses at this time you get paid in advance in insurance so what shows up\n",
            "as a net liability on our balance sheet is gives us funds uh\n",
            "do exercise with an amount of discretion that no other insurance company that I know of in the\n",
            "world enjoys just because we have so much net worth and our float now\n",
            "comes to 165 billion and the man sitting on the far left is\n",
            "responsible for moving that number up from a pittance in 1986\n",
            "to this incredible figure which in most years practically all years\n",
            "hasn't cost us anything so it's like having a bank with no employees no\n",
            "interest and no ability to withdraw the money in\n",
            "a hurry that we have working for us and it's a\n",
            "very valuable asset that uh that shows up as a liability and uh\n",
            "Ajit is responsible for building up this\n",
            "treasure uh which has done been done by out competing insurance companies all over\n",
            "the world and then now a number of our insurance companies in turn are run by talented managers\n",
            "who contributed one way or another uh start with Geico\n",
            "the beginning of my career and the uh that float if you think about it just\n",
            "think of a balance sheet you've got liabilities here and you got assets over here and and the liability side finances\n",
            "the asset side is very simple and stockholders Equity finances it\n",
            "long-term debt finances and so on but stockholders Equity is very expensive in\n",
            "a real sense long-term debt has been cheap for a while but it can get expensive and it\n",
            "can also become new eventually and it and it may not be available\n",
            "uh but float is another item which shows it's a\n",
            "liability but hasn't cost us anything and it it can't disappear in a hurry and\n",
            "it finances the asset side in the same way a stockholders equity\n",
            "and nobody else thinks of it much that way but but we've always thought of it that way and it's built up over time so\n",
            "uh I show at the bottom what's happened with cash and treasury bills\n",
            "through March 31st and I will tell you that the in the month of April\n",
            "we probably added about seven billion dollars to that\n",
            "factor now part of that is because we didn't buy as much stock because that reduces reduces cash and treasury bills\n",
            "we bought about 400 million dollars worth of stock in the month of April that's that's a minus uh in terms of\n",
            "cash available and uh uh we we however sold not some stock\n",
            "which produced maybe four billion and of course we had operating earnings probably two and a half\n",
            "billion or something in that area and my guess is we've probably increased our cash and treasury bills uh six and seven\n",
            "billion in the month and uh I just want to give you a feel for how the cash\n",
            "flows at Berkshire and then if we move to the final I think it's the final one next to the last one uh\n",
            "no I I think it is a lot let's see it's the fourth yeah is this we should have the one up\n",
            "there class a equivalent shares outstanding and and uh you'll notice that every year\n",
            "the number of our shares go down so if we own more businesses and the businesses make more money\n",
            "your chair as shareholders as owners a Berkshire increases every year without\n",
            "you laying out any money now you're laying out the uh the\n",
            "alternative which you could receive in dividends but the reason we've gotten to\n",
            "where we are is because we we kept the money we did pay a dividend\n",
            "in 19. 67 10 cents to share it was a terrible mistake and uh I\n",
            "I always tell people that I I'd love for the men's room and the...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "Tokens generated: 26.25\n",
            "Total Time Taken: 2.93 seconds\n",
            "Tokens per Second: 8.95\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Ajit\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Gap\",\n",
            "        \"Berkshire\"\n",
            "    ]\n",
            "}\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "... directors voted while he's gone but that isn't true I\n",
            "was there I confessed they uh but we're very invested and has produced the\n",
            "500 billion plus of shareholders equity in the 30 billion plus of operating\n",
            "earnings and and we'll continue to follow that policy because it makes a great deal of sense and uh\n",
            "with that I think we've taken care of the preliminaries you can study that\n",
            "the 10q is is on the uh on the uh web page and if you have a\n",
            "week or two vacation you could spend it reading the 10q and but that is the\n",
            "essence of Berkshire and with that I will start with Becky quick and and uh we\n",
            "will alternate between Becky and and the audience and her questions have come in\n",
            "from all over the country and I believe you identified the sender and go to it Becky thanks Warren the first question\n",
            "comes in from Randy Jeffs in Irvine California and his question is if Silicon Valley Bank's deposit had not\n",
            "been fully covered what do you think the economic consequences would have been to the nation\n",
            "simply say it would have been catastrophic and that's why they were covered uh and\n",
            "even though the FDIC limiters two hundred and fifty thousand dollars that that's the way the statute reads\n",
            "but that is not the way the us is going to behave uh any more than they're going to let\n",
            "the debt ceiling uh uh cause the world to go into turmoil and uh they\n",
            "uh well they're just I can't imagine\n",
            "anybody in the administration and the Congress and the Federal Reserve whatever it may\n",
            "have been FDIC I can't imagine anybody's saying uh I'd like to be the one on\n",
            "television tomorrow and explain the American public why we're keeping uh\n",
            "uh only two hundred and fifty thousand dollars insured and we're gonna start around every Bank in the country and\n",
            "disrupt the world financial system uh so uh I think it was inevitable Charlie The\n",
            "Amity no I have nothing to add\n",
            "apparently I should mention this now ajeet and Greg will be here in the\n",
            "morning session which ends at noon and so uh it's got questions to direct to\n",
            "them the time to do it is in the first half of the show and and then after lunch\n",
            "that'll just Charlie and I will be back okay\n",
            "area one hi nirav Patel Haverhill Massachusetts\n",
            "Mr Buffett Mr Monger it seems like you found the Sweet Spot between being too\n",
            "conservative and too aggressive as investors do you ever make bad investment\n",
            "decisions because of your emotions and what do you do to try to keep that from\n",
            "happening well we make\n",
            "bad investment decisions uh plenty of times I make more than Charlie\n",
            "because I'm I like to think it's because I make more decisions but probably more batting average is worse but\n",
            "I can't recall anytime\n",
            "in the history of Berkshire the women in an emotional decision that\n",
            "I know the movie had Jamie Lee in there but that that was for Laughs\n",
            "I mean Jamie Jamie Lee she's good but she's not\n",
            "good enough to get me or Charlie to make an emotional decision\n",
            "laughs Charlie\n",
            "I'm sure you have something to add on that\n",
            "well it's a different movie than it is shown in most corporate meetings [Laughter]\n",
            "personal decision no I don't know that's in business we're talking about\n",
            "yeah no you don't want to be a no emotion person in all of your life but you you definitely want to be a no more\n",
            "no emotion person to making an investment or business decision that uh you can argue that that uh uh\n",
            "with it we probably I would say that we\n",
            "'ve made an emotional decision perhaps and when a manager has been with us for\n",
            "some period and we haven't we've\n",
            "we we've ignored the fact that perhaps they weren't quite what\n",
            "they were earlier but our businesses are so good that they they've run better sometimes\n",
            "uh when uh well I've talked about\n",
            "West Coast for example the wonderful Louisville it ran on\n",
            "it ran on automatic pilot for a while but I don't think we suffered to buy it but you can argue\n",
            "that if Charlie and I hadn't liked Louie as much as we did we might have spotted\n",
            "a little bit early but I don't think it made any difference in the results would you would you agree with that Charlie\n",
            "yeah yeah we totally with it and\n",
            "I'm glad we behaved the way we did it Wesco by the way we bought the thing for\n",
            "a few tens of millions and it became worth two or three billion\n",
            "yeah that wasn't common in the Savings and Loan businesses you may have noticed they want they really went crazy in that\n",
            "industry and and we had a wonderful guy in Louis and we didn't go crazy yeah we didn't go crazy\n",
            "dumb okay Becky\n",
            "this question comes from Ben Knoll in Minneapolis he says he's a Berkshire shareholder of three decades and he's\n",
            "attended many Berkshire meetings he's here again this year and this is addressed to Ajit and Greg he says last\n",
            "year I asked you about how Geico and BNSF appeared to lose ground to their leading competitors Geico on telematics\n",
            "and BNSF on Precision scheduled railroading Ajit you responded by saying how you expected Geico to make progress\n",
            "in a year or two Greg you spoke about your pride in BNSF but you didn't directly address the threat of precision\n",
            "scheduled railroading will each of you please provide perspective on these competitive challenges and our company's\n",
            "strategies to address them let me\n",
            "in terms of Geico and telematics let me make the observation that Geico has\n",
            "certainly taken the ball by the horns and has made rapid strides in terms of trying to bridge the gap\n",
            "in terms of telematics and its competitors they have now reached a point where on\n",
            "all new business close to 90 percent is has a telematics input to to the\n",
            "pricing decision unfortunately less than half of that is being taken up by the policyholders the\n",
            "other point I want to make is even though we have made improvements in in terms of Bridging the Gap on telematics\n",
            "we still haven't started to realize the true benefit and the real culprit or the\n",
            "bottleneck is technology Geico's technology needs a lot more work than I thought it did\n",
            "it has more than 500 actually more than 600 Legacy systems that don't really talk to each other and we're trying to\n",
            "compress them to no more than 15 16 systems that all talk to each other\n",
            "that's a Monumental Challenge and because of that even though we have made improvements in telematics we still have\n",
            "a long way to go because of Technology [Music]\n",
            "because of that and because of the whole issue more broadly in terms of matching rate to risk Geico is still work in\n",
            "progress I don't know if you any of you had a chance to look at the first quarter results but Geico has had a very\n",
            "good first quarter coming in at a combined ratio of 93 and change which means a margin of six and change\n",
            "uh even though that's very good it's not something we can take to the bank because they're two unusual items that\n",
            "contributed to it firstly we've had what is called prior year Reserve releases\n",
            "we've reduced results for the previous years and that contributed to it and secondly every year the first quarter\n",
            "tends to be a seasonally good quote of auto insurance writers\n",
            "so if you just for those two factors my guess is the end of the year Geico will end up with a combined ratio just south\n",
            "of 100 as opposed to the Target they're shooting for 96.\n",
            "I hope they reached the target of 96 by the end of next year\n",
            "and but instead of getting too excited about it I think it's important to realize that even if we reach 96 it will\n",
            "come at the expense of having lost policy holder there is a trade-off between\n",
            "profitability and growth and clearly we have we're going to emphasize\n",
            "profitability and not growth and that will come at the expense of policyholder so it will not be until two years from\n",
            "now that we'll be back on track fighting the battles on both the profitability and growth front\n",
            "Greg yep moving to BNSF\n",
            "I'll start again by expressing great pride in the BNSF team we have an exceptional group of led by Katie and\n",
            "and her managers that uh show up every day to do great work on on the railroad\n",
            "at the same time they would be the first to acknowledge there's more to be done there uh the specific reference to\n",
            "Precision scheduled railroading the other large railroad Class A uh\n",
            "r...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "Tokens generated: 62.00\n",
            "Total Time Taken: 5.49 seconds\n",
            "Tokens per Second: 11.29\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Judd\",\n",
            "        \"Laura Zaberski\",\n",
            "        \"Warren Buffett\",\n",
            "        \"Charlie Munger\",\n",
            "        \"Dan Calkins\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Jazz Wares\",\n",
            "        \"Benjamin Moore\",\n",
            "        \"Berkshire Hathaway\"\n",
            "    ]\n",
            "}\n",
            "<s>GPT4 Correct User: Extract names and organizations from the provided text, and return them in JSON format. Use the following schema:\n",
            "\n",
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"names\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        },\n",
            "        \"organisations\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "                \"type\": \"string\"\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"names\",\n",
            "        \"organisations\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Here's an example of a response in JSON format:\n",
            "\n",
            "{\n",
            "    \"names\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"sample_string_1\",\n",
            "        \"sample_string_2\"\n",
            "    ]\n",
            "}\n",
            "\n",
            "Do not include anything that is not explicitly mentioned in the text. Analyse the text carefully to ensure all requested data is extracted. Include each name and organization only once. Adhere strictly to the response format without adding extra spaces or text.\n",
            "\n",
            "[TEXT_START]\n",
            "\n",
            "...ailroads in the in the U.S follow that and including the two in Canada we're\n",
            "well aware of what they're doing and and obviously pay close attention to their\n",
            "operating Matrix and our team strives every day to be more efficient obviously I would say we balance it with the needs\n",
            "of our customers if I look back to pre-2022 so we look at the three-year\n",
            "period of 2019 2020 2021 the BNSF team\n",
            "made significant progress on their efficiencies and and and delivering\n",
            "overall value back to the shareholders and and to their customers and at the same time maintaining a very safe\n",
            "railroad for our employees so we're making excellent progress that didn't stop last year they made great progress\n",
            "again the reality in 2022 as we did go through a period of time where we had to\n",
            "call it reset the railroad we came out of the pandemic there were the supply challenges we had certain other issue\n",
            "labor issues and other things going on at the port and the reality is our team prioritized getting the railroad back in\n",
            "place for the long term not a short-term focus on hitting certain operating metrics in in\n",
            "2022 we're well aware of where we were relative to those metrics but the real Focus was to get the railroad reset in a\n",
            "in a safe manner such that we could deliver long-term value and long-term service to our customers and and that's\n",
            "really what we'll continue to see with that team they'll be continual progress there'll be years where it's not as\n",
            "quickly or even we go backwards but over the long term we'll be very uh we'll see\n",
            "exceptional results from from that team and and couldn't be more proud that we have that asset thank you\n",
            "I wouldn't I would just [Applause] well he deserves but both of them\n",
            "deserve Applause the I would like to add one thing [Applause]\n",
            "[Music] [Applause] the\n",
            "uh at Geico .com's uh\n",
            "was ajith's Choice my choice go back to guy at Geico\n",
            "to work on the problem of matching rate to risk which is what\n",
            "insurance is all about and uh he arrived\n",
            "with exquisite timing right before the pandemic broke out all kinds of things changed but Todd is\n",
            "doing a wonderful job at Geico and uh and he\n",
            "works closely uh with the Jeep but because he saw his home and all Morgan comes back\n",
            "here and we we get together on the weekend sometimes too so uh uh that's been a\n",
            "a remarkable com accomplishment under difficult circumstances and he's not all the way home but he's a he's made a very\n",
            "very big change uh in multiple ways Geico and then one\n",
            "other thing I would like to mention there have been a lot of public companies created in the last decade\n",
            "thereabouts in insurance and uh there's none of them\n",
            "that we would like to own and and they always started out in their perspective saying this is\n",
            "a tech company not an insurance company of course we're of course they're in a tech company where everybody's\n",
            "whether they're in insurance or a lot of other places are using the facility but\n",
            "you still have to properly match rate to risk and uh uh that they invariably have\n",
            "reported the huge losses they've eaten up capital but there's been one company that nobody\n",
            "has generally heard of there's only been one that I know of company started in the last 10 years\n",
            "that has been a overwhelming success and that's a company that a g\n",
            "and four people who join with them set to develop a new business\n",
            "it's called Berkshire Hathaway specialty it now has uh what's the float a g coming up to 12\n",
            "billion yeah we've we've built more slope than probably all these companies combined\n",
            "we've now it it's cost us essentially nothing in terms of an underwriting loss\n",
            "the four people have turned in I don't know 1500 around the world we we took on the whole industry and we brought\n",
            "some unique how and the four people that came and\n",
            "now have like I said 1500 or so worldwide and we brought capital and we\n",
            "brought okay capabilities that really only Berkshire\n",
            "could Supply so it was the it was the combination of of...\n",
            "\n",
            "[TEXT_END]\n",
            "\n",
            "Now, answer immediately and only in json format.<|end_of_turn|>GPT4 Correct Assistant:\n",
            "Tokens generated: 92.75\n",
            "Total Time Taken: 5.65 seconds\n",
            "Tokens per Second: 16.43\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Buffett\",\n",
            "        \"Munger\",\n",
            "        \"Greg Abel\",\n",
            "        \"Ajit Jane\",\n",
            "        \"Ron Olson\",\n",
            "        \"Howard Buffett\",\n",
            "        \"Ann widblad\",\n",
            "        \"Bobby kodek\",\n",
            "        \"John Rogers\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Berkshire\",\n",
            "        \"Activision Blizzard\",\n",
            "        \"Apple\",\n",
            "        \"Paramount Global\",\n",
            "        \"Northern Trust\"\n",
            "    ]\n",
            "}\n",
            "Tokens generated: 51.25\n",
            "Total Time Taken: 2.94 seconds\n",
            "Tokens per Second: 17.44\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Randy Jeffs\",\n",
            "        \"Nirav Patel\",\n",
            "        \"Ben Knoll\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Silicon Valley Bank\",\n",
            "        \"Berkshire\",\n",
            "        \"Geico\",\n",
            "        \"BNSF\"\n",
            "    ]\n",
            "}\n",
            "Tokens generated: 76.00\n",
            "Total Time Taken: 5.95 seconds\n",
            "Tokens per Second: 12.77\n",
            " {\n",
            "    \"names\": [\n",
            "        \"John Rogers\",\n",
            "        \"Warren Buffett\",\n",
            "        \"Charlie Munger\",\n",
            "        \"Judd Zaberski\",\n",
            "        \"Laura Zaberski\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Aerial Investments\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Allegheny\",\n",
            "        \"Jazz Wares\",\n",
            "        \"Kelly Toys\"\n",
            "    ]\n",
            "}\n",
            "Tokens generated: 139.00\n",
            "Total Time Taken: 6.80 seconds\n",
            "Tokens per Second: 20.43\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Becky\",\n",
            "        \"Mike Santoli\",\n",
            "        \"Warren Buffett\",\n",
            "        \"Charlie Munger\",\n",
            "        \"Greg Abel\",\n",
            "        \"Ajit Jain\",\n",
            "        \"Debbie Pasonic\",\n",
            "        \"Bill Murray\",\n",
            "        \"Jane Frazier\",\n",
            "        \"Ruth Porat\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Apple\",\n",
            "        \"Berkshire's shareholders\",\n",
            "        \"Alphabet\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Alphabet\"\n",
            "    ]\n",
            "}\n",
            "Tokens generated: 49.75\n",
            "Total Time Taken: 1.57 seconds\n",
            "Tokens per Second: 31.72\n",
            " {\n",
            "    \"names\": [\n",
            "        \"BNSF\",\n",
            "        \"Geico\",\n",
            "        \"Berkshire Hathaway specialty\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"BNSF\",\n",
            "        \"Geico\",\n",
            "        \"Berkshire Hathaway specialty\"\n",
            "    ]\n",
            "}\n",
            "Tokens generated: 154.50\n",
            "Total Time Taken: 7.11 seconds\n",
            "Tokens per Second: 21.73\n",
            " {\n",
            "    \"names\": [\n",
            "        \"Mike\",\n",
            "        \"David Modematan\",\n",
            "        \"Warren Buffett\",\n",
            "        \"Charlie Munger\",\n",
            "        \"Howard Buffett\",\n",
            "        \"Suzy Buffett\",\n",
            "        \"Steve Burke\",\n",
            "        \"Ken Chenault\",\n",
            "        \"Chris Davis\",\n",
            "        \"Sue Decker\",\n",
            "        \"Charlotte Diamond\",\n",
            "        \"Tom Murphy Jr\",\n",
            "        \"Ron Olsen\",\n",
            "        \"Wally Weiss\",\n",
            "        \"Merle Whitburn\",\n",
            "        \"Melissa Shapiro Shapiro\"\n",
            "    ],\n",
            "    \"organisations\": [\n",
            "        \"Insurance\",\n",
            "        \"Berkshire Hathaway\",\n",
            "        \"Evercore\",\n",
            "        \"Travelers\",\n",
            "        \"Progressive\",\n",
            "        \"Chubb\",\n",
            "        \"Geico\",\n",
            "        \"Allstate\"\n",
            "    ]\n",
            "}\n",
            "Total number of requests: 8\n",
            "Aggregation complete! The aggregated data has been written to '/content/drive/My Drive/data_extraction/outputs/output.json'.\n",
            "Error rate is 0.0\n"
          ]
        }
      ],
      "source": [
        "import concurrent.futures\n",
        "\n",
        "# Define a function to send a request\n",
        "def send_request(message):\n",
        "    chat_response = chat_completion_request_runpod([message])\n",
        "    return chat_response, message\n",
        "\n",
        "\n",
        "# Define a function to process the chat response\n",
        "def process_chat_response(chat_response, output_format):\n",
        "    try:\n",
        "        chat_response_dict = (\n",
        "            json.loads(chat_response)\n",
        "            if output_format == \"json\"\n",
        "            else yaml.safe_load(chat_response.strip())\n",
        "        )\n",
        "        aggregator.aggregate_json(\n",
        "            chat_response_dict\n",
        "        ) if output_format == \"json\" else aggregator.aggregate_yaml(chat_response_dict)\n",
        "    except (json.JSONDecodeError, yaml.YAMLError):\n",
        "        print(f\"Invalid {output_format.upper()} in chat response: {chat_response}\")\n",
        "        aggregator.fail += 1\n",
        "\n",
        "\n",
        "# Create messages\n",
        "message_lists = [\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"{prompt}\\n\\n[TEXT_START]\\n\\n...{text[i : i + block_size]}...\\n\\n[TEXT_END]\\n\\nNow, answer immediately and only in {config.output_format} format.\"\"\",\n",
        "        }\n",
        "    ]\n",
        "    for i in range(0, len(text), block_size)\n",
        "]\n",
        "\n",
        "if config.batching:\n",
        "    # Initialize a counter\n",
        "    request_counter = 0\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Send the requests in parallel\n",
        "        future_to_chat_response = {\n",
        "            executor.submit(send_request, messages[0]): messages for messages in message_lists\n",
        "        }\n",
        "\n",
        "        for future in concurrent.futures.as_completed(future_to_chat_response):\n",
        "            messages = future_to_chat_response[future]\n",
        "            try:\n",
        "                chat_response, _ = future.result()\n",
        "            except Exception as exc:\n",
        "                print(f\"{messages[0]} generated an exception: {exc}\")\n",
        "            else:\n",
        "                # Increment the counter\n",
        "                request_counter += 1\n",
        "\n",
        "                # Process the chat response\n",
        "                process_chat_response(chat_response, config.output_format)\n",
        "\n",
        "    print(f\"Total number of requests: {request_counter}\")\n",
        "\n",
        "else:\n",
        "    for messages in tqdm(message_lists):\n",
        "        chat_response = chat_completion_request_runpod(messages)\n",
        "\n",
        "        # Process the chat response\n",
        "        process_chat_response(chat_response, config.output_format)\n",
        "\n",
        "# Write the aggregated data to a file\n",
        "aggregator.write_aggregated_data(f\"{project_dir+output_dir}/{config.output_file_name}\")\n",
        "if not aggregator.success:\n",
        "    print(\"All validations failed\")\n",
        "else:\n",
        "    total_attempts = aggregator.success + aggregator.fail\n",
        "    if total_attempts > 0:\n",
        "        error_rate = aggregator.fail / total_attempts\n",
        "        print(f\"Error rate is {error_rate}\")\n",
        "    else:\n",
        "        print(\"No attempts were made, so the error rate cannot be calculated.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
