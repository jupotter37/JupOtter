{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "1. whale_returns.csv\n",
    "2. algo_returns.csv\n",
    "3. sp500_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns\n",
    "whale_returns_csv = Path(\"Resources/whale_returns.csv\")\n",
    "# YOUR CODE HERE\n",
    "whale_df = pd.read_csv(whale_returns_csv, index_col=\"Date\", parse_dates=True)\n",
    "whale_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "whale_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "whale_df.dropna(inplace=True)\n",
    "whale_df.isnull().sum()\n",
    "# whale_df.head() to double check if dropped first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns \n",
    "algo_returns_csv = Path(\"Resources/algo_returns.csv\")\n",
    "# YOUR CODE HERE\n",
    "algo_df = pd.read_csv(algo_returns_csv,index_col=\"Date\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "algo_df.dropna(inplace=True)\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P500 Historic Closing Prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "sp500_history_csv = Path(\"Resources/sp500_history.csv\")\n",
    "# YOUR CODE HERE\n",
    "sp500_df = pd.read_csv(sp500_history_csv, index_col=\"Date\", parse_dates=True)\n",
    "sp500_df = sp500_df.sort_index(ascending=True)\n",
    "sp500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "# YOUR CODE HERE\n",
    "sp500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix data type and get rid of $\n",
    "sp500_df[\"Close\"] = sp500_df[\"Close\"].str.replace('$','')\n",
    "sp500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_df.dtypes\n",
    "sp500_df[\"Close\"] = sp500_df[\"Close\"].astype(float)\n",
    "sp500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "# YOUR CODE HERE\n",
    "\n",
    "sp_daily = sp500_df.pct_change()\n",
    "sp_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "sp_daily.isnull().sum()\n",
    "sp_daily.dropna(inplace=True)\n",
    "sp_daily.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column\n",
    "# YOUR CODE HERE\n",
    "\n",
    "sp_daily.columns = [\"SP 500\"]\n",
    "\n",
    "sp_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "\n",
    "big_portfolio = pd.concat([algo_df, sp_daily, whale_df], axis=\"columns\", join= \"inner\")\n",
    "big_portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Calculate and Plot the daily returns and cumulative returns. Does any portfolio outperform the S&P 500? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns\n",
    "# YOUR CODE HERE\n",
    "daily_return_plot = big_portfolio.plot(figsize=(20,10))\n",
    "daily_return_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "# YOUR CODE HERE\n",
    "cum_returns = (1 + big_portfolio).cumprod()-1\n",
    "cum_returns.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "# YOUR CODE HERE\n",
    "big_portfolio.boxplot(grid=False, rot=100000000, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Standard Deviations\n",
    "# Calculate the standard deviation for each portfolio. \n",
    "# Which portfolios are riskier than the S&P 500? \n",
    "# The portfolios with higher standard deviations are the most risky\n",
    "# YOUR CODE HERE\n",
    "daily_std_dev = big_portfolio.std()\n",
    "daily_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking of least risky std deviations... #1 being least risky\n",
    "daily_std_dev.rank(method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "# YOUR CODE HERE\n",
    "greater_than_SP500 = daily_std_dev[daily_std_dev>daily_std_dev[\"SP 500\"]]\n",
    "print(greater_than_SP500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "# YOUR CODE HERE\n",
    "annual_std_dev = big_portfolio.std() * np.sqrt(252)\n",
    "annual_std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Plot the rolling standard deviation of the various portfolios along with the rolling standard deviation of the S&P 500 (consider a 21 day window). Does the risk increase for each of the portfolios at the same time risk increases in the S&P?\n",
    "2. Construct a correlation table for the algorithmic, whale, and S&P 500 returns. Which returns most closely mimic the S&P?\n",
    "3. Choose one portfolio and plot a rolling beta between that portfolio's returns and S&P 500 returns. Does the portfolio seem sensitive to movements in the S&P 500?\n",
    "4. An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the ewm with a 21 day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the rolling standard deviation for\n",
    "# the S&P 500 and whale portfolios using a 21 trading day window\n",
    "# YOUR CODE HERE\n",
    "big_portfolio.rolling(window=21).std().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a correlation table\n",
    "# YOUR CODE HERE\n",
    "correlation_table = big_portfolio.corr()\n",
    "correlation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Beta for a single portfolio compared to the total market (S&P 500)\n",
    "# (Your graph may differ, dependent upon which portfolio you are comparing)\n",
    "# YOUR CODE HERE\n",
    "soros_cov = big_portfolio[\"SOROS FUND MANAGEMENT LLC\"].cov(big_portfolio[\"SP 500\"])\n",
    "\n",
    "soros_var = big_portfolio[\"SOROS FUND MANAGEMENT LLC\"].var()\n",
    "\n",
    "soros_beta = soros_cov/ soros_var\n",
    "soros_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soros_rolling_covariance = big_portfolio[\"SOROS FUND MANAGEMENT LLC\"].rolling(window=30).cov(big_portfolio[\"SP 500\"])\n",
    "soros_rolling_variance = big_portfolio[\"SP 500\"].rolling(window=30).var()\n",
    "\n",
    "soros_rolling_beta = soros_rolling_covariance / soros_rolling_variance\n",
    "\n",
    "soros_rolling_beta.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a rolling window using the exponentially weighted moving average. \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. (After all, if you could invest in one of two portfolios, each offered the same 10% return, yet one offered lower risk, you'd take that one, right?)\n",
    "\n",
    "1. Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot.\n",
    "2. Determine whether the algorithmic strategies outperform both the market (S&P 500) and the whales portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized Sharpe Ratios\n",
    "# YOUR CODE HERE\n",
    "sharpe = big_portfolio.mean() / big_portfolio.std() * np.sqrt(252)\n",
    "sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE\n",
    "sharpe.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the basis of this performance metric, do our algo strategies outperform both 'the market' and the whales? Type your answer here: Algo 1 does for sure. Algo 2 is better than every whale except for Berk, and worse than SP500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Returns\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Visit [Google Sheets](https://docs.google.com/spreadsheets/) and use the in-built Google Finance function to choose 3-5 stocks for your own portfolio.\n",
    "2. Download the data as CSV files and calculate the portfolio returns.\n",
    "3. Calculate the returns for each stock.\n",
    "4. Using those returns, calculate the weighted returns for your entire portfolio assuming an equal number of shares for each stock.\n",
    "5. Add your portfolio returns to the DataFrame with the other portfolios and rerun the analysis. How does your portfolio fair?\n",
    "\n",
    "\n",
    "## Your analysis should include the following:\n",
    "\n",
    "- Using all portfolios:\n",
    " - The annualized standard deviation (252 trading days) for all portfolios.\n",
    " - The plotted rolling standard deviation using a 21 trading day window for all portfolios.\n",
    " - The calculated annualized Sharpe Ratios and the accompanying bar plot visualization.\n",
    " - A correlation table.\n",
    "- Using your custom portfolio and one other of your choosing:\n",
    " - The plotted beta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first stock\n",
    "# YOUR CODE HERE\n",
    "\n",
    "aapl_historical = (\"Resources/aapl_historical.csv\")\n",
    "aapl_df = pd.read_csv(aapl_historical, index_col=\"Trade DATE\", parse_dates=True)\n",
    "aapl_df = aapl_df.sort_index()\n",
    "aapl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the second stock\n",
    "# YOUR CODE HERE\n",
    "cost_historical = (\"Resources/cost_historical.csv\")\n",
    "cost_df = pd.read_csv(cost_historical, index_col=\"Trade DATE\", parse_dates=True)\n",
    "cost_df = cost_df.sort_index()\n",
    "cost_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the third stock\n",
    "# YOUR CODE HERE\n",
    "\n",
    "goog_historical = (\"Resources/goog_historical.csv\")\n",
    "goog_df = pd.read_csv(goog_historical, index_col=\"Trade DATE\", parse_dates=True)\n",
    "goog_df = goog_df.sort_index()\n",
    "goog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all stocks into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "my_portfolio = pd.concat([goog_df, aapl_df, cost_df], axis=\"rows\",join=\"inner\")\n",
    "\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "# YOUR CODE HERE\n",
    "# not sure why i need to reset index, so i didn't\n",
    "my_portfolio=my_portfolio.reset_index()\n",
    "my_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot so that each column of prices represents a unique symbol\n",
    "# YOUR CODE HERE\n",
    "Overstock=my_portfolio.pivot_table(values=\"NOCP\",index=\"Trade DATE\",columns=\"Symbol\")\n",
    "Overstock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls\n",
    "# YOUR CODE HERE\n",
    "my_portfolio.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted portfolio returns\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "# YOUR CODE HERE\n",
    "my_returns = my_portfolio.pct_change()\n",
    "my_returns.head()\n",
    "my_returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your \"Custom\" portfolio to the larger dataframe of fund returns\n",
    "# YOUR CODE HERE\n",
    "megafolio = pd.concat([my_returns, big_portfolio], axis=\"columns\", join=\"inner\")\n",
    "megafolio.dropna()\n",
    "\n",
    "columns = [\"goog\", \"aapl\", \"cost\",\"Algo 1\", \"Algo 2\", \"SP 500\", \"SOROS FUND MANAGEMENT LLC\", \"PAULSON & CO.INC.\", \"TIGER GLOBAL MANAGEMENT LLC\", \"BERKSHIRE HATHAWAY INC\"]\n",
    "megafolio.columns = columns\n",
    "megafolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the performance and risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk\n",
    "# YOUR CODE HERE\n",
    "risk = megafolio.std()\n",
    "risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling\n",
    "# YOUR CODE HERE\n",
    "megafolio.rolling(window=21).std().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "# YOUR CODE HERE\n",
    "sharpe1 = megafolio.mean() / megafolio.std() * np.sqrt(252)\n",
    "sharpe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE\n",
    "sharpe1.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation analysis\n",
    "# YOUR CODE HERE\n",
    "correlation_table1 = megafolio.corr()\n",
    "correlation_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta\n",
    "# YOUR CODE HERE\n",
    "mega_cov = megafolio.cov()\n",
    "\n",
    "mega_var = megafolio.var()\n",
    "\n",
    "mega_beta = mega_cov/ mega_var\n",
    "mega_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
