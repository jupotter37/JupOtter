{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcab14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, display_html, Math, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "088da526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-11-25'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d1a05",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d2e24",
   "metadata": {},
   "source": [
    "Our team has chosen to target the safest portfolio. This means that our algorithm will choose the optimal weighting for the portfolio so that the final portfolio value is as close as possible to the initial investment, which in this case is $750,000. \n",
    "\n",
    "There are three main concepts our algorithm utilizes to ensure the least risk: beta, volatility, and gradient descent. We will filter out any stocks with a large beta, calculate the volatility of each individual stock, and use gradient descent to arrive upon the optimal portfolio weighting for each of the stocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc1999b",
   "metadata": {},
   "source": [
    "### Reading and Cleaning CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0da503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:633: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"High\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:634: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"High\"] = _np.nanmax([quotes[\"High\"][n - 1], quotes[\"High\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:638: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"Low\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Low\"] = _np.nanmin([quotes[\"Low\"][n - 1], quotes[\"Low\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:643: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Close\"] = quotes[\"Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:645: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Adj Close\"] = quotes[\"Adj Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:646: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Volume\"] += quotes[\"Volume\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:633: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"High\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:634: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"High\"] = _np.nanmax([quotes[\"High\"][n - 1], quotes[\"High\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:638: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"Low\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Low\"] = _np.nanmin([quotes[\"Low\"][n - 1], quotes[\"Low\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:643: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Close\"] = quotes[\"Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:645: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Adj Close\"] = quotes[\"Adj Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:646: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Volume\"] += quotes[\"Volume\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:633: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"High\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:634: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"High\"] = _np.nanmax([quotes[\"High\"][n - 1], quotes[\"High\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:638: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"Low\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Low\"] = _np.nanmin([quotes[\"Low\"][n - 1], quotes[\"Low\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:643: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Close\"] = quotes[\"Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:645: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Adj Close\"] = quotes[\"Adj Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:646: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Volume\"] += quotes[\"Volume\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:633: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"High\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:634: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"High\"] = _np.nanmax([quotes[\"High\"][n - 1], quotes[\"High\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:638: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if not _np.isnan(quotes[\"Low\"][n - 1]):\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Low\"] = _np.nanmin([quotes[\"Low\"][n - 1], quotes[\"Low\"][n - 2]])\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:643: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Close\"] = quotes[\"Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:645: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Adj Close\"] = quotes[\"Adj Close\"][n - 1]\n",
      "C:\\Users\\danie\\anaconda3\\envs\\cfm101\\Lib\\site-packages\\yfinance\\utils.py:646: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  quotes.loc[idx2, \"Volume\"] += quotes[\"Volume\"][n - 1]\n",
      "OIEWRPOIWERPOI: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: oiewrpoiwerpoi Ticker does not reference a valid stock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WEROJWOIEW: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: werojwoiew Ticker does not reference a valid stock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OWEIJR32R: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: oweijr32r Ticker does not reference a valid stock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GGEWOEOE: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: GGEWOEOE Ticker does not reference a valid stock\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>...</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>RY.TO</th>\n",
       "      <th>SHOP.TO</th>\n",
       "      <th>T.TO</th>\n",
       "      <th>TD.TO</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>168.639789</td>\n",
       "      <td>211.621951</td>\n",
       "      <td>145.665501</td>\n",
       "      <td>360.714599</td>\n",
       "      <td>83.711187</td>\n",
       "      <td>116.363342</td>\n",
       "      <td>196.572714</td>\n",
       "      <td>264.929310</td>\n",
       "      <td>44.064212</td>\n",
       "      <td>369.659037</td>\n",
       "      <td>...</td>\n",
       "      <td>141.564543</td>\n",
       "      <td>122.739288</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>25.214359</td>\n",
       "      <td>84.689217</td>\n",
       "      <td>214.563569</td>\n",
       "      <td>692.793878</td>\n",
       "      <td>276.074065</td>\n",
       "      <td>228.572688</td>\n",
       "      <td>57.969780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>171.825505</td>\n",
       "      <td>215.140097</td>\n",
       "      <td>149.087171</td>\n",
       "      <td>362.538234</td>\n",
       "      <td>85.669409</td>\n",
       "      <td>116.421282</td>\n",
       "      <td>202.849765</td>\n",
       "      <td>278.459360</td>\n",
       "      <td>45.273718</td>\n",
       "      <td>370.308284</td>\n",
       "      <td>...</td>\n",
       "      <td>148.532840</td>\n",
       "      <td>123.832169</td>\n",
       "      <td>50.610001</td>\n",
       "      <td>25.520916</td>\n",
       "      <td>85.790451</td>\n",
       "      <td>224.286737</td>\n",
       "      <td>679.626403</td>\n",
       "      <td>280.644095</td>\n",
       "      <td>232.919618</td>\n",
       "      <td>60.282251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>167.653608</td>\n",
       "      <td>211.907272</td>\n",
       "      <td>146.484505</td>\n",
       "      <td>349.084957</td>\n",
       "      <td>84.022266</td>\n",
       "      <td>112.088157</td>\n",
       "      <td>195.258906</td>\n",
       "      <td>276.431078</td>\n",
       "      <td>44.556414</td>\n",
       "      <td>366.241833</td>\n",
       "      <td>...</td>\n",
       "      <td>143.682400</td>\n",
       "      <td>123.467857</td>\n",
       "      <td>48.830002</td>\n",
       "      <td>25.492176</td>\n",
       "      <td>84.384216</td>\n",
       "      <td>218.257961</td>\n",
       "      <td>650.916300</td>\n",
       "      <td>268.617205</td>\n",
       "      <td>225.459288</td>\n",
       "      <td>58.984098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>174.786447</td>\n",
       "      <td>217.070925</td>\n",
       "      <td>149.331001</td>\n",
       "      <td>359.337033</td>\n",
       "      <td>85.871868</td>\n",
       "      <td>116.723626</td>\n",
       "      <td>201.356784</td>\n",
       "      <td>288.825881</td>\n",
       "      <td>45.250680</td>\n",
       "      <td>378.660222</td>\n",
       "      <td>...</td>\n",
       "      <td>152.324055</td>\n",
       "      <td>125.040092</td>\n",
       "      <td>49.560001</td>\n",
       "      <td>25.884954</td>\n",
       "      <td>84.345154</td>\n",
       "      <td>230.288869</td>\n",
       "      <td>654.580279</td>\n",
       "      <td>281.984521</td>\n",
       "      <td>233.373966</td>\n",
       "      <td>60.142445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>173.887177</td>\n",
       "      <td>208.759964</td>\n",
       "      <td>147.720630</td>\n",
       "      <td>362.036667</td>\n",
       "      <td>84.185868</td>\n",
       "      <td>117.369912</td>\n",
       "      <td>199.810619</td>\n",
       "      <td>280.217986</td>\n",
       "      <td>44.157003</td>\n",
       "      <td>369.091828</td>\n",
       "      <td>...</td>\n",
       "      <td>149.968037</td>\n",
       "      <td>125.970016</td>\n",
       "      <td>49.810001</td>\n",
       "      <td>25.827473</td>\n",
       "      <td>84.081490</td>\n",
       "      <td>230.151077</td>\n",
       "      <td>648.640063</td>\n",
       "      <td>278.666550</td>\n",
       "      <td>234.768279</td>\n",
       "      <td>59.975385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-17</th>\n",
       "      <td>260.863597</td>\n",
       "      <td>190.191554</td>\n",
       "      <td>136.902164</td>\n",
       "      <td>450.835091</td>\n",
       "      <td>88.673548</td>\n",
       "      <td>199.652985</td>\n",
       "      <td>223.554142</td>\n",
       "      <td>286.098689</td>\n",
       "      <td>40.902340</td>\n",
       "      <td>313.547891</td>\n",
       "      <td>...</td>\n",
       "      <td>176.923240</td>\n",
       "      <td>120.489998</td>\n",
       "      <td>93.870003</td>\n",
       "      <td>24.219999</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>212.634971</td>\n",
       "      <td>735.003941</td>\n",
       "      <td>301.459804</td>\n",
       "      <td>203.503577</td>\n",
       "      <td>51.762905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-20</th>\n",
       "      <td>262.650244</td>\n",
       "      <td>189.747480</td>\n",
       "      <td>138.836272</td>\n",
       "      <td>453.961689</td>\n",
       "      <td>88.295482</td>\n",
       "      <td>200.475748</td>\n",
       "      <td>224.785817</td>\n",
       "      <td>298.676350</td>\n",
       "      <td>40.844720</td>\n",
       "      <td>315.687901</td>\n",
       "      <td>...</td>\n",
       "      <td>176.551924</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>95.449997</td>\n",
       "      <td>24.200001</td>\n",
       "      <td>85.099998</td>\n",
       "      <td>213.385311</td>\n",
       "      <td>731.607773</td>\n",
       "      <td>303.327090</td>\n",
       "      <td>205.195087</td>\n",
       "      <td>51.624597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21</th>\n",
       "      <td>261.636253</td>\n",
       "      <td>190.394442</td>\n",
       "      <td>139.862314</td>\n",
       "      <td>453.252159</td>\n",
       "      <td>89.165483</td>\n",
       "      <td>197.489799</td>\n",
       "      <td>222.728419</td>\n",
       "      <td>299.555949</td>\n",
       "      <td>40.383366</td>\n",
       "      <td>315.064187</td>\n",
       "      <td>...</td>\n",
       "      <td>173.221861</td>\n",
       "      <td>119.779999</td>\n",
       "      <td>95.540001</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>84.220001</td>\n",
       "      <td>210.568865</td>\n",
       "      <td>738.021048</td>\n",
       "      <td>304.675033</td>\n",
       "      <td>205.545860</td>\n",
       "      <td>50.792894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-22</th>\n",
       "      <td>262.113832</td>\n",
       "      <td>189.717752</td>\n",
       "      <td>140.709268</td>\n",
       "      <td>456.421427</td>\n",
       "      <td>89.015400</td>\n",
       "      <td>201.007383</td>\n",
       "      <td>224.408673</td>\n",
       "      <td>301.298701</td>\n",
       "      <td>40.274616</td>\n",
       "      <td>316.835630</td>\n",
       "      <td>...</td>\n",
       "      <td>173.583787</td>\n",
       "      <td>118.970001</td>\n",
       "      <td>97.129997</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>83.360001</td>\n",
       "      <td>210.899486</td>\n",
       "      <td>742.472706</td>\n",
       "      <td>306.203661</td>\n",
       "      <td>206.542578</td>\n",
       "      <td>50.460786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>260.163924</td>\n",
       "      <td>189.908568</td>\n",
       "      <td>140.880473</td>\n",
       "      <td>457.467805</td>\n",
       "      <td>89.305096</td>\n",
       "      <td>200.960444</td>\n",
       "      <td>225.173194</td>\n",
       "      <td>301.290009</td>\n",
       "      <td>40.392846</td>\n",
       "      <td>317.655530</td>\n",
       "      <td>...</td>\n",
       "      <td>173.847985</td>\n",
       "      <td>118.959999</td>\n",
       "      <td>96.260002</td>\n",
       "      <td>24.059999</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>210.341506</td>\n",
       "      <td>746.706105</td>\n",
       "      <td>307.151468</td>\n",
       "      <td>208.205090</td>\n",
       "      <td>50.945403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        ABBV         ABT         ACN        AIG  \\\n",
       "2023-01-03  168.639789  211.621951  145.665501  360.714599  83.711187   \n",
       "2023-01-04  171.825505  215.140097  149.087171  362.538234  85.669409   \n",
       "2023-01-05  167.653608  211.907272  146.484505  349.084957  84.022266   \n",
       "2023-01-06  174.786447  217.070925  149.331001  359.337033  85.871868   \n",
       "2023-01-09  173.887177  208.759964  147.720630  362.036667  84.185868   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2023-11-17  260.863597  190.191554  136.902164  450.835091  88.673548   \n",
       "2023-11-20  262.650244  189.747480  138.836272  453.961689  88.295482   \n",
       "2023-11-21  261.636253  190.394442  139.862314  453.252159  89.165483   \n",
       "2023-11-22  262.113832  189.717752  140.709268  456.421427  89.015400   \n",
       "2023-11-24  260.163924  189.908568  140.880473  457.467805  89.305096   \n",
       "\n",
       "                  AMZN         AXP          BA        BAC        BIIB  ...  \\\n",
       "2023-01-03  116.363342  196.572714  264.929310  44.064212  369.659037  ...   \n",
       "2023-01-04  116.421282  202.849765  278.459360  45.273718  370.308284  ...   \n",
       "2023-01-05  112.088157  195.258906  276.431078  44.556414  366.241833  ...   \n",
       "2023-01-06  116.723626  201.356784  288.825881  45.250680  378.660222  ...   \n",
       "2023-01-09  117.369912  199.810619  280.217986  44.157003  369.091828  ...   \n",
       "...                ...         ...         ...        ...         ...  ...   \n",
       "2023-11-17  199.652985  223.554142  286.098689  40.902340  313.547891  ...   \n",
       "2023-11-20  200.475748  224.785817  298.676350  40.844720  315.687901  ...   \n",
       "2023-11-21  197.489799  222.728419  299.555949  40.383366  315.064187  ...   \n",
       "2023-11-22  201.007383  224.408673  301.298701  40.274616  316.835630  ...   \n",
       "2023-11-24  200.960444  225.173194  301.290009  40.392846  317.655530  ...   \n",
       "\n",
       "                  QCOM       RY.TO    SHOP.TO       T.TO      TD.TO  \\\n",
       "2023-01-03  141.564543  122.739288  48.790001  25.214359  84.689217   \n",
       "2023-01-04  148.532840  123.832169  50.610001  25.520916  85.790451   \n",
       "2023-01-05  143.682400  123.467857  48.830002  25.492176  84.384216   \n",
       "2023-01-06  152.324055  125.040092  49.560001  25.884954  84.345154   \n",
       "2023-01-09  149.968037  125.970016  49.810001  25.827473  84.081490   \n",
       "...                ...         ...        ...        ...        ...   \n",
       "2023-11-17  176.923240  120.489998  93.870003  24.219999  84.779999   \n",
       "2023-11-20  176.551924  120.529999  95.449997  24.200001  85.099998   \n",
       "2023-11-21  173.221861  119.779999  95.540001  24.100000  84.220001   \n",
       "2023-11-22  173.583787  118.970001  97.129997  24.049999  83.360001   \n",
       "2023-11-24  173.847985  118.959999  96.260002  24.059999  83.349998   \n",
       "\n",
       "                   TXN         UNH         UNP         UPS        USB  \n",
       "2023-01-03  214.563569  692.793878  276.074065  228.572688  57.969780  \n",
       "2023-01-04  224.286737  679.626403  280.644095  232.919618  60.282251  \n",
       "2023-01-05  218.257961  650.916300  268.617205  225.459288  58.984098  \n",
       "2023-01-06  230.288869  654.580279  281.984521  233.373966  60.142445  \n",
       "2023-01-09  230.151077  648.640063  278.666550  234.768279  59.975385  \n",
       "...                ...         ...         ...         ...        ...  \n",
       "2023-11-17  212.634971  735.003941  301.459804  203.503577  51.762905  \n",
       "2023-11-20  213.385311  731.607773  303.327090  205.195087  51.624597  \n",
       "2023-11-21  210.568865  738.021048  304.675033  205.545860  50.792894  \n",
       "2023-11-22  210.899486  742.472706  306.203661  206.542578  50.460786  \n",
       "2023-11-24  210.341506  746.706105  307.151468  208.205090  50.945403  \n",
       "\n",
       "[222 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code below filters out invalid stocks based on the criteria of the assignment and uses multithreading for efficiency\n",
    "\n",
    "# Initializing a dataframe for 'raw' data extracted from the .csv file\n",
    "tickers_raw = pd.read_csv(\"Tickers.csv\", header=None)[0].tolist() \n",
    "\n",
    "# Empty data structures to store ticker data in\n",
    "tickers = []\n",
    "tickers_hist = {}\n",
    "\n",
    "# Dictionary of all the tickers' closing prices between January 01, 2023 and October 31, 2023\n",
    "stock_prices = {}\n",
    "\n",
    "# Exchange rate to convert stock prices from USD to CAD. This is so calculations on the historical data can be consistent with\n",
    "# the initial investment of $750,000 CAD \n",
    "exchange_ticker = yf.Ticker('USDCAD=x')\n",
    "exchange_hist = exchange_ticker.history(start=start_date, end=end_date)\n",
    "exchange_hist.index = pd.DatetimeIndex(exchange_hist.index).tz_localize(None)\n",
    "\n",
    "# Function which consumes a ticker and determines the validation based on prerequisites\n",
    "def validate_ticker(ticker):\n",
    "\n",
    "    # Extracting ticker info from yFinance\n",
    "    ticker_info = yf.Ticker(ticker).history_metadata\n",
    "\n",
    "    # Trying every stock and excepting those that throw an error\n",
    "    try:\n",
    "        # If the stock is valid, we check for each prerequisite:\n",
    "        # Checking for USD/CAD currency and ensuring it's on the US/Canadian market\n",
    "        # Check if the ticker is a stock \n",
    "        # Convert the stock price of the data from USD to CAD \n",
    "        if (ticker_info['currency'] == 'USD' or ticker_info['currency'] == 'CAD') and ticker_info['instrumentType'] == 'EQUITY':\n",
    "            \n",
    "            ticker_hist = yf.Ticker(ticker).history(start=start_date, end=end_date).dropna()\n",
    "            ticker_hist.index = pd.DatetimeIndex(ticker_hist.index).tz_localize(None)\n",
    "\n",
    "            # Checking monthly volume\n",
    "            ticker_monthly_trading_days = ticker_hist['Volume'].groupby(pd.Grouper(freq='MS')).count()\n",
    "            ticker_monthly_volume = ticker_hist['Volume'].groupby(pd.Grouper(freq='MS')).sum()\n",
    "\n",
    "            # Checking if the month has at least 18 trading days\n",
    "            for month in ticker_monthly_trading_days.index:\n",
    "                if ticker_monthly_trading_days.loc[month] < 18:\n",
    "                    ticker_monthly_volume.drop(month, inplace=True)\n",
    "\n",
    "             #Checking if the average monthly volume is greater than or equal to 150,000 USD\n",
    "            if ticker_monthly_volume.mean() >= 150000:\n",
    "                tickers.append(ticker)\n",
    "                tickers_hist[ticker] = ticker_hist\n",
    "\n",
    "                tickers_closing = yf.Ticker(ticker).history(start=start_date, end=end_date)['Close']\n",
    "                tickers_closing.index = pd.DatetimeIndex(tickers_closing.index).tz_localize(None)\n",
    "                \n",
    "                #Adjusted for exchange rates\n",
    "                if ticker_info['currency'] == 'USD':\n",
    "                    stock_prices[ticker] = tickers_closing.mul(exchange_hist['Close']).dropna()\n",
    "                elif ticker_info['currency'] == 'CAD':\n",
    "                    stock_prices[ticker] = tickers_closing\n",
    "            else:\n",
    "                print(f'{ticker} Ticker does not meet average monthly volume requirements')\n",
    "        else:\n",
    "            print(f'{ticker} Ticker does not reference stock denominated in USD or is an ETF or index stock')\n",
    "    except:\n",
    "        print(f'Error: {ticker} Ticker does not reference a valid stock')\n",
    "\n",
    "# Empty data structure for threading\n",
    "threads = []\n",
    "\n",
    "# Checking validity of each ticker in list of tickers given from threading\n",
    "for ticker in tickers_raw:\n",
    "    thread = threading.Thread(target=validate_ticker, args=[ticker])\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Using threading\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Creates a DataFrame that contains all the stocks and their closing prices between January and October 2023 \n",
    "\n",
    "stock_prices = pd.DataFrame(stock_prices)\n",
    "stock_prices.index = pd.to_datetime(stock_prices.index).date\n",
    "stock_prices = stock_prices.sort_index(axis=1)\n",
    "stock_prices = stock_prices.dropna() \n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081e8b5",
   "metadata": {},
   "source": [
    "### Filtering Stocks Based on Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658ee01",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_i = \\frac {\\mathrm{Covariance} (r_i,r_m)}{\\mathrm{Variance} (r_m)}\n",
    "$$\n",
    "\n",
    "The formula above is for $ \\beta_i $, the beta of a particular stock, where $r_i$ is the return of the stock and $r_m$ is the return of the market index. In this case, the market index will use the S&P 500 since it includes a wide breadth of large-cap companies in America. This is also ideal since our algorithm also finds the optimal number of stocks to diversify over and needs a market index that is representative of a wide range of stocks.\n",
    "\n",
    "Since our algorithm is trying to design a portfolio with the least volatility, our portfolio will consist of stocks with the lowest beta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22bed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>...</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>RY.TO</th>\n",
       "      <th>SHOP.TO</th>\n",
       "      <th>T.TO</th>\n",
       "      <th>TD.TO</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>168.639789</td>\n",
       "      <td>211.621951</td>\n",
       "      <td>145.665501</td>\n",
       "      <td>360.714599</td>\n",
       "      <td>83.711187</td>\n",
       "      <td>116.363342</td>\n",
       "      <td>196.572714</td>\n",
       "      <td>264.929310</td>\n",
       "      <td>44.064212</td>\n",
       "      <td>369.659037</td>\n",
       "      <td>...</td>\n",
       "      <td>141.564543</td>\n",
       "      <td>122.739288</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>25.214359</td>\n",
       "      <td>84.689217</td>\n",
       "      <td>214.563569</td>\n",
       "      <td>692.793878</td>\n",
       "      <td>276.074065</td>\n",
       "      <td>228.572688</td>\n",
       "      <td>57.969780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>171.825505</td>\n",
       "      <td>215.140097</td>\n",
       "      <td>149.087171</td>\n",
       "      <td>362.538234</td>\n",
       "      <td>85.669409</td>\n",
       "      <td>116.421282</td>\n",
       "      <td>202.849765</td>\n",
       "      <td>278.459360</td>\n",
       "      <td>45.273718</td>\n",
       "      <td>370.308284</td>\n",
       "      <td>...</td>\n",
       "      <td>148.532840</td>\n",
       "      <td>123.832169</td>\n",
       "      <td>50.610001</td>\n",
       "      <td>25.520916</td>\n",
       "      <td>85.790451</td>\n",
       "      <td>224.286737</td>\n",
       "      <td>679.626403</td>\n",
       "      <td>280.644095</td>\n",
       "      <td>232.919618</td>\n",
       "      <td>60.282251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>167.653608</td>\n",
       "      <td>211.907272</td>\n",
       "      <td>146.484505</td>\n",
       "      <td>349.084957</td>\n",
       "      <td>84.022266</td>\n",
       "      <td>112.088157</td>\n",
       "      <td>195.258906</td>\n",
       "      <td>276.431078</td>\n",
       "      <td>44.556414</td>\n",
       "      <td>366.241833</td>\n",
       "      <td>...</td>\n",
       "      <td>143.682400</td>\n",
       "      <td>123.467857</td>\n",
       "      <td>48.830002</td>\n",
       "      <td>25.492176</td>\n",
       "      <td>84.384216</td>\n",
       "      <td>218.257961</td>\n",
       "      <td>650.916300</td>\n",
       "      <td>268.617205</td>\n",
       "      <td>225.459288</td>\n",
       "      <td>58.984098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>174.786447</td>\n",
       "      <td>217.070925</td>\n",
       "      <td>149.331001</td>\n",
       "      <td>359.337033</td>\n",
       "      <td>85.871868</td>\n",
       "      <td>116.723626</td>\n",
       "      <td>201.356784</td>\n",
       "      <td>288.825881</td>\n",
       "      <td>45.250680</td>\n",
       "      <td>378.660222</td>\n",
       "      <td>...</td>\n",
       "      <td>152.324055</td>\n",
       "      <td>125.040092</td>\n",
       "      <td>49.560001</td>\n",
       "      <td>25.884954</td>\n",
       "      <td>84.345154</td>\n",
       "      <td>230.288869</td>\n",
       "      <td>654.580279</td>\n",
       "      <td>281.984521</td>\n",
       "      <td>233.373966</td>\n",
       "      <td>60.142445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>173.887177</td>\n",
       "      <td>208.759964</td>\n",
       "      <td>147.720630</td>\n",
       "      <td>362.036667</td>\n",
       "      <td>84.185868</td>\n",
       "      <td>117.369912</td>\n",
       "      <td>199.810619</td>\n",
       "      <td>280.217986</td>\n",
       "      <td>44.157003</td>\n",
       "      <td>369.091828</td>\n",
       "      <td>...</td>\n",
       "      <td>149.968037</td>\n",
       "      <td>125.970016</td>\n",
       "      <td>49.810001</td>\n",
       "      <td>25.827473</td>\n",
       "      <td>84.081490</td>\n",
       "      <td>230.151077</td>\n",
       "      <td>648.640063</td>\n",
       "      <td>278.666550</td>\n",
       "      <td>234.768279</td>\n",
       "      <td>59.975385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-17</th>\n",
       "      <td>260.863597</td>\n",
       "      <td>190.191554</td>\n",
       "      <td>136.902164</td>\n",
       "      <td>450.835091</td>\n",
       "      <td>88.673548</td>\n",
       "      <td>199.652985</td>\n",
       "      <td>223.554142</td>\n",
       "      <td>286.098689</td>\n",
       "      <td>40.902340</td>\n",
       "      <td>313.547891</td>\n",
       "      <td>...</td>\n",
       "      <td>176.923240</td>\n",
       "      <td>120.489998</td>\n",
       "      <td>93.870003</td>\n",
       "      <td>24.219999</td>\n",
       "      <td>84.779999</td>\n",
       "      <td>212.634971</td>\n",
       "      <td>735.003941</td>\n",
       "      <td>301.459804</td>\n",
       "      <td>203.503577</td>\n",
       "      <td>51.762905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-20</th>\n",
       "      <td>262.650244</td>\n",
       "      <td>189.747480</td>\n",
       "      <td>138.836272</td>\n",
       "      <td>453.961689</td>\n",
       "      <td>88.295482</td>\n",
       "      <td>200.475748</td>\n",
       "      <td>224.785817</td>\n",
       "      <td>298.676350</td>\n",
       "      <td>40.844720</td>\n",
       "      <td>315.687901</td>\n",
       "      <td>...</td>\n",
       "      <td>176.551924</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>95.449997</td>\n",
       "      <td>24.200001</td>\n",
       "      <td>85.099998</td>\n",
       "      <td>213.385311</td>\n",
       "      <td>731.607773</td>\n",
       "      <td>303.327090</td>\n",
       "      <td>205.195087</td>\n",
       "      <td>51.624597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21</th>\n",
       "      <td>261.636253</td>\n",
       "      <td>190.394442</td>\n",
       "      <td>139.862314</td>\n",
       "      <td>453.252159</td>\n",
       "      <td>89.165483</td>\n",
       "      <td>197.489799</td>\n",
       "      <td>222.728419</td>\n",
       "      <td>299.555949</td>\n",
       "      <td>40.383366</td>\n",
       "      <td>315.064187</td>\n",
       "      <td>...</td>\n",
       "      <td>173.221861</td>\n",
       "      <td>119.779999</td>\n",
       "      <td>95.540001</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>84.220001</td>\n",
       "      <td>210.568865</td>\n",
       "      <td>738.021048</td>\n",
       "      <td>304.675033</td>\n",
       "      <td>205.545860</td>\n",
       "      <td>50.792894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-22</th>\n",
       "      <td>262.113832</td>\n",
       "      <td>189.717752</td>\n",
       "      <td>140.709268</td>\n",
       "      <td>456.421427</td>\n",
       "      <td>89.015400</td>\n",
       "      <td>201.007383</td>\n",
       "      <td>224.408673</td>\n",
       "      <td>301.298701</td>\n",
       "      <td>40.274616</td>\n",
       "      <td>316.835630</td>\n",
       "      <td>...</td>\n",
       "      <td>173.583787</td>\n",
       "      <td>118.970001</td>\n",
       "      <td>97.129997</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>83.360001</td>\n",
       "      <td>210.899486</td>\n",
       "      <td>742.472706</td>\n",
       "      <td>306.203661</td>\n",
       "      <td>206.542578</td>\n",
       "      <td>50.460786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>260.163924</td>\n",
       "      <td>189.908568</td>\n",
       "      <td>140.880473</td>\n",
       "      <td>457.467805</td>\n",
       "      <td>89.305096</td>\n",
       "      <td>200.960444</td>\n",
       "      <td>225.173194</td>\n",
       "      <td>301.290009</td>\n",
       "      <td>40.392846</td>\n",
       "      <td>317.655530</td>\n",
       "      <td>...</td>\n",
       "      <td>173.847985</td>\n",
       "      <td>118.959999</td>\n",
       "      <td>96.260002</td>\n",
       "      <td>24.059999</td>\n",
       "      <td>83.349998</td>\n",
       "      <td>210.341506</td>\n",
       "      <td>746.706105</td>\n",
       "      <td>307.151468</td>\n",
       "      <td>208.205090</td>\n",
       "      <td>50.945403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        ABBV         ABT         ACN        AIG  \\\n",
       "2023-01-03  168.639789  211.621951  145.665501  360.714599  83.711187   \n",
       "2023-01-04  171.825505  215.140097  149.087171  362.538234  85.669409   \n",
       "2023-01-05  167.653608  211.907272  146.484505  349.084957  84.022266   \n",
       "2023-01-06  174.786447  217.070925  149.331001  359.337033  85.871868   \n",
       "2023-01-09  173.887177  208.759964  147.720630  362.036667  84.185868   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2023-11-17  260.863597  190.191554  136.902164  450.835091  88.673548   \n",
       "2023-11-20  262.650244  189.747480  138.836272  453.961689  88.295482   \n",
       "2023-11-21  261.636253  190.394442  139.862314  453.252159  89.165483   \n",
       "2023-11-22  262.113832  189.717752  140.709268  456.421427  89.015400   \n",
       "2023-11-24  260.163924  189.908568  140.880473  457.467805  89.305096   \n",
       "\n",
       "                  AMZN         AXP          BA        BAC        BIIB  ...  \\\n",
       "2023-01-03  116.363342  196.572714  264.929310  44.064212  369.659037  ...   \n",
       "2023-01-04  116.421282  202.849765  278.459360  45.273718  370.308284  ...   \n",
       "2023-01-05  112.088157  195.258906  276.431078  44.556414  366.241833  ...   \n",
       "2023-01-06  116.723626  201.356784  288.825881  45.250680  378.660222  ...   \n",
       "2023-01-09  117.369912  199.810619  280.217986  44.157003  369.091828  ...   \n",
       "...                ...         ...         ...        ...         ...  ...   \n",
       "2023-11-17  199.652985  223.554142  286.098689  40.902340  313.547891  ...   \n",
       "2023-11-20  200.475748  224.785817  298.676350  40.844720  315.687901  ...   \n",
       "2023-11-21  197.489799  222.728419  299.555949  40.383366  315.064187  ...   \n",
       "2023-11-22  201.007383  224.408673  301.298701  40.274616  316.835630  ...   \n",
       "2023-11-24  200.960444  225.173194  301.290009  40.392846  317.655530  ...   \n",
       "\n",
       "                  QCOM       RY.TO    SHOP.TO       T.TO      TD.TO  \\\n",
       "2023-01-03  141.564543  122.739288  48.790001  25.214359  84.689217   \n",
       "2023-01-04  148.532840  123.832169  50.610001  25.520916  85.790451   \n",
       "2023-01-05  143.682400  123.467857  48.830002  25.492176  84.384216   \n",
       "2023-01-06  152.324055  125.040092  49.560001  25.884954  84.345154   \n",
       "2023-01-09  149.968037  125.970016  49.810001  25.827473  84.081490   \n",
       "...                ...         ...        ...        ...        ...   \n",
       "2023-11-17  176.923240  120.489998  93.870003  24.219999  84.779999   \n",
       "2023-11-20  176.551924  120.529999  95.449997  24.200001  85.099998   \n",
       "2023-11-21  173.221861  119.779999  95.540001  24.100000  84.220001   \n",
       "2023-11-22  173.583787  118.970001  97.129997  24.049999  83.360001   \n",
       "2023-11-24  173.847985  118.959999  96.260002  24.059999  83.349998   \n",
       "\n",
       "                   TXN         UNH         UNP         UPS        USB  \n",
       "2023-01-03  214.563569  692.793878  276.074065  228.572688  57.969780  \n",
       "2023-01-04  224.286737  679.626403  280.644095  232.919618  60.282251  \n",
       "2023-01-05  218.257961  650.916300  268.617205  225.459288  58.984098  \n",
       "2023-01-06  230.288869  654.580279  281.984521  233.373966  60.142445  \n",
       "2023-01-09  230.151077  648.640063  278.666550  234.768279  59.975385  \n",
       "...                ...         ...         ...         ...        ...  \n",
       "2023-11-17  212.634971  735.003941  301.459804  203.503577  51.762905  \n",
       "2023-11-20  213.385311  731.607773  303.327090  205.195087  51.624597  \n",
       "2023-11-21  210.568865  738.021048  304.675033  205.545860  50.792894  \n",
       "2023-11-22  210.899486  742.472706  306.203661  206.542578  50.460786  \n",
       "2023-11-24  210.341506  746.706105  307.151468  208.205090  50.945403  \n",
       "\n",
       "[222 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code below calculates the beta for each of the stocks in the DataFrame of valid stocks\n",
    "\n",
    "def get_beta(ticker_list):\n",
    "    market_index = yf.Ticker('^GSPC').history(start=start_date, end=end_date)['Close'].dropna()\n",
    "    market_index.index = pd.DatetimeIndex(market_index.index).tz_localize(None)\n",
    "    market_return = market_index.pct_change()\n",
    "    market_variance = market_return.var()\n",
    "    beta_list = []\n",
    "    beta_df = pd.DataFrame()\n",
    "    for i in range(len(ticker_list.columns)):\n",
    "        stock_return = ticker_list.iloc[:, i].pct_change()\n",
    "        covariance = stock_return.cov(market_return)\n",
    "        beta_list.append(covariance/market_variance)\n",
    "    beta_df['Ticker'] = ticker_list.columns\n",
    "    beta_df['Beta'] = beta_list\n",
    "    return beta_df\n",
    "\n",
    "# Calls the function get_beta() and sorts the betas in descending order\n",
    "beta_df = get_beta(stock_prices)\n",
    "beta_df.sort_values(by=['Beta'], ascending=False, ignore_index=True, inplace=True)\n",
    "beta_df\n",
    "\n",
    "# Filters the resulting DataFrame to discard any stocks with an unreasonably high beta. Since the beta list has been sorted from\n",
    "# greatest to least, the stocks with the greatest beta will always be filtered out first. There will always be at least 10 \n",
    "# stocks in the resulting list of stocks.\n",
    "#minimum = len(beta_df.index)\n",
    "#for i in range(len(beta_df.index)):\n",
    "#    if beta_df.iloc[i].iloc[1] > 1.5 and minimum > 10:\n",
    "#        stock_prices = stock_prices.drop([beta_df.iloc[i].iloc[0]], axis=1)\n",
    "#        minimum -= 1\n",
    "\n",
    "stock_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bb707",
   "metadata": {},
   "source": [
    "### Volatility/Gradient Descent Algorithm to Determine Optimal Weightings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88b6b7",
   "metadata": {},
   "source": [
    "**How does our algorithm work?**\n",
    "\n",
    "Our algorithm works as follows. First, we construct a custom definition of volatility derived by modifying the standard deviation formula as follows:\n",
    "\n",
    "$\\sqrt{\\sum_{t=1}^n \\frac{(\\bar{x}-x_i)^2}{n}}$\n",
    "\n",
    "In the safe strategy, an ideal portfolio is one with zero growth (ignoring trading fees, which are negligible). Therefore, we replace average change $\\bar{x}$ with 0:\n",
    "\n",
    "$\\sqrt{\\sum_{t=1}^n \\frac{(0-x_i)^2}{n}}$\n",
    "\n",
    "Next, we recognize that we are not concerned with volatility over a daily range, but instead a weekly range. Therefore, we consider the squared distance from zero not of the daily change but the change over 5 days (which we use as a reasonable estimate of the number of trading days occurring over a week):\n",
    "\n",
    "$\\text{Volatility}=\\sqrt{\\sum_{i=1}^n \\frac{\\bigl(\\prod_{j=0}^5 (1+x_{i+j})-1 \\bigr)^2}{n}}$\n",
    "\n",
    "The principal goal of our algorithm is to minimize this equation by changing the weightings of each stock.\n",
    "\n",
    "**How we determine optimal stock weightings?**\n",
    "\n",
    "To minimize volatility without having to use brute force, we repeatedly iterate through the list of stocks, changing the weightings of each one at a time. What we do next depends on the feedback received: If an increase in the weighting of stock results in an increase in the volatility of the portfolio, we know to reverse such a decision, and instead decrease the weightings. Through this process of constant trial and feedback (called gradient descent), we can gradually find the optimal weighting for each stock\n",
    "\n",
    "**Cleaning the data and abiding by assignment rules:**\n",
    "\n",
    "If we were simply to let the algorithm in its current description run without change, we could end up with weightings beyond the upper limit of 20%, below lower limits, or perhaps even negative. Therefore, every cycle we go through the results, and make a few corrections to it. First of all, if our algorithm produces a stock with a negative weighting, it is automatically corrected to zero. If a stock exceeds the maximum allowed weighting, it is also reduced to that limit. Lastly, if the weighting of a stock is positive but below the minimum requirement, we compare the volatility of two hypothetical portfolios: one where the weightings are abruptly set to the minimum requirement, and another where it is set to zero. Which ever one results in a lower volatility, we keep.\n",
    "\n",
    "**Excluding stocks from our list:**\n",
    "\n",
    "If we are given a list of stocks greater than the maximum 22, we need a process by which to eliminate some. We do so by dropping the stock with the least weighting every few iterations of our algorithm. The reason we do not drop several at a time is to allow the portfolio to adjust to the changes made.\n",
    "\n",
    "**Finalizing the weights:**\n",
    "\n",
    "Once the algorithm has been iterated a sufficient number of times, we are ready to construct the final portfolio. First, we renorm the weightings such that they add up to 100%. Over time, when we add and subtract weights, this results in changes to the sum. While this is not an issue during the process (for we can simply keep track of the sum), for purposes of presenting the data and calculating the correct investment amounts, we go through this renorming. Second, we go through the weightings again, this time more rigorously; to make sure all rules are being abided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26c1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025512042071520406 0.008246863680736068\n",
      "0.0002527137970314248 0.007330243884057864\n",
      "0.00016410963552884942 0.007009159559137849\n",
      "0.00013252435894759156 0.006929927328534156\n",
      "0.0001252825940158909 0.006899864505511751\n",
      "0.00012115664109759973 0.006850937960850791\n",
      "0.0001162186721280825 0.006842331749623623\n",
      "0.00011328305740400322 0.006840036961958657\n",
      "0.00011105629977437125 0.006842506857282256\n",
      "0.00010927632878986362 0.006867287654751489\n",
      "0.00010876161176619209 0.006910286026603627\n",
      "0.00010837124688156703 0.006894982508154713\n",
      "0.0001081769933623134 0.0069489209670185815\n",
      "0.00010767489015197868 0.006961507334698316\n",
      "0.00010721951153992388 0.0069727906748025086\n",
      "0.00010672510355732151 0.006984493118470369\n",
      "0.00010612667076800144 0.007053316113919564\n",
      "0.00010540928731729202 0.007029971227915549\n",
      "0.00010576156319378189 0.007045941353444237\n",
      "0.00010466203908652283 0.007045924929012061\n",
      "0.00010493630336411909 0.007043452663356403\n",
      "0.00010417791403545415 0.007044292748388611\n",
      "0.00010390612993838739 0.007112550128624974\n",
      "0.00010423866709570374 0.0070482685589655075\n",
      "0.00010384008301504442 0.007113213592265013\n",
      "0.00010358832114921396 0.0071230555480023576\n",
      "0.00010394657103626927 0.007121993593667074\n",
      "0.00010359710801366208 0.007126798852688774\n",
      "0.00010312226408220239 0.007107555780220423\n",
      "0.0001020969790597455 0.007094217993402719\n",
      "0.0001029524122989591 0.007093361555941341\n",
      "0.00010243129680766896 0.007095941534509935\n",
      "0.00010220248652368563 0.007099121439653963\n",
      "0.00010192444117377282 0.007101797193094164\n",
      "0.00010157949527400575 0.007104722637690394\n",
      "0.00010095577336084749 0.007117988067113525\n",
      "0.00010166714177396624 0.007112765123386221\n",
      "0.0001007066447758858 0.007115092328889995\n",
      "0.00010065023506366112 0.007118702509009396\n",
      "0.00010053870838272464 0.007122311910947998\n",
      "0.00010043413545368311 0.007127801136319516\n",
      "0.00010046956885105487 0.00712959462380655\n",
      "0.0001003795469607677 0.007131439395533162\n",
      "0.0001002819070891061 0.0071499115804608895\n",
      "0.00010007360984155828 0.007245110493451083\n",
      "0.00010154577771283924 0.007197428391822267\n",
      "0.00010084041805436164 0.007241131951316757\n",
      "0.00010079904044398012 0.007206145681948044\n",
      "0.000102592515282953 0.00723936627074989\n",
      "0.00010106152322235031 0.007231042747522363\n",
      "0.00010067336465310863 0.007254390903549616\n",
      "0.00010136391179011025 0.007260481515152304\n",
      "0.00010170660372770801 0.007252583059941408\n",
      "0.00010081930026439458 0.0072478775107716106\n",
      "0.00010116830391627179 0.007244622949726451\n",
      "0.00010037993862120686 0.007244439122246841\n",
      "0.00010038653078985129 0.007244587687677924\n",
      "0.0001004020559247281 0.007243224844693798\n",
      "0.00010027925492554936 0.007230405845628839\n",
      "9.92237783358025e-05 0.0072387048108274255\n",
      "0.00010025595208098124 0.007231890897516354\n",
      "9.909822267100484e-05 0.007228779271377802\n",
      "9.911941194228024e-05 0.007230476241219132\n",
      "9.906134003578587e-05 0.007231764233209022\n",
      "9.901077756991391e-05 0.007228990578098296\n",
      "9.897629572145046e-05 0.007230514818845676\n",
      "9.894364906191988e-05 0.007230868406936738\n",
      "9.890619579137558e-05 0.007227696619086565\n",
      "9.886779628266707e-05 0.007229697890059256\n",
      "9.885573995670943e-05 0.007228901585221189\n",
      "9.881483741654559e-05 0.007242249028478995\n",
      "9.98781929681256e-05 0.007159768243599751\n",
      "9.415752063003442e-05 0.0071588505304537\n",
      "9.414982519379967e-05 0.007162252490891924\n",
      "9.405388729888152e-05 0.007166093801761181\n",
      "9.397602564111626e-05 0.007164487313907918\n",
      "9.380159422465957e-05 0.00716649951126238\n",
      "9.373754486189811e-05 0.007172873235072693\n",
      "9.381951116251195e-05 0.007171141612565269\n",
      "9.368096360428238e-05 0.007172361087745941\n",
      "9.36916221172769e-05 0.007175398487965597\n",
      "9.38316708756655e-05 0.007179289448280351\n",
      "9.396377019182471e-05 0.007184189096406216\n",
      "9.424535044312545e-05 0.0071822031684079515\n",
      "9.4134216574206e-05 0.007180403750628403\n",
      "9.400689076348434e-05 0.007179237725094244\n",
      "9.396120496809816e-05 0.007178937240087082\n",
      "9.395499035297537e-05 0.0071774852350532945\n",
      "9.388462735692646e-05 0.007175595083471574\n",
      "9.376968646381723e-05 0.007176157447993161\n",
      "9.379152745995054e-05 0.007177763981130597\n",
      "9.386633326342787e-05 0.007175768728437296\n",
      "9.377835107107362e-05 0.007175872206307515\n",
      "9.375884140976676e-05 0.007181480111091583\n",
      "9.401923136012924e-05 0.007179441264022405\n",
      "9.419403907096252e-05 0.007178246341646949\n",
      "9.419533656575109e-05 0.00717918641687422\n",
      "9.435677574092479e-05 0.007174939999541374\n",
      "9.413193508307922e-05 0.0071721611338153544\n",
      "9.397220595149415e-05 0.007170172722071529\n",
      "9.383364077418582e-05 0.007169970702836731\n",
      "9.381181728366394e-05 0.007170449671628278\n",
      "9.38228407096636e-05 0.007169059515444069\n",
      "9.371768348943505e-05 0.007170323969165279\n",
      "9.373194086191774e-05 0.007173365615029563\n",
      "9.383210968379708e-05 0.007172616118146393\n",
      "9.379661084391405e-05 0.007172711240178682\n",
      "9.401817826240968e-05 0.007170953926160312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_3868\\141447145.py:155: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dropped_stocks = [stocks for stocks in volatility_data.columns if volatility_data[stocks][2] <= 0]\n"
     ]
    }
   ],
   "source": [
    "# Daniel Chung\n",
    "# The code below is our main volatility/gradient descent algorithm\n",
    "\n",
    "def volatility(changes):\n",
    "    vol = 0\n",
    "    length = len(changes.index)\n",
    "    for n in range(1, length - 5):\n",
    "        vol += pow((1 + changes.iloc[n]) * (1 + changes.iloc[n+1]) * (1 + changes.iloc[n+2]) \n",
    "        * (1 + changes.iloc[n+3]) * (1 + changes.iloc[n+4]) - 1, 2) / length       \n",
    "    #vol = pow(vol, 1/2)\n",
    "    return vol\n",
    "\n",
    "def cleanup(old_volatility_data, can_drop):\n",
    "    # as a result of changing weightings, sum will not neccesarily add up to 100%. This is okay as long as relative weightings\n",
    "    # are preserved -i.e, if final weightings add up to 200%, we can just divide every weight by 2 to correct for this.\n",
    "    weight_sum = 0\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        weight_sum = weight_sum + old_volatility_data.iloc[2,n]\n",
    "    # number of stocks we actually invest into\n",
    "    num_stocks = 0\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] != 0:\n",
    "            num_stocks = num_stocks + 1\n",
    "\n",
    "    #finds stock with least weighting\n",
    "    min_stock_index = n\n",
    "    min_weighting = old_volatility_data.iloc[2,0]\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] != 0 and old_volatility_data.iloc[2,n] < min_weighting:\n",
    "            min_stock_index = n\n",
    "            min_weighting = old_volatility_data.iloc[2,n]\n",
    "    #drops stocks if it is permitted, and either there are stocks with negative weightings or we do not meet cap on number\n",
    "    # of stocks\n",
    "    if (can_drop and (num_stocks > 22 or min_weighting <= 0) and num_stocks > 10):\n",
    "        old_volatility_data.iloc[1, min_stock_index] = 0 \n",
    "        old_volatility_data.iloc[2, min_stock_index] = 0\n",
    "\n",
    "    # makes sure upper limit on weightings is not breached\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if (old_volatility_data.iloc[2,n] > weight_sum * 0.2):\n",
    "            weight_sum = weight_sum - (volatility_data.iloc[2,n] - weight_sum * 0.2)\n",
    "            old_volatility_data.iloc[2,n] = weight_sum * 0.2\n",
    "    \n",
    "    # number of stocks with positive investment\n",
    "    pos_stocks = 0\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] > 0:\n",
    "            pos_stocks = pos_stocks + 1\n",
    "    \n",
    "    #makes sure lower limit on weightings is not breached\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if (old_volatility_data.iloc[2,n] < weight_sum/(2*num_stocks)\n",
    "            and old_volatility_data.iloc[2,n] != 0):\n",
    "            min_weighting = 1/(2*num_stocks) * (weight_sum - old_volatility_data.iloc[2,n]) / (1 - 1/(2*num_stocks))            \n",
    "            weight_diff = old_volatility_data.iloc[2,n] - min_weighting\n",
    "            portfolio[old_volatility_data.columns[n]] = (investment * min_weighting \n",
    "                                / stock_prices.iloc[0,n] * stock_prices[columns[n]])\n",
    "            vol_with = volatility(portfolio.sum(axis=1).pct_change())\n",
    "            portfolio[old_volatility_data.columns[n]] = portfolio[old_volatility_data.columns[n]] * 0\n",
    "            vol_without = volatility(portfolio.sum(axis=1).pct_change())\n",
    "            portfolio[old_volatility_data.columns[n]] = (investment * old_volatility_data.iloc[2,n] \n",
    "                                / stock_prices.iloc[0,n] * stock_prices[columns[n]])\n",
    "            if pos_stocks < 12:\n",
    "                weight_sum = weight_sum + min_weighting - old_volatility_data.iloc[2,n]  \n",
    "                old_volatility_data.iloc[2,n] = min_weighting\n",
    "            elif vol_with < vol_without:\n",
    "                weight_sum = weight_sum + min_weighting - old_volatility_data.iloc[2,n]\n",
    "                old_volatility_data.iloc[2,n] = min_weighting\n",
    "            else:\n",
    "                weight_sum = weight_sum - 0.001 - old_volatility_data.iloc[2,n]\n",
    "                old_volatility_data.iloc[2,n] = -0.001\n",
    "                pos_stocks = pos_stocks - 1\n",
    "                                                                                                                                           \n",
    "    return old_volatility_data\n",
    "\n",
    "# Gradient descent function that minimizes volatility\n",
    "# Independent variable: Volatility\n",
    "# Dependent variable: Weighting of stock\n",
    "def min_search(stock, volatility_1, weight_1, weight_2):\n",
    "    # Stock is not invested into at all\n",
    "    if weight_1 == 0 and weight_2 == 0:\n",
    "        portfolio[stock] = portfolio[stock] * 0\n",
    "        volatility_2 = volatility(portfolio.sum(axis=1).pct_change())\n",
    "        return [volatility_2, 0, 0]\n",
    "    else:\n",
    "        portfolio[stock] = (investment * weight_2 / stock_prices.iloc[0][stock]) * stock_prices[stock]\n",
    "        volatility_2 = volatility(portfolio.sum(axis=1).pct_change())\n",
    "        # average change in volatility as a result of changing weightings - approx. for derivative\n",
    "        if weight_1 != weight_2:\n",
    "            # if volatility increases as result of changing weighting in certain direction, we change weighting in opposite\n",
    "            # direction. If volatility decreases, we continue\n",
    "            change = (volatility_2 - volatility_1)/(weight_2 - weight_1)\n",
    "            if change < 0:\n",
    "                new_weight = weight_2 - max(change * 50, -0.01)\n",
    "            else:\n",
    "                new_weight = weight_2 - min(change * 50, 0.01)\n",
    "        #extreme case where algo suggest to keep weightings unchanged (implies optimal weighting is precisley found)\n",
    "        else:\n",
    "            new_weight = weight_2\n",
    "        if new_weight < -0.001:\n",
    "            new_weight = -0.001\n",
    "        return [volatility_2, weight_2, new_weight]\n",
    "\n",
    "# Creation of initial portfolio\n",
    "portfolio = pd.DataFrame()\n",
    "portfolio.index = stock_prices.index\n",
    "\n",
    "# At first, the portfolio is just an equal weighting of all valid stocks\n",
    "columns = stock_prices.columns\n",
    "investment = 750000\n",
    "for n in range(0, len(columns)):\n",
    "    portfolio[columns[n]] = ((investment/len(columns)) / stock_prices.iloc[0, n]) * stock_prices[columns[n]]\n",
    "portfolio\n",
    "    \n",
    "# Dataframe used to keep track of optimization\n",
    "volatility_data = pd.DataFrame()\n",
    "volatility_data.index = ['Vol1', 'Weight1', 'Weight2']\n",
    "volatility_data\n",
    "\n",
    "# Creation of initial values to get optimization started\n",
    "vol1 = volatility(portfolio.sum(axis=1).pct_change())\n",
    "for j in range(0, len(portfolio.columns)):\n",
    "    volatility_data[portfolio.columns[j]] = [vol1, 1/len(portfolio.columns), 1/len(portfolio.columns) + 0.005]\n",
    "\n",
    "iterations = ((len(portfolio.columns) - 10) * 3 + 30)\n",
    "    \n",
    "for i in range(0, iterations):\n",
    "    # Updates volatility to reflect changes made during cleanup\n",
    "    volatility_data.iloc[0,0] = volatility(portfolio.sum(axis=1).pct_change())\n",
    "    # Goes through every stock in portfolio\n",
    "    for j in range (0, len(volatility_data.columns)-1):\n",
    "        # Calls gradient descent on given stock\n",
    "        results = min_search(volatility_data.columns[j],\n",
    "                             volatility_data.iloc[0,j],\n",
    "                             volatility_data.iloc[1,j],\n",
    "                             volatility_data.iloc[2,j])\n",
    "        #updates data for next stock so that it has volatility data to compare with\n",
    "        if j < len(volatility_data.columns)-1:\n",
    "            volatility_data.iloc[0,j+1] = results[0]\n",
    "        else:\n",
    "            volatility_data.iloc[0,0] = results[0] \n",
    "        #updates weightings\n",
    "        volatility_data.iloc[1,j] = results[1]\n",
    "        volatility_data.iloc[2,j] = results[2]\n",
    "        \n",
    "    # If portfolio optimization has only been through a few iterations, we avoid eliminating stocks unless their weightings\n",
    "    # go negative. Otherwise, we unleash the Hunger Games. Also, we only drop stocks every other iteration to allow for\n",
    "    # adjustment of rest of stocks.\n",
    "    if i > 11 and i % 3 == 0:\n",
    "        volatility_data = cleanup(volatility_data, True)\n",
    "    else:\n",
    "        volatility_data = cleanup(volatility_data, False)\n",
    "    print(volatility_data.iloc[0,0], portfolio.sum(axis=1).pct_change().std())\n",
    "\n",
    "# For data presentation, we drop stocks we do not invest at all in\n",
    "dropped_stocks = [stocks for stocks in volatility_data.columns if volatility_data[stocks][2] <= 0]\n",
    "volatility_data.drop(dropped_stocks, axis=1, inplace=True)\n",
    "volatility_data\n",
    "\n",
    "#renorms weightings for portfolio\n",
    "weight_sum = 0\n",
    "for n in range(0, len(volatility_data.columns)):\n",
    "    weight_sum = weight_sum + volatility_data.iloc[2,n]\n",
    "    \n",
    "adjustment_factor = 1/weight_sum\n",
    "\n",
    "for n in range(0, len(volatility_data.columns)):\n",
    "    volatility_data.iloc[2,n] = volatility_data.iloc[2,n] * adjustment_factor\n",
    "    \n",
    "#Here, we go through the list of stocks one more time to make sure none of the requirements are violated. While we\n",
    "# attempt to do that continously using cleanup(), the processes in cleanup sacrifice mathematical precision in exchange for\n",
    "# faster computing, and thus may result in stocks barely not meeting requirements.\n",
    "min_threshold = 1/(2*len(volatility_data.columns))\n",
    "\n",
    "def set_lower_bound(target_value, old_volatility_data, index):\n",
    "    #amount by which to increase weighting\n",
    "    diff = target_value - old_volatility_data.iloc[2, index]\n",
    "    old_volatility_data.iloc[2, index] = target_value\n",
    "    #to prevent rest of weights from being messed up, we must decrease them -if possible -to account for change in weighting\n",
    "    available = 0\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] > target_value:\n",
    "            available += old_volatility_data.iloc[2,n] - target_value\n",
    "    #how much to subtract\n",
    "    subtract = diff/available\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] > min_threshold:\n",
    "            old_volatility_data.iloc[2,n] = (1 - subtract) * (old_volatility_data.iloc[2,n] - target_value) + target_value\n",
    "            \n",
    "def set_upper_bound(old_volatility_data, index):\n",
    "    #amount by which to increase weighting\n",
    "    diff = 0.20 - old_volatility_data.iloc[2, index]\n",
    "    old_volatility_data.iloc[2, index] = 0.20\n",
    "    #to prevent rest of weights from being messed up, we must decrease them -if possible -to account for change in weighting\n",
    "    available = 0\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] < 0.20:\n",
    "            available += 0.20 - old_volatility_data.iloc[2,n] - 0.20\n",
    "    #how much to add\n",
    "    add = diff/available\n",
    "    for n in range(0, len(old_volatility_data.columns)):\n",
    "        if old_volatility_data.iloc[2,n] > min_threshold:\n",
    "            old_volatility_data.iloc[2,n] = 0.20 - (1 - add) * (0.20 - old_volatility_data.iloc[2,n])\n",
    "\n",
    "        \n",
    "for n in range(0, len(volatility_data.columns)):\n",
    "    if volatility_data.iloc[2,n] < min_threshold:\n",
    "        set_lower_bound(min_threshold, volatility_data, n)\n",
    "    elif volatility_data.iloc[2,n] > 0.2:\n",
    "        set_upper_bound(volatility_data, n)\n",
    "\n",
    "#prints out list of stocks to invest in and their weightings\n",
    "investment = 750000\n",
    "investment = investment - 4.95 * len(volatility_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a487f",
   "metadata": {},
   "source": [
    "### Final Portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "195f4f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'volatility_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m             currency_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCAD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m currency_list\n\u001b[1;32m---> 23\u001b[0m final_close_price \u001b[38;5;241m=\u001b[39m get_price(volatility_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-11-24\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     24\u001b[0m final_currency \u001b[38;5;241m=\u001b[39m get_currency(volatility_data)\n\u001b[0;32m     25\u001b[0m final_weight \u001b[38;5;241m=\u001b[39m volatility_data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'volatility_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Daniel Chung\n",
    "# The code below collects, reorganizes, and assembles all the data into a final DataFrame \n",
    "# Retrieves the closing price for each stock on November 25, 2023\n",
    "def get_price(volatility_data, date):\n",
    "    price_list = []\n",
    "    for i in range (len(volatility_data.columns)):\n",
    "        ticker_hist = yf.Ticker(volatility_data.columns[i]).history(start=date, interval='1d').dropna()\n",
    "        ticker_hist.index = pd.DatetimeIndex(ticker_hist.index).tz_localize(None)\n",
    "        price_list.append(ticker_hist['Close'].loc[date])\n",
    "    return price_list\n",
    "\n",
    "# Retrieves the currency of each stock\n",
    "def get_currency(volatility_data):\n",
    "    currency_list = []\n",
    "    for i in range(len(volatility_data.columns)):\n",
    "        ticker_info = yf.Ticker(volatility_data.columns[i]).history_metadata\n",
    "        if ticker_info['currency'] == 'USD':\n",
    "            currency_list.append('USD')\n",
    "        elif ticker_info['currency'] == 'CAD':\n",
    "            currency_list.append('CAD')\n",
    "    return currency_list\n",
    "\n",
    "final_close_price = get_price(volatility_data, '2023-11-24') \n",
    "final_currency = get_currency(volatility_data)\n",
    "final_weight = volatility_data.loc['Weight2']*100\n",
    "final_value = final_weight/100*investment\n",
    "\n",
    "# Organizes all the data into a DataFrame\n",
    "Portfolio_Final_Dict = {\"Ticker\": volatility_data.columns,\n",
    "                        \"Price\": final_close_price, \n",
    "                        \"Currency\": final_currency,\n",
    "                        \"Value (CAD)\": final_value,\n",
    "                        \"Weight\": final_weight} \n",
    "    \n",
    "Portfolio_Final = pd.DataFrame(Portfolio_Final_Dict)\n",
    "Portfolio_Final = Portfolio_Final.reset_index(drop=True)\n",
    "Portfolio_Final.index += 1\n",
    "Portfolio_Final['Shares'] = Portfolio_Final['Value (CAD)']/(Portfolio_Final['Price'])\n",
    "\n",
    "Portfolio_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498d9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exports results to csv file\n",
    "Stocks_Final = Portfolio_Final['Shares']\n",
    "Stocks_Final.index = Portfolio_Final['Ticker']\n",
    "Stocks_Final.to_csv('Portfolio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f8f9bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CAD Spent: 749999.9999999998\n",
      "Weighting Sum:  99.99999999999999\n"
     ]
    }
   ],
   "source": [
    "invested_amount = Portfolio_Final['Value (CAD)'].sum()\n",
    "trading_fee = 4.95 * len(Stocks_Final.index)\n",
    "print(\"Total CAD Spent:\", invested_amount + trading_fee)\n",
    "print(\"Weighting Sum: \", Portfolio_Final['Weight'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
