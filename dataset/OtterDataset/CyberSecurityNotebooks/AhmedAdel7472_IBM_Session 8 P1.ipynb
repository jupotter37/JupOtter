{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 10 IBM Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: Prepare a 5-minute presentation that includes:\n",
    "\n",
    "Your career goals \n",
    "\n",
    "Your key learning  \n",
    "\n",
    "Your achievements\n",
    "\n",
    "recorder sessions: •https://drive.google.com/drive/folders/1Gu7aOnRNCHcWHMkO31I0djo1BtuWIkm7?usp=sharing\n",
    "\n",
    "This is the link of the 3 recorded topics:\n",
    "\n",
    "Resume Writing \n",
    "\n",
    "Interviews \n",
    "\n",
    "Personal Branding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 Parsing Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Data for Earth Quackes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"/home/ahmed/Downloads/database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Depth Error</th>\n",
       "      <th>Depth Seismic Stations</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnitude Seismic Stations</th>\n",
       "      <th>Azimuthal Gap</th>\n",
       "      <th>Horizontal Distance</th>\n",
       "      <th>Horizontal Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location Source</th>\n",
       "      <th>Magnitude Source</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1965</td>\n",
       "      <td>13:44:18</td>\n",
       "      <td>19.246</td>\n",
       "      <td>145.616</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>131.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860706</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/04/1965</td>\n",
       "      <td>11:29:49</td>\n",
       "      <td>1.863</td>\n",
       "      <td>127.352</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860737</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/05/1965</td>\n",
       "      <td>18:05:58</td>\n",
       "      <td>-20.579</td>\n",
       "      <td>-173.972</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860762</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/08/1965</td>\n",
       "      <td>18:49:43</td>\n",
       "      <td>-59.076</td>\n",
       "      <td>-23.557</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860856</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/1965</td>\n",
       "      <td>13:32:50</td>\n",
       "      <td>11.938</td>\n",
       "      <td>126.427</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860890</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Latitude  Longitude        Type  Depth  Depth Error  \\\n",
       "0  01/02/1965  13:44:18    19.246    145.616  Earthquake  131.6          NaN   \n",
       "1  01/04/1965  11:29:49     1.863    127.352  Earthquake   80.0          NaN   \n",
       "2  01/05/1965  18:05:58   -20.579   -173.972  Earthquake   20.0          NaN   \n",
       "3  01/08/1965  18:49:43   -59.076    -23.557  Earthquake   15.0          NaN   \n",
       "4  01/09/1965  13:32:50    11.938    126.427  Earthquake   15.0          NaN   \n",
       "\n",
       "   Depth Seismic Stations  Magnitude Magnitude Type  ...  \\\n",
       "0                     NaN        6.0             MW  ...   \n",
       "1                     NaN        5.8             MW  ...   \n",
       "2                     NaN        6.2             MW  ...   \n",
       "3                     NaN        5.8             MW  ...   \n",
       "4                     NaN        5.8             MW  ...   \n",
       "\n",
       "   Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
       "0                         NaN            NaN                  NaN   \n",
       "1                         NaN            NaN                  NaN   \n",
       "2                         NaN            NaN                  NaN   \n",
       "3                         NaN            NaN                  NaN   \n",
       "4                         NaN            NaN                  NaN   \n",
       "\n",
       "   Horizontal Error  Root Mean Square            ID  Source Location Source  \\\n",
       "0               NaN               NaN  ISCGEM860706  ISCGEM          ISCGEM   \n",
       "1               NaN               NaN  ISCGEM860737  ISCGEM          ISCGEM   \n",
       "2               NaN               NaN  ISCGEM860762  ISCGEM          ISCGEM   \n",
       "3               NaN               NaN  ISCGEM860856  ISCGEM          ISCGEM   \n",
       "4               NaN               NaN  ISCGEM860890  ISCGEM          ISCGEM   \n",
       "\n",
       "  Magnitude Source     Status  \n",
       "0           ISCGEM  Automatic  \n",
       "1           ISCGEM  Automatic  \n",
       "2           ISCGEM  Automatic  \n",
       "3           ISCGEM  Automatic  \n",
       "4           ISCGEM  Automatic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        23412 non-null  object \n",
      " 1   Time                        23412 non-null  object \n",
      " 2   Latitude                    23412 non-null  float64\n",
      " 3   Longitude                   23412 non-null  float64\n",
      " 4   Type                        23412 non-null  object \n",
      " 5   Depth                       23412 non-null  float64\n",
      " 6   Depth Error                 4461 non-null   float64\n",
      " 7   Depth Seismic Stations      7097 non-null   float64\n",
      " 8   Magnitude                   23412 non-null  float64\n",
      " 9   Magnitude Type              23409 non-null  object \n",
      " 10  Magnitude Error             327 non-null    float64\n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64\n",
      " 12  Azimuthal Gap               7299 non-null   float64\n",
      " 13  Horizontal Distance         1604 non-null   float64\n",
      " 14  Horizontal Error            1156 non-null   float64\n",
      " 15  Root Mean Square            17352 non-null  float64\n",
      " 16  ID                          23412 non-null  object \n",
      " 17  Source                      23412 non-null  object \n",
      " 18  Location Source             23412 non-null  object \n",
      " 19  Magnitude Source            23412 non-null  object \n",
      " 20  Status                      23412 non-null  object \n",
      "dtypes: float64(12), object(9)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3965/3126586899.py:1: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['newdate'] = pd.to_datetime(df['Date'],format='mixed')#,format=\"%m/%d/%Y\")\n"
     ]
    }
   ],
   "source": [
    "df['newdate'] = pd.to_datetime(df['Date'],format='mixed')#,format=\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        23412 non-null  object \n",
      " 1   Time                        23412 non-null  object \n",
      " 2   Latitude                    23412 non-null  float64\n",
      " 3   Longitude                   23412 non-null  float64\n",
      " 4   Type                        23412 non-null  object \n",
      " 5   Depth                       23412 non-null  float64\n",
      " 6   Depth Error                 4461 non-null   float64\n",
      " 7   Depth Seismic Stations      7097 non-null   float64\n",
      " 8   Magnitude                   23412 non-null  float64\n",
      " 9   Magnitude Type              23409 non-null  object \n",
      " 10  Magnitude Error             327 non-null    float64\n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64\n",
      " 12  Azimuthal Gap               7299 non-null   float64\n",
      " 13  Horizontal Distance         1604 non-null   float64\n",
      " 14  Horizontal Error            1156 non-null   float64\n",
      " 15  Root Mean Square            17352 non-null  float64\n",
      " 16  ID                          23412 non-null  object \n",
      " 17  Source                      23412 non-null  object \n",
      " 18  Location Source             23412 non-null  object \n",
      " 19  Magnitude Source            23412 non-null  object \n",
      " 20  Status                      23412 non-null  object \n",
      " 21  newdate                     23412 non-null  object \n",
      "dtypes: float64(12), object(10)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data isnt in the same format we knew it from the error so we look for a solution for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "10    23409\n",
       "24        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we need to see where the error came from but we know there are 3 values that are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Depth Error</th>\n",
       "      <th>Depth Seismic Stations</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Azimuthal Gap</th>\n",
       "      <th>Horizontal Distance</th>\n",
       "      <th>Horizontal Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location Source</th>\n",
       "      <th>Magnitude Source</th>\n",
       "      <th>Status</th>\n",
       "      <th>newdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>1975-02-23T02:58:41.000Z</td>\n",
       "      <td>1975-02-23T02:58:41.000Z</td>\n",
       "      <td>8.017</td>\n",
       "      <td>124.075</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>MB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USP0000A09</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>1975-02-23 02:58:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>1985-04-28T02:53:41.530Z</td>\n",
       "      <td>1985-04-28T02:53:41.530Z</td>\n",
       "      <td>-32.998</td>\n",
       "      <td>-71.766</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>USP0002E81</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>HRV</td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>1985-04-28 02:53:41.530000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20650</th>\n",
       "      <td>2011-03-13T02:23:34.520Z</td>\n",
       "      <td>2011-03-13T02:23:34.520Z</td>\n",
       "      <td>36.344</td>\n",
       "      <td>142.344</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>289.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MWC</td>\n",
       "      <td>...</td>\n",
       "      <td>32.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>USP000HWQP</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>GCMT</td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>2011-03-13 02:23:34.520000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date                      Time  Latitude  \\\n",
       "3378   1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017   \n",
       "7512   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n",
       "20650  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n",
       "\n",
       "       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n",
       "3378     124.075  Earthquake  623.0          NaN                     NaN   \n",
       "7512     -71.766  Earthquake   33.0          NaN                     NaN   \n",
       "20650    142.344  Earthquake   10.1         13.9                   289.0   \n",
       "\n",
       "       Magnitude Magnitude Type  ...  Azimuthal Gap  Horizontal Distance  \\\n",
       "3378         5.6             MB  ...            NaN                  NaN   \n",
       "7512         5.6             MW  ...            NaN                  NaN   \n",
       "20650        5.8            MWC  ...           32.3                  NaN   \n",
       "\n",
       "       Horizontal Error  Root Mean Square          ID  Source Location Source  \\\n",
       "3378                NaN               NaN  USP0000A09      US              US   \n",
       "7512                NaN              1.30  USP0002E81      US              US   \n",
       "20650               NaN              1.06  USP000HWQP      US              US   \n",
       "\n",
       "      Magnitude Source    Status                           newdate  \n",
       "3378                US  Reviewed         1975-02-23 02:58:41+00:00  \n",
       "7512               HRV  Reviewed  1985-04-28 02:53:41.530000+00:00  \n",
       "20650             GCMT  Reviewed  2011-03-13 02:23:34.520000+00:00  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Date'].str.len()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                           1975-02-23T02:58:41.000Z\n",
       "Time                           1975-02-23T02:58:41.000Z\n",
       "Latitude                                          8.017\n",
       "Longitude                                       124.075\n",
       "Type                                         Earthquake\n",
       "Depth                                             623.0\n",
       "Depth Error                                         NaN\n",
       "Depth Seismic Stations                              NaN\n",
       "Magnitude                                           5.6\n",
       "Magnitude Type                                       MB\n",
       "Magnitude Error                                     NaN\n",
       "Magnitude Seismic Stations                          NaN\n",
       "Azimuthal Gap                                       NaN\n",
       "Horizontal Distance                                 NaN\n",
       "Horizontal Error                                    NaN\n",
       "Root Mean Square                                    NaN\n",
       "ID                                           USP0000A09\n",
       "Source                                               US\n",
       "Location Source                                      US\n",
       "Magnitude Source                                     US\n",
       "Status                                         Reviewed\n",
       "newdate                       1975-02-23 02:58:41+00:00\n",
       "Name: 3378, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3378]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we accessed the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['newdate']=df['Date'].apply(lambda x:x[:10]) #this function will take only the first 10 letters for all the data not only the 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3965/1051180446.py:1: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['newdate'] = pd.to_datetime(df['Date'],format='mixed')\n"
     ]
    }
   ],
   "source": [
    "df['newdate'] = pd.to_datetime(df['Date'],format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        23412 non-null  object \n",
      " 1   Time                        23412 non-null  object \n",
      " 2   Latitude                    23412 non-null  float64\n",
      " 3   Longitude                   23412 non-null  float64\n",
      " 4   Type                        23412 non-null  object \n",
      " 5   Depth                       23412 non-null  float64\n",
      " 6   Depth Error                 4461 non-null   float64\n",
      " 7   Depth Seismic Stations      7097 non-null   float64\n",
      " 8   Magnitude                   23412 non-null  float64\n",
      " 9   Magnitude Type              23409 non-null  object \n",
      " 10  Magnitude Error             327 non-null    float64\n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64\n",
      " 12  Azimuthal Gap               7299 non-null   float64\n",
      " 13  Horizontal Distance         1604 non-null   float64\n",
      " 14  Horizontal Error            1156 non-null   float64\n",
      " 15  Root Mean Square            17352 non-null  float64\n",
      " 16  ID                          23412 non-null  object \n",
      " 17  Source                      23412 non-null  object \n",
      " 18  Location Source             23412 non-null  object \n",
      " 19  Magnitude Source            23412 non-null  object \n",
      " 20  Status                      23412 non-null  object \n",
      " 21  newdate                     23412 non-null  object \n",
      "dtypes: float64(12), object(10)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['newdate'] = pd.to_datetime(df['newdate'],format='mixed',utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   Date                        23412 non-null  object             \n",
      " 1   Time                        23412 non-null  object             \n",
      " 2   Latitude                    23412 non-null  float64            \n",
      " 3   Longitude                   23412 non-null  float64            \n",
      " 4   Type                        23412 non-null  object             \n",
      " 5   Depth                       23412 non-null  float64            \n",
      " 6   Depth Error                 4461 non-null   float64            \n",
      " 7   Depth Seismic Stations      7097 non-null   float64            \n",
      " 8   Magnitude                   23412 non-null  float64            \n",
      " 9   Magnitude Type              23409 non-null  object             \n",
      " 10  Magnitude Error             327 non-null    float64            \n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64            \n",
      " 12  Azimuthal Gap               7299 non-null   float64            \n",
      " 13  Horizontal Distance         1604 non-null   float64            \n",
      " 14  Horizontal Error            1156 non-null   float64            \n",
      " 15  Root Mean Square            17352 non-null  float64            \n",
      " 16  ID                          23412 non-null  object             \n",
      " 17  Source                      23412 non-null  object             \n",
      " 18  Location Source             23412 non-null  object             \n",
      " 19  Magnitude Source            23412 non-null  object             \n",
      " 20  Status                      23412 non-null  object             \n",
      " 21  newdate                     23412 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), float64(12), object(9)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['newdate']=df['Date'].apply(lambda x:x.split('T')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['newdate'] = pd.to_datetime(df['Date'].apply(lambda x: x.split('T')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1 Incosistency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"/home/ahmed/Downloads/pakistan_intellectual_capital.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S#</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>University Currently Teaching</th>\n",
       "      <th>Department</th>\n",
       "      <th>Province University Located</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Terminal Degree</th>\n",
       "      <th>Graduated from</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area of Specialization/Research Interests</th>\n",
       "      <th>Other Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Dr. Abdul Basit</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineering &amp; DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Dr. Waheed Noor</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Dr. Junaid Baber</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information processing, Multimedia mining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Dr. Maheen Bakhtyar</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP, Information Retrieval, Question Answering...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>Samina Azim</td>\n",
       "      <td>Sardar Bahadur Khan Women's University</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>BS</td>\n",
       "      <td>Balochistan University of Information Technolo...</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>VLSI Electronics DLD Database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S#         Teacher Name  \\\n",
       "0           2   3      Dr. Abdul Basit   \n",
       "1           4   5      Dr. Waheed Noor   \n",
       "2           5   6     Dr. Junaid Baber   \n",
       "3           6   7  Dr. Maheen Bakhtyar   \n",
       "4          24  25          Samina Azim   \n",
       "\n",
       "            University Currently Teaching             Department  \\\n",
       "0               University of Balochistan  Computer Science & IT   \n",
       "1               University of Balochistan  Computer Science & IT   \n",
       "2               University of Balochistan  Computer Science & IT   \n",
       "3               University of Balochistan  Computer Science & IT   \n",
       "4  Sardar Bahadur Khan Women's University       Computer Science   \n",
       "\n",
       "  Province University Located          Designation Terminal Degree  \\\n",
       "0                 Balochistan  Assistant Professor             PhD   \n",
       "1                 Balochistan  Assistant Professor             PhD   \n",
       "2                 Balochistan  Assistant Professor             PhD   \n",
       "3                 Balochistan  Assistant Professor             PhD   \n",
       "4                 Balochistan             Lecturer              BS   \n",
       "\n",
       "                                      Graduated from   Country    Year  \\\n",
       "0                      Asian Institute of Technology  Thailand     NaN   \n",
       "1                      Asian Institute of Technology  Thailand     NaN   \n",
       "2                      Asian Institute of Technology  Thailand     NaN   \n",
       "3                      Asian Institute of Technology  Thailand     NaN   \n",
       "4  Balochistan University of Information Technolo...  Pakistan  2005.0   \n",
       "\n",
       "           Area of Specialization/Research Interests Other Information  \n",
       "0                        Software Engineering & DBMS               NaN  \n",
       "1                                               DBMS               NaN  \n",
       "2          Information processing, Multimedia mining               NaN  \n",
       "3  NLP, Information Retrieval, Question Answering...               NaN  \n",
       "4                      VLSI Electronics DLD Database               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1142 entries, 0 to 1141\n",
      "Data columns (total 13 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Unnamed: 0                                 1142 non-null   int64  \n",
      " 1   S#                                         1142 non-null   int64  \n",
      " 2   Teacher Name                               1142 non-null   object \n",
      " 3   University Currently Teaching              1142 non-null   object \n",
      " 4   Department                                 1142 non-null   object \n",
      " 5   Province University Located                1142 non-null   object \n",
      " 6   Designation                                1123 non-null   object \n",
      " 7   Terminal Degree                            1138 non-null   object \n",
      " 8   Graduated from                             1142 non-null   object \n",
      " 9   Country                                    1142 non-null   object \n",
      " 10  Year                                       489 non-null    float64\n",
      " 11  Area of Specialization/Research Interests  623 non-null    object \n",
      " 12  Other Information                          124 non-null    object \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 116.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Name\n",
      "['Dr. Abdul Basit' 'Dr. Waheed Noor' 'Dr. Junaid Baber' ...\n",
      " 'Dr. Rashad M Jillani' 'Dr. Shahabuddin Ansari' 'Dr. Sajid Anwar']\n",
      "------------------------------------------\n",
      "University Currently Teaching\n",
      "['University of Balochistan' \"Sardar Bahadur Khan Women's University\"\n",
      " 'University of Turbat' 'COMSATS, Islamabad Campus'\n",
      " 'National University of Sciences and Technology' 'RIPHAH International'\n",
      " 'FAST-NU(Islamabad)' 'International Islamic University,Islamabad'\n",
      " 'National University of Modern Languages' 'Air University'\n",
      " 'Bahria University,Islamabad'\n",
      " 'Capital University of Science and Technology'\n",
      " 'Pakistan Institute of Engineering and Applied Sciences'\n",
      " 'University of Sargodha,Mandi Bahauddin Campus' 'NAML-Mianwali'\n",
      " 'University of Lahore-PakPattan' 'University of Sahiwal'\n",
      " 'Barani Institute of Information and Technology'\n",
      " 'Fatima Jinnah Women University' 'FAST(Faisalabad)'\n",
      " 'University of Central Punjab' 'Lahore Garrison University'\n",
      " 'Punjab University College of Information and Technology' 'FAST(Lahore)'\n",
      " 'Information Technology University'\n",
      " 'Lahore University of Management Sciences' 'Virtual University'\n",
      " 'University of Management and Technology' 'Minhaj University Lahore'\n",
      " 'Beaconhouse National University'\n",
      " 'Shaheed Zulfikar Ali Bhutto Institute of Science and Technology'\n",
      " 'QUAID-E-AWAM UNIVERSITY OF ENGINEERING, SCIENCE & TECHNOLOGY,NAWABSHAH\\n'\n",
      " 'Shah Abdul Latif University, Khairpur'\n",
      " 'Shaheed Benazir Bhutto University,Shaheed Benazirabad\\n'\n",
      " 'University of Sindh' 'FAST(Karachi)' 'University of Karachi' 'NED,UET'\n",
      " 'Institute of Business Administration, Karachi\\xa0'\n",
      " 'Institute of Business Administration,Sukkur' 'ISRA University'\n",
      " 'Sir Syed University of Engineering and Technology'\n",
      " 'Jinnah University for Women' 'DHA Suffa University'\n",
      " 'PAF-Karachi Institute of Economics and Technology'\n",
      " 'Mohammad Ali Jinnah University' 'Habib University'\n",
      " 'Islamia University Bhawalpur' 'University of Chakwal'\n",
      " 'Government College University Faisalabad'\n",
      " 'National Textile University,Faisalabad'\n",
      " 'NFC Institute of Engineering and Fertilizer Research'\n",
      " 'Riphah University,Faisalabad' 'Gift University'\n",
      " 'Punjab University,Gujranwala Campus' 'University of Gujrat'\n",
      " 'University of Peshawar'\n",
      " 'University of Engineering and Technology,Peshawar'\n",
      " 'University of Agriculture,Peshawar' 'FAST,Peshawar' 'City University'\n",
      " 'Abasyn University' 'Ghulam Ishaq Khan Institute']\n",
      "------------------------------------------\n",
      "Department\n",
      "['Computer Science & IT' 'Computer Science' 'Computing'\n",
      " 'Computer Science and Software Engineering'\n",
      " 'Computer and Information Sciences' 'Computer Science and IT'\n",
      " 'Software Engineering' 'Computer Sciences' 'Information Technology'\n",
      " 'CS & IT' 'School of Information and Technology'\n",
      " 'Institute of Mathematics & Computer Science'\n",
      " 'ENGINEERING, SCIENCE & TECHNOLOGY' 'Computer Engineering'\n",
      " 'Computing & Information Sciences' 'FACULTY OF COMPUTING & ENGINEERING'\n",
      " 'Computer Science and Engineering']\n",
      "------------------------------------------\n",
      "Province University Located\n",
      "['Balochistan' 'Capital' 'Punjab' 'Sindh' 'KPK']\n",
      "------------------------------------------\n",
      "Designation\n",
      "['Assistant Professor' 'Lecturer' 'Head of Department' 'Professor'\n",
      " 'Chief Scientific Officer' 'Associate Professor' 'Dean'\n",
      " 'Professor/Associate Dean (Research)' nan 'Professor/HoD'\n",
      " 'Associate Professor/Chairman' 'Assistant Professor/Acting Chairperson'\n",
      " 'Senior Assistant Professor' 'Senior Lecturer' 'Jr.Lecturer'\n",
      " 'Professor/Dean' 'Head' 'Controller of Examinations'\n",
      " 'Associate Professor/HoD' 'HEC Approved PhD Supervisor' 'Instructor'\n",
      " 'Principal' 'Adjunct Professor' 'Vice Chancellor'\n",
      " 'Associate Professor/Chairperson' 'Associate Professor/Chair'\n",
      " 'Tutor/Instructor' 'Research Associate' 'Chairman' 'I.T Manager'\n",
      " 'Assistant Professor/HoD ' 'Vice President/Dean' 'Professor/Chairman'\n",
      " 'Professor/Director & Registrar' 'Professor/Co-Chairman'\n",
      " 'Professor/Chairperson' 'Director' 'Permanent Faculty' 'Faculty Member'\n",
      " 'Assistant Professor/Director' 'Lab Engineer'\n",
      " 'Assistant Professor/Chairman' 'Assistant Professor/Principal'\n",
      " 'Teaching Fellow' 'Assistant Professor/Incharge Department'\n",
      " 'Departmental Assistant' 'Teaching Assistant']\n",
      "------------------------------------------\n",
      "Terminal Degree\n",
      "['PhD' 'BS' 'MCS' 'MS' 'BE' 'Phd' nan 'PostDoc' 'Masters' 'MBA' 'MSc'\n",
      " 'BIT' 'MA' 'Mphil' 'MPhil' 'Post Doc' ' MCS' 'MIT' 'BSC' 'MSCS' 'BSIT'\n",
      " 'MSC' 'M.Phil' 'Master' 'Bachelors' 'M.Phil leading to PhD' 'BSCS' 'M.Sc'\n",
      " 'BCS' 'ME' 'B.Ed' 'M.A' 'M.Eng' 'MCIT' 'B.E' 'M.E' 'MSIT' 'Ph.D' 'MSSE'\n",
      " 'MSTN' 'Doctor of Professional Studies' 'BSc' 'BA']\n",
      "------------------------------------------\n",
      "Graduated from\n",
      "['Asian Institute of Technology'\n",
      " 'Balochistan University of Information Technology, Engineering and Management Sciences'\n",
      " 'University of Balochistan' \"Sardar Bahadur Khan Women's University\"\n",
      " 'SRH Hochschule Heidelberg'\n",
      " 'Institute of Business Administration,Karachi' 'DUET,Karachi'\n",
      " 'University of Turbat' 'University of Vienna' 'Monash University'\n",
      " 'University of Stirling' 'Chinese Academy of Sciences'\n",
      " 'University of Innsbruck' 'Vienna University of Technology'\n",
      " 'University of Paris-Est' 'The University of Cambridge'\n",
      " 'Harbin Institute of Technology' 'University of Nice, Sophia Antipolis'\n",
      " 'The University of York' 'Galilée - Université Paris 13'\n",
      " 'University of Bedfordshire' 'North Dakota State University'\n",
      " 'Kyungpook National University' 'The University of Manchester'\n",
      " 'National University of Sciences and Technology'\n",
      " 'FAST– National University of Computer and Emerging Sciences'\n",
      " 'Capital University of Science & Technology' 'Gomal University'\n",
      " 'University of Malaya' 'KTH Royal Institute of Technology'\n",
      " 'University of Technology' 'COMSATS Institute of Information Technology'\n",
      " 'Government College University' 'Mohammad Ali Jinnah University'\n",
      " 'Shaheed Zulfikar Ali Bhutto Institute of Science and Technology'\n",
      " 'Blekinge Institute of Technology' 'University of Grenoble'\n",
      " 'Politecnico di Torino' '\\xa0University of Missouri, KC'\n",
      " 'University of Bonn' 'University of Paris' 'The University of Leeds'\n",
      " '\\xa0University of Windsor'\n",
      " '\\xa0National University of Sciences and Technology-NIIT'\n",
      " 'University of Trento' 'Stockholm University'\n",
      " 'University of New South Wales, Sydney' 'Kingston University London'\n",
      " 'Griffith University' 'University of Salford' 'Loughborough University'\n",
      " 'International Islamic University,Islamabad'\n",
      " 'University of Central Missouri' 'Riphah International University'\n",
      " 'University of BedfordShire' 'University of Illinois'\n",
      " 'University Of Oslo' 'Nancy 2 University' 'University of Limerick'\n",
      " 'Ghulam Ishaq Khan Institute of Science and Technology'\n",
      " 'University Of Waterloo' 'University of Stuttgart'\n",
      " 'Liverpool John Moores University' 'University Of Caen'\n",
      " 'Paris Tech University of Eurecom' 'University Of Salford'\n",
      " 'Lahore University of Management Sciences'\n",
      " 'Dresden University Of Technology, Dresden\\xa0'\n",
      " 'COMSATS Institute of Information Technology,Vehari'\n",
      " 'COMSATS Institute of Information Technology,Wah Cantt' 'TU Berlin'\n",
      " 'FAST– National University of Computer and Emerging Sciences,Islamabad'\n",
      " 'Tsinghua University' 'The University of Auckland' 'IQRA University'\n",
      " 'Universiti Teknologi PETRONAS'\n",
      " 'COMSATS Institute of Information Technology,Islamabad'\n",
      " 'Razak School of Engineering and Advanced Technology, Universiti Teknologi Malaysia (UTM)'\n",
      " 'National University of Modern Languages'\n",
      " 'University of Engineering and Technology'\n",
      " 'University Institute of Information Technology'\n",
      " 'University of Arid Agriculture' 'Quaid-i-Azam University'\n",
      " 'Queen Mary University of London'\n",
      " 'Pakistan Institute of Engineering and Applied Sciences'\n",
      " 'Pohang University of Science and Technology' 'Uppsala University'\n",
      " 'Kyung Hee University' 'University of Liverpool'\n",
      " 'University of Sunderland' 'Mid Sweden University'\n",
      " 'Bahria University,Islamabad' 'Chosun University' 'University of Sussex'\n",
      " 'Paris Descartes University' 'University of Leicester'\n",
      " 'University of Porto' 'University of Manchester'\n",
      " 'Université Henri Poincaré, Nancy 1,' 'Bahria University'\n",
      " 'Centre for Advanced Studies in Engineering'\n",
      " 'Norwegian University of Science and Technology (NTNU),'\n",
      " 'The Islamia University of Bahawalpur ' 'Universiti Technologi'\n",
      " 'California State University' 'University of Genova'\n",
      " 'University of Engineering and Technology,Taxila'\n",
      " 'University of\\xa0Liverpool John Moores University' 'Guildford'\n",
      " 'University of Bradford' 'Graz University of Technology'\n",
      " 'Huazhong University of Science and Technology (HUST), Wuhan'\n",
      " 'University of Konstanz'\n",
      " 'National University of Modern Languages,Islamabad'\n",
      " 'FAST– National University of Computer and Emerging Sciences,Lahore'\n",
      " 'Gwangju Institute of Science and Technology' 'University of Birmingham'\n",
      " 'Manchester University' 'Beijing Institute of Technology'\n",
      " 'University of Paisley'\n",
      " 'Univ of Porto/Univ of Aveiro Portugal/Uni of Minho'\n",
      " 'University of Peshawar' 'Universität Salzburg'\n",
      " 'Colorado State University' 'University of Virginia'\n",
      " 'University of Orleans' 'Zhejiang University' 'University of Leeds'\n",
      " 'Foundation University' 'Barani Institute of Information Technology'\n",
      " 'Abasyn University' 'Pir Mehr Ali Shah Arid Agriculture University'\n",
      " 'Preston' 'University of Bergen' 'Universtiy of Lahore'\n",
      " 'HITEC University,Taxila' 'Allama Iqbal Open University'\n",
      " 'University of Wales,Aberystwyth' '\\xa0University of Bonn'\n",
      " '\\xa0Hongik University'\n",
      " 'Skolkovo Institute of Science and Technology,\\xa0'\n",
      " 'Agricultural University Peshawar' 'National Textile University'\n",
      " 'FAST– National University of Computer and Emerging Sciences,Chiniot-Faisalabad'\n",
      " 'FAST– National University of Computer and Emerging Sciences,Peshawar'\n",
      " '\\xa0Boston University' 'Brunel University'\n",
      " 'George Washington University' 'University of the Punjab'\n",
      " '\\xa0University of Bedfordshire' 'University Of Southern California'\n",
      " 'Beihang University' 'Institute of Business Administration'\n",
      " 'Abdus Salam School of Mathematical Sciences,GC University'\n",
      " 'Linköping University'\n",
      " 'National College of Business Administration and Economics'\n",
      " 'Åbo Akademi University,' 'University of Central Punjab'\n",
      " 'University of Ulm' 'University of Agriculture'\n",
      " 'University of Notre Dame Indiana\\xa0'\n",
      " 'Punjab University College of Information Technology'\n",
      " 'Ilmenau University of Technology' ' Iowa State University'\n",
      " ' University of Innsbruck' 'Vrije University, Amsterdam'\n",
      " ' Columbia University' 'University of Freiburg'\n",
      " ' Delft University of Technology'\n",
      " ' University of Texas at Arlington (UTA)' ' University of Turin'\n",
      " ' University of Central Florida' 'Saarland University'\n",
      " 'University of Central Florida' 'Oxford Brookes University'\n",
      " 'Information Technology University (ITU)' 'University of Canterbury'\n",
      " 'University of Patras' 'Middle East Technical University'\n",
      " 'University of Bristol' 'University of Southern California'\n",
      " 'Northeastern University,Boston' 'Purdue University'\n",
      " 'University of Plymouth' 'University of South Australia'\n",
      " 'Stanford University' 'Chalmers University of Technology'\n",
      " 'Massachusetts Institute of Technology' 'Sapienza University of Rome'\n",
      " 'Eindhoven University of Technology (TU/e)'\n",
      " 'United Nations University International Institute for Software Technology (UNU-IIST)'\n",
      " 'Georgetown University,DC' 'RWTH Aachen University' 'Columbia University'\n",
      " 'Rutgers State University of New Jersey, NJ' 'University of Florida'\n",
      " 'Technical University of Braunschweig'\n",
      " 'Carnegie Mellon University, Pittsburgh' 'The Ohio State University'\n",
      " 'National University of Singapore' 'University of British Columbia'\n",
      " 'University of Pittsburgh' 'The State University of New Jersey'\n",
      " 'The University of Texas at Austin'\n",
      " 'Imperial College, University of London' 'University of Colorado\\xa0'\n",
      " 'University of Bath' 'Tilburg University'\n",
      " 'Pompeu Fabra University Barcelona'\n",
      " 'University of Management and Technology'\n",
      " 'COMSATS Institute of Information Technology,Lahore'\n",
      " 'University of Agriculture, Faisalabad\\xa0'\n",
      " 'University of Engineering & Technology'\n",
      " 'University of Agriculture, Faisalabad'\n",
      " 'Fatima Jinnah Women University, Rawalpindi'\n",
      " 'Kohat University of Science & Technology, Kohat'\n",
      " 'Virtual University of Pakistan' 'Bahauddin Zakariya University'\n",
      " 'University of the Punjab,Gujranwala'\n",
      " 'Lahore College for Women University' 'Superior University, Lahore'\n",
      " 'Shaheed Zulfikar Ali Bhutto Institute of Science and Technology,Islamabad'\n",
      " 'University of South Florida' 'Politecnico di Milano'\n",
      " 'Abdul Wali Khan University, Mardan' 'University of Lahore'\n",
      " 'Minhaj University Lahore' 'Lahore Leads University'\n",
      " 'Middlesex University' 'Beijing Institute of Technology Beijing'\n",
      " 'Beaconhouse National University' 'Hamdard University' 'University Paris'\n",
      " 'Sindh University' 'NED University of Engineering And Technology'\n",
      " 'Staffordshire University' 'DePaul University, Chicago'\n",
      " 'University of Kent' 'Mehran University of Engineering & Technology'\n",
      " 'Quaid-e-Awam University of Engineering, Science & Technology'\n",
      " 'Shah Abdul Latif University, Khairpur' 'Sindh Agriculture University'\n",
      " 'Swansea' 'University of Shanghai for Science and Technology'\n",
      " 'Griffith University,Nathan Campus' 'University of Essex'\n",
      " 'Xiamen university' 'Wayne State University'\n",
      " 'The Queens University of Belfast' 'Sungkyunkwan University'\n",
      " 'Nanyang Tech University' \"Universite d'Evry Val d'Essonne\"\n",
      " 'Sir Syed University of Engineering and Technology'\n",
      " 'New York Institute of Technology' 'Fedral Urdu University'\n",
      " 'ISRA University' 'University of Karachi' 'South Asian University'\n",
      " 'Capital University of Science and Technology'\n",
      " 'University of Manchester Institute of Science and Technology'\n",
      " 'The University of Birmingham'\n",
      " 'Max Planck Institute for Computer Science' 'George Mason University'\n",
      " 'University of Southampton' 'Temple University' 'University of Bayreuth'\n",
      " 'Muroran Institute of Technology,Hokkaido' 'University of Bologna'\n",
      " 'International Islamic University'\n",
      " 'PAF-Karachi Institute of Economics and Technology'\n",
      " 'Institute of Business Administration,Sukkur' 'Myongji University'\n",
      " 'State University of New York System' 'SSindh Agriculture University'\n",
      " 'London University' 'Universiti Putra Malaysia Putra'\n",
      " 'University of Rome Tor Vergata' 'University of Mississippi\\xa0'\n",
      " 'University of Wales' 'University of Northampton'\n",
      " 'University of Abertay Dundee'\n",
      " 'Biztek Institute Of Business & Technology,Karachi'\n",
      " 'University of Surrey' 'Jinnah University for Women'\n",
      " '\\xa0Nanyang Technological University' 'Tokyo Institute of Technology'\n",
      " 'NCSU' 'Usman Institute of Technology' 'Hanyang University, Ansan' 'BUKC'\n",
      " 'Universtiy of Karachi' 'Pace University, New York' 'INSA de Lyon, Rhone'\n",
      " 'University of Dundee' 'Illinois Institute of Technology'\n",
      " 'City University of Science and Technology'\n",
      " 'Usman Institute of Technology (Hamdard University)'\n",
      " 'University of Malaga' 'Manchester Metropolitan University'\n",
      " 'Kyushu University,Fukuoka'\n",
      " 'King Abdullah University of Science and Technology'\n",
      " 'INRIA Saclay Ile-de-France' 'Université de la Rochelle'\n",
      " 'University of South Brittany' 'Aston University, Birmingham'\n",
      " 'University of Agriculture Faisalabad' 'Hamburg University of Technology'\n",
      " 'Government College University, Faisalabad' 'JKU' 'University of Oviedo'\n",
      " 'Beijing University of Posts & Telecommunications'\n",
      " 'Government College University,Faisalabad' 'Nottingham Trent University'\n",
      " 'University of Glasgow' 'Coventry University'\n",
      " 'Riphah International University,Faisalabad'\n",
      " 'Australian National University, Caneberra'\n",
      " 'Swedish University of Agricultural Sciences, Uppsala'\n",
      " 'University of Gujrat' 'IQRA University,Islamabad' 'Jonkoping University'\n",
      " 'Colorado Technical University' 'Cranfield University'\n",
      " 'Technical University of Graz' 'University of York'\n",
      " 'Brock University Canada' 'University of Westminster'\n",
      " 'University of Saarland' 'The University of Queensland'\n",
      " 'University of Rochester' 'Islamia College University '\n",
      " 'IBMS KP Agricultural University Peshawar' 'University of Kuala Lumpur'\n",
      " 'University of Regina' 'TU Wien' 'Swinburne University Of Technology'\n",
      " 'Institute Of Managment Sciences, Peshawar'\n",
      " 'Universiti Tun Hussein Onn Malaysia'\n",
      " 'Institute of Management Sciences, Peshawar' 'University of Huddersfield'\n",
      " 'University of Engineering and Technology,Peshawar'\n",
      " 'IQRA University,Karachi' 'John Moorse University, Liverpool'\n",
      " 'CECOS University of Information Technology and Emerging Sciences,Peshawar'\n",
      " 'University of the West Scotland' 'Concordia University,Montreal' 'JNU'\n",
      " 'Grenoble' 'Florida Atlantic University' 'Seoul National University']\n",
      "------------------------------------------\n",
      "Country\n",
      "['Thailand' 'Pakistan' 'germany' 'Austria' 'Australia' 'UK' 'China'\n",
      " 'France' 'USofA' 'SouthKorea' 'Malaysia' 'Sweden' 'Italy' 'Canada'\n",
      " 'Norway' 'Ireland' 'New Zealand' 'Urbana' 'Portugal' 'Russian Federation'\n",
      " 'USA' 'Finland' ' USA' 'Netherland' ' Germany' ' Sweden' ' New Zealand'\n",
      " 'Greece' 'Turkey' 'South Korea' 'Macau' 'Singapore' 'Spain' 'Japan'\n",
      " 'HongKong' 'Saudi Arabia' 'Mauritius' 'Scotland']\n",
      "------------------------------------------\n",
      "Area of Specialization/Research Interests\n",
      "['Software Engineering & DBMS' 'DBMS'\n",
      " 'Information processing, Multimedia mining'\n",
      " 'NLP, Information Retrieval, Question Answering system'\n",
      " 'VLSI Electronics DLD Database'\n",
      " 'Software Engineering, Computer Networks.'\n",
      " 'Human computer Interaction, Web Development, Software Engineering, Networking'\n",
      " 'Human Computer Interaction, Web' 'JAVA Programming' 'Programming'\n",
      " 'Object Detection, Object Tracking, Pattern Recognition, Human Computer Interaction, Software Engineering, Data Structures and Algorithms, Object Oriented Programming'\n",
      " 'Semantic Web, Machine Learning' 'Semantic Web'\n",
      " 'Computer Graphics, Digital Logic Design, Software Engineering, Operating Systems, Artificial Intelligence'\n",
      " 'Data Structures & Algorithms, Programming'\n",
      " 'Software Engineering, Theory of Automata and Formal Languages'\n",
      " 'wireless sensor networks, MANETS and internet of things'\n",
      " 'Machine Learning and Data mining, decision support system and business intelligence, big data analytics, outcome based education'\n",
      " 'Complex Communication Networks such as Internet of Things, Online social networks, Wireless Sensor networks etc. Biological Networks Modeling and Simulation, Agent-based Computing.'\n",
      " 'Mining Data Streams, Ubiquitous Data Mining, Intrusion Detection, Distributed Data Mining, Machine learning and data mining, Real-Time system; Publish/Subscribe system; Wireless Sensor Networks, Active databases ECA Rules'\n",
      " 'software pipelining, chromatic scheduling, reliable computing and real-time systems'\n",
      " 'system administration and research and development' nan\n",
      " 'Wireless Ad-hoc, Sensor, Vehicular and Body Area Networks'\n",
      " 'modelling and simulating change/business processes, software engineering for mobile applications.'\n",
      " '\\xa0Information security & privacy, Distributed Computing, Knowledge-Based Systems, Data provenance and Semantic Web Technologies.\\xa0'\n",
      " 'security & privacy of cloud computing(outsourced storage & computation), security protocols, Digital watermarking, Secure Provenance'\n",
      " 'Image processing, computer vision, information security'\n",
      " '\\xa0Natural Language Processing (NLP), which falls under the broader category of Artificial Intelligence. Dr. Shahid is interested in building multilingual, bilingual and monolingual resources using supervised and unsupervised learning approaches. He is also interested in applications of Machine Learning approaches.'\n",
      " 'Routing, medium access control, resource allocation and security related issues in: Internet of Things, cloud computing, Wireless Ad hoc Networks (Sensor networks, vehicular networks, cognitive radio networks, delay tolerant networks) & smart grids.\\xa0Moreover, I am interested in applications of algorithmic game theory to various problems in wireless networks and global software development.'\n",
      " '\\xa0MAC protocol design, Internet of Things, and security issues in wireless communication systems'\n",
      " 'Collaborative systems, Social Network Analysis, Information privacy, and Access Control'\n",
      " '\\xa0Formal Methods (verification, modeling, and analysis) of Large Scale Systems, such as Cloud Computing System'\n",
      " 'Vehicular Ad-hoc Network, Wireless Sensor Network, Underwater Wireless Sensor Network, Cyber Physical Systems, Software defined Networking, Information-centric Networking.'\n",
      " 'query processing in wireless sensor network, distributed spatial analysis, distributed computing using ad hoc wireless networks.'\n",
      " 'Wireless Sensor Networks. She is interested in the design and performance evaluation of communication protocols for wireless ad hoc and sensor networks. She is also interested in Information Centric Networks.'\n",
      " 'Artificial Intelligence, Data Mining, Machine Learning, Software Engineering, Requirement Engineering.'\n",
      " 'routing issues on\\xa0Wireless Sensor Networks or Wireless Body Area Networks.'\n",
      " '\\xa0Computer Security and Application of Cellular Automata.'\n",
      " 'Object Oriented Programming, Visual Programming, Software Project Management and Model Transformation.'\n",
      " 'Software Project Management and Software Engineering.'\n",
      " 'Smart Health, Big Data Analytics, Recommendation Systems, Patent Analysis, and Social Network Analysis'\n",
      " 'Software Process Improvement, Requirements Engineering & Software Development Outsourcing\\xa0'\n",
      " '\\xa0interactive systems, human computer interaction, ubiquitous computing and multimodal interfaces.'\n",
      " 'n HCI in general and usability evaluation / user experience\\xa0'\n",
      " 'Underwater Wireless Sensor Networks and Energy Management.'\n",
      " '\\xa0Natural Language Processing, Machine Learning, and Text Mining.'\n",
      " '\\xa0Secure & Dependable Software Defined Networks, Man-at-the-End Attacks Plus Human Attacker Attribution & Profiling, Large Scale Distributed Systems (Fog, Edge, and Cloud Computing (CC), Mobile Cloud Computing (MCC) etc.), Remote Data Auditing, Light Weight Cryptography, Blockchain and Cryptocurrency.'\n",
      " 'Software Testing, Object Oriented Analysis and Design, and Formal Methods'\n",
      " 'Business Intelligence, Information System Management and E-Commerce.'\n",
      " 'Visual Perception, Computer Vision, GPGPU'\n",
      " 'Native Simulation of MPSoC, Virtualization, Software Performance Estimation and Binary Translation'\n",
      " 'Parallel and Distributed Simulation'\n",
      " 'Question Answering, Credibility Assessment, Information Retrieval, Information Processing, Semantic Web'\n",
      " 'Energy Efficiency in Telecommunication Networks, Optical Network Optimization'\n",
      " 'Wireless Networks'\n",
      " 'Wireless Sensor Networks, IOT, Image Encryption and Compression, Localization'\n",
      " 'Human motion analysis, character animation, inertial based motion analysis, ubiquitous computing, robotics'\n",
      " 'Localization in wireless sensor networks; Soft computing techniques'\n",
      " 'Surgical Robotics, Mathematical Modeling, Fuzzy Controllers'\n",
      " 'Databases, Information Retrieval' 'Management and Technology in general'\n",
      " 'Distributed Computing' 'e-learning, Big Data, Application Development'\n",
      " 'Machine Learning'\n",
      " 'Wireless Sensor Networks, Data Centre Networking, Software Defined Networking'\n",
      " 'Pattern Recognition, Computer Vision and Machine Learning, Medical Image Analysis'\n",
      " 'Scientific and Information Visualization, Comparative Visualization, Industrial CT (HEC Approved PhD Supervisor)'\n",
      " 'Software Enginneering, System Modeling and Analysis, Formal Verification'\n",
      " 'Software Engineering, Requirements Engineering, Software Quality, Software Engineering Education (e-Learning), Cybersecurity (Governance, Management, Audit, Data Security and Privacy)'\n",
      " 'Empirical Software Engineering, Requirements Engineering, Usability Engineering, Global Software Development, Agile Development, Software Engineering Education'\n",
      " 'Artificial Intelligence, Model Base Testing'\n",
      " 'Wireless Networks, Evolutionary Computing, Machine Learning'\n",
      " 'Software Engineering Practices, Web Development, Software Project Management'\n",
      " 'Data Science, Machine Learning, Software Engineering,'\n",
      " 'Data Mining, Computational Intelligence, Machine Learning, and Theory of Computation\\xa0'\n",
      " 'Databases, Grid Computing, Cloud Computing, Information Systems and Software Applications Architecture'\n",
      " 'Computational Structural Biology. He is particularly interested in computational identification of novel drug targets, drug repositioning, biophysical modelling of tissues and computational characterization of membrane proteins.'\n",
      " 'Artificial Intelligence, Computational Intelligence, Machine Learning, Data Mining & Knowledge Discovery, Evolutionary Gaming, Machine Vision & Robotics'\n",
      " 'computer networks, high-performance computing and computer communications, performance evaluation (simulation and analytical modeling) of computer and communication systems and mobility management. Currently, he is working on mobility cost analysis in mobile networks.'\n",
      " 'model-driven engineering, software testing, and empirical software engineering'\n",
      " 'Cloud Computing and Services Composition'\n",
      " 'Artificial Intelligence, Computational Intelligence, Machine Learning, Data Mining & Knowledge Discovery, Evolutionary Gaming, Machine Vision & Robotics.'\n",
      " 'agile software development methods, empirical software engineering, requirements engineering, wearable learning, and merger of artificial intelligence with software engineering'\n",
      " 'confluence of Green Computation,\\xa0Compiler Optimizations,\\xa0Memory Hierarchy Optimizations,\\xa0Constraint Programming and\\xa0Graph Theoretic Algorithms. During the last few years he has worked on several compiler optimization problems targeted towards low-end, power constrained processors. These include formalizing instruction scheduling for clustered architectures, memory hierarchy optimizations and code generation.'\n",
      " 'Internet of Things (IoT), mobile and pervasive computing, geo-distributed fog & cloud computing and Software-defined Networking (SDN) with focus on scalability, quality of service (QoS), fault tolerance and security aspects'\n",
      " '\\xa0visual recognition (object detection, image classification, face recognition, etc.), machine learning and programming'\n",
      " 'Computer Vision, Machine Learning, Pattern Recognition and Image/Video Retrieval.'\n",
      " 'Model Driven Software Engineering, in particular focusing on Model Transformations and Automated Model based Software Testing'\n",
      " 'Management Information Systems & its security, Software Project Management, Human Computer interaction, and Supply Chain Management.'\n",
      " 'Model Driven Architecture (MDA), specifically MDA model transformation for generating Unified Modeling Language (UML) artifacts from legacy system design.'\n",
      " 'Computer Programming, Software Engineering, and Artificial Intelligence'\n",
      " 'Computer Communications and Networks.'\n",
      " 'Traffic Analysis, Performance Evaluation, Theory of Computation and Professional Ethics.'\n",
      " '\\xa0Image Processing (particularly Medical Image processing), Computer Vision, Machine Learning, and Bio Informatics.'\n",
      " 'Data mining, Business Intelligence, and Social Computing.'\n",
      " 'Human Computer Interaction, M-commerce, User Acceptance on IT and Requirement Engineering.'\n",
      " 'Cognitive Radio Networks,Wireless sensor Networks,Internet of Things\\n\\n\\n'\n",
      " 'Next Generation Networks and Security'\n",
      " 'Image Processing, Pattern Recognition, Machine Learning and Data Mining, Computational Intelligence Techniques'\n",
      " 'Text Mining,Information Retrieval, Information Extraction, Social Network Analysis, Machine Learning, Graphical Models, Topic Models'\n",
      " 'Professional Software Development and Analysis, Statistical Software Engineering, Stochastic Process, Sensor Networks, Collaborative Communications and Information Security'\n",
      " 'Network Routing Algorithms'\n",
      " 'Natural Language Processing, Text Mining\\xa0'\n",
      " 'Digital Image Processing And Computer Vision'\n",
      " 'Database Designing and Database, Data Mining, Datawarehousing'\n",
      " 'Digital Image Processing and Computer Vision, Computer Graphics'\n",
      " 'S/W Engineering' 'Computer Networks, OS, Computer Architecture'\n",
      " 'Data Warehousing (ETL)'\n",
      " 'Information Retrieval, Data Mining, Social Network Analysis, Probabilistic Topic Models, Machine Learning, Data Grids'\n",
      " 'Requirement Engineering, Global Software Development, Project Management.'\n",
      " 'Image Processing' 'Data Mining, Bioinformatics'\n",
      " 'Communication & Networks,Databases'\n",
      " 'Indoor Positioning Systems, Mobility management,Handover in Wireless Communication.'\n",
      " 'Databases, Data Warehousing,  Artificial Intelligence,Data structures, Algorithms'\n",
      " 'Wireless Sensor Networks Security, Mobile Application Development, VoIP, Cloud Computing, Next Generation Networks, IMS, VOLTE '\n",
      " 'Human Computer Interaction (HCI), Knowledge Management , Software Project Management, Management Information System (MIS)\\n\\n'\n",
      " 'Language Teaching, Applied linguistics (Language teaching) and Literature.'\n",
      " 'Artificial Intelligence, Programming, algorithms,Data warehousing,Databases'\n",
      " 'Language Definition & Translators, Data Structures, Algorithms & Programming'\n",
      " 'Computer Networks, Communication, Operating System'\n",
      " 'Web Application Development, Databases, Programming'\n",
      " 'Wireless Multihop Networks, Bandwidth Estimation and Reservation,IEEE 802.11 and IEEE 802.11e'\n",
      " 'Software Engineering, Success/failure of ERP implementation, Usability, Requirements Prioritization '\n",
      " 'Machine Learning, Data Mining, Evolutionary Algorithms, Artificial Intelligence '\n",
      " 'Large Scale Schema Matching and Integration, Machine Learning & Pattern Recognition, Social Network Analysis, Information Retrieval Systems (Recommender Systems),Semantic Web, Software Re-engineering, Bioinformatics  '\n",
      " 'Computer Vision, Data Analysis , Pattern Matching, Video Surveillance, Object Tracking and Re-Identification'\n",
      " 'Biomedical Image Processing and Analysis, Pattern Recognition, Machine Learning'\n",
      " 'Multimedia design and system, Human computer interaction, Computer Vision, Artificial Intelligence, Image processing, Computer Graphics'\n",
      " 'Image analysis & Deep learning'\n",
      " 'Data Mining, Quality Management, Project Management'\n",
      " 'Semantic Web, Ontology Engineering, Data Sciences'\n",
      " 'Cybersecurity, Mobile Cloud Computing, and IoT' 'Computer Vision'\n",
      " 'Wireless Networks and Security, 5G and Internet of Things.'\n",
      " 'Social Networks Analysis, Software Testing, Algorithm Design and Development.'\n",
      " 'Software Engineering Web Technologies' 'Software Engineering'\n",
      " 'Wireless Sensors, Cluster & Cloud Computing, Programming.'\n",
      " 'Data Privacy, Artificial Intelligence, Digital Marketing, Web Development'\n",
      " 'Ad hoc Networks, Wireless Sensor Networks, Wireless Personal Area Networks and Wireless Body Area Networks'\n",
      " '  Wave Mechanics/Fluid Mechanics'\n",
      " 'Formal Languages , Compiler Design, Quality in Education'\n",
      " 'Data Science, e-Learning, Software Engineering, Augmented/Virtual Reality'\n",
      " 'Mobile Ad hoc Networks, Wireless Sensor Networks (WSNs), Wireless Body Area Networks, Coverage in WSNs, Software Defined Networking, Massive Machine Type Access in Future Generation Networks, Low Power Wide Area Networks (LPWAN), Adaptive Data Rate in LPWAN, Approximation Algorithms, and NP-hard problems in Wireless Sensor Networks, Wireless Chargeable Sensor Networks'\n",
      " 'Pattern recognition, image analysis,\\xa0machine learning.'\n",
      " 'Digital Image Processing, Document Analysis, Computer Vision'\n",
      " 'Digital Preservation, Database Preservation, Information Retrieval, Information Systems'\n",
      " 'Semantic Web Technology, Smart Technologies, Digital Right Management Systems'\n",
      " 'Learning Systems,Quality in Higher Education'\n",
      " 'Distributed Algorithms, Formal Methods, Model Checking'\n",
      " 'Engineering Education, Human Factors in Engineering, Big Data and Cloud.'\n",
      " 'Data Integration, Image Processing' 'Cryptography,Numerical Computing'\n",
      " 'Distributed Computing, Cloud Computing, Grid Computing, Database Systems.'\n",
      " 'Security in Critical Infrastructures, Privacy, Security in Smart Ecosystems, Application Security, Risk Management, Adaptive Security, Internet of Things(IoT), Big Data Security.'\n",
      " 'speech processing and data mining' 'Data Mining'\n",
      " 'Statistical quality control and quality management, Linear profile methodologies for statistical process control'\n",
      " 'Telecommunication and Networking'\n",
      " 'Image Analysis and Pattern Classification' 'Information Security'\n",
      " 'Non-Newtonian Fluid, Analytic Solutions Homotopy, Analysis Method'\n",
      " 'Text mining, Bi-lingual Social network Analysis, Semantic analysis.'\n",
      " 'Information Systems' 'Online Reputation Management Systems'\n",
      " 'Internet of Things; Cloud Computing; Ad hoc Networks; Wireless Sensor Networks; Optical Networks; Algorithm Design and Optimization;'\n",
      " 'Educational data mining'\n",
      " 'Introduction to EMC/EMI,\\xa0 Document Writing using LATEX '\n",
      " 'Cloud Computing , Artficial Intelligence' 'web ontologies'\n",
      " 'Natural Language Processing, Artificial Intelligence and Robotics.'\n",
      " 'Semantic Computing: Semantic Digital Libraries, Ontology evaluation, Ontology mapping and merging, Semantic Cache Query Processing, Semantic Extraction from Multimedia Objects, Semantic Search Engines, Semantic based Learning Systems, Semantic based Query Refinement for WWW, Deep Web Mining Distributed Computing: Networks (IP and Transport Services), Bandwidth Aggregation for Heterogeneous Networks, Fault Tolerance Cryptography and Cryptanalysis, Algorithms, Bioinformatics '\n",
      " 'Multidatabase Systems Schema Translation, Schema Evolution, Schema Integration, Data Integration, Data Mining'\n",
      " 'Digital Libraries; Web/Text Mining; Semantic Web; Information Visualization'\n",
      " 'Wireless Ad Hoc Networks, development and evaluation of Network Coding Aware and Network Coding Based routing protocols suitable to highly dynamic and delay tolerant networks'\n",
      " 'Parallel and distributed computing. Parallel programming environments for multi-/many-core shared and distributed memory parallel computers. Run-time environments and scheduling mechanisms for parallel machines based on multi-cores. Performance analysis of parallel applications.'\n",
      " 'Routing in Mobile Ad hoc Networks Social Network Analysis Application of Graph Theory'\n",
      " 'Software & System Engineering, Computational Intelligence (Soft Computing), Agents and Multi Agent Systems, Autonomous Systems, Component Based Development'\n",
      " 'Semantic Computing, Digital Libraries, Ontology Engineering'\n",
      " 'Mobile Agents; Semantic Web; RDF Graphs'\n",
      " 'Requirements Engineering, Formal Methods.'\n",
      " 'Parallel Programming, Big Data, Games Bases Learning.'\n",
      " 'Wireless sensor networks particularly MAC layer design.'\n",
      " 'Software Testing, Software Requirements Engineering, Agile Development, Global Software Engineering, Formal Methods'\n",
      " 'Corpus linguistics, statistics, and the application of corpus methods in the study of speech and writing, learner language, collocations, phraseology and vocabulary. I am also interested in corpus design and corpus tools development, Experimental Phonetics and Phonology, Forensic Phonetics, Psycholinguistics, Second Language Acquisition, Implicit and Explicit L2 Knowledge, Prosody, Tone.'\n",
      " 'Machine Learning, Artificial Intelligence, Data Mining, Classification, Image Processing, Automata'\n",
      " 'Machine Learning, Artificial Intelligence, Computer Vision, Data Mining, Classification, Image Processing'\n",
      " 'Digital Image Processing, Pattern Recognition, Machine Learning, and Evolutionary Algorithms'\n",
      " 'Medical Image Processing, Pattern Recognition, Natural Language Processing'\n",
      " 'Design and development of PC controlled educational systems, Nuclear Electronics and Instrumentation'\n",
      " 'Numerical Computing, Parallel/Distributed Computing'\n",
      " 'Artificial Intelligence, Mobile Robots, Multi Robot Systems'\n",
      " 'Pattern Recognition, Machine learning, Bioinformatics, Combining Classifiers, Applications of Artificial Neural Network and Support Vector Machine in Computational Materials Science, Genetic Algorithm and Genetic Programming'\n",
      " 'Computer Networks and Security, Parallel and Grid Computing, Computer Architecture'\n",
      " 'Medical Image Reconstruction, Pattern Recognition, Evolutionary Computation, Digital Subtraction Angiography, Embedded Systems, Computational Metallurgy and Materials Science'\n",
      " 'Modeling and Simulation of Physical Systems, Stochastic Optimization, Evolutionary Computing'\n",
      " 'Cloud Computing, Internet of Things, Information Security, Web Mining, Cognitive Computer Science, Self Organizing Systems'\n",
      " 'Ad-Hoc Networks, Wireless Pervasive Systems, Cooperative Networking, Cooperative Sensing and Inference, Self-organized Networked Systems'\n",
      " 'Establishment of Software Services Infrastructure, Development of an Integrated Set of Information Systems, Development of Internet and Database Application Software, Distant Electronic Classroom Utilizing Low Bandwidth Internet, Data Warehousing, Information Security Management'\n",
      " 'Pose Tracking, Image Registration and Alignment, Visual Surveillance and Navigation, 3D Reconstruction, Virtual and Augmented Reality'\n",
      " 'Automatic lexical acquisition, Computational grammar development, Theoretical linguistics, Parallel corpora development and statistical machine translation'\n",
      " 'High performance computing using GPUs, CMPs; Parallel programming using OpenCL and CUDA; Architectures of GPUs/CMPs'\n",
      " 'Software Design & Development, Cyber Security, Database Security'\n",
      " 'Computational geometry, in particular, straight skeletons and Voronoi diagrams; general-purpose computing on graphics processing units (GPGPU); computer graphics and geometric modeling; algorithms and mathematical proofs; parallel and high-performance computing'\n",
      " 'Machine Learning (Artificial & Computational Intelligence), Digital Signal Processing, Biomedical signal analysis, Biometrics'\n",
      " 'Web Design and Development,eCommerce Applications Development,Wireless and Mobile Computing,Advanced Heterogeneous Networks'\n",
      " 'Computer Networking,Cloud Computing'\n",
      " 'Computational Semiotics,Sentiment Analysis,Evolutionary Computation,Charles Sanders Peirce'\n",
      " 'Real-time Non-intrusive Quality Estimation of VoIP'\n",
      " 'machine learning approaches for data intensive computing'\n",
      " 'human machine interfaces'\n",
      " 'Human-Computer Interaction, sonification, ubiquitous computing, accessibility, and location-based services'\n",
      " 'Big data and IoT' 'Data mining and Big Data Analytics'\n",
      " 'curriculum development, professional ethics; software design architectures; software process modeling and improvement; and software testing and quality assurance.'\n",
      " '\\xa0vision-based 3D motion retrieval and reconstruction, 3D pose estimation, action recognition, machine learning, motion synthesis and analysis etc.\\xa0'\n",
      " 'Design and development of energy efficient routing protocols,Cross layer architectures,Caching and forwarding schemes for cognitive radio ad hoc networks,named data networking based wireless networks'\n",
      " 'Security Issues in Agile Methodologies'\n",
      " 'Recommender Systems Intelligent Information Systems Geographical Information Systems and Remote Sensing Data Warehousing and Data Mining'\n",
      " 'Network Security and Monitoring,Digital Forensics,Real time Visualization,Complex Event Processing.'\n",
      " 'Machine Learning Prediction and Recommendation ,Data Mining ,Mobile Application Development'\n",
      " 'Game Intelligence,Adaptive Price Formulation,Data Mining & Machine Learning'\n",
      " 'Machine Learning & Data mining,Applications of computational intelligence in games,Effective computing'\n",
      " 'Graph Theory,Evolutionary Computing,Data Mining and Machine Learning'\n",
      " 'BigData'\n",
      " 'Artificial Intelligence, Computational Intelligence, Machine Learning, swarm intelligence, evolutionary algorithms, and expert systems.\\xa0'\n",
      " 'Data Analytics' 'Signal Processing and machine learning.'\n",
      " 'Neural Networks'\n",
      " 'Natural Language Processing (Morphological Analysis, Annotated Corpus building, Lexical resources), Secure Communication on Internet (IPSec) esp. Key Management Issues for Single Source Multicast Groups and Routing in Mobile Ad-Hoc Networks (Unicast, multicast), Lock-Free Data Structures and Urdu fonts '\n",
      " 'Nature Inspired computing and I developed a novel Artificial Immune System (AIS) security framework for the Mobile Adhoc Network (MANET) routing protocol BeeAdHoc, based on the foraging principles of honey bees.'\n",
      " 'Physics'\n",
      " 'Computational Intelligence,Multimodal Function Optimization,Data Clustering,Image Segmentation\\n\\n\\n'\n",
      " 'NLP'\n",
      " '\\xa0combinatorics, information theory and signal processing. Specific areas are problem in extremal and probabilistic methods in combinatorics, spectral graph theory, coding for distributed storage, interference channels.'\n",
      " 'MACHINE LEARNING (TEXT/IMAGES) AND COMPUTER VISION , CLOUD Computing, Big Data'\n",
      " '\\xa0epistemological access to higher education, role of ICT in motivating English language learners in ESL classroom at university level, and role of non-verbal communication in teaching-learning process of English.'\n",
      " 'graph theory and combinatory.'\n",
      " 'Reconfigurable Asynchronous Adaptive Processing and hardware realization of complex Image processing and communication algorithms.'\n",
      " 'Statistics' 'Mathematics' 'Telecom'\n",
      " 'Design Science, Human-Computer Interaction, Participatory Design, Interaction Design, Computer Science Education, Novel Pedagogies and Learning Theories.'\n",
      " 'Computer Basics and Electronics, Logic and Design, Low level Programming, Computer Architecture, Database Design and Administration and Networking.'\n",
      " 'Telecom,Networking'\n",
      " 'Distributed & Parallel Computation, Security Aspects, Cloud Computing, Big Data Analysis, Formal Specification & Analysis, Business and Software Process Mining.'\n",
      " 'System designing, development, project management, consultation'\n",
      " 'Big Data | Recommender system in cloud computing'\n",
      " 'Wireless sensor networks,Wireless adhoc networks'\n",
      " 'IoT (Internet of Things),\\xa0 RFID systems for IoT,RF MEMS & Antenna Design,UMTS/LTE, LTE advanced,UMTS/LTE, LTE advanced'\n",
      " 'Mobile Development'\n",
      " 'Operating Systems, Data Structures, Programming Languages'\n",
      " 'Structures, Automata Theory'\n",
      " 'Computer Networks, Topics in Internet Research, Optical Communications, Performance Modeling'\n",
      " 'Computational Modelling, Artificial Intelligence, Data Mining and Machine Learning, Multi-Agent Systems'\n",
      " 'Graph Theory (especially Topological Graph Theory)'\n",
      " 'Topological graph theory'\n",
      " 'Programming Languages and Compilers, Protocols and Algorithms for Wireless and Wired Networks'\n",
      " 'Analysis of Algorithms, Advanced Algorithms, High Performance Computing'\n",
      " 'Computer networks, broadband wireless networking, wireless multimedia communication, network deployment and monitoring.'\n",
      " 'Computer Vision, Image Processing, Machine Learning, and Statistics'\n",
      " 'Data Warehousing, Business Process Management and Academic Social Network'\n",
      " 'Image Processing, Computer Vision, Analysis of Algorithms'\n",
      " 'Computer Vision, Image Analysis, Machine Learning'\n",
      " 'Cloud Computing, Distributed Systems, Machine Learning, Data Mining, Mobile and Web Computing, Scalable Applications and Architectures, Algorithms Analysis, Data Structures, Operating Systems'\n",
      " 'Computational Mathematics, Linear Algebra, Calculus, Probability and Statistics'\n",
      " 'Natural Language Processing, Computational Linguistics, Machine Learning, Linguistics'\n",
      " 'Operating Systems and Systems Programming, Embedded and Real Time Operating Systems'\n",
      " 'Digital Logic and Design, Computer, Operating System, Architecture, Computer Networks'\n",
      " 'Databases, Data Structures, Digital Logic & Design'\n",
      " 'Databases, Information Systems'\n",
      " 'Software Engineering, Software Quality Assurance, Software Project Management'\n",
      " 'Object Oriented Design and Programming, Data Structures, Analysis and Design of Algorithms'\n",
      " 'Databases'\n",
      " 'Theory of Formal Languages and Automata, Design and Implementation of Compilers, Programming Languages'\n",
      " 'Online Algorithms, Robotics and Probabilistic Graphical Models, Enterprise Software Development, Software Engineering'\n",
      " 'Programming (C++/JAVA/.NET), Database Design and Administration, Data Structures, Design and Analysis of Algorithms, Theory of Automata.'\n",
      " 'Operating Systems, Computer Architecture, System Programming'\n",
      " 'Programming Fundamentals, Object-Oriented Programming, Data Structures & Algorithms, Theory of Automata, Discrete Mathematics'\n",
      " 'Graph Theory, Combinatorics, Image and Video Processing, Discrete Mathematics, Theory of Automata and Formal Languages, Multimedia System Design'\n",
      " 'Machine Learning, Image Processing, Computer Vision'\n",
      " 'Computer Programming, Software Engineering, Software Quality Assurance'\n",
      " 'Programming, Data Structures'\n",
      " 'Software Engineering, Enterprise Modeling, Object Oriented Analysis and Design'\n",
      " 'Agent Modeling, Intelligent Systems, AI, OOP, OOAD, Software Engineering, SW Architecture Pattern, Fundamentals of Programming Languages'\n",
      " 'Theoretical Physics, Mathematical Physics, Particle Physics, Astronomy, Electronics, Electrodynamics, Magnetism'\n",
      " 'Data Structures and Algorithms, Discrete Mathematics, Object-Oriented Programming'\n",
      " 'Programming in C/C++/VC++, Computer Organization'\n",
      " 'Parallel and Distributed Computing, Computer Vision, Database Systems, Computer Organization and Assembly Language, Business Process Management and academic social networks, Programming (OOP and DSA)'\n",
      " 'Network Programming'\n",
      " 'Ambient Intelligence, Computational Modeling, Data and Text Mining, Information Retrieval, Social Simulation, Enterprise Application Development, Mobile Computing, Computational Modeling, Artificial Intelligence'\n",
      " 'Human Computer Interaction, Software Engineering'\n",
      " 'Software Engineering, Object Oriented Analysis and Design,Software Design and Architecture.'\n",
      " 'Database systems, Project Management, Computer Networks, Software Quality Assurance, Total Quality Management'\n",
      " 'Computer Networks, Wireless Sensor Networks, Opportunistic Networks, Internet Architecture and Protocols'\n",
      " 'Big Data Analytics, Distributed Computing, Data Mining, Web Engineering, Object Oriented Programming, Software Engineering, Database Management Systems'\n",
      " 'Computer Vision, Pattern Recognition and Machine Learning, Multiple View Geometry, Convex Optimization'\n",
      " 'Data Structures and Algorithms, Computer Vision, High Performance Computing'\n",
      " 'Management Information Systems, Human Resource Management, Total Quality Management, Organizational Behavior, Software Project Management'\n",
      " 'Object Oriented System Design and Implementation, Data Structures and Algorithms, Theory of Automata'\n",
      " 'Artificial Intelligence'\n",
      " '\\xa0Imaging especially in the Data Security Issues'\n",
      " 'AI, Computer Vision and Machine Learning.'\n",
      " 'empirical software engineering and software cost estimation.'\n",
      " 'embedded system design with particular emphasis on the design and modeling of reliable and power-efficient solutions.'\n",
      " 'Evolutionary Algorithms, Bioinformatics, Combinatorial Optimization, Search Heuristics, Multi-objective Optimization, Many-Objective Algorithms, and Machine Learning.\\xa0'\n",
      " '\\xa0Information Retrieval, Machine Leaning, Bioinformatics and Data Sciences.'\n",
      " 'Ensemble Learning (AdaBoost) and its applications.'\n",
      " 'Computer Networks,\\n Distributed Systems\\n Cloud Computing'\n",
      " '\\xa0iterative methods to solve inverse problems, neuroimaging techniques including MRI and fMRI, and brain morphometry and topology.'\n",
      " '\\xa0software defined networking, network measurements, Internet traffic classification, and systems security.'\n",
      " 'Computer Vision, Parallel and Distributed Algorithms, Internet of Things and Information retrieval.'\n",
      " 'Big Data, Recommendation Systems, Data Mining, Distributed Computing and Combinatorial Algorithms.\\xa0'\n",
      " 'Software Engineering\\n Software Quality\\n Software Defects\\n Software Predictions\\n Autonomic Computing'\n",
      " '\\xa0web, cloud and IOT technology'\n",
      " 'application of Information and Communication Technologies for Development (ICT4D) purposes.'\n",
      " 'computer networking and network security.\\xa0'\n",
      " 'Software testing and Interaction design.'\n",
      " 'data modeling, database design, distributed systems, data warehouse construction and data mining.'\n",
      " 'computer vision, image processing, Script processing and machine learning.\\xa0'\n",
      " 'Software Engineering in general and IT project management, agile methods (TDD, XP), and software verification and validation in particular.'\n",
      " 'computer vision, graphics, augmented reality, 3D modeling and robotics.'\n",
      " 'Data Mining, Machine Learning, Text Analytics and Big Data Analytics'\n",
      " 'data mining, and big data analytics.'\n",
      " 'Computer Programming, Applied Programming, and Digital Logic Design'\n",
      " 'Ubiquitous Computing, Operating Systems, Distributed Systems, Mobile Systems, Highspeed Routing Architectures and the impact of IT in developing world countries'\n",
      " 'Internet of Things (IoT), Wireless Sensor and Ad Hoc Networks, Opportunistic Networks, Mobile and Distributed Systems, Network Virtualization and Cloud Computing, Distributed Algorithms, AI techniques applied to Networks, Exploiting On Board Diagnostics (OBD-II) in Electronic Fuel Injection (EFI) Vehicles'\n",
      " 'Data Science, Machine Learning, Data Mining, Text Mining, Descriptive and Predictive Analytics, Social Media Analytics, Sentiment Analysis, Recommender Systems, Constrain Based Learning, Big Data'\n",
      " 'Data Science, Scientific Research Informatics, Scientometrics, Alt-metrics, Information Retrieval, Data Mining, Social Media Analytics, Information Visualisation, Educational Data Mining.'\n",
      " 'Embedded Systems, Real-time and Mixed Criticality Systems, Parallel Computing Systems, Runtime Resource Management, Context-aware Computing, and Multicore/Manycore Scheduling.'\n",
      " 'Artificial Intelligence & Machine Learning, Experimental & Computational Neuroscience, Signal & Image Processing (Audio/Video Processing, Sonar/Bio-Acoustics), Wireless Sensor Networks (Environmental & Oceanographic applications)'\n",
      " 'Analysis of reactive, stochastic, real-time, and hybrid systems. Reduction techniques for probabilistic systems using game theory. Formal software verification, in particular model checking. Formal modeling and analysis of distributed computing. Game theory, Petrinets, process algebra, concurrency theory, mathematical logic and automata theory.'\n",
      " 'Educational Technology Integration at Different Levels, Use of Different Technologies to Improve Student Learning'\n",
      " 'Natural Language Processing, Probabilistic Graphical Models, Linguistics'\n",
      " 'Algorithmic and Discrete Geometry, Combinatorics, Extremal Graph Theory'\n",
      " 'solving theoretical and practical problems entailing Computer Vision and Machine Learning, specifically on the problems related to image co-segmentation, remote sensing, medical imaging and affective computing. Our group works extensively in Deep Learning, not only exploring innovative application of deep learning on existing problems but specially extending its theoretical understanding.'\n",
      " 'investigating multidisciplinary approaches to HCI and computer graphics issues particularly the perception of highly realistic cg humans'\n",
      " 'Speech and Language Technologies, Designing interfaces for the low-literate, Telephone-based Speech Interfaces for Access to Information by Non-literate Users, Speech Recognition.'\n",
      " 'data mining, machine learning, and applied artificial intelligence'\n",
      " 'Information systems security, secure distributed and networking systems, databases, multimedia information systems, semantic Web, Web services, ontology, and software testing.'\n",
      " 'analysis and semi-automated detection of similarity patterns in software'\n",
      " 'developing systems and techniques that improve the performance, scalability and programmability of parallel computing systems'\n",
      " 'computer networks and distributed systems and span cloud computing and datacenters, wireless networks, Internet censorship, and ICT for developing regions (including smart grids).'\n",
      " 'program analysis using static and dynamic techniques in automatic software test generation and parallel and incremental techniques in scaling algorithms for multicore processors and the intersection of these domains'\n",
      " 'development of on-line models for parametric estimation of solid fuel-fired industrial boilers'\n",
      " 'Systems and Networks\\xa0- IoT, CPS, WSN, ICT4D\\xa0'\n",
      " 'object detection and tracking using multimodal sensors'\n",
      " 'short, medium and long term forecasting of energy demand, renewable energy generation forecasting for wind and solar resources, demand side management in agricultural, residential and industrial sectors, energy efficiency, and renewable energy integration in existing building stock'\n",
      " 'assistive technologies\\xa0(mobile apps and VR/AR systems) to enhance the quality of life\\xa0of persons with disabilities (e.g. autism, dyslexia, visual impairment) and older adults, educational technologies for children (child-computer interaction),\\xa0and affective computing'\n",
      " 'social network analysis, mining social influence, machine learning'\n",
      " 'AI based Encryption Techniques and Quantum Computing'\n",
      " 'Computer Networks' 'Wireless Computer Networks'\n",
      " 'Wireless Sensor Networks and Web programming'\n",
      " 'Machine Learning, Data Sciences, Computer Vision & Graphics'\n",
      " 'Web Engineering'\n",
      " 'Software Process Improvement, Databases, Data Warehousing'\n",
      " 'Embedded System, Computer Architecture, Logic designing and Robotics.'\n",
      " 'Data Mining, Schema Extraction, Data Integration' 'Computer Science'\n",
      " 'Software Engineering, Web Development' 'Cognitive Protocol Networks'\n",
      " 'Computer Networks and Web development methodologies.'\n",
      " 'Computer networks' 'Computer Networks, Vehicular Ad-hoc Networks'\n",
      " 'Artificial Intelligence,Software Engineering' 'Web Development'\n",
      " 'Computer Control' 'Educational Quality Management and Databases Design'\n",
      " 'Software Design & Architecture, Algorithms Refinement, Design Patterns & Frameworks, Enterprise Systems, Information Systems Development & Management, Knowledge Management Systems, Technology Management & Consulting, Technopreneurship, Systems Thinking.'\n",
      " 'Software Engineering, Requirement Engineering, Database Modeling, Software Quality Assurance, Reverse Engineering, Formal Methods, Self Adaptive Systems, Cloud Computing, Fault Tolerant Systems'\n",
      " 'Business Processes, Strategic Management, Operations Research, Management Consultant in Strategy Planning, Operations Management, Program Management'\n",
      " 'Finance, Business Management and Accounting' 'Research based teaching'\n",
      " 'Embedded Systems, Artificial Intelligence and Image Processing'\n",
      " 'Computing Sciences' 'Networking' 'Project Management'\n",
      " 'Telecommunication' 'Software Engineering and Programming'\n",
      " 'Mobile Computing' 'Machine Learning, TSP Optimization'\n",
      " 'Distributed System & Networks'\n",
      " 'Software Testing and Quality Assurance\\xa0'\n",
      " 'Computer Vision and Pattern Recognition\\xa0'\n",
      " 'Digital Signal Processing,Speech Recognition and Synthesis systems,Computer Networks.'\n",
      " 'Bioinformatics,Structural biology,Graph theory,Operations Research'\n",
      " \"Pervasive Computing,secure device/service discovery, activity recognition and access control mechanisms using proximity/sensors' data, policy-based systems, context-awareness and adaptation mechanisms,sensor networks, wireless networks (including WiFi, Bluetooth, WiMAX, etc), and solutions to various issues in distributed and pervasive computing systems through the integration of tools and techniques from distinct disciplines/areas. \\xa0\"\n",
      " 'resource management, job scheduling strategies, energy efficiency, and workload characterization for performance optimization of parallel and distributed systems such as cloud computing, and location-based services i.e., map-matching strategy for GPS trajectories'\n",
      " 'computing and information systems domain.'\n",
      " 'Numerical linear algebra,Matrix Computation,Numerical Analysis'\n",
      " '\\xa0High Performance Computing with special emphasis on new and emerging architectures including multicore processors'\n",
      " 'Machine Learning & Combinatorial Optimization Techniques with applications in image / video retrieval, cancer classification, surface inspection, bioinformatics, multi-label classification, and face recognition'\n",
      " 'Network Security and Data Security, Name Data Network or Content Centric Network, Security and Privacy isssues in MANET or Ad hoc computing, Internet of Things, Machine-to-Machine and Device-to-Device Communications, Wireless Communications (4G, 5G, etc. ), Optimization'\n",
      " 'Error Correction Coding, Optimization Wireless Routing, Mathematical analysis of transmission networks, Evolutionary computation, Applied Machine Learning'\n",
      " 'Disaster Management, Information Systems, Geo Informatics, Social Informatics, Urban Planning, Image Processing'\n",
      " 'Elliptic Curve Cryptography, Embedded OS, Quality Assurance & Software Engineering, Open source technology, Databases, Vocational trainings for intellectually challenged\\n'\n",
      " ' Computer Hardware, Computer Architecture, Mass-Storage devices (Winchester, Flash and Solid-State Drives.)'\n",
      " 'Data Communication, Computer Network, Algorithms development, Programming languages and Machine learning.'\n",
      " 'Data Mining, Machine Learning, Brain Computer Interface (BCI), Intelligent Transportation Systems'\n",
      " 'Big Data Security, Deep Learning,Algorithms'\n",
      " 'Software Engineering, Data Mining, Image Processing'\n",
      " 'VANETs, Databases, Data Mining, IoT, Natural Language Processing'\n",
      " 'Software Engineering, Database Systems, Algorithms'\n",
      " 'Temporal and Spatial Database Systems, Artificial Intelligence, Health Information Systems, Software Engineering\\xa0'\n",
      " 'Languages, Software Development, Information Mgmt & Operating Systems\\xa0'\n",
      " 'Languages, Data Mining, Data Modeling\\xa0'\n",
      " 'Soft Computing, Data Mining, Fuzzy Set Theory\\xa0'\n",
      " 'Operating Systems, Networking, Parallel Computing\\xa0'\n",
      " 'Software Project Management, Software Configuration Management'\n",
      " 'Computer Graphics, Image Processing, Discrete Mathematics\\xa0'\n",
      " 'Machine Learning, Robust Speech Recognition, Image Processing.'\n",
      " 'Computer Vision, Image Processing and Computational Linguistics.'\n",
      " 'Software Development Methodologies.' 'Computer Vision.'\n",
      " 'Information Security.' 'Data Mining .' 'Semantics.'\n",
      " 'Wireless Ad-Hoc Routing Protocols and Information Security.'\n",
      " 'Cloud Adoption: A Goal-Oriented Requirements Engineering Approach Research Interests: Requirements Engineering, Risk Management, Cloud Architecture, Software Engineering'\n",
      " 'Educational Data Mining' 'Databases and Software Engineering.'\n",
      " 'Online Information Security in Financial Transactions'\n",
      " 'Artificial Intelligance, Software Engineering, Web Development .'\n",
      " 'Image Processing, Software Engineering.' 'Machine Learning.'\n",
      " 'Scientific Workflows, Scientific (machine generated) Data Management, Ontology based data integration, and Data transformation as well as transportation in scientific applications. Moreover, his interests also include the dataflow and data transformation languages.'\n",
      " 'Embedded Control Systems, Sketch-Based Interfaces and Modeling, Soft Computing, Computer Graphics, and Renewable Energy based Irrigation Systems.'\n",
      " 'Multimedia Data Mining'\n",
      " 'Semantic Web technologies, Online Social Networks, Privacy and Data Protection, Social Application Development, Multi Agent Systems'\n",
      " '\\xa0Distributed Systems, Cloud Computing, Network Design, Security and Management, Algorithms and Data Structures and Theoretical computer science.'\n",
      " 'security and resource management in Wireless Medical Sensor Networks, Wireless Body Area Networks, Wireless Sensor Networks, Virtual Sensor Networks, Mobile Crowd Sensing, Participatory Sensing, Quality of Monitoring for medical and health applications and Quality of Service optimization for audiovisual communications.'\n",
      " 'Theoretical Computer Science, Computer Networks, Computational Intelligence and Network Coding'\n",
      " 'Human Computer Interaction, Usability Engineering, Mobile Interaction \\n'\n",
      " 'Data Mining, Business Intelligence, Big Data Analytics, Digital Image Processing, Digital Watermarking Security, Error Correcting Codes, Spread Spectrum'\n",
      " 'Collaborative Software Process (CSP) Measurements , Mapping data from Object Oriented Databases to RDF based Ontology Interests: Object Oriented Programming Object Oriented Analysis & Design Data Structures & Algorithms'\n",
      " 'Software Engineering and Project Management, Quality Assurance and Requirement Engineering, Information Systems, Electronic Commerce and Security issues.'\n",
      " 'Object Oriented Programming, Web Engineering, Database concepts and Operating Systems. Cloud Computing, Semantic web.'\n",
      " 'Object Oriented Programing, Data Structures and Algorithms, Introduction to Programming, Web Development, Mobile Applications Development and Operating Systems.'\n",
      " 'Reservoir Engineering, Multiphase Flow, Artificial Intelligence.'\n",
      " 'GPU based volume rendering, Biomedical imaging and visualization, Soft body simulations, Physically based animation, Physically based rendering, Cloth simulation, Augmented reality\\xa0'\n",
      " 'Ontology-based Classification and Mind Uploading\\xa0'\n",
      " 'Computational Biology , Big Data Analysis , Computational Social Science '\n",
      " 'Big Data Analytics ,Data Mining , Machine Learning , Human Computer Interaction '\n",
      " 'Data Provenance , E-Commerce , Data WareHouse '\n",
      " ' Bioinformatics , Biometrics , Social Computing '\n",
      " 'Data Mining, Computer Architecture, Design and Analysis of Algorithms\\xa0'\n",
      " 'Intelligent and Multi-Agent Systems,\\nScheduling issues in Distributed Systems\\nSecurity and Management Issues in Next Generation Networks'\n",
      " 'Data & Text Mining, Machine Learning, Research Trends in Artificial Intelligence, Information Retrieval, Computability and Complexity, Graph Theory and Algorithms.'\n",
      " 'Insider threats Detection\\nRisk Assessment & prevention\\nEfficient Video Processing Techniques\\nCloud Computing'\n",
      " 'Internet of Things\\nSmart Sensors & Networks'\n",
      " 'Big Data Analytics, Data Mining, Date warehousing'\n",
      " 'Networking, Telecommunication and Wireless ad-hoc Networks'\n",
      " 'Image Processing, Pattern Recognition, Machine Learning'\n",
      " 'Software Engineering\\nUse of software metrics for improving software processes\\nSocial network analysis'\n",
      " 'Electronics\\nComputer Network'\n",
      " 'Network Security\\nTechnology in Education'\n",
      " 'Software Design\\nSoftware Testing'\n",
      " 'Computer Organization and Architecture\\nIntelligent Systems\\nHuman Computer Interaction\\nComputer Negtworks'\n",
      " 'Human Computer Interaction\\nArtificial Intelligence'\n",
      " 'WBAN (Wireless Body area Network), Wireless Adhoc Network, Wireless Sensor Network'\n",
      " 'Security, Computer Networks, Telecommunication Infrastructure, Wireless ad-hoc Networks, System Administration.'\n",
      " 'Human Computer Interaction\\nUser Experience\\nInteraction Design\\nIntelligent Systems'\n",
      " 'System Architect\\nMachine Learning\\nBig data\\nNetwork Security'\n",
      " 'Ubiquitous Computing, Wireless Networks'\n",
      " 'Reports on  Census of Pakistan  1951,1961,1972,1981 and 1998\\nDemography Analysis of Pakistan\\n Apply  Pearson’s System of frequency Curve in different date set of PDF, PGS with complete programming in R, SAS\\n\\n?'\n",
      " 'Data Science, Predictive Analysis Based Decision Support System.'\n",
      " 'Software Costing and Estimation\\nSoftware Quality\\nBig Data Analytics'\n",
      " 'MPLS on Satellite Communication\\nWearable Body Area Networks\\nNetwork  Security'\n",
      " 'Analog IC designing\\nSemicinductor devices'\n",
      " 'Artificial Intelligence\\nSoftware Engineering'\n",
      " 'Theoretical Computer Science\\nAlgorithm & Complexities\\n\\n '\n",
      " 'Information System Audit\\nInformation Security\\nIT Governance\\nIT Risk Management\\nTelecommunication and Networking\\nGlobal IT Standards and Frameworks\\n\\n '\n",
      " 'Machine Learning\\nIntelligent Systems\\nTheoretical Computer Science\\nAlgorithm & Complexities\\nEnergy Systems\\nRobotics\\nRenewable Energy.'\n",
      " 'Data & Text Mining\\nMachine Learning\\nInformation Retrieval'\n",
      " 'Big Data Analysis\\nNoSQL Databases\\nGrid Computing\\nData Mining'\n",
      " 'Grid Computing\\nData Mining' '\\xa0Energy Systems'\n",
      " 'Modelling and simulation of grid-connected photovoltaic system, efficient battery charging devices for PV system, intelligent control, non-linear systems and exploitation of evolutionary algorithms such as genetic algorithm (GA), particle swarm optimization (PSO) and differential evolution (DE) in engineering applications.'\n",
      " 'Building energy efficiency, data fusion, uncertainty analysis and robust control.'\n",
      " 'Artificial Intelligence, Human Computer Interaction, Machine Learning, and Data Mining.'\n",
      " 'Human Computer Interactions,Semantic Web,Ubiquitous Computing'\n",
      " 'Text Summarization, Machine Learning, Information Retrieval, Influence Mining, Affective Computing, Psychology and Computational Linguistics.'\n",
      " 'Mobile Computing, Human Computer Interaction and Mobile Game Development.'\n",
      " 'Telemedicine, Telematics, Optical-Laser Communication System, Satellite Communication, Micro wave [LOS] Communication System etc.'\n",
      " 'Digital processing and management tools for 2D and 3D shape repositories; geometric modeling; data structures; advanced programming; algorithm analysis; digital computer logic; computer architecture; linear algebra; discrete mathematics.'\n",
      " 'Social network analysis,Land use change,Climate change adaptation,Infectious disease transmission,Social anthropology'\n",
      " 'Artificial Intelligence and Planning Graphs'\n",
      " 'Robotics, Machine Learning, Probabilistic Reasoning and Computational Intelligence'\n",
      " 'design and analysis of efficient algorithms, graph theory, discrete and combinatorial optimization, and machine learning/data mining.'\n",
      " 'Computer Architecture, Compiler Optimizations and Natural Languages'\n",
      " 'RDBMS, Distributed Systems, Multi-Agent System (MAS), Data Minning and Data Minning Techniques.'\n",
      " 'Information Retrieval/Processing,Web Usability Engineering,Software Quality Assurance'\n",
      " 'Research interests include the security aspects of multimedia (Audio and Video), Compression, Encryption, Steganography, Secure transmission and the Key management schemes for standard and scalable video.'\n",
      " 'Natural Language Processing, Automated Software Engineering, Image Processing, Machine Translation'\n",
      " 'Formal software engineering, Software architecture, Multi-agent robotics'\n",
      " ' Computer Networks' ' Programming, Networking'\n",
      " 'Wireless sensor networks. Internet of things(IoT), Scheduling patterns of sensor messages, Node failures management, QoS aware message scheduling'\n",
      " 'Machine Learning/Data Science/Data Mining/Statistical Pattern Analysis in general but with a particular interest in probabilistic approaches of high-dimensional data projection approaches and their use in answering questions related to biological problems related to protein analytics, patient specific analytics etc.'\n",
      " 'Data Mining and Network Programming' 'Wireless Sensor Network'\n",
      " 'Data Mining with emphasis of big data analytics, Machine Learning, Applications of Machine learning and data mining, Decision support system, Applications of machine learning in health sciences'\n",
      " 'Computer Networks (Information Network Security (Access Control/Authorization), Cloud Computing Security)'\n",
      " 'Image classification, Image retrieval, Content-Based Image Retrieval, Machine learning, Computer vision'\n",
      " 'Wireless Communication and Networks'\n",
      " 'E-commerce, usability testing, User interface design, User acceptance testing, User experience design, Databases, Requirement engineering & analysis, Human-computer-interaction.'\n",
      " 'Data Mining (Classification, Prediction, Online Social Networks, Recommender Systems and other similar topics), Information Security (Privacy preservation, Authentication and other similar topics).'\n",
      " 'Geographical Information System, Advanced theory of Computation, Big Data Analytics'\n",
      " 'Software Engineering, Model-Based Software Engineering, Model-Based Testing, Software Architecture and Design, Software Process Improvement, Formal Methods, Model Checking, Software Quality Assurance, Software Testing, Programming Techniques, Parallel Programming, Mobile Computing, Autimated Testing'\n",
      " 'Computer Architecture, Operating System, Computer Networks'\n",
      " 'Research Paper Recommender Systems (Co-Citation & Bibliographic Analysis, Content and Metadata based Recommendation), Information Retrieval in Digital Libraries (Rule based information extraction from PDF sources)'\n",
      " 'Wireless Sensor Networks (WSN), Wireless Body Area Networks (WBAN), Internet of Things (IoT), Energy Harvesting (EH)'\n",
      " 'Wireless Networks, Cognitive Radio Networks.'\n",
      " 'Network Techonologies, Information Technology' 'Programming, Networks'\n",
      " 'NGS Data (Assembly, Annotation, Metabolic Pathways Analysis), Computational Biology.'\n",
      " 'Software engineering, Project Management, Programming, Management Information System, Geographic Information Systems, Information System Control and audit, DBMS'\n",
      " 'using Geospatial technologies to strengthen and integrate health systems'\n",
      " 'His core expertise are in the field of machine learning and his focused area of research is “Text Classification”. '\n",
      " 'Trusted Computing along with Agent Oriented Technologies, and Machine Learning along with Data Mining'\n",
      " 'Computational Intelligence and Artificial Neural Network'\n",
      " 'Human Acceptance of Autonomous Social Media Agent'\n",
      " 'Computer Engineering'\n",
      " 'Enterprise Modeling, Software Engineering, Information Retrieval, Information and Knowledge Modeling and Information Logistics'\n",
      " 'Web Engineering, Web Semantics, Web 2.0, Lifelogging, Smartphones, Information Overload, Technology for People with Special Needs'\n",
      " 'Database Security (Fine Grained Security Techniques, K-Anonymity, Digital Watermarking, Data Encryption), Data Warehousing (Data Quality Techniques, Data De-duplication), Data Mining, Big Data Analytics'\n",
      " 'Sentiment Analysis, Text Simplification, Plagiarism Detection, Automatic paraphrasing'\n",
      " 'Networks, Mobile Adhoc networks, Wireless sensor Networks, Distrinuted systems, Differential services, Routing Algorithms, Internet Protocol IPv6'\n",
      " 'Agile Software Development, Software Quality, Empirical Research in Software Engineering'\n",
      " 'Concurrency and Parallelism Operating System Kernels Programming Languages Computer Architecture Internet of Things'\n",
      " 'Human Computer Interaction, Technology Enhanced Learning, Learning Analytics, Persuasive Technologies, UX Design'\n",
      " 'Middleware, Sensor networks, Embedded systems, Pervasive computing ,Wireless communications.'\n",
      " 'Intelligent Transport System, Security, Privacy, Formal Modelling Delay Tolerant Networking, multicasting'\n",
      " '60-GHz networks, resource allocation in HetNets, Capacity analysis in wireless networks'\n",
      " 'Artificial Intelligence, Machine Learning, Neural Networks, Algorithms'\n",
      " 'Network Security' 'Artificial Intelligence, Natural Language Processing'\n",
      " 'Artificial Intelligence-Artificial Neural Networks Artificial Intelligence-Particle Swarm Optimization'\n",
      " 'Datamining'\n",
      " 'Blockchain and Cryptocurrencies, Graph Theory and Social Networks, Combinatorial Optimization, Algorithm Engineering, Game Theory, Algorithmic Trading'\n",
      " 'Numerical Solution of initial and initial Boundary Value Problems.'\n",
      " 'Biostatistics: Statistical Genetics and Bioinformatics, Linear and Mixed Linear Models, Experimental Designs'\n",
      " 'Applied Statistics and Biostatistics' 'BioStatistics'\n",
      " 'Bayesian Statistics' 'fluid dynamics'\n",
      " 'Statistics, Human Resources management'\n",
      " 'Mobile Ad Hoc Networks (MANETs)'\n",
      " 'Machine Learning in Security and Privacy'\n",
      " 'WIRELESS SENSOR NETWORK\\xa0\\xa0'\n",
      " 'Software Modularization, Software Architecture Recovery, Bugs Prioritization, Software Quality Metrics, Clustering, Classification, Digital Forensics (Files recovery)  '\n",
      " 'INFORMATIONAL AND BUSINESS SUPPORT SYSTEM\\xa0\\xa0'\n",
      " 'SOFTWARE ENGINEERING\\xa0\\xa0' 'EMBEDDED SYSTEM ENGINEERING\\xa0\\xa0'\n",
      " '\\xa0INFORMATION TECHNOLOGY\\xa0\\xa0' 'Information Technology/Finance\\xa0'\n",
      " 'COMPUTER SCIENCE\\xa0\\xa0' 'COMPUTER SYSTEM ENGINEERING\\xa0\\xa0'\n",
      " 'Electronic System Engineering / Optical Communication Systems'\n",
      " 'System Engineering' 'Communication & Electronics' 'Electronics Design'\n",
      " 'Pattern Recognition,Non-destructive testing, Biomedical engineering, Chemometrics, Image/signal processing; Knowledge Based & Decision Systems'\n",
      " 'Electrical Impedance Tomography, Inverse algorithms, evolutionary algorithms (EAs), Robotic Vision and Bioinformatics'\n",
      " 'Machine Learning, Big Data Anaysis, Data Mining, Artificial Intelligence, Semantic Analysis'\n",
      " 'Digital Multimedia Systems, Video Compression and Communication, Video Transcoding, Content Adaptation, Pervasive Media delivery'\n",
      " 'Medical Image Processing and Analysis, Digital Signal Processing, Numerical Methods'\n",
      " 'Pruning and Quantizing CNN, GPGPU,']\n",
      "------------------------------------------\n",
      "Other Information\n",
      "[nan 'PhD in progress ' 'PhD in progress'\n",
      " '2 year post doctorate at Telecom Bretagne (Rennes Campus), IRISA, France in 2011/2012'\n",
      " 'MS in progress' 'PhD in progress from IIU'\n",
      " 'PhD in progress from Capital University of Science & Technology'\n",
      " 'PhD in progress from  Quaid-e-Azam University, Islamabad \\n'\n",
      " 'PhD in progress from COMSATS' 'PhD in progress from Bahria University'\n",
      " 'MS in progress from UET,Taxila' 'MS in progress from Bahria University'\n",
      " 'MS in progress from National University of Sciences and Technology'\n",
      " 'PhD in progress from Abasyn University,Pakistan\\n'\n",
      " 'PhD in progress from Shaheed Zulfikar Ali Bhutto Institute of Science and Technology'\n",
      " 'MS in progress from IQRA' 'MS in progress from UAAR'\n",
      " 'PhD in progress from ISRA' 'MSCS in progress from UAAR'\n",
      " 'MSCS in progress UAAR' 'MS in progress from FAST'\n",
      " 'MS in progress from FAST Peshawar' 'PhD in progress from UCP'\n",
      " 'PhD in progress from UMT' 'PhD in progress from NCBA&E'\n",
      " 'Phd in progress' 'M.Phil in progress' 'PhD in progress from UET'\n",
      " 'MS in progress from College of Electrical and Mechanical Engineering – National University of Sciences and Technology, Islamabad'\n",
      " 'MS in progress from Leads University,Lahore'\n",
      " 'PhD in progress from ISRA University' 'MS in progress from QUEST'\n",
      " 'PhD in progress from QUEST'\n",
      " 'MS in progress from Sindh University Jamshoro'\n",
      " 'MS in progress from Tondo-Jam University'\n",
      " 'Phil leading to Ph.D. (Course Work 4 CGPA) from University of Sindh'\n",
      " 'PhD candidate'\n",
      " 'PhD in progress from Institute of Business Administration,Karachi'\n",
      " 'PhD in progress from MAJU,Karachi,Pakistan'\n",
      " 'PhD in progress from PAK-KIEFT' 'PhD in progress from NED' 'Visiting'\n",
      " 'MSSE in progress from PAK-KIEFT' 'MS in progress from MAJU'\n",
      " 'MS in progress from PAK-KIET'\n",
      " 'PhD in progress from  Federal Urdu University of Arts, Science & Technology'\n",
      " 'HEC Approved Supervisor' 'On Study Leave' 'On study leave'\n",
      " 'Remained at the Chancellor’s list by achieving 4.0 CGPA during the MS Computer Science Program at Colorado Technical University, USA'\n",
      " 'Currently Member of Board of  Studies of Kohat University and Shaheed Benazir Bhutto  University'\n",
      " 'MS will complete in 2018' 'HEC approved PhD Supervisor']\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in df.select_dtypes('object').columns:\n",
    "    print(i)\n",
    "    print(df[i].unique())\n",
    "    print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Thailand', 'Pakistan', 'germany', 'Austria', 'Australia', 'UK',\n",
       "       'China', 'France', 'USofA', 'SouthKorea', 'Malaysia', 'Sweden',\n",
       "       'Italy', 'Canada', 'Norway', 'Ireland', 'New Zealand', 'Urbana',\n",
       "       'Portugal', 'Russian Federation', 'USA', 'Finland', ' USA',\n",
       "       'Netherland', ' Germany', ' Sweden', ' New Zealand', 'Greece',\n",
       "       'Turkey', 'South Korea', 'Macau', 'Singapore', 'Spain', 'Japan',\n",
       "       'HongKong', 'Saudi Arabia', 'Mauritius', 'Scotland'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean the data:\n",
    " 1)strip to remove any additional spaces \n",
    " 2)lower and upper case\n",
    " 3)Name differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country']=df['Country'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3965/2253785465.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Country'].replace('USofA','USA',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Country'].replace('USofA','USA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3965/295801130.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Country'].replace('south korea','southkorea',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Country'].replace('south korea','southkorea',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thailand', 'pakistan', 'germany', 'austria', 'australia', 'uk',\n",
       "       'china', 'france', 'usa', 'southkorea', 'malaysia', 'sweden',\n",
       "       'italy', 'canada', 'norway', 'ireland', 'new zealand', 'urbana',\n",
       "       'portugal', 'russian federation', 'finland', 'netherland',\n",
       "       'greece', 'turkey', 'macau', 'singapore', 'spain', 'japan',\n",
       "       'hongkong', 'saudi arabia', 'mauritius', 'scotland'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex3 Character Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ahmed/Downloads/ks-projects-201612.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IBM/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IBM/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/IBM/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IBM/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/IBM/myenv/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/home/ahmed/Downloads/ks-projects-201612.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this problem indicates that there is some char can't read by the utf-8 encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m895.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "with open (r'/home/ahmed/Downloads/ks-projects-201612.csv','rb') as myobj:\n",
    "    result=chardet.detect(myobj.read(10000))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we write encoding=type we see in the chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3603/1931465512.py:1: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('/home/ahmed/Downloads/ks-projects-201612.csv',encoding='Windows-1252')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/home/ahmed/Downloads/ks-projects-201612.csv',encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>...</th>\n",
       "      <th>2091</th>\n",
       "      <th>2092</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>3.28M</td>\n",
       "      <td>...</td>\n",
       "      <td>76.6M</td>\n",
       "      <td>76.4M</td>\n",
       "      <td>76.3M</td>\n",
       "      <td>76.1M</td>\n",
       "      <td>76M</td>\n",
       "      <td>75.8M</td>\n",
       "      <td>75.6M</td>\n",
       "      <td>75.4M</td>\n",
       "      <td>75.2M</td>\n",
       "      <td>74.9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angola</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>1.57M</td>\n",
       "      <td>...</td>\n",
       "      <td>168M</td>\n",
       "      <td>170M</td>\n",
       "      <td>172M</td>\n",
       "      <td>175M</td>\n",
       "      <td>177M</td>\n",
       "      <td>179M</td>\n",
       "      <td>182M</td>\n",
       "      <td>184M</td>\n",
       "      <td>186M</td>\n",
       "      <td>188M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>400k</td>\n",
       "      <td>402k</td>\n",
       "      <td>404k</td>\n",
       "      <td>405k</td>\n",
       "      <td>407k</td>\n",
       "      <td>409k</td>\n",
       "      <td>411k</td>\n",
       "      <td>413k</td>\n",
       "      <td>414k</td>\n",
       "      <td>...</td>\n",
       "      <td>1.33M</td>\n",
       "      <td>1.3M</td>\n",
       "      <td>1.27M</td>\n",
       "      <td>1.25M</td>\n",
       "      <td>1.22M</td>\n",
       "      <td>1.19M</td>\n",
       "      <td>1.17M</td>\n",
       "      <td>1.14M</td>\n",
       "      <td>1.11M</td>\n",
       "      <td>1.09M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>2650</td>\n",
       "      <td>...</td>\n",
       "      <td>63k</td>\n",
       "      <td>62.9k</td>\n",
       "      <td>62.9k</td>\n",
       "      <td>62.8k</td>\n",
       "      <td>62.7k</td>\n",
       "      <td>62.7k</td>\n",
       "      <td>62.6k</td>\n",
       "      <td>62.5k</td>\n",
       "      <td>62.5k</td>\n",
       "      <td>62.4k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>40.2k</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3M</td>\n",
       "      <td>12.4M</td>\n",
       "      <td>12.5M</td>\n",
       "      <td>12.5M</td>\n",
       "      <td>12.6M</td>\n",
       "      <td>12.7M</td>\n",
       "      <td>12.7M</td>\n",
       "      <td>12.8M</td>\n",
       "      <td>12.8M</td>\n",
       "      <td>12.9M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                country   1800   1801   1802   1803   1804   1805   1806  \\\n",
       "0           Afghanistan  3.28M  3.28M  3.28M  3.28M  3.28M  3.28M  3.28M   \n",
       "1                Angola  1.57M  1.57M  1.57M  1.57M  1.57M  1.57M  1.57M   \n",
       "2               Albania   400k   402k   404k   405k   407k   409k   411k   \n",
       "3               Andorra   2650   2650   2650   2650   2650   2650   2650   \n",
       "4  United Arab Emirates  40.2k  40.2k  40.2k  40.2k  40.2k  40.2k  40.2k   \n",
       "\n",
       "    1807   1808  ...   2091   2092   2093   2094   2095   2096   2097   2098  \\\n",
       "0  3.28M  3.28M  ...  76.6M  76.4M  76.3M  76.1M    76M  75.8M  75.6M  75.4M   \n",
       "1  1.57M  1.57M  ...   168M   170M   172M   175M   177M   179M   182M   184M   \n",
       "2   413k   414k  ...  1.33M   1.3M  1.27M  1.25M  1.22M  1.19M  1.17M  1.14M   \n",
       "3   2650   2650  ...    63k  62.9k  62.9k  62.8k  62.7k  62.7k  62.6k  62.5k   \n",
       "4  40.2k  40.2k  ...  12.3M  12.4M  12.5M  12.5M  12.6M  12.7M  12.7M  12.8M   \n",
       "\n",
       "    2099   2100  \n",
       "0  75.2M  74.9M  \n",
       "1   186M   188M  \n",
       "2  1.11M  1.09M  \n",
       "3  62.5k  62.4k  \n",
       "4  12.8M  12.9M  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file to see its contents\n",
    "df=pd.read_excel(r\"/home/ahmed/Downloads/D7JamZGeakUaQHsuqtSR6Dg1mEhH9g.xlsx\")\n",
    "\n",
    "# Display the first few rows and summary to identify what needs cleaning\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197 entries, 0 to 196\n",
      "Columns: 302 entries, country to 2100\n",
      "dtypes: object(302)\n",
      "memory usage: 464.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>...</th>\n",
       "      <th>2091</th>\n",
       "      <th>2092</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>197</td>\n",
       "      <td>164</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>179</td>\n",
       "      <td>185</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2.5M</td>\n",
       "      <td>2M</td>\n",
       "      <td>1.01M</td>\n",
       "      <td>2.01M</td>\n",
       "      <td>2.02M</td>\n",
       "      <td>2.02M</td>\n",
       "      <td>2.03M</td>\n",
       "      <td>2.03M</td>\n",
       "      <td>2.04M</td>\n",
       "      <td>...</td>\n",
       "      <td>2.18M</td>\n",
       "      <td>12.4M</td>\n",
       "      <td>17.6M</td>\n",
       "      <td>30.9M</td>\n",
       "      <td>77.6M</td>\n",
       "      <td>77.7M</td>\n",
       "      <td>46.1M</td>\n",
       "      <td>42.5M</td>\n",
       "      <td>17.4M</td>\n",
       "      <td>11M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            country  1800 1801   1802   1803   1804   1805   1806   1807  \\\n",
       "count           197   197  197    197    197    197    197    197    197   \n",
       "unique          197   164  183    186    185    179    185    180    181   \n",
       "top     Afghanistan  2.5M   2M  1.01M  2.01M  2.02M  2.02M  2.03M  2.03M   \n",
       "freq              1     6    4      3      3      4      4      3      3   \n",
       "\n",
       "         1808  ...   2091   2092   2093   2094   2095   2096   2097   2098  \\\n",
       "count     197  ...    197    197    197    197    197    197    197    197   \n",
       "unique    180  ...    191    184    190    191    192    193    191    192   \n",
       "top     2.04M  ...  2.18M  12.4M  17.6M  30.9M  77.6M  77.7M  46.1M  42.5M   \n",
       "freq        5  ...      2      3      2      3      2      2      2      3   \n",
       "\n",
       "         2099 2100  \n",
       "count     197  197  \n",
       "unique    189  191  \n",
       "top     17.4M  11M  \n",
       "freq        2    3  \n",
       "\n",
       "[4 rows x 302 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Afghanistan', 'Angola', 'Albania', 'Andorra',\n",
       "       'United Arab Emirates', 'Argentina', 'Armenia',\n",
       "       'Antigua and Barbuda', 'Australia', 'Austria', 'Azerbaijan',\n",
       "       'Burundi', 'Belgium', 'Benin', 'Burkina Faso', 'Bangladesh',\n",
       "       'Bulgaria', 'Bahrain', 'Bahamas', 'Bosnia and Herzegovina',\n",
       "       'Belarus', 'Belize', 'Bolivia', 'Brazil', 'Barbados', 'Brunei',\n",
       "       'Bhutan', 'Botswana', 'Central African Republic', 'Canada',\n",
       "       'Switzerland', 'Chile', 'China', \"Cote d'Ivoire\", 'Cameroon',\n",
       "       'Congo, Dem. Rep.', 'Congo, Rep.', 'Colombia', 'Comoros',\n",
       "       'Cape Verde', 'Costa Rica', 'Cuba', 'Cyprus', 'Czech Republic',\n",
       "       'Germany', 'Djibouti', 'Dominica', 'Denmark', 'Dominican Republic',\n",
       "       'Algeria', 'Ecuador', 'Egypt', 'Eritrea', 'Spain', 'Estonia',\n",
       "       'Ethiopia', 'Finland', 'Fiji', 'France', 'Micronesia, Fed. Sts.',\n",
       "       'Gabon', 'United Kingdom', 'Georgia', 'Ghana', 'Guinea', 'Gambia',\n",
       "       'Guinea-Bissau', 'Equatorial Guinea', 'Greece', 'Grenada',\n",
       "       'Guatemala', 'Guyana', 'Hong Kong, China', 'Honduras', 'Holy See',\n",
       "       'Croatia', 'Haiti', 'Hungary', 'Indonesia', 'India', 'Ireland',\n",
       "       'Iran', 'Iraq', 'Iceland', 'Israel', 'Italy', 'Jamaica', 'Jordan',\n",
       "       'Japan', 'Kazakhstan', 'Kenya', 'Kyrgyz Republic', 'Cambodia',\n",
       "       'Kiribati', 'St. Kitts and Nevis', 'South Korea', 'Kuwait', 'Lao',\n",
       "       'Lebanon', 'Liberia', 'Libya', 'St. Lucia', 'Liechtenstein',\n",
       "       'Sri Lanka', 'Lesotho', 'Lithuania', 'Luxembourg', 'Latvia',\n",
       "       'Morocco', 'Monaco', 'Moldova', 'Madagascar', 'Maldives', 'Mexico',\n",
       "       'Marshall Islands', 'North Macedonia', 'Mali', 'Malta', 'Myanmar',\n",
       "       'Montenegro', 'Mongolia', 'Mozambique', 'Mauritania', 'Mauritius',\n",
       "       'Malawi', 'Malaysia', 'Namibia', 'Niger', 'Nigeria', 'Nicaragua',\n",
       "       'Netherlands', 'Norway', 'Nepal', 'Nauru', 'New Zealand', 'Oman',\n",
       "       'Pakistan', 'Panama', 'Peru', 'Philippines', 'Palau',\n",
       "       'Papua New Guinea', 'Poland', 'North Korea', 'Portugal',\n",
       "       'Paraguay', 'Palestine', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
       "       'Saudi Arabia', 'Sudan', 'Senegal', 'Singapore', 'Solomon Islands',\n",
       "       'Sierra Leone', 'El Salvador', 'San Marino', 'Somalia', 'Serbia',\n",
       "       'South Sudan', 'Sao Tome and Principe', 'Suriname',\n",
       "       'Slovak Republic', 'Slovenia', 'Sweden', 'Eswatini', 'Seychelles',\n",
       "       'Syria', 'Chad', 'Togo', 'Thailand', 'Tajikistan', 'Turkmenistan',\n",
       "       'Timor-Leste', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey',\n",
       "       'Tuvalu', 'Taiwan', 'Tanzania', 'Uganda', 'Ukraine', 'Uruguay',\n",
       "       'United States', 'Uzbekistan', 'St. Vincent and the Grenadines',\n",
       "       'Venezuela', 'Vietnam', 'Vanuatu', 'Samoa', 'Yemen',\n",
       "       'South Africa', 'Zambia', 'Zimbabwe'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using replace to clean specific entries\n",
    "df['country'] = df['country'].replace({\n",
    "    \"cote d'ivoire\": \"côte d'ivoire\",\n",
    "    \"congo, dem. rep.\": \"democratic republic of the congo\",\n",
    "    \"congo, rep.\": \"republic of the congo\",\n",
    "    \"micronesia, fed. sts.\": \"micronesia\",\n",
    "    \"st. kitts and nevis\": \"saint kitts and nevis\",\n",
    "    \"st. lucia\": \"saint lucia\",\n",
    "    \"st. vincent and the grenadines\": \"saint vincent and the grenadines\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['afghanistan', 'angola', 'albania', 'andorra',\n",
       "       'united arab emirates', 'argentina', 'armenia',\n",
       "       'antigua and barbuda', 'australia', 'austria', 'azerbaijan',\n",
       "       'burundi', 'belgium', 'benin', 'burkina faso', 'bangladesh',\n",
       "       'bulgaria', 'bahrain', 'bahamas', 'bosnia and herzegovina',\n",
       "       'belarus', 'belize', 'bolivia', 'brazil', 'barbados', 'brunei',\n",
       "       'bhutan', 'botswana', 'central african republic', 'canada',\n",
       "       'switzerland', 'chile', 'china', \"côte d'ivoire\", 'cameroon',\n",
       "       'democratic republic of the congo', 'republic of the congo',\n",
       "       'colombia', 'comoros', 'cape verde', 'costa rica', 'cuba',\n",
       "       'cyprus', 'czech republic', 'germany', 'djibouti', 'dominica',\n",
       "       'denmark', 'dominican republic', 'algeria', 'ecuador', 'egypt',\n",
       "       'eritrea', 'spain', 'estonia', 'ethiopia', 'finland', 'fiji',\n",
       "       'france', 'micronesia', 'gabon', 'united kingdom', 'georgia',\n",
       "       'ghana', 'guinea', 'gambia', 'guinea-bissau', 'equatorial guinea',\n",
       "       'greece', 'grenada', 'guatemala', 'guyana', 'hong kong, china',\n",
       "       'honduras', 'holy see', 'croatia', 'haiti', 'hungary', 'indonesia',\n",
       "       'india', 'ireland', 'iran', 'iraq', 'iceland', 'israel', 'italy',\n",
       "       'jamaica', 'jordan', 'japan', 'kazakhstan', 'kenya',\n",
       "       'kyrgyz republic', 'cambodia', 'kiribati', 'saint kitts and nevis',\n",
       "       'south korea', 'kuwait', 'lao', 'lebanon', 'liberia', 'libya',\n",
       "       'saint lucia', 'liechtenstein', 'sri lanka', 'lesotho',\n",
       "       'lithuania', 'luxembourg', 'latvia', 'morocco', 'monaco',\n",
       "       'moldova', 'madagascar', 'maldives', 'mexico', 'marshall islands',\n",
       "       'north macedonia', 'mali', 'malta', 'myanmar', 'montenegro',\n",
       "       'mongolia', 'mozambique', 'mauritania', 'mauritius', 'malawi',\n",
       "       'malaysia', 'namibia', 'niger', 'nigeria', 'nicaragua',\n",
       "       'netherlands', 'norway', 'nepal', 'nauru', 'new zealand', 'oman',\n",
       "       'pakistan', 'panama', 'peru', 'philippines', 'palau',\n",
       "       'papua new guinea', 'poland', 'north korea', 'portugal',\n",
       "       'paraguay', 'palestine', 'qatar', 'romania', 'russia', 'rwanda',\n",
       "       'saudi arabia', 'sudan', 'senegal', 'singapore', 'solomon islands',\n",
       "       'sierra leone', 'el salvador', 'san marino', 'somalia', 'serbia',\n",
       "       'south sudan', 'sao tome and principe', 'suriname',\n",
       "       'slovak republic', 'slovenia', 'sweden', 'eswatini', 'seychelles',\n",
       "       'syria', 'chad', 'togo', 'thailand', 'tajikistan', 'turkmenistan',\n",
       "       'timor-leste', 'tonga', 'trinidad and tobago', 'tunisia', 'turkey',\n",
       "       'tuvalu', 'taiwan', 'tanzania', 'uganda', 'ukraine', 'uruguay',\n",
       "       'united states', 'uzbekistan', 'saint vincent and the grenadines',\n",
       "       'venezuela', 'vietnam', 'vanuatu', 'samoa', 'yemen',\n",
       "       'south africa', 'zambia', 'zimbabwe'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].replace({\n",
    "    \"Hong Kong, China\": \"Hong Kong\",\n",
    "    \"Kyrgyz Republic\": \"Kyrgyzstan\",\n",
    "    \"Slovak Republic\": \"Slovakia\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['afghanistan', 'angola', 'albania', 'andorra',\n",
       "       'united arab emirates', 'argentina', 'armenia',\n",
       "       'antigua and barbuda', 'australia', 'austria', 'azerbaijan',\n",
       "       'burundi', 'belgium', 'benin', 'burkina faso', 'bangladesh',\n",
       "       'bulgaria', 'bahrain', 'bahamas', 'bosnia and herzegovina',\n",
       "       'belarus', 'belize', 'bolivia', 'brazil', 'barbados', 'brunei',\n",
       "       'bhutan', 'botswana', 'central african republic', 'canada',\n",
       "       'switzerland', 'chile', 'china', \"côte d'ivoire\", 'cameroon',\n",
       "       'democratic republic of the congo', 'republic of the congo',\n",
       "       'colombia', 'comoros', 'cape verde', 'costa rica', 'cuba',\n",
       "       'cyprus', 'czech republic', 'germany', 'djibouti', 'dominica',\n",
       "       'denmark', 'dominican republic', 'algeria', 'ecuador', 'egypt',\n",
       "       'eritrea', 'spain', 'estonia', 'ethiopia', 'finland', 'fiji',\n",
       "       'france', 'micronesia', 'gabon', 'united kingdom', 'georgia',\n",
       "       'ghana', 'guinea', 'gambia', 'guinea-bissau', 'equatorial guinea',\n",
       "       'greece', 'grenada', 'guatemala', 'guyana', 'hong kong, china',\n",
       "       'honduras', 'holy see', 'croatia', 'haiti', 'hungary', 'indonesia',\n",
       "       'india', 'ireland', 'iran', 'iraq', 'iceland', 'israel', 'italy',\n",
       "       'jamaica', 'jordan', 'japan', 'kazakhstan', 'kenya',\n",
       "       'kyrgyz republic', 'cambodia', 'kiribati', 'saint kitts and nevis',\n",
       "       'south korea', 'kuwait', 'lao', 'lebanon', 'liberia', 'libya',\n",
       "       'saint lucia', 'liechtenstein', 'sri lanka', 'lesotho',\n",
       "       'lithuania', 'luxembourg', 'latvia', 'morocco', 'monaco',\n",
       "       'moldova', 'madagascar', 'maldives', 'mexico', 'marshall islands',\n",
       "       'north macedonia', 'mali', 'malta', 'myanmar', 'montenegro',\n",
       "       'mongolia', 'mozambique', 'mauritania', 'mauritius', 'malawi',\n",
       "       'malaysia', 'namibia', 'niger', 'nigeria', 'nicaragua',\n",
       "       'netherlands', 'norway', 'nepal', 'nauru', 'new zealand', 'oman',\n",
       "       'pakistan', 'panama', 'peru', 'philippines', 'palau',\n",
       "       'papua new guinea', 'poland', 'north korea', 'portugal',\n",
       "       'paraguay', 'palestine', 'qatar', 'romania', 'russia', 'rwanda',\n",
       "       'saudi arabia', 'sudan', 'senegal', 'singapore', 'solomon islands',\n",
       "       'sierra leone', 'el salvador', 'san marino', 'somalia', 'serbia',\n",
       "       'south sudan', 'sao tome and principe', 'suriname',\n",
       "       'slovak republic', 'slovenia', 'sweden', 'eswatini', 'seychelles',\n",
       "       'syria', 'chad', 'togo', 'thailand', 'tajikistan', 'turkmenistan',\n",
       "       'timor-leste', 'tonga', 'trinidad and tobago', 'tunisia', 'turkey',\n",
       "       'tuvalu', 'taiwan', 'tanzania', 'uganda', 'ukraine', 'uruguay',\n",
       "       'united states', 'uzbekistan', 'saint vincent and the grenadines',\n",
       "       'venezuela', 'vietnam', 'vanuatu', 'samoa', 'yemen',\n",
       "       'south africa', 'zambia', 'zimbabwe'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming you have a DataFrame `df_population` with 'Country', 'Year', and 'Population' columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Filter the data for Afghanistan\u001b[39;00m\n\u001b[1;32m      6\u001b[0m afghanistan_data \u001b[38;5;241m=\u001b[39m df_population[df_population[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfghanistan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame `df_population` with 'Country', 'Year', and 'Population' columns\n",
    "# Filter the data for Afghanistan\n",
    "afghanistan_data = df_population[df_population['Country'] == 'Afghanistan']\n",
    "\n",
    "# Sort the data by year to ensure the plot is in chronological order\n",
    "afghanistan_data = afghanistan_data.sort_values(by='Year')\n",
    "\n",
    "# Plotting the population trend over time using a line chart\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(afghanistan_data['Year'], afghanistan_data['Population'], marker='o', linestyle='-', color='b')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title(\"Population Trend in Afghanistan Over Time\", fontsize=16)\n",
    "plt.xlabel(\"Year\", fontsize=14)\n",
    "plt.ylabel(\"Population\", fontsize=14)\n",
    "\n",
    "# Show the chart\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
