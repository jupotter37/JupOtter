{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5PM1KRMEczD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The content of the file is then tokenized using the simple_tokenizer function, which removes special characters and splits the text into tokens using no python Libraries"
      ],
      "metadata": {
        "id": "pYeE5T9UJ5rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenizer(text):\n",
        "    # Remove all the special characters and replace punctuation with spaces\n",
        "    for char in ['.', ',', '!', '?', ';', ':', '\"', \"'\", '(', ')', '[', ']', '{', '}']:\n",
        "        text = text.replace(char, ' ')\n",
        "\n",
        "    # Split the text into tokens\n",
        "    tokens = text.split()\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Example usage\n",
        "print(\"Original Text:\")\n",
        "print(corpus)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "tokens = simple_tokenizer(corpus)\n",
        "print(\"Tokens after Tokenization:\")\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eJJd7dkIM1p",
        "outputId": "088624f7-7a06-46eb-ae9b-3352a63adcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Welcome to the Programming Education Hub! We take pride in offering a comprehensive array of courses to elevate your programming skills and knowledge.\n",
            "\n",
            "Our curriculum covers a diverse range of subjects, including but not limited to:\n",
            "- Programming Languages: Python, Java, JavaScript, C++, Ruby, and more.\n",
            "- Data Science: Explore the world of data analytics, statistics, and machine learning.\n",
            "- Machine Learning: Dive into the fascinating realm of algorithms, pattern recognition, and artificial intelligence.\n",
            "- Deep Learning: Understand neural networks, deep neural architectures, and applications in modern AI.\n",
            "- Web Development: Master front-end and back-end technologies to craft interactive and dynamic websites.\n",
            "- Mobile App Development: Learn to create mobile applications for iOS and Android platforms.\n",
            "\n",
            "Whether you're a beginner taking your first steps in programming or an experienced developer seeking advanced knowledge, our courses cater to learners of all levels.\n",
            "\n",
            "Immerse yourself in our hands-on projects, coding challenges, and real-world applications. Our instructors, experts in their respective fields, are dedicated to providing you with in-depth insights and practical skills.\n",
            "\n",
            "Join our vibrant community of learners who share a passion for programming and technology. Collaborate on projects, participate in coding competitions, and stay updated with the latest industry trends.\n",
            "\n",
            "In addition to our educational offerings, we'd like to acknowledge the visionary behind our platform—Usman Ghias. As the founder of COD Crafters, a renowned software house, Usman brings a wealth of experience and expertise to our programming courses.\n",
            "\n",
            "Explore the COD Crafters website to discover the projects and technologies championed by Usman Ghias and his team. At COD Crafters, innovation meets excellence, and technology is crafted to shape the future.\n",
            "\n",
            "Embark on a journey of programming excellence, data exploration, and technological innovation with Usman Ghias and the Programming Education Hub. Together, let's unlock the full potential of your coding skills and pave the way for a successful and rewarding career!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tokens after Tokenization:\n",
            "['Welcome', 'to', 'the', 'Programming', 'Education', 'Hub', 'We', 'take', 'pride', 'in', 'offering', 'a', 'comprehensive', 'array', 'of', 'courses', 'to', 'elevate', 'your', 'programming', 'skills', 'and', 'knowledge', 'Our', 'curriculum', 'covers', 'a', 'diverse', 'range', 'of', 'subjects', 'including', 'but', 'not', 'limited', 'to', '-', 'Programming', 'Languages', 'Python', 'Java', 'JavaScript', 'C++', 'Ruby', 'and', 'more', '-', 'Data', 'Science', 'Explore', 'the', 'world', 'of', 'data', 'analytics', 'statistics', 'and', 'machine', 'learning', '-', 'Machine', 'Learning', 'Dive', 'into', 'the', 'fascinating', 'realm', 'of', 'algorithms', 'pattern', 'recognition', 'and', 'artificial', 'intelligence', '-', 'Deep', 'Learning', 'Understand', 'neural', 'networks', 'deep', 'neural', 'architectures', 'and', 'applications', 'in', 'modern', 'AI', '-', 'Web', 'Development', 'Master', 'front-end', 'and', 'back-end', 'technologies', 'to', 'craft', 'interactive', 'and', 'dynamic', 'websites', '-', 'Mobile', 'App', 'Development', 'Learn', 'to', 'create', 'mobile', 'applications', 'for', 'iOS', 'and', 'Android', 'platforms', 'Whether', 'you', 're', 'a', 'beginner', 'taking', 'your', 'first', 'steps', 'in', 'programming', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'knowledge', 'our', 'courses', 'cater', 'to', 'learners', 'of', 'all', 'levels', 'Immerse', 'yourself', 'in', 'our', 'hands-on', 'projects', 'coding', 'challenges', 'and', 'real-world', 'applications', 'Our', 'instructors', 'experts', 'in', 'their', 'respective', 'fields', 'are', 'dedicated', 'to', 'providing', 'you', 'with', 'in-depth', 'insights', 'and', 'practical', 'skills', 'Join', 'our', 'vibrant', 'community', 'of', 'learners', 'who', 'share', 'a', 'passion', 'for', 'programming', 'and', 'technology', 'Collaborate', 'on', 'projects', 'participate', 'in', 'coding', 'competitions', 'and', 'stay', 'updated', 'with', 'the', 'latest', 'industry', 'trends', 'In', 'addition', 'to', 'our', 'educational', 'offerings', 'we', 'd', 'like', 'to', 'acknowledge', 'the', 'visionary', 'behind', 'our', 'platform—Usman', 'Ghias', 'As', 'the', 'founder', 'of', 'COD', 'Crafters', 'a', 'renowned', 'software', 'house', 'Usman', 'brings', 'a', 'wealth', 'of', 'experience', 'and', 'expertise', 'to', 'our', 'programming', 'courses', 'Explore', 'the', 'COD', 'Crafters', 'website', 'to', 'discover', 'the', 'projects', 'and', 'technologies', 'championed', 'by', 'Usman', 'Ghias', 'and', 'his', 'team', 'At', 'COD', 'Crafters', 'innovation', 'meets', 'excellence', 'and', 'technology', 'is', 'crafted', 'to', 'shape', 'the', 'future', 'Embark', 'on', 'a', 'journey', 'of', 'programming', 'excellence', 'data', 'exploration', 'and', 'technological', 'innovation', 'with', 'Usman', 'Ghias', 'and', 'the', 'Programming', 'Education', 'Hub', 'Together', 'let', 's', 'unlock', 'the', 'full', 'potential', 'of', 'your', 'coding', 'skills', 'and', 'pave', 'the', 'way', 'for', 'a', 'successful', 'and', 'rewarding', 'career']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to achieve the same task using the NLTK library, one of the popular NLP libraries in Python."
      ],
      "metadata": {
        "id": "STxgbEXxKF-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSPuy_y8KMu-",
        "outputId": "58158cd1-6b9d-48a6-8754-cbd40c8627da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')  # Download the necessary data\n",
        "\n",
        "def nltk_tokenizer(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Example usage\n",
        "print(\"Original Text:\")\n",
        "print(corpus)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "tokens_nltk = nltk_tokenizer(corpus)\n",
        "print(\"Tokens using NLTK Tokenizer:\")\n",
        "print(tokens_nltk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaTEM-r5IMx5",
        "outputId": "21ca0c42-cd9e-482b-90af-cb233f7eded9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Welcome to the Programming Education Hub! We take pride in offering a comprehensive array of courses to elevate your programming skills and knowledge.\n",
            "\n",
            "Our curriculum covers a diverse range of subjects, including but not limited to:\n",
            "- Programming Languages: Python, Java, JavaScript, C++, Ruby, and more.\n",
            "- Data Science: Explore the world of data analytics, statistics, and machine learning.\n",
            "- Machine Learning: Dive into the fascinating realm of algorithms, pattern recognition, and artificial intelligence.\n",
            "- Deep Learning: Understand neural networks, deep neural architectures, and applications in modern AI.\n",
            "- Web Development: Master front-end and back-end technologies to craft interactive and dynamic websites.\n",
            "- Mobile App Development: Learn to create mobile applications for iOS and Android platforms.\n",
            "\n",
            "Whether you're a beginner taking your first steps in programming or an experienced developer seeking advanced knowledge, our courses cater to learners of all levels.\n",
            "\n",
            "Immerse yourself in our hands-on projects, coding challenges, and real-world applications. Our instructors, experts in their respective fields, are dedicated to providing you with in-depth insights and practical skills.\n",
            "\n",
            "Join our vibrant community of learners who share a passion for programming and technology. Collaborate on projects, participate in coding competitions, and stay updated with the latest industry trends.\n",
            "\n",
            "In addition to our educational offerings, we'd like to acknowledge the visionary behind our platform—Usman Ghias. As the founder of COD Crafters, a renowned software house, Usman brings a wealth of experience and expertise to our programming courses.\n",
            "\n",
            "Explore the COD Crafters website to discover the projects and technologies championed by Usman Ghias and his team. At COD Crafters, innovation meets excellence, and technology is crafted to shape the future.\n",
            "\n",
            "Embark on a journey of programming excellence, data exploration, and technological innovation with Usman Ghias and the Programming Education Hub. Together, let's unlock the full potential of your coding skills and pave the way for a successful and rewarding career!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tokens using NLTK Tokenizer:\n",
            "['Welcome', 'to', 'the', 'Programming', 'Education', 'Hub', '!', 'We', 'take', 'pride', 'in', 'offering', 'a', 'comprehensive', 'array', 'of', 'courses', 'to', 'elevate', 'your', 'programming', 'skills', 'and', 'knowledge', '.', 'Our', 'curriculum', 'covers', 'a', 'diverse', 'range', 'of', 'subjects', ',', 'including', 'but', 'not', 'limited', 'to', ':', '-', 'Programming', 'Languages', ':', 'Python', ',', 'Java', ',', 'JavaScript', ',', 'C++', ',', 'Ruby', ',', 'and', 'more', '.', '-', 'Data', 'Science', ':', 'Explore', 'the', 'world', 'of', 'data', 'analytics', ',', 'statistics', ',', 'and', 'machine', 'learning', '.', '-', 'Machine', 'Learning', ':', 'Dive', 'into', 'the', 'fascinating', 'realm', 'of', 'algorithms', ',', 'pattern', 'recognition', ',', 'and', 'artificial', 'intelligence', '.', '-', 'Deep', 'Learning', ':', 'Understand', 'neural', 'networks', ',', 'deep', 'neural', 'architectures', ',', 'and', 'applications', 'in', 'modern', 'AI', '.', '-', 'Web', 'Development', ':', 'Master', 'front-end', 'and', 'back-end', 'technologies', 'to', 'craft', 'interactive', 'and', 'dynamic', 'websites', '.', '-', 'Mobile', 'App', 'Development', ':', 'Learn', 'to', 'create', 'mobile', 'applications', 'for', 'iOS', 'and', 'Android', 'platforms', '.', 'Whether', 'you', \"'re\", 'a', 'beginner', 'taking', 'your', 'first', 'steps', 'in', 'programming', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'knowledge', ',', 'our', 'courses', 'cater', 'to', 'learners', 'of', 'all', 'levels', '.', 'Immerse', 'yourself', 'in', 'our', 'hands-on', 'projects', ',', 'coding', 'challenges', ',', 'and', 'real-world', 'applications', '.', 'Our', 'instructors', ',', 'experts', 'in', 'their', 'respective', 'fields', ',', 'are', 'dedicated', 'to', 'providing', 'you', 'with', 'in-depth', 'insights', 'and', 'practical', 'skills', '.', 'Join', 'our', 'vibrant', 'community', 'of', 'learners', 'who', 'share', 'a', 'passion', 'for', 'programming', 'and', 'technology', '.', 'Collaborate', 'on', 'projects', ',', 'participate', 'in', 'coding', 'competitions', ',', 'and', 'stay', 'updated', 'with', 'the', 'latest', 'industry', 'trends', '.', 'In', 'addition', 'to', 'our', 'educational', 'offerings', ',', 'we', \"'d\", 'like', 'to', 'acknowledge', 'the', 'visionary', 'behind', 'our', 'platform—Usman', 'Ghias', '.', 'As', 'the', 'founder', 'of', 'COD', 'Crafters', ',', 'a', 'renowned', 'software', 'house', ',', 'Usman', 'brings', 'a', 'wealth', 'of', 'experience', 'and', 'expertise', 'to', 'our', 'programming', 'courses', '.', 'Explore', 'the', 'COD', 'Crafters', 'website', 'to', 'discover', 'the', 'projects', 'and', 'technologies', 'championed', 'by', 'Usman', 'Ghias', 'and', 'his', 'team', '.', 'At', 'COD', 'Crafters', ',', 'innovation', 'meets', 'excellence', ',', 'and', 'technology', 'is', 'crafted', 'to', 'shape', 'the', 'future', '.', 'Embark', 'on', 'a', 'journey', 'of', 'programming', 'excellence', ',', 'data', 'exploration', ',', 'and', 'technological', 'innovation', 'with', 'Usman', 'Ghias', 'and', 'the', 'Programming', 'Education', 'Hub', '.', 'Together', ',', 'let', \"'s\", 'unlock', 'the', 'full', 'potential', 'of', 'your', 'coding', 'skills', 'and', 'pave', 'the', 'way', 'for', 'a', 'successful', 'and', 'rewarding', 'career', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuPcmugFMSBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Lemmatization by Defining the Rules"
      ],
      "metadata": {
        "id": "evy412sVNc6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_lemmatizer(word):\n",
        "    #Rules Definition\n",
        "    lemmatization_rules = {\n",
        "        'courses': 'course',\n",
        "        'programming': 'program',\n",
        "        'languages': 'language',\n",
        "        'analytics': 'analytic',\n",
        "        'statistics': 'statistic',\n",
        "        'learning': 'learn',\n",
        "        'algorithms': 'algorithm',\n",
        "        'pattern': 'pattern',\n",
        "        'intelligence': 'intelligent',\n",
        "        'technologies': 'technology',\n",
        "        'applications': 'application',\n",
        "        'websites': 'website',\n",
        "        'applications': 'application',\n",
        "        'platforms': 'platform',\n",
        "        'steps': 'step',\n",
        "        'skills': 'skill',\n",
        "        'fields': 'field',\n",
        "        'instructors': 'instructor',\n",
        "        'experts': 'expert',\n",
        "        'projects': 'project',\n",
        "        'competitions': 'competition',\n",
        "        'trends': 'trend',\n",
        "        'offerings': 'offering',\n",
        "        'innovation': 'innovate',\n",
        "        'excellence': 'excellent',\n",
        "        'technology': 'technological',\n",
        "        'programming': 'program',\n",
        "        'data': 'datum',\n",
        "        'joints': 'joint',\n",
        "        'platform': 'platform',\n",
        "        'excellence': 'excellent',\n",
        "        'exploration': 'explore',\n",
        "        'innovation': 'innovate',\n",
        "        'education': 'educate',\n",
        "        'journey': 'journey',\n",
        "        'crafters': 'crafter',\n",
        "        'courses': 'course',\n",
        "        'experts': 'expert',\n",
        "        'in-depth': 'in-depth',\n",
        "        'real-world': 'real-world',\n",
        "        'applications': 'application',\n",
        "        'instructors': 'instructor',\n",
        "        'experiences': 'experience',\n",
        "        'passion': 'passion',\n",
        "        'technology': 'technology',\n",
        "        'collaborate': 'collaborate',\n",
        "        'coding': 'code',\n",
        "        'industry': 'industry',\n",
        "        'trends': 'trend',\n",
        "        'offerings': 'offering',\n",
        "        'visionary': 'visionary',\n",
        "        'platform': 'platform',\n",
        "        'experience': 'experience',\n",
        "        'technology': 'technology',\n",
        "        'coding': 'code',\n",
        "        'innovation': 'innovate',\n",
        "        'excellence': 'excellent',\n",
        "        'technology': 'technology',\n",
        "        'shape': 'shape',\n",
        "        'potential': 'potential',\n",
        "        'coding': 'code',\n",
        "        'career': 'career',\n",
        "    }\n",
        "\n",
        "    return lemmatization_rules.get(word, word)\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "\n",
        "# Lemmatization\n",
        "lemmatized_tokens = [simple_lemmatizer(word.lower()) for word in corpus.split()]\n",
        "\n",
        "# Output\n",
        "print(\"Original Text:\")\n",
        "print(corpus)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "print(\"Lemmatized Tokens:\")\n",
        "print(lemmatized_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeweowFwMR4q",
        "outputId": "cd031d63-2612-4fba-d675-57b534029fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Welcome to the Programming Education Hub! We take pride in offering a comprehensive array of courses to elevate your programming skills and knowledge.\n",
            "\n",
            "Our curriculum covers a diverse range of subjects, including but not limited to:\n",
            "- Programming Languages: Python, Java, JavaScript, C++, Ruby, and more.\n",
            "- Data Science: Explore the world of data analytics, statistics, and machine learning.\n",
            "- Machine Learning: Dive into the fascinating realm of algorithms, pattern recognition, and artificial intelligence.\n",
            "- Deep Learning: Understand neural networks, deep neural architectures, and applications in modern AI.\n",
            "- Web Development: Master front-end and back-end technologies to craft interactive and dynamic websites.\n",
            "- Mobile App Development: Learn to create mobile applications for iOS and Android platforms.\n",
            "\n",
            "Whether you're a beginner taking your first steps in programming or an experienced developer seeking advanced knowledge, our courses cater to learners of all levels.\n",
            "\n",
            "Immerse yourself in our hands-on projects, coding challenges, and real-world applications. Our instructors, experts in their respective fields, are dedicated to providing you with in-depth insights and practical skills.\n",
            "\n",
            "Join our vibrant community of learners who share a passion for programming and technology. Collaborate on projects, participate in coding competitions, and stay updated with the latest industry trends.\n",
            "\n",
            "In addition to our educational offerings, we'd like to acknowledge the visionary behind our platform—Usman Ghias. As the founder of COD Crafters, a renowned software house, Usman brings a wealth of experience and expertise to our programming courses.\n",
            "\n",
            "Explore the COD Crafters website to discover the projects and technologies championed by Usman Ghias and his team. At COD Crafters, innovation meets excellence, and technology is crafted to shape the future.\n",
            "\n",
            "Embark on a journey of programming excellence, data exploration, and technological innovation with Usman Ghias and the Programming Education Hub. Together, let's unlock the full potential of your coding skills and pave the way for a successful and rewarding career!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lemmatized Tokens:\n",
            "['welcome', 'to', 'the', 'program', 'educate', 'hub!', 'we', 'take', 'pride', 'in', 'offering', 'a', 'comprehensive', 'array', 'of', 'course', 'to', 'elevate', 'your', 'program', 'skill', 'and', 'knowledge.', 'our', 'curriculum', 'covers', 'a', 'diverse', 'range', 'of', 'subjects,', 'including', 'but', 'not', 'limited', 'to:', '-', 'program', 'languages:', 'python,', 'java,', 'javascript,', 'c++,', 'ruby,', 'and', 'more.', '-', 'datum', 'science:', 'explore', 'the', 'world', 'of', 'datum', 'analytics,', 'statistics,', 'and', 'machine', 'learning.', '-', 'machine', 'learning:', 'dive', 'into', 'the', 'fascinating', 'realm', 'of', 'algorithms,', 'pattern', 'recognition,', 'and', 'artificial', 'intelligence.', '-', 'deep', 'learning:', 'understand', 'neural', 'networks,', 'deep', 'neural', 'architectures,', 'and', 'application', 'in', 'modern', 'ai.', '-', 'web', 'development:', 'master', 'front-end', 'and', 'back-end', 'technology', 'to', 'craft', 'interactive', 'and', 'dynamic', 'websites.', '-', 'mobile', 'app', 'development:', 'learn', 'to', 'create', 'mobile', 'application', 'for', 'ios', 'and', 'android', 'platforms.', 'whether', \"you're\", 'a', 'beginner', 'taking', 'your', 'first', 'step', 'in', 'program', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'knowledge,', 'our', 'course', 'cater', 'to', 'learners', 'of', 'all', 'levels.', 'immerse', 'yourself', 'in', 'our', 'hands-on', 'projects,', 'code', 'challenges,', 'and', 'real-world', 'applications.', 'our', 'instructors,', 'expert', 'in', 'their', 'respective', 'fields,', 'are', 'dedicated', 'to', 'providing', 'you', 'with', 'in-depth', 'insights', 'and', 'practical', 'skills.', 'join', 'our', 'vibrant', 'community', 'of', 'learners', 'who', 'share', 'a', 'passion', 'for', 'program', 'and', 'technology.', 'collaborate', 'on', 'projects,', 'participate', 'in', 'code', 'competitions,', 'and', 'stay', 'updated', 'with', 'the', 'latest', 'industry', 'trends.', 'in', 'addition', 'to', 'our', 'educational', 'offerings,', \"we'd\", 'like', 'to', 'acknowledge', 'the', 'visionary', 'behind', 'our', 'platform—usman', 'ghias.', 'as', 'the', 'founder', 'of', 'cod', 'crafters,', 'a', 'renowned', 'software', 'house,', 'usman', 'brings', 'a', 'wealth', 'of', 'experience', 'and', 'expertise', 'to', 'our', 'program', 'courses.', 'explore', 'the', 'cod', 'crafter', 'website', 'to', 'discover', 'the', 'project', 'and', 'technology', 'championed', 'by', 'usman', 'ghias', 'and', 'his', 'team.', 'at', 'cod', 'crafters,', 'innovate', 'meets', 'excellence,', 'and', 'technology', 'is', 'crafted', 'to', 'shape', 'the', 'future.', 'embark', 'on', 'a', 'journey', 'of', 'program', 'excellence,', 'datum', 'exploration,', 'and', 'technological', 'innovate', 'with', 'usman', 'ghias', 'and', 'the', 'program', 'educate', 'hub.', 'together,', \"let's\", 'unlock', 'the', 'full', 'potential', 'of', 'your', 'code', 'skill', 'and', 'pave', 'the', 'way', 'for', 'a', 'successful', 'and', 'rewarding', 'career!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Sentence Segmentation\n",
        "sentences = sent_tokenize(corpus)\n",
        "\n",
        "print(\"Sentences after Segmentation:\")\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Lemmatization\n",
        "def nltk_lemmatizer(tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Lemmatize each tokenized sentence\n",
        "lemmatized_sentences = [nltk_lemmatizer(tokens) for tokens in tokenized_sentences]\n",
        "\n",
        "print(\"Lemmatized Tokens:\")\n",
        "for i, lemmatized_tokens in enumerate(lemmatized_sentences, 1):\n",
        "    print(f\"{i}. {lemmatized_tokens}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "valHNWWSIMuC",
        "outputId": "c4f1d97a-b626-42c7-8832-e2522183ce2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences after Segmentation:\n",
            "1. Welcome to the Programming Education Hub!\n",
            "2. We take pride in offering a comprehensive array of courses to elevate your programming skills and knowledge.\n",
            "3. Our curriculum covers a diverse range of subjects, including but not limited to:\n",
            "- Programming Languages: Python, Java, JavaScript, C++, Ruby, and more.\n",
            "4. - Data Science: Explore the world of data analytics, statistics, and machine learning.\n",
            "5. - Machine Learning: Dive into the fascinating realm of algorithms, pattern recognition, and artificial intelligence.\n",
            "6. - Deep Learning: Understand neural networks, deep neural architectures, and applications in modern AI.\n",
            "7. - Web Development: Master front-end and back-end technologies to craft interactive and dynamic websites.\n",
            "8. - Mobile App Development: Learn to create mobile applications for iOS and Android platforms.\n",
            "9. Whether you're a beginner taking your first steps in programming or an experienced developer seeking advanced knowledge, our courses cater to learners of all levels.\n",
            "10. Immerse yourself in our hands-on projects, coding challenges, and real-world applications.\n",
            "11. Our instructors, experts in their respective fields, are dedicated to providing you with in-depth insights and practical skills.\n",
            "12. Join our vibrant community of learners who share a passion for programming and technology.\n",
            "13. Collaborate on projects, participate in coding competitions, and stay updated with the latest industry trends.\n",
            "14. In addition to our educational offerings, we'd like to acknowledge the visionary behind our platform—Usman Ghias.\n",
            "15. As the founder of COD Crafters, a renowned software house, Usman brings a wealth of experience and expertise to our programming courses.\n",
            "16. Explore the COD Crafters website to discover the projects and technologies championed by Usman Ghias and his team.\n",
            "17. At COD Crafters, innovation meets excellence, and technology is crafted to shape the future.\n",
            "18. Embark on a journey of programming excellence, data exploration, and technological innovation with Usman Ghias and the Programming Education Hub.\n",
            "19. Together, let's unlock the full potential of your coding skills and pave the way for a successful and rewarding career!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lemmatized Tokens:\n",
            "1. ['Welcome', 'to', 'the', 'Programming', 'Education', 'Hub', '!']\n",
            "2. ['We', 'take', 'pride', 'in', 'offering', 'a', 'comprehensive', 'array', 'of', 'course', 'to', 'elevate', 'your', 'programming', 'skill', 'and', 'knowledge', '.']\n",
            "3. ['Our', 'curriculum', 'cover', 'a', 'diverse', 'range', 'of', 'subject', ',', 'including', 'but', 'not', 'limited', 'to', ':', '-', 'Programming', 'Languages', ':', 'Python', ',', 'Java', ',', 'JavaScript', ',', 'C++', ',', 'Ruby', ',', 'and', 'more', '.']\n",
            "4. ['-', 'Data', 'Science', ':', 'Explore', 'the', 'world', 'of', 'data', 'analytics', ',', 'statistic', ',', 'and', 'machine', 'learning', '.']\n",
            "5. ['-', 'Machine', 'Learning', ':', 'Dive', 'into', 'the', 'fascinating', 'realm', 'of', 'algorithm', ',', 'pattern', 'recognition', ',', 'and', 'artificial', 'intelligence', '.']\n",
            "6. ['-', 'Deep', 'Learning', ':', 'Understand', 'neural', 'network', ',', 'deep', 'neural', 'architecture', ',', 'and', 'application', 'in', 'modern', 'AI', '.']\n",
            "7. ['-', 'Web', 'Development', ':', 'Master', 'front-end', 'and', 'back-end', 'technology', 'to', 'craft', 'interactive', 'and', 'dynamic', 'website', '.']\n",
            "8. ['-', 'Mobile', 'App', 'Development', ':', 'Learn', 'to', 'create', 'mobile', 'application', 'for', 'iOS', 'and', 'Android', 'platform', '.']\n",
            "9. ['Whether', 'you', \"'re\", 'a', 'beginner', 'taking', 'your', 'first', 'step', 'in', 'programming', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'knowledge', ',', 'our', 'course', 'cater', 'to', 'learner', 'of', 'all', 'level', '.']\n",
            "10. ['Immerse', 'yourself', 'in', 'our', 'hands-on', 'project', ',', 'coding', 'challenge', ',', 'and', 'real-world', 'application', '.']\n",
            "11. ['Our', 'instructor', ',', 'expert', 'in', 'their', 'respective', 'field', ',', 'are', 'dedicated', 'to', 'providing', 'you', 'with', 'in-depth', 'insight', 'and', 'practical', 'skill', '.']\n",
            "12. ['Join', 'our', 'vibrant', 'community', 'of', 'learner', 'who', 'share', 'a', 'passion', 'for', 'programming', 'and', 'technology', '.']\n",
            "13. ['Collaborate', 'on', 'project', ',', 'participate', 'in', 'coding', 'competition', ',', 'and', 'stay', 'updated', 'with', 'the', 'latest', 'industry', 'trend', '.']\n",
            "14. ['In', 'addition', 'to', 'our', 'educational', 'offering', ',', 'we', \"'d\", 'like', 'to', 'acknowledge', 'the', 'visionary', 'behind', 'our', 'platform—Usman', 'Ghias', '.']\n",
            "15. ['As', 'the', 'founder', 'of', 'COD', 'Crafters', ',', 'a', 'renowned', 'software', 'house', ',', 'Usman', 'brings', 'a', 'wealth', 'of', 'experience', 'and', 'expertise', 'to', 'our', 'programming', 'course', '.']\n",
            "16. ['Explore', 'the', 'COD', 'Crafters', 'website', 'to', 'discover', 'the', 'project', 'and', 'technology', 'championed', 'by', 'Usman', 'Ghias', 'and', 'his', 'team', '.']\n",
            "17. ['At', 'COD', 'Crafters', ',', 'innovation', 'meet', 'excellence', ',', 'and', 'technology', 'is', 'crafted', 'to', 'shape', 'the', 'future', '.']\n",
            "18. ['Embark', 'on', 'a', 'journey', 'of', 'programming', 'excellence', ',', 'data', 'exploration', ',', 'and', 'technological', 'innovation', 'with', 'Usman', 'Ghias', 'and', 'the', 'Programming', 'Education', 'Hub', '.']\n",
            "19. ['Together', ',', 'let', \"'s\", 'unlock', 'the', 'full', 'potential', 'of', 'your', 'coding', 'skill', 'and', 'pave', 'the', 'way', 'for', 'a', 'successful', 'and', 'rewarding', 'career', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levenshtein Distance by Just using Python"
      ],
      "metadata": {
        "id": "8uEubWtAPkAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(word1, word2):\n",
        "    len_word1, len_word2 = len(word1), len(word2)\n",
        "\n",
        "    # Create a matrix to store distances\n",
        "    matrix = [[0] * (len_word2 + 1) for _ in range(len_word1 + 1)]\n",
        "\n",
        "    # Initialize the matrix\n",
        "    for i in range(len_word1 + 1):\n",
        "        matrix[i][0] = i\n",
        "    for j in range(len_word2 + 1):\n",
        "        matrix[0][j] = j\n",
        "\n",
        "    # Populate the matrix with Levenshtein distances\n",
        "    for i in range(1, len_word1 + 1):\n",
        "        for j in range(1, len_word2 + 1):\n",
        "            cost = 0 if word1[i - 1] == word2[j - 1] else 1\n",
        "            matrix[i][j] = min(\n",
        "                matrix[i - 1][j] + 1,      # Deletion\n",
        "                matrix[i][j - 1] + 1,      # Insertion\n",
        "                matrix[i - 1][j - 1] + cost  # Substitution\n",
        "            )\n",
        "\n",
        "    # The bottom-right cell contains the Levenshtein distance\n",
        "    return matrix[len_word1][len_word2]\n",
        "\n",
        "# Example usage\n",
        "word1 = \"programming\"\n",
        "word2 = \"programing\"\n",
        "\n",
        "lev_distance = levenshtein_distance(word1, word2)\n",
        "\n",
        "# Output\n",
        "print(f\"Levenshtein Distance between '{word1}' and '{word2}': {lev_distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX1_p4tTOrl9",
        "outputId": "19017116-bc5e-453d-b3ad-d236f9c18c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein Distance between 'programming' and 'programing': 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cn2Q2TaPMQpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnmP1rZ-MQnQ",
        "outputId": "74456ad4-a315-4912-87cd-df8ca1c58ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.23.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.23.0 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.23.0->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.23.0 python-Levenshtein-0.23.0 rapidfuzz-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Lemmatization and Segmentation (using a simple approach)\n",
        "lemmatized_tokens = [word.lower() for word in corpus.split()]\n",
        "\n",
        "# Calculate Levenshtein distance between two words\n",
        "word1 = \"programming\"\n",
        "word2 = \"programing\"\n",
        "\n",
        "lev_distance = Levenshtein.distance(word1, word2)\n",
        "\n",
        "# Output\n",
        "#print(\"Original Text:\")\n",
        "#print(corpus)\n",
        "#print(\"\\n\\n\\n\")\n",
        "\n",
        "print(f\"Levenshtein Distance between '{word1}' and '{word2}': {lev_distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFFmDPa8MQkQ",
        "outputId": "d51902e4-5a05-47d4-f2ee-4ee4f35530a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein Distance between 'programming' and 'programing': 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3dHHRgwxQw9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(corpus):\n",
        "    \"\"\"\n",
        "    Get frequency statistics of pairs of consecutive symbols in the corpus.\n",
        "    \"\"\"\n",
        "    stats = {}\n",
        "    for word in corpus:\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols) - 1):\n",
        "            pair = (symbols[i], symbols[i + 1])\n",
        "            stats[pair] = stats.get(pair, 0) + 1\n",
        "    return stats\n",
        "\n",
        "def merge_symbols(corpus, pair):\n",
        "    \"\"\"\n",
        "    Merge the most frequent pair of symbols in the corpus.\n",
        "    \"\"\"\n",
        "    new_corpus = []\n",
        "    bigram = \" \".join(pair)\n",
        "    replacement = \"\".join(pair)\n",
        "    for word in corpus:\n",
        "        new_word = word.replace(bigram, replacement)\n",
        "        new_corpus.append(new_word)\n",
        "    return new_corpus\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "corpus_tokens = corpus.split()\n",
        "\n",
        "# Apply Byte Pair Encoding\n",
        "num_merges = 10  # You can adjust this based on your needs\n",
        "for _ in range(num_merges):\n",
        "    pair_stats = get_stats(corpus_tokens)\n",
        "    if not pair_stats:\n",
        "        break\n",
        "    best_pair = max(pair_stats, key=pair_stats.get)\n",
        "    corpus_tokens = merge_symbols(corpus_tokens, best_pair)\n",
        "\n",
        "# Output\n",
        "#print(\"Original Text:\")\n",
        "#print(corpus)\n",
        "#print(\"\\n\\n\\n\")\n",
        "\n",
        "print(\"Tokenized Text after Byte Pair Encoding:\")\n",
        "print(\" \".join(corpus_tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceVRTYioQv96",
        "outputId": "4a8c389f-7a6a-4e47-cf2e-5228211b9d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Text after Byte Pair Encoding:\n",
            "Welcome to the Programming Education Hub! We take pride in offering a comprehensive array of courses to elevate your programming skills and knowledge. Our curriculum covers a diverse range of subjects, including but not limited to: - Programming Languages: Python, Java, JavaScript, C++, Ruby, and more. - Data Science: Explore the world of data analytics, statistics, and machine learning. - Machine Learning: Dive into the fascinating realm of algorithms, pattern recognition, and artificial intelligence. - Deep Learning: Understand neural networks, deep neural architectures, and applications in modern AI. - Web Development: Master front-end and back-end technologies to craft interactive and dynamic websites. - Mobile App Development: Learn to create mobile applications for iOS and Android platforms. Whether you're a beginner taking your first steps in programming or an experienced developer seeking advanced knowledge, our courses cater to learners of all levels. Immerse yourself in our hands-on projects, coding challenges, and real-world applications. Our instructors, experts in their respective fields, are dedicated to providing you with in-depth insights and practical skills. Join our vibrant community of learners who share a passion for programming and technology. Collaborate on projects, participate in coding competitions, and stay updated with the latest industry trends. In addition to our educational offerings, we'd like to acknowledge the visionary behind our platform—Usman Ghias. As the founder of COD Crafters, a renowned software house, Usman brings a wealth of experience and expertise to our programming courses. Explore the COD Crafters website to discover the projects and technologies championed by Usman Ghias and his team. At COD Crafters, innovation meets excellence, and technology is crafted to shape the future. Embark on a journey of programming excellence, data exploration, and technological innovation with Usman Ghias and the Programming Education Hub. Together, let's unlock the full potential of your coding skills and pave the way for a successful and rewarding career!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHsohCTZML1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphanumeric characters and convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
        "    return text\n",
        "\n",
        "def build_bigram_model(tokens):\n",
        "    bigrams = list(zip(tokens, tokens[1:]))\n",
        "    bigram_counts = Counter(bigrams)\n",
        "    unigram_counts = Counter(tokens)\n",
        "    return bigram_counts, unigram_counts\n",
        "\n",
        "def calculate_bigram_probability(bigram, bigram_counts, unigram_counts, smoothing=1e-5):\n",
        "    # Laplace smoothing for bigram probabilities\n",
        "    numerator = bigram_counts[bigram] + smoothing\n",
        "    denominator = unigram_counts[bigram[0]] + len(unigram_counts) * smoothing\n",
        "    return numerator / denominator\n",
        "\n",
        "def calculate_perplexity(tokens, bigram_counts, unigram_counts):\n",
        "    total_log_prob = 0\n",
        "    for bigram in zip(tokens, tokens[1:]):\n",
        "        bigram_prob = calculate_bigram_probability(bigram, bigram_counts, unigram_counts)\n",
        "        total_log_prob += -math.log2(bigram_prob)\n",
        "    perplexity = 2**(total_log_prob / len(tokens))\n",
        "    return perplexity\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "# Preprocess the corpus\n",
        "corpus = preprocess_text(corpus)\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "corpus_tokens = corpus.split()\n",
        "\n",
        "# Build a bigram language model\n",
        "bigram_counts, unigram_counts = build_bigram_model(corpus_tokens)\n",
        "\n",
        "# Calculate perplexity\n",
        "perplexity = calculate_perplexity(corpus_tokens, bigram_counts, unigram_counts)\n",
        "\n",
        "# Output\n",
        "#print(\"Original Text:\")\n",
        "#print(corpus)\n",
        "#print(\"\\n\\n\\n\")\n",
        "\n",
        "print(f\"Perplexity of the Corpus: {perplexity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxo8k5O2Rs_R",
        "outputId": "76ad90b4-b226-421d-d90c-573f0351ff0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of the Corpus: 2.3187165394073967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYbUirqORs5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Read text from file\n",
        "file_path = \"/content/drive/MyDrive/corpus.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "corpus_tokens = word_tokenize(corpus)\n",
        "\n",
        "# Perform part-of-speech tagging\n",
        "pos_tags = pos_tag(corpus_tokens)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Part-of-Speech Tags:\")\n",
        "for word, pos_tag in pos_tags:\n",
        "    print(f\"{word}: {pos_tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lik1xj4VRs2A",
        "outputId": "7cd8220b-830a-4229-e26a-9ea189788400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech Tags:\n",
            "Welcome: VB\n",
            "to: TO\n",
            "the: DT\n",
            "Programming: NNP\n",
            "Education: NNP\n",
            "Hub: NNP\n",
            "!: .\n",
            "We: PRP\n",
            "take: VBP\n",
            "pride: NN\n",
            "in: IN\n",
            "offering: VBG\n",
            "a: DT\n",
            "comprehensive: JJ\n",
            "array: NN\n",
            "of: IN\n",
            "courses: NNS\n",
            "to: TO\n",
            "elevate: VB\n",
            "your: PRP$\n",
            "programming: VBG\n",
            "skills: NNS\n",
            "and: CC\n",
            "knowledge: NN\n",
            ".: .\n",
            "Our: PRP$\n",
            "curriculum: NN\n",
            "covers: VBZ\n",
            "a: DT\n",
            "diverse: JJ\n",
            "range: NN\n",
            "of: IN\n",
            "subjects: NNS\n",
            ",: ,\n",
            "including: VBG\n",
            "but: CC\n",
            "not: RB\n",
            "limited: JJ\n",
            "to: TO\n",
            ":: :\n",
            "-: :\n",
            "Programming: VBG\n",
            "Languages: NNS\n",
            ":: :\n",
            "Python: NNP\n",
            ",: ,\n",
            "Java: NNP\n",
            ",: ,\n",
            "JavaScript: NNP\n",
            ",: ,\n",
            "C++: NNP\n",
            ",: ,\n",
            "Ruby: NNP\n",
            ",: ,\n",
            "and: CC\n",
            "more: JJR\n",
            ".: .\n",
            "-: :\n",
            "Data: NNPS\n",
            "Science: NN\n",
            ":: :\n",
            "Explore: IN\n",
            "the: DT\n",
            "world: NN\n",
            "of: IN\n",
            "data: NNS\n",
            "analytics: NNS\n",
            ",: ,\n",
            "statistics: NNS\n",
            ",: ,\n",
            "and: CC\n",
            "machine: NN\n",
            "learning: NN\n",
            ".: .\n",
            "-: :\n",
            "Machine: NN\n",
            "Learning: NN\n",
            ":: :\n",
            "Dive: NNP\n",
            "into: IN\n",
            "the: DT\n",
            "fascinating: JJ\n",
            "realm: NN\n",
            "of: IN\n",
            "algorithms: NN\n",
            ",: ,\n",
            "pattern: JJ\n",
            "recognition: NN\n",
            ",: ,\n",
            "and: CC\n",
            "artificial: JJ\n",
            "intelligence: NN\n",
            ".: .\n",
            "-: :\n",
            "Deep: JJ\n",
            "Learning: NNP\n",
            ":: :\n",
            "Understand: NNP\n",
            "neural: JJ\n",
            "networks: NNS\n",
            ",: ,\n",
            "deep: JJ\n",
            "neural: JJ\n",
            "architectures: NNS\n",
            ",: ,\n",
            "and: CC\n",
            "applications: NNS\n",
            "in: IN\n",
            "modern: JJ\n",
            "AI: NNP\n",
            ".: .\n",
            "-: :\n",
            "Web: JJ\n",
            "Development: NNP\n",
            ":: :\n",
            "Master: NN\n",
            "front-end: NN\n",
            "and: CC\n",
            "back-end: JJ\n",
            "technologies: NNS\n",
            "to: TO\n",
            "craft: VB\n",
            "interactive: JJ\n",
            "and: CC\n",
            "dynamic: JJ\n",
            "websites: NNS\n",
            ".: .\n",
            "-: :\n",
            "Mobile: JJ\n",
            "App: NNP\n",
            "Development: NNP\n",
            ":: :\n",
            "Learn: NNP\n",
            "to: TO\n",
            "create: VB\n",
            "mobile: JJ\n",
            "applications: NNS\n",
            "for: IN\n",
            "iOS: NN\n",
            "and: CC\n",
            "Android: NNP\n",
            "platforms: NNS\n",
            ".: .\n",
            "Whether: IN\n",
            "you: PRP\n",
            "'re: VBP\n",
            "a: DT\n",
            "beginner: NN\n",
            "taking: VBG\n",
            "your: PRP$\n",
            "first: JJ\n",
            "steps: NNS\n",
            "in: IN\n",
            "programming: VBG\n",
            "or: CC\n",
            "an: DT\n",
            "experienced: JJ\n",
            "developer: NN\n",
            "seeking: VBG\n",
            "advanced: JJ\n",
            "knowledge: NN\n",
            ",: ,\n",
            "our: PRP$\n",
            "courses: NNS\n",
            "cater: VBP\n",
            "to: TO\n",
            "learners: NNS\n",
            "of: IN\n",
            "all: DT\n",
            "levels: NNS\n",
            ".: .\n",
            "Immerse: NNP\n",
            "yourself: PRP\n",
            "in: IN\n",
            "our: PRP$\n",
            "hands-on: JJ\n",
            "projects: NNS\n",
            ",: ,\n",
            "coding: VBG\n",
            "challenges: NNS\n",
            ",: ,\n",
            "and: CC\n",
            "real-world: NN\n",
            "applications: NNS\n",
            ".: .\n",
            "Our: PRP$\n",
            "instructors: NNS\n",
            ",: ,\n",
            "experts: NNS\n",
            "in: IN\n",
            "their: PRP$\n",
            "respective: JJ\n",
            "fields: NNS\n",
            ",: ,\n",
            "are: VBP\n",
            "dedicated: VBN\n",
            "to: TO\n",
            "providing: VBG\n",
            "you: PRP\n",
            "with: IN\n",
            "in-depth: JJ\n",
            "insights: NNS\n",
            "and: CC\n",
            "practical: JJ\n",
            "skills: NNS\n",
            ".: .\n",
            "Join: VB\n",
            "our: PRP$\n",
            "vibrant: JJ\n",
            "community: NN\n",
            "of: IN\n",
            "learners: NNS\n",
            "who: WP\n",
            "share: NN\n",
            "a: DT\n",
            "passion: NN\n",
            "for: IN\n",
            "programming: VBG\n",
            "and: CC\n",
            "technology: NN\n",
            ".: .\n",
            "Collaborate: NNP\n",
            "on: IN\n",
            "projects: NNS\n",
            ",: ,\n",
            "participate: VB\n",
            "in: IN\n",
            "coding: VBG\n",
            "competitions: NNS\n",
            ",: ,\n",
            "and: CC\n",
            "stay: VB\n",
            "updated: VBN\n",
            "with: IN\n",
            "the: DT\n",
            "latest: JJS\n",
            "industry: NN\n",
            "trends: NNS\n",
            ".: .\n",
            "In: IN\n",
            "addition: NN\n",
            "to: TO\n",
            "our: PRP$\n",
            "educational: JJ\n",
            "offerings: NNS\n",
            ",: ,\n",
            "we: PRP\n",
            "'d: MD\n",
            "like: VB\n",
            "to: TO\n",
            "acknowledge: VB\n",
            "the: DT\n",
            "visionary: NN\n",
            "behind: IN\n",
            "our: PRP$\n",
            "platform—Usman: NN\n",
            "Ghias: NNP\n",
            ".: .\n",
            "As: IN\n",
            "the: DT\n",
            "founder: NN\n",
            "of: IN\n",
            "COD: NNP\n",
            "Crafters: NNP\n",
            ",: ,\n",
            "a: DT\n",
            "renowned: JJ\n",
            "software: NN\n",
            "house: NN\n",
            ",: ,\n",
            "Usman: NNP\n",
            "brings: VBZ\n",
            "a: DT\n",
            "wealth: NN\n",
            "of: IN\n",
            "experience: NN\n",
            "and: CC\n",
            "expertise: NN\n",
            "to: TO\n",
            "our: PRP$\n",
            "programming: NN\n",
            "courses: NNS\n",
            ".: .\n",
            "Explore: IN\n",
            "the: DT\n",
            "COD: NNP\n",
            "Crafters: NNP\n",
            "website: VBP\n",
            "to: TO\n",
            "discover: VB\n",
            "the: DT\n",
            "projects: NNS\n",
            "and: CC\n",
            "technologies: NNS\n",
            "championed: VBN\n",
            "by: IN\n",
            "Usman: NNP\n",
            "Ghias: NNP\n",
            "and: CC\n",
            "his: PRP$\n",
            "team: NN\n",
            ".: .\n",
            "At: IN\n",
            "COD: NNP\n",
            "Crafters: NNP\n",
            ",: ,\n",
            "innovation: NN\n",
            "meets: NNS\n",
            "excellence: NN\n",
            ",: ,\n",
            "and: CC\n",
            "technology: NN\n",
            "is: VBZ\n",
            "crafted: VBN\n",
            "to: TO\n",
            "shape: VB\n",
            "the: DT\n",
            "future: NN\n",
            ".: .\n",
            "Embark: NNP\n",
            "on: IN\n",
            "a: DT\n",
            "journey: NN\n",
            "of: IN\n",
            "programming: VBG\n",
            "excellence: NN\n",
            ",: ,\n",
            "data: NNS\n",
            "exploration: NN\n",
            ",: ,\n",
            "and: CC\n",
            "technological: JJ\n",
            "innovation: NN\n",
            "with: IN\n",
            "Usman: NNP\n",
            "Ghias: NNP\n",
            "and: CC\n",
            "the: DT\n",
            "Programming: NNP\n",
            "Education: NNP\n",
            "Hub: NNP\n",
            ".: .\n",
            "Together: RB\n",
            ",: ,\n",
            "let: VB\n",
            "'s: POS\n",
            "unlock: VB\n",
            "the: DT\n",
            "full: JJ\n",
            "potential: NN\n",
            "of: IN\n",
            "your: PRP$\n",
            "coding: VBG\n",
            "skills: NNS\n",
            "and: CC\n",
            "pave: VB\n",
            "the: DT\n",
            "way: NN\n",
            "for: IN\n",
            "a: DT\n",
            "successful: JJ\n",
            "and: CC\n",
            "rewarding: VBG\n",
            "career: NN\n",
            "!: .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPAVsiUKSDCN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}