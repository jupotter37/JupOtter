{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZUu2PF0gAEM2lE61bEJqI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quamrl-hoda/pwAssignment_/blob/main/deepLearningFrameworksAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1  What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "\n",
        "\n",
        "TensorFlow 2.0 is a significant upgrade from TensorFlow 1.x, designed to enhance usability, simplify model building, and improve performance for machine learning applications. Below are the key features and differences between TensorFlow 2.0 and its predecessor.\n",
        "\n",
        "## Key Features of TensorFlow 2.0\n",
        "\n",
        "- **Eager Execution by Default**: TensorFlow 2.0 uses eager execution as the default mode, allowing operations to be executed immediately as they are called, which simplifies debugging and development[1][2][3].\n",
        "  \n",
        "- **Integration of Keras**: Keras is now the official high-level API for building and training models in TensorFlow 2.0, providing a more intuitive interface for model creation[1][7]. This integration allows users to leverage Keras' simplicity while still benefiting from TensorFlow's robust capabilities.\n",
        "\n",
        "- **Simplified API**: Many deprecated or redundant APIs from TensorFlow 1.x have been removed or consolidated in TensorFlow 2.0, streamlining the user experience and making it easier to learn[1][4][3].\n",
        "\n",
        "- **Improved Model Deployment**: TensorFlow 2.0 supports seamless deployment of models across various platforms, including TensorFlow Lite for mobile devices, TensorFlow.js for web applications, and TensorFlow Extended for production pipelines[5][7].\n",
        "\n",
        "- **Enhanced Performance Features**: The new version includes features such as the Distribution Strategy API for distributed training and AutoGraph for converting Python code into graph code automatically, which improves performance during training[8].\n",
        "\n",
        "## Differences Between TensorFlow 1.x and 2.0\n",
        "\n",
        "| Feature/Aspect               | TensorFlow 1.x                                   | TensorFlow 2.0                                   |\n",
        "|------------------------------|--------------------------------------------------|--------------------------------------------------|\n",
        "| **Execution Model**          | Uses a symbolic graph approach; requires sessions to execute computations[3]. | Eager execution by default; operations are executed immediately[4]. |\n",
        "| **Model Building API**       | Multiple options (e.g., tf.contrib, Keras) leading to confusion[2]. | Keras is the primary API for model building, simplifying the process[1]. |\n",
        "| **API Complexity**           | Contains many outdated APIs; complex to navigate[4]. | Streamlined API with fewer redundancies; easier for newcomers[3]. |\n",
        "| **Debugging**                | More challenging due to the need for sessions[3]. | Easier debugging with immediate execution feedback[5]. |\n",
        "| **Deployment**               | Limited support for deployment across platforms[7]. | Robust deployment capabilities across various platforms like mobile and web[5]. |\n",
        "| **Community Support**        | Gradually evolving community resources[6].      | Strong community support with extensive documentation and tutorials available[8]. |\n"
      ],
      "metadata": {
        "id": "wKjFj224Kdc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2  How do you install TensorFlow 2.0?\n",
        "\n",
        "To install TensorFlow 2.0, you can follow these step-by-step instructions tailored for different operating systems. Below are the general steps for installing TensorFlow 2.0 using pip, which is the recommended method.\n",
        "\n",
        "### Installation Steps\n",
        "\n",
        "#### 1. System Requirements\n",
        "- Ensure you have Python 3.5–3.8 installed.\n",
        "- For GPU support, ensure you have a compatible NVIDIA GPU and the necessary drivers.\n",
        "\n",
        "#### 2. Create a Virtual Environment (Optional but Recommended)\n",
        "Creating a virtual environment helps manage dependencies and avoid conflicts.\n",
        "\n",
        "```bash\n",
        "# Create a virtual environment named 'tf_env'\n",
        "python -m venv tf_env\n",
        "\n",
        "# Activate the virtual environment\n",
        "# On Windows\n",
        "tf_env\\Scripts\\activate\n",
        "# On macOS/Linux\n",
        "source tf_env/bin/activate\n",
        "```\n",
        "\n",
        "#### 3. Upgrade pip\n",
        "Before installing TensorFlow, upgrade pip to the latest version:\n",
        "\n",
        "```bash\n",
        "pip install --upgrade pip\n",
        "```\n",
        "\n",
        "#### 4. Install TensorFlow 2.0\n",
        "You can install TensorFlow 2.0 using the following command:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow==2.0.0\n",
        "```\n",
        "\n",
        "If you want to install TensorFlow with GPU support, use:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow-gpu==2.0.0\n",
        "```\n",
        "\n",
        "**Note**: Do not install both `tensorflow` and `tensorflow-gpu` in the same environment.\n",
        "\n",
        "#### 5. Verify the Installation\n",
        "To ensure that TensorFlow has been installed correctly, run the following command in Python:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)  # This should print '2.0.0'\n",
        "```\n",
        "\n",
        "For GPU verification, run:\n",
        "\n",
        "```python\n",
        "print(tf.config.list_physical_devices('GPU'))  # This should list any available GPUs.\n",
        "```\n"
      ],
      "metadata": {
        "id": "W-o1UvgFKvic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3  What is the primary function of the tf.function in TensorFlow 2.0?\n",
        "\n",
        "The primary function of `tf.function` in TensorFlow 2.0 is to transform Python functions into callable TensorFlow graphs. This transformation enables several key benefits:\n",
        "\n",
        "- **Performance Optimization**: By compiling the function into a graph, TensorFlow can optimize the execution, leading to improved performance during computation. This is particularly beneficial for large-scale machine learning tasks where efficiency is crucial[1][3].\n",
        "\n",
        "- **Eager Execution Bridging**: `tf.function` allows users to write code in a more Pythonic style while still taking advantage of graph execution. It supports data-dependent control flow, meaning you can use standard Python constructs like `if`, `for`, and `while`, which are then converted into their TensorFlow equivalents during graph execution[1][4].\n",
        "\n",
        "- **Polymorphism**: The decorator creates polymorphic callables, meaning it can handle different input types and shapes by generating specialized graphs for each unique input signature. This feature allows TensorFlow to perform optimizations based on the specific characteristics of the inputs[3][4]."
      ],
      "metadata": {
        "id": "qJsC8L2QK-Yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4  What is the purpose of the Model class in TensorFlow 2.0?\n",
        "\n",
        "The `Model` class in TensorFlow 2.0, specifically within the Keras API, serves a crucial role in defining and managing machine learning models. Here are the primary purposes and features of the `Model` class:\n",
        "\n",
        "## Purpose of the Model Class\n",
        "\n",
        "- **Encapsulation of Layers**: The `Model` class groups together layers into a single object, allowing for organized management of the model architecture. This encapsulation helps streamline the process of building complex models by treating them as a cohesive unit.\n",
        "\n",
        "- **Training and Inference**: The `Model` class provides built-in methods for training and inference, such as `fit()`, `evaluate()`, and `predict()`. These methods facilitate the training process by handling data input, loss computation, and optimization automatically.\n",
        "\n",
        "- **Custom Model Architectures**: By subclassing the `Model` class, users can create custom architectures tailored to specific needs. This flexibility allows for the implementation of unique forward passes and layer configurations that may not be possible with predefined models.\n"
      ],
      "metadata": {
        "id": "acHjYxxoLOw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5  How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "Creating a neural network using TensorFlow 2.0 involves several steps, which can be accomplished using the Keras API. Below is a structured guide that outlines how to build a simple neural network model.\n",
        "\n",
        "### Steps to Create a Neural Network in TensorFlow 2.0\n",
        "\n",
        "#### 1. Install TensorFlow\n",
        "Ensure you have TensorFlow 2.0 installed. You can do this via pip:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow==2.0.0\n",
        "```\n",
        "\n",
        "#### 2. Import Required Libraries\n",
        "Start by importing the necessary libraries:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "```\n",
        "\n",
        "#### 3. Prepare the Dataset\n",
        "For this example, let's use the Fashion MNIST dataset, which can be easily loaded from Keras:\n",
        "\n",
        "```python\n",
        "# Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "```\n",
        "\n",
        "#### 4. Define the Model Architecture\n",
        "You can create a neural network using the Sequential API, which is straightforward for stacking layers:\n",
        "\n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),   # Input layer: reshape the input data from 28x28 to 784 vector\n",
        "    layers.Dense(128, activation='relu'),    # Hidden layer with ReLU activation\n",
        "    layers.Dense(10, activation='softmax')   # Output layer for multi-class classification (10 classes)\n",
        "])\n",
        "```\n",
        "\n",
        "#### 5. Compile the Model\n",
        "Before training the model, you need to compile it by specifying the optimizer, loss function, and metrics:\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "#### 6. Train the Model\n",
        "Use the `fit` method to train your model on the training data:\n",
        "\n",
        "```python\n",
        "model.fit(train_images, train_labels, epochs=5)  # Train for 5 epochs\n",
        "```\n",
        "\n",
        "#### 7. Evaluate the Model\n",
        "After training, evaluate your model’s performance on the test dataset:\n",
        "\n",
        "```python\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "```\n"
      ],
      "metadata": {
        "id": "FksZbHi-LhBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6  What is the importance of Tensor Space in TensorFlow?\n",
        "\n",
        "\n",
        "Tensor space is a fundamental concept in TensorFlow that plays a crucial role in how data is represented and manipulated within the framework. Here are the key points regarding its importance:\n",
        "\n",
        "## Importance of Tensor Space in TensorFlow\n",
        "\n",
        "- **Data Representation**: Tensors are the core data structure in TensorFlow, representing multi-dimensional arrays. They can hold various data types, including integers, floats, and strings, making them versatile for different applications in machine learning and deep learning[2].\n",
        "\n",
        "- **Mathematical Operations**: Tensor space allows for efficient execution of mathematical operations. TensorFlow uses tensors to perform computations on large datasets, enabling operations like addition, multiplication, and more complex functions to be carried out efficiently across multiple dimensions[4].\n",
        "\n",
        "- **Shape and Dimension Management**: Understanding tensor shapes (the number of dimensions and the size of each dimension) is crucial for building machine learning models. The shape of a tensor determines how data is organized and influences how operations can be applied. For instance, the shape dictates whether tensors can be broadcast together during operations[2][5].\n",
        "\n",
        "- **Support for Sparse Data**: TensorFlow provides specialized support for sparse tensors, which are efficient representations of tensors containing many zero values. This is particularly important in applications like natural language processing (NLP) and computer vision, where data often contains significant amounts of redundancy[3].\n",
        "\n",
        "- **Facilitating Model Training**: Tensors enable the representation of inputs, outputs, weights, and gradients within neural networks. This representation is essential for training models using backpropagation, where gradients are calculated and updated through tensor operations[4].\n",
        "\n",
        "- **Flexibility in Model Architecture**: Tensor space allows developers to create complex model architectures by combining various tensor operations. This flexibility is vital for implementing advanced techniques such as convolutional layers in CNNs or recurrent layers in RNNs[5].\n"
      ],
      "metadata": {
        "id": "MmJ8TnyvLsuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7  How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "\n",
        "\n",
        "Integrating TensorBoard with TensorFlow 2.0 is a straightforward process that enhances your ability to visualize and monitor the training of machine learning models. Here’s how to do it step-by-step:\n",
        "\n",
        "### Steps to Integrate TensorBoard with TensorFlow 2.0\n",
        "\n",
        "#### 1. Install TensorFlow\n",
        "Ensure you have TensorFlow 2.0 installed:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow==2.0.0\n",
        "```\n",
        "\n",
        "#### 2. Import Required Libraries\n",
        "Start by importing TensorFlow and the necessary Keras components:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "```\n",
        "\n",
        "#### 3. Prepare Your Dataset\n",
        "Load and preprocess your dataset. For example, using the MNIST dataset:\n",
        "\n",
        "```python\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize the data\n",
        "```\n",
        "\n",
        "#### 4. Define Your Model\n",
        "Create a simple neural network model using the Keras Sequential API:\n",
        "\n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "#### 5. Compile the Model\n",
        "Compile the model by specifying the optimizer, loss function, and metrics:\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "#### 6. Set Up TensorBoard Callback\n",
        "Create a TensorBoard callback to log training metrics:\n",
        "\n",
        "```python\n",
        "log_dir = \"logs/fit/\"  # Specify the log directory\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                                   histogram_freq=1,\n",
        "                                                   write_graph=True,\n",
        "                                                   write_images=True)\n",
        "```\n",
        "\n",
        "- **`log_dir`**: Directory where logs will be stored.\n",
        "- **`histogram_freq`**: Frequency for computing activation histograms.\n",
        "- **`write_graph`**: Whether to visualize the graph.\n",
        "- **`write_images`**: Whether to visualize model weights as images.\n",
        "\n",
        "#### 7. Train the Model with TensorBoard Callback\n",
        "Fit your model while passing in the TensorBoard callback:\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard_callback])\n",
        "```\n",
        "\n",
        "#### 8. Launch TensorBoard\n",
        "After training, launch TensorBoard to visualize the logs:\n",
        "\n",
        "```bash\n",
        "%tensorboard --logdir logs/fit/\n",
        "```\n",
        "\n",
        "This command opens a new tab in your browser displaying various visualizations such as loss and accuracy graphs, model architecture, and histograms of weights.\n"
      ],
      "metadata": {
        "id": "0RdltHv3L4wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8  What is the purpose of TensorFlow Playground?\n",
        "\n",
        "TensorFlow Playground is an interactive web application designed to help users understand the fundamentals of neural networks and deep learning without requiring extensive knowledge of mathematics or programming. Here are the key purposes and features of TensorFlow Playground:\n",
        "\n",
        "- **Educational Tool**: TensorFlow Playground serves as an educational platform where users can experiment with neural networks in a visual and intuitive manner. It allows individuals, especially those new to machine learning, to grasp core concepts by manipulating parameters and observing outcomes in real-time[1][2].\n",
        "\n",
        "- **Interactive Experimentation**: Users can modify various aspects of a neural network, such as the number of layers, the number of neurons in each layer, activation functions, learning rates, and more. This hands-on approach facilitates a deeper understanding of how these changes affect the model's performance and behavior[4][5].\n",
        "\n",
        "- **Visualization of Neural Network Operations**: The application visually represents how neural networks operate, showing how data points are classified and how the decision boundaries evolve as training progresses. This visualization helps demystify complex concepts like weight adjustments and feature extraction[2][4].\n",
        "\n",
        "- **Support for Different Datasets**: TensorFlow Playground includes several datasets that users can choose from to test their models, including classification tasks (like XOR and spiral datasets) and regression tasks. This variety allows users to explore different types of machine learning problems[4][5].\n",
        "\n",
        "- **Accessibility**: By providing a browser-based interface, TensorFlow Playground makes it easy for anyone to start experimenting with neural networks without needing to set up a development environment or write code. This accessibility is particularly beneficial for educators and students in introductory courses on artificial intelligence[1][3]."
      ],
      "metadata": {
        "id": "Guwt_EB-MKm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9  What is Netron, and how is it useful for deep learning models?\n",
        "\n",
        "Netron is a powerful open-source tool designed for visualizing neural network, deep learning, and machine learning models. It provides a user-friendly interface that allows researchers and developers to explore the architecture of various models without the need for extensive setup or configuration. Here are the key aspects of Netron and its usefulness:\n",
        "\n",
        "### Purpose of Netron\n",
        "\n",
        "- **Model Visualization**: Netron enables users to visualize the structure of machine learning models, making it easier to understand how different layers and components interact. This is particularly useful for complex models where understanding the architecture can be challenging.\n",
        "\n",
        "- **Support for Multiple Frameworks**: The tool supports a wide range of model formats, including TensorFlow Lite, ONNX, Keras, Caffe, PyTorch, and more. This versatility allows users to work with models from different frameworks without needing to set up each framework individually.\n",
        "\n",
        "- **Accessibility**: By providing a straightforward way to visualize models, Netron eliminates the need for users to install specific libraries or frameworks required for training the model. Users can simply load their model files into Netron and view the architecture directly.\n",
        "\n",
        "- **Detailed Layer Information**: When visualizing a model, Netron displays detailed information about each layer, including layer types, activation functions, input/output shapes, and parameters. This helps users analyze the model's configuration and performance characteristics effectively.\n",
        "\n",
        "- **Exporting Visualizations**: Users can export visualizations as images, which can be useful for documentation or sharing insights with colleagues. This feature enhances collaboration among team members working on machine learning projects.\n",
        "\n",
        "### Usefulness for Deep Learning Models\n",
        "\n",
        "- **Simplifies Model Analysis**: Netron makes it easier to debug and analyze deep learning models by providing clear visual representations of their architectures. This can help identify potential issues or areas for improvement in model design.\n",
        "\n",
        "- **Educational Tool**: For those new to deep learning, Netron serves as an excellent educational resource. It allows learners to explore various architectures interactively, enhancing their understanding of how neural networks function.\n",
        "\n",
        "- **Research Facilitation**: Researchers can use Netron to quickly visualize pre-trained models or architectures from published papers without needing to replicate the entire training environment. This capability accelerates research by allowing quick access to model insights.\n"
      ],
      "metadata": {
        "id": "FkBCBwGSMXkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q10  What is the difference between TensorFlow and PyTorch?\n",
        "\n",
        "\n",
        "The differences between TensorFlow and PyTorch are significant, reflecting their distinct design philosophies and use cases. Here’s a comprehensive comparison based on various factors:\n",
        "\n",
        "### 1. **Design Philosophy**\n",
        "- **TensorFlow**: Utilizes a static computation graph, which requires the entire model architecture to be defined before running any computations. This approach allows for optimizations that can improve performance, particularly in production environments.\n",
        "- **PyTorch**: Employs a dynamic computation graph (eager execution), enabling users to change the model architecture on-the-fly during runtime. This flexibility makes PyTorch more intuitive and user-friendly, especially for research and experimentation.\n",
        "\n",
        "### 2. **Ease of Use**\n",
        "- **PyTorch**: Generally considered more \"Pythonic,\" making it easier for beginners to learn and implement models quickly. The object-oriented design allows for straightforward model building and debugging using standard Python tools.\n",
        "- **TensorFlow**: Historically had a steeper learning curve due to its more complex API and lower-level operations. However, recent updates, including the integration of Keras as a high-level API, have made it more accessible.\n",
        "\n",
        "### 3. **Performance and Scalability**\n",
        "- **TensorFlow**: Known for its strong performance in large-scale applications and distributed training. It efficiently handles complex models and offers robust tools like TensorBoard for visualization and debugging.\n",
        "- **PyTorch**: While it has improved its scalability features, TensorFlow still leads in terms of optimized resource management for large models. PyTorch is often favored for rapid prototyping but may not match TensorFlow's efficiency in production settings.\n",
        "\n",
        "### 4. **Community and Ecosystem**\n",
        "- **TensorFlow**: Backed by Google, it has a large community and extensive resources, making it a popular choice in industry settings for deploying machine learning models.\n",
        "- **PyTorch**: Gaining traction particularly in academic research due to its flexibility and ease of use. The community is rapidly growing, especially among researchers focused on experimental projects.\n",
        "\n",
        "### 5. **Use Cases**\n",
        "- **TensorFlow**: Better suited for production environments where scalability, performance optimization, and deployment are critical. It is widely used in applications like Google Search and by companies like Uber.\n",
        "- **PyTorch**: Preferred in research settings where rapid experimentation and flexibility are essential. It powers applications such as OpenAI's ChatGPT.\n",
        "\n"
      ],
      "metadata": {
        "id": "FnriQBJfMrPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q11  How do you install PyTorch?\n",
        "\n",
        "To install PyTorch, you can follow these steps based on your operating system and preferred package manager (either pip or conda). Here’s a concise guide to help you through the installation process.\n",
        "\n",
        "### Installation Steps for PyTorch\n",
        "\n",
        "#### 1. **Choose Your Environment**\n",
        "It's recommended to create a virtual environment to avoid conflicts with other packages. You can use either `venv` for Python or `conda` if you prefer Anaconda.\n",
        "\n",
        "**Using venv:**\n",
        "```bash\n",
        "# Create a virtual environment\n",
        "python -m venv pytorch_env\n",
        "\n",
        "# Activate the virtual environment\n",
        "# On Windows\n",
        "pytorch_env\\Scripts\\activate\n",
        "# On macOS/Linux\n",
        "source pytorch_env/bin/activate\n",
        "```\n",
        "\n",
        "**Using conda:**\n",
        "```bash\n",
        "# Create a conda environment\n",
        "conda create --name pytorch_env python=3.8\n",
        "\n",
        "# Activate the conda environment\n",
        "conda activate pytorch_env\n",
        "```\n",
        "\n",
        "#### 2. **Install PyTorch**\n",
        "Visit the [PyTorch official website](https://pytorch.org/get-started/locally/) to customize your installation command based on your preferences (OS, package manager, Python version, and whether you want GPU support).\n",
        "\n",
        "**For pip installation:**\n",
        "- **CPU-only version:**\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "- **With CUDA (GPU support):** Replace `x.x` with your CUDA version (e.g., `11.3`).\n",
        "```bash\n",
        "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cuX.X/\n",
        "```\n",
        "\n",
        "**For conda installation:**\n",
        "- **CPU-only version:**\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
        "```\n",
        "- **With CUDA (GPU support):** Again, replace `x.x` with your CUDA version.\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio cudatoolkit=11.x -c pytorch\n",
        "```\n",
        "\n",
        "#### 3. **Verify the Installation**\n",
        "To ensure that PyTorch is installed correctly, run the following commands in a Python console:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "print(torch.__version__)  # Check PyTorch version\n",
        "\n",
        "# Check if CUDA is available (for GPU support)\n",
        "print(torch.cuda.is_available())\n",
        "```\n"
      ],
      "metadata": {
        "id": "CSr2s9k1M9N7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q12 What is the basic structure of a PyTorch neural network?\n",
        "\n",
        "The basic structure of a neural network in PyTorch is defined primarily through the use of the `nn.Module` class, which provides a framework for building and managing neural network architectures. Here’s an overview of how to structure a neural network in PyTorch:\n",
        "\n",
        "### Components of a PyTorch Neural Network\n",
        "\n",
        "1. **Subclassing `nn.Module`**:\n",
        "   - To create a custom neural network, you typically subclass `nn.Module`. This allows you to define your model's architecture and behavior.\n",
        "\n",
        "2. **Initialization (`__init__` method)**:\n",
        "   - In the `__init__` method, you define the layers of your network. This includes fully connected layers (using `nn.Linear`), activation functions (like ReLU), and any other necessary components.\n",
        "   - Example:\n",
        "     ```python\n",
        "     import torch\n",
        "     import torch.nn as nn\n",
        "\n",
        "     class NeuralNetwork(nn.Module):\n",
        "         def __init__(self):\n",
        "             super(NeuralNetwork, self).__init__()\n",
        "             self.flatten = nn.Flatten()  # Flatten input images\n",
        "             self.linear_relu_stack = nn.Sequential(\n",
        "                 nn.Linear(28 * 28, 512),  # First layer with 784 inputs and 512 outputs\n",
        "                 nn.ReLU(),                # Activation function\n",
        "                 nn.Linear(512, 512),      # Second layer\n",
        "                 nn.ReLU(),\n",
        "                 nn.Linear(512, 10)        # Output layer for 10 classes\n",
        "             )\n",
        "     ```\n",
        "\n",
        "3. **Forward Pass (`forward` method)**:\n",
        "   - The `forward` method defines how data flows through the network. It specifies how inputs are transformed into outputs by passing them through the defined layers.\n",
        "   - Example:\n",
        "     ```python\n",
        "         def forward(self, x):\n",
        "             x = self.flatten(x)  # Flatten the input\n",
        "             logits = self.linear_relu_stack(x)  # Pass through the layers\n",
        "             return logits\n",
        "     ```\n",
        "\n",
        "### Example Structure of a Simple Neural Network\n",
        "\n",
        "Here’s a complete example that illustrates the basic structure of a simple feedforward neural network in PyTorch:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()  # Flatten input images\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),  # Input layer: 784 inputs (28x28 images)\n",
        "            nn.ReLU(),                # Activation function for non-linearity\n",
        "            nn.Linear(512, 512),      # Hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)        # Output layer: 10 classes (for digits 0-9)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                  # Flatten the input tensor\n",
        "        logits = self.linear_relu_stack(x)   # Forward pass through layers\n",
        "        return logits\n",
        "\n",
        "# Instantiate the model\n",
        "model = NeuralNetwork()\n",
        "print(model)\n",
        "```\n",
        "\n",
        "### Key Points\n",
        "\n",
        "- **Layers**: Each layer is defined in the `__init__` method using various classes from `torch.nn`, such as `nn.Linear` for fully connected layers and activation functions like `nn.ReLU`.\n",
        "- **Flattening**: The input images are typically flattened into vectors before being passed to the first layer.\n",
        "- **Sequential Container**: The `nn.Sequential` class allows you to stack layers in a sequential manner, simplifying model construction.\n",
        "- **Forward Method**: This method is crucial as it dictates how data flows through the network during both training and inference.\n"
      ],
      "metadata": {
        "id": "T-ehcXf8NNUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q13  What is the significance of tensors in PyTorch?\n",
        "\n",
        "Tensors are a fundamental component of PyTorch, serving as the primary data structure for encoding inputs, outputs, and model parameters in machine learning applications. Here are the key points that highlight the significance of tensors in PyTorch:\n",
        "\n",
        "### 1. **Core Data Structure**\n",
        "Tensors are multi-dimensional arrays that can represent a variety of data types, including integers, floats, and booleans. They are similar to NumPy arrays but with additional capabilities tailored for deep learning. Tensors can efficiently handle large datasets and complex operations, making them essential for building neural networks and performing computations in PyTorch [1][3].\n",
        "\n",
        "### 2. **GPU Acceleration**\n",
        "One of the most significant advantages of tensors in PyTorch is their ability to run on GPUs and other hardware accelerators. This capability allows for faster computation, which is crucial when training large models on extensive datasets. By leveraging GPU resources, PyTorch can execute tensor operations more efficiently than traditional CPU-bound computations [2][3].\n",
        "\n",
        "### 3. **Automatic Differentiation**\n",
        "Tensors in PyTorch are optimized for automatic differentiation, which is vital for training neural networks using backpropagation. When performing operations on tensors, PyTorch automatically tracks gradients, allowing for efficient computation of derivatives. This feature simplifies the implementation of optimization algorithms during model training [2][4].\n",
        "\n",
        "### 4. **Dynamic Computation Graphs**\n",
        "PyTorch utilizes a dynamic computation graph, meaning that the graph is built on-the-fly as operations are executed. This flexibility allows users to change the model architecture during runtime and facilitates debugging and experimentation. Tensors play a crucial role in this dynamic framework by enabling real-time updates to the graph based on tensor operations [1][2].\n",
        "\n",
        "### 5. **Versatile Manipulation**\n",
        "Tensors support a wide range of operations, including reshaping, slicing, and broadcasting, which are essential for preparing data for neural networks. The ability to manipulate tensors easily allows researchers and developers to preprocess datasets effectively and adapt them to various model architectures [1][3].\n",
        "\n",
        "### 6. **Interoperability with NumPy**\n",
        "Tensors can share memory with NumPy arrays, allowing for seamless integration between PyTorch and NumPy workflows. This interoperability enables users to leverage existing NumPy code while benefiting from PyTorch's advanced features [2][3].\n"
      ],
      "metadata": {
        "id": "IRH2YKtmNdOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q14  What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "\n",
        "\n",
        "The difference between `torch.Tensor` and `torch.cuda.Tensor` in PyTorch primarily revolves around where the tensors are stored and how they are utilized in computations. Here’s a detailed breakdown:\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "1. **Memory Location**:\n",
        "   - **`torch.Tensor`**: This type of tensor is stored in CPU memory. All operations performed on these tensors are executed on the CPU.\n",
        "   - **`torch.cuda.Tensor`**: This tensor is specifically designed to reside in GPU memory (CUDA memory). Operations on these tensors are executed on the GPU, which can significantly accelerate computations, especially for large-scale data processing and deep learning tasks.\n",
        "\n",
        "2. **Creation and Usage**:\n",
        "   - **Creating a CPU Tensor**: You can create a tensor on the CPU using:\n",
        "     ```python\n",
        "     cpu_tensor = torch.Tensor([1.0, 2.0, 3.0])\n",
        "     ```\n",
        "   - **Creating a CUDA Tensor**: To create a tensor directly on the GPU, you can use:\n",
        "     ```python\n",
        "     cuda_tensor = torch.cuda.FloatTensor([1.0, 2.0, 3.0])\n",
        "     ```\n",
        "   - Alternatively, you can create a tensor on the CPU and then move it to the GPU:\n",
        "     ```python\n",
        "     cpu_tensor = torch.Tensor([1.0, 2.0, 3.0])\n",
        "     cuda_tensor = cpu_tensor.to('cuda')  # Moves to GPU\n",
        "     ```\n",
        "\n",
        "3. **Operations Compatibility**:\n",
        "   - You cannot perform operations between `torch.Tensor` (CPU) and `torch.cuda.Tensor` (GPU) directly. Mixing these types will result in an error because they reside in different memory spaces. For example:\n",
        "     ```python\n",
        "     result = cpu_tensor + cuda_tensor  # This will raise an error\n",
        "     ```\n",
        "   - To perform operations together, both tensors must be on the same device (either both on CPU or both on GPU).\n",
        "\n",
        "4. **Performance Implications**:\n",
        "   - Using `torch.cuda.Tensor` allows for leveraging GPU acceleration, which is crucial for training deep learning models efficiently. The speedup from using GPUs can be substantial compared to using CPUs for large matrix operations and neural network training.\n",
        "\n",
        "5. **Default Behavior**:\n",
        "   - By default, when you use methods like `.cuda()` or `.to('cuda')`, PyTorch will transfer tensors to the default CUDA device (usually `cuda:0`). If you have multiple GPUs, you can specify which one to use by passing the device index.\n"
      ],
      "metadata": {
        "id": "z-NXEUZSNnHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q15  What is the purpose of the torch.optim module in PyTorch?\n",
        "\n",
        "The `torch.optim` module in PyTorch serves a vital purpose in the training of neural networks by providing a collection of optimization algorithms. These algorithms are essential for adjusting the weights and biases of a model to minimize the loss function, thereby improving the model's performance. Here’s a detailed overview of its significance:\n",
        "\n",
        "### Purpose of `torch.optim`\n",
        "\n",
        "1. **Optimization Algorithms**: The module includes several commonly used optimization algorithms such as:\n",
        "   - **Stochastic Gradient Descent (SGD)**: A foundational optimizer that updates model parameters based on the gradient of the loss function.\n",
        "   - **Adam**: Combines the advantages of two other extensions of SGD, namely AdaGrad and RMSProp, making it suitable for a wide range of problems.\n",
        "   - **Adagrad**: Adapts the learning rate based on historical gradients, which is particularly useful for sparse data.\n",
        "   - **RMSprop**: An adaptive learning rate method that is effective for non-stationary objectives.\n",
        "\n",
        "2. **Parameter Management**: The optimizers in this module can handle multiple parameter groups, allowing users to apply different learning rates or optimization strategies to various parts of a model. This flexibility is beneficial for complex architectures where different layers may require distinct training dynamics.\n",
        "\n",
        "3. **Learning Rate Scheduling**: `torch.optim` supports learning rate schedulers that adjust the learning rate during training based on predefined strategies. This can help enhance convergence and overall model performance.\n",
        "\n",
        "4. **Integration with Training Loop**: The optimizers are designed to fit seamlessly into the training loop:\n",
        "   - Use `optimizer.zero_grad()` to reset gradients before each training iteration.\n",
        "   - Call `loss.backward()` to compute gradients.\n",
        "   - Use `optimizer.step()` to update model parameters based on computed gradients.\n",
        "\n",
        "5. **Custom Optimizers**: Users can create custom optimizers by subclassing `torch.optim.Optimizer`, enabling specialized behavior tailored to specific needs or new optimization algorithms not included in the standard library.\n"
      ],
      "metadata": {
        "id": "FI7FUlR5NyYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q16  What are some common activation functions used in neural networks?\n",
        "\n",
        "Activation functions are crucial components of neural networks that introduce non-linearity into the model, enabling it to learn complex patterns in data. Here are some common activation functions used in neural networks:\n",
        "\n",
        "### 1. **Sigmoid Function**\n",
        "- **Formula**: $$ f(x) = \\frac{1}{1 + e^{-x}} $$\n",
        "- **Range**: (0, 1)\n",
        "- **Use Case**: Commonly used for binary classification problems as it outputs probabilities.\n",
        "\n",
        "### 2. **Tanh (Hyperbolic Tangent)**\n",
        "- **Formula**: $$ f(x) = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} $$\n",
        "- **Range**: (-1, 1)\n",
        "- **Use Case**: Often preferred over the sigmoid function because it centers the data, leading to faster convergence.\n",
        "\n",
        "### 3. **ReLU (Rectified Linear Unit)**\n",
        "- **Formula**: $$ f(x) = \\max(0, x) $$\n",
        "- **Range**: [0, ∞)\n",
        "- **Use Case**: Widely used in hidden layers of deep networks due to its simplicity and effectiveness in mitigating the vanishing gradient problem.\n",
        "\n",
        "### 4. **Leaky ReLU**\n",
        "- **Formula**: $$ f(x) = \\begin{cases}\n",
        "x & \\text{if } x > 0 \\\\\n",
        "\\alpha x & \\text{if } x \\leq 0\n",
        "\\end{cases} $$ (where $$ \\alpha $$ is a small constant, e.g., 0.01)\n",
        "- **Range**: (-∞, ∞)\n",
        "- **Use Case**: Addresses the \"dying ReLU\" problem by allowing a small gradient when the unit is not active.\n",
        "\n",
        "### 5. **Softmax**\n",
        "- **Formula**: $$ f(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}} $$\n",
        "- **Range**: (0, 1), and the outputs sum to 1.\n",
        "- **Use Case**: Typically used in the output layer of multi-class classification problems to produce probabilities for each class.\n",
        "\n",
        "### 6. **Linear Activation Function**\n",
        "- **Formula**: $$ f(x) = x $$\n",
        "- **Range**: (-∞, ∞)\n",
        "- **Use Case**: Used in regression tasks where the output can take any value.\n"
      ],
      "metadata": {
        "id": "BpKDsaU_N9K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q17  What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "\n",
        "\n",
        "The difference between `torch.nn.Module` and `torch.nn.Sequential` in PyTorch lies in their structure, usage, and flexibility in defining neural network architectures. Here’s a detailed comparison based on the provided search results:\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "1. **Definition and Structure**:\n",
        "   - **`torch.nn.Module`**: This is the base class for all neural network modules in PyTorch. When you create a custom model, you typically subclass `nn.Module`. This requires defining two main methods:\n",
        "     - `__init__()`: Where you initialize the layers of the model.\n",
        "     - `forward()`: Where you define the forward pass, specifying how input data flows through the layers.\n",
        "   - **`torch.nn.Sequential`**: This is a subclass of `nn.Module` that allows you to define a neural network in a simpler way when the layers are arranged sequentially. You can pass layers as arguments to `nn.Sequential`, and it automatically handles the forward pass without needing to explicitly define it.\n",
        "\n",
        "2. **Usage**:\n",
        "   - **`nn.Module`**: Used when you need more control over the model architecture, such as implementing complex architectures that require branching or multiple inputs/outputs. It is ideal for models where the flow of data is not strictly sequential.\n",
        "   - **`nn.Sequential`**: Best suited for straightforward architectures where layers are stacked one after another. It simplifies code for models that do not require additional logic in the forward method.\n",
        "\n",
        "3. **Flexibility**:\n",
        "   - **`nn.Module`**: Offers greater flexibility since you can implement any kind of forward pass logic, including conditional operations, loops, or other complex structures.\n",
        "   - **`nn.Sequential`**: Limited to linear stacks of layers. If you need to perform operations that deviate from a simple chain (like skipping connections or merging outputs), you would need to use `nn.Module`.\n",
        "\n",
        "4. **Example Usage**:\n",
        "   - **Using `nn.Module`**:\n",
        "     ```python\n",
        "     import torch.nn as nn\n",
        "\n",
        "     class MyModel(nn.Module):\n",
        "         def __init__(self):\n",
        "             super(MyModel, self).__init__()\n",
        "             self.layer1 = nn.Linear(10, 5)\n",
        "             self.layer2 = nn.ReLU()\n",
        "\n",
        "         def forward(self, x):\n",
        "             x = self.layer1(x)\n",
        "             return self.layer2(x)\n",
        "     ```\n",
        "   - **Using `nn.Sequential`**:\n",
        "     ```python\n",
        "     import torch.nn as nn\n",
        "\n",
        "     model = nn.Sequential(\n",
        "         nn.Linear(10, 5),\n",
        "         nn.ReLU()\n",
        "     )\n",
        "     ```\n",
        "\n",
        "5. **When to Use Each**:\n",
        "   - Use **`nn.Module`** when building complex models that require custom behavior in the forward method or involve multiple branches.\n",
        "   - Use **`nn.Sequential`** for simpler models where layers are applied sequentially without additional logic.\n"
      ],
      "metadata": {
        "id": "eu0bbSkjOIQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q18  How can you monitor training progress in TensorFlow 2.0?\n",
        "\n",
        "\n",
        "Monitoring training progress in TensorFlow 2.0 is essential for understanding how well your model is learning and for making adjustments to improve performance. Here are several methods to effectively monitor the training process:\n",
        "\n",
        "### 1. **Using Callbacks**\n",
        "TensorFlow provides a variety of callback functions that can be used during the training process to monitor performance and make decisions based on the metrics:\n",
        "\n",
        "- **ModelCheckpoint**: This callback saves the model at specified intervals, allowing you to keep the best-performing version of your model based on validation metrics.\n",
        "  \n",
        "- **EarlyStopping**: This callback stops training when a monitored metric has stopped improving, which helps prevent overfitting.\n",
        "\n",
        "Example of setting up callbacks:\n",
        "```python\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Use callbacks in model training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, callbacks=[checkpoint, early_stopping])\n",
        "```\n",
        "\n",
        "### 2. **Using TensorBoard**\n",
        "TensorBoard is a powerful visualization tool that allows you to monitor various aspects of your model's training process in real-time:\n",
        "\n",
        "- **Metrics Visualization**: You can visualize loss and accuracy over epochs, view histograms of weights and biases, and observe gradients.\n",
        "  \n",
        "- **Setup**: To use TensorBoard, you need to create a TensorBoard callback that logs metrics during training.\n",
        "\n",
        "Example setup for TensorBoard:\n",
        "```python\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Set up TensorBoard logging\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Use the callback in model training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, callbacks=[tensorboard_callback])\n",
        "```\n",
        "\n",
        "To view the logs in TensorBoard:\n",
        "```bash\n",
        "tensorboard --logdir=logs/fit/\n",
        "```\n",
        "\n",
        "### 3. **Custom Training Loops**\n",
        "For more control over the training process, you can implement custom training loops using `tf.GradientTape`. This allows you to manually track and print metrics during each epoch or batch.\n",
        "\n",
        "Example of a custom training loop:\n",
        "```python\n",
        "for epoch in range(epochs):\n",
        "    for batch in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(batch[0], training=True)\n",
        "            loss = loss_fn(batch[1], predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
        "```\n",
        "\n",
        "### 4. **Progress Bars**\n",
        "You can also implement progress bars using `tf.keras.utils.Progbar` or similar utilities to provide visual feedback during training.\n"
      ],
      "metadata": {
        "id": "purG_xM7OVF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q19  How does the Keras API fit into TensorFlow 2.0?\n",
        "\n",
        "The Keras API plays a significant role in TensorFlow 2.0, providing a high-level interface for building and training machine learning models. Here’s how it fits into TensorFlow 2.0:\n",
        "\n",
        "### Integration with TensorFlow 2.0\n",
        "\n",
        "1. **Unified API**: Keras is integrated directly into TensorFlow 2.0 as `tf.keras`, allowing users to access all Keras functionalities without needing to install it separately. This integration simplifies the workflow for developers and researchers by providing a consistent API for model building, training, and evaluation.\n",
        "\n",
        "2. **Ease of Use**: The Keras API is designed to be user-friendly, enabling developers to create complex neural network architectures with fewer lines of code. It abstracts many of the lower-level details involved in model construction, allowing users to focus more on designing their models rather than on implementation specifics[1].\n",
        "\n",
        "3. **Model Types**: Keras supports various model architectures, including:\n",
        "   - **Sequential Models**: For linear stacks of layers where each layer has exactly one input tensor and one output tensor.\n",
        "   - **Functional API**: For more complex architectures that require multiple inputs or outputs, shared layers, or non-linear connections.\n",
        "   - **Model Subclassing**: Allows for complete customization of the model architecture by subclassing `tf.keras.Model`[2].\n",
        "\n",
        "4. **Training and Evaluation**: The Keras API provides built-in methods such as `fit()`, `evaluate()`, and `predict()`, which streamline the training and evaluation process. These methods handle data input, loss computation, and optimization automatically, making it easier for users to implement machine learning workflows[1][2].\n",
        "\n",
        "5. **Callbacks and Monitoring**: Keras includes various callbacks (e.g., ModelCheckpoint, EarlyStopping) that allow users to monitor training progress and make adjustments dynamically. This feature enhances the ability to manage training effectively and prevent overfitting.\n",
        "\n",
        "6. **Compatibility with TensorFlow Features**: The integration ensures that Keras models can leverage TensorFlow's powerful features, such as distributed training, mixed precision training, and TensorBoard for visualization. This compatibility enhances the capabilities of Keras while maintaining its simplicity[1][4].\n"
      ],
      "metadata": {
        "id": "ke-94GCPOehK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q20  What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "\n",
        "\n",
        "\n",
        "#### Steps to Implement the Project:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Load the MNIST dataset using TensorFlow's built-in functions.\n",
        "   - Preprocess the data by normalizing the pixel values to a range of [0, 1] and reshaping the images if necessary.\n",
        "\n",
        "2. **Model Design**:\n",
        "   - Use the Keras API within TensorFlow to define a neural network architecture. A common choice is to use a Convolutional Neural Network (CNN) for better performance on image data.\n",
        "   - Example architecture might include:\n",
        "     - Input layer (28x28 pixels)\n",
        "     - Convolutional layers with ReLU activation\n",
        "     - Pooling layers\n",
        "     - Fully connected layers\n",
        "     - Output layer with softmax activation for classification.\n",
        "\n",
        "3. **Training the Model**:\n",
        "   - Compile the model with an appropriate optimizer (e.g., Adam), loss function (e.g., sparse categorical crossentropy), and metrics (e.g., accuracy).\n",
        "   - Train the model on the training dataset while validating it on a separate validation set.\n",
        "\n",
        "4. **Evaluation**:\n",
        "   - Evaluate the model's performance on a test set to determine its accuracy.\n",
        "   - Analyze confusion matrices or classification reports to understand misclassifications.\n",
        "\n",
        "5. **Deployment**:\n",
        "   - Optionally, deploy the model using TensorFlow Serving or create a simple web application to allow users to input handwritten digits for prediction.\n",
        "\n",
        "### Example\n",
        "\n"
      ],
      "metadata": {
        "id": "sZ6ExTeAOoPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1nEnlCsKUAO",
        "outputId": "c915fdc6-be0c-4aee-e60f-e0405b1f7637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 30ms/step - accuracy: 0.8959 - loss: 0.3388 - val_accuracy: 0.9867 - val_loss: 0.0463\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 27ms/step - accuracy: 0.9840 - loss: 0.0503 - val_accuracy: 0.9882 - val_loss: 0.0387\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.9890 - loss: 0.0358 - val_accuracy: 0.9883 - val_loss: 0.0468\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0237 - val_accuracy: 0.9870 - val_loss: 0.0512\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 28ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 0.9873 - val_loss: 0.0473\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0492\n",
            "Test accuracy: 0.9871000051498413\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q21  What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "The main advantage of using pre-trained models in TensorFlow and PyTorch is their ability to significantly reduce development time and improve performance for various machine learning tasks. Here are the key benefits:\n",
        "\n",
        "### 1. **Reduced Development Time**\n",
        "Pre-trained models come with knowledge acquired during extensive training on large datasets. This means that developers do not need to start from scratch, allowing for quicker implementation of models. By leveraging existing architectures and weights, practitioners can focus on fine-tuning the model for their specific tasks rather than building and training a new model from the ground up [3][4].\n",
        "\n",
        "### 2. **Improved Performance**\n",
        "Models that have been pre-trained often outperform those trained from scratch, particularly in tasks that require a deep understanding of data. The extensive general knowledge gained during pre-training helps these models achieve better accuracy and robustness in real-world applications [3].\n",
        "\n",
        "### 3. **Transfer Learning**\n",
        "Pre-trained models facilitate transfer learning, which allows users to adapt these models to new tasks with relatively small datasets. This is particularly beneficial in scenarios where labeled data is scarce or expensive to obtain, enabling effective use of limited resources [3][4].\n",
        "\n",
        "### 4. **Resource Efficiency**\n",
        "Fine-tuning a pre-trained model typically requires fewer computational resources compared to training a large model from scratch. This efficiency is crucial for researchers and organizations with limited computational power or budgets, making advanced machine learning techniques more accessible [3].\n",
        "\n",
        "### 5. **Versatility**\n",
        "Pre-trained models are versatile and can be adapted for various applications within a domain. For instance, a pre-trained language model can be fine-tuned for tasks such as translation, summarization, or sentiment analysis, allowing for broader applicability across different problems [3][4].\n",
        "\n",
        "### 6. **State-of-the-Art Results**\n",
        "Utilizing pre-trained models often leads to state-of-the-art performance on benchmark datasets, as these models have been trained on vast amounts of data and are optimized for specific tasks [3].\n"
      ],
      "metadata": {
        "id": "N9TyhmbzPH4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Practical**"
      ],
      "metadata": {
        "id": "R8t4LQqyPPrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1  How do you install and verify that TensorFlow 2.0 was installed successfully?\n",
        "\n",
        "\n",
        "To install TensorFlow 2.0 and verify that it was installed successfully, you can follow these steps:\n",
        "\n",
        "### Installation Steps\n",
        "\n",
        "1. **Upgrade pip**: Ensure that you have the latest version of pip.\n",
        "   ```bash\n",
        "   pip install --upgrade pip\n",
        "   ```\n",
        "\n",
        "2. **Install TensorFlow**:\n",
        "   - For CPU users:\n",
        "     ```bash\n",
        "     pip install tensorflow==2.0.0\n",
        "     ```\n",
        "   - For GPU users (ensure you have the appropriate CUDA and cuDNN installed):\n",
        "     ```bash\n",
        "     pip install tensorflow-gpu==2.0.0\n",
        "     ```\n",
        "\n",
        "### Verification Steps\n",
        "\n",
        "After installing TensorFlow, you can verify the installation with the following commands:\n",
        "\n",
        "- **Verify CPU setup**:\n",
        "   ```bash\n",
        "   python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n",
        "   ```\n",
        "   If a tensor is returned, you've installed TensorFlow successfully.\n",
        "\n",
        "- **Verify GPU setup** (if applicable):\n",
        "   ```bash\n",
        "   python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
        "   ```\n",
        "   If a list of GPU devices is returned, you've installed TensorFlow successfully.\n",
        "\n"
      ],
      "metadata": {
        "id": "hfqMwbDNPueT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tensorflow==2.0.0  # or pip install tensorflow-gpu==2.0.0 for GPU users\n",
        "\n",
        "# Verify installation\n",
        "import tensorflow as tf;\n",
        "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
        "import tensorflow as tf;\n",
        "print(tf.config.list_physical_devices('GPU'))  # For GPU users"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GUeeq5OPOWf",
        "outputId": "654aacb7-b97f-4909-86da-edc8e329b64a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mtf.Tensor(1331.571, shape=(), dtype=float32)\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2  How can you define a simple function in TensorFlow 2.0 to perform addition?"
      ],
      "metadata": {
        "id": "yb5XLtVpQlqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple addition function\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Example usage\n",
        "x = tf.constant(5)\n",
        "y = tf.constant(3)\n",
        "\n",
        "result = add(x, y)\n",
        "print(f'The result of adding {x.numpy()} and {y.numpy()} is: {result.numpy()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQe9zwN-PO5i",
        "outputId": "257d952f-e88e-41ac-df2a-950685377409"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of adding 5 and 3 is: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3  How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n",
        "\n",
        "To create a simple neural network in TensorFlow 2.0 with one hidden layer, you can utilize the Keras API, which is integrated into TensorFlow. Below is a step-by-step guide along with example code to demonstrate how to set up and train this model using the popular MNIST dataset for handwritten digit classification.\n",
        "\n",
        "### Step-by-Step Guide\n",
        "\n",
        "1. **Import Required Libraries**: Start by importing TensorFlow and necessary modules.\n",
        "2. **Load and Preprocess the Data**: Load the MNIST dataset and preprocess it by normalizing the pixel values.\n",
        "3. **Define the Model**: Use the Sequential API to create a model with one hidden layer.\n",
        "4. **Compile the Model**: Specify the optimizer, loss function, and metrics.\n",
        "5. **Train the Model**: Fit the model on the training data.\n",
        "6. **Evaluate the Model**: Test the model's performance on unseen data.\n",
        "\n",
        "### Example\n"
      ],
      "metadata": {
        "id": "Oqkf7AqXQwOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape((60000, 28 * 28)).astype('float32') / 255  # Flatten and normalize\n",
        "X_test = X_test.reshape((10000, 28 * 28)).astype('float32') / 255    # Flatten and normalize\n",
        "\n",
        "# Step 2: Define the model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(28 * 28,)),  # Hidden layer with 128 neurons\n",
        "    layers.Dense(10, activation='softmax')                         # Output layer for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(X_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv-vC5UwPO2k",
        "outputId": "0cbafc3c-4bef-4221-db6d-6f7424a05e65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.4492 - val_accuracy: 0.9657 - val_loss: 0.1301\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1267 - val_accuracy: 0.9723 - val_loss: 0.0977\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0882 - val_accuracy: 0.9755 - val_loss: 0.0821\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0638 - val_accuracy: 0.9772 - val_loss: 0.0809\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0488 - val_accuracy: 0.9783 - val_loss: 0.0712\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.0825\n",
            "Test accuracy: 0.977400004863739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4  How can you visualize the training progress using TensorFlow and Matplotlib?\n",
        "\n",
        "To visualize the training progress of a model in TensorFlow using Matplotlib, you can track metrics such as loss and accuracy during training and then plot these metrics after training is complete. Below is a step-by-step guide along with example code to demonstrate how to achieve this.\n",
        "\n",
        "### Step-by-Step Guide\n",
        "\n",
        "1. **Import Required Libraries**: Import TensorFlow, Matplotlib, and any other necessary libraries.\n",
        "2. **Load and Preprocess Data**: Use a dataset (e.g., MNIST) for training.\n",
        "3. **Define the Model**: Create a simple neural network model using Keras.\n",
        "4. **Train the Model**: Fit the model to the training data while recording metrics.\n",
        "5. **Visualize the Training Progress**: Use Matplotlib to plot the loss and accuracy.\n",
        "\n",
        "### Example"
      ],
      "metadata": {
        "id": "Q_vMSFiZRL2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape((60000, 28 * 28)).astype('float32') / 255  # Flatten and normalize\n",
        "X_test = X_test.reshape((10000, 28 * 28)).astype('float32') / 255    # Flatten and normalize\n",
        "\n",
        "# Step 2: Define the model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(28 * 28,)),  # Hidden layer with 128 neurons\n",
        "    layers.Dense(10, activation='softmax')                         # Output layer for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model and store history\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Step 5: Visualize the training progress\n",
        "# Plotting loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "DP2vpO8JPO0q",
        "outputId": "8093145b-95ba-4600-bcdd-088628f56231"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.4568 - val_accuracy: 0.9660 - val_loss: 0.1216\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1325 - val_accuracy: 0.9690 - val_loss: 0.1033\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.0870 - val_accuracy: 0.9775 - val_loss: 0.0807\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0617 - val_accuracy: 0.9753 - val_loss: 0.0860\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0470 - val_accuracy: 0.9778 - val_loss: 0.0694\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5  How do you install PyTorch and verify the PyTorch installation?\n",
        "\n",
        "To install PyTorch and verify the installation, you can follow these steps based on the provided search results. Below is a concise guide that includes the installation commands and verification steps.\n",
        "\n",
        "### Step 1: Set Up a Python Environment\n",
        "\n",
        "It is recommended to create a virtual environment to avoid conflicts with other packages. You can use either `venv` or `conda`.\n",
        "\n",
        "#### Using `venv`:\n",
        "```bash\n",
        "# Create a virtual environment\n",
        "python -m venv myenv\n",
        "\n",
        "# Activate the virtual environment\n",
        "# On Windows\n",
        "myenv\\Scripts\\activate\n",
        "# On macOS/Linux\n",
        "source myenv/bin/activate\n",
        "```\n",
        "\n",
        "#### Using `conda`:\n",
        "```bash\n",
        "# Create a conda environment\n",
        "conda create -n myenv python=3.9\n",
        "\n",
        "# Activate the conda environment\n",
        "conda activate myenv\n",
        "```\n",
        "\n",
        "### Step 2: Install PyTorch\n",
        "\n",
        "You can install PyTorch using either `pip` or `conda`. The following command installs the stable version of PyTorch:\n",
        "\n",
        "#### Using `pip`:\n",
        "```bash\n",
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # For CUDA 11.8\n",
        "```\n",
        "\n",
        "#### Using `conda`:\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch  # For CUDA 11.8\n",
        "```\n",
        "\n",
        "### Step 3: Verify the Installation\n",
        "\n",
        "After installing PyTorch, you can verify that it was installed successfully by running the following commands in Python:\n",
        "\n",
        "1. **Check if PyTorch is installed**:\n",
        "   ```python\n",
        "   import torch\n",
        "   print(torch.__version__)  # This will print the version of PyTorch installed\n",
        "   ```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iHe4CG2GRiFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6  How do you create a simple neural network in PyTorch?\n",
        "\n",
        "To create a simple neural network in PyTorch, you can follow these steps, which include defining the model architecture, setting up the training process, and training the model using a dataset. Below is a complete example that demonstrates how to implement a basic feedforward neural network using the MNIST dataset for handwritten digit classification.\n",
        "\n",
        "### Step-by-Step Implementation\n",
        "\n",
        "1. **Import Required Libraries**: Import PyTorch and other necessary libraries.\n",
        "2. **Load and Preprocess Data**: Load the MNIST dataset and preprocess it.\n",
        "3. **Define the Neural Network**: Create a simple feedforward neural network with one hidden layer.\n",
        "4. **Set Up Loss Function and Optimizer**: Define the loss function and optimizer for training.\n",
        "5. **Train the Model**: Implement the training loop to train the model.\n",
        "6. **Evaluate the Model**: Test the model's performance on unseen data.\n",
        "\n",
        "### Example\n",
        "\n"
      ],
      "metadata": {
        "id": "zEKpIi0RSNtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Define the neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(128, 10)        # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
        "        x = torch.relu(self.fc1(x))  # Apply ReLU activation\n",
        "        x = self.fc2(x)               # Output layer\n",
        "        return x\n",
        "\n",
        "# Step 3: Initialize the model, loss function, and optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Step 4: Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()           # Zero the gradients\n",
        "        outputs = model(images)         # Forward pass\n",
        "        loss = criterion(outputs, labels) # Compute loss\n",
        "        loss.backward()                 # Backward pass\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on test images: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD2YLnw8POyv",
        "outputId": "81bd0e94-9411-411d-b6fc-a26a5276f9e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 154kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.51MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/5], Loss: 0.1965\n",
            "Epoch [2/5], Loss: 0.0935\n",
            "Epoch [3/5], Loss: 0.2685\n",
            "Epoch [4/5], Loss: 0.0806\n",
            "Epoch [5/5], Loss: 0.1388\n",
            "Accuracy of the model on test images: 96.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7  How do you define a loss function and optimizer in PyTorch?\n",
        "\n",
        "To define a loss function and an optimizer in PyTorch, you can follow these steps. This includes selecting a suitable loss function based on your task (classification, regression, etc.) and choosing an optimizer to update the model's parameters during training.\n",
        "\n",
        "### Step 1: Import Required Libraries\n",
        "\n",
        "First, ensure you have PyTorch installed and import the necessary modules.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "```\n",
        "\n",
        "### Step 2: Define a Loss Function\n",
        "\n",
        "PyTorch provides various built-in loss functions in the `torch.nn` module. Here are some common examples:\n",
        "\n",
        "- **Mean Squared Error Loss (MSELoss)**: Used for regression tasks.\n",
        "- **Cross Entropy Loss (CrossEntropyLoss)**: Commonly used for multi-class classification tasks.\n",
        "\n",
        "Here’s how to define a loss function:\n",
        "\n",
        "```python\n",
        "# For regression\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "# For classification\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "```\n",
        "\n",
        "### Step 3: Define an Optimizer\n",
        "\n",
        "PyTorch also offers several optimizers in the `torch.optim` module. The choice of optimizer can affect how quickly your model learns. Common optimizers include:\n",
        "\n",
        "- **Stochastic Gradient Descent (SGD)**\n",
        "- **Adam**\n",
        "- **RMSprop**\n",
        "\n",
        "Here’s how to define an optimizer:\n",
        "\n",
        "```python\n",
        "# Assuming 'model' is your neural network instance\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer with a learning rate of 0.001\n",
        "\n",
        "# Alternatively, using SGD\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "```\n",
        "\n",
        "### Example"
      ],
      "metadata": {
        "id": "xvDtn9bMSkD7"
      }
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(128, 10)        # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
        "        x = torch.relu(self.fc1(x))  # Apply ReLU activation\n",
        "        x = self.fc2(x)               # Output layer\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define the loss function (for classification)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (using Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example usage during training:\n",
        "# Assuming 'inputs' is your input data and 'targets' are your labels\n",
        "\n",
        "# Create a random input tensor (replace with your actual data)\n",
        "inputs = torch.randn(64, 1, 28, 28)  # Example: 64 images, 1 channel, 28x28 size\n",
        "\n",
        "# Create a random target tensor (replace with your actual labels)\n",
        "targets = torch.randint(0, 10, (64,))  # Example: 64 labels between 0 and 9\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(inputs)\n",
        "loss = loss_function(outputs, targets)\n",
        "\n",
        "# Backward pass and optimization step\n",
        "optimizer.zero_grad()   # Zero the gradients before backward pass\n",
        "loss.backward()         # Backpropagation to compute gradients\n",
        "optimizer.step()        # Update parameters based on gradients\n",
        "\n",
        "print(f'Loss: {loss.item()}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP4UMj2JTcW3",
        "outputId": "944a3b05-b94b-4611-a59d-3d870fc24338"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.3046109676361084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8  How do you implement a custom loss function in PyTorch?\n",
        "\n",
        "To implement a custom loss function in PyTorch, you can follow two primary approaches: using a function-based implementation or subclassing `torch.nn.Module`. Below are examples of both methods.\n",
        "\n",
        "### Method 1: Function-Based Implementation\n",
        "\n",
        "This is the simplest way to create a custom loss function by defining a Python function that takes the predicted and target values as input, performs the necessary calculations, and returns the loss value.\n",
        "\n",
        "#### Example:\n"
      ],
      "metadata": {
        "id": "ICqosGHMS4d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def custom_mean_squared_error(y_pred, y_true):\n",
        "    # Calculate the squared differences\n",
        "    square_difference = torch.square(y_pred - y_true)\n",
        "    # Calculate the mean of squared differences\n",
        "    loss_value = torch.mean(square_difference)\n",
        "    return loss_value\n",
        "\n",
        "# Example usage\n",
        "y_predictions = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "\n",
        "# Compute custom loss\n",
        "loss = custom_mean_squared_error(y_predictions, target)\n",
        "print('Custom Loss:', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZItVXmYT7tj",
        "outputId": "5e4695a7-9528-4642-bc47-6ef9e8cd52ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Loss: tensor(2.3687, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Method 2: Class-Based Implementation\n",
        "\n",
        "This method involves creating a custom class that inherits from `torch.nn.Module`. You need to implement the `forward` method to define how the loss is calculated.\n",
        "\n",
        "#### Example:"
      ],
      "metadata": {
        "id": "_FtByWCTTpav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomMSE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSE, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate the squared differences\n",
        "        square_difference = torch.square(predictions - targets)\n",
        "        # Calculate the mean of squared differences\n",
        "        loss_value = torch.mean(square_difference)\n",
        "        return loss_value\n",
        "\n",
        "# Example usage\n",
        "model = CustomMSE()\n",
        "y_predictions = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "\n",
        "# Compute custom loss\n",
        "loss = model(y_predictions, target)\n",
        "print('Custom Loss:', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrQtlAzASf7W",
        "outputId": "ec42ba4a-5369-454d-f49c-0b3c7e82dfdf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Loss: tensor(1.4293, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9  How do you save and load a TensorFlow model?\n",
        "To save and load a TensorFlow model, you can use the built-in methods provided by the Keras API in TensorFlow. Here’s a detailed overview of how to accomplish this, including code examples.\n",
        "\n",
        "### Saving a TensorFlow Model\n",
        "\n",
        "You can save a model in two primary formats: the **SavedModel format** and the **HDF5 format**.\n",
        "\n",
        "#### 1. **Using SavedModel Format**\n",
        "\n",
        "The SavedModel format is TensorFlow's standard format for saving models. It saves the architecture, weights, and training configuration.\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create and train a simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Assume X_train and y_train are your training data\n",
        "# model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Save the entire model\n",
        "model.save('saved_model/my_model')\n",
        "```\n",
        "\n",
        "#### 2. **Using HDF5 Format**\n",
        "\n",
        "You can also save your model in HDF5 format by specifying the file extension `.h5`.\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "# Save the entire model in HDF5 format\n",
        "model.save('my_model.h5')\n",
        "```\n",
        "\n",
        "### Loading a TensorFlow Model\n",
        "\n",
        "You can load a saved model using the `tf.keras.models.load_model()` function. This works for both SavedModel and HDF5 formats.\n",
        "\n",
        "#### 1. **Loading from SavedModel Format**\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "# Load the model from SavedModel format\n",
        "loaded_model = tf.keras.models.load_model('saved_model/my_model')\n",
        "\n",
        "# Evaluate the loaded model (assuming you have test data)\n",
        "# loss, acc = loaded_model.evaluate(X_test, y_test)\n",
        "```\n",
        "\n",
        "#### 2. **Loading from HDF5 Format**\n",
        "\n",
        "**Example Code:**\n",
        "```python\n",
        "# Load the model from HDF5 format\n",
        "loaded_model_h5 = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# Evaluate the loaded model (assuming you have test data)\n",
        "# loss, acc = loaded_model_h5.evaluate(X_test, y_test)\n",
        "```\n"
      ],
      "metadata": {
        "id": "pn4QRSTzUDJO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MOqsppxPOw1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}