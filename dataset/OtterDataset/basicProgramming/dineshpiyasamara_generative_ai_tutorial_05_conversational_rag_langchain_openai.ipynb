{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversational RAG Application** with LangChain and OpenAI LLM"
      ],
      "metadata": {
        "id": "lef7p29Xx2sJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ycI2RyfalchY"
      },
      "outputs": [],
      "source": [
        "# Install the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-chroma -qU\n",
        "!pip install langchain_community -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "JoPwH-kip3R3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "EPPocIblyJqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "kkNHsve5p7dn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Embedding Model"
      ],
      "metadata": {
        "id": "48G8yiVsyPpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "gPV9_Zy_qBzt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load PDF Document"
      ],
      "metadata": {
        "id": "D78cVIkjyYKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -qU"
      ],
      "metadata": {
        "id": "XAvfWD6lqOLZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load the PDF document\n",
        "loader = PyPDFLoader(\"/content/codeprolk.pdf\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "ac-S00S6qYVU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Eb-fLHjrn0j",
        "outputId": "58d40032-73af-40a3-f128-40062e400fa5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Documents into Chunks"
      ],
      "metadata": {
        "id": "_8OOhkODyjWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
        "\n",
        "# Split the documents into chunks\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "ptvGrsvKrPVt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usqy9MGXrgDF",
        "outputId": "0e97cd1c-82f9-4923-bed9-c142881aee2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Vector Store and Retriever"
      ],
      "metadata": {
        "id": "I7MnJIZ2yxSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Create a vector store from the document chunks\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "y15EleEcrjSG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "G64K2R5FrwCy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Prompt Template"
      ],
      "metadata": {
        "id": "V9EPhkQgy6qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = (\n",
        "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "aU_TD8nZAuEx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cudtTu84AyUR",
        "outputId": "9a676c59-eb17-4c80-fd56-3d2a70e8deba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Retrieval-Augmented Generation (RAG) Chain"
      ],
      "metadata": {
        "id": "5TuCnfLczDWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Create the question-answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Create the RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, qa_chain)"
      ],
      "metadata": {
        "id": "DbtGkmDsAAly"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invoke RAG Chain with Example Questions"
      ],
      "metadata": {
        "id": "E_IyORkszM7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"who is codeprolk\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "V5m6Hj1Nsr_S",
        "outputId": "953f2dd0-5ce8-4608-a264-20d1b96d3cdb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of technology-related courses in Sinhala, focusing on programming, data science, and machine learning. CodePRO LK aims to empower Sri Lankans with valuable skills in the tech industry through accessible and high-quality education. The platform continues to evolve and expand its offerings to support its mission of preparing learners for success in the global tech industry.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"what is rag architecture\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "b5nwbJSMBkCy",
        "outputId": "cb05c970-34d1-49de-8bd6-e8ff721b9668"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'m not familiar with \"rag architecture.\" It seems to be a term or concept that is not related to the context provided about CodePRO LK and its community engagement, partnerships, and future directions in tech education. If you have more context or details about \"rag architecture,\" I may be able to provide a better answer.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"what are the courses codeprolk offer\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Anvx2peAuW4Z",
        "outputId": "21492a3f-591d-412e-9686-d27e675778e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CodePRO LK offers a variety of free courses presented in Sinhala, catering to various proficiency levels from beginners to intermediates. Some key courses include Python GUI – Tkinter. In the future, CodePRO LK aims to expand its offerings to cover advanced topics like artificial intelligence, cybersecurity, and advanced data analytics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"can you list down\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Df3JqKAtud9d",
        "outputId": "e75ef85b-53ac-4536-91e6-f5b9a38df97d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'List down what specifically? Please provide more details so I can assist you accurately.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Chat History"
      ],
      "metadata": {
        "id": "M9zhcOquxRd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "# Define the contextualize system prompt\n",
        "contextualize_system_prompt = (\n",
        "    \"using chat history and the latest user question, just reformulate question if needed and otherwise return it as is\"\n",
        ")\n",
        "\n",
        "# Create the contextualize prompt template\n",
        "contextualize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the history-aware retriever\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "MbtznRHYnl0O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create History-Aware RAG Chain"
      ],
      "metadata": {
        "id": "0K8lbhT_zft_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMpIFaKBnoK1",
        "outputId": "d5b3e023-fe27-4961-cb70-bbcc6e7d7b7a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the question-answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Create the history aware RAG chain\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)"
      ],
      "metadata": {
        "id": "g_S6smugoFR3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manage Chat Session History"
      ],
      "metadata": {
        "id": "RtIb6oQXz0cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# Initialize the store for session histories\n",
        "store = {}\n",
        "\n",
        "# Function to get the session history for a given session ID\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "# Create the conversational RAG chain with session history\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "4XZzWEn4oIbd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Invoke Conversational RAG Chain with Example Questions"
      ],
      "metadata": {
        "id": "DZtd5mnK0EIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"who is codeprolk\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "6xnYf4aBoLqe",
        "outputId": "2b5257a1-e50d-4a9e-e929-240c90ad9007"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 7d48947a-adae-4a9b-a748-45e9097146c1 not found for run b2a3d8cf-5aa5-4866-b4b3-96b67061ee9a. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of technology-related courses in Sinhala, focusing on programming, data science, and machine learning. CodePRO LK aims to empower Sri Lankans with valuable skills in the tech industry through accessible and high-quality education. The platform continues to evolve and expand its offerings to support its mission of preparing learners for success in the global tech industry. Additionally, CodePRO LK engages its community through various events like webinars, live coding sessions, hackathons, and tech talks to provide networking opportunities and practical experience. The platform also collaborates with educational institutions, tech companies, and industry experts to enhance its content and resources, ensuring learners are well-prepared for real-world challenges.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s735BMqNoOol",
        "outputId": "8c71cc1b-6487-4944-ece6-fbe82289b966"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'101': InMemoryChatMessageHistory(messages=[HumanMessage(content='who is codeprolk'), AIMessage(content='CodePRO LK is a dynamic educational platform founded by Dinesh Piyasamara during the COVID-19 pandemic. It offers a diverse range of technology-related courses in Sinhala, focusing on programming, data science, and machine learning. CodePRO LK aims to empower Sri Lankans with valuable skills in the tech industry through accessible and high-quality education. The platform continues to evolve and expand its offerings to support its mission of preparing learners for success in the global tech industry. Additionally, CodePRO LK engages its community through various events like webinars, live coding sessions, hackathons, and tech talks to provide networking opportunities and practical experience. The platform also collaborates with educational institutions, tech companies, and industry experts to enhance its content and resources, ensuring learners are well-prepared for real-world challenges.')])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"what is rag architecture\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "h2O6ZiKIoQwV",
        "outputId": "177dc08b-b3be-433e-a933-8fabddeece07"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run c3646b41-4593-4272-9c98-9089f717a6c8 not found for run f66beff5-a633-4c99-9d10-281d0d77da06. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'m sorry, but I don\\'t have information on \"rag architecture.\" It seems to be a specific term or concept that is not related to the context provided about CodePRO LK. If you have any other questions or need clarification on a different topic, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"what are the courses codeprolk offer\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "NUW1P7cboS2l",
        "outputId": "5a7a393c-34dd-4fab-a29f-4bb89fdb5f2d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run f87e5b41-ba35-49ef-9d2c-ee84f5eccd89 not found for run a77042d3-773f-41f5-be08-7940ef39d96e. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"CodePRO LK offers a variety of technology-related courses in Sinhala to empower learners with valuable skills in programming, data science, and machine learning. Some of the key courses offered by CodePRO LK include:\\n\\n1. Python GUI – Tkinter: This course covers the essentials of creating graphical user interfaces using Python's Tkinter library.\\n\\nCodePRO LK aims to cater to learners of all proficiency levels, from beginners to intermediates, ensuring that individuals at different stages can benefit from the courses. Additionally, the platform plans to expand its course offerings in the future to cover more advanced topics and emerging technologies such as artificial intelligence, cybersecurity, and advanced data analytics.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"can you list down\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "E8lFZXpjoVUY",
        "outputId": "06626374-400e-477f-c60f-0eca430cff6f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run e883ec27-d3b6-48e0-aa25-9beecabcc3c3 not found for run abd2ab11-d52d-4545-9494-09bbf56c7a2b. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I apologize for the confusion earlier. Here is a list of some of the courses offered by CodePRO LK:\\n\\n1. Python GUI – Tkinter: This course covers the essentials of creating graphical user interfaces using Python's Tkinter library.\\n\\nPlease note that CodePRO LK aims to expand its course offerings in the future to cover more advanced topics and emerging technologies such as artificial intelligence, cybersecurity, and advanced data analytics.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}