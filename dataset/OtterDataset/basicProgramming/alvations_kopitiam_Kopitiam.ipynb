{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports we need.\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq with PyTorch\n",
    "====\n",
    "\n",
    "Sequence-to-Sequence (Seq2Seq) learning is a useful class of neural network model to map sequential input into an output sequence. It has been shown to work well on various task, from machine translation to interpreting Python without an interpreter. {{citations-needed}}\n",
    "\n",
    "This notebook is a hands-on session to write an encoder-decoder Seq2Seq network using PyTorch for [DataScience SG meetup](https://www.meetup.com/DataScience-SG-Singapore/events/246541733/). Here's the accompanying slides for this notebook: https://goo.gl/Lu6CxB\n",
    "\n",
    "\n",
    "It would be great if you have at least worked through the [\"Deep Learning in 60 minutes\" PyTorch tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) before continuing the rest of the notebook.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Acknowledgements\n",
    "----\n",
    "\n",
    "The dataset used in this exercise is hosted on https://www.kaggle.com/alvations/sg-kopi\n",
    "\n",
    "The materials of this notebook and the accompanying slides are largely based on the \n",
    "\n",
    " - [PyTorch Seq2Seq tutorials by Sean Robertson](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) and \n",
    " - [Luong et al. tutorial on neural machine translation in ACL16](https://sites.google.com/site/acl16nmt/home).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kopi Problems\n",
    "====\n",
    "\n",
    "In this hands-on session, we want to **train a neural network to translate from Singlish Kopi orders to English?**\n",
    "\n",
    "\n",
    "**\"Singlish\" -> English**\n",
    "\n",
    "```\n",
    "\"Kopi\" -> Coffee with condensed milk\n",
    "\"Kopi O\" -> Coffee without milk or sugar\n",
    "\"Kopi dinosaur gau siew dai peng\" -> ???\n",
    "```\n",
    "\n",
    "(Image Source: http://www.straitstimes.com/lifestyle/food/get-your-kopi-kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://static.straitstimes.com.sg/sites/default/files/160522_kopi.jpg\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://static.straitstimes.com.sg/sites/default/files/160522_kopi.jpg\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seriously?\n",
    "----\n",
    "\n",
    "Yes, we'll be translating Singlish Kopi orders to English using the [sequence-to-sequence network](https://arxiv.org/abs/1409.3215) (Sutskever et al. 2014).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first...\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Munging\n",
    "====\n",
    "\n",
    "Before any machine/deep learning, we have to get some data and \"hammer\" it until we get it into the shape we want.\n",
    "\n",
    "> *Data scientists spend 60% of their time on cleaning and organizing data. Collecting data sets comes second at 19% of their time, meaning data scientists spend around 80% of their time on preparing and managing data for analysis.*\n",
    "\n",
    "> (Source: [Gil Press](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#3e4dc0416f63) Forbes article)\n",
    "\n",
    "**Step 1:** Take the data from somewhere, in this case: http://kaggle.com/alvations/sg-kopi.\n",
    "\n",
    "**Step 2:** Import your favorite dataframe and text processing library.\n",
    "\n",
    "**Step 3:** Munge the data till desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Terms</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kopi O</td>\n",
       "      <td>Black Coffee with Sugar</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kopi</td>\n",
       "      <td>Black Coffee with Condensed Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kopi C</td>\n",
       "      <td>Black Coffee with Evaporated Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kopi Kosong</td>\n",
       "      <td>Black Coffee without sugar or milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kopi Gah Dai</td>\n",
       "      <td>Black Coffee with extra condensed milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Local Terms                                 Meaning  \\\n",
       "0        Kopi O                 Black Coffee with Sugar   \n",
       "1          Kopi        Black Coffee with Condensed Milk   \n",
       "2        Kopi C       Black Coffee with Evaporated Milk   \n",
       "3   Kopi Kosong      Black Coffee without sugar or milk   \n",
       "4  Kopi Gah Dai  Black Coffee with extra condensed milk   \n",
       "\n",
       "                                              Source  \n",
       "0  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "1  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "2  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "3  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "4  https://daneshd.com/2010/02/28/a-rough-guide-t...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Reads the tab-delimited data using Pandas.\n",
    "kopitiam = pd.read_csv('kopitiam.tsv', sep='\\t')\n",
    "kopitiam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Reshaping the Data and Adding START and END Symbols\n",
    "----\n",
    "\n",
    "To get the data in shape, we want to:\n",
    "  \n",
    "  1. normalize and tokenize of the input\n",
    "  2. pad the input with START (`<s>`) and END (`<\\s>`) symbols.\n",
    "\n",
    "If we look at the data carefully, sometimes we see that we have a mix of capitalized and lowered cased spellings, esp. in the \"Local Terms\" column. E.g. \"Kopi O\" and \"Kopi o\". For simplicity, we'll lowercase all the inputs and outputs so that our models don't think that the big \"O\" and the small \"o\" are different things.\n",
    "\n",
    "Additionally, we want to tokinze our input so that we pad the punctuations with spaces away from the preceeding or following word. There are many tokenization functions, we'll use the `word_tokenize()` function in `nltk`.\n",
    "\n",
    "As for padding the sentence with START and END symbols. It's an indication that we give to our Recurrent Neural Network (RNN) that denotes the start/end of our in/output sequences. \n",
    "\n",
    "\n",
    "(**Cut-away:** Here's some experts pitching in on why we need the START/END symbol. https://twitter.com/alvations/status/955770616648364037) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL;DR\n",
    "----\n",
    "\n",
    "Given, $[in]$:\n",
    "\n",
    "```\n",
    "kopi o\n",
    "black coffee with sugar\n",
    "```\n",
    "\n",
    "We want, $[out]$:\n",
    "\n",
    "```\n",
    "['<s>', 'kopi', 'o', '</s>']\n",
    "['<s>', 'black', 'coffee', 'with', 'sugar', '</s>']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Singlish sentence: ['<s>', 'kopi', 'o', '</s>']\n",
      "First English sentence: ['<s>', 'black', 'coffee', 'with', 'sugar', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "singlish_sents = [START] + kopitiam['Local Terms'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "english_sents = [START] + kopitiam['Meaning'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First Singlish sentence:', singlish_sents[0])\n",
    "print('First English sentence:', english_sents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.2 Vectorize the Data\n",
    "----\n",
    "\n",
    "There are many ways to vectorize text data. And since we are going to use RNN which requires the order of the sequences to be kept, we can simply convert our vocabulary (unique words) in the data into an indexed dictionary and replace each sentence as a list of indices. \n",
    "\n",
    "Thankfully, we don't have to write messy classes to create objects that stores these dictionary of indices to the respective words. We have the awesome `gensim` library and the [gensim.corpora.Dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) class.\n",
    "\n",
    "> **Note:** \n",
    ">\n",
    "> We want to `<s>` and `<\\s>` to take the 0th and 1st indices so we first initialize a sentence with only the `<s>` symbol and another sentence with `<\\s>` to prevent the native Python dictionary hashing that messes up the order of a set. \n",
    "> \n",
    "> So we'll do `Dictionary([['<s>'], ['</s>'], ['UNK']])` before we use `Dictionary.add_documents()`.\n",
    ">\n",
    "> To convert the input sequence of tokens into list of indices we use the [`Dictionary.doc2idx()`](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx) function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL;DR\n",
    "----\n",
    "\n",
    "Given this $[in]$:\n",
    "\n",
    "```\n",
    "['<s>', 'kopi', 'o', '</s>']\n",
    "['<s>', 'black', 'coffee', 'with', 'sugar', '</s>']\n",
    "```\n",
    "\n",
    "\n",
    "We want $[out]$:\n",
    "\n",
    "```\n",
    "[0, 3, 4, 1]\n",
    "[0, 3, 4, 6, 5, 1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Singlish words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'kopi'), (3, 'o'), (4, 'c'), (5, 'kosong'), (6, 'dai'), (7, 'gah'), (8, 'siew'), (9, 'po')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'black'), (3, 'coffee'), (4, 'sugar'), (5, 'with'), (6, 'condensed'), (7, 'milk'), (8, 'evaporated'), (9, 'or')]\n"
     ]
    }
   ],
   "source": [
    "# Let's convert the individual words into some sort of unique index \n",
    "# and use the unique to represent the words. \n",
    "## Cut-away: Integers = 1-2 bytes vs UTF-8 Strings = no. of chars * 1-2 bytes. @_@\n",
    "\n",
    "english_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "singlish_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "singlish_vocab.add_documents(singlish_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Singlish words in Dictionary:\\n', sorted(singlish_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save our dictionaries.\n",
    "with open('singlish_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(singlish_vocab, fout)\n",
    "    \n",
    "with open('english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Singlish sentence:\n",
      "['<s>', 'kopi', 'o', '</s>']\n",
      "[0, 2, 3, 1]\n",
      "\n",
      "First English sentence:\n",
      "['<s>', 'black', 'coffee', 'with', 'sugar', '</s>']\n",
      "[0, 2, 3, 5, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "# Now, convert all the sentences into list of the indices \n",
    "print('First Singlish sentence:')\n",
    "print(singlish_sents[0])\n",
    "print(singlish_vocab.doc2idx(singlish_sents[0]), end='\\n\\n')\n",
    "\n",
    "print('First English sentence:')\n",
    "print(english_sents[0])\n",
    "print(english_vocab.doc2idx(english_sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 21, 10, 8, 6, 11, 1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets create a function to convert new sentences into the indexed forms.\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END])\n",
    "\n",
    "new_kopi = \"Kopi dinosaur gau siew dai peng\"\n",
    "vectorize_sent(new_kopi, singlish_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.3. Clobbering the Data into PyTorch Variable\n",
    "----\n",
    "\n",
    "For the last step of data hammering, we need to clobber the vectorized sentence into PyTorch `Variable` type. \n",
    "\n",
    "**Note:** Before continuing this notebook, you're strongly encourage to go through the following if you're unfamiliar with PyTorch:\n",
    "http://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0\n",
       "    2\n",
       "   21\n",
       "   10\n",
       "    8\n",
       "    6\n",
       "   11\n",
       "    1\n",
       "[torch.LongTensor of size 8x1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "new_kopi = \"Kopi dinosaur gau siew dai peng\"\n",
    "variable_from_sent(new_kopi, singlish_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the sentence length.\n",
    "variable_from_sent(new_kopi, singlish_vocab).size()[0] # Includes START and END symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the whole training corpus.\n",
    "singlish_tensors = kopitiam['Local Terms'].apply(lambda s: variable_from_sent(s, singlish_vocab))\n",
    "english_tensors = kopitiam['Meaning'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(singlish_tensors, english_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The Seq2Seq Model\n",
    "====\n",
    "\n",
    "A Recurrent Neural Network (RNN), is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "> *The general idea is to make **two recurrent neural network transform from one sequence to another**. An encoder network condenses an input sequence into a vector and a decoder netwrok unfolds the vector into a new sequence.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. The Encoder\n",
    "====\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
    "\n",
    "\n",
    "<img src=\"http://pytorch.org/tutorials/_images/encoder-network.png\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Simple Decoder\n",
    "====\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string `<s>` token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "\n",
    "\n",
    "<img src=\"http://pytorch.org/tutorials/_images/decoder-network.png\" align='left'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Training the Model\n",
    "====\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the `<s>` token as its first input, and the last hidden state of the encoder as its first hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1 Set the Hyperparamters and Prepare Data (again...)\n",
    "----\n",
    "\n",
    "As with all gradient methods in deep/machine learning, the basic idea is to:\n",
    "\n",
    " 1. Iterate through **batch_size** data points **epochs** no. of times\n",
    " 2. For each batch of data, calculate the **loss** between the (i) predicted output (y_hat) given the inputs (x) and (ii) the actual output (y). For deep learning models, **backpropagate** the loss\n",
    " 3. Make the **optimizer** take a step based on the **learning_rate** and the **backpropagated** losses\n",
    " 4. Repeat Step 1-3 until certain stopping criteria (e.g. the loss is no longer reducing or is taking an upwards trend or until a fix no. of epochs is completed)\n",
    " \n",
    " \n",
    "\n",
    "**Note:** If you're unfamiliar with the steps above, I strongly encourage you to:\n",
    "\n",
    " - Watch @sirajraval on https://www.youtube.com/embed/q555kfIFUCM and \n",
    " - Spend some time going through this blogpost by @iamtrask http://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "learning_rate=0.01\n",
    "batch_size = 2\n",
    "epochs = 30 # Since we are taking batch_size=2 and epochs=30, we only look at 60 data points.\n",
    "criterion = nn.NLLLoss()\n",
    "MAX_LENGTH=20\n",
    "\n",
    "# Initialize the network for encoder and decoder.\n",
    "input_vocab, output_vocab = singlish_vocab, english_vocab\n",
    "encoder = EncoderRNN(len(input_vocab), hidden_size)\n",
    "decoder = DecoderRNN(hidden_size, len(output_vocab))\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "# Initialize the optimizer for encoder and decoder.\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# If batchsize == 1, choose 1 data points per batch:\n",
    "##training_data = [[random.choice(sent_pairs)] for i in range(epochs)]\n",
    "\n",
    "# If batch_size > 1, use random.sample() instead of random.choice:\n",
    "training_data = [random.sample(sent_pairs, batch_size) for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2. Loop through the batches\n",
    "---\n",
    "\n",
    "To start the model training, first we iterate through the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3. Iterating through each word in the encoder.\n",
    "----\n",
    "\n",
    "Moving on, for each batch, we iterate through the data points (i.e. sentence pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) for the GRU.\n",
    "            encoder_outputs[ei] = encoder_output[0][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3.1. Outputs of the Encoder\n",
    "----\n",
    "\n",
    "Before we move on with the training data, we should take a look at the coolest feature of PyTorch (aka Tensorflow Eager mode way before eager mode is a thing). \n",
    "\n",
    "The fact that we can hijack the training process and start printing out layer output values or current parameters without needing to wait till the end of the training is pretty powerful. \n",
    "\n",
    "This is an artifact of how the PyTorch library designer allows users to probe and change the network at any point of time without first declaring and fixing a specific network. \n",
    "\n",
    "**Cut-away:** Here's some heated blogpost of imperative/declarative programming style.\n",
    "\n",
    "- Funny yet Informative: https://tylermcginnis.com/imperative-vs-declarative-programming/\n",
    "\n",
    "- Simple Python is de facto imperative but it's possible to do otherwise: http://www.benfrederickson.com/python-as-a-declarative-programming-language/\n",
    "\n",
    "<!--\n",
    "Pardon me being frank (not hotdog)\n",
    "----\n",
    "\n",
    "IMHO, I (Liling) don't really care how I write my network as long as the library allows me to have flexibility to alter networks and training mechanisms to suit what I'm trying to do. And for now, I write less code to do the same thing in PyTorch, so yeah... -->\n",
    "\n",
    "----\n",
    "\n",
    "Lets take a look at the last sentence we processed with the code above (Section 2.3.3.)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(68, 10)\n",
      "  (gru): GRU(10, 10)\n",
      ") \n",
      "\n",
      "Dictionary(68 unique tokens: ['<s>', '</s>', 'UNK', 'kopi', 'o']...)\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The encoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 68 unique words\n",
    "print(encoder, '\\n')\n",
    "print(singlish_vocab)\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  0\n",
      " 14\n",
      "  4\n",
      "  6\n",
      "  1\n",
      "[torch.LongTensor of size 5x1]\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The last input sentence, in PyTorch Tensor data structure.\n",
    "print(data_batch[-1][0]) \n",
    "print('########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 14, 4, 6, 1] \n",
      "\n",
      "########\n",
      "\n",
      "<s> teh o kosong </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The last input sentence as list(int)\n",
    "print(list(map(int, data_batch[-1][0])), '\\n')\n",
    "print('########\\n')\n",
    "\n",
    "# The last input sentence as list(int)\n",
    "print(' '.join([singlish_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "print('\\n########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.1214  0.2326 -0.3078 -0.0045 -0.0870  0.0150  0.4273  0.3584  0.1007  0.2582\n",
      "-0.0815  0.2332 -0.4338 -0.3060  0.0044  0.1103  0.5286 -0.0093  0.4035  0.1736\n",
      "-0.6873  0.0396  0.3701 -0.7467 -0.1440 -0.4195  0.5479  0.2969  0.4136 -0.0482\n",
      "-0.4481  0.3308 -0.2921 -0.4302 -0.5618 -0.2736  0.3295  0.1484  0.5261  0.0894\n",
      " 0.1654  0.2799  0.1352 -0.2455  0.0506 -0.1016 -0.3219 -0.3612  0.3636 -0.1309\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 20x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The encoded outputs of the last sentence \n",
    "# Note: We have a matrix of 20 (MAX_LENGTH) x 10 (hidden_size) and \n",
    "#       for this particular sentence, we only have 4 encoded outputs\n",
    "print(encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We see only 5 rows are populated. With each rows representing the encoded output of the individual states as we step through the RNN. And the final row `encoded_outputs` will correspond to the `encoder_hidden`, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "  -0.0078 -0.5923  0.6164  0.1475 -0.5511  0.6830  0.5584  0.0438  0.3793\n",
      "\n",
      "Columns 9 to 9 \n",
      "  -0.0317\n",
      "[torch.FloatTensor of size 1x1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The last hidden state of the last input sentence. \n",
    "# Note: For vanilla RNN (Elman Net), the last hidden state of the encoder\n",
    "#       is the start state of the decoder's hidden state.\n",
    "print(encoder_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4. Iterating through each word in the decoder.\n",
    "----\n",
    "\n",
    "After encoding, we \n",
    "\n",
    " 1. initialize the start of the decoder input with the index of our START symbol.\n",
    " 2. use the final encoded hidden state as the start of the decoder hidden state, i.e. `decoder_hidden = encoder_hidden`. \n",
    " 3. step through the state, i.e. `decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)`\n",
    " 4. we map the softmax output (negative log probabilities to the words) and choose the best prediction as the predicted word for the current state, i.e. `topv, topi = decoder_output.data.topk(1); ni = topi[0][0]`\n",
    " 5. as we move through the decoder states (i.e. as we predict the previous words), we use the newly predicted word as the input to the next state, i.e. `decoder_input = Variable(torch.LongTensor([ni]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are all these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4.1 Outputs of the Decoder\n",
    "----\n",
    "\n",
    "Once again, we hijack the training process and take a look at what we're doing at the docoder. \n",
    "\n",
    "Here we see the last sentence in our training_data in the previous jupyter notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(116, 10)\n",
      "  (gru): GRU(10, 10)\n",
      "  (softmax): LogSoftmax()\n",
      "  (out): Linear(in_features=10, out_features=116)\n",
      ") \n",
      "\n",
      "Dictionary(116 unique tokens: ['<s>', '</s>', 'black', 'coffee', 'sugar']...)\n",
      "\n",
      "########\n",
      "\n",
      "<s> tai ga ho </s>\n",
      "<s> horlicks </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cut-away: The decoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 117 unique words\n",
    "print(decoder, '\\n')\n",
    "print(english_vocab)\n",
    "print('\\n########\\n')\n",
    "\n",
    "# The last input sentence.\n",
    "print(' '.join([singlish_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "# The last target sentence.\n",
    "print(' '.join([english_vocab[i] for i in map(int, data_batch[-1][1])]))\n",
    "\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we arrive at the predicted word from decoder_output?\n",
    "-----\n",
    "\n",
    "We look at the `decoder_output.data` that shows a vector of 117 columns, each column correspond to the target word that we are predicting. The values are negative log probabilities.\n",
    "\n",
    "Then the `decoder_output.topk`, will filter and leave the topk predictions based on the vector of negative log probabilities. \n",
    "\n",
    "The `decoder_output.topk` will return a list of tuples were the first item is the score (i.e. negative log probability) and the second item is the index of the word for the target vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "\n",
      "########\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-4.9682 -5.1267 -5.6028 -4.0663 -4.5102 -4.4591 -4.9175 -5.0732 -5.0293 -5.3705\n",
      "\n",
      "Columns 10 to 19 \n",
      "-5.0894 -4.9453 -4.6394 -4.9664 -5.1267 -4.4543 -5.0366 -4.8566 -4.6203 -4.9958\n",
      "\n",
      "Columns 20 to 29 \n",
      "-4.7038 -4.5959 -4.7804 -4.8709 -5.0501 -4.8864 -4.8876 -5.0000 -4.6976 -4.6324\n",
      "\n",
      "Columns 30 to 39 \n",
      "-4.4754 -5.4241 -4.5974 -4.6645 -4.7227 -4.9907 -5.0174 -4.8825 -4.9364 -4.7163\n",
      "\n",
      "Columns 40 to 49 \n",
      "-5.0280 -5.0492 -4.6629 -5.1601 -4.3666 -4.3587 -4.8414 -4.7386 -4.4162 -4.6509\n",
      "\n",
      "Columns 50 to 59 \n",
      "-4.7710 -4.9370 -4.4109 -4.6621 -4.6100 -4.8891 -4.8433 -4.4666 -4.8315 -4.4337\n",
      "\n",
      "Columns 60 to 69 \n",
      "-4.6725 -4.8010 -4.5824 -4.7252 -4.5903 -4.8131 -4.2811 -5.3550 -5.5460 -4.8272\n",
      "\n",
      "Columns 70 to 79 \n",
      "-5.2190 -4.6178 -4.9321 -5.2433 -4.6670 -4.0502 -4.4425 -4.5862 -4.6299 -4.5233\n",
      "\n",
      "Columns 80 to 89 \n",
      "-5.2702 -4.7900 -5.3953 -4.6982 -4.4740 -4.9680 -4.4162 -5.1073 -4.9964 -4.5141\n",
      "\n",
      "Columns 90 to 99 \n",
      "-5.1502 -4.7556 -4.3382 -4.8319 -4.6833 -4.7920 -4.5417 -4.5824 -4.7229 -4.4789\n",
      "\n",
      "Columns 100 to 109 \n",
      "-4.7015 -4.9493 -4.7649 -5.0959 -4.5520 -5.3925 -4.7920 -5.0965 -4.8581 -5.4309\n",
      "\n",
      "Columns 110 to 116 \n",
      "-4.1824 -4.6310 -4.8550 -5.0144 -5.2293 -4.9815 -4.7103\n",
      "[torch.FloatTensor of size 1x117]\n",
      "\n",
      "\n",
      "########\n",
      "(\n",
      "-4.0502\n",
      "[torch.FloatTensor of size 1x1]\n",
      ", \n",
      " 75\n",
      "[torch.LongTensor of size 1x1]\n",
      ")\n",
      "\n",
      "########\n",
      "\n",
      "-4.0502\n",
      "[torch.FloatTensor of size 1x1]\n",
      "\n",
      "\n",
      " 75\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# The last word in the last sentence. \n",
    "print([english_vocab[i] for i in map(int, data_batch[-1][1])][-1])\n",
    "print('\\n########')\n",
    "\n",
    "# The -log probability of the word that's most probably the \n",
    "# correct target word as we moved from the encoder to the decoder.\n",
    "print(decoder_output.data)\n",
    "\n",
    "print('\\n########')\n",
    "\n",
    "# The word with the highest probability\n",
    "print(decoder_output.data.topk(1))\n",
    "print('\\n########')\n",
    "\n",
    "# Take a look at what's the decoder's guess for the final word in the last sentence.\n",
    "topv, topi = decoder_output.data.topk(1)\n",
    "print(topv) # The -log probability of the decoder's guess.\n",
    "print(topi) # The index of the word in the english_vocab.\n",
    "print(english_vocab[int(topi)]) # Decoder's guess of the final word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.5 Backpropagate the Loss and Optimizers Takes a Step.\n",
    "----\n",
    "\n",
    "The \"magic\" of deep learning libraries like PyTorch, Tensorflow, DyNet, etc. is that we don't have to write our own derivative and recursive backpropagation functions. \n",
    "\n",
    "In PyTorch, we simply do something like:\n",
    "\n",
    "```python\n",
    ">>> criterion = nn.NLLLoss()\n",
    ">>> ... ... (yada yada network)\n",
    ">>> loss += criterion(decoder_output, target_variable[di])\n",
    ">>> loss.backward() \n",
    ">>> optimizer.step()\n",
    "```\n",
    "\n",
    "## Viva la backpropaganda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are alll these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n",
    "    #####################################################\n",
    "    # 2.3.5 Backpropagate the Loss and Optimizers Takes a Step.\n",
    "    #####################################################\n",
    "    loss.backward() # Backpropagate.\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try translating with the small model\n",
    "====\n",
    "\n",
    "It's good to note that the model has only seen 60 random data pairs of singlish and english sentences using these hyperparameters:\n",
    "\n",
    "```\n",
    "hidden_size = 10\n",
    "learning_rate=0.01\n",
    "batch_size = 2\n",
    "epochs = 30 # Since we are taking batch_size=2 and epochs=30, we only look at 60 data points.\n",
    "criterion = nn.NLLLoss()\n",
    "MAX_LENGTH=20\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.6 Getting the Model to Translate\n",
    "====\n",
    "\n",
    "Remember that during training, our decode takes the `encoder_hidden` as in start state of the `decoder_hidden` and starts predicting the words as we move along the decoder states?\n",
    "\n",
    "Similarly, when translating input sentences with no target sentences, we'll do the same prediction in the decoder but the only difference is that we **DON'T** need to:\n",
    "\n",
    "- measure the difference between the prediction and the actual target sentence since we don't have it, (i.e. we don't need to do `criterion(decoder_output, target_variable[di])`) and\n",
    "- backpropagate nor update the loss\n",
    "- do anything to the optimizer\n",
    "\n",
    "\n",
    "You can see that the `translator()` function is very much like our `train_one_epoch` code, we added:\n",
    "\n",
    " - the need to keep a list of the decoded words' indices\n",
    " - instead of returning the loss, we return the list of decoded word indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, \n",
    "                                                 decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni)\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 2\n",
       " 8\n",
       " 6\n",
       " 1\n",
       "[torch.LongTensor of size 5x1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'kopi siew dai'\n",
    "variable_from_sent(sent, singlish_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 5, 13, 4, 12, 23, 4, 1]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words = translator(my_encoder, my_decoder, \n",
    "                          variable_from_sent(sent, singlish_vocab))\n",
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee', 'with', 'less', 'sugar', 'but', 'and', 'sugar']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[english_vocab[i] for i in output_words[1:output_words.index(1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(kopi_order):\n",
    "    output_words = translator(my_encoder, my_decoder, variable_from_sent(kopi_order, singlish_vocab))\n",
    "    print(output_words)\n",
    "    output_sentence = [english_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 5, 13, 4, 12, 23, 4, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coffee with less sugar but and sugar'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi siew dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 3, 5, 7, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coffee coffee with milk'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 5, 3, 4, 57, 12, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'black with coffee sugar added but'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 29, 10, 4, 12, 28, 4, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tea without sugar but only sugar'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, 60 data points is insufficient for the model to be trained properly!!!\n",
    "----\n",
    "\n",
    "Lets clean up the training code and train it longer so that it sees more sentence pairs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1 Formalize the training per epoch as a function\n",
    "====\n",
    "\n",
    "Now we know how to write the \n",
    "\n",
    " - network architectures as objects in PyTorch\n",
    " - training process using standard Pythonic loops across epochs and each data points per epoch.\n",
    " \n",
    "Lets put everything together and write functions to simplify how we train a model.\n",
    "\n",
    "**Acknowledgement:** Largely, the following code is from http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "    \n",
    "#########################################################\n",
    "# Training per epoch,\n",
    "# Iterates across data points per epoch.\n",
    "#########################################################\n",
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    # Initialize the variable input with the index of the START.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # As the first state of the decoder, we take the last step of the encoder.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        loss += criterion(decoder_output, target_variable[di])\n",
    "        if ni == END_IDX:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Re-Train\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 19m 27s) (100 0%) 2.6212\n",
      "0m 2s (- 18m 45s) (200 0%) 2.0315\n",
      "0m 3s (- 17m 31s) (300 0%) 1.9701\n",
      "0m 4s (- 17m 4s) (400 0%) 1.9609\n",
      "0m 5s (- 16m 40s) (500 0%) 2.0464\n",
      "0m 5s (- 16m 29s) (600 0%) 2.1187\n",
      "0m 6s (- 16m 18s) (700 0%) 1.9449\n",
      "0m 7s (- 16m 11s) (800 0%) 2.0178\n",
      "0m 8s (- 16m 7s) (900 0%) 2.0096\n",
      "0m 9s (- 16m 6s) (1000 1%) 1.9958\n",
      "0m 10s (- 16m 9s) (1100 1%) 1.9795\n",
      "0m 11s (- 16m 8s) (1200 1%) 1.8545\n",
      "0m 12s (- 16m 8s) (1300 1%) 1.7732\n",
      "0m 13s (- 16m 8s) (1400 1%) 1.5005\n",
      "0m 14s (- 16m 9s) (1500 1%) 1.6381\n",
      "0m 15s (- 16m 5s) (1600 1%) 1.6208\n",
      "0m 16s (- 16m 3s) (1700 1%) 1.5456\n",
      "0m 17s (- 16m 2s) (1800 1%) 1.4217\n",
      "0m 18s (- 16m 4s) (1900 1%) 1.5309\n",
      "0m 19s (- 16m 3s) (2000 2%) 1.4450\n",
      "0m 20s (- 15m 59s) (2100 2%) 1.4215\n",
      "0m 21s (- 16m 0s) (2200 2%) 1.4209\n",
      "0m 22s (- 16m 0s) (2300 2%) 1.2946\n",
      "0m 23s (- 16m 1s) (2400 2%) 1.4898\n",
      "0m 24s (- 16m 2s) (2500 2%) 1.2311\n",
      "0m 25s (- 16m 1s) (2600 2%) 1.2861\n",
      "0m 26s (- 16m 2s) (2700 2%) 1.1607\n",
      "0m 27s (- 16m 1s) (2800 2%) 1.3717\n",
      "0m 28s (- 16m 2s) (2900 2%) 1.3822\n",
      "0m 29s (- 16m 4s) (3000 3%) 1.3662\n",
      "0m 30s (- 16m 4s) (3100 3%) 1.1817\n",
      "0m 31s (- 16m 5s) (3200 3%) 1.3635\n",
      "0m 32s (- 16m 5s) (3300 3%) 1.2366\n",
      "0m 34s (- 16m 9s) (3400 3%) 1.2331\n",
      "0m 35s (- 16m 8s) (3500 3%) 1.1480\n",
      "0m 36s (- 16m 14s) (3600 3%) 1.1370\n",
      "0m 38s (- 16m 42s) (3700 3%) 1.1261\n",
      "0m 39s (- 16m 51s) (3800 3%) 1.1117\n",
      "0m 41s (- 16m 55s) (3900 3%) 1.1260\n",
      "0m 42s (- 16m 58s) (4000 4%) 1.1846\n",
      "0m 43s (- 16m 59s) (4100 4%) 0.9976\n",
      "0m 44s (- 17m 0s) (4200 4%) 1.0898\n",
      "0m 46s (- 17m 7s) (4300 4%) 1.0471\n",
      "0m 47s (- 17m 13s) (4400 4%) 0.9087\n",
      "0m 48s (- 17m 19s) (4500 4%) 0.9965\n",
      "0m 50s (- 17m 24s) (4600 4%) 0.9225\n",
      "0m 51s (- 17m 34s) (4700 4%) 1.0338\n",
      "0m 53s (- 17m 36s) (4800 4%) 0.9872\n",
      "0m 54s (- 17m 37s) (4900 4%) 0.9865\n",
      "0m 55s (- 17m 37s) (5000 5%) 0.9203\n",
      "0m 57s (- 17m 42s) (5100 5%) 0.8926\n",
      "0m 58s (- 17m 47s) (5200 5%) 0.9575\n",
      "0m 59s (- 17m 50s) (5300 5%) 0.9738\n",
      "1m 1s (- 17m 51s) (5400 5%) 0.8469\n",
      "1m 2s (- 17m 58s) (5500 5%) 0.8140\n",
      "1m 4s (- 18m 3s) (5600 5%) 0.8182\n",
      "1m 5s (- 18m 3s) (5700 5%) 0.7970\n",
      "1m 6s (- 18m 1s) (5800 5%) 0.7954\n",
      "1m 7s (- 17m 59s) (5900 5%) 0.8720\n",
      "1m 8s (- 17m 59s) (6000 6%) 0.9509\n",
      "1m 10s (- 17m 59s) (6100 6%) 0.7458\n",
      "1m 11s (- 17m 57s) (6200 6%) 0.7547\n",
      "1m 12s (- 17m 58s) (6300 6%) 0.7434\n",
      "1m 13s (- 18m 0s) (6400 6%) 0.7218\n",
      "1m 14s (- 17m 58s) (6500 6%) 0.5513\n",
      "1m 16s (- 17m 58s) (6600 6%) 0.7797\n",
      "1m 17s (- 18m 4s) (6700 6%) 0.7203\n",
      "1m 19s (- 18m 5s) (6800 6%) 0.7622\n",
      "1m 20s (- 18m 4s) (6900 6%) 0.6791\n",
      "1m 21s (- 18m 3s) (7000 7%) 0.6535\n",
      "1m 22s (- 18m 5s) (7100 7%) 0.7205\n",
      "1m 24s (- 18m 5s) (7200 7%) 0.6958\n",
      "1m 26s (- 18m 13s) (7300 7%) 0.6917\n",
      "1m 27s (- 18m 14s) (7400 7%) 0.7571\n",
      "1m 28s (- 18m 13s) (7500 7%) 0.7107\n",
      "1m 29s (- 18m 11s) (7600 7%) 0.5905\n",
      "1m 31s (- 18m 13s) (7700 7%) 0.6321\n",
      "1m 32s (- 18m 14s) (7800 7%) 0.5832\n",
      "1m 33s (- 18m 13s) (7900 7%) 0.5936\n",
      "1m 35s (- 18m 15s) (8000 8%) 0.6117\n",
      "1m 37s (- 18m 21s) (8100 8%) 0.6204\n",
      "1m 38s (- 18m 25s) (8200 8%) 0.6432\n",
      "1m 39s (- 18m 24s) (8300 8%) 0.5753\n",
      "1m 41s (- 18m 23s) (8400 8%) 0.5785\n",
      "1m 42s (- 18m 23s) (8500 8%) 0.5571\n",
      "1m 44s (- 18m 26s) (8600 8%) 0.6137\n",
      "1m 46s (- 18m 36s) (8700 8%) 0.4746\n",
      "1m 47s (- 18m 39s) (8800 8%) 0.6111\n",
      "1m 50s (- 18m 53s) (8900 8%) 0.5273\n",
      "1m 52s (- 19m 0s) (9000 9%) 0.5126\n",
      "1m 54s (- 19m 1s) (9100 9%) 0.5298\n",
      "1m 55s (- 19m 2s) (9200 9%) 0.5910\n",
      "1m 57s (- 19m 4s) (9300 9%) 0.5111\n",
      "1m 59s (- 19m 13s) (9400 9%) 0.4428\n",
      "2m 1s (- 19m 17s) (9500 9%) 0.4999\n",
      "2m 3s (- 19m 22s) (9600 9%) 0.4806\n",
      "2m 5s (- 19m 27s) (9700 9%) 0.5871\n",
      "2m 7s (- 19m 30s) (9800 9%) 0.5160\n",
      "2m 9s (- 19m 35s) (9900 9%) 0.6229\n",
      "2m 10s (- 19m 36s) (10000 10%) 0.5398\n",
      "2m 12s (- 19m 38s) (10100 10%) 0.6497\n",
      "2m 13s (- 19m 37s) (10200 10%) 0.5974\n",
      "2m 15s (- 19m 36s) (10300 10%) 0.4924\n",
      "2m 16s (- 19m 38s) (10400 10%) 0.4909\n",
      "2m 18s (- 19m 39s) (10500 10%) 0.5640\n",
      "2m 20s (- 19m 41s) (10600 10%) 0.4897\n",
      "2m 21s (- 19m 44s) (10700 10%) 0.4988\n",
      "2m 23s (- 19m 43s) (10800 10%) 0.5413\n",
      "2m 24s (- 19m 40s) (10900 10%) 0.5353\n",
      "2m 25s (- 19m 38s) (11000 11%) 0.4279\n",
      "2m 26s (- 19m 36s) (11100 11%) 0.5253\n",
      "2m 28s (- 19m 34s) (11200 11%) 0.4779\n",
      "2m 29s (- 19m 31s) (11300 11%) 0.4906\n",
      "2m 30s (- 19m 28s) (11400 11%) 0.5002\n",
      "2m 31s (- 19m 25s) (11500 11%) 0.4955\n",
      "2m 32s (- 19m 23s) (11600 11%) 0.4607\n",
      "2m 33s (- 19m 21s) (11700 11%) 0.4950\n",
      "2m 35s (- 19m 19s) (11800 11%) 0.4877\n",
      "2m 36s (- 19m 17s) (11900 11%) 0.4831\n",
      "2m 37s (- 19m 15s) (12000 12%) 0.4683\n",
      "2m 38s (- 19m 14s) (12100 12%) 0.3873\n",
      "2m 40s (- 19m 13s) (12200 12%) 0.5174\n",
      "2m 41s (- 19m 12s) (12300 12%) 0.4287\n",
      "2m 43s (- 19m 12s) (12400 12%) 0.4794\n",
      "2m 44s (- 19m 12s) (12500 12%) 0.5395\n",
      "2m 46s (- 19m 11s) (12600 12%) 0.5392\n",
      "2m 47s (- 19m 13s) (12700 12%) 0.5140\n",
      "2m 49s (- 19m 12s) (12800 12%) 0.5447\n",
      "2m 50s (- 19m 10s) (12900 12%) 0.5946\n",
      "2m 52s (- 19m 13s) (13000 13%) 0.4198\n",
      "2m 54s (- 19m 15s) (13100 13%) 0.4372\n",
      "2m 55s (- 19m 13s) (13200 13%) 0.4922\n",
      "2m 56s (- 19m 11s) (13300 13%) 0.4843\n",
      "2m 59s (- 19m 18s) (13400 13%) 0.4710\n",
      "3m 1s (- 19m 23s) (13500 13%) 0.4680\n",
      "3m 2s (- 19m 22s) (13600 13%) 0.5315\n",
      "3m 4s (- 19m 22s) (13700 13%) 0.5375\n",
      "3m 5s (- 19m 20s) (13800 13%) 0.4862\n",
      "3m 7s (- 19m 18s) (13900 13%) 0.5427\n",
      "3m 8s (- 19m 17s) (14000 14%) 0.3887\n",
      "3m 9s (- 19m 15s) (14100 14%) 0.4617\n",
      "3m 10s (- 19m 13s) (14200 14%) 0.4378\n",
      "3m 12s (- 19m 13s) (14300 14%) 0.4251\n",
      "3m 13s (- 19m 12s) (14400 14%) 0.4816\n",
      "3m 15s (- 19m 13s) (14500 14%) 0.5405\n",
      "3m 17s (- 19m 13s) (14600 14%) 0.5149\n",
      "3m 18s (- 19m 13s) (14700 14%) 0.5146\n",
      "3m 20s (- 19m 12s) (14800 14%) 0.4540\n",
      "3m 21s (- 19m 11s) (14900 14%) 0.5449\n",
      "3m 23s (- 19m 11s) (15000 15%) 0.4820\n",
      "3m 24s (- 19m 10s) (15100 15%) 0.3799\n",
      "3m 26s (- 19m 9s) (15200 15%) 0.4905\n",
      "3m 27s (- 19m 8s) (15300 15%) 0.4813\n",
      "3m 28s (- 19m 6s) (15400 15%) 0.4140\n",
      "3m 29s (- 19m 3s) (15500 15%) 0.5446\n",
      "3m 31s (- 19m 4s) (15600 15%) 0.5155\n",
      "3m 33s (- 19m 5s) (15700 15%) 0.4819\n",
      "3m 34s (- 19m 3s) (15800 15%) 0.3921\n",
      "3m 35s (- 19m 1s) (15900 15%) 0.4813\n",
      "3m 36s (- 18m 58s) (16000 16%) 0.4776\n",
      "3m 38s (- 18m 57s) (16100 16%) 0.4415\n",
      "3m 39s (- 18m 56s) (16200 16%) 0.4435\n",
      "3m 40s (- 18m 54s) (16300 16%) 0.3817\n",
      "3m 42s (- 18m 52s) (16400 16%) 0.4782\n",
      "3m 43s (- 18m 50s) (16500 16%) 0.4090\n",
      "3m 44s (- 18m 49s) (16600 16%) 0.4836\n",
      "3m 46s (- 18m 47s) (16700 16%) 0.5169\n",
      "3m 47s (- 18m 47s) (16800 16%) 0.4211\n",
      "3m 48s (- 18m 45s) (16900 16%) 0.4901\n",
      "3m 50s (- 18m 43s) (17000 17%) 0.4240\n",
      "3m 51s (- 18m 41s) (17100 17%) 0.4438\n",
      "3m 52s (- 18m 39s) (17200 17%) 0.5077\n",
      "3m 53s (- 18m 37s) (17300 17%) 0.4263\n",
      "3m 54s (- 18m 35s) (17400 17%) 0.3913\n",
      "3m 56s (- 18m 33s) (17500 17%) 0.4183\n",
      "3m 57s (- 18m 31s) (17600 17%) 0.3963\n",
      "3m 58s (- 18m 29s) (17700 17%) 0.4108\n",
      "4m 0s (- 18m 29s) (17800 17%) 0.4083\n",
      "4m 1s (- 18m 28s) (17900 17%) 0.4686\n",
      "4m 3s (- 18m 29s) (18000 18%) 0.4544\n",
      "4m 5s (- 18m 30s) (18100 18%) 0.4831\n",
      "4m 6s (- 18m 30s) (18200 18%) 0.5226\n",
      "4m 8s (- 18m 28s) (18300 18%) 0.4100\n",
      "4m 9s (- 18m 27s) (18400 18%) 0.4876\n",
      "4m 12s (- 18m 31s) (18500 18%) 0.4229\n",
      "4m 13s (- 18m 30s) (18600 18%) 0.5095\n",
      "4m 15s (- 18m 28s) (18700 18%) 0.4397\n",
      "4m 16s (- 18m 28s) (18800 18%) 0.4783\n",
      "4m 17s (- 18m 26s) (18900 18%) 0.4967\n",
      "4m 19s (- 18m 25s) (19000 19%) 0.4985\n",
      "4m 20s (- 18m 24s) (19100 19%) 0.3656\n",
      "4m 21s (- 18m 22s) (19200 19%) 0.4487\n",
      "4m 23s (- 18m 20s) (19300 19%) 0.4748\n",
      "4m 24s (- 18m 17s) (19400 19%) 0.4515\n",
      "4m 25s (- 18m 15s) (19500 19%) 0.4901\n",
      "4m 26s (- 18m 13s) (19600 19%) 0.4169\n",
      "4m 27s (- 18m 11s) (19700 19%) 0.3527\n",
      "4m 29s (- 18m 10s) (19800 19%) 0.3894\n",
      "4m 30s (- 18m 9s) (19900 19%) 0.4173\n",
      "4m 32s (- 18m 10s) (20000 20%) 0.4066\n",
      "4m 34s (- 18m 10s) (20100 20%) 0.4299\n",
      "4m 35s (- 18m 8s) (20200 20%) 0.4273\n",
      "4m 37s (- 18m 7s) (20300 20%) 0.4308\n",
      "4m 38s (- 18m 6s) (20400 20%) 0.3655\n",
      "4m 39s (- 18m 4s) (20500 20%) 0.3752\n",
      "4m 40s (- 18m 2s) (20600 20%) 0.4432\n",
      "4m 42s (- 18m 1s) (20700 20%) 0.4851\n",
      "4m 43s (- 18m 0s) (20800 20%) 0.3114\n",
      "4m 44s (- 17m 58s) (20900 20%) 0.4381\n",
      "4m 46s (- 17m 57s) (21000 21%) 0.4211\n",
      "4m 47s (- 17m 55s) (21100 21%) 0.3877\n",
      "4m 49s (- 17m 54s) (21200 21%) 0.2837\n",
      "4m 50s (- 17m 52s) (21300 21%) 0.3812\n",
      "4m 51s (- 17m 50s) (21400 21%) 0.3746\n",
      "4m 52s (- 17m 49s) (21500 21%) 0.3716\n",
      "4m 54s (- 17m 47s) (21600 21%) 0.4938\n",
      "4m 55s (- 17m 45s) (21700 21%) 0.4438\n",
      "4m 56s (- 17m 43s) (21800 21%) 0.3613\n",
      "4m 57s (- 17m 41s) (21900 21%) 0.4583\n",
      "4m 58s (- 17m 39s) (22000 22%) 0.3963\n",
      "5m 0s (- 17m 37s) (22100 22%) 0.3438\n",
      "5m 1s (- 17m 35s) (22200 22%) 0.3765\n",
      "5m 2s (- 17m 34s) (22300 22%) 0.4002\n",
      "5m 3s (- 17m 32s) (22400 22%) 0.3995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 5s (- 17m 31s) (22500 22%) 0.3814\n",
      "5m 6s (- 17m 30s) (22600 22%) 0.3901\n",
      "5m 8s (- 17m 29s) (22700 22%) 0.3862\n",
      "5m 9s (- 17m 28s) (22800 22%) 0.4758\n",
      "5m 10s (- 17m 26s) (22900 22%) 0.3878\n",
      "5m 12s (- 17m 24s) (23000 23%) 0.4225\n",
      "5m 14s (- 17m 26s) (23100 23%) 0.5454\n",
      "5m 16s (- 17m 26s) (23200 23%) 0.4694\n",
      "5m 17s (- 17m 24s) (23300 23%) 0.3817\n",
      "5m 19s (- 17m 26s) (23400 23%) 0.4832\n",
      "5m 21s (- 17m 25s) (23500 23%) 0.4088\n",
      "5m 23s (- 17m 26s) (23600 23%) 0.5001\n",
      "5m 24s (- 17m 24s) (23700 23%) 0.4284\n",
      "5m 25s (- 17m 22s) (23800 23%) 0.4701\n",
      "5m 26s (- 17m 21s) (23900 23%) 0.3915\n",
      "5m 28s (- 17m 18s) (24000 24%) 0.4172\n",
      "5m 29s (- 17m 16s) (24100 24%) 0.4408\n",
      "5m 30s (- 17m 14s) (24200 24%) 0.3569\n",
      "5m 31s (- 17m 12s) (24300 24%) 0.3775\n",
      "5m 32s (- 17m 10s) (24400 24%) 0.4002\n",
      "5m 34s (- 17m 9s) (24500 24%) 0.3985\n",
      "5m 35s (- 17m 9s) (24600 24%) 0.4297\n",
      "5m 37s (- 17m 8s) (24700 24%) 0.4781\n",
      "5m 38s (- 17m 6s) (24800 24%) 0.3800\n",
      "5m 40s (- 17m 7s) (24900 24%) 0.3192\n",
      "5m 42s (- 17m 6s) (25000 25%) 0.4469\n",
      "5m 44s (- 17m 7s) (25100 25%) 0.3963\n",
      "5m 45s (- 17m 5s) (25200 25%) 0.3613\n",
      "5m 47s (- 17m 4s) (25300 25%) 0.4252\n",
      "5m 48s (- 17m 3s) (25400 25%) 0.4408\n",
      "5m 49s (- 17m 1s) (25500 25%) 0.4185\n",
      "5m 51s (- 17m 0s) (25600 25%) 0.5082\n",
      "5m 52s (- 16m 58s) (25700 25%) 0.3960\n",
      "5m 53s (- 16m 57s) (25800 25%) 0.3946\n",
      "5m 55s (- 16m 56s) (25900 25%) 0.4215\n",
      "5m 56s (- 16m 55s) (26000 26%) 0.3645\n",
      "5m 58s (- 16m 54s) (26100 26%) 0.3679\n",
      "5m 59s (- 16m 53s) (26200 26%) 0.3772\n",
      "6m 1s (- 16m 53s) (26300 26%) 0.3534\n",
      "6m 3s (- 16m 52s) (26400 26%) 0.5529\n",
      "6m 5s (- 16m 53s) (26500 26%) 0.4458\n",
      "6m 6s (- 16m 52s) (26600 26%) 0.4347\n",
      "6m 8s (- 16m 51s) (26700 26%) 0.3917\n",
      "6m 10s (- 16m 50s) (26800 26%) 0.4485\n",
      "6m 11s (- 16m 49s) (26900 26%) 0.4495\n",
      "6m 12s (- 16m 48s) (27000 27%) 0.4268\n",
      "6m 13s (- 16m 46s) (27100 27%) 0.3989\n",
      "6m 15s (- 16m 43s) (27200 27%) 0.3596\n",
      "6m 16s (- 16m 42s) (27300 27%) 0.4801\n",
      "6m 17s (- 16m 40s) (27400 27%) 0.3422\n",
      "6m 18s (- 16m 38s) (27500 27%) 0.3973\n",
      "6m 19s (- 16m 36s) (27600 27%) 0.3632\n",
      "6m 21s (- 16m 36s) (27700 27%) 0.3182\n",
      "6m 23s (- 16m 35s) (27800 27%) 0.3451\n",
      "6m 24s (- 16m 33s) (27900 27%) 0.3742\n",
      "6m 25s (- 16m 31s) (28000 28%) 0.4821\n",
      "6m 26s (- 16m 29s) (28100 28%) 0.3897\n",
      "6m 28s (- 16m 28s) (28200 28%) 0.4287\n",
      "6m 29s (- 16m 26s) (28300 28%) 0.4082\n",
      "6m 30s (- 16m 25s) (28400 28%) 0.4448\n",
      "6m 32s (- 16m 23s) (28500 28%) 0.4497\n",
      "6m 33s (- 16m 22s) (28600 28%) 0.4060\n",
      "6m 35s (- 16m 22s) (28700 28%) 0.4645\n",
      "6m 36s (- 16m 21s) (28800 28%) 0.3609\n",
      "6m 38s (- 16m 20s) (28900 28%) 0.3874\n",
      "6m 40s (- 16m 19s) (29000 28%) 0.3628\n",
      "6m 41s (- 16m 19s) (29100 29%) 0.4511\n",
      "6m 43s (- 16m 17s) (29200 29%) 0.3365\n",
      "6m 44s (- 16m 16s) (29300 29%) 0.4455\n",
      "6m 46s (- 16m 16s) (29400 29%) 0.4339\n",
      "6m 48s (- 16m 15s) (29500 29%) 0.4002\n",
      "6m 49s (- 16m 13s) (29600 29%) 0.4126\n",
      "6m 50s (- 16m 12s) (29700 29%) 0.3488\n",
      "6m 51s (- 16m 10s) (29800 29%) 0.3862\n",
      "6m 53s (- 16m 8s) (29900 29%) 0.3519\n",
      "6m 54s (- 16m 6s) (30000 30%) 0.4067\n",
      "6m 55s (- 16m 5s) (30100 30%) 0.4056\n",
      "6m 56s (- 16m 3s) (30200 30%) 0.4271\n",
      "6m 58s (- 16m 1s) (30300 30%) 0.3386\n",
      "6m 59s (- 15m 59s) (30400 30%) 0.3990\n",
      "7m 0s (- 15m 58s) (30500 30%) 0.4706\n",
      "7m 1s (- 15m 56s) (30600 30%) 0.4477\n",
      "7m 3s (- 15m 55s) (30700 30%) 0.2569\n",
      "7m 4s (- 15m 53s) (30800 30%) 0.4178\n",
      "7m 5s (- 15m 52s) (30900 30%) 0.4937\n",
      "7m 7s (- 15m 50s) (31000 31%) 0.4465\n",
      "7m 8s (- 15m 48s) (31100 31%) 0.3285\n",
      "7m 9s (- 15m 46s) (31200 31%) 0.4218\n",
      "7m 10s (- 15m 45s) (31300 31%) 0.4696\n",
      "7m 11s (- 15m 43s) (31400 31%) 0.3832\n",
      "7m 13s (- 15m 41s) (31500 31%) 0.4170\n",
      "7m 14s (- 15m 40s) (31600 31%) 0.3873\n",
      "7m 15s (- 15m 38s) (31700 31%) 0.4157\n",
      "7m 16s (- 15m 36s) (31800 31%) 0.4066\n",
      "7m 18s (- 15m 35s) (31900 31%) 0.3711\n",
      "7m 19s (- 15m 34s) (32000 32%) 0.3259\n",
      "7m 21s (- 15m 33s) (32100 32%) 0.3732\n",
      "7m 22s (- 15m 31s) (32200 32%) 0.4397\n",
      "7m 23s (- 15m 30s) (32300 32%) 0.3709\n",
      "7m 25s (- 15m 28s) (32400 32%) 0.4648\n",
      "7m 26s (- 15m 27s) (32500 32%) 0.4233\n",
      "7m 27s (- 15m 25s) (32600 32%) 0.4257\n",
      "7m 28s (- 15m 23s) (32700 32%) 0.4112\n",
      "7m 30s (- 15m 22s) (32800 32%) 0.3761\n",
      "7m 31s (- 15m 20s) (32900 32%) 0.3913\n",
      "7m 32s (- 15m 19s) (33000 33%) 0.3449\n",
      "7m 33s (- 15m 17s) (33100 33%) 0.3776\n",
      "7m 35s (- 15m 16s) (33200 33%) 0.4293\n",
      "7m 36s (- 15m 15s) (33300 33%) 0.3843\n",
      "7m 38s (- 15m 13s) (33400 33%) 0.4248\n",
      "7m 39s (- 15m 12s) (33500 33%) 0.4509\n",
      "7m 41s (- 15m 11s) (33600 33%) 0.3809\n",
      "7m 42s (- 15m 10s) (33700 33%) 0.3296\n",
      "7m 43s (- 15m 8s) (33800 33%) 0.3560\n",
      "7m 45s (- 15m 7s) (33900 33%) 0.3458\n",
      "7m 46s (- 15m 6s) (34000 34%) 0.3890\n",
      "7m 48s (- 15m 5s) (34100 34%) 0.4343\n",
      "7m 49s (- 15m 3s) (34200 34%) 0.3741\n",
      "7m 50s (- 15m 2s) (34300 34%) 0.4823\n",
      "7m 52s (- 15m 0s) (34400 34%) 0.4440\n",
      "7m 53s (- 14m 58s) (34500 34%) 0.3809\n",
      "7m 54s (- 14m 56s) (34600 34%) 0.4349\n",
      "7m 55s (- 14m 54s) (34700 34%) 0.3844\n",
      "7m 56s (- 14m 53s) (34800 34%) 0.3668\n",
      "7m 57s (- 14m 51s) (34900 34%) 0.4670\n",
      "7m 59s (- 14m 50s) (35000 35%) 0.4635\n",
      "8m 0s (- 14m 49s) (35100 35%) 0.3413\n",
      "8m 2s (- 14m 47s) (35200 35%) 0.3527\n",
      "8m 3s (- 14m 46s) (35300 35%) 0.4296\n",
      "8m 4s (- 14m 44s) (35400 35%) 0.4537\n",
      "8m 6s (- 14m 43s) (35500 35%) 0.4047\n",
      "8m 7s (- 14m 42s) (35600 35%) 0.3766\n",
      "8m 9s (- 14m 41s) (35700 35%) 0.4438\n",
      "8m 10s (- 14m 39s) (35800 35%) 0.3894\n",
      "8m 12s (- 14m 38s) (35900 35%) 0.4387\n",
      "8m 14s (- 14m 38s) (36000 36%) 0.3990\n",
      "8m 15s (- 14m 37s) (36100 36%) 0.4094\n",
      "8m 17s (- 14m 37s) (36200 36%) 0.3841\n",
      "8m 19s (- 14m 36s) (36300 36%) 0.4182\n",
      "8m 20s (- 14m 34s) (36400 36%) 0.3870\n",
      "8m 21s (- 14m 32s) (36500 36%) 0.3265\n",
      "8m 22s (- 14m 31s) (36600 36%) 0.4196\n",
      "8m 24s (- 14m 29s) (36700 36%) 0.4255\n",
      "8m 25s (- 14m 28s) (36800 36%) 0.4353\n",
      "8m 26s (- 14m 26s) (36900 36%) 0.4123\n",
      "8m 28s (- 14m 25s) (37000 37%) 0.4451\n",
      "8m 29s (- 14m 23s) (37100 37%) 0.4102\n",
      "8m 31s (- 14m 22s) (37200 37%) 0.4870\n",
      "8m 32s (- 14m 21s) (37300 37%) 0.4499\n",
      "8m 33s (- 14m 19s) (37400 37%) 0.3711\n",
      "8m 34s (- 14m 17s) (37500 37%) 0.3179\n",
      "8m 35s (- 14m 16s) (37600 37%) 0.3928\n",
      "8m 37s (- 14m 15s) (37700 37%) 0.3289\n",
      "8m 40s (- 14m 16s) (37800 37%) 0.3971\n",
      "8m 42s (- 14m 15s) (37900 37%) 0.3258\n",
      "8m 44s (- 14m 15s) (38000 38%) 0.3173\n",
      "8m 45s (- 14m 13s) (38100 38%) 0.3009\n",
      "8m 46s (- 14m 12s) (38200 38%) 0.4980\n",
      "8m 48s (- 14m 11s) (38300 38%) 0.3607\n",
      "8m 49s (- 14m 9s) (38400 38%) 0.4630\n",
      "8m 50s (- 14m 8s) (38500 38%) 0.2686\n",
      "8m 52s (- 14m 6s) (38600 38%) 0.4232\n",
      "8m 53s (- 14m 5s) (38700 38%) 0.4091\n",
      "8m 55s (- 14m 4s) (38800 38%) 0.4526\n",
      "8m 56s (- 14m 2s) (38900 38%) 0.4189\n",
      "8m 57s (- 14m 0s) (39000 39%) 0.3925\n",
      "8m 58s (- 13m 59s) (39100 39%) 0.3593\n",
      "9m 0s (- 13m 57s) (39200 39%) 0.4399\n",
      "9m 1s (- 13m 56s) (39300 39%) 0.4265\n",
      "9m 2s (- 13m 54s) (39400 39%) 0.3383\n",
      "9m 4s (- 13m 53s) (39500 39%) 0.3899\n",
      "9m 6s (- 13m 53s) (39600 39%) 0.3644\n",
      "9m 8s (- 13m 53s) (39700 39%) 0.3964\n",
      "9m 10s (- 13m 52s) (39800 39%) 0.3982\n",
      "9m 11s (- 13m 51s) (39900 39%) 0.4466\n",
      "9m 13s (- 13m 49s) (40000 40%) 0.3840\n",
      "9m 14s (- 13m 48s) (40100 40%) 0.4291\n",
      "9m 16s (- 13m 48s) (40200 40%) 0.3520\n",
      "9m 18s (- 13m 47s) (40300 40%) 0.3826\n",
      "9m 19s (- 13m 46s) (40400 40%) 0.3539\n",
      "9m 21s (- 13m 44s) (40500 40%) 0.3888\n",
      "9m 23s (- 13m 44s) (40600 40%) 0.4605\n",
      "9m 24s (- 13m 43s) (40700 40%) 0.3879\n",
      "9m 26s (- 13m 41s) (40800 40%) 0.3962\n",
      "9m 27s (- 13m 40s) (40900 40%) 0.4219\n",
      "9m 29s (- 13m 38s) (41000 41%) 0.4495\n",
      "9m 30s (- 13m 37s) (41100 41%) 0.2915\n",
      "9m 31s (- 13m 35s) (41200 41%) 0.4125\n",
      "9m 32s (- 13m 33s) (41300 41%) 0.3429\n",
      "9m 34s (- 13m 32s) (41400 41%) 0.4364\n",
      "9m 35s (- 13m 31s) (41500 41%) 0.3765\n",
      "9m 36s (- 13m 29s) (41600 41%) 0.3330\n",
      "9m 37s (- 13m 27s) (41700 41%) 0.3753\n",
      "9m 39s (- 13m 26s) (41800 41%) 0.3413\n",
      "9m 40s (- 13m 25s) (41900 41%) 0.3666\n",
      "9m 41s (- 13m 23s) (42000 42%) 0.3409\n",
      "9m 43s (- 13m 22s) (42100 42%) 0.3562\n",
      "9m 44s (- 13m 20s) (42200 42%) 0.4772\n",
      "9m 46s (- 13m 19s) (42300 42%) 0.4137\n",
      "9m 47s (- 13m 17s) (42400 42%) 0.4160\n",
      "9m 48s (- 13m 16s) (42500 42%) 0.3664\n",
      "9m 50s (- 13m 15s) (42600 42%) 0.3716\n",
      "9m 51s (- 13m 13s) (42700 42%) 0.3530\n",
      "9m 52s (- 13m 11s) (42800 42%) 0.3552\n",
      "9m 54s (- 13m 11s) (42900 42%) 0.3661\n",
      "9m 55s (- 13m 9s) (43000 43%) 0.4340\n",
      "9m 57s (- 13m 9s) (43100 43%) 0.3541\n",
      "9m 59s (- 13m 7s) (43200 43%) 0.3490\n",
      "10m 0s (- 13m 6s) (43300 43%) 0.3669\n",
      "10m 2s (- 13m 5s) (43400 43%) 0.3663\n",
      "10m 4s (- 13m 4s) (43500 43%) 0.3729\n",
      "10m 5s (- 13m 3s) (43600 43%) 0.4789\n",
      "10m 6s (- 13m 2s) (43700 43%) 0.3713\n",
      "10m 8s (- 13m 1s) (43800 43%) 0.4054\n",
      "10m 10s (- 12m 59s) (43900 43%) 0.4070\n",
      "10m 11s (- 12m 58s) (44000 44%) 0.4223\n",
      "10m 13s (- 12m 57s) (44100 44%) 0.4100\n",
      "10m 14s (- 12m 56s) (44200 44%) 0.4210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 17s (- 12m 55s) (44300 44%) 0.3186\n",
      "10m 18s (- 12m 54s) (44400 44%) 0.3586\n",
      "10m 19s (- 12m 52s) (44500 44%) 0.4145\n",
      "10m 20s (- 12m 51s) (44600 44%) 0.4227\n",
      "10m 22s (- 12m 49s) (44700 44%) 0.3791\n",
      "10m 23s (- 12m 48s) (44800 44%) 0.4208\n",
      "10m 25s (- 12m 47s) (44900 44%) 0.3840\n",
      "10m 27s (- 12m 47s) (45000 45%) 0.3889\n",
      "10m 30s (- 12m 46s) (45100 45%) 0.4763\n",
      "10m 32s (- 12m 46s) (45200 45%) 0.3089\n",
      "10m 34s (- 12m 45s) (45300 45%) 0.3891\n",
      "10m 36s (- 12m 45s) (45400 45%) 0.4884\n",
      "10m 37s (- 12m 43s) (45500 45%) 0.4429\n",
      "10m 39s (- 12m 42s) (45600 45%) 0.3713\n",
      "10m 40s (- 12m 41s) (45700 45%) 0.3547\n",
      "10m 41s (- 12m 39s) (45800 45%) 0.4215\n",
      "10m 42s (- 12m 37s) (45900 45%) 0.4109\n",
      "10m 44s (- 12m 36s) (46000 46%) 0.3405\n",
      "10m 45s (- 12m 35s) (46100 46%) 0.3082\n",
      "10m 46s (- 12m 33s) (46200 46%) 0.4464\n",
      "10m 48s (- 12m 31s) (46300 46%) 0.4337\n",
      "10m 49s (- 12m 30s) (46400 46%) 0.3706\n",
      "10m 51s (- 12m 29s) (46500 46%) 0.4415\n",
      "10m 52s (- 12m 28s) (46600 46%) 0.4358\n",
      "10m 54s (- 12m 26s) (46700 46%) 0.4015\n",
      "10m 55s (- 12m 24s) (46800 46%) 0.4534\n",
      "10m 56s (- 12m 23s) (46900 46%) 0.4090\n",
      "10m 57s (- 12m 21s) (47000 47%) 0.3851\n",
      "10m 59s (- 12m 20s) (47100 47%) 0.4481\n",
      "11m 0s (- 12m 18s) (47200 47%) 0.3757\n",
      "11m 1s (- 12m 17s) (47300 47%) 0.3886\n",
      "11m 3s (- 12m 16s) (47400 47%) 0.4207\n",
      "11m 4s (- 12m 14s) (47500 47%) 0.3694\n",
      "11m 6s (- 12m 13s) (47600 47%) 0.3564\n",
      "11m 7s (- 12m 12s) (47700 47%) 0.3802\n",
      "11m 9s (- 12m 10s) (47800 47%) 0.3627\n",
      "11m 10s (- 12m 9s) (47900 47%) 0.3929\n",
      "11m 11s (- 12m 7s) (48000 48%) 0.3360\n",
      "11m 13s (- 12m 6s) (48100 48%) 0.3678\n",
      "11m 15s (- 12m 5s) (48200 48%) 0.4129\n",
      "11m 16s (- 12m 4s) (48300 48%) 0.4101\n",
      "11m 18s (- 12m 2s) (48400 48%) 0.4232\n",
      "11m 19s (- 12m 1s) (48500 48%) 0.3472\n",
      "11m 20s (- 12m 0s) (48600 48%) 0.4077\n",
      "11m 22s (- 11m 58s) (48700 48%) 0.3894\n",
      "11m 23s (- 11m 57s) (48800 48%) 0.3582\n",
      "11m 24s (- 11m 55s) (48900 48%) 0.3562\n",
      "11m 25s (- 11m 53s) (49000 49%) 0.4397\n",
      "11m 27s (- 11m 52s) (49100 49%) 0.3919\n",
      "11m 28s (- 11m 50s) (49200 49%) 0.4803\n",
      "11m 29s (- 11m 49s) (49300 49%) 0.3928\n",
      "11m 30s (- 11m 47s) (49400 49%) 0.4341\n",
      "11m 32s (- 11m 46s) (49500 49%) 0.4255\n",
      "11m 33s (- 11m 44s) (49600 49%) 0.3147\n",
      "11m 34s (- 11m 43s) (49700 49%) 0.3927\n",
      "11m 36s (- 11m 41s) (49800 49%) 0.4495\n",
      "11m 37s (- 11m 40s) (49900 49%) 0.4209\n",
      "11m 38s (- 11m 38s) (50000 50%) 0.3908\n",
      "11m 40s (- 11m 37s) (50100 50%) 0.4089\n",
      "11m 41s (- 11m 35s) (50200 50%) 0.3974\n",
      "11m 42s (- 11m 34s) (50300 50%) 0.4014\n",
      "11m 44s (- 11m 32s) (50400 50%) 0.4326\n",
      "11m 45s (- 11m 31s) (50500 50%) 0.4330\n",
      "11m 46s (- 11m 29s) (50600 50%) 0.3617\n",
      "11m 47s (- 11m 28s) (50700 50%) 0.4016\n",
      "11m 49s (- 11m 26s) (50800 50%) 0.4354\n",
      "11m 50s (- 11m 25s) (50900 50%) 0.3795\n",
      "11m 52s (- 11m 24s) (51000 51%) 0.3757\n",
      "11m 53s (- 11m 23s) (51100 51%) 0.4600\n",
      "11m 55s (- 11m 22s) (51200 51%) 0.4361\n",
      "11m 57s (- 11m 20s) (51300 51%) 0.4408\n",
      "11m 58s (- 11m 19s) (51400 51%) 0.3875\n",
      "11m 59s (- 11m 18s) (51500 51%) 0.3751\n",
      "12m 1s (- 11m 16s) (51600 51%) 0.3579\n",
      "12m 2s (- 11m 15s) (51700 51%) 0.4081\n",
      "12m 3s (- 11m 13s) (51800 51%) 0.4073\n",
      "12m 5s (- 11m 12s) (51900 51%) 0.3666\n",
      "12m 6s (- 11m 10s) (52000 52%) 0.4207\n",
      "12m 8s (- 11m 9s) (52100 52%) 0.3745\n",
      "12m 9s (- 11m 7s) (52200 52%) 0.4505\n",
      "12m 10s (- 11m 6s) (52300 52%) 0.3731\n",
      "12m 11s (- 11m 4s) (52400 52%) 0.4309\n",
      "12m 13s (- 11m 3s) (52500 52%) 0.3122\n",
      "12m 15s (- 11m 2s) (52600 52%) 0.4837\n",
      "12m 17s (- 11m 2s) (52700 52%) 0.4416\n",
      "12m 19s (- 11m 1s) (52800 52%) 0.3232\n",
      "12m 20s (- 10m 59s) (52900 52%) 0.3668\n",
      "12m 21s (- 10m 57s) (53000 53%) 0.3523\n",
      "12m 23s (- 10m 56s) (53100 53%) 0.4187\n",
      "12m 24s (- 10m 54s) (53200 53%) 0.3975\n",
      "12m 25s (- 10m 53s) (53300 53%) 0.4148\n",
      "12m 28s (- 10m 52s) (53400 53%) 0.4568\n",
      "12m 29s (- 10m 51s) (53500 53%) 0.3447\n",
      "12m 31s (- 10m 50s) (53600 53%) 0.4375\n",
      "12m 32s (- 10m 48s) (53700 53%) 0.4473\n",
      "12m 34s (- 10m 47s) (53800 53%) 0.3512\n",
      "12m 36s (- 10m 46s) (53900 53%) 0.4036\n",
      "12m 37s (- 10m 45s) (54000 54%) 0.4009\n",
      "12m 39s (- 10m 44s) (54100 54%) 0.4012\n",
      "12m 40s (- 10m 42s) (54200 54%) 0.3338\n",
      "12m 41s (- 10m 40s) (54300 54%) 0.4586\n",
      "12m 42s (- 10m 39s) (54400 54%) 0.3866\n",
      "12m 43s (- 10m 37s) (54500 54%) 0.3653\n",
      "12m 45s (- 10m 36s) (54600 54%) 0.4687\n",
      "12m 46s (- 10m 35s) (54700 54%) 0.3247\n",
      "12m 48s (- 10m 33s) (54800 54%) 0.3675\n",
      "12m 49s (- 10m 32s) (54900 54%) 0.3250\n",
      "12m 51s (- 10m 31s) (55000 55%) 0.4517\n",
      "12m 52s (- 10m 29s) (55100 55%) 0.4074\n",
      "12m 53s (- 10m 28s) (55200 55%) 0.4316\n",
      "12m 55s (- 10m 26s) (55300 55%) 0.3468\n",
      "12m 56s (- 10m 25s) (55400 55%) 0.4100\n",
      "12m 57s (- 10m 23s) (55500 55%) 0.3770\n",
      "13m 0s (- 10m 23s) (55600 55%) 0.3672\n",
      "13m 2s (- 10m 22s) (55700 55%) 0.3136\n",
      "13m 4s (- 10m 21s) (55800 55%) 0.4114\n",
      "13m 5s (- 10m 19s) (55900 55%) 0.4394\n",
      "13m 7s (- 10m 18s) (56000 56%) 0.3483\n",
      "13m 8s (- 10m 17s) (56100 56%) 0.4244\n",
      "13m 10s (- 10m 15s) (56200 56%) 0.4163\n",
      "13m 11s (- 10m 14s) (56300 56%) 0.3443\n",
      "13m 12s (- 10m 12s) (56400 56%) 0.4045\n",
      "13m 13s (- 10m 11s) (56500 56%) 0.4064\n",
      "13m 15s (- 10m 9s) (56600 56%) 0.3791\n",
      "13m 16s (- 10m 8s) (56700 56%) 0.3641\n",
      "13m 17s (- 10m 6s) (56800 56%) 0.4235\n",
      "13m 19s (- 10m 5s) (56900 56%) 0.3945\n",
      "13m 20s (- 10m 4s) (57000 56%) 0.4030\n",
      "13m 22s (- 10m 2s) (57100 57%) 0.3570\n",
      "13m 23s (- 10m 1s) (57200 57%) 0.4073\n",
      "13m 24s (- 9m 59s) (57300 57%) 0.4438\n",
      "13m 25s (- 9m 58s) (57400 57%) 0.3449\n",
      "13m 26s (- 9m 56s) (57500 57%) 0.3328\n",
      "13m 28s (- 9m 55s) (57600 57%) 0.4337\n",
      "13m 29s (- 9m 53s) (57700 57%) 0.4127\n",
      "13m 31s (- 9m 52s) (57800 57%) 0.2905\n",
      "13m 32s (- 9m 50s) (57900 57%) 0.4024\n",
      "13m 34s (- 9m 49s) (58000 57%) 0.3768\n",
      "13m 35s (- 9m 48s) (58100 58%) 0.3420\n",
      "13m 37s (- 9m 46s) (58200 58%) 0.4332\n",
      "13m 38s (- 9m 45s) (58300 58%) 0.3627\n",
      "13m 39s (- 9m 44s) (58400 58%) 0.4302\n",
      "13m 41s (- 9m 42s) (58500 58%) 0.4267\n",
      "13m 43s (- 9m 41s) (58600 58%) 0.3576\n",
      "13m 44s (- 9m 40s) (58700 58%) 0.3833\n",
      "13m 45s (- 9m 38s) (58800 58%) 0.4976\n",
      "13m 47s (- 9m 37s) (58900 58%) 0.3935\n",
      "13m 48s (- 9m 35s) (59000 59%) 0.4012\n",
      "13m 49s (- 9m 34s) (59100 59%) 0.3260\n",
      "13m 51s (- 9m 32s) (59200 59%) 0.3972\n",
      "13m 52s (- 9m 31s) (59300 59%) 0.4439\n",
      "13m 53s (- 9m 29s) (59400 59%) 0.4309\n",
      "13m 54s (- 9m 28s) (59500 59%) 0.3728\n",
      "13m 56s (- 9m 26s) (59600 59%) 0.4250\n",
      "13m 57s (- 9m 25s) (59700 59%) 0.3749\n",
      "13m 59s (- 9m 24s) (59800 59%) 0.3236\n",
      "14m 0s (- 9m 22s) (59900 59%) 0.3665\n",
      "14m 1s (- 9m 21s) (60000 60%) 0.3955\n",
      "14m 3s (- 9m 19s) (60100 60%) 0.4134\n",
      "14m 4s (- 9m 18s) (60200 60%) 0.3706\n",
      "14m 5s (- 9m 16s) (60300 60%) 0.4725\n",
      "14m 7s (- 9m 15s) (60400 60%) 0.4097\n",
      "14m 9s (- 9m 14s) (60500 60%) 0.3595\n",
      "14m 11s (- 9m 13s) (60600 60%) 0.3956\n",
      "14m 12s (- 9m 12s) (60700 60%) 0.3587\n",
      "14m 13s (- 9m 10s) (60800 60%) 0.3717\n",
      "14m 15s (- 9m 9s) (60900 60%) 0.3161\n",
      "14m 16s (- 9m 7s) (61000 61%) 0.3980\n",
      "14m 18s (- 9m 6s) (61100 61%) 0.4152\n",
      "14m 19s (- 9m 4s) (61200 61%) 0.4220\n",
      "14m 21s (- 9m 3s) (61300 61%) 0.3376\n",
      "14m 22s (- 9m 2s) (61400 61%) 0.3524\n",
      "14m 23s (- 9m 0s) (61500 61%) 0.4089\n",
      "14m 25s (- 8m 59s) (61600 61%) 0.4601\n",
      "14m 26s (- 8m 58s) (61700 61%) 0.3668\n",
      "14m 28s (- 8m 56s) (61800 61%) 0.3865\n",
      "14m 30s (- 8m 55s) (61900 61%) 0.3597\n",
      "14m 32s (- 8m 54s) (62000 62%) 0.3303\n",
      "14m 34s (- 8m 53s) (62100 62%) 0.4123\n",
      "14m 35s (- 8m 52s) (62200 62%) 0.3579\n",
      "14m 38s (- 8m 51s) (62300 62%) 0.3581\n",
      "14m 41s (- 8m 51s) (62400 62%) 0.3412\n",
      "14m 42s (- 8m 49s) (62500 62%) 0.3948\n",
      "14m 44s (- 8m 48s) (62600 62%) 0.3832\n",
      "14m 46s (- 8m 47s) (62700 62%) 0.3761\n",
      "14m 48s (- 8m 46s) (62800 62%) 0.4399\n",
      "14m 50s (- 8m 45s) (62900 62%) 0.3322\n",
      "14m 52s (- 8m 43s) (63000 63%) 0.3766\n",
      "14m 54s (- 8m 43s) (63100 63%) 0.3193\n",
      "14m 56s (- 8m 42s) (63200 63%) 0.3952\n",
      "14m 59s (- 8m 41s) (63300 63%) 0.4011\n",
      "15m 2s (- 8m 40s) (63400 63%) 0.3621\n",
      "15m 5s (- 8m 40s) (63500 63%) 0.4449\n",
      "15m 8s (- 8m 39s) (63600 63%) 0.4352\n",
      "15m 10s (- 8m 38s) (63700 63%) 0.3413\n",
      "15m 12s (- 8m 37s) (63800 63%) 0.4525\n",
      "15m 15s (- 8m 37s) (63900 63%) 0.3714\n",
      "15m 18s (- 8m 36s) (64000 64%) 0.4537\n",
      "15m 21s (- 8m 35s) (64100 64%) 0.4043\n",
      "15m 23s (- 8m 35s) (64200 64%) 0.4039\n",
      "15m 26s (- 8m 34s) (64300 64%) 0.3940\n",
      "15m 29s (- 8m 33s) (64400 64%) 0.4139\n",
      "15m 31s (- 8m 32s) (64500 64%) 0.3839\n",
      "15m 33s (- 8m 31s) (64600 64%) 0.4263\n",
      "15m 35s (- 8m 30s) (64700 64%) 0.3266\n",
      "15m 38s (- 8m 29s) (64800 64%) 0.3869\n",
      "15m 40s (- 8m 28s) (64900 64%) 0.3264\n",
      "15m 42s (- 8m 27s) (65000 65%) 0.3649\n",
      "15m 44s (- 8m 26s) (65100 65%) 0.3629\n",
      "15m 46s (- 8m 25s) (65200 65%) 0.3648\n",
      "15m 48s (- 8m 24s) (65300 65%) 0.4432\n",
      "15m 51s (- 8m 23s) (65400 65%) 0.3506\n",
      "15m 53s (- 8m 22s) (65500 65%) 0.3870\n",
      "15m 54s (- 8m 20s) (65600 65%) 0.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15m 57s (- 8m 19s) (65700 65%) 0.3715\n",
      "15m 58s (- 8m 18s) (65800 65%) 0.3087\n",
      "16m 0s (- 8m 16s) (65900 65%) 0.3822\n",
      "16m 1s (- 8m 15s) (66000 66%) 0.4123\n",
      "16m 3s (- 8m 13s) (66100 66%) 0.4110\n",
      "16m 4s (- 8m 12s) (66200 66%) 0.4022\n",
      "16m 6s (- 8m 11s) (66300 66%) 0.3446\n",
      "16m 7s (- 8m 9s) (66400 66%) 0.3676\n",
      "16m 9s (- 8m 8s) (66500 66%) 0.3612\n",
      "16m 10s (- 8m 6s) (66600 66%) 0.3775\n",
      "16m 12s (- 8m 5s) (66700 66%) 0.4020\n",
      "16m 14s (- 8m 4s) (66800 66%) 0.3724\n",
      "16m 16s (- 8m 3s) (66900 66%) 0.3613\n",
      "16m 18s (- 8m 2s) (67000 67%) 0.3980\n",
      "16m 20s (- 8m 0s) (67100 67%) 0.3695\n",
      "16m 22s (- 7m 59s) (67200 67%) 0.2630\n",
      "16m 23s (- 7m 57s) (67300 67%) 0.4065\n",
      "16m 25s (- 7m 56s) (67400 67%) 0.3409\n",
      "16m 27s (- 7m 55s) (67500 67%) 0.4073\n",
      "16m 29s (- 7m 54s) (67600 67%) 0.4438\n",
      "16m 30s (- 7m 52s) (67700 67%) 0.4007\n",
      "16m 32s (- 7m 51s) (67800 67%) 0.3757\n",
      "16m 34s (- 7m 50s) (67900 67%) 0.3836\n",
      "16m 35s (- 7m 48s) (68000 68%) 0.3427\n",
      "16m 37s (- 7m 47s) (68100 68%) 0.3790\n",
      "16m 38s (- 7m 45s) (68200 68%) 0.3383\n",
      "16m 40s (- 7m 44s) (68300 68%) 0.3469\n",
      "16m 42s (- 7m 43s) (68400 68%) 0.4327\n",
      "16m 44s (- 7m 41s) (68500 68%) 0.3625\n",
      "16m 45s (- 7m 40s) (68600 68%) 0.3545\n",
      "16m 46s (- 7m 38s) (68700 68%) 0.3846\n",
      "16m 48s (- 7m 37s) (68800 68%) 0.3028\n",
      "16m 49s (- 7m 35s) (68900 68%) 0.3766\n",
      "16m 51s (- 7m 34s) (69000 69%) 0.3898\n",
      "16m 52s (- 7m 32s) (69100 69%) 0.3602\n",
      "16m 53s (- 7m 31s) (69200 69%) 0.3906\n",
      "16m 55s (- 7m 29s) (69300 69%) 0.4036\n",
      "16m 56s (- 7m 28s) (69400 69%) 0.3338\n",
      "16m 57s (- 7m 26s) (69500 69%) 0.4317\n",
      "16m 59s (- 7m 25s) (69600 69%) 0.3978\n",
      "17m 1s (- 7m 23s) (69700 69%) 0.3683\n",
      "17m 3s (- 7m 22s) (69800 69%) 0.3315\n",
      "17m 4s (- 7m 21s) (69900 69%) 0.3101\n",
      "17m 6s (- 7m 20s) (70000 70%) 0.4151\n",
      "17m 8s (- 7m 18s) (70100 70%) 0.4184\n",
      "17m 10s (- 7m 17s) (70200 70%) 0.3681\n",
      "17m 12s (- 7m 16s) (70300 70%) 0.3767\n",
      "17m 14s (- 7m 14s) (70400 70%) 0.4464\n",
      "17m 16s (- 7m 13s) (70500 70%) 0.3586\n",
      "17m 17s (- 7m 12s) (70600 70%) 0.3878\n",
      "17m 19s (- 7m 10s) (70700 70%) 0.2946\n",
      "17m 20s (- 7m 9s) (70800 70%) 0.3741\n",
      "17m 21s (- 7m 7s) (70900 70%) 0.4255\n",
      "17m 23s (- 7m 6s) (71000 71%) 0.3236\n",
      "17m 24s (- 7m 4s) (71100 71%) 0.3705\n",
      "17m 26s (- 7m 3s) (71200 71%) 0.3332\n",
      "17m 27s (- 7m 1s) (71300 71%) 0.4459\n",
      "17m 28s (- 7m 0s) (71400 71%) 0.4261\n",
      "17m 29s (- 6m 58s) (71500 71%) 0.3329\n",
      "17m 30s (- 6m 56s) (71600 71%) 0.4150\n",
      "17m 32s (- 6m 55s) (71700 71%) 0.4102\n",
      "17m 33s (- 6m 53s) (71800 71%) 0.3197\n",
      "17m 35s (- 6m 52s) (71900 71%) 0.3123\n",
      "17m 36s (- 6m 50s) (72000 72%) 0.3607\n",
      "17m 37s (- 6m 49s) (72100 72%) 0.3773\n",
      "17m 39s (- 6m 47s) (72200 72%) 0.3394\n",
      "17m 40s (- 6m 46s) (72300 72%) 0.3430\n",
      "17m 42s (- 6m 45s) (72400 72%) 0.3438\n",
      "17m 44s (- 6m 43s) (72500 72%) 0.3720\n",
      "17m 46s (- 6m 42s) (72600 72%) 0.3832\n",
      "17m 48s (- 6m 41s) (72700 72%) 0.4202\n",
      "17m 49s (- 6m 39s) (72800 72%) 0.4073\n",
      "17m 51s (- 6m 38s) (72900 72%) 0.3286\n",
      "17m 53s (- 6m 36s) (73000 73%) 0.4369\n",
      "17m 54s (- 6m 35s) (73100 73%) 0.3843\n",
      "17m 55s (- 6m 33s) (73200 73%) 0.4108\n",
      "17m 56s (- 6m 32s) (73300 73%) 0.4005\n",
      "17m 57s (- 6m 30s) (73400 73%) 0.3665\n",
      "17m 59s (- 6m 29s) (73500 73%) 0.3714\n",
      "18m 0s (- 6m 27s) (73600 73%) 0.4275\n",
      "18m 1s (- 6m 25s) (73700 73%) 0.3862\n",
      "18m 3s (- 6m 24s) (73800 73%) 0.3471\n",
      "18m 4s (- 6m 22s) (73900 73%) 0.3578\n",
      "18m 5s (- 6m 21s) (74000 74%) 0.3567\n",
      "18m 6s (- 6m 19s) (74100 74%) 0.3303\n",
      "18m 8s (- 6m 18s) (74200 74%) 0.3767\n",
      "18m 10s (- 6m 17s) (74300 74%) 0.3511\n",
      "18m 11s (- 6m 15s) (74400 74%) 0.4442\n",
      "18m 13s (- 6m 14s) (74500 74%) 0.4255\n",
      "18m 15s (- 6m 12s) (74600 74%) 0.3717\n",
      "18m 17s (- 6m 11s) (74700 74%) 0.3581\n",
      "18m 18s (- 6m 10s) (74800 74%) 0.4086\n",
      "18m 20s (- 6m 8s) (74900 74%) 0.3806\n",
      "18m 21s (- 6m 7s) (75000 75%) 0.3220\n",
      "18m 22s (- 6m 5s) (75100 75%) 0.3709\n",
      "18m 24s (- 6m 4s) (75200 75%) 0.3268\n",
      "18m 25s (- 6m 2s) (75300 75%) 0.3430\n",
      "18m 26s (- 6m 1s) (75400 75%) 0.3420\n",
      "18m 28s (- 5m 59s) (75500 75%) 0.4312\n",
      "18m 29s (- 5m 58s) (75600 75%) 0.2691\n",
      "18m 30s (- 5m 56s) (75700 75%) 0.3732\n",
      "18m 31s (- 5m 54s) (75800 75%) 0.3465\n",
      "18m 33s (- 5m 53s) (75900 75%) 0.3237\n",
      "18m 34s (- 5m 51s) (76000 76%) 0.4141\n",
      "18m 36s (- 5m 50s) (76100 76%) 0.3652\n",
      "18m 37s (- 5m 49s) (76200 76%) 0.3913\n",
      "18m 39s (- 5m 47s) (76300 76%) 0.3817\n",
      "18m 42s (- 5m 46s) (76400 76%) 0.4273\n",
      "18m 43s (- 5m 45s) (76500 76%) 0.3221\n",
      "18m 44s (- 5m 43s) (76600 76%) 0.4844\n",
      "18m 46s (- 5m 42s) (76700 76%) 0.3472\n",
      "18m 47s (- 5m 40s) (76800 76%) 0.4426\n",
      "18m 48s (- 5m 39s) (76900 76%) 0.3462\n",
      "18m 50s (- 5m 37s) (77000 77%) 0.4156\n",
      "18m 51s (- 5m 36s) (77100 77%) 0.3987\n",
      "18m 53s (- 5m 34s) (77200 77%) 0.3947\n",
      "18m 54s (- 5m 33s) (77300 77%) 0.4685\n",
      "18m 56s (- 5m 31s) (77400 77%) 0.4252\n",
      "18m 59s (- 5m 30s) (77500 77%) 0.4180\n",
      "19m 1s (- 5m 29s) (77600 77%) 0.4573\n",
      "19m 5s (- 5m 28s) (77700 77%) 0.4043\n",
      "19m 7s (- 5m 27s) (77800 77%) 0.3744\n",
      "19m 8s (- 5m 25s) (77900 77%) 0.4502\n",
      "19m 10s (- 5m 24s) (78000 78%) 0.3543\n",
      "19m 11s (- 5m 22s) (78100 78%) 0.4353\n",
      "19m 12s (- 5m 21s) (78200 78%) 0.3640\n",
      "19m 14s (- 5m 19s) (78300 78%) 0.3207\n",
      "19m 15s (- 5m 18s) (78400 78%) 0.3672\n",
      "19m 17s (- 5m 16s) (78500 78%) 0.3249\n",
      "19m 18s (- 5m 15s) (78600 78%) 0.4054\n",
      "19m 19s (- 5m 13s) (78700 78%) 0.4080\n",
      "19m 21s (- 5m 12s) (78800 78%) 0.3392\n",
      "19m 22s (- 5m 10s) (78900 78%) 0.3708\n",
      "19m 23s (- 5m 9s) (79000 79%) 0.3052\n",
      "19m 24s (- 5m 7s) (79100 79%) 0.2871\n",
      "19m 26s (- 5m 6s) (79200 79%) 0.3688\n",
      "19m 27s (- 5m 4s) (79300 79%) 0.3734\n",
      "19m 29s (- 5m 3s) (79400 79%) 0.2752\n",
      "19m 30s (- 5m 1s) (79500 79%) 0.4037\n",
      "19m 31s (- 5m 0s) (79600 79%) 0.3997\n",
      "19m 32s (- 4m 58s) (79700 79%) 0.3665\n",
      "19m 33s (- 4m 57s) (79800 79%) 0.4199\n",
      "19m 35s (- 4m 55s) (79900 79%) 0.3590\n",
      "19m 36s (- 4m 54s) (80000 80%) 0.3581\n",
      "19m 37s (- 4m 52s) (80100 80%) 0.3595\n",
      "19m 38s (- 4m 50s) (80200 80%) 0.3769\n",
      "19m 40s (- 4m 49s) (80300 80%) 0.3634\n",
      "19m 41s (- 4m 48s) (80400 80%) 0.3260\n",
      "19m 43s (- 4m 46s) (80500 80%) 0.3030\n",
      "19m 44s (- 4m 45s) (80600 80%) 0.4637\n",
      "19m 45s (- 4m 43s) (80700 80%) 0.2846\n",
      "19m 46s (- 4m 41s) (80800 80%) 0.3302\n",
      "19m 47s (- 4m 40s) (80900 80%) 0.4464\n",
      "19m 48s (- 4m 38s) (81000 81%) 0.3795\n",
      "19m 50s (- 4m 37s) (81100 81%) 0.3983\n",
      "19m 51s (- 4m 35s) (81200 81%) 0.4300\n",
      "19m 52s (- 4m 34s) (81300 81%) 0.5096\n",
      "19m 53s (- 4m 32s) (81400 81%) 0.3584\n",
      "19m 55s (- 4m 31s) (81500 81%) 0.3689\n",
      "19m 57s (- 4m 29s) (81600 81%) 0.4303\n",
      "19m 59s (- 4m 28s) (81700 81%) 0.3413\n",
      "20m 1s (- 4m 27s) (81800 81%) 0.4545\n",
      "20m 2s (- 4m 25s) (81900 81%) 0.3705\n",
      "20m 4s (- 4m 24s) (82000 82%) 0.3689\n",
      "20m 5s (- 4m 22s) (82100 82%) 0.3773\n",
      "20m 6s (- 4m 21s) (82200 82%) 0.4191\n",
      "20m 7s (- 4m 19s) (82300 82%) 0.3303\n",
      "20m 9s (- 4m 18s) (82400 82%) 0.4343\n",
      "20m 10s (- 4m 16s) (82500 82%) 0.3862\n",
      "20m 11s (- 4m 15s) (82600 82%) 0.4028\n",
      "20m 13s (- 4m 13s) (82700 82%) 0.3832\n",
      "20m 14s (- 4m 12s) (82800 82%) 0.3572\n",
      "20m 15s (- 4m 10s) (82900 82%) 0.3715\n",
      "20m 17s (- 4m 9s) (83000 83%) 0.3795\n",
      "20m 19s (- 4m 8s) (83100 83%) 0.3329\n",
      "20m 21s (- 4m 6s) (83200 83%) 0.4019\n",
      "20m 23s (- 4m 5s) (83300 83%) 0.4335\n",
      "20m 26s (- 4m 4s) (83400 83%) 0.3635\n",
      "20m 27s (- 4m 2s) (83500 83%) 0.2865\n",
      "20m 30s (- 4m 1s) (83600 83%) 0.3342\n",
      "20m 31s (- 3m 59s) (83700 83%) 0.3691\n",
      "20m 33s (- 3m 58s) (83800 83%) 0.3441\n",
      "20m 35s (- 3m 57s) (83900 83%) 0.3626\n",
      "20m 36s (- 3m 55s) (84000 84%) 0.3708\n",
      "20m 37s (- 3m 53s) (84100 84%) 0.4567\n",
      "20m 38s (- 3m 52s) (84200 84%) 0.3256\n",
      "20m 40s (- 3m 51s) (84300 84%) 0.4183\n",
      "20m 41s (- 3m 49s) (84400 84%) 0.3046\n",
      "20m 43s (- 3m 48s) (84500 84%) 0.3779\n",
      "20m 44s (- 3m 46s) (84600 84%) 0.3858\n",
      "20m 45s (- 3m 44s) (84700 84%) 0.3280\n",
      "20m 46s (- 3m 43s) (84800 84%) 0.3928\n",
      "20m 47s (- 3m 41s) (84900 84%) 0.4585\n",
      "20m 49s (- 3m 40s) (85000 85%) 0.4100\n",
      "20m 50s (- 3m 38s) (85100 85%) 0.3951\n",
      "20m 51s (- 3m 37s) (85200 85%) 0.4299\n",
      "20m 52s (- 3m 35s) (85300 85%) 0.3361\n",
      "20m 53s (- 3m 34s) (85400 85%) 0.4538\n",
      "20m 55s (- 3m 32s) (85500 85%) 0.3756\n",
      "20m 56s (- 3m 31s) (85600 85%) 0.3749\n",
      "20m 57s (- 3m 29s) (85700 85%) 0.3647\n",
      "20m 58s (- 3m 28s) (85800 85%) 0.3814\n",
      "20m 59s (- 3m 26s) (85900 85%) 0.4063\n",
      "21m 0s (- 3m 25s) (86000 86%) 0.3890\n",
      "21m 1s (- 3m 23s) (86100 86%) 0.3415\n",
      "21m 2s (- 3m 22s) (86200 86%) 0.3907\n",
      "21m 3s (- 3m 20s) (86300 86%) 0.3379\n",
      "21m 5s (- 3m 19s) (86400 86%) 0.4003\n",
      "21m 6s (- 3m 17s) (86500 86%) 0.3806\n",
      "21m 7s (- 3m 16s) (86600 86%) 0.3513\n",
      "21m 9s (- 3m 14s) (86700 86%) 0.3853\n",
      "21m 10s (- 3m 13s) (86800 86%) 0.3780\n",
      "21m 11s (- 3m 11s) (86900 86%) 0.3497\n",
      "21m 13s (- 3m 10s) (87000 87%) 0.3859\n",
      "21m 14s (- 3m 8s) (87100 87%) 0.4022\n",
      "21m 15s (- 3m 7s) (87200 87%) 0.3860\n",
      "21m 17s (- 3m 5s) (87300 87%) 0.3953\n",
      "21m 18s (- 3m 4s) (87400 87%) 0.3938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21m 19s (- 3m 2s) (87500 87%) 0.3767\n",
      "21m 20s (- 3m 1s) (87600 87%) 0.3895\n",
      "21m 21s (- 2m 59s) (87700 87%) 0.3553\n",
      "21m 22s (- 2m 58s) (87800 87%) 0.3408\n",
      "21m 24s (- 2m 56s) (87900 87%) 0.3766\n",
      "21m 25s (- 2m 55s) (88000 88%) 0.2869\n",
      "21m 26s (- 2m 53s) (88100 88%) 0.4391\n",
      "21m 27s (- 2m 52s) (88200 88%) 0.4249\n",
      "21m 28s (- 2m 50s) (88300 88%) 0.3634\n",
      "21m 29s (- 2m 49s) (88400 88%) 0.4156\n",
      "21m 30s (- 2m 47s) (88500 88%) 0.3691\n",
      "21m 31s (- 2m 46s) (88600 88%) 0.3917\n",
      "21m 32s (- 2m 44s) (88700 88%) 0.4061\n",
      "21m 33s (- 2m 43s) (88800 88%) 0.3796\n",
      "21m 35s (- 2m 41s) (88900 88%) 0.3656\n",
      "21m 36s (- 2m 40s) (89000 89%) 0.3918\n",
      "21m 38s (- 2m 38s) (89100 89%) 0.3190\n",
      "21m 39s (- 2m 37s) (89200 89%) 0.4269\n",
      "21m 41s (- 2m 35s) (89300 89%) 0.4161\n",
      "21m 43s (- 2m 34s) (89400 89%) 0.3910\n",
      "21m 44s (- 2m 33s) (89500 89%) 0.4486\n",
      "21m 46s (- 2m 31s) (89600 89%) 0.3107\n",
      "21m 47s (- 2m 30s) (89700 89%) 0.4483\n",
      "21m 49s (- 2m 28s) (89800 89%) 0.4603\n",
      "21m 50s (- 2m 27s) (89900 89%) 0.3857\n",
      "21m 51s (- 2m 25s) (90000 90%) 0.4475\n",
      "21m 53s (- 2m 24s) (90100 90%) 0.3643\n",
      "21m 54s (- 2m 22s) (90200 90%) 0.3354\n",
      "21m 55s (- 2m 21s) (90300 90%) 0.3976\n",
      "21m 56s (- 2m 19s) (90400 90%) 0.3345\n",
      "21m 58s (- 2m 18s) (90500 90%) 0.3784\n",
      "22m 1s (- 2m 17s) (90600 90%) 0.3553\n",
      "22m 2s (- 2m 15s) (90700 90%) 0.3775\n",
      "22m 4s (- 2m 14s) (90800 90%) 0.3661\n",
      "22m 5s (- 2m 12s) (90900 90%) 0.4529\n",
      "22m 7s (- 2m 11s) (91000 91%) 0.2974\n",
      "22m 8s (- 2m 9s) (91100 91%) 0.3696\n",
      "22m 10s (- 2m 8s) (91200 91%) 0.4227\n",
      "22m 11s (- 2m 6s) (91300 91%) 0.3710\n",
      "22m 12s (- 2m 5s) (91400 91%) 0.2515\n",
      "22m 14s (- 2m 3s) (91500 91%) 0.3222\n",
      "22m 17s (- 2m 2s) (91600 91%) 0.3807\n",
      "22m 19s (- 2m 1s) (91700 91%) 0.3835\n",
      "22m 21s (- 1m 59s) (91800 91%) 0.3404\n",
      "22m 23s (- 1m 58s) (91900 91%) 0.3516\n",
      "22m 24s (- 1m 56s) (92000 92%) 0.4000\n",
      "22m 26s (- 1m 55s) (92100 92%) 0.3818\n",
      "22m 27s (- 1m 53s) (92200 92%) 0.3278\n",
      "22m 29s (- 1m 52s) (92300 92%) 0.3811\n",
      "22m 30s (- 1m 51s) (92400 92%) 0.3042\n",
      "22m 31s (- 1m 49s) (92500 92%) 0.3235\n",
      "22m 32s (- 1m 48s) (92600 92%) 0.3570\n",
      "22m 34s (- 1m 46s) (92700 92%) 0.3419\n",
      "22m 35s (- 1m 45s) (92800 92%) 0.4188\n",
      "22m 36s (- 1m 43s) (92900 92%) 0.3068\n",
      "22m 38s (- 1m 42s) (93000 93%) 0.3761\n",
      "22m 39s (- 1m 40s) (93100 93%) 0.3506\n",
      "22m 41s (- 1m 39s) (93200 93%) 0.4326\n",
      "22m 43s (- 1m 37s) (93300 93%) 0.3434\n",
      "22m 44s (- 1m 36s) (93400 93%) 0.4289\n",
      "22m 46s (- 1m 35s) (93500 93%) 0.4084\n",
      "22m 48s (- 1m 33s) (93600 93%) 0.3198\n",
      "22m 49s (- 1m 32s) (93700 93%) 0.3564\n",
      "22m 50s (- 1m 30s) (93800 93%) 0.4176\n",
      "22m 52s (- 1m 29s) (93900 93%) 0.3861\n",
      "22m 54s (- 1m 27s) (94000 94%) 0.3775\n",
      "22m 55s (- 1m 26s) (94100 94%) 0.3180\n",
      "22m 57s (- 1m 24s) (94200 94%) 0.3307\n",
      "22m 58s (- 1m 23s) (94300 94%) 0.4497\n",
      "23m 0s (- 1m 21s) (94400 94%) 0.3011\n",
      "23m 1s (- 1m 20s) (94500 94%) 0.4009\n",
      "23m 2s (- 1m 18s) (94600 94%) 0.3822\n",
      "23m 3s (- 1m 17s) (94700 94%) 0.4075\n",
      "23m 6s (- 1m 16s) (94800 94%) 0.3593\n",
      "23m 8s (- 1m 14s) (94900 94%) 0.4138\n",
      "23m 9s (- 1m 13s) (95000 95%) 0.4122\n",
      "23m 11s (- 1m 11s) (95100 95%) 0.3711\n",
      "23m 12s (- 1m 10s) (95200 95%) 0.3740\n",
      "23m 14s (- 1m 8s) (95300 95%) 0.3711\n",
      "23m 15s (- 1m 7s) (95400 95%) 0.4073\n",
      "23m 17s (- 1m 5s) (95500 95%) 0.4779\n",
      "23m 19s (- 1m 4s) (95600 95%) 0.3696\n",
      "23m 22s (- 1m 3s) (95700 95%) 0.3499\n",
      "23m 25s (- 1m 1s) (95800 95%) 0.3616\n",
      "23m 27s (- 1m 0s) (95900 95%) 0.4356\n",
      "23m 29s (- 0m 58s) (96000 96%) 0.2885\n",
      "23m 32s (- 0m 57s) (96100 96%) 0.3785\n",
      "23m 34s (- 0m 55s) (96200 96%) 0.4216\n",
      "23m 35s (- 0m 54s) (96300 96%) 0.3152\n",
      "23m 37s (- 0m 52s) (96400 96%) 0.4321\n",
      "23m 39s (- 0m 51s) (96500 96%) 0.2995\n",
      "23m 41s (- 0m 50s) (96600 96%) 0.4400\n",
      "23m 42s (- 0m 48s) (96700 96%) 0.2607\n",
      "23m 44s (- 0m 47s) (96800 96%) 0.3190\n",
      "23m 45s (- 0m 45s) (96900 96%) 0.3270\n",
      "23m 47s (- 0m 44s) (97000 97%) 0.3678\n",
      "23m 48s (- 0m 42s) (97100 97%) 0.4021\n",
      "23m 50s (- 0m 41s) (97200 97%) 0.4273\n",
      "23m 51s (- 0m 39s) (97300 97%) 0.4392\n",
      "23m 53s (- 0m 38s) (97400 97%) 0.3865\n",
      "23m 54s (- 0m 36s) (97500 97%) 0.3908\n",
      "23m 55s (- 0m 35s) (97600 97%) 0.4093\n",
      "23m 56s (- 0m 33s) (97700 97%) 0.3774\n",
      "23m 58s (- 0m 32s) (97800 97%) 0.3796\n",
      "23m 59s (- 0m 30s) (97900 97%) 0.3021\n",
      "24m 0s (- 0m 29s) (98000 98%) 0.3609\n",
      "24m 2s (- 0m 27s) (98100 98%) 0.3806\n",
      "24m 3s (- 0m 26s) (98200 98%) 0.3513\n",
      "24m 4s (- 0m 24s) (98300 98%) 0.3687\n",
      "24m 6s (- 0m 23s) (98400 98%) 0.3713\n",
      "24m 7s (- 0m 22s) (98500 98%) 0.4607\n",
      "24m 8s (- 0m 20s) (98600 98%) 0.3611\n",
      "24m 9s (- 0m 19s) (98700 98%) 0.3999\n",
      "24m 11s (- 0m 17s) (98800 98%) 0.3846\n",
      "24m 12s (- 0m 16s) (98900 98%) 0.3250\n",
      "24m 14s (- 0m 14s) (99000 99%) 0.3901\n",
      "24m 16s (- 0m 13s) (99100 99%) 0.3776\n",
      "24m 17s (- 0m 11s) (99200 99%) 0.4677\n",
      "24m 18s (- 0m 10s) (99300 99%) 0.3477\n",
      "24m 19s (- 0m 8s) (99400 99%) 0.3741\n",
      "24m 20s (- 0m 7s) (99500 99%) 0.4347\n",
      "24m 22s (- 0m 5s) (99600 99%) 0.4464\n",
      "24m 23s (- 0m 4s) (99700 99%) 0.4054\n",
      "24m 25s (- 0m 2s) (99800 99%) 0.3940\n",
      "24m 27s (- 0m 1s) (99900 99%) 0.4435\n",
      "24m 28s (- 0m 0s) (100000 100%) 0.3949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c096b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b7716a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 20\n",
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 100\n",
    "\n",
    "my_encoder = EncoderRNN(len(singlish_vocab), hidden_size)\n",
    "my_decoder = DecoderRNN(hidden_size, len(english_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before moving on, SAVE THE MODELS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100000\n",
      "encoder_vanilla_100_100000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Here's a nice bleeding edge Python trick, (only works on Python3.6)\n",
    "# F-strings for the win!!\n",
    "# See https://www.python.org/dev/peps/pep-0498/\n",
    "print(hidden_size, batches)\n",
    "print(f'encoder_vanilla_{hidden_size}_{batches}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# In Python >= 3.6\n",
    "with open(f'encoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_encoder, fout)\n",
    "with open(f'decoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_decoder, fout)\n",
    "\n",
    "# For Python < 3.6\n",
    "with open('encoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "    pickle.dump(my_encoder, fout)\n",
    "with open('decoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "    pickle.dump(my_decoder, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 5, 13, 4, 12, 23, 4, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coffee with less sugar but and sugar'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi siew dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 21, 22, 3, 5, 6, 7, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'strong iced coffee with condensed milk'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Kopi gau siew dai peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 21, 2, 3, 5, 4, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'strong black coffee with sugar'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Kopi O gau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 88, 29, 65, 29, 19, 6, 7, 76, 78, 74, 77, 65, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'weak tea . tea water condensed milk to dilute the beverage .'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Teh poh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 82, 26, 83, 84, 61, 3, 5, 59, 19, 57, 81, 80, 76, 74, 70, 67, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'heaviest , purest version of coffee with no water added at all to the initial brew'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi tiloh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22, 2, 3, 5, 7, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'iced black coffee with milk'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi c peng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!!!\n",
    "====\n",
    "\n",
    "If you've made it this far down the notebook, you desire a pat on the back!\n",
    "\n",
    "You have successfully trained a Sequence-to-Sequence model in PyTorch. It's a first step towards bleeding edge developments in Natural Language Process (NLP) with deep learning. \n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "But the translator is far from great and the kopi uncle/auntie is going to stare blankly at you and say, \"Huh?!\". <br>\n",
    "So here's some next steps that you can take to improve the model =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0. Next Steps\n",
    "====\n",
    "\n",
    "Our code above implemented the basic single layer Elman network ([Elman, 1990](https://web.stanford.edu/group/pdplab/pdphandbook/handbookch8.html)), aka. Simple Recurrent Network (SRN), aka. vanilla RNN but we replace the neural network cell with Gated Recurrent Unit (GRU) ([Cho et al. 2014](https://arxiv.org/abs/1406.1078))\n",
    "\n",
    "There are several things that we can do to improve the model and the [PyTorch tutorial on Seq2Seq](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) gave a detailed exploration on\n",
    "\n",
    " - teacher forcing ([Williams and Zipser, 1989](http://ieeexplore.ieee.org/document/6795228/)) \n",
    " - attention context [(Bahdanau et al. 2015)](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "\n",
    "For the impatient, here's a pre-trained models with teacher forcing that you can play with on https://goo.gl/TVbW5u:\n",
    "\n",
    "-----\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DataScience SG Meetup (Jan 18) Epilogue \n",
    "====\n",
    "\n",
    "Sorry to keep you guys waiting for the slides and code, I cleaned up the code a little more and added more text explanations so that the notebook is more readable. \n",
    "\n",
    "To those that sat through watching me code the `???` in the DataScience SG meetup, thank you all for coming for the meetup grinding through neural net crash course and code walkthrough. \n",
    "\n",
    "Hopefully, you had picked up a few tricks in NLP, PyTorch and/or implementing the Seq2Seq model.\n",
    "\n",
    "I had fun going through the code together and chatting with you all after the talk. Thank you all again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
