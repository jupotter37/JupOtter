{
 "metadata": {
  "name": "",
  "signature": "sha256:afb94bc91a052c57720a486043d265fe819628b7d5cbf65a22568399456c75f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting Started with Predictive Services"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we show how to set up a GraphLab Predictive Service deployment, to enable low-latency REST queries of trained machine learning models from a cluster of EC2 instances. For more information, see the [Predictive Services](https://graphlab.com/learn/userguide/index.html#Deployment_GraphLab_Predictive_Services) section of the User Guide.\n",
      "\n",
      "We show how easy it is to: \n",
      "\n",
      "1. Launch a Predictive Service deployment\n",
      "1. Add new Predictive Objects\n",
      "1. Update existing Predictive Objects\n",
      "1. Monitor deployment status\n",
      "1. Query deployed Predictive Objects\n",
      "1. Integrate deployment into an application\n",
      "1. Terminate the Predictive Service deployment\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphlab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Define EC2 Configuration\n",
      "\n",
      "To launch a Predictive Service deployment we need to specify an [Ec2Config](https://graphlab.com/products/create/docs/generated/graphlab.deploy.Ec2Config.html) object for this deployment. This configuration includes the region (defaults to us-west-2), instance type (defaults to m3.xlarge), and your aws credentials (if needed)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "env = graphlab.deploy.Ec2Config(region='us-west-2',\n",
      "                                instance_type='m3.xlarge',\n",
      "                                aws_access_key_id='YOUR_ACCESS_KEY', \n",
      "                                aws_secret_access_key='YOUR_SECRET_KEY')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Launch the Predictive Service Deployment\n",
      "\n",
      "To launch a Predictive Service Deployment the API is [graphlab.deploy.predictive_service.create](https://graphlab.com/products/create/docs/generated/graphlab.deploy.predictive_service.create.html#graphlab.deploy.predictive_service.create). The required parameters are a name for the deployment, the EC2 configuration we defined in the previous step, and an S3 path for the root 'working directory' for this Predictive Service. This path is where the models and predictive objects will be uploaded, and where logs will be written for this Predictive Service.\n",
      "\n",
      "When this command is executed the EC2 instances will be launched immediately, then a load balancer will be launched, configured, and finally the load balancer will add the instances into the cluster as they pass health checks. The Predictive Service object will also be added to the workbench, so the deployment can be easily loaded in a later Python session."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment = graphlab.deploy.predictive_service.create('sample-service-onefive', env, 's3://gl-rajat-testing/pred-root/sample-service')\n",
      "deployment.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Launching Predictive Service with 1 hosts, as specified by num_hosts parameter\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Launching Predictive Service, with name: sample-service-onefive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 0/5]: Initializing S3 locations.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 1/5]: Launching EC2 instances.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] This commercial license of GraphLab Create is assigned to engr@turi.com.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Launching an m3.xlarge instance in the us-west-2a availability zone, with id: i-7ed516b7. You will be responsible for the cost of this instance.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] WARNING: Launching Predictive Service without SSL certificate!\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 2/5]: Launching Load Balancer.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 3/5]: Configuring Load Balancer.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 4/5]: Waiting for Load Balancer to put all instances into service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster not fully operational yet, [0/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cluster is fully operational, [1/1] instances currently in service.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] [Step 5/5]: Finalizing Configuration.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Cache enabled successfully!\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are other parameters which are optional, like specifying an SSL credential pair for HTTPS, specifying API keys and Admin keys (API keys enable REST queries, Admin keys enable adding/modifying the deployment), and the number of hosts in the cluster.\n",
      "\n",
      "Print the deployment to see the details about this deployment. This shows the information necessary to connect to the deployment from an application, which predictive objects (models) are deployed, and whether there are any pending changes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "text": [
        "Name                  : sample-service-onefive\n",
        "State Path            : s3://gl-rajat-testing/pred-root/sample-service\n",
        "Description           : None\n",
        "API Key               : 806fc046-62da-4e5b-ab9d-0dc6ac2ff549\n",
        "CORS origin           : \n",
        "Global Cache State    : enabled\n",
        "Load Balancer DNS Name: sample-service-onefive-137425129.us-west-2.elb.amazonaws.com\n",
        "\n",
        "Deployed predictive objects:\n",
        "No Pending changes."
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Visualize Predictive Service\n",
      "\n",
      "GraphLab Canvas shows the details of this Predictive Service, and provides the introductory monitoring dashboard for the cluster. See the API documentation [here](https://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.show.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.show)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Canvas is accessible via web browser at the URL: http://localhost:59585/index.html\n",
        "Opening Canvas in default web browser.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] retrieving metrics from predictive service...\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare a Predictive Object (train a Model)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the cluster is ready, let's quickly train a Model to upload to this deployment. Each GraphLab Model is a Predictive Object. Custom Predictive Objects can also be specified by writing a function in Python, see the [User Guide](https://graphlab.com/learn/userguide/index.html#Deployment_GraphLab_Predictive_Services_Working_with_Predictive_Objects) for more information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_url = 'https://static.turi.com/datasets/movie_ratings/sample.small'\n",
      "data = graphlab.SFrame.read_csv(data_url,delimiter='\\t',column_type_hints={'rating':int})\n",
      "(train_set, test_set) = data.random_split(0.8)\n",
      "model = graphlab.popularity_recommender.create(train_set, 'user', 'movie', 'rating')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>PROGRESS: Downloading https://static.turi.com/datasets/movie_ratings/sample.small to /var/tmp/graphlab-rajat/42160/000005.small</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Downloading https://static.turi.com/datasets/movie_ratings/sample.small to /var/tmp/graphlab-rajat/42160/000005.small"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file https://static.turi.com/datasets/movie_ratings/sample.small</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file https://static.turi.com/datasets/movie_ratings/sample.small"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 2.10975 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 2.10975 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Read 1549015 lines. Lines per second: 652272</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Read 1549015 lines. Lines per second: 652272"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file https://static.turi.com/datasets/movie_ratings/sample.small</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file https://static.turi.com/datasets/movie_ratings/sample.small"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 4000000 lines in 4.33449 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 4000000 lines in 4.33449 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Recsys training: model = popularity</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Recsys training: model = popularity"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Preparing data set.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Preparing data set."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS:     Data has 3200435 observations with 12020 users and 17188 items.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS:     Data has 3200435 observations with 12020 users and 17188 items."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS:     Data prepared in: 4.25899s</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS:     Data prepared in: 4.25899s"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: 3200435 observations to process; with 17188 unique items.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: 3200435 observations to process; with 17188 unique items."
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Add the Predictive Object to the deployment, then apply changes\n",
      "\n",
      "Adding a Predictive Object stages this Predictive Object to be deployed to the cluster. To add a predictive object specify a name (which will be used in the URI to query the model in the REST API), and then specify the model object (or a path to the model). See the API documentation [here](https://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.add.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.add)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.add('recs', model, description='Sample Recommender')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] New predictive object 'recs' added, use apply_changes() to deploy all pending changes, or continue other modification.\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if you print the deployment there will be a pending predictive object that was just added."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "text": [
        "Name                  : sample-service-onefive\n",
        "State Path            : s3://gl-rajat-testing/pred-root/sample-service\n",
        "Description           : None\n",
        "API Key               : 806fc046-62da-4e5b-ab9d-0dc6ac2ff549\n",
        "CORS origin           : \n",
        "Global Cache State    : enabled\n",
        "Load Balancer DNS Name: sample-service-onefive-137425129.us-west-2.elb.amazonaws.com\n",
        "\n",
        "Deployed predictive objects:\n",
        "Pending changes: \n",
        "\tAdding: recs, description: "
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Updating an existing model\n",
      " \n",
      "To update an existing model or predictive object, use the [update](https://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.update.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.update) method. Update will increment the version of an existing predictive object. When published, the updated model will be proactively warmed in the distributed cache, and existing cached entries for this model will be expired in 15 minutes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To complete the publishing of this Predictive Object (model), call the [apply_changes](https://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.apply_changes.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.apply_changes) method. By calling this API the pending predictive objects will be uploaded to S3, and the cluster will be notified to download them from S3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.apply_changes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Uploading local path /var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT to s3 path: s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.sidx to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.sidx\n",
        "\r",
        "Completed 1 of 11 part(s) with 8 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_ade2c73172c7342b.sidx to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_ade2c73172c7342b.sidx\n",
        "\r",
        "Completed 2 of 11 part(s) with 7 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/dir_archive.ini to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/dir_archive.ini\n",
        "\r",
        "Completed 3 of 11 part(s) with 6 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.frame_idx to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.frame_idx\n",
        "\r",
        "Completed 4 of 11 part(s) with 5 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/version to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/version\n",
        "\r",
        "Completed 5 of 11 part(s) with 4 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/pickle_archive to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/pickle_archive\n",
        "\r",
        "Completed 6 of 11 part(s) with 3 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Completed 7 of 11 part(s) with 3 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.0000 to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_719dbd25102195e0.0000\n",
        "\r",
        "Completed 8 of 11 part(s) with 2 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/objects.bin to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/objects.bin\n",
        "\r",
        "Completed 9 of 11 part(s) with 1 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Completed 10 of 11 part(s) with 1 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "Completed 11 of 11 part(s) with 1 file(s) remaining"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Successfully uploaded to s3 path s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Notifying: ec2-52-27-212-78.us-west-2.compute.amazonaws.com\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "upload: ../../../../var/folders/g3/n0zyc7612mdfs9bmp4h5vn180000gn/T/predictive_object_YzaqGT/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_ade2c73172c7342b.0000 to s3://gl-rajat-testing/pred-root/sample-service/predictive_objects/recs/1/a8287914-0dc2-4a8a-b0d3-8122d5d12fdb/m_ade2c73172c7342b.0000\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the status of the deployment, call the get_status API."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.get_status()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "text": [
        "[{'cache': {u'healthy': True, u'num_keys': 1, u'type': u'local'},\n",
        "  'dns_name': u'ec2-52-27-212-78.us-west-2.compute.amazonaws.com',\n",
        "  'id': u'i-7ed516b7',\n",
        "  'models': [{u'cache_enabled': True,\n",
        "    u'description': u'',\n",
        "    u'name': u'recs',\n",
        "    u'reason': u'N/A',\n",
        "    u'status': u'Loaded successfully',\n",
        "    u'version': 1}],\n",
        "  'reason': u'N/A',\n",
        "  'state': u'InService'}]"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Query service (using deployment object)\n",
      "\n",
      "To test this Predictive Object deployed to the Predictive Service, use the [query](https://turi.com/products/create/docs/generated/graphlab.deploy.PredictiveService.query.html) function from the deployment object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recs = deployment.query('recs', method='recommend', data={'users':['Jacob Smith']})\n",
      "recs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "text": [
        "{u'response': [{u'movie': u'Bellydance Fitness Fusion for Beginners with Suhaila: Buns',\n",
        "   u'rank': 1,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u\"Stephen Sondheim's Putting It Together\",\n",
        "   u'rank': 2,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Strange Relations',\n",
        "   u'rank': 3,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Celebrating Bird: The Triumph of Charlie Parker',\n",
        "   u'rank': 4,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Kiddy Grade',\n",
        "   u'rank': 5,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Loves of Carmen',\n",
        "   u'rank': 6,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'The Bob Newhart Show: Season 2',\n",
        "   u'rank': 7,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Dragon Ball Z: Great Saiyaman: Declaration',\n",
        "   u'rank': 8,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Sangam', u'rank': 9, u'score': 5.0, u'user': u'Jacob Smith'},\n",
        "  {u'movie': u'Hart to Hart: Season 1',\n",
        "   u'rank': 10,\n",
        "   u'score': 5.0,\n",
        "   u'user': u'Jacob Smith'}],\n",
        " u'uuid': u'fc605592-de0e-43ac-b4f8-8df361d18b8d',\n",
        " u'version': 1}"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Query service (using a client library)\n",
      "\n",
      "Now to integrate this Predictive Service deployment into an application, next step is to query the REST API on the cluster. Below are the available client libraries for Predictive Service. One can also use curl, which can be modified for any programming language needed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Please follow the instructions to install and use these client libraries.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### [Python Predictive Service Client](https://github.com/turi-code/Turi-Predictive-Service-Client-Python)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### [Node Predictive Service Client](https://github.com/turi-code/Turi-Predictive-Service-Client-Node)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### [Javascript Predictive Service Client](https://github.com/turi-code/Turi-Predictive-Service-Client-JS)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### [Java Predictive Service Client](https://github.com/turi-code/Turi-Predictive-Service-Client-Java)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### cURL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -X POST -d '{\"api key\": \"806fc046-62da-4e5b-ab9d-0dc6ac2ff549\", \"data\":{\"method\":\"recommend\", \"data\": {\"users\":[\"Jacob Smith\"]}}}' http://sample-service-onefive-137425129.us-west-2.elb.amazonaws.com/query/recs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Terminate Predictive Services Deployment\n",
      "\n",
      "To terminate a Predictive Service, call the [terminate_service()](https://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.terminate_service.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.terminate_service) API. There are options to delete the logs and predictive objects as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.terminate_service(remove_logs=True, remove_state=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Deleting load balancer: sample-service-onefive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Terminating EC2 host(s) [u'i-7ed516b7'] in us-west-2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Deleting log files.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Deleting state data.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Deleting s3 state data.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Deleted reference to PredictiveService('sample-service-onefive') from current session.\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a lot more you can do with a Predictive Service. Spin one up for yourself and see how easy it is to consume a Model, or define your own Custom Predictive Object."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
