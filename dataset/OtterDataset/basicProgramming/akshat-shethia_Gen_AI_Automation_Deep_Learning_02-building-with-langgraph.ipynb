{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa533b08-a7bf-46c8-bda8-e3b0e68d7004",
   "metadata": {},
   "source": [
    "# Building with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80480c1a-b9da-487f-9293-8f991ba57dbd",
   "metadata": {},
   "source": [
    "## Building a ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd85174-7bcc-4000-83ba-2874ed15c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "matplotlib 3.9.1 requires pillow>=8, which is not installed.\n",
      "scikit-learn 1.5.1 requires joblib>=1.2.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade -q openai langchain langchain-openai langchain-community langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33823fa-9733-449f-829e-2bdf203a7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637d3655-8d9f-4ef1-a3b1-9976cf1e6696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the API key from .env\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4beecb-74ed-44ef-8e0f-bd7019677666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "# defining the chatbot node\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# adding the node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# setting the entry and the finish points\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3359e9-2377-4185-b530-c361d0fb5274",
   "metadata": {},
   "source": [
    "## Visualizing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652d99be-f2e3-42cb-a9af-a85aef41fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5566c1-429d-4030-95b2-f95652de39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4778a311-0a74-42b1-891e-1419babfa99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \n",
      "| __start__ |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | chatbot |   \n",
      " +---------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | __end__ |   \n",
      " +---------+   \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b64d7-ffed-4dfb-8a78-b9f98c3633ef",
   "metadata": {},
   "source": [
    "## Running the ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20697292-5540-40d6-a787-37721497da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Distance to moon in km\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The average distance from the Earth to the Moon is approximately 384,400 kilometers (about 238,855 miles). This distance can vary slightly due to the Moon's elliptical orbit around the Earth.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Paris is ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Paris is the capital city of France, known for its rich history, art, fashion, and culture. It's famous for iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and the Champs-Élysées. The city is often referred to as \"The City of Light\" (La Ville Lumière) and is renowned for its vibrant atmosphere, world-class cuisine, and romantic ambiance. Paris is also a major center for art, literature, and philosophy, attracting millions of visitors each year. Would you like to know more about a specific aspect of Paris?\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye',  'q']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    for event in graph.stream({'messages': ('user', user_input)}):\n",
    "        for value in event.values():\n",
    "            print(f'Assistant: {value[\"messages\"][-1].content}')\n",
    "            print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8e583-81c6-4b09-84f6-66d4480af33c",
   "metadata": {},
   "source": [
    "## Tavily AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ddc45e-0a80-4d9f-a9ee-eefd5d633729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4573fb0-6232-42af-9a3d-4ffcc0e214e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362a7552-f2f6-4dfe-b031-63febaa6432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'EUFA EURO 2024 FINAL',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Spain vs. England Highlights | UEFA Euro 2024 | Final',\n",
       "   'url': 'https://www.foxsports.com/watch/fmc-6s3o670adn0rrlmt',\n",
       "   'content': 'Check out the top moments between Spain and England in the UEFA Euro 2024 Final! JULY 14・uefa euro goals・11:23. UEFA Euro EURO - Spain vs. England - 07/14/2024 Harry Kane Nico Williams Lamine ...',\n",
       "   'score': 0.9994385,\n",
       "   'raw_content': None},\n",
       "  {'title': 'UEFA Euro 2024 final - Wikipedia',\n",
       "   'url': 'https://en.wikipedia.org/wiki/UEFA_Euro_2024_Final',\n",
       "   'content': \"The UEFA Euro 2024 final was a football match that determined the winners of UEFA Euro 2024.The match was the 17th final of the UEFA European Championship, a quadrennial tournament contested by the men's national teams of the member associations of UEFA to decide the champions of Europe. The match was held at the Olympiastadion in Berlin, Germany, on 14 July 2024, and was contested by Spain ...\",\n",
       "   'score': 0.9993953,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Spain vs England EURO 2024 final preview: Where to watch ... - UEFA.com',\n",
       "   'url': 'https://www.uefa.com/euro2024/news/028f-1b597d73ac44-281bef77526d-1000--spain-vs-england-euro-2024-final-preview-where-to-watch-k/',\n",
       "   'content': 'All you need to know about the UEFA EURO 2024 final between Spain and England. Article top media content. Article body. Spain and England meet in the UEFA EURO 2024 final on Sunday 14 July.',\n",
       "   'score': 0.9975845,\n",
       "   'raw_content': None},\n",
       "  {'title': 'EURO 2024 final: Who was in it? When and where was it? - UEFA.com',\n",
       "   'url': 'https://www.uefa.com/euro2024/news/0284-18bb952a9458-2a9e1ff202c4-1000--euro-2024-final-when-and-where-is-it/',\n",
       "   'content': 'The UEFA EURO 2024 final was played on Sunday 14 July, kicking off at 21:00 CET. The final: all the reaction. The match took place at Olympiastadion Berlin, the biggest stadium at the tournament ...',\n",
       "   'score': 0.9974191,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Spain 2-1 England: Late Oyarzabal winner earns La Roja ... - UEFA.com',\n",
       "   'url': 'https://www.uefa.com/euro2024/news/028f-1b5e5c2b7b67-d5faab9be20b-1000--spain-2-1-england-late-oyarzabal-winner-earns-la-roja-reco/',\n",
       "   'content': \"Mikel Oyarzabal's goal four minutes from time earned Spain a 2-1 win against England in the final of UEFA EURO 2024 - a record-breaking fourth title for La Roja. Considering both coaches ...\",\n",
       "   'score': 0.9972316,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.17}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "# initializing a Tavily client\n",
    "client = TavilyClient(api_key=os.environ.get('TAVILY_API_KEY'))\n",
    "\n",
    "response = client.search(query='EUFA EURO 2024 FINAL')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657c7f2f-a13a-4006-99e7-e042b7bf0bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Spain vs. England Highlights | UEFA Euro 2024 | Final, URL: https://www.foxsports.com/watch/fmc-6s3o670adn0rrlmt\n",
      "Title: UEFA Euro 2024 final - Wikipedia, URL: https://en.wikipedia.org/wiki/UEFA_Euro_2024_Final\n",
      "Title: Spain vs England EURO 2024 final preview: Where to watch ... - UEFA.com, URL: https://www.uefa.com/euro2024/news/028f-1b597d73ac44-281bef77526d-1000--spain-vs-england-euro-2024-final-preview-where-to-watch-k/\n",
      "Title: EURO 2024 final: Who was in it? When and where was it? - UEFA.com, URL: https://www.uefa.com/euro2024/news/0284-18bb952a9458-2a9e1ff202c4-1000--euro-2024-final-when-and-where-is-it/\n",
      "Title: Spain 2-1 England: Late Oyarzabal winner earns La Roja ... - UEFA.com, URL: https://www.uefa.com/euro2024/news/028f-1b5e5c2b7b67-d5faab9be20b-1000--spain-2-1-england-late-oyarzabal-winner-earns-la-roja-reco/\n"
     ]
    }
   ],
   "source": [
    "for result in response['results']:\n",
    "    print(f\"Title: {result['title']}, URL: {result['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a77b6a-2578-4bc8-b2f8-72058c6b8612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What LLM agents?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': 'LLM agents are systems that leverage Large Language Models (LLMs) to reason through problems, create plans to solve them, and execute these plans with the assistance of various tools. They combine data analysis, strategic planning, data retrieval, and learning from past actions to handle complex issues effectively. These agents can utilize a Planning Module for question-decomposition, a RAG pipeline for information retrieval, and memory modules for accurate handling of subquestions. The applications of LLM agents are diverse and can range from generating context-aware answers to solving programmatically complex tasks through code interpretation.',\n",
       " 'images': ['https://promptengineering.org/content/images/2023/08/Prompt-engineering---Large-Language-Model-LLM--Autonomous-Agent-Structure---PromptEngineering.org.jpg',\n",
       "  'https://gptpluginz.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-30-at-2.11.50-PM-1024x562.jpg',\n",
       "  'https://gptpluginz.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-30-at-3.11.05-PM-1024x516.png',\n",
       "  'https://promptengineering.org/content/images/size/w1000/2023/07/Prompt-engineering---Large-Language-Model-LLM--Autonomous-Agent.jpg',\n",
       "  'https://arize.com/wp-content/uploads/2023/05/llm-agent-in-product-docs-chatbot-architecture-diagram-example-831x797.png'],\n",
       " 'results': [{'title': 'LLM agents: The ultimate guide | SuperAnnotate',\n",
       "   'url': 'https://www.superannotate.com/blog/llm-agents',\n",
       "   'content': \"LLM agents are designed for exactly these kinds of situations in language model applications. They combine thorough data analysis, strategic planning, data retrieval, and the ability to learn from past actions to solve complex issues. In this article, we'll explore what LLM agents are, their benefits, abilities, practical examples, and the ...\",\n",
       "   'score': 0.9988441,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Introduction to LLM Agents | NVIDIA Technical Blog',\n",
       "   'url': 'https://developer.nvidia.com/blog/introduction-to-llm-agents',\n",
       "   'content': 'Demystifying Retrieval-Augmented Generation Pipelines\\nBuild Enterprise Retrieval-Augmented Generation Apps with NVIDIA Retrieval QA Embedding Model\\nTraining a Text2Sparql Model with MK-SQuIT and NeMo\\nRelated posts\\nDevelop Custom Enterprise Generative AI with NVIDIA NeMo\\nStreamline Evaluation of LLMs for Accuracy with NVIDIA NeMo Evaluator\\nNVIDIA H200 Tensor Core GPUs and NVIDIA TensorRT-LLM Set MLPerf LLM Inference Records\\nAn Easy Introduction to Multimodal Retrieval Augmented Generation\\nHow to Take a RAG Application from Pilot to Production in Four Steps While there isn’t a widely accepted definition for LLM-powered agents, they can be described as a system that can use an LLM to reason through a problem, create a plan to solve the problem, and execute the plan with the help of a set of tools.\\n To answer this question, you essentially must answer three questions individually (i.e., we need a planning module):\\nIn this case, you would need an agent that has access to a \\xa0Planning Module that does question-decomposition (generates sub-questions and searches for answers till the larger problem is solved), a RAG pipeline (used as a tool) to retrieve specific information, and memory modules to accurately handle the subquestions. Agents for enterprise applications\\nWhile the applications of agents are practically boundless, the following are a few interesting cases that may have an outsized impact for many businesses:\\n“Talk to your data” agent\\n“Talk to your data” isn’t a simple problem. For instance, agents can use a RAG pipeline to generate context aware answers, a code interpreter to solve complex programmatically tasks, an API to search information over the internet, or even any simple API service like a weather API or an API for an Instant messaging application.\\n',\n",
       "   'score': 0.9954083,\n",
       "   'raw_content': None},\n",
       "  {'title': 'What are LLM Agents? (Guide) - truefoundry.com',\n",
       "   'url': 'https://www.truefoundry.com/blog/llm-agents',\n",
       "   'content': 'In the context of LLM (Large Language Model) agents, tools refer to external resources, services, or APIs (Application Programming Interfaces) that the agent can utilize to perform specific tasks or enhance its capabilities. These tools serve as supplementary components that extend the functionality of the LLM agent beyond its inherent language ...',\n",
       "   'score': 0.9946775,\n",
       "   'raw_content': None},\n",
       "  {'title': 'LLM Agents Demystified. Hands-on ReAct agent implementation… | by Li ...',\n",
       "   'url': 'https://towardsdatascience.com/llm-agents-demystified-8e2a62c185fa',\n",
       "   'content': 'Alongside the well-known RAGs, agents are another popular family of LLM applications. What makes agents stand out is their ability to reason, plan, and act via accessible tools. When it comes to implementation, AdalFlow has simplified it down to a generator that can use tools, taking multiple steps (sequential or parallel) to complete a user ...',\n",
       "   'score': 0.9929882,\n",
       "   'raw_content': None},\n",
       "  {'title': \"Navigating the World of LLM Agents: A Beginner's Guide\",\n",
       "   'url': 'https://towardsdatascience.com/navigating-the-world-of-llm-agents-a-beginners-guide-3b8d499db7a9',\n",
       "   'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nNavigating the World of LLM Agents: A Beginner’s Guide\\nA Step-by-Step Guide to Discover and Harness the Power of LLM Agents and Toolkits\\nDominik Polzer\\nFollow\\nTowards Data Science\\n--\\n1\\nShare\\nTable of Contents\\nIntro\\nWhat are Agents?What — The Chain-of-ThoughtThe Agent Executor — The Agent behind the Agent\\nFrom Theory to Practice\\nHow to Use the SQLDatabaseToolkit?Hands-On Tutorial\\nSummary\\nIntro\\nThis article is about how we can get LLMs (Large Language Models) to solve complex tasks independently.\\n linkedin.com/in/polzerdo/\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams --\\n--\\n1\\nWritten by Dominik Polzer\\nTowards Data Science\\nMachine Learning Engineer. This concept we want to transfer to LLMs to continuously make new decisions and thus gradually approaching the solution to more complex problems.\\n',\n",
       "   'score': 0.9875203,\n",
       "   'raw_content': None},\n",
       "  {'title': 'A Complete Guide to LLMs-based Autonomous Agents (Part I): - Medium',\n",
       "   'url': 'https://medium.com/the-modern-scientist/a-complete-guide-to-llms-based-autonomous-agents-part-i-69515c016792',\n",
       "   'content': 'Sign up\\nSign in\\nSign up\\nSign in\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\nYule Wang, PhD\\nFollow\\nThe Modern Scientist\\n--\\n6\\nListen\\nShare\\n— — Chain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\nLarge Language Models (LLMs) provide an intuitive natural language interface, making them ideal for user-computer interactions and addressing complex problems. This is my personal blog…\\nwww.youtube.com\\nOther YT Videos:\\nIn-Depth Look at Transformer Based Models: BERT, GPT: Training Objectives & Architectures Compared\\nChatGPT’s reinforcement model — InstructGPT\\nWord-Embeddings: GloVe, CBOW, skip-gram\\n--\\n--\\n6\\nWritten by Yule Wang, PhD\\nThe Modern Scientist\\nMLE, PhD. Mission Cloud Consulting. The method presented follows a “plan a step” followed by “resolve this plan” loop, rather than a strategy where all steps are planned upfront and then executed, as seen in plan-and-solve agents:\\nBiography\\nYule Wang, Physics PhD, NLP Machine Learning Engineer\\nMy LinkedIn: https://www.linkedin.com/in/yule-wang-ml/\\nMy YouTube Channel\\nYule Wang\\n YT channel: youtube.com/@yulewang_machinelearning LinkedIn: linkedin.com/in/yule-wang-ml/\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams While Llama-2 as the competent open-sourced model, though competent, can sometimes might fall short in some reasoning tasks; GPT-4, as the the most powerful model available for public use, showcases prowess in fields such as generic reasoning tasks, including reading comprehension, commonsense reasoning and logical reasoning, and is also adept at code generation.',\n",
       "   'score': 0.96820134,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Intro to LLM Agents with Langchain: When RAG is Not Enough',\n",
       "   'url': 'https://towardsdatascience.com/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834',\n",
       "   'content': 'Good luck with your AI projects and don’t hesitate to reach out if you need help at your company!\\n--\\n--\\nWritten by Alex Honchar\\nTowards Data Science\\nCo-founder @ Neurons Lab\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Notice, how we can easily decompose and define separately:\\nThe final definition of the agent will look as simple as this:\\nAs you can see in the outputs of the script (or you can run it yourself), it solves the issue in the previous part related to tools. For example, while building the tree of thoughts prompts, I save my sub-prompts in the prompts repository and load them:\\nYou can see in this notebook the result of such reasoning, the point I want to make here is the right process for defining your reasoning steps and versioning them in such an LLMOps system like Langsmith. If you prefer a narrative walkthrough, you can find the YouTube video here:\\nAs always, you can find the code on GitHub, and here are separate Colab Notebooks:\\nIntroduction to the agents\\nLet’s begin the lecture by exploring various examples of LLM agents. Also, you can see other examples of popular reasoning techniques in public repositories like ReAct or Self-ask with search:\\nOther notable approaches are:\\nStep 2: Memory\\nStep 3: Tools\\nChatGPT Plugins and OpenAI API function calling are good examples of LLMs augmented with tool use capability working in practice.\\n',\n",
       "   'score': 0.95945925,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 2.81}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.search(\n",
    "    query='What LLM agents?',\n",
    "    search_depth='advanced',\n",
    "    max_results=7,\n",
    "    include_images=True,\n",
    "    include_answer=True,\n",
    "    include_raw_content=False\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac70237-229d-4c60-973f-aedbb0a1e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Madrid won the UEFA Champions League in 2024 by defeating Borussia Dortmund 2-0 in the final.\n"
     ]
    }
   ],
   "source": [
    "answer = client.qna_search(query='Who won the UEFA Champions League in 2024?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b60a94c-6b99-4dc4-b5d3-2399db1b1d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Tutorials - langchain-ai.github.io',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/tutorials/',\n",
       "  'content': 'Reflection & Critique¶ Basic Reflection: Prompt the agent to reflect on and revise its outputs; Reflexion: Critique missing and superfluous details to guide next steps; Language Agent Tree Search: Use reflection and rewards to drive a tree search over agents; Self-Discover Agent: Analyze an agent that learns about its own capabilities ...',\n",
       "  'score': 0.98573,\n",
       "  'raw_content': None},\n",
       " {'title': 'Langgraph agentic rag',\n",
       "  'url': 'https://langchain-ai.github.io/langgraphjs/tutorials/rag/langgraph_agentic_rag/',\n",
       "  'content': 'Langgraph agentic rag Langgraph agentic rag Table of contents Setup Load env vars Install dependencies Retriever Agent state Nodes and Edges Edges Graph See the LangSmith trace here. Langgraph crag Langgraph self rag Langgraph adaptive rag local Planning Agents Reflection & Critique How-to Guides',\n",
       "  'score': 0.9823,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.adapters.openai import convert_openai_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "query = 'What is the \"Reflection & Critique\" pattern used in agentic applications and LangGraph?'\n",
    "\n",
    "response = client.search(query, max_results=5, search_depth='advanced')['results']\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a7d4d1-41d1-4b3f-86a9-3f9be95cadf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI critical thinker research assistant. \\n        Your sole purpose is to write well written, objective and structured reports on given text.'),\n",
       " HumanMessage(content='Information: \"\"\"[{\\'title\\': \\'Tutorials - langchain-ai.github.io\\', \\'url\\': \\'https://langchain-ai.github.io/langgraph/tutorials/\\', \\'content\\': \\'Reflection & Critique¶ Basic Reflection: Prompt the agent to reflect on and revise its outputs; Reflexion: Critique missing and superfluous details to guide next steps; Language Agent Tree Search: Use reflection and rewards to drive a tree search over agents; Self-Discover Agent: Analyze an agent that learns about its own capabilities ...\\', \\'score\\': 0.98573, \\'raw_content\\': None}, {\\'title\\': \\'Langgraph agentic rag\\', \\'url\\': \\'https://langchain-ai.github.io/langgraphjs/tutorials/rag/langgraph_agentic_rag/\\', \\'content\\': \\'Langgraph agentic rag Langgraph agentic rag Table of contents Setup Load env vars Install dependencies Retriever Agent state Nodes and Edges Edges Graph See the LangSmith trace here. Langgraph crag Langgraph self rag Langgraph adaptive rag local Planning Agents Reflection & Critique How-to Guides\\', \\'score\\': 0.9823, \\'raw_content\\': None}]\"\"\"\\n        Using the above information, answer the following query: \"\"\"What is the \"Reflection & Critique\" pattern used in agentic applications and LangGraph?\"\"\" in a detailed report')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the OpenAI API prompt\n",
    "prompt = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': f'''You are an AI critical thinker research assistant. \n",
    "        Your sole purpose is to write well written, objective and structured reports on given text.'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': f'''Information: \"\"\"{response}\"\"\"\n",
    "        Using the above information, answer the following query: \"\"\"{query}\"\"\" in a detailed report'''\n",
    "    }\n",
    "]\n",
    "\n",
    "lc_messages = convert_openai_messages(prompt)\n",
    "lc_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a86bda9a-4b75-4a77-ace3-ab73a8dfbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Report on the \"Reflection & Critique\" Pattern in Agentic Applications and LangGraph\n",
      "\n",
      "#### Introduction\n",
      "The \"Reflection & Critique\" pattern represents a methodological approach in agentic applications, particularly within the LangGraph framework. This pattern is designed to enhance the performance and adaptability of agents by enabling them to engage in self-evaluation and iterative improvement of their outputs. This report explores the components and implications of this pattern based on the information provided.\n",
      "\n",
      "#### Overview of Reflection & Critique\n",
      "The Reflection & Critique pattern consists of two primary components:\n",
      "\n",
      "1. **Basic Reflection**: \n",
      "   - This involves prompting the agent to reflect on its outputs after executing a task. The agent is encouraged to assess its performance critically, identifying strengths and weaknesses in its responses. This self-evaluation process allows the agent to consider its reasoning and decision-making pathways, ultimately leading to improved future performance.\n",
      "\n",
      "2. **Reflexion**: \n",
      "   - Reflexion goes a step further by focusing on identifying missing or superfluous details in the agent's outputs. This critique process is essential as it provides feedback that can guide the agent's next steps. By refining its understanding of what constitutes relevant and accurate information, the agent can enhance its effectiveness in subsequent interactions.\n",
      "\n",
      "#### Advanced Techniques\n",
      "The Reflection & Critique pattern also incorporates advanced techniques such as:\n",
      "\n",
      "- **Language Agent Tree Search**: \n",
      "   - This technique utilizes reflection and reward mechanisms to perform a tree search across multiple agents. By evaluating different branches of potential outputs, agents can optimize their responses based on learned experiences and rewards received from previous interactions. This approach fosters a dynamic learning environment where agents continually adapt based on performance feedback.\n",
      "\n",
      "- **Self-Discover Agent**: \n",
      "   - This involves agents that are capable of analyzing their own capabilities. By understanding their strengths and limitations, these agents can better navigate complex tasks and make informed decisions about which strategies to employ in various scenarios.\n",
      "\n",
      "#### Application in LangGraph\n",
      "In the context of LangGraph, a framework for building and managing language agents, the Reflection & Critique pattern is integrated into several aspects:\n",
      "\n",
      "- **Agent State Management**: \n",
      "   - The reflection process helps maintain an agent's state by continually updating it based on recent experiences and critiques. This ensures that agents are always operating with the most relevant information and capabilities.\n",
      "\n",
      "- **Nodes and Edges**: \n",
      "   - The structure of LangGraph, which includes nodes (representing agents or tasks) and edges (representing connections or relationships), benefits from the iterative improvements made possible by the Reflection & Critique pattern. As agents reflect and critique, they can modify their interactions and relationships within the graph, leading to more efficient pathways for information retrieval and processing.\n",
      "\n",
      "#### Summary\n",
      "The \"Reflection & Critique\" pattern is a vital component of agentic applications within the LangGraph framework, promoting self-awareness and continuous improvement among language agents. By employing techniques such as Basic Reflection, Reflexion, Language Agent Tree Search, and Self-Discover Agents, this pattern enhances the agents' capabilities to analyze their performance, refine their outputs, and adapt to new challenges effectively. The integration of these reflective practices into LangGraph not only improves individual agent performance but also strengthens the overall functionality of the system, making it a robust tool for developing intelligent language-based applications. \n",
      "\n",
      "#### References\n",
      "1. Langchain AI Documentation: [Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "2. Langgraph Agentic RAG Documentation: [Langgraph agentic rag](https://langchain-ai.github.io/langgraphjs/tutorials/rag/langgraph_agentic_rag/)\n"
     ]
    }
   ],
   "source": [
    "response = ChatOpenAI(model='gpt-4o-mini').invoke(lc_messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc51455-d484-4adf-b1b7-5c723a064889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
