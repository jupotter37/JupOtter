{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99dfb27c-bf97-422e-ac75-0dcaa25e47b0",
   "metadata": {},
   "source": [
    "<h2 align=center> Topic Modelling with BERTopic B2B Case</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f2255-b9ed-4ff8-b53f-f39ad56b7b2a",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img width=\"1112px\" src='Capture.PNG' />\n",
    "    <p style=\"text-align: center;color:gray\">Figure 1: BERTopic() Topic Modelling</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235b8d8-5e9b-4278-a469-d30ed3a249db",
   "metadata": {},
   "source": [
    "In this notebook, we conduct Topic Modelling on the B2B Use case with the goal of discovering new topics. \n",
    "\n",
    "####  The steps that are followed are: \n",
    "##### 1) Take in input of the different columns in the dataset: `col1`,`col2`,`col3`,and `col4`. \n",
    "##### The `col1` column seems to be the most important column as it contains all the new scraped keywords from the websites. The column `col3` contains the top 5 keywords with the highest similarity from the `col4` column. \n",
    "##### 2) After getting results from all the different columns, the <b>results_df</b> contains the results of each topic varied from -1, 0, ... along with the keywords present in them. This can be used to analyze and discover new topics. \n",
    "##### 3) The results of the topic modelling technique gives us topics from -1 to .... Here the -1 is the topic which the model understood as different, too general thus it categorizes them into this separate topic. \n",
    "             - The keywords in topic -1 are then analyzed to see if they contain any relevant keywords which could be maybe put in other discovered topics or simply thrown away. \n",
    "             - This process is done by firstly using keywords from topic -1 as the input for a new topic modelling and then in case there are new topics generated, we can analyze them.\n",
    "             - Secondly, we can also look at them manually since the count of the keywords are relatively low and would build reassurance and trust in our sets of topics. \n",
    "##### 4) To analyse the topic generated the following steps are followed: \n",
    "    1) We look at the intertopic ditance map, the clusters formed give us a good representation of which topics are similar, and which maybe an outlier.\n",
    "    2) We also find semantically similar topics by using cosine similarity to group topics together.\n",
    "    3) We form several visualizations such as bar graph, top words score for each topic for better clearity.\n",
    "             \n",
    "Evaluation of Topic Modelling: https://highdemandskills.com/topic-model-evaluation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cb8a4-2c7a-492a-9100-ee861bd9306a",
   "metadata": {},
   "source": [
    "### Installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223c65fe-d273-4f69-ab11-eb99a807e738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2851, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2685, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/basecommand.py\", line 209, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/commands/install.py\", line 310, in run\n",
      "    wb.build(autobuilding=True)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/wheel.py\", line 748, in build\n",
      "    self.requirement_set.prepare_files(self.finder)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/req/req_set.py\", line 360, in prepare_files\n",
      "    ignore_dependencies=self.ignore_dependencies))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/req/req_set.py\", line 647, in _prepare_file\n",
      "    set(req_to_install.extras) - set(dist.extras)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2810, in extras\n",
      "    return [dep for dep in self._dep_map if dep]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2853, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2886, in _compute_dependencies\n",
      "    common = frozenset(reqs_for_extra(None))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2883, in reqs_for_extra\n",
      "    if req.marker_fn(override={'extra':extra}):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pip/_vendor/_markerlib/markers.py\", line 113, in marker_fn\n",
      "    return eval(compiled_marker, environment)\n",
      "  File \"<environment marker>\", line 1, in <module>\n",
      "NameError: name 'platform_system' is not defined\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Installing all the dependencies \n",
    "!pip install bertopic[visualization] --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "78fe4d63-50ed-44d4-a45f-d6c7c5ca2043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import openpyxl\n",
    "from copy import deepcopy\n",
    "from bertopic import BERTopic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from scipy import special\n",
    "import plotly.express as px\n",
    "\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e44dc18-28ba-45af-93a1-d37a6878b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================Library Versions=================================\n",
      "Numpy Version: 1.20.0\n",
      "Pandas Version: 1.3.4\n",
      "Plotly Version: 4.14.2\n"
     ]
    }
   ],
   "source": [
    "#Printing the requirements \n",
    "print(\"=======================Library Versions=================================\")\n",
    "print(f'Numpy Version: {np.__version__}')\n",
    "print(f'Pandas Version: {pd.__version__}')\n",
    "print(f'Plotly Version: {py.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913aa82-ee9f-42d5-bcba-673eb8ead2a3",
   "metadata": {},
   "source": [
    "## Loading the Dataset and Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96bc78-4449-44ad-aac8-11e03f33844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df.xlsx')\n",
    "df = df.iloc[: , :5]\n",
    "df = df.rename_axis('Index').reset_index()\n",
    "df.pop('Unnamed: 0')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebcbb0b-b198-40fd-8168-7375b2c6c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_values(dataframe, column):\n",
    "    print(\"============================================Exploratory Data Analysis=====================================================\")\n",
    "    print(f'Shape of the dataframe is {dataframe.shape}')\n",
    "    print()\n",
    "    print(dataframe.info())\n",
    "    print()\n",
    "    wordcloud2 = WordCloud().generate(' '.join(dataframe[column]))\n",
    "    plt.figure(figsize = (10, 8), facecolor = None)\n",
    "    plt.imshow(wordcloud2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34d19f-a6e3-40a1-9a0a-7f397f91387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analysis_values(df,'topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d193940-1199-4fb8-b68f-ae4935397d3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reusable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c295eb3-dd45-4331-a79d-7fcdcdaa21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_val(modelname, topics):\n",
    "    \"\"\"\n",
    "    Input: a) modelname: Name of the BERTopic() model used. \n",
    "           b) topics: The list of topics generated by the model.\n",
    "           \n",
    "    Function: Takes in the input and returns a dictionary with topic names as the keys and the keyword's index values from the df as the values.\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped_topics = {topic: [] for topic in set(topics)}\n",
    "    \n",
    "    for index, topic in enumerate(topics):\n",
    "        grouped_topics[topic].append(index)\n",
    "        \n",
    "    return grouped_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2784e09-7cad-42bf-a16d-7d79976f88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result_df(dictionary, topicsdict):\n",
    "    ''''\n",
    "    Input: a) Dictionary: The dictionary with results of dict of get_topic_val function. It has all the topics as the keys with their respective keywords as the index given by the model.\n",
    "           b) topicsdict: The dictionary with the index of the corresponding keyword row in the dataframe as the key and their string keyword as the value.\n",
    "           \n",
    "    Function: Takes in the inputs, maps the index values of keywords with their actual keyword names and returns a result dataframe.\n",
    "    '''\n",
    "    \n",
    "    key = []\n",
    "    re_keywords = []\n",
    "    val = dictionary.items()\n",
    "    \n",
    "    for i, value in val:\n",
    "        key.append(i)\n",
    "        val = [*map(topicsdict.get, value)]\n",
    "        re_keywords.append(val)\n",
    "        \n",
    "    new_dict = {k: v for k, v in zip(key, re_keywords)}\n",
    "    result_df = pd.DataFrame(new_dict.items(), columns = ['Topic Nr','Present_Input_Keywords'])\n",
    "    result_df = result_df.rename_axis('Index').reset_index()\n",
    "    \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73e4e84-c1eb-4fbf-9167-c911887bb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representativedocs(model, topics, docs, keywords):\n",
    "    \"\"\"\n",
    "    Input: a) Model: Name of the model you want the results for.\n",
    "           b) topics: topics extracted by the model\n",
    "           c) docs: documents given as the input to the model. This is the different topic names that the model suggests. (Top n)\n",
    "           d) Keywords: the input keywords given to the model\n",
    "    \n",
    "    Function: Takes in all the inputs and extracts the representative documents per topic.\n",
    "    \"\"\"\n",
    "    model.get_topic_info()\n",
    "    \n",
    "    #extracting the topic names/numbers \n",
    "    top_names = model.topic_names\n",
    "    top_names = pd.DataFrame(top_names.items(), columns = [topics,docs])\n",
    "    \n",
    "    #extracting representative docs for all the topics \n",
    "    rep_docs = model.representative_docs\n",
    "    rep_docs = pd.DataFrame(rep_docs.items(), columns = [topics, keywords])\n",
    "    \n",
    "    #get topics with probability \n",
    "    top_proba = model.get_topics()\n",
    "    \n",
    "    output = pd.merge(top_names, \n",
    "                rep_docs, \n",
    "                how='left', \n",
    "                left_on='topic_num', \n",
    "                right_on='topic_num')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ad40f39-fce8-4d12-a153-d3d8aa903f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similarity_score(model,topicnr,resultdf, threshold):\n",
    "    '''\n",
    "    Parameters: \n",
    "        Inputs: a) model: the model used to train your topic modelling\n",
    "                b) topicnr: the topic for which you want to see the similarity score. IMP: here the nr is the index of the row and not the topic nr so for topic -1 = topicnr is 0\n",
    "                c) resultdf: the resultant df to merge to get combined results \n",
    "                d) threshold: the threshold above which you want to get similar topics\n",
    "        Ouput: A pandas dataframe with topicnr, topic names, keywords present (input) and the distance score for each. \n",
    "    '''\n",
    "    \n",
    "    if model.topic_embeddings is not None:\n",
    "        embeddings = np.array(model.topic_embeddings)\n",
    "    else:\n",
    "        embeddings = model.c_tf_idf\n",
    "        \n",
    "    distance_matrix = cosine_similarity(embeddings)\n",
    "    data = distance_matrix[topicnr]\n",
    "    score_df = pd.DataFrame(data = data, columns = {'similarity_score'})\n",
    "    score_df = score_df.rename_axis('Index').reset_index()\n",
    "\n",
    "    #merging score with resultant dataframe\n",
    "    df = pd.merge(score_df, resultdf, on = 'Index')\n",
    "    \n",
    "    df = df[df['similarity_score'] >= threshold]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e159392b-2153-45d5-904a-2cc59a91ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_dataframe(model, representdocsdf):\n",
    "    \"\"\"\n",
    "    Inputs: a) Model: name of the model\n",
    "            b) dataframe1: This is the dataframe formed including the topics and their top n topic names for each\n",
    "            c) representdocsdf: This is the resultant dataframe of the representative docs function\n",
    "            \n",
    "            \n",
    "    Function: Returns the resultant dataframe with topic number, their top n names with c-tf-idf scores and all the keywords they contain. \n",
    "    \"\"\"\n",
    "    dataframe1 = pd.DataFrame(model.topics.items(), columns = ['Topic Nr', 'Possible Topic Names'])\n",
    "    finaldfname = pd.merge(dataframe1, representdocsdf)\n",
    "    \n",
    "    return finaldfname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "640970b6-1b1e-46af-a09a-bca8556d320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_class_similarity_score(model):\n",
    "    '''\n",
    "    Parameters: \n",
    "        Inputs: a) model: the model used to train your topic modelling\n",
    "                b) topicnr: the topic for which you want to see the similarity score. IMP: here the nr is the index of the row and not the topic nr so for topic -1 = topicnr is 0\n",
    "                c) resultdf: the resultant df to merge to get combined results \n",
    "                d) threshold: the threshold above which you want to get similar topics\n",
    "        Ouput: A pandas dataframe with topicnr, topic names, keywords present (input) and the distance score for each. \n",
    "    '''\n",
    "    \n",
    "    topics = sorted(list(model.get_topics().keys()))\n",
    "\n",
    "    # Extract topic words and their frequencies\n",
    "    topic_list = sorted(topics)\n",
    "    \n",
    "    embeddings = model.c_tf_idf\n",
    "    distance_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    most_similar_ind = []\n",
    "    most_similar_val = [] \n",
    "\n",
    "    for topic in topic_list:\n",
    "        data = distance_matrix[topic] #topic -1\n",
    "        i = np.argsort(data, axis=0)[-2] \n",
    "        most_similar_ind.append(i)   #ensure length and order for the list \n",
    "        most_similar_val.append(data[i])\n",
    "                 \n",
    "    similar_df = pd.DataFrame()\n",
    "    similar_df['Topic Nr'] = topic_list\n",
    "    similar_df['most_similar'] =  most_similar_ind\n",
    "    similar_df['c_similarity_score'] = most_similar_val\n",
    "    similar_df = similar_df.rename_axis('Index').reset_index()\n",
    "    return similar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1d3de5a-10c3-4e32-93ec-4747585afc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from typing import List\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def intertopic_distance(topic_model,topics):\n",
    "# Select topics based on top_n and topics args\n",
    "    if topics is not None:\n",
    "        topics = list(topics)\n",
    "    elif top_n_topics is not None:\n",
    "        topics = sorted(topic_model.get_topic_freq().Topic.to_list()[1:top_n_topics + 1])\n",
    "    else:\n",
    "        topics = sorted(list(topic_model.get_topics().keys()))\n",
    "\n",
    "    # Extract topic words and their frequencies\n",
    "    topic_list = sorted(topics)\n",
    "    frequencies = [topic_model.topic_sizes[topic] for topic in topic_list]\n",
    "    words = [\" | \".join([word[0] for word in topic_model.get_topic(topic)[:5]]) for topic in topic_list]\n",
    "\n",
    "    # Embed c-TF-IDF into 2D\n",
    "    all_topics = sorted(list(topic_model.get_topics().keys()))\n",
    "    indices = np.array([all_topics.index(topic) for topic in topics])\n",
    "    embeddings = topic_model.c_tf_idf.toarray()[indices]\n",
    "    embeddings = MinMaxScaler().fit_transform(embeddings)\n",
    "    embeddings = UMAP(n_neighbors=2, n_components=2, metric='hellinger').fit_transform(embeddings)\n",
    "    \n",
    "    print(embeddings)\n",
    "\n",
    "    # Dataframe containing the values\n",
    "    df = pd.DataFrame({\"x\": embeddings[1:, 0], \"y\": embeddings[1:, 1],\n",
    "                       \"Topic\": topic_list[1:], \"Words\": words[1:], \"Size\": frequencies[1:]})\n",
    "    \n",
    "    # Prepare figure range\n",
    "    #narrowing down the size of the fig\n",
    "    #x_range = (df.x.min() - abs((df.x.min()) * .15), df.x.max() + abs((df.x.max()) * .15))\n",
    "    #y_range = (df.y.min() - abs((df.y.min()) * .15), df.y.max() + abs((df.y.max()) * .15))\n",
    "    \n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3a38c-5f46-4e42-b472-6a2c3ad4e77a",
   "metadata": {},
   "source": [
    "## `Use Case 0`: Trying on the <i>col1</i>  Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea5a25-234e-40bb-9e8f-d2e79b3a537a",
   "metadata": {},
   "source": [
    "The default embedding model for english is `all-MiniLM-L6-v2`. While for multi-lingual it is `paraphrase-multilingual-MiniLM-L12-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137d884-4531-4d96-9c66-1d7b38445de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df.loc[:,'col1'].values)\n",
    "print(docs[:5])\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267c180-4be8-4b15-afde-c08fd05d9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = BERTopic(embedding_model = 'sentence-transformers/LaBSE', language=\"multilingual\",calculate_probabilities=True,verbose=True)\n",
    "topics, probs = model_0.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae03493-357f-4a19-8b1b-7b21da08e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_topics_freq_0 = model_0.get_topic_info()\n",
    "\n",
    "fig = px.bar(input_topics_freq_0,x='Topic',y='Count', title = 'Distribution of Input Topic Generated')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720697f5-b8b9-4bd7-8864-120010746ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.visualize_barchart(topics = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd91f0a-adbd-4747-b2ce-9b61360c5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_dict = dict(zip(df.Index, df.col1))\n",
    "grouped_topics = get_topic_val(model_0, topics)\n",
    "res_df = make_result_df(grouped_topics,most_similar_dict)\n",
    "result_df = make_final_dataframe(model_0,res_df)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261d7ac-6c09-4548-bf01-5e7dd5a46a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity_score(model_0, 1, result_df, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743740c4-e6ed-4d44-8efd-c05277b98989",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Present_Input_Keywords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb91ea-0b75-4ddb-8377-b6ab4b194f80",
   "metadata": {},
   "source": [
    "`get_topic()`: Return top n words for a specific topic and their c-TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613215ed-87d4-41c9-a9ad-8a7793350deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.get_topic(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954edcf-fb23-4add-bc91-88e57509b119",
   "metadata": {},
   "source": [
    "Looking at the top words in the topic -1 by making a wordclous of all the keywords as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757eca71-5f83-4aa1-b8f9-705f68774651",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = result_df['Present_Input_Keywords'][1]\n",
    "\n",
    "from collections import Counter\n",
    "word_could_dict=Counter(my_list)\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate_from_frequencies(word_could_dict)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c254da7-62c8-4a28-a21a-0174fd9ef0b2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81308a-77ce-4bd1-a437-8af33433a5ce",
   "metadata": {},
   "source": [
    "## `Use Case 1`: Trying on the <i>col2</i> column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e522a9-b950-4785-aef6-1ad0facf6241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = list(df.loc[:,'col2'].values)\n",
    "print(docs[:5])\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd50b6-2ac0-4c57-9e05-e6716c174948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = BERTopic(embedding_model = 'paraphrase-multilingual-mpnet-base-v2',language=\"multilingual\",calculate_probabilities=True,verbose=True)\n",
    "topics, probs = model_1.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a97c12-157b-4889-8317-cff6b80be49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_topics_freq = model_1.get_topic_info()\n",
    "fig = px.bar(input_topics_freq,x='Topic',y='Count', title = 'Distribution of Input ''col2'' Topic Generated')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf66fc1-a338-4bcc-8ccc-902824a611d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.visualize_barchart(topics = [-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077695dc-2edb-4c64-a5e0-3a3fce44087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary of the topics and their corresponding keywords\n",
    "df_col2_dict = dict(zip(df.Index, df.col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afa4db-f221-4b5a-9648-3956a6626ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_val = get_topic_val(model_1, topics)\n",
    "res = make_result_df(grouped_val,df_col2_dict)\n",
    "result_df = make_final_dataframe(model_1, res) \n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f9c7f-b60f-4f54-b67e-19e057aa1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity_score(model_1, 1, result_df, 0.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faf96f-b2db-4937-8bac-c45e44c75fa3",
   "metadata": {},
   "source": [
    "The `result_df` above is the result dataframe for the column col2. Here, the column `Possible Topic Names` represents the possible topic names with their c-td-idf scores and the column `Present_Input_Keywords` contains all the keywords that were the input to the model and were combined together to form a new topic. \n",
    "\n",
    "The analysis of the above dataframe can be done by looking at the list of the keywords from the `Present_Input_Keywords` and then looking at the top 10 topic names the model assigns them by using the <b>.get_topic()</b> function. Then, by analyzing which keywords are combined together correctly and has an appropriate topic name (as suggested by the model), we can assign topic names to them and discover new relevant topics. For better visualization, we can also have a look at the similarity matrix and the word scores for each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520fc06-d336-477a-ad1f-f6f7813f0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.get_topic(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576ac2c-5ca1-41b2-8869-802c8fa74684",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe3b30-c415-4364-a7f2-0c50c668815f",
   "metadata": {},
   "source": [
    "## `Use Case 02`: Trying on the <i>col3</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f0d10-8a02-4e13-9ce7-ed1c0a1fc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the '' from string set values\n",
    "df['col3'] = df.col3.apply(lambda x: literal_eval(str(x)))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60f38e-ab8f-4f49-bcf6-4e4776782dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the new topics column and explode each topic into a new row and add it into a pd Dataframe\n",
    "newdf = df['col3']\n",
    "topics = newdf.explode('col3')\n",
    "topics_df = pd.DataFrame(topics)\n",
    "topics_df = topics_df.rename_axis('Index').reset_index()\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044b074-5842-4bfe-93ba-212026d94d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary of the topics and their corresponding keywords\n",
    "topics_dict = dict(zip(topics_df.Index, topics_df.col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7a265-427b-47a6-9aee-1278c81aa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(topics_df.loc[:,'col3'].values)\n",
    "\n",
    "model_02 = BERTopic(embedding_model = \"sentence-transformers/LaBSE\",language=\"multilingual\",calculate_probabilities=True,verbose=True,n_gram_range=(1, 2), nr_topics = 'auto')\n",
    "topics, probs = model_02.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76c8e4-78ac-46b1-8c4f-3bf5dd89e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = model_02.get_topic_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775faccf-6cc6-4480-bc9b-82cf1bfd953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(new_topics,x='Topic',y='Count', title = 'Distribution of Topic Generated Use Case 02')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b695243-b1bc-4c8c-85e8-1fe0d452e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel\n",
    "result_df.to_csv('b2b_results_keywords', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe7e52-01c2-4e8e-8b1b-d2a8c3a7dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = model_02.visualize_topics()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282575d-11b9-4d07-b4d2-c31f04f913d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02.visualize_heatmap(n_clusters = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e2659-507c-43a5-a5d6-0436f3ffaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02.visualize_barchart(topics = [-1,0,1,2,3,105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49ca2b-5b17-4633-a345-1d3878c6d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_2['Present_Input_Keywords'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032608ef-1215-48f7-8d71-b8ed69fe5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_2['Present_Input_Keywords'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b26ac1-c324-4c2a-bfd9-3ea9c5ea6354",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a05cff-5079-4e4a-8692-ae533a6ea0c6",
   "metadata": {},
   "source": [
    "## Analysing the not classified keywords i.e. `Topic -1` from the <b>topics</b> column. \n",
    "\n",
    "Since, there are about 545 keywords which were not put into the specific topics from the keywords from the topics column. We will be using those as an input to the bert model to see if the model finds any new topics within them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a793b9c-4556-40bf-8545-a23aabe501d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_classified = result_df['Present_Input_Keywords'][0]\n",
    "not_classified_df = pd.DataFrame(not_classified, columns = {'not_classified'})\n",
    "not_classified_df = not_classified_df.rename_axis('Index').reset_index()\n",
    "\n",
    "not_classified_topics_dict = dict(zip(not_classified_df.Index, not_classified_df.not_classified))\n",
    "not_classified_df.to_csv('not_classified_topics_col', sep='\\t', encoding='utf-8')\n",
    "not_classified = list(not_classified_df['not_classified'])\n",
    "print(not_classified[:7])\n",
    "print(len(not_classified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c0e67-169e-40d1-8644-9582d407bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_classified_model = BERTopic(embedding_model = \"sentence-transformers/LaBSE\",language=\"multilingual\",calculate_probabilities=True,verbose=True, nr_topics = 'auto')\n",
    "topics, probs = not_classified_model.fit_transform(not_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae787fd-c2c3-4478-b8ef-8cb98c851e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_formed = not_classified_model.get_topic_freq()\n",
    "fig = px.bar(topics_formed,x='Topic',y='Count', title = 'Distribution of Topic Generated by Topic -1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50235796-2f49-4af7-a9d7-8528b3a6d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_classified_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e9a52-3c49-439f-9dae-d784991063a7",
   "metadata": {},
   "source": [
    "### Let's look at the `topic 3 ` and `topic 0` for investigating if they actually are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcffc9-3bcc-496a-9e7a-724ab8acc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = get_topic_val(not_classified_model, topics)\n",
    "r_top = make_result_df(all_topics,not_classified_topics_dict)\n",
    "result_df = make_final_dataframe(not_classified_model, r_top)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74d113-3590-4eb0-bd8b-2eb2a68500d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Topic number 3 keywords\n",
    "result_df['Present_Input_Keywords'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66ac8f-2c0d-434c-b502-965c15315a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_classified_model.get_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755430c0-7a4e-4dd7-b323-8fb6884ce72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic number 0 keywords\n",
    "result_df['Present_Input_Keywords'][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb458a6-aaa7-44dc-9c60-d864fd8d6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_classified_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c8fea-4332-4bd3-86a8-91b692cc6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity_score(not_classified_model, 3, result_df, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ef9cd-aa79-41c8-8166-f68fa0bc5fb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc4bb1-50a1-410c-91b5-7102b5b9e4f9",
   "metadata": {},
   "source": [
    "## `Use Case 03`: Trying on the <i>col4</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d5dcb-7783-4f39-8130-b8687a88216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the '' from string set values\n",
    "df['col4'] = df.topic_selection.apply(lambda x: literal_eval(str(x)))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b270d-087c-4daa-90bb-3b2cf3bee583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the new topics column and explode each topic into a new row and add it into a pd Dataframe\n",
    "df2 = df['col4']\n",
    "#df2.loc[0] = np.array(['français'])\n",
    "topics2 = df2.explode('col4')\n",
    "topics2 = pd.DataFrame(topics2)\n",
    "topics2.iloc[0] = np.array(['français'])\n",
    "topics2 = topics2.rename_axis('Index').reset_index()\n",
    "topics2.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a10d99-9d24-4591-a865-ef3f971402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary of the topics and their corresponding keywords\n",
    "topics_dict_03 = dict(zip(topics2.Index, topics2.col4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8722a-0dd8-4c74-8c31-997173a8d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_2 = list(topics2['col4'])\n",
    "docs_2[:2]\n",
    "print(len(docs_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7a077-2e5e-4c77-a85b-a354a18f6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = BERTopic(embedding_model = \"sentence-transformers/LaBSE\",language=\"multilingual\",calculate_probabilities=True,verbose=True,n_gram_range=(1, 2), nr_topics = 'auto')\n",
    "topics, probs = model_3.fit_transform(docs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37590a-a311-42cc-92af-f0cda7c6019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_freq_3_use = model_3.get_topic_freq()\n",
    "topics_freq_3_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6e38f-d088-4760-9d5e-f78eb03272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(topics_freq_3_use,x='Topic',y='Count', title = 'Distribution of Topic Generated UseCase 03')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87f67c-bc64-48e7-9f88-c2648d31a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.visualize_barchart(topics = [-1,0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f1c4a-3a7c-4512-9ef4-05cf4257961b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_3.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c8d0e-a47a-42ac-b3b4-3ab60dbdf0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = get_topic_val(model_3, topics)\n",
    "r_top = make_result_df(all_topics,topics_dict_03)\n",
    "result_df = make_final_dataframe(model_3, r_top)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0221d-3bca-4763-9dcd-48344ed9f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('topics_selection_res', sep = '\\t', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46c35c-65b8-44f4-8671-06435bda458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Present_Input_Keywords'][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d31414-b2be-46b0-b902-d50490baa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.get_topic(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ffb8-6440-40ff-a1a1-643e9d119222",
   "metadata": {},
   "source": [
    "By looking at the topic 0 all the keywords in it, we can see that the topic could be about gaining consultancy but also getting some info about topic name possible. Which can be seen in the model's predicted names as well containing string, keyword as the possible topic names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b094b6-475a-443f-8d1d-82e7f253cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the similar topics using cosine similarity\n",
    "get_similarity_score(model_3, 1, result_df, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5ba03-47fe-4011-a115-2cbbb0815199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388542d4-cbec-4098-b6d1-ccb16e8e1a2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finding Similar Topics\n",
    "###  UMAP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04eb0f-e122-4641-9492-6e69941d950e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intertopic_distance = intertopic_distance(model_02,topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb59810-0107-45e7-bb90-ed93cc7cd725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intertopic_distance = intertopic_distance.groupby('Topic').mean()\n",
    "intertopic_distance = intertopic_distance.rename_axis('Topic Nr').reset_index()\n",
    "#intertopic_distance['centroid'] = intertopic_distance[['x','y']].mean(axis=1)\n",
    "intertopic_distance['diff'] = intertopic_distance.x - intertopic_distance.y\n",
    "intertopic_distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c2383-20f3-4d87-9661-89255c7d2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_topics = get_topic_val(model_02, topics)\n",
    "res_top = make_result_df(grouped_topics,topics_dict)\n",
    "result_df = make_final_dataframe(model_02,res_top)\n",
    "result_df_2 = pd.merge(result_df, intertopic_distance, on = 'Topic Nr')\n",
    "result_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f1971-e872-4cc4-8d20-dbab19a21c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity_score(model_3, 6, result_df, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3c7e5-f20a-4cb8-a9bb-7550de00f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Possible Topic Names'][14][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532082f1-961b-4fca-bfe0-4e2693232bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Possible Topic Names'][22][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818c4ae-666e-4f76-819f-d31574c94d5b",
   "metadata": {},
   "source": [
    "The drawback with using UMAP embeddings for getting similar topics is that since it's a dimension reduction technique, it's distance from the clusters are the best metrics to compare and additionally, new values of x and y are generated after each run of the chunk. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fab19f-d522-47e1-ab76-8c0fbadbcfd0",
   "metadata": {},
   "source": [
    "### C-TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e39df3-6acc-4640-bdf1-b5f4ed6c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = get_class_similarity_score(model_3)\n",
    "c_df = pd.merge(c_df, result_df, on = 'Index')\n",
    "c_df.pop('Topic Nr_y')\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537b935-52ec-4246-8195-54726fa5fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df.sort_values(['c_similarity_score'], ascending=[False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb9b3a-5aab-4960-932d-3895128f21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df['Possible Topic Names'][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60486f-ad6e-4029-82c8-fc0340255e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df['Possible Topic Names'][3][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65bf18c-7590-4f55-83b6-639c6963f027",
   "metadata": {},
   "source": [
    "## Assigning New Keywords to Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed213d6a-476c-4087-9762-2e434a4fb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_keywords = [\"my account\",\"your account\"]\n",
    "assign_new_topics(model_3, input_keywords,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385867c-a0f3-4a04-bc22-d451c34a9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics, similarity = model_3.find_topics(\"your account\", top_n=5); \n",
    "print(similar_topics)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578350cf-3510-40ca-bbdc-d3e64dc14f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f489d-9812-44c0-9a3e-c55152c8bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, similarity = model_3.find_topics(\"我的賬戶\", top_n=5);\n",
    "print(topics)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca63ce5-3bb3-44a8-ac02-171faff1478a",
   "metadata": {},
   "source": [
    "## Save/Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277ecd1-3a74-4d0d-be71-34bf54790b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = model_3\n",
    "topic_model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670eb82-f267-4749-9940-abff3ff0c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "topic_model = BERTopic.load(\"my_model\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
