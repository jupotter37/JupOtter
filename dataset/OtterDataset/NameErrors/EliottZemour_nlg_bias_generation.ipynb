{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from a_inlp import generate_inlp, generate_sentences\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.load(\"data/saved_P/P_gender_test_79.npy\")\n",
    "\n",
    "embedding = model.lm_head.weight.cpu().detach().numpy()\n",
    "embedding_norm = np.array([x / np.linalg.norm(x) for x in embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'temperature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe man is a doctor, the woman\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m generate_sentences(prompt, tokenizer, model, embedding, P, device, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mINLP\u001b[39;49m\u001b[39m\"\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/bias-free-nlg/a_inlp/a_inlp.py:468\u001b[0m, in \u001b[0;36mgenerate_sentences\u001b[0;34m(prompt, tokenizer, model, embedding, P, device, method, alpha)\u001b[0m\n\u001b[1;32m    451\u001b[0m scores \u001b[39m=\u001b[39m postprocess_next_token_scores(\n\u001b[1;32m    452\u001b[0m     model,\n\u001b[1;32m    453\u001b[0m     scores\u001b[39m=\u001b[39mnext_token_logits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m     num_beams\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    464\u001b[0m )\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m do_sample:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Temperature (higher temperature => more likely to sample low probability tokens)\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     \u001b[39mif\u001b[39;00m temperature \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m    469\u001b[0m         scores \u001b[39m=\u001b[39m scores \u001b[39m/\u001b[39m temperature\n\u001b[1;32m    470\u001b[0m     \u001b[39m# Top-p/top-k filtering\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temperature' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = \"The man is a doctor, the woman\"\n",
    "\n",
    "generate_sentences(prompt, tokenizer, model, embedding, P, device, method=\"INLP\", alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The man is a doctor, the woman is\"\n",
    "for k in range(10):\n",
    "    generate_inlp(prompt, tokenizer, model, embedding, P, device, alpha=2.0, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e8cf6c8a0e336b88b8b74ceca74e60238c1300ebcacd360aa408440a347c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
