{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blocked-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "banner-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/example_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quantitative-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['template', 'caption_1', 'caption_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "native-nature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success_kid</td>\n",
       "      <td>Didnt study for a test</td>\n",
       "      <td>still get a higher grade than someone who did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>success_kid</td>\n",
       "      <td>Ate spaghetti with a white shirt on</td>\n",
       "      <td>no stains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>success_kid</td>\n",
       "      <td>New neighbors</td>\n",
       "      <td>Free Wif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awkward_seal</td>\n",
       "      <td>You laugh when your friend says something</td>\n",
       "      <td>He was being serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awkward_seal</td>\n",
       "      <td>took a photo</td>\n",
       "      <td>camera the wrong way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       template                                   caption_1  \\\n",
       "0   success_kid                      Didnt study for a test   \n",
       "1   success_kid         Ate spaghetti with a white shirt on   \n",
       "2   success_kid                               New neighbors   \n",
       "3  awkward_seal   You laugh when your friend says something   \n",
       "4  awkward_seal                                took a photo   \n",
       "\n",
       "                                        caption_2  \n",
       "0   still get a higher grade than someone who did  \n",
       "1                                       no stains  \n",
       "2                                        Free Wif  \n",
       "3                            He was being serious  \n",
       "4                            camera the wrong way  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prostate-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_process_column(row):\n",
    "    return row.caption_1 + '|' + row.caption_2 + '|'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unauthorized-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['txt'] = data.apply(gen_process_column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loved-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_npy(folder, file_name, columns, df):\n",
    "    \"\"\"\n",
    "    Permite crear los archivos de entrenamiento, prueba y validación. \n",
    "    Es necesario definir las columnas que van a ser utilizadas. \n",
    "    \n",
    "    Params\n",
    "    ---------\n",
    "        folder (str):\n",
    "            Ruta donde se van a guardar los archivos.\n",
    "        \n",
    "        file_name (str):\n",
    "            Nombre del archivo de destino.\n",
    "            \n",
    "        columns (list):\n",
    "            Una lista de columnas que contiene la información a exportar\n",
    "            \n",
    "        df (pandas.DataFrame):\n",
    "            Un DataFrame que contenga la información para procesar\n",
    "    \"\"\"\n",
    "    save_path = os.path.join(folder, file_name)\n",
    "    array = df[columns].values\n",
    "    np.save(save_path, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "processed-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npy('../data', 'prueba.npy', columns = ['template', 'txt'], df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "plain-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(os.path.join('../data', 'prueba.npy'), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "herbal-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "label_id_counter = 0\n",
    "for i, row in enumerate(train_data):\n",
    "    template_id = str(row[0]).zfill(12)\n",
    "    text = row[1].lower()\n",
    "    start_index = len(template_id) + 2 + 1 + 2  # template_id, spaces, box_index, spaces\n",
    "    box_index = 0\n",
    "    for j in range(0, len(text)):\n",
    "        char = text[j]\n",
    "        # note: it is critical that the number of spaces plus len(box_index) is >= the convolution width\n",
    "        texts.append(template_id + '  ' + str(box_index) + '  ' + text[0:j])\n",
    "        if char in labels_index:\n",
    "            label_id = labels_index[char]\n",
    "        else:\n",
    "            label_id = label_id_counter\n",
    "            labels_index[char] = label_id\n",
    "            label_id_counter += 1\n",
    "        labels.append(label_id)\n",
    "        if char == '|':\n",
    "            box_index += 1\n",
    "\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "political-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_char_to_int(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            char_counts[char] = char_counts[char] + 1 if char in char_counts else 1\n",
    "    char_counts_sorted = sorted(char_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    char_to_int = {}\n",
    "    for i, row in enumerate(char_counts_sorted):\n",
    "        char_to_int[row[0]] = i + 1\n",
    "    return char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "crucial-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = map_char_to_int(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "proved-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "weird-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(texts, char_to_int):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        sequences.append([char_to_int[char] for char in text])\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "literary-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = texts_to_sequences(texts, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "controlled-costa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_to_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-516bec413640>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-516bec413640>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'char_to_int' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [char_to_int[char] for char in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "colored-novelty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'd': 1,\n",
       " 'i': 2,\n",
       " 'n': 3,\n",
       " 't': 4,\n",
       " 's': 5,\n",
       " 'u': 6,\n",
       " 'y': 7,\n",
       " 'f': 8,\n",
       " 'o': 9,\n",
       " 'r': 10,\n",
       " 'a': 11,\n",
       " 'e': 12,\n",
       " '|': 13,\n",
       " 'l': 14,\n",
       " 'g': 15,\n",
       " 'h': 16,\n",
       " 'm': 17,\n",
       " 'w': 18,\n",
       " 'p': 19,\n",
       " 'b': 20,\n",
       " 'k': 21,\n",
       " 'c': 22,\n",
       " '’': 23}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "written-nursing",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.strings.unicode_split(example_texts, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-miracle",
   "metadata": {},
   "source": [
    "# Codificadores de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "metropolitan-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(os.path.join('../data', 'prueba.npy'), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "absolute-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(\"\".join(data.txt.values.tolist()).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "completed-shore",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-d6ea0e53bdea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0municode_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.strings.unicode_split(texts, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-civilization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
