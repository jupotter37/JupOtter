{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "double-olive",
   "metadata": {},
   "source": [
    "# Pytorch-GRU-LSTM\n",
    "##\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "previous-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "civil-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局参数\n",
    "type_map = {'train':0, 'val':1, 'test':2}\n",
    "input_path_dir = 'C:/ZhangLI/Codes/DataSet/kdd-cup/'\n",
    "input_path_dir = 'E:/Dataset/kdd/'\n",
    "file_name = 'sdwpf_baidukddcup2022_full.csv'\n",
    "cols = ['Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir', 'Pab1', 'Pab2', 'Pab3', 'Prtv', 'Patv']\n",
    "lable = 'Patv'\n",
    "\n",
    "train_size = 24 * 6 * 153\n",
    "val_size = 24 * 6 * 16\n",
    "test_size = 24 * 6 * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spiritual-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(f'{input_path_dir}{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wicked-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据的类\n",
    "class WPFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Desc: Data\n",
    "        ...\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Desc: \n",
    "        Input: DataSet\n",
    "        \"\"\"\n",
    "        self.data_set = data\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self._start = [0, 153*144-144, 169*144-144]  # [0, 21888, 24192]\n",
    "        self._end = [153*144, 169*144, 184*144]  # [22032, 24336, 26496]\n",
    "        \n",
    "    def get_data(self, flag='train'):\n",
    "        \"\"\"\n",
    "        Desc: \n",
    "        Input: \n",
    "            train: train data\n",
    "            val: val data\n",
    "            test: test data\n",
    "        \"\"\"\n",
    "        if flag == 'train':\n",
    "            clip_start = self._start[type_map[flag]]\n",
    "            clip_end = self._end[type_map[flag]]\n",
    "        elif flag == 'val':\n",
    "            clip_start = self._start[type_map[flag]]\n",
    "            clip_end = self._end[type_map[flag]]\n",
    "        self._data_set = self.data_set[clip_start:clip_end]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "        \n",
    "        \"\"\"\n",
    "        s_begin = index\n",
    "        s_end = index + 30de0  # 使用200个点预测288个点\n",
    "        e_begin = s_end\n",
    "        e_end = s_end + 288\n",
    "        seq_x = self._data_set[s_begin:s_end]\n",
    "        seq_y = self._data_set[e_begin:e_end]\n",
    "        return seq_x, seq_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "        \n",
    "        \"\"\"\n",
    "        #return int((len(self._data_set)-200)/288)\n",
    "        return int(len(self._data_set) - 300 - 288 + 1)  # 数据的长度\n",
    "\n",
    "ds = WPFDataset(data_raw[cols].values) \n",
    "ds.get_data()\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "# WPFDataset[2] 使用索引的方式获取数据时，会自动调用 getitem 方法\n",
    "count = 1\n",
    "for i in dl:\n",
    "    count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinct-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 386\n",
    "int((len(data_raw)-200)/288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "speaking-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Desc: define model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Desc: init class\n",
    "        \"\"\"\n",
    "        super(RnnModel, self).__init__()\n",
    "        self.input_l = 10  # 特征的个数\n",
    "        self.output_l = 288  # 预测的长度\n",
    "        self.hidden_l = 48  # 隐藏层的个数\n",
    "        self.layer_l = 1\n",
    "        \n",
    "        self.lstm = nn.GRU(input_size=self.input_l, hidden_size=self.hidden_l, num_layers=1, batch_first=True, dropout=0.25)\n",
    "        self.fn = nn.Linear(in_features=self.hidden_l, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Desc: forward\n",
    "        Input: x[batch_size, seq_len(time_step), feature_num]\n",
    "            h0[bi*num_layer, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        h0 = Variable(torch.zeros(1, x.size(0), self.hidden_l))\n",
    "        # TODO input and output\n",
    "        h_out, hn = self.lstm(x, h0)  # \n",
    "        # print(h_out.size())\n",
    "        out = self.fn(h_out)\n",
    "        # print(out.size())\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "delayed-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\installsoftware\\python365\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1679, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2071, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1622, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1436, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1703, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1418, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0820, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1388, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0941, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1497, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1474, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0921, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1502, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9b03d4db352b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mtrian_and_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-9b03d4db352b>\u001b[0m in \u001b[0;36mtrian_and_val\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m#print(y.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m288\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 这里有点瞎搞的意思\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m#print(y_.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\zhangli\\software\\installer\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fb52dcd4f664>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# TODO input and output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mh_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;31m# print(h_out.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\zhangli\\software\\installer\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\zhangli\\software\\installer\\python38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    822\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    823\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def trian_and_val():\n",
    "    # 获取模型\n",
    "    model = RnnModel()\n",
    "    # 数据处理，获取数据集\n",
    "    data_raw[cols] = data_raw[cols].fillna(0)\n",
    "    scaler = MinMaxScaler() # 进行实例化\n",
    "    scaler = scaler.fit(data_raw[cols]) # 生成min()和max()\n",
    "    data_tran = scaler.transform(data_raw[cols])\n",
    "    ds = WPFDataset(data_tran)   \n",
    "    dl = DataLoader(ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "    # 定义参数\n",
    "    model_optim = torch.optim.Adam(params=model.parameters())\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # 训练\n",
    "    epoches = 3\n",
    "    for i in range(epoches):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for x, y in dl:\n",
    "            x = x.to(torch.float32)\n",
    "            y = y[:, -288:, -1:].type(torch.float64)\n",
    "            #print(y.size())\n",
    "            \n",
    "            y_ = model(x)\n",
    "            y_ = y_[..., -288:, -1:].type(torch.float64)  # 这里有点瞎搞的意思\n",
    "            #print(y_.size())\n",
    "            loss = criterion(y, y_)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            # model_optim.maximize(loss)\n",
    "            model_optim.step()\n",
    "            model_optim.zero_grad()\n",
    "            # print(loss)\n",
    "        is_debug = True\n",
    "        if is_debug:\n",
    "            train_loss = np.average(train_loss)\n",
    "            epoch_end_time = time.time()\n",
    "            print(\"Epoch: {}, \\nTrain Loss: {}, \\nValidation Loss: {}\".format(i, train_loss, train_loss))\n",
    "            # print(\"Elapsed time for epoch-{}: {}\".format(epoch, epoch_end_time - epoch_start_time))\n",
    "    # 停止训练\n",
    "    # 模型保存\n",
    "# XXDataSet 创建数据类，数据的预测，数据的加载，数据的处理\n",
    "    # getitem  # 这些都是内置的方法\n",
    "    # len\n",
    "    # process\n",
    "    # get_data # 留一个外置接口API就可以了\n",
    "# Models 单纯的定义类\n",
    "    # forward\n",
    "# Experience 创建模型类，定义训练过程 参数，训练，停止 模型保存  [进化成专家的过程]\n",
    "    # seeding\n",
    "    # optim\n",
    "    # critie\n",
    "    # process one \n",
    "    # stop\n",
    "    # save\n",
    "    # get model -- statis\n",
    "# trian and val 每一个模型的真实训练\n",
    "    # train\n",
    "    # val\n",
    "# configs\n",
    "    # -- perpare\n",
    "    # -- consant\n",
    "    # -- \n",
    "# logs\n",
    "# checkpoint\n",
    "# utils\n",
    "# predict\n",
    "trian_and_val()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hidden-audience",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
