{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from analysis_article.true_positive_ratio import true_positive_ratio\n",
    "from analysis_article.paths_importance import paths_importance_analysis\n",
    "from analysis_article.cross_validation_overfitting_iteration import cross_validation\n",
    "from analysis_article.cross_validation_overfitting_iteration import patience_cross_validation\n",
    "from analysis_article.signal_to_noise import signal_to_noise\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:42:01.132297Z",
     "start_time": "2024-08-29T09:41:57.255148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.00847\n",
      "Step number  123\n",
      "[0]\tvalidation_0-rmse:0.01752\n",
      "Step number  103\n",
      "i\n",
      "0\n",
      "Creating a new labels for 5k dataset\n",
      "[0]\tvalidation_0-rmse:0.01359\n",
      "[0]\tvalidation_0-rmse:2.55568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01manalysis_article\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrue_positive_ratio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m true_positive_ratio\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01manalysis_article\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpaths_importance\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m paths_importance_analysis\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01manalysis_article\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcross_validation_overfitting_iteration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_validation\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/analysis_article/../analysis_article/true_positive_ratio.py:149\u001B[0m\n\u001B[1;32m    143\u001B[0m     plot_tpr_vs_iterations_max_min(true_positive_ratio_1, save_fig\u001B[38;5;241m=\u001B[39msave_fig)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# uncomment to use the file as a script\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m \u001B[43mtrue_positive_ratio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber_of_simulations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynthetic_dataset_scenario\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoise_variance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximum_number_of_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_fig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/analysis_article/../analysis_article/true_positive_ratio.py:61\u001B[0m, in \u001B[0;36mtrue_positive_ratio\u001B[0;34m(number_of_simulations, synthetic_dataset_scenario, noise_variance, maximum_number_of_steps, save_fig, show_settings)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# pattern boosting\u001B[39;00m\n\u001B[1;32m     60\u001B[0m pattern_boosting \u001B[38;5;241m=\u001B[39m PatternBoosting()\n\u001B[0;32m---> 61\u001B[0m \u001B[43mpattern_boosting\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m final_test_error \u001B[38;5;241m=\u001B[39m pattern_boosting\u001B[38;5;241m.\u001B[39mtest_error[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     63\u001B[0m final_train_error \u001B[38;5;241m=\u001B[39m pattern_boosting\u001B[38;5;241m.\u001B[39mtrain_error[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/pattern_boosting.py:101\u001B[0m, in \u001B[0;36mPatternBoosting.training\u001B[0;34m(self, training_dataset, test_dataset, global_train_labels_variance)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;66;03m# print(\"size of pattern boosting: \", asizeof.asizeof(self))\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;66;03m# print(\"size of trainig dataset: \", asizeof.asizeof(self.training_dataset))\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iterations \u001B[38;5;241m=\u001B[39m iteration_number \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 101\u001B[0m selected_column_number, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient_boosting_step\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mboosting_matrix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mboosting_matrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mnumber_of_learners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_number\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m test_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXgb_step\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_error\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(test_dataset))\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/gradient_boosting_step.py:34\u001B[0m, in \u001B[0;36mGradientBoostingStep.select_column\u001B[0;34m(self, model, boosting_matrix, labels, number_of_learners)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__step_training_a_whole_new_XGB_model(boosting_matrix, labels, number_of_learners)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m Settings\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXgb_step\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__step_using_xgboost\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mboosting_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelected algorithm not recognized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/gradient_boosting_step.py:41\u001B[0m, in \u001B[0;36mGradientBoostingStep.__step_using_xgboost\u001B[0;34m(self, model, boosting_matrix, labels)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     40\u001B[0m     model \u001B[38;5;241m=\u001B[39m GradientBoostingModel(ModelType\u001B[38;5;241m.\u001B[39mxgb_one_step)\n\u001B[0;32m---> 41\u001B[0m selected_column \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_one_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboosting_matrix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# -------------------------------------------------------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Settings\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/gradient_boosting_model.py:229\u001B[0m, in \u001B[0;36mGradientBoostingModel.fit_one_step\u001B[0;34m(self, boosting_matrix, labels)\u001B[0m\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m selected_column[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 229\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_my\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboosting_matrix\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;66;03m# ----------------------------------------------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# compute the residuals, they should coincide with the residuals of the last model\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \n\u001B[1;32m    234\u001B[0m     \u001B[38;5;66;03m# ----------------------------------------------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m    236\u001B[0m     neg_gradient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__neg_gradient(labels, y_hat)\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/gradient_boosting_model.py:51\u001B[0m, in \u001B[0;36mGradientBoostingModel.predict_my\u001B[0;34m(self, boosting_matrix_matrix)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions_vector\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mis\u001B[39;00m ModelType\u001B[38;5;241m.\u001B[39mxgb_one_step:\n\u001B[0;32m---> 51\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43m[\u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboosting_matrix_matrix\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mmatrix_dimension\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\n\u001B[1;32m     52\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatrix_dimension\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\n\u001B[1;32m     53\u001B[0m \u001B[43m                            \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_learners_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_learners_dimension\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/gradient_boosting_model.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions_vector\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mis\u001B[39;00m ModelType\u001B[38;5;241m.\u001B[39mxgb_one_step:\n\u001B[0;32m---> 51\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboosting_matrix_matrix\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mmatrix_dimension\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m\n\u001B[1;32m     52\u001B[0m                             xgb_model, matrix_dimension \u001B[38;5;129;01min\u001B[39;00m\n\u001B[1;32m     53\u001B[0m                             \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_learners_list, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_learners_dimension)])\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/venv/lib/python3.11/site-packages/xgboost/sklearn.py:1186\u001B[0m, in \u001B[0;36mXGBModel.predict\u001B[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[1;32m   1184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_can_use_inplace_predict():\n\u001B[1;32m   1185\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1186\u001B[0m         predts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace_predict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1187\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1188\u001B[0m \u001B[43m            \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1189\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpredict_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmargin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1194\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m _is_cupy_alike(predts):\n\u001B[1;32m   1195\u001B[0m             \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=import-error\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/venv/lib/python3.11/site-packages/xgboost/core.py:2530\u001B[0m, in \u001B[0;36mBooster.inplace_predict\u001B[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[1;32m   2526\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _ensure_np_dtype\n\u001B[1;32m   2528\u001B[0m     data, _ \u001B[38;5;241m=\u001B[39m _ensure_np_dtype(data, data\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   2529\u001B[0m     _check_call(\n\u001B[0;32m-> 2530\u001B[0m         \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterPredictFromDense\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2531\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2532\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_array_interface\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2533\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2534\u001B[0m \u001B[43m            \u001B[49m\u001B[43mp_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2535\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2536\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdims\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2537\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2538\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2539\u001B[0m     )\n\u001B[1;32m   2540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _prediction_output(shape, dims, preds, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   2541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, PandasTransformed):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the accompanying Jupyter Notebook for our published paper. This interactive notebook is designed to allow you to reproduce the results presented in our study with ease. By following the instructions and running the provided code cells, you can verify the findings and explore the data and methodologies used in our research.\n",
    "\n",
    "Please be aware that due to the computational intensity of some of the analyses, the Jupyter Notebook environment may occasionally encounter difficulties in executing the entire workflow. If you encounter such issues, we have provided a robust alternative to ensure you can still replicate the results.\n",
    "\n",
    "Within the directory of this notebook, locate the function files that the Jupyter Notebook is intended to run. At the end of each of these files, there is a section of commented-out code. This code is identical to what is executed within the Jupyter Notebook. To proceed, simply uncomment this code block and run the file as a standalone script in your preferred Python environment. By doing so, you should be able to achieve the same outputs as those intended within the Jupyter Notebook setup without any compromise in the results.\n",
    "\n",
    "If `save_fig` is True the plots are saved in the folder `analysis_article`.\n",
    "\n",
    "We hope this notebook enhances your understanding of our work, and we encourage you to reach out with any questions or feedback you may have."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to True Positive Ratio Plotting with Synthetic Dataset Analysis\n",
    "\n",
    "In this snipped of code we will be plotting the true positive ratio using a synthetic dataset. Our objective is to gauge the efficacy of an algorithm known for its path selection capabilities.\n",
    "\n",
    "## Parameters Description:\n",
    "\n",
    "- `number_of_simulations` (Default: 200): This parameter controls the number of simulation iterations for the algorithm. To secure a robust measure of algorithm performance, we average the results over these simulations, defaulting to 200 unless adjusted according to user requirements.\n",
    "\n",
    "- `synthetic_dataset_scenario`: Selects the scenario for synthetic dataset generation, each designed to challenge the algorithm in different ways, reflecting various possible real-life conditions.\n",
    "\n",
    "## True Positive Ratio (TPR):\n",
    "The True Positive Ratio is indicative of the algorithm's accuracy, computed each iteration as the number of correct path selections over the total selected paths.\n",
    "\n",
    "## Synthetic Dataset:\n",
    "Through the `synthetic_dataset_scenario` parameter, the user can decide which setting to replicate.\n",
    "\n",
    "\n",
    "## Note on Path Boosting Methodologies:\n",
    "It is important to note the distinction in path boosting methods applied in different scenarios. For scenarios 1 and 2, where only a single metal center is considered, path boosting is employed in its standard form. However, scenario 3 is unique in that it applies cyclic path boosting, taking into account the multiple metal centers that influence the path selection process in more complex ways. This specificity in methodology is crucial to accurately modeling and analyzing each scenario's corresponding dataset.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "true_positive_ratio(number_of_simulations=200, synthetic_dataset_scenario=1, noise_variance=0.2,\n",
    "                    maximum_number_of_steps=None, save_fig=False, show_settings=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:42:07.056452Z",
     "start_time": "2024-08-29T09:42:07.049348Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrue_positive_ratio\u001B[49m(number_of_simulations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, synthetic_dataset_scenario\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, noise_variance\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m      2\u001B[0m                         maximum_number_of_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, save_fig\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, show_settings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'true_positive_ratio' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paths Importance\n",
    "Get paths importance, settings as before, in addition consider the parameter `update_features_importance_by_comparison`, to select the importance measure\n",
    "\n",
    "## Importance measure:\n",
    "If `update_features_importance_by_comparison` is `True` then the importance of each selected column is given by the error improvment of the seclected column compared with the second best choice.\n",
    "If `update_features_importance_by_comparison` is `False` the importance of the selected column is given by the overall error improvment.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths_importance_analysis(\"5k_synthetic_dataset\", number_of_simulations=200, synthetic_dataset_scenario=2,\n",
    "                          noise_variance=0.2, maximum_number_of_steps=None,\n",
    "                          update_features_importance_by_comparison=True, show_settings=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "Performs cross validation to find the optimal `maximum_number_of_steps`.\n",
    "Patience is the number of consecutive steps where increases in the cross validation test error after which we consider the algorithm is overfitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cross_validation(number_of_simulations=15, k_folds=5, scenario=1, patience=3, dataset_name=\"5k_synthetic_dataset\",\n",
    "                 noise_variance=0.2, maximum_number_of_steps=None, save_fig=False, use_wrapper_boosting=None,\n",
    "                 show_settings=True)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cross Validation patience analysis\n",
    "After running cross validation a file containing the test error for the k-fold cross validation is created and here it is possible to study how the selected point for overfitting moves with different `patience`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "patience_cross_validation(\n",
    "    file_path=\"/Users/popcorn/PycharmProjects/pattern_boosting/results/cross_validation/Xgb_step_1800_max_path_length_5_60k_dataset_gbtree_999999/wrapped_boosting/test_errors_cross_validation_list.pkl\",\n",
    "    patience_range=range(5, 100, 5))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Signal to noise ratio\n",
    "`noise_variance_list` is contains the list of the variance of the normal distribution used to generate the noise for the synthetic dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "signal_to_noise(number_of_simulations=200,\n",
    "                noise_variance_list=[0.2, 0.5, 0.8, 1.1, 1.4, 1.7],\n",
    "                # [0.2, 0.325, 0.5, 0.625, 0.75, 0.875, 1, 1.125, 1.25, 1.375, 1.5, 1.625]\n",
    "                synthetic_dataset_scenario=1,\n",
    "                dataset_name=\"5k_synthetic_dataset\", maximum_number_of_steps=None,\n",
    "                save_fig=True, use_wrapper_boosting=None, show_settings=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Path Boosting\n",
    "Here you can run path boosting and obtain the main analysis on the results\n",
    "Since parallelization is needed here, it is not possible to run the algorithm in the jupiter Notebook directly, the following script just launches the file [path_boosting.py](path_boosting.py). To modify the settings go into the file `settings.py` in the main folder. [settings.py](../settings.py). Due to jupiter notebook running environment, parallel processing the set-up for launching the file may result quite complicated in particular for multiprocessing, in this case we suggest to run directly the file [path_boosting.py](path_boosting.py) from the console."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T13:25:34.319559Z",
     "start_time": "2024-08-29T13:22:45.805931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "%run 'path_boosting.py'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU's:  10\n",
      "Dataset name:  5k_synthetic_dataset\n",
      "Creating a new labels for 5k dataset\n",
      "Splitting the dataset\n",
      "Splitting the dataset\n",
      "[0]\tvalidation_0-rmse:3.32264\n",
      "[0]\tvalidation_0-rmse:1.49982[0]\tvalidation_0-rmse:6.46860\n",
      "\n",
      "[0]\tvalidation_0-rmse:1.62534\n",
      "[0]\tvalidation_0-rmse:2.31699\n",
      "[0]\tvalidation_0-rmse:3.97699\n",
      "[0]\tvalidation_0-rmse:2.06944\n",
      "[0]\tvalidation_0-rmse:1.47794\n",
      "[0]\tvalidation_0-rmse:1.80273[0]\tvalidation_0-rmse:1.91690\n",
      "\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "[0]\tvalidation_0-rmse:2.34583\n",
      "computing test error\n",
      "[0]\tvalidation_0-rmse:2.98663\n",
      "[0]\tvalidation_0-rmse:2.68685\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "[0]\tvalidation_0-rmse:2.16601\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "computing test error\n",
      "len final test error 350\n",
      "final test error:\n",
      " 0.71949810277156\n",
      "Saving location:\n",
      "/Users/popcorn/PycharmProjects/pattern_boosting/results/Xgb_step_350_max_path_length_101_5k_synthetic_dataset_gbtree/wrapped_boosting/final_test_error.txt\n",
      "Number of tained models:  14\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/analysis_article/path_boosting.py:90\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m         synthetic_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 90\u001B[0m     analysis \u001B[38;5;241m=\u001B[39m \u001B[43mAnalysisWrapperPatternBoosting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapper_pattern_boosting\u001B[49m\u001B[43m,\u001B[49m\u001B[43msave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_analysis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow_analysis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m     analysis\u001B[38;5;241m.\u001B[39mplot_all_analysis(n\u001B[38;5;241m=\u001B[39mSettings\u001B[38;5;241m.\u001B[39mn_of_paths_importance_plotted, synthetic_dataset\u001B[38;5;241m=\u001B[39msynthetic_dataset)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/analysis_wrapper_pattern_boosting.py:34\u001B[0m, in \u001B[0;36mAnalysisWrapperPatternBoosting.__init__\u001B[0;34m(self, wrapper_pattern_boosting, test_predictions, train_predictions, save, show)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# old method, it works, but it is slow\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# self.train_predictions = self.wrapper_pattern_boosting.predict(self.wrapper_pattern_boosting.test_dataset)\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_predictions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrapper_pattern_boosting\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_test_dataset_parallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_predictions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrapper_pattern_boosting\u001B[38;5;241m.\u001B[39mpredict_train_dataset_parallel()\n",
      "File \u001B[0;32m~/PycharmProjects/pattern_boosting/classes/wrapper_pattern_boosting.py:80\u001B[0m, in \u001B[0;36mWrapperPatternBoosting.predict_test_dataset_parallel\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     77\u001B[0m args_list \u001B[38;5;241m=\u001B[39m [(graph, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_trained_pattern_boosting_models()) \u001B[38;5;28;01mfor\u001B[39;00m graph \u001B[38;5;129;01min\u001B[39;00m graphs_list]\n\u001B[1;32m     79\u001B[0m \u001B[38;5;66;03m# Use multiprocessing Pool to parallelize the task\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_processes\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m pool:\n\u001B[1;32m     81\u001B[0m     results \u001B[38;5;241m=\u001B[39m pool\u001B[38;5;241m.\u001B[39mmap(predict_test_dataset_graph, args_list)\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# Aggregation of results and normalization\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:119\u001B[0m, in \u001B[0;36mBaseContext.Pool\u001B[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m'''Returns a process pool object'''\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pool\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocesses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:215\u001B[0m, in \u001B[0;36mPool.__init__\u001B[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_processes \u001B[38;5;241m=\u001B[39m processes\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_repopulate_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:306\u001B[0m, in \u001B[0;36mPool._repopulate_pool\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_repopulate_pool\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_repopulate_pool_static\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_processes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inqueue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_outqueue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrap_exception\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:329\u001B[0m, in \u001B[0;36mPool._repopulate_pool_static\u001B[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001B[0m\n\u001B[1;32m    327\u001B[0m w\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m w\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcess\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPoolWorker\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    328\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 329\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    330\u001B[0m pool\u001B[38;5;241m.\u001B[39mappend(w)\n\u001B[1;32m    331\u001B[0m util\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madded worker\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:42\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     40\u001B[0m tracker_fd \u001B[38;5;241m=\u001B[39m resource_tracker\u001B[38;5;241m.\u001B[39mgetfd()\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds\u001B[38;5;241m.\u001B[39mappend(tracker_fd)\n\u001B[0;32m---> 42\u001B[0m prep_data \u001B[38;5;241m=\u001B[39m \u001B[43mspawn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_preparation_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m fp \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mBytesIO()\n\u001B[1;32m     44\u001B[0m set_spawning_popen(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py:187\u001B[0m, in \u001B[0;36mget_preparation_data\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001B[39;00m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001B[39;00m\n\u001B[1;32m    186\u001B[0m main_module \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 187\u001B[0m main_mod_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[43mmain_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__spec__\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m main_mod_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minit_main_from_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m main_mod_name\n",
      "\u001B[0;31mAttributeError\u001B[0m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
