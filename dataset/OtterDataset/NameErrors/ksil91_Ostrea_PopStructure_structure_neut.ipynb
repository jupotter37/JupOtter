{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelized *STRUCTURE* analyses on unlinked neutral SNPs\n",
    "\n",
    "Part of the `ipyrad.analysis` toolkit. Here I am taking a structure file creating by the radiator R package from a filtered vcf, which requires a little file formatting. Otherwise it should work with an ipyrad created Structure file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required software\n",
    "You can easily install the required software for this notebook with a locally installed `conda` environment. Just run the commented code below in a terminal. If you are working on an HPC cluster you **do not need** administrator privileges to install the software in this way, since it is only installed locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda install ipyrad -c ipyrad\n",
    "## conda install structure -c ipyrad\n",
    "## conda install clumpp -c ipyrad\n",
    "## conda install toytree -c eaton-lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t.cri.ksilliman/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import ipyrad.analysis as ipa      ## ipyrad analysis toolkit\n",
    "import ipyparallel as ipp          ## parallel processing\n",
    "import toyplot                     ## plotting library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyparallel v.6.1.1\n"
     ]
    }
   ],
   "source": [
    "print \"ipyparallel v.{}\".format(ipp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel cluster setup\n",
    "Start an `ipcluster` instance in a separate terminal. An easy way to do this in a jupyter-notebook running on an HPC cluster is to go to your Jupyter dashboard, and click [new], and then [terminal], and run '`ipcluster start`' in that terminal. This will start a local cluster on the compute node you are connected to. See our [ipyparallel tutorial] (coming soon) for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## ipcluster start --n=24 --profile='n24'\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 'cores')\n"
     ]
    }
   ],
   "source": [
    "## get parallel client\n",
    "ipyclient = ipp.Client(profile=\"n24\")\n",
    "print(len(ipyclient), 'cores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter input and output file locations\n",
    "The `.str` file is a structure formatted file that includes all SNPs present in the data set. Here I needed to do a little file formatting to make it work with the .str file output by radiator. The `.snps.map` file is an optional file that maps which loci each SNP is from. If this file is used then each replicate analysis will *randomly* sample a single SNP from each locus in each rep. The results from many reps therefore will represent variation across unlinked SNP data sets, as well as variation caused by uncertainty. The `workdir` is the location where you want output files to be written and will be created if it does not already exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC2-10-C5\t1\t\t\t\t4\t2\t1\t4\t3\n",
      "BC2-10-C5\t1\t\t\t\t4\t2\t1\t1\t1\n",
      "BC2-11-C5\t1\t\t\t\t-9\t2\t-9\t-9\t3\n",
      "BC2-11-C5\t1\t\t\t\t-9\t2\t-9\t-9\t3\n",
      "BC2-12-C6\t1\t\t\t\t4\t2\t1\t4\t3\n",
      "BC2-12-C6\t1\t\t\t\t4\t2\t1\t1\t3\n",
      "BC2-13-C4\t1\t\t\t\t4\t2\t1\t4\t3\n",
      "BC2-13-C4\t1\t\t\t\t4\t2\t1\t4\t3\n",
      "BC2-16-C6\t1\t\t\t\t4\t2\t1\t4\t3\n",
      "BC2-16-C6\t1\t\t\t\t4\t2\t1\t4\t3\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "sed -r 's/^([^\\t]*\\t[^\\t]*)(.*)$/\\1\\t\\t\\t\\2/' OL-c85t10-x45m75-maf025-neutI2-filt.str | tail -n +2 > OL-c85t10-x45m75-maf025-neutI2-filt_head.str  \n",
    "head OL-c85t10-x45m75-maf025-neutI2-filt_head.str | cut -f 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the structure formatted file\n",
    "strfile = \"./OL-c85t10-x45m75-maf025-neutI2-filt_head.str\"\n",
    "\n",
    "## an optional mapfile, to sample unlinked SNPs\n",
    "mapfile = \"./OL-c85t10-x45m75-maf025-neutI2-filt.snps.map\"\n",
    "\n",
    "## the directory where outfiles should be written\n",
    "workdir = \"./OL_t10x45m75_maf025_neutI2_filt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create mapfile\n",
    "IN = open(\"OL-c85t10-x45m75-maf025-neutI2-filt.str\",\"r\")\n",
    "OUT = open(mapfile,\"w\")\n",
    "loci = IN.readline().strip().split()\n",
    "IN.close()\n",
    "snp = 1\n",
    "span = 1\n",
    "OUT.write(str(span)+\"\\t\"+loci[0]+\"\\t0\\t\"+str(snp)+\"\\n\")\n",
    "\n",
    "for l in range(1,len(loci)):\n",
    "    snp+=1\n",
    "    tag = loci[l].split(\"_\")[1]\n",
    "    if loci[l-1].split(\"_\")[1] != tag:\n",
    "        span += 1\n",
    "    OUT.write(str(span)+\"\\t\"+loci[l]+\"\\t0\\t\"+str(snp)+\"\\n\")\n",
    " \n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6154\tlocus_9983__38__38\t0\t13182\n",
      "6154\tlocus_9983__39__39\t0\t13183\n",
      "6154\tlocus_9983__46__46\t0\t13184\n",
      "6154\tlocus_9983__47__47\t0\t13185\n",
      "6154\tlocus_9983__74__74\t0\t13186\n",
      "6155\tlocus_99894__13__13\t0\t13187\n",
      "6155\tlocus_99894__28__28\t0\t13188\n",
      "6155\tlocus_99894__37__37\t0\t13189\n",
      "6156\tlocus_99918__38__38\t0\t13190\n",
      "6157\tlocus_99985__67__67\t0\t13191\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "tail OL-c85t10-x45m75-maf025-neutI2-filt.snps.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a *Structure* Class object\n",
    "Structure is kind of an old fashioned program that requires creating quite a few input files to run, which makes it not very convenient to use in a programmatic and reproducible way. To work around this we've created a convenience wrapper object to make it easy to submit Structure jobs and to summarize their results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a Structure object\n",
    "structN = ipa.structure(name=\"OL_t10x45m75maf025_neutI2\",\n",
    "                       data=strfile,\n",
    "                       mapfile=mapfile,\n",
    "                       workdir=workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameter options for this object\n",
    "Our Structure object will be used to submit jobs to the cluster. It has associated with it a name, a set of input files, and a large number of parameter settings. You can modify the parameters by setting them like below. You can also use tab-completion to see all of the available options, or print them like below. See the [full structure docs here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&ved=0ahUKEwjt9tjpkszYAhWineAKHZ4-BxAQFgg4MAI&url=https%3A%2F%2Fwww.researchgate.net%2Ffile.PostFileLoader.html%3Fid%3D591c636cdc332d78a46a1948%26assetKey%3DAS%253A495017111953409%25401495032684846&usg=AOvVaw0WjG0uD0MXrs5ResMIHnik) for further details on the function of each parameter. In support of reproducibility, it is good practice to print both the mainparams and extraparams so it is clear which options you used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burnin             50000               \n",
      "extracols          0                   \n",
      "label              1                   \n",
      "locdata            0                   \n",
      "mapdistances       0                   \n",
      "markernames        0                   \n",
      "markovphase        0                   \n",
      "missing            -9                  \n",
      "notambiguous       -999                \n",
      "numreps            200000              \n",
      "onerowperind       0                   \n",
      "phased             0                   \n",
      "phaseinfo          0                   \n",
      "phenotype          0                   \n",
      "ploidy             2                   \n",
      "popdata            1                   \n",
      "popflag            1                   \n",
      "recessivealleles   0                   \n",
      "\n",
      "admburnin           500                 \n",
      "alpha               1.0                 \n",
      "alphamax            10.0                \n",
      "alphapriora         1.0                 \n",
      "alphapriorb         2.0                 \n",
      "alphapropsd         0.025               \n",
      "ancestdist          0                   \n",
      "ancestpint          0.9                 \n",
      "computeprob         1                   \n",
      "echodata            0                   \n",
      "fpriormean          0.01                \n",
      "fpriorsd            0.05                \n",
      "freqscorr           1                   \n",
      "gensback            2                   \n",
      "inferalpha          1                   \n",
      "inferlambda         0                   \n",
      "intermedsave        0                   \n",
      "lambda_             1.0                 \n",
      "linkage             0                   \n",
      "locispop            0                   \n",
      "locprior            0                   \n",
      "locpriorinit        1.0                 \n",
      "log10rmax           1.0                 \n",
      "log10rmin           -4.0                \n",
      "log10rpropsd        0.1                 \n",
      "log10rstart         -2.0                \n",
      "maxlocprior         20.0                \n",
      "metrofreq           10                  \n",
      "migrprior           0.01                \n",
      "noadmix             0                   \n",
      "numboxes            1000                \n",
      "onefst              0                   \n",
      "pfrompopflagonly    0                   \n",
      "popalphas           0                   \n",
      "popspecificlambda   0                   \n",
      "printlambda         1                   \n",
      "printlikes          0                   \n",
      "printnet            1                   \n",
      "printqhat           0                   \n",
      "printqsum           1                   \n",
      "randomize           0                   \n",
      "reporthitrate       0                   \n",
      "seed                12345               \n",
      "sitebysite          0                   \n",
      "startatpopinfo      0                   \n",
      "unifprioralpha      1                   \n",
      "updatefreq          10000               \n",
      "usepopinfo          0                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## set mainparams for object\n",
    "structN.mainparams.burnin = 50000\n",
    "structN.mainparams.numreps = 200000\n",
    "structN.mainparams.popdata = 1\n",
    "structN.mainparams.popflag = 1\n",
    "# I don't want the popflag used as a prior, so set that to zero in the Structure object\n",
    "structN.popflag = [0] * structN.ntaxa\n",
    "## see all mainparams\n",
    "print structN.mainparams\n",
    "\n",
    "## see or set extraparams\n",
    "print structN.extraparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit jobs to run on the cluster\n",
    "The function `run()` distributes jobs to run on the cluster and load-balances the parallel workload. It takes a number of arguments. The first, `kpop`, is the number of populations. The second, `nreps`, is the number of replicated runs to perform. Each rep has a different random seed, and if you entered a mapfile for your Structure object then it will subsample unlinked snps independently in each replicate. The `seed` argument can be used to make the replicate analyses reproducible. The `extraparams.seed` parameter will be generated from this for each replicate. And finally, provide it the `ipyclient` object that we created above. The structure object will store an *asynchronous results object* for each job that is submitted so that we can query whether the jobs are finished yet or not. Using a simple for-loop we'll submit 20 replicate jobs to run at four different values of K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a range of K-values to test\n",
    "tests = [8,7,6,5,4,3,2,1,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-8]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-7]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-6]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-5]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-4]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-3]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-2]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-1]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-9]\n",
      "submitted 5 structure jobs [OL_t10x45m75maf025_neutI2-K-10]\n"
     ]
    }
   ],
   "source": [
    "## submit batches of 5 replicate jobs for each value of K \n",
    "for kpop in tests:\n",
    "    structN.run(\n",
    "        kpop=kpop,  \n",
    "        nreps=5, \n",
    "        seed=12345,\n",
    "        ipyclient=ipyclient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress until finished\n",
    "You can check for finished results by using the `get_clumpp_table()` function, which tries to summarize the finished results files. If no results are ready it will simply print a warning message telling you to wait. If you want the notebook to block/wait until all jobs are finished then execute the `wait()` function of the ipyclient object, like below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>,\n",
       " <AsyncResult: _call_structure:finished>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see submitted jobs (we query first 10 here)\n",
    "structN.asyncs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'struct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b93b4c33ca14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## query a specific job result by index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'struct' is not defined"
     ]
    }
   ],
   "source": [
    "## query a specific job result by index\n",
    "if struct.asyncs[1].ready():\n",
    "    print struct.asyncs[1].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## block/wait until all jobs finished\n",
    "ipyclient.wait() "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
