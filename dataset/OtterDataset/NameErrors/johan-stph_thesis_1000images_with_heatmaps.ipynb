{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/johan-stph/thesis/blob/main/1000images_with_heatmaps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diOD7-Ya3Y6a"
   },
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frF0W5alTm74"
   },
   "outputs": [],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1VFwbwtTt-U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP3Z5JBpT790"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YE4KAkrIT8zv"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 to match the ResNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batchsize = 10\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xCtvxMZUJ8X"
   },
   "source": [
    "### Resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4MSTUDtUBuC"
   },
   "outputs": [],
   "source": [
    "model_resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model_resnet.fc = torch.nn.Linear(2048, 10)  # CIFAR-10 has 10 classes\n",
    "model_resnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mfVLTTWUdj0"
   },
   "outputs": [],
   "source": [
    "target_layers_res = [model_resnet.layer4[-1]]\n",
    "\n",
    "# Initialize Grad-CAM\n",
    "cam_res = GradCAM(model=model_resnet, target_layers=target_layers_res, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKd-GdkrUsAS"
   },
   "source": [
    "### Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2v8yYDEUu91"
   },
   "outputs": [],
   "source": [
    "model_dense = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "model_dense.to(device)\n",
    "model_dense.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onQRMgFMVAiS"
   },
   "outputs": [],
   "source": [
    "target_layers_dense = [model_dense.features.denseblock4.denselayer16]  # Last layer in the last dense block\n",
    "cam_dense = GradCAM(model=model_dense, target_layers=target_layers_dense, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otB83dHEVM5a"
   },
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rEpnHiEVQNb"
   },
   "outputs": [],
   "source": [
    "model_vgg19 = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
    "model_vgg19.to(device)\n",
    "model_vgg19.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sa_GFpiTVVuR"
   },
   "outputs": [],
   "source": [
    "target_layers_vgg19 = [model_vgg19.features[-1]]  # Last convolutional layer\n",
    "cam_vgg19 = GradCAM(model=model_vgg19, target_layers=target_layers_vgg19, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKekJ8jiVj7n"
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzTtlrEVVlfW"
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_combined_heatmaps = []\n",
    "\n",
    "N = 100  # Number of batches to process\n",
    "# batch size = 10 to avoid overflow of GPU memory\n",
    "\n",
    "for batch, (images, labels) in enumerate(trainloader):\n",
    "    if batch > N:\n",
    "        break\n",
    "\n",
    "    targets = [ClassifierOutputTarget(label.item()) for label in labels]\n",
    "    grayscale_cams_vgg19 = cam_vgg19(input_tensor=images, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "    grayscale_cams_dense = cam_dense(input_tensor=images, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "    grayscale_cams_res = cam_res(input_tensor=images, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "\n",
    "    # Combine heatmaps\n",
    "    stacked_heatmaps = np.stack((grayscale_cams_vgg19, grayscale_cams_dense, grayscale_cams_res))\n",
    "    combined_heatmaps = np.max(stacked_heatmaps, axis=0)\n",
    "\n",
    "    # Append to lists\n",
    "    all_images.append(images.cpu().numpy())\n",
    "    all_labels.append(labels.cpu().numpy())\n",
    "    all_combined_heatmaps.append(combined_heatmaps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5pcptEIaQft"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert a sample tensor image to numpy array and denormalize\n",
    "def denormalize(tensor_img):\n",
    "    return ((tensor_img * 0.5) + 0.5).clamp(0, 1).numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Take the first image, label, and heatmap for demonstration\n",
    "sample_image = denormalize(torch.tensor(all_images[0][0]))  # Convert to shape (height, width, channels)\n",
    "sample_label = all_labels[0][0]\n",
    "sample_heatmap = all_combined_heatmaps[0][0]  # Assuming shape (height, width)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "axs[0].imshow(sample_image)\n",
    "axs[0].set_title(f'Original Image - Label: {sample_label}')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Heatmap\n",
    "axs[1].imshow(sample_heatmap, cmap='jet')\n",
    "axs[1].set_title('Combined Heatmap')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1UWHVGub0Vb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "all_images_array = np.array(all_images)\n",
    "all_labels_array = np.array(all_labels)\n",
    "all_combined_heatmaps_array = np.array(all_combined_heatmaps)\n",
    "\n",
    "# Save to disk\n",
    "np.save('all_images.npy', all_images_array)\n",
    "np.save('all_labels.npy', all_labels_array)\n",
    "np.save('all_combined_heatmaps.npy', all_combined_heatmaps_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OlccTjvs0Nq"
   },
   "outputs": [],
   "source": [
    "save_path = '/content/drive/My Drive/bachelorarbeit/cifar10/1000images/'\n",
    "np.save(save_path + 'all_images.npy', all_images_array)\n",
    "np.save(save_path + 'all_labels.npy', all_labels_array)\n",
    "np.save(save_path + 'all_combined_heatmaps.npy', all_combined_heatmaps_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SVQg1F0fpQp"
   },
   "source": [
    "# AB HIER STARTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1kMcPFxf0y7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1zwwhK1nIen"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NquzmWTkcADz"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBimbexAxsUI"
   },
   "outputs": [],
   "source": [
    "load_path = '/content/drive/My Drive/bachelorarbeit/cifar10/1000images/'\n",
    "all_images_array = np.load(load_path + 'all_images.npy')\n",
    "all_labels_array = np.load(load_path + 'all_labels.npy')\n",
    "all_combined_heatmaps_array = np.load(load_path + 'all_combined_heatmaps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p__gLxwx0vg"
   },
   "outputs": [],
   "source": [
    "images_tensor = torch.tensor(all_images_array, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(all_labels_array, dtype=torch.long)\n",
    "heatmaps_tensor = torch.tensor(all_combined_heatmaps_array, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gf5BYyq_OXgN"
   },
   "outputs": [],
   "source": [
    "images_tensor = images_tensor.reshape(-1, 3, 224, 224)\n",
    "images_tensor.shape #torch.Size([1010, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxd6c_pePnrp"
   },
   "outputs": [],
   "source": [
    "labels_tensor = labels_tensor.reshape(-1)\n",
    "labels_tensor.shape #torch.Size([1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7WU9ijfQEDB"
   },
   "outputs": [],
   "source": [
    "heatmaps_tensor = heatmaps_tensor.reshape((-1, 224, 224)).unsqueeze(1)\n",
    "heatmaps_tensor.shape # torch.Size([1010, 1, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOurS9u1sW1n"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to create a Gaussian kernel\n",
    "def create_gaussian_kernel(kernel_size=9, sigma=1.5):\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "\n",
    "    mean = (kernel_size - 1) / 2.\n",
    "    variance = sigma ** 2.\n",
    "\n",
    "    gaussian_kernel = torch.exp(\n",
    "        -torch.sum((xy_grid - mean) ** 2., dim=-1) / (2 * variance)\n",
    "    )\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "    return gaussian_kernel\n",
    "\n",
    "# Create a more aggressive Gaussian kernel\n",
    "gaussian_kernel = create_gaussian_kernel(kernel_size=51, sigma=20.0) \n",
    "gaussian_kernel = gaussian_kernel.view(1, 1, 51, 51) \n",
    "\n",
    "# Apply Gaussian smoothing\n",
    "smoothed_heatmaps = F.conv2d(heatmaps_tensor, gaussian_kernel, padding=25) \n",
    "\n",
    "smoothed_heatmaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmtKhciYd2_v"
   },
   "outputs": [],
   "source": [
    "def denormalize(tensor_img):\n",
    "    return ((tensor_img * 0.5) + 0.5).clamp(0, 1).numpy().transpose(1, 2, 0)\n",
    "\n",
    "sample_image = denormalize(torch.tensor(images_tensor[0]))  # Convert to shape (height, width, channels)\n",
    "sample_label = labels_tensor[0]\n",
    "sample_heatmap = heatmaps_tensor[0].detach().numpy().transpose((1, 2, 0))\n",
    "smoothed_heatmap = smoothed_heatmaps[0].detach().numpy().transpose((1, 2, 0))\n",
    "\n",
    "print(\"Original Heatmap Values:\", sample_heatmap[0:5, 0:5, 0])  \n",
    "print(\"Smoothed Heatmap Values:\", smoothed_heatmap[0:5, 0:5, 0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "# Original image\n",
    "axs[0].imshow(sample_image)\n",
    "axs[0].set_title(f'Original Image - Label: {sample_label}')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Original Heatmap\n",
    "axs[1].imshow((sample_heatmap * 255).astype(np.uint8), cmap='hot')\n",
    "axs[1].set_title('Original Heatmap')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Smoothed Heatmap\n",
    "axs[2].imshow((smoothed_heatmap  * 255).astype(np.uint8), cmap='hot')\n",
    "axs[2].set_title('Smoothed Heatmap')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Difference Heatmap\n",
    "# Calculate the difference\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQAWy9GTLl0e"
   },
   "source": [
    "### Test and Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpzqJRa6RYsv"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images_tensor, labels_tensor, heatmaps_tensor):\n",
    "        self.images = images_tensor\n",
    "        self.labels = labels_tensor\n",
    "        self.heatmaps = heatmaps_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        heatmap = self.heatmaps[idx]\n",
    "\n",
    "        return image, label, heatmap\n",
    "\n",
    "# Create dataset\n",
    "dataset = MyDataset(images_tensor, labels_tensor, smoothed_heatmaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8q_5qurLx7z"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Calculate lengths for train/test split\n",
    "total_len = len(dataset)\n",
    "print(total_len)\n",
    "train_len = int(0.95 * total_len)\n",
    "test_len = total_len - train_len\n",
    "\n",
    "# Perform the split\n",
    "train_dataset, test_dataset = random_split(dataset, [train_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDwReuBmRd14"
   },
   "outputs": [],
   "source": [
    "image_one, label_one, heatmap_one = dataset[0]\n",
    "image_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goOWf-JGLykB"
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRdDfUtyKo4-"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.block(x)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = self.conv_block(in_channels, 64)\n",
    "        self.conv2 = self.conv_block(64, 128)\n",
    "        self.conv3 = self.conv_block(128, 256)\n",
    "        self.conv4 = self.conv_block(256, 512)\n",
    "\n",
    "        # Middle part\n",
    "        self.res_block = ResidualBlock(512, 512)\n",
    "\n",
    "        # Decoder (Transpose Convolution to upsample)\n",
    "        self.deconv1 = self.deconv_block(512, 256)\n",
    "        self.deconv2 = self.deconv_block(256, 128)\n",
    "        self.deconv3 = self.deconv_block(128, 64)\n",
    "        self.deconv4 = self.deconv_block(64, out_channels, last_layer=True)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def deconv_block(self, in_channels, out_channels, last_layer=False):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ]\n",
    "        if last_layer:\n",
    "            layers.append(nn.Sigmoid())\n",
    "        else:\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.res_block(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.deconv4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIaRk31NgPbE"
   },
   "outputs": [],
   "source": [
    "image_one, label_one, heatmap_one = dataset[0]\n",
    "image_one = image_one.unsqueeze(0)\n",
    "print(image_one.shape)\n",
    "\n",
    "test_generator = Generator()\n",
    "test_generator(image_one).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDhGtIEUL_GX"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # More complex model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)  # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, heatmap, img):\n",
    "        heatmap = F.interpolate(heatmap, size=(224, 224))\n",
    "        img_input = torch.cat((img, heatmap), dim=1)  # Concatenate along the channel dimension\n",
    "        return self.model(img_input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "h9e6Z-abizpB",
    "outputId": "91158de5-b241-4fbc-85f0-f4513d91ae6e"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-8df1d0ef8ca0>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Test the Discriminator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheatmap\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m224\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m224\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m224\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m224\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mtest_discriminator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDiscriminator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mheatmap\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mheatmap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the Discriminator\n",
    "image, label, heatmap = torch.randn(3, 224, 224), torch.randn(1), torch.randn(1, 224, 224)\n",
    "test_discriminator = Discriminator()\n",
    "image = image.unsqueeze(0)\n",
    "heatmap = heatmap.unsqueeze(0)\n",
    "print(\"Input Heatmap Shape:\", heatmap.shape)  # [1, 1, 224, 224]\n",
    "print(\"Input Image Shape:\", image.shape)  # [1, 3, 224, 224]\n",
    "output = test_discriminator(heatmap, image)\n",
    "print(\"Output Shape:\", output.shape)  # Output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-PfXPxwhuIm"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, generator, discriminator, optim_g, optim_d, loss_fn, device, epochs, display_images=5):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Initialize lists to store losses\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "            image, heatmap = image.to(device), heatmap.to(device)\n",
    "\n",
    "            # Generate color images from grayscale images\n",
    "            generated_images = generator(image)\n",
    "\n",
    "            # Compute loss for discriminator\n",
    "            real_output = discriminator(heatmap, image)\n",
    "            fake_output = discriminator(generated_images.detach(), image)\n",
    "\n",
    "            real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "            fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "            discriminator_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            optim_d.zero_grad()\n",
    "            discriminator_loss.backward()\n",
    "            optim_d.step()\n",
    "\n",
    "            # Compute loss for generator\n",
    "            fake_output = discriminator(generated_images, image)\n",
    "            generator_loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "\n",
    "            optim_g.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optim_g.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{len(dataloader)}, Generator Loss: {generator_loss.item()}, Discriminator Loss: {discriminator_loss.item()}\")\n",
    "\n",
    "        # Append losses for this epoch\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        discriminator_losses.append(discriminator_loss.item())\n",
    "\n",
    "        # Visualization after each epoch\n",
    "        image = image.cpu().detach()\n",
    "        generated_images = generated_images.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "        heatmap = heatmap.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "        fig = plt.figure(figsize=(30, 4))\n",
    "        for i in range(display_images):\n",
    "            # Display grayscale input image\n",
    "            ax = fig.add_subplot(3, display_images, i + 1, xticks=[], yticks=[])\n",
    "            ax.imshow(denormalize(image[i]))\n",
    "\n",
    "            # Display generated heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((generated_images[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "            # Display original heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + 2 * display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((heatmap[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the generator and discriminator loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "            plt.plot(generator_losses, label=\"Generator\")\n",
    "            plt.plot(discriminator_losses, label=\"Discriminator\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            torch.save(generator.state_dict(), f'generator_gan_v1_epoch_{epoch+1}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lOmVE82e8Ew"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "lr_disc = 0.0002\n",
    "lr_gener = 0.0002\n",
    "\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lmc6GhTJiAqP"
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "optim_g = torch.optim.Adam(generator.parameters(), lr=lr_gener, betas=betas)\n",
    "optim_d = torch.optim.Adam(discriminator.parameters(), lr=lr_disc, betas=betas)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBolMAdriG0M"
   },
   "outputs": [],
   "source": [
    "train(train_dataloader, generator, discriminator, optim_g, optim_d, loss_fn, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZZmaAm5r4Pk"
   },
   "source": [
    "# train v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlKRY9pZr5bZ"
   },
   "outputs": [],
   "source": [
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "def train_v2(dataloader, generator, discriminator, optim_g, optim_d, loss_fn, device, epochs, display_images=5):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Initialize lists to store losses\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "            image, heatmap = image.to(device), heatmap.to(device)\n",
    "\n",
    "            # Generate heatmaps from images\n",
    "            generated_images = generator(image)\n",
    "\n",
    "            # Compute loss for discriminator\n",
    "            real_output = discriminator(heatmap, image)\n",
    "            fake_output = discriminator(generated_images.detach(), image)\n",
    "\n",
    "            real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "            fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "            discriminator_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            optim_d.zero_grad()\n",
    "            discriminator_loss.backward()\n",
    "            optim_d.step()\n",
    "\n",
    "            # Compute loss for generator\n",
    "            fake_output = discriminator(generated_images, image)\n",
    "            gan_loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "\n",
    "            # Compute MSE loss between the generated and real heatmaps\n",
    "            mse_loss = F.mse_loss(generated_images, heatmap)\n",
    "\n",
    "            # Combine the GAN loss and the MSE loss\n",
    "            lambda_factor = 0.8  # Tune this factor\n",
    "            generator_loss = gan_loss + lambda_factor * mse_loss\n",
    "\n",
    "            optim_g.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optim_g.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{len(dataloader)}, Generator Loss: {generator_loss.item()}, Discriminator Loss: {discriminator_loss.item()}\")\n",
    "\n",
    "        # Append losses for this epoch\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        discriminator_losses.append(discriminator_loss.item())\n",
    "\n",
    "        # Visualization after each epoch\n",
    "        image = image.cpu().detach()\n",
    "        generated_images = generated_images.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "        heatmap = heatmap.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "        fig = plt.figure(figsize=(30, 4))\n",
    "        for i in range(display_images):\n",
    "            # Display grayscale input image\n",
    "            ax = fig.add_subplot(3, display_images, i + 1, xticks=[], yticks=[])\n",
    "            ax.imshow(denormalize(image[i]))\n",
    "\n",
    "            # Display generated heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((generated_images[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "            # Display original heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + 2 * display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((heatmap[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the generator and discriminator loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "            plt.plot(generator_losses, label=\"Generator\")\n",
    "            plt.plot(discriminator_losses, label=\"Discriminator\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            torch.save(generator.state_dict(), f'generator_gan_v2_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yewt3BZAsCWO"
   },
   "outputs": [],
   "source": [
    "generator_v2 = Generator().to(device)\n",
    "discriminator_v2 = Discriminator().to(device)\n",
    "\n",
    "\n",
    "optim_g_v2 = torch.optim.Adam(generator_v2.parameters(), lr=lr_gener, betas=betas)\n",
    "optim_d_v2 = torch.optim.Adam(discriminator_v2.parameters(), lr=lr_disc, betas=betas)\n",
    "\n",
    "\n",
    "train_dataloader_v2 = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IG7IiazUsL7M"
   },
   "outputs": [],
   "source": [
    "train_v2(train_dataloader_v2, generator_v2, discriminator_v2, optim_g_v2, optim_d_v2, loss_fn, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7n0oEdM0LOS"
   },
   "source": [
    "# Gan with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-VDg5600Kuw"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.block(x)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Generator_v2(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=3, out_channels=1):\n",
    "        super(Generator_v2, self).__init__()\n",
    "\n",
    "        # Embedding for class label\n",
    "        self.embedding = nn.Embedding(num_classes, 50)  # 50 is the size of the embedding vector\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = self.conv_block(in_channels + 50, 64)  # Concatenated channel size becomes in_channels + 50\n",
    "        self.conv2 = self.conv_block(64, 128)\n",
    "        self.conv3 = self.conv_block(128, 256)\n",
    "        self.conv4 = self.conv_block(256, 512)\n",
    "\n",
    "        # Middle part\n",
    "        self.res_block = ResidualBlock(512, 512)\n",
    "\n",
    "        # Decoder (Transpose Convolution to upsample)\n",
    "        self.deconv1 = self.deconv_block(512, 256)\n",
    "        self.deconv2 = self.deconv_block(256, 128)\n",
    "        self.deconv3 = self.deconv_block(128, 64)\n",
    "        self.deconv4 = self.deconv_block(64, out_channels, last_layer=True)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def deconv_block(self, in_channels, out_channels, last_layer=False):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ]\n",
    "        if last_layer:\n",
    "            layers.append(nn.Sigmoid())\n",
    "        else:\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        # Embed labels and reshape them to concatenate with images\n",
    "        labels = self.embedding(labels)\n",
    "        labels = labels.view(labels.size(0), 50, 1, 1)\n",
    "        labels = labels.expand(-1, -1, x.size(2), x.size(3))\n",
    "\n",
    "        # Concatenate labels with images\n",
    "        x = torch.cat([x, labels], dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.res_block(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.deconv4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtGHOdQo1zL8"
   },
   "outputs": [],
   "source": [
    "class Discriminator_v2(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=4):\n",
    "        super(Discriminator_v2, self).__init__()\n",
    "\n",
    "        # Embedding for class label\n",
    "        self.embedding = nn.Embedding(num_classes, 50)\n",
    "\n",
    "        # Discriminator model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels + 50, 64, 4, stride=2, padding=1),  # in_channels + 50 due to label embedding\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, heatmap, img, labels):\n",
    "        heatmap = F.interpolate(heatmap, size=(224, 224))  # Resize heatmap to match image size\n",
    "\n",
    "        # Embed labels and reshape to concatenate with images and heatmaps\n",
    "        labels = self.embedding(labels)\n",
    "        labels = labels.view(labels.size(0), 50, 1, 1)\n",
    "        labels = labels.expand(-1, -1, heatmap.size(2), heatmap.size(3))\n",
    "\n",
    "        # Concatenate label embedding, heatmap and image\n",
    "        img_input = torch.cat((img, heatmap, labels), dim=1)  # Concatenate along channel dimension\n",
    "\n",
    "        return self.model(img_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcxnA4NqN-CK"
   },
   "outputs": [],
   "source": [
    "def jaccard_index(heatmap1, heatmap2):\n",
    "    # Convert to binary\n",
    "    heatmap1_binary = (heatmap1 > 0.2).float()\n",
    "    heatmap2_binary = (heatmap2 > 0.2).float()\n",
    "\n",
    "    # Compute Jaccard Index (Intersection over Union)\n",
    "    intersection = torch.sum(heatmap1_binary * heatmap2_binary)\n",
    "    union = torch.sum(heatmap1_binary) + torch.sum(heatmap2_binary) - intersection\n",
    "\n",
    "    IoU = intersection / union\n",
    "    return IoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DA8FcGs_GY8w"
   },
   "outputs": [],
   "source": [
    "mse_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSxwAIoo5JCJ"
   },
   "outputs": [],
   "source": [
    "generator_losses = []\n",
    "\n",
    "discriminator_losses = []\n",
    "jaccard_indices = []\n",
    "\n",
    "def train_v3(dataloader, generator, discriminator, optim_g, optim_d, loss_fn, device, epochs, display_images=5):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Initialize lists to store losses\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "            image, heatmap, label = image.to(device), heatmap.to(device), label.to(device)\n",
    "\n",
    "            # Generate heatmaps from images and labels\n",
    "            generated_images = generator(image, label)\n",
    "\n",
    "            IoU = jaccard_index(generated_images, heatmap)\n",
    "\n",
    "            # Compute loss for discriminator\n",
    "            real_output = discriminator(heatmap, image, label)\n",
    "            fake_output = discriminator(generated_images.detach(), image, label)\n",
    "\n",
    "            real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "            fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "            discriminator_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            optim_d.zero_grad()\n",
    "            discriminator_loss.backward()\n",
    "            optim_d.step()\n",
    "\n",
    "            # Compute loss for generator\n",
    "            fake_output = discriminator(generated_images, image, label)\n",
    "            gan_loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "\n",
    "            # Compute MSE loss between the generated and real heatmaps\n",
    "            mse_loss = F.mse_loss(generated_images, heatmap)\n",
    "            mse_losses.append(mse_loss.item())\n",
    "\n",
    "            # Combine the GAN loss and the MSE loss\n",
    "            lambda_factor = 0.8  # Tune this factor\n",
    "            generator_loss = gan_loss + lambda_factor * mse_loss\n",
    "\n",
    "            optim_g.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optim_g.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{len(dataloader)}, Generator Loss: {generator_loss.item()}, Discriminator Loss: {discriminator_loss.item()}, Jaccard Index: {IoU.item()}\")\n",
    "\n",
    "        # Append losses for this epoch\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        discriminator_losses.append(discriminator_loss.item())\n",
    "        jaccard_indices.append(IoU.item())\n",
    "\n",
    "        # Visualization after each epoch\n",
    "        image = image.cpu().detach()\n",
    "        generated_images = generated_images.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "        heatmap = heatmap.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "        fig = plt.figure(figsize=(30, 4))\n",
    "        for i in range(display_images):\n",
    "            # Display grayscale input image\n",
    "            ax = fig.add_subplot(3, display_images, i + 1, xticks=[], yticks=[])\n",
    "            ax.imshow(denormalize(image[i]))\n",
    "\n",
    "            # Display generated heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((generated_images[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "            # Display original heatmap\n",
    "            ax = fig.add_subplot(3, display_images, i + 1 + 2 * display_images, xticks=[], yticks=[])\n",
    "            ax.imshow((heatmap[i] * 255).astype(np.uint8), cmap='hot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the generator and discriminator loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "            plt.plot(generator_losses, label=\"Generator\")\n",
    "            plt.plot(discriminator_losses, label=\"Discriminator\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            torch.save(generator.state_dict(), f'generator_cgan_loss-0_epoch_{epoch+1}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKSgN6kRHLJb",
    "outputId": "c6a2674d-5e3c-45ed-868e-fc98e90b05a2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(mse_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHupildEGTwY"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "lr_disc = 0.0002\n",
    "lr_gener = 0.0002\n",
    "\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td3eN3uRiedq"
   },
   "outputs": [],
   "source": [
    "generator_v3 = Generator_v2().to(device)\n",
    "discriminator_v3 = Discriminator_v2().to(device)\n",
    "\n",
    "\n",
    "optim_g_v3 = torch.optim.Adam(generator_v3.parameters(), lr=lr_gener, betas=betas)\n",
    "optim_d_v3 = torch.optim.Adam(discriminator_v3.parameters(), lr=lr_disc, betas=betas)\n",
    "\n",
    "\n",
    "train_dataloader_v3 = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhqggaAT6ULB"
   },
   "outputs": [],
   "source": [
    "train_v3(train_dataloader_v3, generator_v3, discriminator_v3, optim_g_v3, optim_d_v3, loss_fn, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABMCcI2ipWmS"
   },
   "source": [
    "## Evaluation of GAN Modell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Storing of generator"
   ],
   "metadata": {
    "id": "DAKpwTnmP9Yk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHi_WQPQpX-E"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_results(dataloader, generator, device, num_images=100):\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "    count = 0\n",
    "\n",
    "    for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Generate heatmaps from images and labels\n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(image) # removed labels\n",
    "\n",
    "        # Move to CPU for visualization\n",
    "        image = image.cpu().detach()\n",
    "        generated_images = generated_images.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "        heatmap = heatmap.cpu().detach().numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Display grayscale input image\n",
    "            ax = fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
    "            ax.imshow(denormalize(image[i]))\n",
    "            ax.set_title(\"Input Image\")\n",
    "\n",
    "            # Display generated heatmap\n",
    "            ax = fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
    "            ax.imshow((generated_images[i] * 255).astype(np.uint8), cmap='hot')\n",
    "            ax.set_title(\"Generated Heatmap\")\n",
    "\n",
    "            # Display original heatmap\n",
    "            ax = fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
    "            ax.imshow((heatmap[i] * 255).astype(np.uint8), cmap='hot')\n",
    "            ax.set_title(\"Original Heatmap\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "def jaccard_index(heatmap1, heatmap2):\n",
    "    # Convert to binary\n",
    "    heatmap1_binary = (heatmap1 > 0.15).float()\n",
    "    heatmap2_binary = (heatmap2 > 0.15).float()\n",
    "\n",
    "    # Compute Jaccard Index (Intersection over Union)\n",
    "    intersection = torch.sum(heatmap1_binary * heatmap2_binary)\n",
    "    union = torch.sum(heatmap1_binary) + torch.sum(heatmap2_binary) - intersection\n",
    "\n",
    "    IoU = intersection / union\n",
    "    return IoU\n"
   ],
   "metadata": {
    "id": "zZkQJ9Pth76F"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_jaccard_gan(dataloader, generator, device, num_images=100):\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "    count = 0\n",
    "    jaccard_sum = 0.0  # Initialize variable to store sum of all Jaccard indices\n",
    "\n",
    "    for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Generate heatmaps from images and labels\n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(image)  # removed labels\n",
    "\n",
    "        # Move to CPU for further computation\n",
    "        generated_images = generated_images.cpu().detach()\n",
    "        heatmap = heatmap.cpu().detach()\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            # Calculate the Jaccard index for each pair of generated and original heatmaps\n",
    "            jaccard = jaccard_index(generated_images[i], heatmap[i])\n",
    "            jaccard_sum += jaccard.item()  # Accumulate Jaccard index\n",
    "            count += 1\n",
    "\n",
    "    average_jaccard = jaccard_sum / num_images  # Compute the average Jaccard index\n",
    "    return average_jaccard\n"
   ],
   "metadata": {
    "id": "WH7Ul1TRhh3w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_jaccard_cgan(dataloader, generator, device, num_images=100):\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "    count = 0\n",
    "    jaccard_sum = 0.0  # Initialize variable to store sum of all Jaccard indices\n",
    "\n",
    "    for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Generate heatmaps from images and labels\n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(image, label)  # removed labels\n",
    "\n",
    "        # Move to CPU for further computation\n",
    "        generated_images = generated_images.cpu().detach()\n",
    "        heatmap = heatmap.cpu().detach()\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            # Calculate the Jaccard index for each pair of generated and original heatmaps\n",
    "            jaccard = jaccard_index(generated_images[i], heatmap[i])\n",
    "            jaccard_sum += jaccard.item()  # Accumulate Jaccard index\n",
    "            count += 1\n",
    "\n",
    "    average_jaccard = jaccard_sum / num_images  # Compute the average Jaccard index\n",
    "    return average_jaccard\n"
   ],
   "metadata": {
    "id": "T6deLOta39yK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_mse_cgan(dataloader, generator, device, num_images=100):\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "    count = 0\n",
    "    jaccard_sum = 0.0  # Initialize variable to store sum of all Jaccard indices\n",
    "\n",
    "    for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Generate heatmaps from images and labels\n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(image, label)  # removed labels\n",
    "\n",
    "        # Move to CPU for further computation\n",
    "        generated_images = generated_images.cpu().detach()\n",
    "        heatmap = heatmap.cpu().detach()\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            # Calculate the Jaccard index for each pair of generated and original heatmaps\n",
    "            jaccard = mse_loss(generated_images[i], heatmap[i])\n",
    "            jaccard_sum += jaccard.item()  # Accumulate Jaccard index\n",
    "            count += 1\n",
    "\n",
    "    average_jaccard = jaccard_sum / num_images  # Compute the average Jaccard index\n",
    "    return average_jaccard"
   ],
   "metadata": {
    "id": "FASgVnOY8ISC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_mse_gan(dataloader, generator, device, num_images=100):\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "    count = 0\n",
    "    jaccard_sum = 0.0  # Initialize variable to store sum of all Jaccard indices\n",
    "\n",
    "    for batch, (image, label, heatmap) in enumerate(dataloader):\n",
    "        if count >= num_images:\n",
    "            break\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Generate heatmaps from images and labels\n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(image)  # removed labels\n",
    "\n",
    "        # Move to CPU for further computation\n",
    "        generated_images = generated_images.cpu().detach()\n",
    "        heatmap = heatmap.cpu().detach()\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            if count >= num_images:\n",
    "                break\n",
    "\n",
    "            # Calculate the Jaccard index for each pair of generated and original heatmaps\n",
    "            jaccard = mse_loss(generated_images[i], heatmap[i])\n",
    "            jaccard_sum += jaccard.item()  # Accumulate Jaccard index\n",
    "            count += 1\n",
    "\n",
    "    average_jaccard = jaccard_sum / num_images  # Compute the average Jaccard index\n",
    "    return average_jaccard"
   ],
   "metadata": {
    "id": "KS017jrw8M0I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load models from gdrive"
   ],
   "metadata": {
    "id": "YGH_ADghBxld"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os"
   ],
   "metadata": {
    "id": "hUWza-TZDOaK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cd \"/content/drive/My Drive/bachelorarbeit/models/\"; ls\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGF8QFmkCKeo",
    "outputId": "a83aa556-b590-403d-bd0b-ffbe702f641d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generator_cgan_epoch_100.pth\t     generator_gan_v1_epoch_100.pth\n",
      "generator_cgan_epoch_20.pth\t     generator_gan_v1_epoch_20.pth\n",
      "generator_cgan_epoch_40.pth\t     generator_gan_v1_epoch_40.pth\n",
      "generator_cgan_epoch_60.pth\t     generator_gan_v1_epoch_60.pth\n",
      "generator_cgan_epoch_80.pth\t     generator_gan_v1_epoch_80.pth\n",
      "generator_cgan_loss-0_epoch_100.pth  generator_gan_v2_epoch_100.pth\n",
      "generator_cgan_loss-0_epoch_20.pth   generator_gan_v2_epoch_20.pth\n",
      "generator_cgan_loss-0_epoch_40.pth   generator_gan_v2_epoch_40.pth\n",
      "generator_cgan_loss-0_epoch_60.pth   generator_gan_v2_epoch_60.pth\n",
      "generator_cgan_loss-0_epoch_80.pth   generator_gan_v2_epoch_80.pth\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "base_path = \"/content/drive/My Drive/bachelorarbeit/models/\""
   ],
   "metadata": {
    "id": "VocxNY4kBw8W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gan_v1_files = [\n",
    "    \"generator_gan_v1_epoch_20.pth\",\n",
    "    \"generator_gan_v1_epoch_40.pth\",\n",
    "    \"generator_gan_v1_epoch_60.pth\",\n",
    "    \"generator_gan_v1_epoch_80.pth\",\n",
    "    \"generator_gan_v1_epoch_100.pth\"\n",
    "]\n",
    "gan_v2_files = [\n",
    "    \"generator_gan_v2_epoch_20.pth\",\n",
    "    \"generator_gan_v2_epoch_40.pth\",\n",
    "    \"generator_gan_v2_epoch_60.pth\",\n",
    "    \"generator_gan_v2_epoch_80.pth\",\n",
    "    \"generator_gan_v2_epoch_100.pth\",\n",
    "]"
   ],
   "metadata": {
    "id": "FLsdMloKDSwH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cgan_v1_files = [\n",
    "    \"generator_cgan_loss-0_epoch_20.pth\",\n",
    "    \"generator_cgan_loss-0_epoch_40.pth\",\n",
    "    \"generator_cgan_loss-0_epoch_60.pth\",\n",
    "    \"generator_cgan_loss-0_epoch_80.pth\",\n",
    "    \"generator_cgan_loss-0_epoch_100.pth\"\n",
    "]\n",
    "cgan_v2_files = [\n",
    "    \"generator_cgan_epoch_20.pth\",\n",
    "    \"generator_cgan_epoch_40.pth\",\n",
    "    \"generator_cgan_epoch_60.pth\",\n",
    "    \"generator_cgan_epoch_80.pth\",\n",
    "    \"generator_cgan_epoch_100.pth\"\n",
    "]"
   ],
   "metadata": {
    "id": "c5fACfebHLa9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gan_v1 = []\n",
    "gan_v2 = []\n",
    "cgan_v1 = []\n",
    "cgan_v2 = []\n",
    "for file_name in gan_v1_files:\n",
    "  file_name = base_path + file_name\n",
    "  gen_model = Generator().to(device)\n",
    "  gen_model.load_state_dict(torch.load(file_name))\n",
    "  gan_v1.append(gen_model)\n",
    "for file_name in gan_v2_files:\n",
    "  file_name = base_path + file_name\n",
    "  gen_model = Generator().to(device)\n",
    "  gen_model.load_state_dict(torch.load(file_name))\n",
    "  gan_v2.append(gen_model)\n",
    "\n",
    "for file_name in cgan_v1_files:\n",
    "  file_name = base_path + file_name\n",
    "  gen_model = Generator_v2().to(device)\n",
    "  gen_model.load_state_dict(torch.load(file_name))\n",
    "  cgan_v1.append(gen_model)\n",
    "for file_name in cgan_v2_files:\n",
    "  file_name = base_path + file_name\n",
    "  gen_model = Generator_v2().to(device)\n",
    "  gen_model.load_state_dict(torch.load(file_name))\n",
    "  cgan_v2.append(gen_model)\n"
   ],
   "metadata": {
    "id": "PWCF3meEDcgB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-uapXavjZCd"
   },
   "outputs": [],
   "source": [
    "your_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vergleich des Jaccard Index der verschiedenen Generation mit jeweils 10 Bildern"
   ],
   "metadata": {
    "id": "rDtyKI89Vfuc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "jaccard_gan_v1 = []\n",
    "mse_loss_gan_v1 = []\n",
    "for generator in gan_v1:\n",
    "  dl = DataLoader(dataset, batch_size = 32, shuffle=False)\n",
    "  jaccard_gan_v1.append(calculate_jaccard_gan(dl, generator, device))\n",
    "  mse_loss_gan_v1.append(calculate_mse_gan(dl, generator, device))\n",
    "print(jaccard_gan_v1)\n",
    "print(mse_loss_gan_v1)"
   ],
   "metadata": {
    "id": "vOOjZgW5VfKJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "jaccard_gan_v2 = []\n",
    "mse_loss_gan_v2 = []\n",
    "for generator in gan_v2:\n",
    "  dl = DataLoader(dataset, batch_size = 32, shuffle=False)\n",
    "  jaccard_gan_v2.append(calculate_jaccard_gan(dl, generator, device))\n",
    "  mse_loss_gan_v2.append(calculate_mse_gan(dl, generator, device))\n",
    "print(jaccard_gan_v2)\n",
    "print(mse_loss_gan_v2)"
   ],
   "metadata": {
    "id": "FYqN3QEo3Gt6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "jaccard_cgan_v1 = []\n",
    "mse_loss_cgan_v1 = []\n",
    "for generator in cgan_v1:\n",
    "  dl = DataLoader(dataset, batch_size = 32, shuffle=False)\n",
    "  jaccard_cgan_v1.append(calculate_jaccard_cgan(dl, generator, device))\n",
    "  mse_loss_cgan_v1.append(calculate_mse_cgan(dl, generator, device))\n",
    "print(jaccard_cgan_v1)\n",
    "print(mse_loss_cgan_v1)"
   ],
   "metadata": {
    "id": "YpDB1Q3U3J9g"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "jaccard_cgan_v2 = []\n",
    "mse_loss_cgan_v2 = []\n",
    "for generator in cgan_v2:\n",
    "  dl = DataLoader(dataset, batch_size = 32, shuffle=False)\n",
    "  jaccard_cgan_v2.append(calculate_jaccard_cgan(dl, generator, device))\n",
    "  mse_loss_cgan_v2.append(calculate_mse_cgan(dl, generator, device))\n",
    "print(jaccard_cgan_v2)\n",
    "print(mse_loss_cgan_v1)"
   ],
   "metadata": {
    "id": "jQkpUMBb3KM1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_label = ['20', '40', '60', '80', '100']\n",
    "\n",
    "# Create the line chart with figsize\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for GAN V1\n",
    "plt.plot(epoch_label, jaccard_gan_v1, marker='o', linestyle='-', label='GAN V1')\n",
    "\n",
    "# Plot for GAN V2\n",
    "plt.plot(epoch_label, jaccard_gan_v2, marker='x', linestyle='--', label='GAN V2')\n",
    "\n",
    "# Plot for CGAN V1\n",
    "plt.plot(epoch_label, jaccard_cgan_v1, marker='s', linestyle='-.', label='CGAN V1')\n",
    "\n",
    "# Plot for CGAN V2\n",
    "plt.plot(epoch_label, jaccard_cgan_v2, marker='d', linestyle=':', label='CGAN V2')\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Jaccard - Index')\n",
    "plt.title('Jaccard - Index for Different GAN and CGAN Versions at Various Epochs')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a legend to differentiate the lines\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "t-APbHfdjgrz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_label = ['20', '40', '60', '80', '100']\n",
    "\n",
    "# Create the line chart with figsize\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for GAN V1\n",
    "plt.plot(epoch_label, mse_loss_gan_v1, marker='o', linestyle='-', label='GAN V1')\n",
    "\n",
    "# Plot for GAN V2\n",
    "plt.plot(epoch_label, mse_loss_gan_v2, marker='x', linestyle='--', label='GAN V2')\n",
    "\n",
    "# Plot for CGAN V1\n",
    "plt.plot(epoch_label, mse_loss_cgan_v1, marker='s', linestyle='-.', label='CGAN V1')\n",
    "\n",
    "# Plot for CGAN V2\n",
    "plt.plot(epoch_label, mse_loss_cgan_v2, marker='d', linestyle=':', label='CGAN V2')\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE - Loss')\n",
    "plt.title('MSE - Loss for Different GAN and CGAN Versions at Various Epochs')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a legend to differentiate the lines\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "5KN-QYrXhCTc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vergleich der 4 besten Methoden auf jeweils 100 Bildern"
   ],
   "metadata": {
    "id": "JVGCyHROVlht"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "xWAE8DG6VVz4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisierung"
   ],
   "metadata": {
    "id": "TXbuzm5OVeLs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for i, gen_model in enumerate(gens):\n",
    "    print(\"Visualizing for one of the generators...\", i + 1)\n",
    "    visualize_results(DataLoader(dataset, batch_size=32, shuffle=False), gen_model, device, num_images=5)"
   ],
   "metadata": {
    "id": "2Tg-TkVqEfxu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "e8zOGkikjYbc",
    "outputId": "6443f1ba-ec26-4d1c-d5a5-4d9167672d32"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-2ff0c7fa009e>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mvisualize_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0myour_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerator_v3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_images\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'generator_v3' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_results(your_dataloader, generator_v3, device, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMqxbBvXRHGULmmKsct1ijn",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
