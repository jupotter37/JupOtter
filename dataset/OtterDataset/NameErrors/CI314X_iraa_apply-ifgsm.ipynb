{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aIhjLR2OoKwN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import torchvision\n",
    "\n",
    "from os.path import join as join_path\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_FOLDER = '/home/jovyan/work/'\n",
    "path = join_path(PATH_TO_FOLDER, 'run_attacks')\n",
    "SAVE_PATH = join_path(PATH_TO_FOLDER, 'run_attacks', 'tmp_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1678645276679,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "F5hvIQhhDib_",
    "outputId": "e41c57f0-3b6c-444b-cc57-553db20267b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BJkjGuL64iM"
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adv(ref, eps, alpha, iters):\n",
    "    image = transforms.ToTensor()(ref)\n",
    "    image = image.unsqueeze_(0)\n",
    "    image = image.to(DEVICE)\n",
    "    p = torch.zeros_like(image).to(DEVICE)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    model = Linearity(DEVICE)\n",
    "\n",
    "    for i in range(iters):\n",
    "        res = image + p\n",
    "        res.data.clamp_(0., 1.)\n",
    "        score = model(res)\n",
    "        print(\"linearity score:\", score.item())\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward() \n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "\n",
    "    res_image = (image).data.clamp_(min=0, max=1)\n",
    "    res_img = (res_image.squeeze().data.cpu().numpy().transpose(1, 2, 0) * 255).astype('uint8')\n",
    "    return res_img\n",
    "\n",
    "# images = sorted(os.listdir('test_ims'))\n",
    "# im = cv2.imread('test_ims/'+images[0])\n",
    "# im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "# eps = 10/255\n",
    "# alpha = 1/255\n",
    "# iters = 10\n",
    "# im = adv(im, eps, alpha, iters)\n",
    "# im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "# os.makedirs('res_fgsm', exist_ok=True)\n",
    "# cv2.imwrite('res_fgsm/'+images[0], im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3pQc5eElocK"
   },
   "source": [
    "# Run IQA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18804,
     "status": "ok",
     "timestamp": 1678645252172,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "uU2FJIwDu37z",
    "outputId": "19f2a011-dbff-4718-f8f2-bcda316bc0a9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10206\n"
     ]
    }
   ],
   "source": [
    "# _type_folder = 'TID2013/distorted_images' # val2017 train2017 test2017\n",
    "\n",
    "_type_folder = 'KADID10K/kadid10k/images'\n",
    "image_type_folder = 'kadid10k'\n",
    "\n",
    "all_images = sorted(glob.glob(join_path(PATH_TO_FOLDER, 'data', _type_folder, '*')))\n",
    "# image_type_folder = f'mscoco_{_type_folder}'\n",
    "# image_type_folder = _type_folder\n",
    "# image_type_folder = 'tid2013'\n",
    "\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_type_folder = 'train2017'\n",
    "\n",
    "# _type_folder = 'KADID10K/kadid10k/images'\n",
    "# image_type_folder = 'kadid10k'\n",
    "\n",
    "all_images = [join_path(PATH_TO_FOLDER, 'data', _type_folder, '000000009898.jpg'), join_path(PATH_TO_FOLDER, 'data', _type_folder, '000000333018.jpg')]\n",
    "image_type_folder = f'mscoco_{_type_folder}'\n",
    "# image_type_folder = _type_folder\n",
    "# image_type_folder = 'tid2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(join_path(PATH_TO_FOLDER, 'data', 'KADID10K', 'images_HackPredictModelV31_padding.csv'))\n",
    "# df['distortion_type'] = df['image_name'].apply(lambda x: int(x.split('_')[1]) if len(x) != 7 else 0)\n",
    "# ims = list(set(df[df['distortion_type'] == 6]['image_name'])) + list(set(df[df['distortion_type'] == 22]['image_name']))\n",
    "# all_images = [join_path(PATH_TO_FOLDER, 'data', 'KADID10K', 'kadid10k', 'images', i) for i in ims]\n",
    "# all_images = sorted(all_images)\n",
    "\n",
    "# image_type_folder = 'kadid10k_only_6_22'\n",
    "\n",
    "# len(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egsXTvs2lvg0",
    "tags": []
   },
   "source": [
    "## Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L2sF6o-PlyN5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import resize, to_tensor, normalize\n",
    "from PIL import Image\n",
    "# import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EegPYDnsl3x6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'metrics', 'Linearity'))\n",
    "from IQAmodel import IQAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gPvG2eNpl8Xp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_32X8D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = IQAModel().to(device)\n",
    "model_path = '/home/jovyan/storage/NR-metric-models/p1q2.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "k = checkpoint['k']\n",
    "b = checkpoint['b']\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1677619233282,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "8L9LEoxjmJER",
    "outputId": "379c6831-63f5-4c9d-f58a-4957bc07b935",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ifgsm_alpha1_eps3_i2_lin_mscoco_train2017.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 3 / 255\n",
    "alpha = 1 / 255\n",
    "iters = 2\n",
    "fname = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}_lin_{image_type_folder}.csv'\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.21416473388672"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images[:1]):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    \n",
    "    image = resize(image, (498, 664))\n",
    "    image = to_tensor(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    p = torch.zeros_like(image).to(DEVICE)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    before_score = 0\n",
    "    for i in range(iters):\n",
    "        image_for_attack = image + p\n",
    "        image_for_attack.data.clamp_(0., 1.)\n",
    "        image_for_attack = normalize(image_for_attack, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        score = model(image_for_attack)[-1]\n",
    "        score = score * k[-1] + b[-1]\n",
    "        if i == 0:\n",
    "            before_score = score.cpu().detach().item()\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward() \n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "        \n",
    "    after_score = score.cpu().detach().item()\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "    \n",
    "    \n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}'\n",
    "df['metric'] = 'lin'\n",
    "\n",
    "x = (gains[:, 1] - gains[:, 0]) # .mean()\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_after_attack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mimage_after_attack\u001b[49m)\u001b[38;5;66;03m#.save('000000333018_attack_fgsm_30.jpg')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_after_attack' is not defined"
     ]
    }
   ],
   "source": [
    "Image.fromarray(image_after_attack)#.save('000000333018_attack_fgsm_30.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(join_path(SAVE_PATH, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSDjjWOjv3--",
    "tags": []
   },
   "source": [
    "## Paq-2-Piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['my_device'] = str(device)\n",
    "\n",
    "os.chdir(join_path(PATH_TO_FOLDER, 'metrics', 'Paq-2-Piq'))\n",
    "from paq2piq_standalone import InferenceModel, RoIPoolModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = InferenceModel(RoIPoolModel().to(device), 'D:\\\\me\\\\iqa_aimasters\\\\metrics\\\\Paq-2-Piq\\\\RoIPoolModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RoIPoolModel()\n",
    "model_path = join_path(PATH_TO_FOLDER, 'metrics', 'Paq-2-Piq', 'RoIPoolModel.pth')\n",
    "model_state = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(model_state[\"model\"])\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2p_transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_v407QJweKZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps = 5 / 255\n",
    "\n",
    "alpha = 2 / 255\n",
    "iters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = p2p_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    model.input_block_rois((20, 20), [image.shape[-2], image.shape[-1]], device=device)\n",
    "    \n",
    "    p = torch.zeros_like(image).to(DEVICE)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    before_score = 0\n",
    "    for i in range(iters):\n",
    "        image_for_attack = image + p\n",
    "        image_for_attack.data.clamp_(0., 1.)\n",
    "        score = model(image_for_attack)[0][0]\n",
    "        if i == 0:\n",
    "            before_score = score.cpu().detach().item()\n",
    "        # print(\"score:\", score.item())\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward() \n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "        \n",
    "    after_score = score.cpu().detach().item()\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('\\\\')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_255_eps{int(eps * 255)}_255_i{iters}'\n",
    "df['metric'] = 'p2p'\n",
    "\n",
    "x = (gains[:, 1] - gains[:, 0]) # .mean()\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}_p2p_{image_type_folder}.csv'\n",
    "df.to_csv(join_path(SAVE_PATH, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d3IAPMS1UTb",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Nima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6gXmOAAxC0S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.chdir('D:\\\\me\\\\iqa_aimasters\\\\metrics\\\\Nima\\\\nima')\n",
    "\n",
    "# from inference.inference_model import InferenceModel\n",
    "\n",
    "# path_to_model_weight = \"D:\\\\me\\\\iqa_aimasters\\\\metrics\\\\Nima\\\\pretrain-model.pth\" \n",
    "# model = InferenceModel(path_to_model=path_to_model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRPgk75C13ja",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eps = 5 / 255\n",
    "\n",
    "# alpha = 2 / 255\n",
    "# iters = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306403,
     "status": "ok",
     "timestamp": 1677619737901,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "XehWQaVQ13mQ",
    "outputId": "701ab3fe-2fdc-4234-ce29-0339eb41ffde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# res = []\n",
    "# gains = []\n",
    "# for image_file in tqdm(all_images):\n",
    "#     im = Image.open(image_file).convert('RGB')\n",
    "#     image = model.transform(im)\n",
    "#     image = image.to(device)\n",
    "#     image = image.unsqueeze(0)\n",
    "    \n",
    "#     p = torch.zeros_like(image).to(DEVICE)\n",
    "#     p = Variable(p, requires_grad=True)\n",
    "#     before_score = 0\n",
    "#     for i in range(iters):\n",
    "#         image_for_attack = image + p\n",
    "#         image_for_attack.data.clamp_(0., 1.)\n",
    "#         prob = model.model(image_for_attack)[0]\n",
    "#         score = (model.const_nima * prob).sum()\n",
    "#         if i == 0:\n",
    "#             before_score = score.cpu().detach().item()\n",
    "#         # print(\"score:\", score.item())\n",
    "#         loss = 1 - score / 100\n",
    "#         loss.backward() \n",
    "#         g = p.grad\n",
    "#         g = torch.sign(g)\n",
    "#         p.data -= alpha * g\n",
    "#         p.data.clamp_(-eps, +eps)\n",
    "#         p.grad.zero_()\n",
    "        \n",
    "#     after_score = score.cpu().detach().item()\n",
    "    \n",
    "#     gains.append([before_score, after_score])\n",
    "#     res.append([image_file.split('\\\\')[-1], before_score, after_score])\n",
    "# gains = np.array(gains)\n",
    "\n",
    "# df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "# df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_255_eps{int(eps * 255)}_255_i{iters}'\n",
    "# df['metric'] = 'nima'\n",
    "\n",
    "# x = (gains[:, 1] - gains[:, 0]) # .mean()\n",
    "# x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fname = f'ifgsm_alpha{int(alpha * 255)}_255_eps{int(eps * 255)}_255_i{iters}_nima_mscoco_val2017'\n",
    "# df.to_csv(join_path(PATH_TO_FOLDER, 'results', f'{fname}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3Aoflsw7ONA",
    "tags": []
   },
   "source": [
    "## SPAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0VbzDeJ7PZY"
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'metrics', 'SPAQ'))\n",
    "\n",
    "from Prepare_image import Image_load\n",
    "\n",
    "\n",
    "class Baseline(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.backbone = torchvision.models.resnet50(pretrained=False)\n",
    "        fc_feature = self.backbone.fc.in_features\n",
    "        self.backbone.fc = torch.nn.Linear(fc_feature, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.backbone(x)\n",
    "        return result\n",
    "\n",
    "model = Baseline()\n",
    "model_path = '/home/jovyan/storage/NR-metric-models/BL_release.pt'\n",
    "checkpoint = torch.load(model_path, device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device);\n",
    "model.eval();\n",
    "\n",
    "prepare_image = Image_load(size=512, stride=224)\n",
    "\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1677621867351,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "YdIc6Wep8Dxn",
    "outputId": "90ba54c9-9fc1-4fe0-db60-f6daf66484bf"
   },
   "outputs": [],
   "source": [
    "eps = 3 / 255\n",
    "\n",
    "alpha = 1 / 255\n",
    "iters = 2\n",
    "fname = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}_spaq_{image_type_folder}.csv'\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    try:\n",
    "        # image = prepare_image(Image.open(image_file).convert('RGB'), attack=False).to(device)\n",
    "        # before_score = model(image).mean().cpu().detach().cpu().item()\n",
    "        image = prepare_image(Image.open(image_file).convert('RGB'), attack=True).to(device)\n",
    "    except:\n",
    "        res.append([image_file.split('/')[-1], -1, -1])\n",
    "        continue\n",
    "\n",
    "    p = torch.zeros_like(image).to(DEVICE)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    # before_score = 0\n",
    "    before_score = -1\n",
    "    for i in range(iters):\n",
    "        image_for_attack = image + p\n",
    "        image_for_attack.data.clamp_(0., 1.)\n",
    "        score = model(image_for_attack).mean()\n",
    "        # if i == 0:\n",
    "        #     before_score = score.cpu().detach().item()\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward() \n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "        \n",
    "    # after_score = score.cpu().detach().item()\n",
    "    \n",
    "    try:\n",
    "        image_for_attack = (image_for_attack.squeeze().data.cpu().numpy().transpose(1, 2, 0) * 255).astype('uint8')\n",
    "        img = prepare_image(Image.fromarray(image_for_attack).convert('RGB'), attack=False).to(device)\n",
    "        after_score = model(img).mean().cpu().detach().item()\n",
    "    except:\n",
    "        after_score = -1\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}'\n",
    "df['metric'] = 'spaq'\n",
    "\n",
    "print(\"gain diff: \", (gains[:, 1] - gains[:, 0]).mean())\n",
    "print(\"gain percent:\", ((gains[:, 1] - gains[:, 0]) / gains[:, 0]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(join_path(SAVE_PATH, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7zwfXNg2NGo",
    "tags": []
   },
   "source": [
    "## KonCept512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QF7beKMLDaU0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import argparse\n",
    "import os\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPVKlwwI2Nxm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'metrics', 'KonCept512'))\n",
    "\n",
    "from inceptionresnetv2 import inceptionresnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8J1dd_L82LnE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_qa(nn.Module):\n",
    "    def __init__(self,num_classes,**kwargs):\n",
    "        super(model_qa,self).__init__()\n",
    "        base_model = inceptionresnetv2(num_classes=1000, pretrained='imagenet')\n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1536, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),         \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.base(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4eRmaX92h1w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "KonCept512 = model_qa(num_classes=1)\n",
    "KonCept512.load_state_dict(torch.load('/home/jovyan/storage/NR-metric-models/KonCept512.pth'))\n",
    "KonCept512.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTdCen-92h4D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "koncept_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((384, 512))\n",
    "    ])\n",
    "koncept_normalize = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps = 2 / 255\n",
    "\n",
    "alpha = 3 / 255\n",
    "iters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1794426,
     "status": "ok",
     "timestamp": 1678648284942,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "ZAJMJECD3iJG",
    "outputId": "3e8c7ba0-926d-4cc0-db80-d266abd91530",
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    image = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "    image = koncept_transform(image).to(device)\n",
    "    image = koncept_normalize(image).unsqueeze(0)\n",
    "    p = torch.zeros_like(image).to(DEVICE)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    before_score = 0\n",
    "    for i in range(iters):\n",
    "        image_for_attack = image + p\n",
    "        # print(image_for_attack.max(), image_for_attack.min())\n",
    "        image_for_attack.data.clamp_(-1., 1.)\n",
    "        # image_for_attack = koncept_normalize(image_for_attack) # .unsqueeze(0)\n",
    "        score = KonCept512(image_for_attack)[0][0]\n",
    "        if i == 0:\n",
    "            before_score = score.cpu().detach().item()\n",
    "        # print(\"score:\", score.item())\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward() \n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "        \n",
    "    after_score = score.cpu().detach().item()\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('\\\\')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_255_eps{int(eps * 255)}_255_i{iters}'\n",
    "df['metric'] = 'koncept'\n",
    "\n",
    "x = (gains[:, 1] - gains[:, 0]) # .mean()\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}_koncept_{image_type_folder}.csv'\n",
    "df.to_csv(join_path(SAVE_PATH, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLaGlFeJ6buP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdHUrx2A6bwz",
    "tags": []
   },
   "source": [
    "## MDTVSFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "# from torchvision import transforms\n",
    "import skvideo.io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.utils.backcompat.broadcast_warning.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'metrics', 'MDTVSFA'))\n",
    "\n",
    "from VQAmodel import VQAModel\n",
    "from CNNfeatures import CNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VQAModel().to(device)\n",
    "model.load_state_dict(torch.load('/home/jovyan/storage/NR-metric-models/MDTVSFA.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extractor = CNNModel(model='ResNet-50').to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train();\n",
    "extractor.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps = 2 / 255\n",
    "\n",
    "alpha = 2 / 255\n",
    "iters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images): \n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    p = torch.zeros_like(image).to(device)\n",
    "    p = Variable(p, requires_grad=True)\n",
    "    before_score = 0\n",
    "    for i in range(iters):\n",
    "        image_for_attack = image + p\n",
    "        features_mean, features_std = extractor(image_for_attack)\n",
    "        features = torch.cat((features_mean, features_std), 1).squeeze()\n",
    "        features = torch.unsqueeze(features, 0)\n",
    "        input_length = features.shape[1] * torch.ones(1, 1, dtype=torch.long)\n",
    "        score = model((features, input_length))[0]\n",
    "        image_for_attack.data.clamp_(-1., 1.)        \n",
    "        if i == 0:\n",
    "            before_score = score.detach().cpu().item()\n",
    "        loss = 1 - score / 100\n",
    "        loss.backward()\n",
    "        g = p.grad\n",
    "        g = torch.sign(g)\n",
    "        p.data -= alpha * g\n",
    "        p.data.clamp_(-eps, +eps)\n",
    "        p.grad.zero_()\n",
    "        \n",
    "    after_score = score.cpu().detach().item()\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "    \n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}'\n",
    "df['metric'] = 'mdtvsfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"gain diff: \", (gains[:, 1] - gains[:, 0]).mean())\n",
    "print(\"gain percent:\", ((gains[:, 1] - gains[:, 0]) / gains[:, 0]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = f'ifgsm_alpha{int(alpha * 255)}_eps{int(eps * 255)}_i{iters}_mdtvsfa_{image_type_folder}.csv'\n",
    "df.to_csv(join_path(SAVE_PATH, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_type_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
