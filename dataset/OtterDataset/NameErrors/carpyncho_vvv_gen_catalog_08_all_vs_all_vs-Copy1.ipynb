{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from libs.container import Container\n",
    "from libs.display import d\n",
    "from libs.nearest import nearest\n",
    "from libs.experiment import KFoldExperiment, WithAnotherExperiment, roc, metrics\n",
    "from libs.precstar import  prec_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s2_5k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", \"tile\", \"cls\"] \n",
    "X_columns = [c for c in sample.columns if c not in no_features]\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_small = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s5k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_mid = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s20k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_big = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "cpu = joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = {0:0, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Amplitude\n",
       "2. AmplitudeH\n",
       "3. AmplitudeJ\n",
       "4. AmplitudeJH\n",
       "5. AmplitudeJK\n",
       "6. Autocor_length\n",
       "7. Beyond1Std\n",
       "8. CAR_mean\n",
       "9. CAR_sigma\n",
       "10. CAR_tau\n",
       "11. Con\n",
       "12. Eta_e\n",
       "13. FluxPercentileRatioMid20\n",
       "14. FluxPercentileRatioMid35\n",
       "15. FluxPercentileRatioMid50\n",
       "16. FluxPercentileRatioMid65\n",
       "17. FluxPercentileRatioMid80\n",
       "18. Freq1_harmonics_amplitude_0\n",
       "19. Freq1_harmonics_amplitude_1\n",
       "20. Freq1_harmonics_amplitude_2\n",
       "21. Freq1_harmonics_amplitude_3\n",
       "22. Freq1_harmonics_rel_phase_0\n",
       "23. Freq1_harmonics_rel_phase_1\n",
       "24. Freq1_harmonics_rel_phase_2\n",
       "25. Freq1_harmonics_rel_phase_3\n",
       "26. LinearTrend\n",
       "27. MaxSlope\n",
       "28. Mean\n",
       "29. Meanvariance\n",
       "30. MedianAbsDev\n",
       "31. MedianBRP\n",
       "32. PairSlopeTrend\n",
       "33. PercentAmplitude\n",
       "34. PercentDifferenceFluxPercentile\n",
       "35. PeriodLS\n",
       "36. Period_fit\n",
       "37. Psi_CS\n",
       "38. Psi_eta\n",
       "39. Q31\n",
       "40. Rcs\n",
       "41. Skew\n",
       "42. SmallKurtosis\n",
       "43. Std\n",
       "44. c89_c3\n",
       "45. c89_hk_color\n",
       "46. c89_jh_color\n",
       "47. c89_jk_color\n",
       "48. c89_m2\n",
       "49. c89_m4\n",
       "50. cnt\n",
       "51. n09_c3\n",
       "52. n09_hk_color\n",
       "53. n09_jh_color\n",
       "54. n09_jk_color\n",
       "55. n09_m2\n",
       "56. n09_m4\n",
       "57. ppmb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZES = {\n",
    "    'b220': 211850,\n",
    "    'b234': 297302,\n",
    "    'b247': 414497,\n",
    "    'b248': 426369,\n",
    "    'b261': 575075,\n",
    "    'b262': 591770,\n",
    "    'b263': 585661,\n",
    "    'b264': 614967,\n",
    "    'b277': 753146,\n",
    "    'b278': 781612,\n",
    "    'b396': 494646}\n",
    "\n",
    "SP = .1\n",
    "\n",
    "def get_prec_star(r, tile_name):\n",
    "    rs = SIZES[tile_name]\n",
    "    return prec_star(r.y_test, r.probabilities[:,1], r.test_size, rs)\n",
    "\n",
    "def get_metrics(kf, vss, train_name):\n",
    "    # kfold correction\n",
    "    \n",
    "    pstar = get_prec_star(kf, train_name)\n",
    "    \n",
    "    idx = nearest(pstar, SP)\n",
    "    precs, recs, curve = kf.prec_rec_curve\n",
    "    kfold_prec = precs[idx]\n",
    "    kfold_recall = recs[idx]\n",
    "    \n",
    "    m = Container(\n",
    "        kfold=(kfold_prec, kfold_recall), vss=Container())\n",
    "    \n",
    "    for vs in vss:\n",
    "        pstar = get_prec_star(vs, vs.test_name)\n",
    "        idx = nearest(pstar, SP)\n",
    "        \n",
    "        precs, recs, curve = vs.prec_rec_curve\n",
    "        prec = precs[idx]\n",
    "        recall = recs[idx]\n",
    "        m.vss[vs.test_name] = (prec, recall)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "def run(train, data):\n",
    "    print \">>>> Kfolding {} <<<<\".format(train)\n",
    "    kf = KFoldExperiment(\n",
    "        clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\", n_jobs=cpu), clsnum=cls, \n",
    "        data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\", verbose=False)\n",
    "    kf = kf(train, nfolds=10)\n",
    "    \n",
    "    print \">>>> Vs {}<<<<\".format(train)\n",
    "    vs = WithAnotherExperiment(\n",
    "        clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), verbose=False, \n",
    "        clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "    vs = vs(train)\n",
    "    \n",
    "    return train, get_metrics(kf=kf, vss=vs, train_name=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfd25bc5ed18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "cpu = joblib.cpu_count()\n",
    "print cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ff00d1b9f52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     result = jobs(\n\u001b[1;32m      3\u001b[0m         \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         for k in sorted(data_small.keys()))\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"small\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_small)\n",
    "        for k in sorted(data_small.keys()))\n",
    "results[\"small\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Kfolding b220 <<<<\n",
      ">>>> Kfolding b234 <<<<\n",
      ">>>> Kfolding b247 <<<<\n",
      ">>>> Kfolding b248 <<<<\n",
      ">>>> Kfolding b261 <<<<\n",
      ">>>> Kfolding b262 <<<<\n",
      ">>>> Kfolding b263 <<<<\n",
      ">>>> Kfolding b264 <<<<\n",
      ">>>> Kfolding b277 <<<<\n",
      ">>>> Kfolding b278 <<<<\n",
      ">>>> Kfolding b396 <<<<\n",
      ">>>> Vs b220<<<<\n",
      ">>>> Vs b234<<<<\n",
      ">>>> Vs b396<<<<\n",
      ">>>> Vs b247<<<<\n",
      ">>>> Vs b248<<<<\n",
      ">>>> Vs b261<<<<\n",
      ">>>> Vs b264<<<<\n",
      ">>>> Vs b263<<<<\n",
      ">>>> Vs b262<<<<\n",
      ">>>> Vs b278<<<<\n",
      ">>>> Vs b277<<<<\n"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_mid)\n",
    "        for k in sorted(data_mid.keys()))\n",
    "results[\"mid\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Kfolding b220 <<<<\n",
      ">>>> Kfolding b234 <<<<\n",
      ">>>> Kfolding b247 <<<<\n",
      ">>>> Kfolding b248 <<<<\n",
      ">>>> Kfolding b261 <<<<\n",
      ">>>> Kfolding b262 <<<<\n",
      ">>>> Kfolding b263 <<<<\n",
      ">>>> Kfolding b264 <<<<\n",
      ">>>> Kfolding b277 <<<<\n",
      ">>>> Kfolding b278 <<<<\n",
      ">>>> Kfolding b396 <<<<\n",
      ">>>> Vs b220<<<<\n",
      ">>>> Vs b396<<<<\n",
      ">>>> Vs b247<<<<\n",
      ">>>> Vs b234<<<<\n",
      ">>>> Vs b261<<<<\n",
      ">>>> Vs b248<<<<\n",
      ">>>> Vs b264<<<<\n",
      ">>>> Vs b262<<<<\n",
      ">>>> Vs b278<<<<\n",
      ">>>> Vs b263<<<<\n",
      ">>>> Vs b277<<<<\n"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_big)\n",
    "        for k in sorted(data_big.keys()))\n",
    "results[\"big\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/o3o4vZ/all_vs_all_vs/results.npy\", [results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b220 65\n",
      "b234 126\n",
      "b247 192\n",
      "b248 222\n",
      "b261 253\n",
      "b262 318\n",
      "b263 319\n",
      "b264 312\n",
      "b277 434\n",
      "b278 441\n",
      "b396 15\n"
     ]
    }
   ],
   "source": [
    "for k, data in sorted(data_big.items()):\n",
    "    print k, len(data[data.vs_type!=\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "03_sample2.5k.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
