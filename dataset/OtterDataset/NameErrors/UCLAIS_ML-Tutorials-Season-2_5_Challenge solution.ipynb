{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57a2c56",
   "metadata": {},
   "source": [
    "# 4. Challenge\n",
    "\n",
    "## Background information\n",
    "\n",
    "This week's challenge will be a  bit different - instead of building a system for classification problem, we are going to develop simple GAN to generate art in Claude Monet's style!\n",
    "\n",
    "Such system will consist of generator and discriminator models through which we will pass C. Monet's example artwork. After training such system, we will use trained generator to output new images that (in a perfect case) should be similar to the real artwork.\n",
    "\n",
    "***As GAN models are quite complex, the training can take up to 30 minutes (depending on your device's specifications). Thus, you should use around 1000 images of the whole dataset***. This, of course, will have an impact on your output quality.\n",
    "\n",
    "## Data\n",
    "\n",
    "The training data containing Claude Monet's artwork can be accessed using the following [link](https://drive.google.com/file/d/1OCb3PjQTUvBtPMXpzS2Lsy_GT2i7D6HI/view?usp=sharing). It contains over 1100 images, but you should probably use only 1000 of them.\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64bd98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b87a05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your image folder path\n",
    "path = r\"C:/Users/marty/Desktop/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b9f70",
   "metadata": {},
   "source": [
    "After defining the image folder path, we need to import the image data. For such purpose, we are going to use PIL library (similar to opencv). Since some of you might not be familiar with such library, we have already written you a function that takes the folder path and the number of images you want to import and outputs images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3416fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the dimensions of the image and leave function as it is\n",
    "def import_images(path, number):\n",
    "    image_file_list = os.listdir(path)\n",
    "    \n",
    "    pixels = []\n",
    "    images = []\n",
    "    \n",
    "    for i in range(number):\n",
    "        image = PIL.Image.open(path + '\\\\' + image_file_list[i], 'r')\n",
    "        width = 100\n",
    "        image = image.resize((width, width), PIL.Image.ANTIALIAS)\n",
    "        pix = np.array(image.getdata())\n",
    "        pixels.append(pix.reshape(100, 100, 3))\n",
    "        images.append(images)\n",
    "    return np.array(pixels), images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e9730f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 100, 3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import images and pixels and check the shape of your dataset\n",
    "pixels,imgs = import_images(path, 1000)\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22171c9b",
   "metadata": {},
   "source": [
    "### Building model\n",
    "\n",
    "After a rather short preprocessing part, it's time to build our GAN model. As it has been mentioned in the theoretical part, the GAN model consists of generator and discriminator models. In the following code blocks, you will need to define these models and the GAN itself. To simplify the task, some part of the code is already written.\n",
    "\n",
    "#### Discriminator\n",
    "In the following function you will need to:\n",
    "- Define the input shape (remember your image shape)\n",
    "- After the first three layers, you will need to add the second convolutional block\n",
    "- For the final two layers, flatten your inputs and pass through dense layer\n",
    "- Define your optimizer and compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8f105a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(in_shape = (100, 100, 3)):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape),\n",
    "        tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = optimizer,\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8e741",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "The majority of code is already writte, so you will need to write two deconvolutional blocks containing LeakyReLU layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "24d71dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(latent_dim):\n",
    "    \n",
    "    num_nodes = 128 * 25 * 25\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(num_nodes, input_dim = latent_dim),\n",
    "        tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
    "        tf.keras.layers.Reshape((25, 25, 128)),\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Conv2D(3, (7,7) , padding='same')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f0620",
   "metadata": {},
   "source": [
    "#### GAN\n",
    "\n",
    "Finally, combine these two models into GAN. In this code block, you will need to:\n",
    "- Add generator and discriminator blocks to your model\n",
    "- Define your optimizer\n",
    "- Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add77a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc23390",
   "metadata": {},
   "source": [
    "#### Additional functions\n",
    "\n",
    "In addition to defining our model, we also need functions for formating the real image data, generating latent points that will be used as an input data to our generator ('clues' for our generator) and generating fake data itself. To simplify the problem, all these functions are already provided to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847a5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_gen(data, num_samples):\n",
    "    \n",
    "    idx = randint(0, data.shape[0], num_samples)\n",
    "    X = data[idx]\n",
    "    y = ones((num_samples, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9a4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_point_gen(latent_dim, num_samples):\n",
    "    \n",
    "    x = randn(latent_dim * num_samples)\n",
    "    x = x.reshape(num_samples, latent_dim)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bba64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_data_gen(generator, latent_dim, num_samples):\n",
    "    \n",
    "    x = latent_point_gen(latent_dim, num_samples)\n",
    "    \n",
    "    X = generator.predict(x)\n",
    "    \n",
    "    y = zeros((num_samples, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553dc1f",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "So far, we have defined our model and some additional functions that are going to be used for generating data. It's now time to actually train our system!\n",
    "\n",
    "To make it easier for you, we also are providing all code for the train and performance summary (just to observe our training) functions. You will only need to define the number of epochs and batch.\n",
    "\n",
    "As a whole, the train function operates in the following way:\n",
    "- It takes input data and formates it\n",
    "- Similarly, the fake data is generated\n",
    "- After stacking fake and real data, we pass it through discriminator that outputs the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e98bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan, data, latent_dim, num_epochs=100, num_batch=10):\n",
    "    \n",
    "    batch_per_epoch = int(data.shape[0] / num_batch)\n",
    "    \n",
    "    half_batch = int(num_batch / 2)\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            \n",
    "            X_real, y_real = real_data_gen(data, half_batch)\n",
    "            X_fake, y_fake = fake_data_gen(generator, latent_dim, half_batch)\n",
    "            \n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            \n",
    "            discriminator_loss, _ = discriminator.train_on_batch(X, y)\n",
    "            \n",
    "            X_gan = latent_point_gen(latent_dim, num_batch)\n",
    "            y_gan = ones((num_batch, 1))\n",
    "            \n",
    "            generator_loss = gan.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, batch_per_epoch, discriminator_loss, generator_loss))\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            \n",
    "            summarize_performance(i, generator, discriminator, data, latent_dim)\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f7f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, data, latent_dim, num_samples=100):\n",
    "    \n",
    "    X_real, y_real = real_data_gen(data, num_samples)\n",
    "    \n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "    \n",
    "    x_fake, y_fake = fake_data_gen(generator, latent_dim, num_samples)\n",
    "    \n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    \n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "    \n",
    "    generator.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1c3c1",
   "metadata": {},
   "source": [
    "Lastly, let's train apply all functions and train the system (it might take 15-30 minutes to train your model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "acd05b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "discriminator = get_discriminator()\n",
    "generator = get_generator(latent_dim)\n",
    "gan = get_gan(generator, discriminator)\n",
    "train(generator, discriminator, gan, np.array(pixels), latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09271e",
   "metadata": {},
   "source": [
    "### Generating art\n",
    "\n",
    "Finally, we can use this model to generate example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78408b6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_point_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19252/809867038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#model = tf.keras.models.load_model(r\"C:/Users/marty/Desktop/ML learning/AI_SOC_TUTORIALS/WEEK_8/Challenge/generator_model_100.h5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlatent_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlatent_point_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_point_gen' is not defined"
     ]
    }
   ],
   "source": [
    "#model = generator\n",
    "\n",
    "#model = tf.keras.models.load_model(r\"C:/Users/marty/Desktop/ML learning/AI_SOC_TUTORIALS/WEEK_8/Challenge/generator_model_100.h5\")\n",
    "\n",
    "latent_points = latent_point_gen(100, 1)\n",
    "\n",
    "X = model.predict(latent_points)\n",
    "\n",
    "array = np.array(X.reshape(100,100,3), dtype=np.uint8)\n",
    "\n",
    "new_image = PIL.Image.fromarray(array)\n",
    "\n",
    "plt.imshow(new_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
