{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a8073f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# 스파크 환경 설정 객체 생성\n",
    "spark = SparkSession.builder.appName(\"241206_03_summary\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c56d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').load('data/2015-summary.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3223340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,IntegerType,true)))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "856e0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db5e0bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb398e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "929a570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "|    United States|\n",
      "|            Egypt|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ce0682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "914a3cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from mobility_data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb7f5d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1980f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup2 = df.select('DEST_COUNTRY_NAME').dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12c7b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5f5b419d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'selcet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_dup3 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselcet\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEST_COUNTRY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropDuplicates()\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m      2\u001b[0m df_dup3\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py:1643\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1645\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'selcet'"
     ]
    }
   ],
   "source": [
    "df_dup3 = df.selcet('DEST_COUNTRY_NAME').dropDuplicates().cache()\n",
    "df_dup3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a29bf857",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dup\u001b[49m\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dup' is not defined"
     ]
    }
   ],
   "source": [
    "df_dup.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f509d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ded5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.withColumn('withInCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "907ba55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withInCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3098f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.withColumn('category', expr('CASE WHEN count<10 THEN \"under\" WHEN count>=10 THEN \"upper\" END'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d477f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "|    United States|            Romania|   15|   upper|\n",
      "|    United States|            Croatia|    1|   under|\n",
      "|    United States|            Ireland|  344|   upper|\n",
      "|            Egypt|      United States|   15|   upper|\n",
      "|    United States|              India|   62|   upper|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a882eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.withColumn('withINCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "05486bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withINCountry|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|    United States|            Romania|   15|   upper|        false|\n",
      "|    United States|            Croatia|    1|   under|        false|\n",
      "|    United States|            Ireland|  344|   upper|        false|\n",
      "|            Egypt|      United States|   15|   upper|        false|\n",
      "|    United States|              India|   62|   upper|        false|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e686eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|withInCountry|count|\n",
      "+-------------+-----+\n",
      "|         true|    1|\n",
      "|        false|  255|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupBy(\"withInCountry\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6c8ddf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.where('count<5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3afdd5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withINCountry|\n",
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "|       United States|            Croatia|    1|   under|        false|\n",
      "|       United States|          Singapore|    1|   under|        false|\n",
      "|             Moldova|      United States|    1|   under|        false|\n",
      "|               Malta|      United States|    1|   under|        false|\n",
      "|             Algeria|      United States|    4|   under|        false|\n",
      "|       United States|          Gibraltar|    1|   under|        false|\n",
      "|Saint Vincent and...|      United States|    1|   under|        false|\n",
      "|            Suriname|      United States|    1|   under|        false|\n",
      "|       United States|             Cyprus|    1|   under|        false|\n",
      "|       United States|           Malaysia|    3|   under|        false|\n",
      "|            Thailand|      United States|    3|   under|        false|\n",
      "|             Liberia|      United States|    2|   under|        false|\n",
      "|             Hungary|      United States|    2|   under|        false|\n",
      "|       United States|            Vietnam|    2|   under|        false|\n",
      "|        Burkina Faso|      United States|    1|   under|        false|\n",
      "|            Djibouti|      United States|    1|   under|        false|\n",
      "|       United States|            Estonia|    1|   under|        false|\n",
      "|       United States|            Hungary|    3|   under|        false|\n",
      "|              Zambia|      United States|    1|   under|        false|\n",
      "|            Malaysia|      United States|    2|   under|        false|\n",
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cf3b8610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7cbd8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withINCountry|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|    United States|            Croatia|    1|   under|        false|\n",
      "|    United States|          Singapore|    1|   under|        false|\n",
      "|    United States|          Gibraltar|    1|   under|        false|\n",
      "|    United States|             Cyprus|    1|   under|        false|\n",
      "|    United States|           Malaysia|    3|   under|        false|\n",
      "|    United States|            Vietnam|    2|   under|        false|\n",
      "|    United States|            Estonia|    1|   under|        false|\n",
      "|    United States|            Hungary|    3|   under|        false|\n",
      "|    United States|           Thailand|    4|   under|        false|\n",
      "|    United States|            Liberia|    2|   under|        false|\n",
      "|    United States|              Malta|    2|   under|        false|\n",
      "|    United States|          Lithuania|    1|   under|        false|\n",
      "|    United States|           Bulgaria|    1|   under|        false|\n",
      "|    United States|            Georgia|    1|   under|        false|\n",
      "|    United States|            Bahrain|    1|   under|        false|\n",
      "|    United States|   Papua New Guinea|    1|   under|        false|\n",
      "|    United States|          Greenland|    4|   under|        false|\n",
      "|    United States|          Indonesia|    2|   under|        false|\n",
      "|    United States|         Montenegro|    1|   under|        false|\n",
      "|    United States|            Namibia|    1|   under|        false|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7=df5.where('count<5').where('ORIGIN_COUNTRY_NAME != \"United States\"')\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7aa65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from mobility_data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbd8a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper 인 ORIGIN_COUNTRY_NAEM별 평균 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35e4ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#카운트가 200 이상인 ORIGIN_COUNTRY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fe6f8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국내 여행이 아니면서 가장 횟수가 많은 ORIGIN_COUNTRY_NAME top 10을 추출해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e2fdc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국내 여행이 아니면서 가장 횟수가 적은 ORIGIN_COUNTRY_NAME top 10을 추출해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7c81819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#도착국가별 count 총합이 가장 많은 top10을 추출해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91e31ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "202bcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SecondSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6c9a7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/emp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b5957ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "11b54fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6216039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| ename|deptno|\n",
      "+------+------+\n",
      "| SMITH|    20|\n",
      "| ALLEN|    30|\n",
      "|  WARD|    30|\n",
      "| JONES|    20|\n",
      "|MARTIN|    30|\n",
      "| BLAKE|    30|\n",
      "| CLARK|    10|\n",
      "| SCOTT|    20|\n",
      "|  KING|    10|\n",
      "|TURNER|    30|\n",
      "| ADAMS|    20|\n",
      "| JAMES|    30|\n",
      "|  FORD|    20|\n",
      "|MILLER|    10|\n",
      "|  JACK|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename','deptno').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ab874d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ename|deptno|\n",
      "+-----+------+\n",
      "|SMITH|    20|\n",
      "|JONES|    20|\n",
      "|SCOTT|    20|\n",
      "|ADAMS|    20|\n",
      "| FORD|    20|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename', 'deptno').where('deptno=20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "728ebfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4a997323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(job)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41f1ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "||\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b63190e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 43:==============================================>       (173 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('job').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5433c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf235986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:=================================================>    (183 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b7a6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c71b9e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(approx_count_distinct('job',0.1)).show() #성능면에서 유리한 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8f9a0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first, last, min, max, sum, avg, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5922ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|first(ename)|last(ename)|\n",
      "+------------+-----------+\n",
      "|       SMITH|       JACK|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(first('ename'), last('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6eaafa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min(sal)|max(sal)|\n",
      "+--------+--------+\n",
      "|     800|    5000|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('sal'), max('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "62ab160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+----------+\n",
      "|count(empno)|count(1)|max(ename)|min(ename)|\n",
      "+------------+--------+----------+----------+\n",
      "|          15|      15|      WARD|     ADAMS|\n",
      "+------------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('empno'), count('*'),max('ename'),min('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ec1b39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "437d103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 59:=========================================>            (155 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.selectExpr('sum(distinct sal)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a9e34cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------------+\n",
      "|total_tx|total_salary|       mean_salary|\n",
      "+--------+------------+------------------+\n",
      "|      15|       32225|2148.3333333333335|\n",
      "+--------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = df.select(count('sal').alias('total_tx'),\n",
    "                sum('sal').alias('total_salary'),\n",
    "                #avg('sal').alias('avg_salary')\n",
    "                expr('mean(sal)').alias('mean_salary')\n",
    "               )\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4fca3c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2c9f3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c9dbd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.groupBy('job').agg(expr('avg(sal) as SAL_AVG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1ed2d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "21761f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|         SAL_STDEV|\n",
      "+---------+------------------+\n",
      "|  ANALYST|               0.0|\n",
      "| SALESMAN|154.11035007422439|\n",
      "|    CLERK| 880.6815542521599|\n",
      "|  MANAGER|223.91714737574006|\n",
      "|PRESIDENT|               0.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(expr('stddev_pop(sal) as SAL_STDEV')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "537f77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "windowspec = Window.orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "86ffde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salAllRank = rank().over(windowspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b58ea112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "96f215a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 14:27:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "#데이터프레임에 컬럼으로 추가 > 액션\n",
    "df.withColumn(\"salary_rank\", salAllRank).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c2c93d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7839|          1|\n",
      "| 9292|          2|\n",
      "| 7788|          3|\n",
      "| 7902|          3|\n",
      "| 7566|          5|\n",
      "| 7698|          6|\n",
      "| 7782|          7|\n",
      "| 7499|          8|\n",
      "| 7844|          9|\n",
      "| 7934|         10|\n",
      "| 7521|         11|\n",
      "| 7654|         11|\n",
      "| 7876|         13|\n",
      "| 7900|         14|\n",
      "| 7369|         15|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 14:27:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select( 'empno', salAllRank.alias('salary_rank') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e14c40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowspec = Window.orderBy(desc('sal'))\n",
    "windowspec =Window.partitionBy('job').orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3cd589fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "salJobRank = rank().over(windowspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b530db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f04c879aa30>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "52dfefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----------+\n",
      "|      job| ename| sal|salJobRank|\n",
      "+---------+------+----+----------+\n",
      "|  ANALYST| SCOTT|3000|         1|\n",
      "|  ANALYST|  FORD|3000|         1|\n",
      "| SALESMAN| ALLEN|1600|         1|\n",
      "| SALESMAN|TURNER|1500|         2|\n",
      "| SALESMAN|  WARD|1250|         3|\n",
      "| SALESMAN|MARTIN|1250|         3|\n",
      "|    CLERK|  JACK|3200|         1|\n",
      "|    CLERK|MILLER|1300|         2|\n",
      "|    CLERK| ADAMS|1100|         3|\n",
      "|    CLERK| JAMES| 950|         4|\n",
      "|    CLERK| SMITH| 800|         5|\n",
      "|  MANAGER| JONES|2975|         1|\n",
      "|  MANAGER| BLAKE|2850|         2|\n",
      "|  MANAGER| CLARK|2450|         3|\n",
      "|PRESIDENT|  KING|5000|         1|\n",
      "+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    'job',\n",
    "    'ename',\n",
    "    'sal',\n",
    "    salJobRank.alias('salJobRank')  # rank 결과에 별칭 부여\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "89cb108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#부서별 급여 순위 생성부서별 급여 순위 생성\n",
    "dept_window_spec = Window.partitionBy('deptno').orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9d4bfcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = df.withColumn( 'dept_salary_rank', rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "664a3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               2|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               5|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "new_df = df.withColumn( 'dept_salary_rank', row_number().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a2d1c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               2|\n",
      "| ADAMS|    20|1100|               3|\n",
      "| SMITH|    20| 800|               4|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               5|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "new_df = df.withColumn( 'dept_salary_rank', dense_rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "50221dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#누적 급여 계산#누적 급여 계산\n",
    "from pyspark.sql.functions import dense_rank\n",
    "sum_window_spec = Window.partitionBy('deptno').orderBy('empno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "97513515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|cum_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|       800|\n",
      "| JONES|    20|2975|      3775|\n",
      "| SCOTT|    20|3000|      6775|\n",
      "| ADAMS|    20|1100|      7875|\n",
      "|  FORD|    20|3000|     10875|\n",
      "| CLARK|    10|2450|      2450|\n",
      "|  KING|    10|5000|      7450|\n",
      "|MILLER|    10|1300|      8750|\n",
      "|  JACK|    70|3200|      3200|\n",
      "| ALLEN|    30|1600|      1600|\n",
      "|  WARD|    30|1250|      2850|\n",
      "|MARTIN|    30|1250|      4100|\n",
      "| BLAKE|    30|2850|      6950|\n",
      "|TURNER|    30|1500|      8450|\n",
      "| JAMES|    30| 950|      9400|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = df.withColumn( 'cum_salary', sum('sal').over(sum_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'cum_salary'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "73485582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|deptno|        avg_salary|\n",
      "+------+------------------+\n",
      "|    20|            2175.0|\n",
      "|    10|2916.6666666666665|\n",
      "|    70|            3200.0|\n",
      "|    30|1566.6666666666667|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# 부서별 평균 급여 계산\n",
    "df.groupBy(\"deptno\").agg(avg(\"sal\").alias(\"avg_salary\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0c51c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+\n",
      "|empno|deptno|   dept_avg_salary|\n",
      "+-----+------+------------------+\n",
      "| 7369|    20|            2175.0|\n",
      "| 7566|    20|            2175.0|\n",
      "| 7788|    20|            2175.0|\n",
      "| 7876|    20|            2175.0|\n",
      "| 7902|    20|            2175.0|\n",
      "| 7782|    10|2916.6666666666665|\n",
      "| 7839|    10|2916.6666666666665|\n",
      "| 7934|    10|2916.6666666666665|\n",
      "| 9292|    70|            3200.0|\n",
      "| 7499|    30|1566.6666666666667|\n",
      "| 7521|    30|1566.6666666666667|\n",
      "| 7654|    30|1566.6666666666667|\n",
      "| 7698|    30|1566.6666666666667|\n",
      "| 7844|    30|1566.6666666666667|\n",
      "| 7900|    30|1566.6666666666667|\n",
      "+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "avg_window_spec = Window.partitionBy('deptno')\n",
    "new_avg_df = df.withColumn('dept_avg_salary', avg('sal').over(avg_window_spec))\n",
    "new_avg_df.select('empno', 'deptno', 'dept_avg_salary',).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8eeffb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+-----------+\n",
      "| ename|deptno| sal|prev_salary|next_salary|\n",
      "+------+------+----+-----------+-----------+\n",
      "| SMITH|    20| 800|       null|       2975|\n",
      "| JONES|    20|2975|        800|       3000|\n",
      "| SCOTT|    20|3000|       2975|       1100|\n",
      "| ADAMS|    20|1100|       3000|       3000|\n",
      "|  FORD|    20|3000|       1100|       null|\n",
      "| CLARK|    10|2450|       null|       5000|\n",
      "|  KING|    10|5000|       2450|       1300|\n",
      "|MILLER|    10|1300|       5000|       null|\n",
      "|  JACK|    70|3200|       null|       null|\n",
      "| ALLEN|    30|1600|       null|       1250|\n",
      "|  WARD|    30|1250|       1600|       1250|\n",
      "|MARTIN|    30|1250|       1250|       2850|\n",
      "| BLAKE|    30|2850|       1250|       1500|\n",
      "|TURNER|    30|1500|       2850|        950|\n",
      "| JAMES|    30| 950|       1500|       null|\n",
      "+------+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lead, lag 이전 급여 , 이후 급여\n",
    "from pyspark.sql.functions import lag, lead\n",
    "\n",
    "row_window_spec = Window.partitionBy('deptno').orderBy('empno')\n",
    "\n",
    "#이전급여 컬럼, 이후급여 컬럼 2개 추가\n",
    "lead_lagg_sal_df = df.withColumn('prev_salary', lag('sal').over(row_window_spec))\\\n",
    "            .withColumn('next_salary', lead('sal').over(row_window_spec))\n",
    "\n",
    "lead_lagg_sal_df.select('ename', 'deptno', 'sal',  'prev_salary', 'next_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a393cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('deptno', 'job').agg(count('*'),sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c54fb3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 188:===============================================>     (180 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f5a24b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|  null|  ANALYST|       2|    6000|\n",
      "|  null|    CLERK|       5|    7350|\n",
      "|  null|  MANAGER|       3|    8275|\n",
      "|  null|PRESIDENT|       1|    5000|\n",
      "|  null| SALESMAN|       4|    5600|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cube('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bb914",
   "metadata": {},
   "source": [
    "select\n",
    "    deptno, job,\n",
    "    max(sal)as max_sal,\n",
    "    min(sal)as min_sal,\n",
    "from emp\n",
    "group by rollup(deptno,  job)\n",
    "order by deptno, job;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0b44e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+-------+\n",
      "|deptno|      job|max(sal)|min_sal|\n",
      "+------+---------+--------+-------+\n",
      "|  null|     null|    5000|    800|\n",
      "|    10|     null|    5000|   1300|\n",
      "|    10|    CLERK|    1300|   1300|\n",
      "|    10|  MANAGER|    2450|   2450|\n",
      "|    10|PRESIDENT|    5000|   5000|\n",
      "|    20|     null|    3000|    800|\n",
      "|    20|  ANALYST|    3000|   3000|\n",
      "|    20|    CLERK|    1100|    800|\n",
      "|    20|  MANAGER|    2975|   2975|\n",
      "|    30|     null|    2850|    950|\n",
      "|    30|    CLERK|     950|    950|\n",
      "|    30|  MANAGER|    2850|   2850|\n",
      "|    30| SALESMAN|    1600|   1250|\n",
      "|    70|     null|    3200|   3200|\n",
      "|    70|    CLERK|    3200|   3200|\n",
      "+------+---------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 192:============================================>        (168 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno', 'job').agg(max('sal'),min('sal').alias('min_sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job별 평균급여 job, avg_salary, total_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpetno, job 평균급여, 최대급여를모두 소계를 냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "459cbcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+----------+\n",
      "|deptno|      job|        avg_salary|max_salary|\n",
      "+------+---------+------------------+----------+\n",
      "|    10|    CLERK|            1300.0|      1300|\n",
      "|    20|  ANALYST|            3000.0|      3000|\n",
      "|    70|     null|            3200.0|      3200|\n",
      "|    30| SALESMAN|            1400.0|      1600|\n",
      "|    10|     null|2916.6666666666665|      5000|\n",
      "|    70|    CLERK|            3200.0|      3200|\n",
      "|    30|  MANAGER|            2850.0|      2850|\n",
      "|  null|     null|2148.3333333333335|      5000|\n",
      "|    10|PRESIDENT|            5000.0|      5000|\n",
      "|    30|     null|1566.6666666666667|      2850|\n",
      "|    10|  MANAGER|            2450.0|      2450|\n",
      "|    20|     null|            2175.0|      3000|\n",
      "|    20|  MANAGER|            2975.0|      2975|\n",
      "|    20|    CLERK|             950.0|      1100|\n",
      "|    30|    CLERK|             950.0|       950|\n",
      "+------+---------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df.rollup(\"deptno\", \"job\").agg(\n",
    "    avg(\"sal\").alias(\"avg_salary\"),  # 평균 급여\n",
    "    max(\"sal\").alias(\"max_salary\")  # 최대 급여\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cf0509f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91718d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
