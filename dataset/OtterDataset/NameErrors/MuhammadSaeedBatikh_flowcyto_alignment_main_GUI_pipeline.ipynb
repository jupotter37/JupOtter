{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from pipeline import *\n",
    "from visualization import *\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.core.display import display, HTML\n",
    "import os \n",
    "import pipeline as pl\n",
    "print(os.path.abspath(pl.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = '../../data/080322-ENU-Mouse-Normalisation-Data-Gated.csv'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path, sep=',')\n",
    "columns_names = df.columns.tolist()\n",
    "sample_code_column= 'sample_code'\n",
    "samples_codes = df[sample_code_column]\n",
    "samples_codes = np.unique(samples_codes)\n",
    "unique_samples_codes = np.unique([e.split('-')[0]for e in samples_codes])\n",
    "   \n",
    "X, Y, columns_names,_ = load_data(path, unique_samples_codes, sample_code_column= 'sample_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(X, Y, 15, channel_names=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.segment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.commit_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interact_pick_channel_segment(pipeline, channel):\n",
    "    channel = columns_names.index(channel)-1\n",
    "    area_threshold_widget  = widgets.FloatSlider(min=0.0, max=0.05, step=0.001, value=pipeline.area_thresholds[channel], )\n",
    "    width_threshold_widget = widgets.FloatSlider(min=0.0, max=0.6, step=.025, value=pipeline.width_thresholds[channel])\n",
    "    depth_threshold_widget = widgets.FloatSlider(min=0.0, max=0.7, step=.025, value=pipeline.depth_thresholds[channel])\n",
    "\n",
    "    interact(interactive_update_segments,\n",
    "         area_threshold = area_threshold_widget,\n",
    "         width_threshold = width_threshold_widget,\n",
    "         depth_threshold = depth_threshold_widget,\n",
    "         channel = fixed(channel),\n",
    "         pipeline=fixed(pipeline))\n",
    "\n",
    "def interactive_update_segments(pipeline, channel, area_threshold, width_threshold,\n",
    "                                depth_threshold):\n",
    "\n",
    "        pipeline.resegment_channel(channel,area_threshold, width_threshold,depth_threshold)\n",
    "\n",
    "\n",
    "        plot_channel_segments(ch=channel,\n",
    "                              samples=pipeline.samples,\n",
    "                               max_per_plt=20,show_labels=False,\n",
    "                              limit_x0=-.2,limit_x1=1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ch_widget = widgets.ToggleButtons(\n",
    "    options=columns_names[1:-2],\n",
    "    description='Channel',\n",
    "    disabled=False,\n",
    "    style={\"button_width\": \"100px\"}\n",
    ")\n",
    "\n",
    "ch = ch_widget.index\n",
    "\n",
    "# kde_window_widget = widgets.FloatSlider(min=0.0, max=0.6, step=.025, value=kde_window[ch])\n",
    "interact(interact_pick_channel_segment,\n",
    "         channel = ch_widget,\n",
    "         pipeline=fixed(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interactive_recompute_and_update_location_hierarchy_and_refs(pipeline, channel, jaccard_thresholds, mode):\n",
    "    pipeline.recompute_and_update_location_hierarchy_and_refs([channel], jaccard_thresholds)\n",
    "    plot_gates_dendrogram(pipeline.agg_models_dict[channel],channel,\n",
    "                          pipeline.jaccard_thresholds[channel], columns_names[channel+1])\n",
    "    plt.figure()\n",
    "    plot_gate_as_tiles(pipeline.data_handler, channel, pipeline.Loc_Ref_Dict_All_Ch)\n",
    "    if mode==1 or mode ==2:\n",
    "        plt.figure()\n",
    "        plot_network_graph(channel, pipeline.incidence_matrices[channel], pipeline.channel_names)\n",
    "        plt.figure()\n",
    "        sns.heatmap(pipeline.Sim_Matrix_dict[channel], cmap='Blues')\n",
    "        if mode ==2:\n",
    "            plot_channel_segments(ch=channel,\n",
    "                               samples=pipeline.samples,\n",
    "                               max_per_plt=20,show_labels=False, color_fill_lg= True,\n",
    "                               limit_x0=-.2,limit_x1=1.2)\n",
    "def interact_pick_channel_location_grouping(pipeline, channel, mode):\n",
    "    channel = columns_names.index(channel)-1\n",
    "\n",
    "    jaccard_threshold_widget = widgets.FloatSlider(min=0.4, max=0.9,\n",
    "                                                   step=.01, value=pipeline.jaccard_thresholds[channel])\n",
    "\n",
    "\n",
    "    interact(interactive_recompute_and_update_location_hierarchy_and_refs,\n",
    "         jaccard_thresholds = jaccard_threshold_widget,\n",
    "         channel = fixed(channel),\n",
    "            mode = fixed(mode),\n",
    "         pipeline=fixed(pipeline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.commit_changes()\n",
    "ch_widget = widgets.ToggleButtons(\n",
    "    options=columns_names[1:-2],\n",
    "    description='Channel',\n",
    "    disabled=False,\n",
    "    style={\"button_width\": \"100px\"}\n",
    ")\n",
    "\n",
    "mode_widget = widgets.Dropdown(\n",
    "    options=[0, 1, 2],\n",
    "    value=0,\n",
    "    description='Mode:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "interact(interact_pick_channel_location_grouping,\n",
    "         channel = ch_widget,\n",
    "         mode = mode_widget,\n",
    "         pipeline=fixed(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in pipeline.samples:\n",
    "    print(len(s.gates[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.Loc_Ref_Dict_All_Ch[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.commit_changes()\n",
    "channels = list(range(15))\n",
    "pipeline.update_morphology_hierarchy_and_refs(channels,1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "pipeline.commit_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print(channels)\n",
    "pipeline.align_samples(channels, verbose=True, subsample_ratio=.5, n_sample=60)\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_scatter_aligned_vs_original([[13,14]], pipeline, columns_names=pipeline.channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.files_names = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(pipeline.aligned_samples.keys())\n",
    "aligned_samples_numbers, aligned_channels = [k[0] for k in keys], [k[1] for k in keys]\n",
    "aligned_samples_numbers, aligned_channels = np.sort(np.unique(aligned_samples_numbers)), np.sort(np.unique(aligned_channels))\n",
    "print(aligned_samples_numbers, aligned_channels)\n",
    "samp_num_ch_dict = { for s in aligned_samples_numbers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mkeys\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'keys' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_export(pipeline, 'new_csv.csv', format='fcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "All_ch_populations = {}\n",
    "for ch in channels:\n",
    "    samples_populations = []\n",
    "    for s, sample in enumerate(pipeline.samples):\n",
    "        channel_data = sample.data[:, ch]\n",
    "        population = np.zeros([channel_data.shape[0],1], dtype=np.int)\n",
    "        for gate in sample.gates[ch]:\n",
    "            index = np.logical_and(channel_data>=gate.gate[0], channel_data<=gate.gate[1])\n",
    "            lg = gate.location_group\n",
    "            population[index] = lg\n",
    "        print(np.unique(population), np.count_nonzero(population) == channel_data.shape[0])\n",
    "        samples_populations+=[population]\n",
    "    All_ch_populations[ch] = samples_populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_pop_Ys = copy.deepcopy(Y.reshape(-1,1))\n",
    "for ch in channels:\n",
    "    pop_Y_ch = np.concatenate(All_ch_populations[ch], axis=0)\n",
    "    print(pop_Y_ch.shape, all_pop_Ys[0].shape)\n",
    "    all_pop_Ys = np.concatenate([all_pop_Ys, pop_Y_ch], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "population_dict = {8:'B220', 10:'CD44',12:'NK1',13:'CD4', 14:'CD3'}\n",
    "population_header = ['sample_num', *[f'{c}-'+population_dict[c] for c in channels]]\n",
    "print(population_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(f'population_label.csv',all_pop_Ys,delimiter=',',header=','.join(population_header),\n",
    "                   fmt=','.join(['%i']*len(population_header)), comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxmean_align(x,y, mi, mx, q_alignment, func0 = None):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Creates a warping function that soft aligns target boundaries and mean oto corresponding reference values.\n",
    "\n",
    "    :param x: :obj:`numpy.array(dtype=float)`, shape = [1, n], A 1-D array containing target data.\n",
    "    :param y: :obj:`numpy.array(dtype=float)`, shape = [1, n], A 1-D array containing reference data.\n",
    "    :param mi: :obj:`float`, reference segment left quantile.\n",
    "    :param mx: :obj:`float`, reference segment right quantile.\n",
    "    :param q_alignment: :obj:`float`. A quantile value for robust alignment. Instead of matching min and max values of reference, the function matches q_alignment and 1-q_alignment quantiles.\n",
    "    :param func0: :obj:`function, the transformation that needs to be applied before the minmax_alignment, typically the inverse probability transform.\n",
    "    :return: :obj:`function`, a warping function that aligns the boundaries of target to reference gates.\n",
    "    '''\n",
    "\n",
    "    #  f(x)   = aa x**3 + alpha * x**2 + beta*x + gamma\n",
    "    #  f(x)   = alpha * x**2 + beta*x + gamma\n",
    "    # E(f(x)) = alpha * Ex*2 + beta*EY + gamma = EY\n",
    "    # f(x_mx) = alpha * x_mx*2 + beta*x_mx + gamma = y_mx\n",
    "    # f(x_mi) = alpha * x_mi*2 + beta*x_mi + gamma = y_mi\n",
    "\n",
    "    # TODO: ensure monotonicity. Fix bug with quadratic warping.\n",
    "\n",
    "    if func0 is None:\n",
    "        func0 = lambda x:x\n",
    "\n",
    "    z = func0(x)\n",
    "    ind = ~np.isnan(z)\n",
    "    x_mean, y_mean =z[ind].mean(), y.mean()\n",
    "\n",
    "    # TODO: use the precomputed quantiles for target gate\n",
    "    x_mx, x_mi = np.quantile(z[ind],1-q_alignment), np.quantile(z[ind], q_alignment)\n",
    "    M = np.array([\n",
    "        [x_mx**2, x_mx, 1],\n",
    "        [x_mi**2, x_mi, 1],\n",
    "        [z[ind].std()**2 + x_mean**2, x_mean, 1]\n",
    "    ])\n",
    "    b = np.array([mx, mi, y_mean])\n",
    "    s = np.linalg.inv(M)@b.T\n",
    "    alpha, beta, gamma = s[0], s[1], s[2]\n",
    "    print('alpha',alpha, 'beta',beta, 'gamma',gamma)\n",
    "    return lambda x: alpha * func0(x)**2 + beta * func0(x) + gamma\n",
    "\n",
    "def linear_reg_inter(ymean, xmean, x0, y0):\n",
    "\n",
    "    '''\n",
    "\n",
    "    :param ymean:\n",
    "    :param xmean:\n",
    "    :param x0:\n",
    "    :param y0:\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    a = (ymean - y0)/(xmean-x0)\n",
    "    f = lambda x: a*x + y0-a*x0\n",
    "    return f\n",
    "\n",
    "# def comb_func_factory(x, f_start, f_middle, f_end, x_cut_point_start, x_cut_point_end):\n",
    "#     ind_st = x<x_cut_point_start\n",
    "#     ind_end = x>x_cut_point_end\n",
    "#     ys = f_start(x[ind_st])\n",
    "#     ym = f_middle(x[~np.logical_or(ind_st, ind_end)])\n",
    "#     ye = f_end(x[ind_end])\n",
    "#     return np.concatenate([ys, ym, ye])\n",
    "#\n",
    "#\n",
    "# def combine_funcs(funcs, locations, smooth_sigma=0.1):\n",
    "#     xcom = []\n",
    "#     ycom = []\n",
    "#     plot = True\n",
    "#     for i, f in enumerate(funcs):\n",
    "#         g0, g1 = locations[i]\n",
    "#         print(g0, g1)\n",
    "#         x_s = np.linspace(g0, g1, 2000)\n",
    "#         y_s = f(x_s)\n",
    "#         xcom += [x_s]\n",
    "#         ycom += [y_s]\n",
    "#         if plot:\n",
    "#             plt.plot(x_s, y_s)\n",
    "#             plt.xlim(-.3,1.3)\n",
    "#             plt.ylim(-.3,1.3)\n",
    "#     xcom = np.concatenate(xcom)\n",
    "#     ycom = np.concatenate(ycom)\n",
    "#     # middle\n",
    "#     f_middle = scipy.interpolate.interp1d(xcom, ycom, kind='cubic')\n",
    "#\n",
    "#     # start\n",
    "#     x_cut_point_end = locations[0][0] + .1*np.abs(locations[0][0]-locations[0][1])\n",
    "#     ind = np.argmin(np.abs(xcom-x_cut_point_end))\n",
    "#     x_cut_point_start = xcom[ind]\n",
    "#     y_cut_point_start = ycom[ind]\n",
    "#     ind = xcom<=x_cut_point_start\n",
    "#     x, y = xcom[ind], ycom[ind]\n",
    "#     f_start = linear_reg_inter(y.mean(), x.mean(), x_cut_point_start, y_cut_point_start)\n",
    "#     x = np.linspace(-.3, x_cut_point_start, 20000)\n",
    "#     if plot:\n",
    "#         plt.figure()\n",
    "#         plt.plot(x, f_start(x))\n",
    "#\n",
    "#     # end\n",
    "#     x_cut_point_end = locations[-1][1] - .1*np.abs(locations[-1][0]-locations[-1][1])\n",
    "#     ind = np.argmin(np.abs(xcom-x_cut_point_end))\n",
    "#     x_cut_point_end = xcom[ind]\n",
    "#     y_cut_point_end = ycom[ind]\n",
    "#     ind = xcom >= x_cut_point_end\n",
    "#     x, y = xcom[ind], ycom[ind]\n",
    "#     f_end = linear_reg_inter(y.mean(), x.mean(), x_cut_point_end, y_cut_point_end)\n",
    "#     if plot:\n",
    "#         x = np.linspace(x_cut_point_end, 1.3, 20000)\n",
    "#         plt.plot(x, f_end(x))\n",
    "#         x = np.linspace(x_cut_point_start, x_cut_point_end, 20000)\n",
    "#         plt.plot(x, f_middle(x))\n",
    "#\n",
    "#     comb_func = lambda x: gaussian_filter1d(comb_func_factory(x, f_start, f_middle, f_end,\n",
    "#                                                               x_cut_point_start, x_cut_point_end),smooth_sigma)\n",
    "#     return comb_func\n",
    "#\n",
    "\n",
    "def lambda_IPT_factory(ref_inv_cdf, target_ecdf):\n",
    "\n",
    "    '''\n",
    "    A factory method for Inverse Probability Transform. The reason why it is necessary to have this kind of factory/additional layer is that\n",
    "    python lambdas do not store default hyperparamters for non-primitive data types and will access the most recent parameters in its closure.\n",
    "    By having a factory, we ensure that parameters are snapshotted in the scope of the factory and the returned lambda closure has its own unique hyperparameters.\n",
    "\n",
    "    :param ref_inv_cdf: :obj:`function`, inverse empirical cumulative distribution function (ECDF) of reference segment\n",
    "    :param target_ecdf: :obj:`function`, ECDF of target segment.\n",
    "    :return: :obj:`function`, inverse probability transform.\n",
    "    '''\n",
    "\n",
    "    return lambda x: ref_inv_cdf(target_ecdf(x))\n",
    "\n",
    "def compute_cdf_and_inv_cdf(ref_gate, k=3):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Computes the CDF and Inverse CDF of a gate. (typically for a reference gate)\n",
    "\n",
    "    :param ref_gate: :obj:`Gate`, reference gate.\n",
    "    :param k: :obj:`int`, BSpline degree (default =3).\n",
    "    :returns:\n",
    "         - ref_ecdf - :obj:`function`, reference Empirical Cumulative distribution function.\n",
    "         - ref_inv_cdf - :obj:`function`, reference inverse Cumulative distribution function.\n",
    "\n",
    "    '''\n",
    "\n",
    "    ref_seg = ref_gate.segment\n",
    "    # Compute empirical cumulative distribution function for the reference segment\n",
    "    ref_ecdf = sm.distributions.empirical_distribution.ECDF(ref_seg)\n",
    "    # Compute the inverse of the ECDF of reference using monotone function inverter\n",
    "    ref_inv_cdf = sm.distributions.empirical_distribution.monotone_fn_inverter(ref_ecdf,\n",
    "                                                                               ref_seg)\n",
    "    # fit a BSpline tp inverse ECDF\n",
    "\n",
    "    ref_inv_cdf = scipy.interpolate.BSpline(\n",
    "        ref_inv_cdf.x,\n",
    "        ref_inv_cdf.y,\n",
    "        k=k,\n",
    "        extrapolate=False\n",
    "    )\n",
    "    return ref_ecdf, ref_inv_cdf\n",
    "\n",
    "def get_smooth_and_monotonic(t, y):\n",
    "\n",
    "    '''\n",
    "\n",
    "    A convolution-based transform to ensure smoothness and monotonicity.\n",
    "\n",
    "    :param t:\n",
    "    :param y:\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    N = y.shape[0]//10\n",
    "    yy =  np.convolve(y, np.ones(N)/N, mode='valid')\n",
    "    yy, idx = np.unique(yy, return_index=True)\n",
    "    tt = t[idx]\n",
    "    return np.sort(tt), np.sort(yy), [tt.min(), tt.max()]\n",
    "\n",
    "def combined(x, model, funcs, locations, sigma, only_use_MARS = False ):\n",
    "\n",
    "    '''\n",
    "\n",
    "    The final combined function of MARS model and segments transformations.\n",
    "\n",
    "    :param x: :obj:`numpy.array(dtype=float)`, shape = [1, n], A 1-D array containing target data.\n",
    "    :param model: model: :obj:`pyearth.Earth` MARS model.\n",
    "    :param funcs: obj:`list(function)`, a list of warping functions for each segment.\n",
    "    :param locations: obj:`list(tuple)`, a list of tuples that contain the start and end range of each function.\n",
    "    :return: y: :obj:`numpy.array(dtype=float)`, shape = [1, n], A 1-D array containing transformed target data.\n",
    "    '''\n",
    "\n",
    "    if only_use_MARS:\n",
    "        y = model.predict(x)\n",
    "        return y\n",
    "\n",
    "    y = np.zeros(x.shape)\n",
    "    all_inds = []\n",
    "    for i, g in enumerate(locations):\n",
    "        ind = np.logical_and(x>=g[0], x<g[1])\n",
    "        f = funcs[i]\n",
    "        if f is not None:\n",
    "            y[ind] =  gaussian_filter1d( f(x[ind]), sigma )\n",
    "            all_inds+=[ind]\n",
    "    if len(all_inds)>1:\n",
    "        remaining_ind = ~np.logical_or(*all_inds)\n",
    "    else:\n",
    "        remaining_ind = ~all_inds[0]\n",
    "\n",
    "    if np.count_nonzero(remaining_ind)>0:\n",
    "        y[remaining_ind] = model.predict(x[remaining_ind])\n",
    "    return y\n",
    "\n",
    "def combine_funcs(model, xs_ys, funcs, locations, sigma, subsample_ratio=1, plot = True, ax = None):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Creates a combined function of MARS model and every segments transformations.\n",
    "\n",
    "    :param model: :obj:`pyearth.Earth` MARS model.\n",
    "    :param xs_ys: obj:`list(list(numpy.array))`, a list of x values and transformed y values in the form of [ [target_seg1, f(target_seg1)], [target_seg2, f(target_seg2)], ...].\n",
    "    :param funcs: obj:`list(function)`, a list of warping functions for each segment.\n",
    "    :param locations: obj:`list(tuple)`, a list of tuples that contain the start and end range of each function.\n",
    "    :param sigma: :obj:`float`, the standard deviation of Gaussian kernel.\n",
    "    :param subsample_ratio: :obj:`float`, a number between [0,1]`, represents the ratio of cells to consider to estimate MARS parameters.\n",
    "    :param plot: :obj:`Bool`, if :obj:`True`, plots warping functions.\n",
    "    :param ax: :obj:`matplotlib.axes.Axes`, axes to draw on. If :obj:`None`, a new axes is created.\n",
    "    :return: :obj:`function`, the complete warping function for a sample's channel including its MARS regression model for extrapolation.\n",
    "    '''\n",
    "    xcom = []\n",
    "    ycom = []\n",
    "\n",
    "    if plot and ax is None:\n",
    "        ax = plt.subplots(1,1)[1]\n",
    "    for i, xy in enumerate(xs_ys):\n",
    "        x_s, y_s,= xs_ys[i][0],xs_ys[i][1]\n",
    "        if 0<subsample_ratio<1:\n",
    "            m = x_s.shape[0]\n",
    "            indx = np.random.randint(0, m, int(m*subsample_ratio))\n",
    "            xcom += [x_s[indx]]\n",
    "            ycom += [y_s[indx]]\n",
    "        elif subsample_ratio == 1:\n",
    "            xcom += [x_s]\n",
    "            ycom += [y_s]\n",
    "        else:\n",
    "            raise Exception(f'subsample_ratio must be >0 and <=1, you passed {subsample_ratio}')\n",
    "        if plot:\n",
    "            ax.plot(x_s, y_s, linewidth=3)\n",
    "    xcom = np.concatenate(xcom)\n",
    "    ycom = np.concatenate(ycom)\n",
    "    # middle\n",
    "    model.fit(xcom, ycom)\n",
    "    comb_func = lambda x: combined(x, model, funcs, locations, sigma)\n",
    "    if plot:\n",
    "            t = np.linspace(-.1,1.1,5000)\n",
    "            ax.plot(t, comb_func(t))\n",
    "            ax.set_xlim(-.3,1.3)\n",
    "            ax.set_ylim(-.3,1.3)\n",
    "    return comb_func\n",
    "\n",
    "\n",
    "\n",
    "def estimate_alignment_funcs_for_target(ch, target_sample, q_alignment, Loc_Ref_Dict_All_Ch, Ref_Dict_indx_by_Loc_and_Morph, Ref_CDF_and_InvCDF, verbose):\n",
    "\n",
    "\n",
    "    funcs = []\n",
    "    z = target_sample(ch)\n",
    "    sample_orignal = copy.deepcopy(z)\n",
    "    gates_locations = []\n",
    "    xys = []\n",
    "\n",
    "    for i in range(len(target_sample.gates[ch])):\n",
    "        target_gate = target_sample.gates[ch][i]\n",
    "        ind = np.logical_and(z >= target_gate.gate[0], z < target_gate.gate[1])\n",
    "        target_seg1 = target_gate.segment\n",
    "        lo_gr, mr_gr = target_gate.location_group, target_gate.morphology_group\n",
    "\n",
    "        ref_gate = Loc_Ref_Dict_All_Ch[ch][lo_gr]\n",
    "        mr_gr_ref = Ref_Dict_indx_by_Loc_and_Morph.get((lo_gr, mr_gr))\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print('diff:', np.abs(target_gate.segment - target_seg1).sum())\n",
    "            print('lo_gr, mr_gr', lo_gr, mr_gr)\n",
    "            print('\\n mr_gr_ref', mr_gr_ref, '\\n')\n",
    "            print('target gate', target_gate, '\\n')\n",
    "\n",
    "        if target_gate.leave_to_MARS:\n",
    "            funcf = None\n",
    "\n",
    "        else:\n",
    "            if mr_gr_ref:\n",
    "                ref_cdf, ref_inv_cdf = Ref_CDF_and_InvCDF.get((lo_gr, mr_gr))\n",
    "\n",
    "                if mr_gr_ref != target_gate:\n",
    "                    # Compute empirical cumulative distribution function for the target segment\n",
    "                    target_ecdf = sm.distributions.empirical_distribution.ECDF(target_seg1)\n",
    "                    func0 = lambda_IPT_factory(ref_inv_cdf, target_ecdf)\n",
    "\n",
    "                else:\n",
    "                    func0 = lambda x: x\n",
    "\n",
    "            q0, q1 = ref_gate.get_tight_gates(q=q_alignment)\n",
    "            if mr_gr_ref:\n",
    "                funcf = minmaxmean_align(target_seg1, ref_gate.segment, q0, q1, q_alignment, func0)\n",
    "\n",
    "            else:\n",
    "                funcf = minmaxmean_align(target_seg1, ref_gate.segment, q0, q1, q_alignment)\n",
    "\n",
    "        funcs += [funcf]\n",
    "        if verbose:\n",
    "            print('loc. gate is alredy ref?', ref_gate == target_gate)\n",
    "            print('gate:\\n', target_gate.gate)\n",
    "        sample_orignal[ind] = z[ind]\n",
    "        if not target_gate.leave_to_MARS:\n",
    "            t = np.linspace(target_gate.tight_gate[0], target_gate.tight_gate[1], 2000)\n",
    "            y = funcf(t)\n",
    "            ind = ~np.isnan(y)\n",
    "            xys += [[t[ind], y[ind]]]\n",
    "        gates_locations += [[target_gate.gate[0], target_gate.gate[1]]]\n",
    "\n",
    "    return funcs, xys, gates_locations, sample_orignal\n",
    "\n",
    "\n",
    "def align_samples_func(ch, q_alignment,\n",
    "                  samples,\n",
    "                  aligned_samples,\n",
    "                  original_samples,\n",
    "                  Loc_Ref_Dict_All_Ch,\n",
    "                  Loc_Morph_Ref_Dict_All_Ch,\n",
    "                  Ref_Inv_CDF_Dict_All_Ch,\n",
    "                  funcs_dict, comp_func_dict,earth_models_dict,\n",
    "                  gates_locations_dict,\n",
    "                  n_sample,\n",
    "                  sigma, earth_smoothing_penalty, subsample_ratio=1,\n",
    "                  in_place_eval = True,\n",
    "                  verbose=False):\n",
    "\n",
    "    Ref_Dict_indx_by_Loc_and_Morph = Loc_Morph_Ref_Dict_All_Ch[ch]\n",
    "    Ref_CDF_and_InvCDF = {}\n",
    "    for (lo_gr, mr_gr), ref_gate in Ref_Dict_indx_by_Loc_and_Morph.items():\n",
    "        ref_ecdf, ref_inv_cdf = compute_cdf_and_inv_cdf(ref_gate)\n",
    "        Ref_CDF_and_InvCDF[lo_gr, mr_gr] = (ref_ecdf, ref_inv_cdf)\n",
    "\n",
    "    Ref_Inv_CDF_Dict_All_Ch[ch] = Ref_CDF_and_InvCDF\n",
    "\n",
    "    for targ_num in range(n_sample):\n",
    "        if verbose:\n",
    "            print(f'Sample {targ_num} **** \\n')\n",
    "\n",
    "        target_sample = samples[targ_num]\n",
    "        funcs, xys, gates_locations, sample_orignal = estimate_alignment_funcs_for_target(ch,target_sample= target_sample, q_alignment=q_alignment,\n",
    "                                                                       Loc_Ref_Dict_All_Ch= Loc_Ref_Dict_All_Ch,\n",
    "                                                                       Ref_Dict_indx_by_Loc_and_Morph=Ref_Dict_indx_by_Loc_and_Morph,\n",
    "                                                                       Ref_CDF_and_InvCDF=Ref_CDF_and_InvCDF, verbose= verbose )\n",
    "\n",
    "        model = Earth(penalty=earth_smoothing_penalty, smooth=True, max_degree=1, )\n",
    "        comp_func = combine_funcs(model, xys, funcs, gates_locations, sigma=sigma, subsample_ratio=subsample_ratio, plot=False)\n",
    "        comp_func_dict[ch, targ_num] = comp_func\n",
    "        earth_models_dict[ch, targ_num] = model\n",
    "        funcs_dict[targ_num, ch] = funcs\n",
    "\n",
    "        if in_place_eval:\n",
    "            gates_locations_dict[targ_num, ch] = gates_locations\n",
    "            sample_aligned = comp_func(sample_orignal)\n",
    "            aligned_samples[targ_num, ch] = sample_aligned\n",
    "            original_samples[targ_num, ch] = sample_orignal\n",
    "\n",
    "    return comp_func_dict, funcs_dict, earth_models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.samples[57].gates[10][1].leave_to_MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in range(7,10):\n",
    "    align_samples_func(ch=ch, q_alignment = pipeline.gate_factor_q[ch],\n",
    "                       samples=pipeline.samples, aligned_samples=pipeline.aligned_samples,\n",
    "                       original_samples=pipeline.original_samples,\n",
    "                       Loc_Ref_Dict_All_Ch=pipeline.Loc_Ref_Dict_All_Ch,Ref_Inv_CDF_Dict_All_Ch=pipeline.Ref_Inv_CDF_Dict_All_Ch,\n",
    "                       Loc_Morph_Ref_Dict_All_Ch=pipeline.Loc_Morph_Ref_Dict_All_Ch,\n",
    "                       funcs_dict=pipeline.funcs_dict, comp_func_dict=pipeline.comp_func_dict,\n",
    "                       gates_locations_dict=pipeline.gates_locations_dict,\n",
    "                       earth_models_dict=pipeline.earth_models_dict,\n",
    "                       n_sample = 60, sigma=1,\n",
    "                       earth_smoothing_penalty = .1,\n",
    "                       subsample_ratio = .5,\n",
    "                       verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_vs_aligned([10],pipeline.samples, pipeline.aligned_samples,\n",
    "                             pipeline.Loc_Ref_Dict_All_Ch, columns_names,n_sample = -1,\n",
    "                             max_per_plt=15, root_path = None, xlim0=0, xlim1 = 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_aligned_vs_original([[10,14]], pipeline, columns_names=pipeline.channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_samples_data = []\n",
    "for s in range(pipeline.num_samples):\n",
    "    sample = []\n",
    "    orig_sample = []\n",
    "    for ch in range(pipeline.num_channels):\n",
    "        samp_ch = pipeline.aligned_samples[s, ch].reshape(-1, 1)\n",
    "        sample +=[samp_ch]\n",
    "    sample = np.concatenate(sample, axis=1 )\n",
    "    y = np.zeros([sample.shape[0],1], dtype=np.int)+s\n",
    "    sample = np.concatenate([y, sample], axis = 1)\n",
    "    aligned_samples_data += [sample]\n",
    "\n",
    "aligned_samples_data = np.concatenate(aligned_samples_data)\n",
    "header = ','.join(pipeline.channel_names)\n",
    "np.savetxt('aligned_data_all_markers.csv',aligned_samples_data,delimiter=',',header=header,\n",
    "           fmt=','.join(['%i'] + ['%1.4f']*pipeline.num_channels), comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_samples_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(60):\n",
    "for i in [56,57,58]:\n",
    "    t = np.linspace(0,1.2,2000)\n",
    "    f = pipeline.comp_func_dict[10, i]\n",
    "    y = f(t)\n",
    "    plt.plot(t,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "i = 18\n",
    "plt.scatter(pipeline.aligned_samples[i,0], pipeline.aligned_samples[i,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_hist = np.ones([60, 15, 256],dtype=np.int)\n",
    "data_hist = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for y in range(60):\n",
    "    sample_hists = np.ones([15, 256], dtype=np.int)\n",
    "    for i in range(15):\n",
    "        x = np.histogram(X[Y==y, i], bins=256)[0]\n",
    "        sample_hists[i, :] = x\n",
    "    # data_hist[y, :, :] = sample_hists\n",
    "    data_hist[y] = sample_hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(data_hist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_path = '..\\\\..\\\\data\\\\60_mice_15_channels_hists.mat'\n",
    "np.savetxt(path,data_hist,delimiter=',',header=columns_names[1:-2],\n",
    "                   fmt=','.join(['%i'] * 15), comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_hist.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_path = '..\\\\..\\\\data\\\\60_mice_15_channels_hists.xlsx'\n",
    "df.to_excel(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df1[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}