{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[00:00:000.00 --> 00:00:000.78] [SPEAKER_02]  How are you doing today?',\n",
       " '[00:00:001.62 --> 00:00:002.42] [SPEAKER_02]  Doing great.',\n",
       " '[00:00:002.42 --> 00:00:003.20] [SPEAKER_02]  Doing great.',\n",
       " '[00:00:003.34 --> 00:00:003.68] [SPEAKER_02]  Is your name Brittany?',\n",
       " '[00:00:004.06 --> 00:00:004.44] [SPEAKER_02]  Is your name Brittany?',\n",
       " '[00:00:004.82 --> 00:00:005.58] [SPEAKER_02]  Okay, perfect.',\n",
       " \"[00:00:005.62 --> 00:00:005.94] [SPEAKER_02]  I'm Jessica.\",\n",
       " '[00:00:005.94 --> 00:00:006.38] [SPEAKER_02]  Okay, perfect.',\n",
       " \"[00:00:006.52 --> 00:00:006.90] [SPEAKER_02]  I'm Jessica.\",\n",
       " \"[00:00:007.14 --> 00:00:009.68] [SPEAKER_02]  I'll help you start the exam before you see the doctor today.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "output_root = \"./recordings/\"\n",
    "dz_paths = glob(output_root + '*/*/capspeaker.txt')\n",
    "\n",
    "with open(dz_paths[0], \"r\") as txt:\n",
    "    dialogues = txt.read()\n",
    "    dialogues = dialogues.splitlines()\n",
    "dialogues[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue contains : 4 speakers\n",
      "{'SPEAKER_00', 'SPEAKER_02', 'SPEAKER_01', 'SPEAKER_03'}\n",
      "removed 281 lines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"[SPEAKER_02]  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.\",\n",
       " '[SPEAKER_03]  It just set up.',\n",
       " \"[SPEAKER_02]  We'll get you set up in the chair.\",\n",
       " \"[SPEAKER_03]  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.\",\n",
       " \"[SPEAKER_02]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\",\n",
       " '[SPEAKER_03]  O-Z-D-V-K.  Good.  O-Z-D-V-K.  Good.  O-Z-D-V-K.  Good.',\n",
       " '[SPEAKER_02]  Good. Anything here on this line or is this a little too blurry?',\n",
       " \"[SPEAKER_03]  guy.  too blurry.  W-Z-O-D-C?  Sorry, that's an F.  too blurry.  W-Z-O-D-C?  Sorry, that's an F.\",\n",
       " '[SPEAKER_02]  guys.',\n",
       " '[SPEAKER_03]  Okay, perfect.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diarization_utils import CaptionCleaner, millisec, timeStr\n",
    "\n",
    "cleaner = CaptionCleaner()\n",
    "cleaned = cleaner.condense(dialogues)\n",
    "cleaned[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing diarization misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 334 diarizations\n"
     ]
    }
   ],
   "source": [
    "dz_paths = glob(output_root + '*/*/diarization.txt')\n",
    "print(f'found {len(dz_paths)} diarizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/diarization.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[ 00:00:01.960 -->  00:00:02.996] A SPEAKER_02',\n",
       " '[ 00:00:04.337 -->  00:00:05.441] B SPEAKER_02',\n",
       " '[ 00:00:05.899 -->  00:00:06.799] C SPEAKER_02',\n",
       " '[ 00:00:07.852 -->  00:00:11.977] D SPEAKER_02',\n",
       " '[ 00:00:12.096 -->  00:00:12.911] E SPEAKER_03',\n",
       " '[ 00:00:12.911 -->  00:00:14.134] F SPEAKER_02',\n",
       " '[ 00:00:15.984 -->  00:00:17.546] G SPEAKER_03',\n",
       " '[ 00:00:20.993 -->  00:00:22.843] H SPEAKER_03',\n",
       " '[ 00:00:23.047 -->  00:00:23.488] I SPEAKER_03',\n",
       " '[ 00:00:28.446 -->  00:00:29.363] J SPEAKER_03']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dzs = open(dz_paths[0]).read().splitlines()\n",
    "print(dz_paths[0])\n",
    "dzs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ 00:00:01.960 -->  00:00:02.996] A SPEAKER_02', '[ 00:00:04.337 -->  00:00:05.441] B SPEAKER_02', '[ 00:00:05.899 -->  00:00:06.799] C SPEAKER_02', '[ 00:00:07.852 -->  00:00:11.977] D SPEAKER_02']\n",
      "['[ 00:00:12.096 -->  00:00:12.911] E SPEAKER_03']\n",
      "['[ 00:00:12.911 -->  00:00:14.134] F SPEAKER_02']\n",
      "['[ 00:00:15.984 -->  00:00:17.546] G SPEAKER_03', '[ 00:00:20.993 -->  00:00:22.843] H SPEAKER_03', '[ 00:00:23.047 -->  00:00:23.488] I SPEAKER_03', '[ 00:00:28.446 -->  00:00:29.363] J SPEAKER_03', '[ 00:00:29.533 -->  00:00:29.702] K SPEAKER_03']\n",
      "['[ 00:00:38.208 -->  00:00:46.375] L SPEAKER_02']\n",
      "['[ 00:00:47.003 -->  00:00:50.110] M SPEAKER_03', '[ 00:00:50.466 -->  00:00:50.534] N SPEAKER_03']\n",
      "['[ 00:00:50.534 -->  00:00:53.913] O SPEAKER_02']\n",
      "['[ 00:00:50.568 -->  00:00:50.806] P SPEAKER_03']\n",
      "['[ 00:00:53.166 -->  00:00:58.531] Q SPEAKER_03']\n",
      "['[ 00:00:58.123 -->  00:00:58.378] R SPEAKER_02']\n",
      "['[ 00:00:58.870 -->  00:00:59.804] S SPEAKER_03']\n",
      "['[ 00:00:59.821 -->  00:01:01.842] T SPEAKER_02', '[ 00:01:03.302 -->  00:01:03.828] U SPEAKER_02', '[ 00:01:04.541 -->  00:01:10.976] V SPEAKER_02']\n",
      "['[ 00:01:05.458 -->  00:01:05.509] W SPEAKER_03']\n",
      "['[ 00:01:05.509 -->  00:01:05.577] X SPEAKER_00']\n",
      "['[ 00:01:08.531 -->  00:01:08.599] Y SPEAKER_00']\n",
      "['[ 00:01:12.843 -->  00:01:12.860] Z SPEAKER_02']\n",
      "['[ 00:01:12.860 -->  00:01:13.641] AA SPEAKER_03', '[ 00:01:14.168 -->  00:01:15.033] AB SPEAKER_03']\n",
      "['[ 00:01:15.033 -->  00:01:16.629] AC SPEAKER_02']\n",
      "['[ 00:01:15.050 -->  00:01:22.538] AD SPEAKER_03']\n",
      "['[ 00:01:20.959 -->  00:01:22.555] AE SPEAKER_02']\n",
      "['[ 00:01:22.555 -->  00:01:22.623] AF SPEAKER_03', '[ 00:01:23.081 -->  00:01:24.371] AG SPEAKER_03']\n",
      "['[ 00:01:24.117 -->  00:01:28.531] AH SPEAKER_02']\n",
      "['[ 00:01:28.123 -->  00:01:29.957] AI SPEAKER_03']\n",
      "['[ 00:01:31.451 -->  00:01:33.064] AJ SPEAKER_02']\n",
      "['[ 00:01:33.539 -->  00:01:36.239] AK SPEAKER_03', '[ 00:01:36.561 -->  00:01:37.546] AL SPEAKER_03']\n",
      "['[ 00:01:37.444 -->  00:01:38.752] AM SPEAKER_02']\n",
      "['[ 00:01:38.310 -->  00:01:42.079] AN SPEAKER_03']\n",
      "['[ 00:01:43.488 -->  00:01:47.325] AO SPEAKER_02', '[ 00:01:52.979 -->  00:01:57.207] AP SPEAKER_02']\n",
      "['[ 00:01:56.629 -->  00:01:58.650] AQ SPEAKER_03']\n",
      "['[ 00:02:00.161 -->  00:02:02.504] AR SPEAKER_02']\n",
      "['[ 00:02:02.555 -->  00:02:05.203] AS SPEAKER_03']\n",
      "['[ 00:02:06.697 -->  00:02:08.616] AT SPEAKER_02']\n",
      "['[ 00:02:08.412 -->  00:02:11.434] AU SPEAKER_03', '[ 00:02:12.487 -->  00:02:13.505] AV SPEAKER_03']\n",
      "['[ 00:02:13.251 -->  00:02:14.592] AW SPEAKER_02', '[ 00:02:22.266 -->  00:02:31.146] AX SPEAKER_02', '[ 00:02:31.179 -->  00:02:36.120] AY SPEAKER_02']\n",
      "['[ 00:02:35.594 -->  00:02:36.086] AZ SPEAKER_01']\n",
      "['[ 00:02:36.120 -->  00:02:36.426] BA SPEAKER_01', '[ 00:02:36.918 -->  00:02:37.784] BB SPEAKER_01']\n",
      "['[ 00:02:37.784 -->  00:02:41.230] BC SPEAKER_02', '[ 00:02:42.775 -->  00:02:46.120] BD SPEAKER_02', '[ 00:02:47.003 -->  00:02:50.331] BE SPEAKER_02']\n",
      "['[ 00:02:51.587 -->  00:02:52.317] BF SPEAKER_01']\n",
      "['[ 00:02:52.487 -->  00:02:53.319] BG SPEAKER_02']\n",
      "['[ 00:02:55.220 -->  00:02:55.271] BH SPEAKER_01']\n",
      "['[ 00:02:55.882 -->  00:02:56.561] BI SPEAKER_02', '[ 00:02:58.786 -->  00:02:59.482] BJ SPEAKER_02']\n",
      "['[ 00:03:01.468 -->  00:03:03.573] BK SPEAKER_01']\n",
      "['[ 00:03:02.300 -->  00:03:03.115] BL SPEAKER_02']\n",
      "['[ 00:03:06.103 -->  00:03:06.986] BM SPEAKER_02']\n",
      "['[ 00:03:08.395 -->  00:03:10.415] BN SPEAKER_01']\n",
      "['[ 00:03:09.193 -->  00:03:09.787] BO SPEAKER_02']\n",
      "['[ 00:03:11.960 -->  00:03:17.275] BP SPEAKER_02']\n",
      "['[ 00:03:17.037 -->  00:03:17.054] BQ SPEAKER_01']\n",
      "['[ 00:03:18.191 -->  00:03:20.755] BR SPEAKER_02', '[ 00:03:21.230 -->  00:03:21.281] BS SPEAKER_02', '[ 00:03:21.910 -->  00:03:22.606] BT SPEAKER_02', '[ 00:03:23.132 -->  00:03:23.166] BU SPEAKER_02']\n",
      "['[ 00:03:23.166 -->  00:03:23.556] BV SPEAKER_03']\n",
      "['[ 00:03:23.556 -->  00:03:23.658] BW SPEAKER_02']\n",
      "['[ 00:03:23.658 -->  00:03:23.794] BX SPEAKER_03']\n",
      "['[ 00:03:23.794 -->  00:03:25.390] BY SPEAKER_02']\n",
      "['[ 00:03:23.845 -->  00:03:27.852] BZ SPEAKER_03']\n",
      "['[ 00:03:29.465 -->  00:03:34.015] CA SPEAKER_02']\n",
      "['[ 00:03:30.093 -->  00:03:30.449] CB SPEAKER_03']\n",
      "['[ 00:03:34.660 -->  00:03:34.694] CC SPEAKER_01']\n",
      "['[ 00:03:35.288 -->  00:03:36.222] CD SPEAKER_02']\n",
      "['[ 00:03:37.784 -->  00:03:38.769] CE SPEAKER_01']\n",
      "['[ 00:03:38.582 -->  00:03:39.210] CF SPEAKER_02']\n",
      "['[ 00:03:40.297 -->  00:03:40.823] CG SPEAKER_01', '[ 00:03:40.857 -->  00:03:41.146] CH SPEAKER_01']\n",
      "['[ 00:03:40.908 -->  00:03:44.286] CI SPEAKER_02']\n",
      "['[ 00:03:42.487 -->  00:03:42.962] CJ SPEAKER_01']\n",
      "['[ 00:03:46.290 -->  00:03:46.375] CK SPEAKER_01']\n",
      "['[ 00:03:46.375 -->  00:03:47.682] CL SPEAKER_02']\n",
      "['[ 00:03:48.514 -->  00:03:49.363] CM SPEAKER_01']\n",
      "['[ 00:03:49.363 -->  00:03:50.365] CN SPEAKER_02']\n",
      "['[ 00:03:52.470 -->  00:03:52.504] CO SPEAKER_01']\n",
      "['[ 00:03:52.504 -->  00:03:53.149] CP SPEAKER_02', '[ 00:03:55.543 -->  00:03:56.324] CQ SPEAKER_02']\n",
      "['[ 00:03:58.208 -->  00:03:59.040] CR SPEAKER_01']\n",
      "['[ 00:03:59.040 -->  00:03:59.634] CS SPEAKER_02']\n",
      "['[ 00:03:59.057 -->  00:03:59.193] CT SPEAKER_03']\n",
      "['[ 00:04:01.264 -->  00:04:04.983] CU SPEAKER_02']\n",
      "['[ 00:04:04.558 -->  00:04:06.137] CV SPEAKER_03']\n",
      "['[ 00:04:07.784 -->  00:04:10.840] CW SPEAKER_02']\n",
      "['[ 00:04:10.365 -->  00:04:14.711] CX SPEAKER_03', '[ 00:04:15.186 -->  00:04:16.086] CY SPEAKER_03']\n",
      "['[ 00:04:16.086 -->  00:04:20.432] CZ SPEAKER_02']\n",
      "['[ 00:04:16.120 -->  00:04:16.833] DA SPEAKER_03']\n",
      "['[ 00:04:22.079 -->  00:04:23.709] DB SPEAKER_02']\n",
      "['[ 00:04:24.592 -->  00:04:29.804] DC SPEAKER_03']\n",
      "['[ 00:04:28.921 -->  00:04:33.947] DD SPEAKER_02']\n",
      "['[ 00:04:32.062 -->  00:04:32.334] DE SPEAKER_03']\n",
      "['[ 00:04:34.473 -->  00:04:39.295] DF SPEAKER_03', '[ 00:04:40.008 -->  00:04:40.076] DG SPEAKER_03', '[ 00:04:40.636 -->  00:04:41.383] DH SPEAKER_03']\n",
      "['[ 00:04:40.755 -->  00:04:44.983] DI SPEAKER_02']\n",
      "['[ 00:04:44.983 -->  00:04:46.103] DJ SPEAKER_03']\n",
      "['[ 00:04:46.103 -->  00:04:47.818] DK SPEAKER_02']\n",
      "['[ 00:04:47.088 -->  00:04:50.076] DL SPEAKER_03']\n",
      "['[ 00:04:49.787 -->  00:04:50.942] DM SPEAKER_02', '[ 00:04:52.724 -->  00:04:55.169] DN SPEAKER_02']\n",
      "['[ 00:04:54.490 -->  00:04:54.983] DO SPEAKER_03']\n",
      "['[ 00:04:55.169 -->  00:04:55.254] DP SPEAKER_03']\n",
      "['[ 00:04:55.254 -->  00:04:55.271] DQ SPEAKER_02', '[ 00:04:56.595 -->  00:05:02.843] DR SPEAKER_02']\n",
      "['[ 00:05:05.848 -->  00:05:06.494] DS SPEAKER_01']\n",
      "['[ 00:05:06.494 -->  00:05:11.638] DT SPEAKER_02']\n",
      "['[ 00:05:12.741 -->  00:05:20.042] DU SPEAKER_03', '[ 00:05:20.755 -->  00:05:21.162] DV SPEAKER_03']\n",
      "['[ 00:05:21.162 -->  00:05:28.701] DW SPEAKER_02']\n",
      "['[ 00:05:21.468 -->  00:05:21.859] DX SPEAKER_03']\n",
      "['[ 00:05:24.151 -->  00:05:25.000] DY SPEAKER_03']\n",
      "['[ 00:05:26.409 -->  00:05:26.765] DZ SPEAKER_03']\n",
      "['[ 00:05:28.005 -->  00:05:28.022] EA SPEAKER_00']\n",
      "['[ 00:05:29.533 -->  00:05:30.602] EB SPEAKER_00']\n"
     ]
    }
   ],
   "source": [
    "def deduplicate(groups):\n",
    "    old = []\n",
    "    deduped = []\n",
    "    for g in groups:\n",
    "        if old != g:\n",
    "            old = g\n",
    "            deduped.append(g)\n",
    "    return deduped\n",
    "\n",
    "groups = []\n",
    "g = []\n",
    "lastend = 0\n",
    "for d in dzs:\n",
    "    # same speaker\n",
    "    if g and (g[0].split()[-1] != d.split()[-1]): \n",
    "        groups.append(g)\n",
    "        g = []\n",
    "    \n",
    "    g.append(d)\n",
    "    \n",
    "    end = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=d)[1]\n",
    "    end = millisec(end)\n",
    "    if (lastend > end):     #segment engulfed by a previous segment\n",
    "        groups.append(g)\n",
    "        g = []\n",
    "    else:\n",
    "        lastend = end\n",
    "    if g:\n",
    "        groups.append(g)\n",
    "groups = deduplicate(groups)\n",
    "print(*groups, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading wav file: ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/input_prep.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "fpath = '/'.join(dz_paths[0].split('/')[:-1])\n",
    "print(f'reading wav file: {fpath + \"/input_prep.wav\"}')\n",
    "audio = AudioSegment.from_wav(fpath + \"/input_prep.wav\")\n",
    "gidx = -1\n",
    "for g in groups:\n",
    "    start = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[0])[0]\n",
    "    end = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[-1])[1]\n",
    "    start = millisec(start)\n",
    "    end = millisec(end)\n",
    "    gidx += 1\n",
    "    audio[start:end].export(fpath + '/' + str(gidx) + '.wav', format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = whisper.load_model('large', device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    audiof = fpath + '/' + str(i) + '.wav'\n",
    "    result = model.transcribe(audio=audiof, language='en', word_timestamps=True)#, initial_prompt=result.get('text', \"\"))\n",
    "    with open(fpath + '/' + str(i)+'.json', \"w\") as outfile:\n",
    "        json.dump(result, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diarization_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n",
      "captions saved to /./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt:\n",
      "html saved to ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.html:\n"
     ]
    }
   ],
   "source": [
    "spacermilli = 2000\n",
    "speakers = {'SPEAKER_00':('SPEAKER_00', '#e1ffc7', 'darkgreen'), 'SPEAKER_01':('SPEAKER_01', 'white', 'darkorange') }\n",
    "def_boxclr = 'white'\n",
    "def_spkrclr = 'orange'\n",
    "html = list(preS)\n",
    "txt = list(\"\")\n",
    "gidx = -1\n",
    "for g in groups:  \n",
    "    shift = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[0])[0]\n",
    "    shift = millisec(shift) - spacermilli #the start time in the original video\n",
    "    shift=max(shift, 0)\n",
    "    \n",
    "    gidx += 1\n",
    "    \n",
    "    captions = json.load(open(fpath + '/' + str(gidx) + '.json'))['segments']\n",
    "\n",
    "    if captions:\n",
    "        speaker = g[0].split()[-1]\n",
    "        boxclr = def_boxclr\n",
    "        spkrclr = def_spkrclr\n",
    "        if speaker in speakers:\n",
    "            speaker, boxclr, spkrclr = speakers[speaker] \n",
    "    \n",
    "        html.append(f'<div class=\"e\" style=\"background-color: {boxclr}\">\\n');\n",
    "        html.append('<p  style=\"margin:0;padding: 5px 10px 10px 10px;word-wrap:normal;white-space:normal;\">\\n')\n",
    "        html.append(f'<span style=\"color:{spkrclr};font-weight: bold;\">{speaker}</span><br>\\n\\t\\t\\t\\t')\n",
    "        \n",
    "        for c in captions:\n",
    "            start = shift + c['start'] * 1000.0 \n",
    "            start = start / 1000.0   #time resolution ot youtube is Second.            \n",
    "            end = (shift + c['end'] * 1000.0) / 1000.0      \n",
    "            txt.append(f'[{timeStr(start)} --> {timeStr(end)}] [{speaker}] {c[\"text\"]}\\n')\n",
    "\n",
    "            for i, w in enumerate(c['words']):\n",
    "                if w == \"\":\n",
    "                    continue\n",
    "                start = (shift + w['start']*1000.0) / 1000.0        \n",
    "                #end = (shift + w['end']) / 1000.0   #time resolution ot youtube is Second.  \n",
    "                html.append(f'<a href=\"#{timeStr(start)}\" id=\"{\"{:.1f}\".format(round(start*5)/5)}\" class=\"lt\" onclick=\"jumptoTime({int(start)}, this.id)\">{w[\"word\"]}</a><!--\\n\\t\\t\\t\\t-->')\n",
    "            #html.append('\\n')      \n",
    "            html.append('</p>\\n')\n",
    "            html.append(f'</div>\\n')\n",
    "\n",
    "        html.append(postS)\n",
    "\n",
    "        capclean = CaptionCleaner()\n",
    "        with open(f\"{fpath}/capspeaker.txt\", \"w\", encoding='utf-8') as file:\n",
    "            s = \"\".join(txt)\n",
    "            file.write(s)\n",
    "            print(f'captions saved to /{fpath}/capspeaker.txt:')\n",
    "        with open(f\"{fpath}/capspeaker.html\", \"w\", encoding='utf-8') as file:    #TODO: proper html embed tag when video/audio from file\n",
    "            s = \"\".join(html)\n",
    "            file.write(s)\n",
    "            print(f'html saved to {fpath}/capspeaker.html:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/miniconda3/envs/diarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/digitalopt/proj/diarization/recordings/RT-JJara/1040390_6190_VC_1_1_29_11_2023_14_17_42/capspeaker.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from diarization_utils import CaptionCleaner\n",
    "\n",
    "output_root = \"/home/digitalopt/proj/diarization/recordings/\"\n",
    "cap_paths = glob(output_root + '*/*/capspeaker.txt')\n",
    "\n",
    "cap_paths.sort()\n",
    "cap_paths[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcleaner\u001b[49m\u001b[38;5;241m.\u001b[39mNER \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaner' is not defined"
     ]
    }
   ],
   "source": [
    "cleaner.NER == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy model en_core_web_trf loaded\n",
      "removed 75 lines.\n",
      "Dialogue contains : 5 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 486\n",
      "speaker: SPEAKER_01, words spoken: 109\n",
      "speaker: SPEAKER_00, words spoken: 98\n",
      "speaker: SPEAKER_04, words spoken: 46\n",
      "speaker: SPEAKER_03, words spoken: 320\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_04', 46), ('SPEAKER_00', 98), ('SPEAKER_01', 109), ('SPEAKER_03', 320), ('SPEAKER_02', 486)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/1040390_6190_VC_1_1_29_11_2023_14_17_42/capspeaker.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "truncated speaker list: ['SPEAKER_01', 'SPEAKER_03', 'SPEAKER_02']\n",
      "speaker mapping <spaker in data> : <new spaker label>\n",
      "{'SPEAKER_01': 'LocalTech', 'SPEAKER_03': 'Patient__', 'SPEAKER_02': 'Assistant'}\n",
      "removing names...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"[Assistant]  Hi, how's everyone doing today?\",\n",
       " \"[LocalTech]  How's everyone doing today?  Good. How are you?\",\n",
       " '[Assistant]  Doing great.',\n",
       " '[LocalTech]  Doing great.',\n",
       " \"[Assistant]  Is this [NAME]? Yes, ma'am. Nice to meet you. My name is [NAME]. I'll help you start your exam before you see the doctor today.\",\n",
       " \"[LocalTech]  Nice to meet you.  My name is [NAME].  I'll help you start your exam before you see the doctor.\",\n",
       " '[LocalTech]',\n",
       " \"[SPEAKER_02]  And we'll get you set up in the chair first.\",\n",
       " '[SPEAKER_00]  set up in the chair first.',\n",
       " \"[SPEAKER_01]  Is that comfortable?  You think?  Yeah.  Yeah, I'm gonna fix your feet.  Okay, thanks.  You're welcome.  You're welcome.  Can I go in on his left eye a tad bit?\",\n",
       " '[SPEAKER_02]  Yeah, sure. Is this better?  Yes.',\n",
       " \"[SPEAKER_01]  You're going to.\",\n",
       " '[SPEAKER_04]  Eyelashes are important.',\n",
       " '[SPEAKER_01]  I know they point down.  Does that feel comfortable?  Yeah.  He looks good.  Okay, thank you.  Thank you.',\n",
       " \"[SPEAKER_02]  Okay, thank you.  OK, so we'll start.  You're going to see three lines of letters.  Without squinting, what's the lowest one you're able to read?\",\n",
       " \"[SPEAKER_01]  Okay, so we'll start.  You're gonna see three lines of letters  without squinting.\",\n",
       " \"[SPEAKER_03]  What's the lowest one you're able to read?  DKVCN.\",\n",
       " '[SPEAKER_02]  Good. Are you able to read this one?',\n",
       " '[SPEAKER_03]  Are you able to read this one?  Yeah, D-O-N-K-B.',\n",
       " '[SPEAKER_02]  Good. Anything here?',\n",
       " \"[SPEAKER_03]  any  Thank you.  I'm like seeing three, but from what I see it looks like BHKCN.\",\n",
       " \"[SPEAKER_02]  Good. Now I'm going to block the left eye for you.  So this time with the right eye.  Again, the lowest that you're able to.\",\n",
       " \"[SPEAKER_03]  Now I'm going to block the left\",\n",
       " '[SPEAKER_00]  Bye.',\n",
       " '[SPEAKER_03]  for you.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = CaptionCleaner()    \n",
    "captions = cleaner.read_captions(cap_paths[1])\n",
    "cleaned = cleaner.clean(captions)\n",
    "cleaned[:25]\n",
    "# outfile = '/'.join(cap_paths[0].split('/')[:-1]) + '/cleaner_caps.txt'\n",
    "# with open(outfile, 'w') as file:\n",
    "#     output = '\\n'.join(cleaned)\n",
    "#     file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[Assistant]  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.\",\n",
       " '[Patient__]  It just set up.',\n",
       " \"[Assistant]  We'll get you set up in the chair.\",\n",
       " \"[Patient__]  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.\",\n",
       " \"[Assistant]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\",\n",
       " '[Patient__]  O-Z-D-V-K.  Good.',\n",
       " '[Assistant]  Good. Anything here on this line or is this a little too blurry?',\n",
       " \"[Patient__]  guy.  too blurry.  W-Z-O-D-C?  Sorry, that's an F.\",\n",
       " '[Assistant]  guys.',\n",
       " '[Patient__]  Okay, perfect.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SPEAKER_02]  How are you doing today?',\n",
       " '[SPEAKER_02]  Doing great.',\n",
       " '[SPEAKER_02]  Doing great.',\n",
       " '[SPEAKER_02]  Is your name Brittany?',\n",
       " '[SPEAKER_02]  Is your name Brittany?']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing1 = cleaner.remove_time(captions)\n",
    "thing1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SPEAKER_02]  How are you doing today?',\n",
       " '[SPEAKER_02]  Doing great.',\n",
       " '[SPEAKER_02]  Is your name Brittany?',\n",
       " '[SPEAKER_02]  Okay, perfect.',\n",
       " \"[SPEAKER_02]  I'm Jessica.\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing2 = cleaner.deduplicate(thing1)\n",
    "thing2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SPEAKER_02]  How are you doing today?',\n",
       " '[SPEAKER_02]  Doing great.',\n",
       " '[SPEAKER_02]  Is your name Brittany?',\n",
       " '[SPEAKER_02]  Okay, perfect.',\n",
       " \"[SPEAKER_02]  I'm Jessica.\",\n",
       " '[SPEAKER_02]  Okay, perfect.',\n",
       " \"[SPEAKER_02]  I'm Jessica.\",\n",
       " \"[SPEAKER_02]  I'll help you start the exam before you see the doctor today.\",\n",
       " '[SPEAKER_02]  Okay.',\n",
       " '[SPEAKER_03]  It just set up.',\n",
       " \"[SPEAKER_02]  We'll get you set up in the chair.\",\n",
       " '[SPEAKER_03]  And then are you sitting comfortable?',\n",
       " '[SPEAKER_03]  Yeah.',\n",
       " '[SPEAKER_03]  Bear with me.',\n",
       " \"[SPEAKER_03]  I'm still training on this part.\",\n",
       " \"[SPEAKER_03]  You're good.\",\n",
       " '[SPEAKER_03]  Is that okay?',\n",
       " '[SPEAKER_03]  Yeah.',\n",
       " \"[SPEAKER_02]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\",\n",
       " '[SPEAKER_03]  O-Z-D-V-K.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[SPEAKER_02]  How are you doing today?  Doing great.  Is your name Brittany?  Okay, perfect.  I'm Jessica.  Okay, perfect.  I'm Jessica.  I'll help you start the exam before you see the doctor today.  Okay.\",\n",
       " '[SPEAKER_03]  It just set up.',\n",
       " \"[SPEAKER_02]  We'll get you set up in the chair.\",\n",
       " \"[SPEAKER_03]  And then are you sitting comfortable?  Yeah.  Bear with me.  I'm still training on this part.  You're good.  Is that okay?  Yeah.\",\n",
       " \"[SPEAKER_02]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\",\n",
       " '[SPEAKER_03]  O-Z-D-V-K.  Good.',\n",
       " '[SPEAKER_02]  Good. Anything here on this line or is this a little too blurry?',\n",
       " \"[SPEAKER_03]  guy.  too blurry.  W-Z-O-D-C?  Sorry, that's an F.\",\n",
       " '[SPEAKER_02]  guys.',\n",
       " '[SPEAKER_03]  Okay, perfect.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def condense(txt):\n",
    "    condensed = []\n",
    "    old_speaker = ''\n",
    "    line = ''\n",
    "    for idx in range(len(txt)):\n",
    "        speaker = txt[idx][1:11]\n",
    "        if old_speaker == speaker:\n",
    "            line += txt[idx][12:]\n",
    "        else:\n",
    "            if line != '':\n",
    "                condensed.append(line)\n",
    "            old_speaker = speaker\n",
    "            line = f'[{speaker}]'\n",
    "            line += txt[idx][12:]\n",
    "    return condensed\n",
    "\n",
    "thing3 = condense(thing2)\n",
    "thing3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After manually editing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/miniconda3/envs/diarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from diarization_utils import CaptionCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/datasets/diarization_recordings/processed_recordings/'\n",
    "jjara = data_dir + 'RT-JJara/'\n",
    "stephens = data_dir + 'rt-lstephens/'\n",
    "brokus = data_dir + 'rt-sbrokus/'\n",
    "\n",
    "jjara = glob(jjara + '*/reviewed_caps.txt')\n",
    "stephens = glob(stephens + '*/reviewed_caps.txt')\n",
    "brokus = glob(brokus + '*/reviewed_caps.txt')\n",
    "for i in [jjara, stephens, brokus]:\n",
    "    print (len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "new_root = '/data/datasets/Exam_v3/'\n",
    "cnt = 30\n",
    "for fgrp in [jjara, stephens, brokus]:\n",
    "    for f in fgrp:\n",
    "        if cnt % 3 != 0:\n",
    "            fpath = new_root + 'val/' + str(cnt).zfill(6) + '.txt'\n",
    "            shutil.copy(f,fpath)\n",
    "        else: \n",
    "            fpath = new_root + 'test/' + str(cnt).zfill(6) + '.txt'\n",
    "            shutil.copy(f,fpath)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy model en_core_web_trf loaded\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/capspeaker.txt\n",
      "removed 74 lines.\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 539\n",
      "speaker: SPEAKER_03, words spoken: 210\n",
      "speaker: SPEAKER_01, words spoken: 33\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 33), ('SPEAKER_03', 210), ('SPEAKER_02', 539)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/595841_4602_VC_1_1_01_12_2023_14_34_27/capspeaker.txt\n",
      "removed 32 lines.\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 4 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 405\n",
      "speaker: SPEAKER_01, words spoken: 46\n",
      "speaker: SPEAKER_02, words spoken: 61\n",
      "speaker: SPEAKER_00, words spoken: 1\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 1), ('SPEAKER_01', 46), ('SPEAKER_02', 61), ('SPEAKER_03', 405)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/595841_4602_VC_1_1_01_12_2023_14_34_27/capspeaker.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "new speaker list: ['SPEAKER_01', 'SPEAKER_02', 'SPEAKER_03']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SPEAKER_00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/digitalopt/proj/diarization/diary2dataset.ipynb Cell 22\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/digitalopt/proj/diarization/diary2dataset.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreading \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/digitalopt/proj/diarization/diary2dataset.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m captions \u001b[39m=\u001b[39m cleaner\u001b[39m.\u001b[39mread_captions(p)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/digitalopt/proj/diarization/diary2dataset.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cleaned \u001b[39m=\u001b[39m cleaner\u001b[39m.\u001b[39;49mclean(captions)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/digitalopt/proj/diarization/diary2dataset.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outfile \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(p\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/cleaner_caps.txt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/digitalopt/proj/diarization/diary2dataset.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cleaner\u001b[39m.\u001b[39mwrite_captions(cleaned, outfile)\n",
      "File \u001b[0;32m~/proj/diarization/diarization_utils.py:81\u001b[0m, in \u001b[0;36mCaptionCleaner.clean\u001b[0;34m(self, txt)\u001b[0m\n\u001b[1;32m     79\u001b[0m txt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondense(txt)\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspeaker_cnt(txt)\n\u001b[0;32m---> 81\u001b[0m txt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremap_speaker_names(txt, for_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNER:\n\u001b[1;32m     83\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mremoving names...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/proj/diarization/diarization_utils.py:137\u001b[0m, in \u001b[0;36mCaptionCleaner.remap_speaker_names\u001b[0;34m(self, captions, for_train)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m# use mapping to rename speakers in each caption line.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(captions)):\n\u001b[0;32m--> 137\u001b[0m     captions[idx] \u001b[39m=\u001b[39m captions[idx]\u001b[39m.\u001b[39mreplace(captions[idx][\u001b[39m1\u001b[39m:\u001b[39m11\u001b[39m], new_speaker[captions[idx][\u001b[39m1\u001b[39;49m:\u001b[39m11\u001b[39;49m]])\n\u001b[1;32m    138\u001b[0m \u001b[39mreturn\u001b[39;00m captions\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SPEAKER_00'"
     ]
    }
   ],
   "source": [
    "cleaner = CaptionCleaner()\n",
    "cleaner.load_NER_model()\n",
    "output_root = \"/home/digitalopt/proj/diarization/recordings/\"\n",
    "cap_paths = glob(output_root + '*/*/capspeaker.txt')\n",
    "for p in cap_paths:\n",
    "    print(f'reading {p}')\n",
    "    captions = cleaner.read_captions(p)\n",
    "    cleaned = cleaner.clean(captions)\n",
    "    outfile = '/'.join(p.split('/')[:-1]) + '/cleaner_caps.txt'\n",
    "    cleaner.write_captions(cleaned, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remapping speaker names:\n",
    "\n",
    "- SPEAKER_00 : local tech\n",
    "- SPEAKER_01 : patient\n",
    "- SPEAKER_02 : assistant\n",
    "\n",
    "if speaker had greatest words spoken, they are the assistant.\n",
    "if speaker had 2nd most words, they are the patient\n",
    "if speaker spoke the least, they are the local tech.\n",
    "\n",
    "first, identify the speaker names and words spoken in the caption set.\n",
    "second, map the speaker names to new identifiers\n",
    "second, for each caption, identify the speaker and replace the speaker name according to the new mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[SPEAKER_02]  How are you doing today?', '[SPEAKER_03]  Doing great.', '[SPEAKER_02]  Is your name Brittany?', '[SPEAKER_03]  Yes.', \"[SPEAKER_02]  Okay, perfect.  I'm Jessica. I'll help you start the exam before you see the doctor today. We'll get you set up in the chair.\", '[SPEAKER_01]  And then are you sitting comfortable?']\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 23), ('SPEAKER_03', 121), ('SPEAKER_02', 514)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[SPEAKER_02]  How are you doing today?',\n",
       " '[SPEAKER_01]  Doing great.',\n",
       " '[SPEAKER_02]  Is your name Brittany?',\n",
       " '[SPEAKER_01]  Yes.',\n",
       " \"[SPEAKER_02]  Okay, perfect.  I'm Jessica. I'll help you start the exam before you see the doctor today. We'll get you set up in the chair.\",\n",
       " '[SPEAKER_00]  And then are you sitting comfortable?',\n",
       " '[SPEAKER_01]  Yeah.',\n",
       " \"[SPEAKER_00]  Bear with me.  I'm still training on this part.  You're good.  Is that okay?\",\n",
       " '[SPEAKER_01]  Yeah.',\n",
       " \"[SPEAKER_02]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions2 = captions.copy()\n",
    "print(captions2[:6])\n",
    "thing = cleaner.remap_speaker_names(captions2)\n",
    "thing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 514\n",
      "speaker: SPEAKER_03, words spoken: 121\n",
      "speaker: SPEAKER_01, words spoken: 23\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 23), ('SPEAKER_03', 121), ('SPEAKER_02', 514)]\n",
      "Processing ./recordings/RT-JJara/595841_4602_VC_1_1_01_12_2023_14_34_27/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 362\n",
      "speaker: SPEAKER_02, words spoken: 51\n",
      "speaker: SPEAKER_01, words spoken: 29\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 29), ('SPEAKER_02', 51), ('SPEAKER_03', 362)]\n",
      "Processing ./recordings/RT-JJara/1932708_11628_VC_1_1_04_12_2023_16_02_48/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 592\n",
      "speaker: SPEAKER_01, words spoken: 93\n",
      "speaker: SPEAKER_00, words spoken: 1\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 1), ('SPEAKER_01', 93), ('SPEAKER_02', 592)]\n",
      "Processing ./recordings/RT-JJara/2027333_1486_VC_1_1_01_12_2023_09_24_47/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 663\n",
      "speaker: SPEAKER_02, words spoken: 946\n",
      "speaker: SPEAKER_00, words spoken: 87\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 87), ('SPEAKER_01', 663), ('SPEAKER_02', 946)]\n",
      "Processing ./recordings/RT-JJara/2035583_11646_VC_1_1_30_11_2023_15_11_35/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 1110\n",
      "speaker: SPEAKER_02, words spoken: 286\n",
      "speaker: SPEAKER_00, words spoken: 11\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 11), ('SPEAKER_02', 286), ('SPEAKER_01', 1110)]\n",
      "Processing ./recordings/RT-JJara/2034790_12362_VC_1_1_01_12_2023_11_44_45/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 533\n",
      "speaker: SPEAKER_00, words spoken: 111\n",
      "speaker: SPEAKER_01, words spoken: 94\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 94), ('SPEAKER_00', 111), ('SPEAKER_02', 533)]\n",
      "Processing ./recordings/RT-JJara/17885_428_VC_1_1_28_11_2023_15_20_01/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 486\n",
      "speaker: SPEAKER_01, words spoken: 104\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 104), ('SPEAKER_00', 486)]\n",
      "Processing ./recordings/RT-JJara/798404_4858_VC_1_1_05_12_2023_10_34_26/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 1528\n",
      "speaker: SPEAKER_00, words spoken: 19\n",
      "speaker: SPEAKER_02, words spoken: 1193\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 19), ('SPEAKER_02', 1193), ('SPEAKER_01', 1528)]\n",
      "Processing ./recordings/RT-JJara/2037112_5400_VC_1_1_01_12_2023_09_59_40/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 2267\n",
      "speaker: SPEAKER_00, words spoken: 385\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 385), ('SPEAKER_01', 2267)]\n",
      "Processing ./recordings/RT-JJara/2035607_861_VC_1_1_30_11_2023_14_17_39/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 108\n",
      "speaker: SPEAKER_02, words spoken: 1585\n",
      "speaker: SPEAKER_00, words spoken: 210\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 108), ('SPEAKER_00', 210), ('SPEAKER_02', 1585)]\n",
      "Processing ./recordings/rt-lstephens/1442410_6967_VC_1_1_01_12_2023_18_35_50/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 92\n",
      "speaker: SPEAKER_02, words spoken: 453\n",
      "speaker: SPEAKER_00, words spoken: 21\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 21), ('SPEAKER_01', 92), ('SPEAKER_02', 453)]\n",
      "Processing ./recordings/rt-lstephens/180186_1772_VC_1_1_04_12_2023_11_49_44/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 464\n",
      "speaker: SPEAKER_01, words spoken: 133\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 133), ('SPEAKER_03', 464)]\n",
      "Processing ./recordings/rt-lstephens/474039_726_VC_1_1_05_12_2023_10_43_41/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 158\n",
      "speaker: SPEAKER_04, words spoken: 500\n",
      "speaker: SPEAKER_03, words spoken: 33\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 33), ('SPEAKER_02', 158), ('SPEAKER_04', 500)]\n",
      "Processing ./recordings/rt-lstephens/696884_5310_VC_1_1_05_12_2023_11_16_56/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_04, words spoken: 466\n",
      "speaker: SPEAKER_02, words spoken: 132\n",
      "speaker: SPEAKER_01, words spoken: 69\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 69), ('SPEAKER_02', 132), ('SPEAKER_04', 466)]\n",
      "Processing ./recordings/rt-lstephens/1711515_11357_VC_1_1_28_11_2023_18_25_35/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 95\n",
      "speaker: SPEAKER_01, words spoken: 502\n",
      "speaker: SPEAKER_03, words spoken: 177\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 95), ('SPEAKER_03', 177), ('SPEAKER_01', 502)]\n",
      "Processing ./recordings/rt-lstephens/973397_4715_VC_1_1_30_11_2023_17_22_09/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 456\n",
      "speaker: SPEAKER_01, words spoken: 175\n",
      "speaker: SPEAKER_03, words spoken: 35\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 35), ('SPEAKER_01', 175), ('SPEAKER_02', 456)]\n",
      "Processing ./recordings/rt-lstephens/1130238_6039_VC_1_1_01_12_2023_16_39_52/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 384\n",
      "speaker: SPEAKER_01, words spoken: 49\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 49), ('SPEAKER_02', 384)]\n",
      "Processing ./recordings/rt-lstephens/159838_1444_VC_1_1_01_12_2023_10_13_17/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 427\n",
      "speaker: SPEAKER_02, words spoken: 48\n",
      "speaker: SPEAKER_03, words spoken: 141\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 48), ('SPEAKER_03', 141), ('SPEAKER_01', 427)]\n",
      "Processing ./recordings/rt-lstephens/1052783_6838_VC_1_1_04_12_2023_15_49_25/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 379\n",
      "speaker: SPEAKER_01, words spoken: 69\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 69), ('SPEAKER_02', 379)]\n",
      "Processing ./recordings/rt-lstephens/612446_5307_VC_1_1_01_12_2023_18_03_36/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 71\n",
      "speaker: SPEAKER_01, words spoken: 378\n",
      "speaker: SPEAKER_02, words spoken: 86\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 71), ('SPEAKER_02', 86), ('SPEAKER_01', 378)]\n",
      "Processing ./recordings/rt-sbrokus/34898_571_VC_1_1_04_12_2023_11_05_51/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 581\n",
      "speaker: SPEAKER_01, words spoken: 40\n",
      "speaker: SPEAKER_02, words spoken: 147\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 40), ('SPEAKER_02', 147), ('SPEAKER_03', 581)]\n",
      "Processing ./recordings/rt-sbrokus/359862_4466_VC_1_1_04_12_2023_13_36_20/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 589\n",
      "speaker: SPEAKER_02, words spoken: 95\n",
      "speaker: SPEAKER_00, words spoken: 2\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 2), ('SPEAKER_02', 95), ('SPEAKER_01', 589)]\n",
      "Processing ./recordings/rt-sbrokus/95892_1244_VC_1_1_01_12_2023_15_27_20/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 588\n",
      "speaker: SPEAKER_02, words spoken: 98\n",
      "speaker: SPEAKER_03, words spoken: 78\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 78), ('SPEAKER_02', 98), ('SPEAKER_01', 588)]\n",
      "Processing ./recordings/rt-sbrokus/559134_5169_VC_1_1_01_12_2023_11_09_16/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 681\n",
      "speaker: SPEAKER_01, words spoken: 218\n",
      "speaker: SPEAKER_00, words spoken: 9\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 9), ('SPEAKER_01', 218), ('SPEAKER_02', 681)]\n",
      "Processing ./recordings/rt-sbrokus/163548_1814_VC_1_1_04_12_2023_12_07_16/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 72\n",
      "speaker: SPEAKER_01, words spoken: 561\n",
      "speaker: SPEAKER_03, words spoken: 75\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 72), ('SPEAKER_03', 75), ('SPEAKER_01', 561)]\n",
      "Processing ./recordings/rt-sbrokus/609869_5088_VC_1_1_04_12_2023_10_34_29/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 585\n",
      "speaker: SPEAKER_01, words spoken: 125\n",
      "speaker: SPEAKER_00, words spoken: 23\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 23), ('SPEAKER_01', 125), ('SPEAKER_02', 585)]\n",
      "Processing ./recordings/rt-sbrokus/590038_4757_VC_1_1_01_12_2023_09_21_54/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 592\n",
      "speaker: SPEAKER_00, words spoken: 51\n",
      "speaker: SPEAKER_02, words spoken: 88\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 51), ('SPEAKER_02', 88), ('SPEAKER_01', 592)]\n",
      "Processing ./recordings/rt-sbrokus/350602_785_VC_1_1_01_12_2023_15_15_57/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 495\n",
      "speaker: SPEAKER_00, words spoken: 25\n",
      "speaker: SPEAKER_01, words spoken: 39\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 25), ('SPEAKER_01', 39), ('SPEAKER_03', 495)]\n",
      "Processing ./recordings/rt-sbrokus/405969_4506_VC_1_1_01_12_2023_14_38_33/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 682\n",
      "speaker: SPEAKER_02, words spoken: 81\n",
      "speaker: SPEAKER_00, words spoken: 5\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 5), ('SPEAKER_02', 81), ('SPEAKER_03', 682)]\n",
      "Processing ./recordings/rt-sbrokus/566198_1378_VC_1_1_28_11_2023_16_38_04/clean_captions.txt\n",
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 564\n",
      "speaker: SPEAKER_02, words spoken: 68\n",
      "speaker: SPEAKER_03, words spoken: 142\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 68), ('SPEAKER_03', 142), ('SPEAKER_01', 564)]\n"
     ]
    }
   ],
   "source": [
    "def new_filepath(fpath):\n",
    "    fname = fpath.split('/')[:-1]\n",
    "    fname.append('speaker_captions.txt')\n",
    "    fname = '/'.join(fname)\n",
    "    return fname\n",
    "jjara = data_dir + 'RT-JJara/'\n",
    "jjara = glob(jjara + '*/clean_captions.txt')[:10]\n",
    "\n",
    "path_groups = [jjara, stephens, brokus]\n",
    "for group in path_groups:\n",
    "    for path in group:\n",
    "        print(f'Processing {path}')\n",
    "        newfile = new_filepath(path)\n",
    "        captions = cleaner.read_captions(path)\n",
    "        speakers = cleaner.speaker_cnt(captions)\n",
    "        captions = cleaner.remap_speaker_names(captions)\n",
    "        cleaner.write_captions(captions, newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speakers keys: dict_keys([])\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 564\n",
      "speaker: SPEAKER_02, words spoken: 68\n",
      "speaker: SPEAKER_03, words spoken: 142\n"
     ]
    }
   ],
   "source": [
    "fname = './recordings/rt-sbrokus/566198_1378_VC_1_1_28_11_2023_16_38_04/clean_captions.txt'\n",
    "captions = cleaner.read_captions(fname)\n",
    "speakers = cleaner.speaker_cnt(captions)\n",
    "# captions = cleaner.remap_speaker_names(captions)\n",
    "# cleaner.write_captions(captions, newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/miniconda3/envs/diarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_trf\n",
    "import spacy_transformers\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SPEAKER_02]  How are you doing today?',\n",
       " '[SPEAKER_03]  Doing great.',\n",
       " '[SPEAKER_02]  Is your name Brittany?',\n",
       " '[SPEAKER_03]  Yes.',\n",
       " \"[SPEAKER_02]  Okay, perfect.  I'm Jessica. I'll help you start the exam before you see the doctor today. We'll get you set up in the chair.\",\n",
       " '[SPEAKER_01]  And then are you sitting comfortable?',\n",
       " '[SPEAKER_03]  Yeah.',\n",
       " \"[SPEAKER_01]  Bear with me.  I'm still training on this part.  You're good.  Is that okay?\",\n",
       " '[SPEAKER_03]  Yeah.',\n",
       " \"[SPEAKER_02]  Thank you. Okay, so you should see three lines of letters with no squinting. What's the smallest line you're able to read?\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = cleaner.read_captions(jjara[0])\n",
    "captions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/miniconda3/envs/diarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 40 caption texts\n",
      "spacy model en_core_web_trf loaded\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2031456_11398_VC_1_1_01_12_2023_15_03_31/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 514\n",
      "speaker: SPEAKER_03, words spoken: 121\n",
      "speaker: SPEAKER_01, words spoken: 23\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 23), ('SPEAKER_03', 121), ('SPEAKER_02', 514)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/595841_4602_VC_1_1_01_12_2023_14_34_27/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 362\n",
      "speaker: SPEAKER_02, words spoken: 51\n",
      "speaker: SPEAKER_01, words spoken: 29\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 29), ('SPEAKER_02', 51), ('SPEAKER_03', 362)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/1932708_11628_VC_1_1_04_12_2023_16_02_48/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 592\n",
      "speaker: SPEAKER_01, words spoken: 93\n",
      "speaker: SPEAKER_00, words spoken: 1\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 1), ('SPEAKER_01', 93), ('SPEAKER_02', 592)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2027333_1486_VC_1_1_01_12_2023_09_24_47/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 663\n",
      "speaker: SPEAKER_02, words spoken: 946\n",
      "speaker: SPEAKER_00, words spoken: 87\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 87), ('SPEAKER_01', 663), ('SPEAKER_02', 946)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2035583_11646_VC_1_1_30_11_2023_15_11_35/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 1110\n",
      "speaker: SPEAKER_02, words spoken: 286\n",
      "speaker: SPEAKER_00, words spoken: 11\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 11), ('SPEAKER_02', 286), ('SPEAKER_01', 1110)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2034790_12362_VC_1_1_01_12_2023_11_44_45/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 533\n",
      "speaker: SPEAKER_00, words spoken: 111\n",
      "speaker: SPEAKER_01, words spoken: 94\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 94), ('SPEAKER_00', 111), ('SPEAKER_02', 533)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/17885_428_VC_1_1_28_11_2023_15_20_01/clean_captions.txt\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 486\n",
      "speaker: SPEAKER_01, words spoken: 104\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 104), ('SPEAKER_00', 486)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/798404_4858_VC_1_1_05_12_2023_10_34_26/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 1528\n",
      "speaker: SPEAKER_00, words spoken: 19\n",
      "speaker: SPEAKER_02, words spoken: 1193\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 19), ('SPEAKER_02', 1193), ('SPEAKER_01', 1528)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2037112_5400_VC_1_1_01_12_2023_09_59_40/clean_captions.txt\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 2267\n",
      "speaker: SPEAKER_00, words spoken: 385\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 385), ('SPEAKER_01', 2267)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2035607_861_VC_1_1_30_11_2023_14_17_39/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 108\n",
      "speaker: SPEAKER_02, words spoken: 1585\n",
      "speaker: SPEAKER_00, words spoken: 210\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 108), ('SPEAKER_00', 210), ('SPEAKER_02', 1585)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/798404_4858_VC_1_1_05_12_2023_10_34_25/clean_captions.txt\n",
      "Dialogue contains : 4 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 263\n",
      "speaker: SPEAKER_03, words spoken: 2957\n",
      "speaker: SPEAKER_01, words spoken: 103\n",
      "speaker: SPEAKER_00, words spoken: 4\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 4), ('SPEAKER_01', 103), ('SPEAKER_02', 263), ('SPEAKER_03', 2957)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/798404_4858_VC_1_1_05_12_2023_10_34_25/clean_captions.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "new speaker list: ['SPEAKER_01', 'SPEAKER_02', 'SPEAKER_03']\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/2036574_11202_VC_1_1_01_12_2023_10_28_12/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 39\n",
      "speaker: SPEAKER_01, words spoken: 420\n",
      "speaker: SPEAKER_02, words spoken: 1200\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 39), ('SPEAKER_01', 420), ('SPEAKER_02', 1200)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/102725_1374_VC_1_1_04_12_2023_16_44_06/clean_captions.txt\n",
      "Dialogue contains : 4 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 853\n",
      "speaker: SPEAKER_04, words spoken: 270\n",
      "speaker: SPEAKER_02, words spoken: 29\n",
      "speaker: SPEAKER_00, words spoken: 1\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 1), ('SPEAKER_02', 29), ('SPEAKER_04', 270), ('SPEAKER_01', 853)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/102725_1374_VC_1_1_04_12_2023_16_44_06/clean_captions.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "new speaker list: ['SPEAKER_02', 'SPEAKER_04', 'SPEAKER_01']\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/298880_387_VC_1_1_04_12_2023_15_43_49/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 495\n",
      "speaker: SPEAKER_00, words spoken: 130\n",
      "speaker: SPEAKER_01, words spoken: 63\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 63), ('SPEAKER_00', 130), ('SPEAKER_02', 495)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/28081_391_VC_1_1_28_11_2023_17_27_15/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 423\n",
      "speaker: SPEAKER_02, words spoken: 62\n",
      "speaker: SPEAKER_01, words spoken: 81\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 62), ('SPEAKER_01', 81), ('SPEAKER_00', 423)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/34401_575_VC_1_1_28_11_2023_14_42_16/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 411\n",
      "speaker: SPEAKER_00, words spoken: 59\n",
      "speaker: SPEAKER_02, words spoken: 16\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 16), ('SPEAKER_00', 59), ('SPEAKER_01', 411)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/521679_1570_VC_1_1_30_11_2023_12_05_38/clean_captions.txt\n",
      "Dialogue contains : 4 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 497\n",
      "speaker: SPEAKER_01, words spoken: 130\n",
      "speaker: SPEAKER_02, words spoken: 16\n",
      "speaker: SPEAKER_00, words spoken: 7\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 7), ('SPEAKER_02', 16), ('SPEAKER_01', 130), ('SPEAKER_03', 497)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/521679_1570_VC_1_1_30_11_2023_12_05_38/clean_captions.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "new speaker list: ['SPEAKER_02', 'SPEAKER_01', 'SPEAKER_03']\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/469703_9570_VC_1_1_29_11_2023_16_23_53/clean_captions.txt\n",
      "Dialogue contains : 5 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 136\n",
      "speaker: SPEAKER_00, words spoken: 1\n",
      "speaker: SPEAKER_01, words spoken: 425\n",
      "speaker: SPEAKER_03, words spoken: 111\n",
      "speaker: SPEAKER_04, words spoken: 60\n",
      "More than three speakers in captions! Only 3 speakers allowed.\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 1), ('SPEAKER_04', 60), ('SPEAKER_03', 111), ('SPEAKER_02', 136), ('SPEAKER_01', 425)]\n",
      "/home/digitalopt/proj/diarization/recordings/RT-JJara/469703_9570_VC_1_1_29_11_2023_16_23_53/clean_captions.txt is invalid! Only 3 speakers allowed. Removing speakers by lowest word count.\n",
      "new speaker list: ['SPEAKER_03', 'SPEAKER_02', 'SPEAKER_01']\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/477169_1508_VC_1_1_30_11_2023_16_26_11/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 447\n",
      "speaker: SPEAKER_00, words spoken: 67\n",
      "speaker: SPEAKER_02, words spoken: 25\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 25), ('SPEAKER_00', 67), ('SPEAKER_01', 447)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/RT-JJara/73015_939_VC_1_1_28_11_2023_15_22_48/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 471\n",
      "speaker: SPEAKER_00, words spoken: 19\n",
      "speaker: SPEAKER_02, words spoken: 42\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 19), ('SPEAKER_02', 42), ('SPEAKER_01', 471)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/34898_571_VC_1_1_04_12_2023_11_05_51/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 581\n",
      "speaker: SPEAKER_01, words spoken: 40\n",
      "speaker: SPEAKER_02, words spoken: 147\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 40), ('SPEAKER_02', 147), ('SPEAKER_03', 581)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/359862_4466_VC_1_1_04_12_2023_13_36_20/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 589\n",
      "speaker: SPEAKER_02, words spoken: 95\n",
      "speaker: SPEAKER_00, words spoken: 2\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 2), ('SPEAKER_02', 95), ('SPEAKER_01', 589)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/95892_1244_VC_1_1_01_12_2023_15_27_20/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 588\n",
      "speaker: SPEAKER_02, words spoken: 98\n",
      "speaker: SPEAKER_03, words spoken: 78\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 78), ('SPEAKER_02', 98), ('SPEAKER_01', 588)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/559134_5169_VC_1_1_01_12_2023_11_09_16/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 681\n",
      "speaker: SPEAKER_01, words spoken: 218\n",
      "speaker: SPEAKER_00, words spoken: 9\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 9), ('SPEAKER_01', 218), ('SPEAKER_02', 681)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/163548_1814_VC_1_1_04_12_2023_12_07_16/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 72\n",
      "speaker: SPEAKER_01, words spoken: 561\n",
      "speaker: SPEAKER_03, words spoken: 75\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 72), ('SPEAKER_03', 75), ('SPEAKER_01', 561)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/609869_5088_VC_1_1_04_12_2023_10_34_29/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 585\n",
      "speaker: SPEAKER_01, words spoken: 125\n",
      "speaker: SPEAKER_00, words spoken: 23\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 23), ('SPEAKER_01', 125), ('SPEAKER_02', 585)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/590038_4757_VC_1_1_01_12_2023_09_21_54/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 592\n",
      "speaker: SPEAKER_00, words spoken: 51\n",
      "speaker: SPEAKER_02, words spoken: 88\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 51), ('SPEAKER_02', 88), ('SPEAKER_01', 592)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/350602_785_VC_1_1_01_12_2023_15_15_57/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 495\n",
      "speaker: SPEAKER_00, words spoken: 25\n",
      "speaker: SPEAKER_01, words spoken: 39\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 25), ('SPEAKER_01', 39), ('SPEAKER_03', 495)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/405969_4506_VC_1_1_01_12_2023_14_38_33/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 682\n",
      "speaker: SPEAKER_02, words spoken: 81\n",
      "speaker: SPEAKER_00, words spoken: 5\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 5), ('SPEAKER_02', 81), ('SPEAKER_03', 682)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-sbrokus/566198_1378_VC_1_1_28_11_2023_16_38_04/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 564\n",
      "speaker: SPEAKER_02, words spoken: 68\n",
      "speaker: SPEAKER_03, words spoken: 142\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 68), ('SPEAKER_03', 142), ('SPEAKER_01', 564)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/1442410_6967_VC_1_1_01_12_2023_18_35_50/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 92\n",
      "speaker: SPEAKER_02, words spoken: 453\n",
      "speaker: SPEAKER_00, words spoken: 21\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 21), ('SPEAKER_01', 92), ('SPEAKER_02', 453)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/180186_1772_VC_1_1_04_12_2023_11_49_44/clean_captions.txt\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_03, words spoken: 464\n",
      "speaker: SPEAKER_01, words spoken: 133\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 133), ('SPEAKER_03', 464)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/474039_726_VC_1_1_05_12_2023_10_43_41/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 158\n",
      "speaker: SPEAKER_04, words spoken: 500\n",
      "speaker: SPEAKER_03, words spoken: 33\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 33), ('SPEAKER_02', 158), ('SPEAKER_04', 500)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/696884_5310_VC_1_1_05_12_2023_11_16_56/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_04, words spoken: 466\n",
      "speaker: SPEAKER_02, words spoken: 132\n",
      "speaker: SPEAKER_01, words spoken: 69\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 69), ('SPEAKER_02', 132), ('SPEAKER_04', 466)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/1711515_11357_VC_1_1_28_11_2023_18_25_35/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 95\n",
      "speaker: SPEAKER_01, words spoken: 502\n",
      "speaker: SPEAKER_03, words spoken: 177\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 95), ('SPEAKER_03', 177), ('SPEAKER_01', 502)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/973397_4715_VC_1_1_30_11_2023_17_22_09/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 456\n",
      "speaker: SPEAKER_01, words spoken: 175\n",
      "speaker: SPEAKER_03, words spoken: 35\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_03', 35), ('SPEAKER_01', 175), ('SPEAKER_02', 456)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/1130238_6039_VC_1_1_01_12_2023_16_39_52/clean_captions.txt\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 384\n",
      "speaker: SPEAKER_01, words spoken: 49\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 49), ('SPEAKER_02', 384)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/159838_1444_VC_1_1_01_12_2023_10_13_17/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_01, words spoken: 427\n",
      "speaker: SPEAKER_02, words spoken: 48\n",
      "speaker: SPEAKER_03, words spoken: 141\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_02', 48), ('SPEAKER_03', 141), ('SPEAKER_01', 427)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/1052783_6838_VC_1_1_04_12_2023_15_49_25/clean_captions.txt\n",
      "Dialogue contains : 2 speakers.\n",
      "speaker: SPEAKER_02, words spoken: 379\n",
      "speaker: SPEAKER_01, words spoken: 69\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_01', 69), ('SPEAKER_02', 379)]\n",
      "removing names...\n",
      "reading /home/digitalopt/proj/diarization/recordings/rt-lstephens/612446_5307_VC_1_1_01_12_2023_18_03_36/clean_captions.txt\n",
      "Dialogue contains : 3 speakers.\n",
      "speaker: SPEAKER_00, words spoken: 71\n",
      "speaker: SPEAKER_01, words spoken: 378\n",
      "speaker: SPEAKER_02, words spoken: 86\n",
      "sorted speakers by word count: \n",
      "[('SPEAKER_00', 71), ('SPEAKER_02', 86), ('SPEAKER_01', 378)]\n",
      "removing names...\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from diarization_utils import CaptionCleaner\n",
    "\n",
    "output_root = \"/home/digitalopt/proj/diarization/recordings/\"\n",
    "cap_paths = glob(output_root + '*/*/clean_captions.txt')\n",
    "print(f'found {len(cap_paths)} caption texts')\n",
    "cleaner = CaptionCleaner()\n",
    "cleaner.load_NER_model()\n",
    "for p in cap_paths:\n",
    "    print(f'reading {p}')\n",
    "    captions = cleaner.read_captions(p)\n",
    "    cleaned = cleaner.clean(captions, full_clean=False)\n",
    "    if cleaned:\n",
    "        outfile = '/'.join(p.split('/')[:-1]) + '/clean_captions1.txt'\n",
    "        cleaner.write_captions(cleaned, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging vision exam stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/digitalopt/proj/datasets/Exam_v2/test/000024.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/test/000025.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/test/000026.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/test/000027.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/test/000028.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "data_dir = '/home/digitalopt/proj/datasets/Exam_v2/'\n",
    "fpaths = glob(data_dir + '*/*.txt')\n",
    "fpaths.sort()\n",
    "fpaths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/digitalopt/proj/datasets/Exam_v2/train/000000.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000001.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000002.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000003.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000004.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000005.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000006.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000007.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000008.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000009.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000010.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000011.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000012.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000013.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000014.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000015.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000016.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000017.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000018.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000019.txt',\n",
       " '/home/digitalopt/proj/datasets/Exam_v2/train/000020.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpaths[6:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/proj/datasets/Exam_v2/train/000000.txt {'greeting_setup': (), 'va_unaided': (), 'subjective_refraction': (), 'close_vision': ()}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "template = dict(greeting_setup=(),\n",
    "                va_unaided=(),\n",
    "                subjective_refraction=(),\n",
    "                close_vision=()  \n",
    ")\n",
    "\n",
    "exam_by_stage = defaultdict(list)\n",
    "\n",
    "for p in fpaths:\n",
    "    exam_by_stage[p] = template\n",
    "\n",
    "print(fpaths[6], exam_by_stage[fpaths[6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exam_by_stage[fpaths[6]]['greeting_setup'] = (0,17)\n",
    "exam_by_stage[fpaths[6]]['va_unaided'] = (17,27)\n",
    "exam_by_stage[fpaths[6]]['subjective_refraction'] = (27,61)\n",
    "exam_by_stage[fpaths[6]]['close_vision'] = (61,67)\n",
    "\n",
    "exam_by_stage[fpaths[7]]['greeting_setup'] = (0,9)\n",
    "exam_by_stage[fpaths[7]]['va_unaided'] = (9,23)\n",
    "exam_by_stage[fpaths[7]]['subjective_refraction'] = (23,69)\n",
    "exam_by_stage[fpaths[7]]['close_vision'] = (69,73)\n",
    "\n",
    "exam_by_stage[fpaths[8]]['greeting_setup'] = (0,16)\n",
    "exam_by_stage[fpaths[8]]['va_unaided'] = (16,26)\n",
    "exam_by_stage[fpaths[8]]['subjective_refraction'] = (26,59)\n",
    "exam_by_stage[fpaths[8]]['close_vision'] = (59,66)\n",
    "\n",
    "exam_by_stage[fpaths[9]]['greeting_setup'] = (0,9)\n",
    "exam_by_stage[fpaths[9]]['va_unaided'] = (9,19)\n",
    "exam_by_stage[fpaths[9]]['subjective_refraction'] = (19,68)\n",
    "exam_by_stage[fpaths[9]]['close_vision'] = (68,72)\n",
    "\n",
    "exam_by_stage[fpaths[10]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[10]]['va_unaided'] = (11,21)\n",
    "exam_by_stage[fpaths[10]]['subjective_refraction'] = (21,65)\n",
    "exam_by_stage[fpaths[10]]['close_vision'] = (65,75)\n",
    "\n",
    "exam_by_stage[fpaths[11]]['greeting_setup'] = (0,9)\n",
    "exam_by_stage[fpaths[11]]['va_unaided'] = (9,21)\n",
    "exam_by_stage[fpaths[11]]['subjective_refraction'] = (21,77)\n",
    "exam_by_stage[fpaths[11]]['close_vision'] = (77,83)\n",
    "\n",
    "exam_by_stage[fpaths[12]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[12]]['va_unaided'] = (11,21)\n",
    "exam_by_stage[fpaths[12]]['subjective_refraction'] = (21,37)\n",
    "exam_by_stage[fpaths[12]]['close_vision'] = (37,43)\n",
    "\n",
    "exam_by_stage[fpaths[13]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[13]]['va_unaided'] = (11,32)\n",
    "exam_by_stage[fpaths[13]]['subjective_refraction'] = (32,60)\n",
    "exam_by_stage[fpaths[13]]['close_vision'] = (60,62)\n",
    "\n",
    "exam_by_stage[fpaths[14]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[14]]['va_unaided'] = (11,27)\n",
    "exam_by_stage[fpaths[14]]['subjective_refraction'] = (27,61)\n",
    "exam_by_stage[fpaths[14]]['close_vision'] = (61,68)\n",
    "\n",
    "exam_by_stage[fpaths[15]]['greeting_setup'] = (0,12)\n",
    "exam_by_stage[fpaths[15]]['va_unaided'] = (12,34)\n",
    "exam_by_stage[fpaths[15]]['subjective_refraction'] = (34,56)\n",
    "exam_by_stage[fpaths[15]]['close_vision'] = (56,67)\n",
    "\n",
    "exam_by_stage[fpaths[16]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[16]]['va_unaided'] = (11,25)\n",
    "exam_by_stage[fpaths[16]]['subjective_refraction'] = (25,57)\n",
    "exam_by_stage[fpaths[16]]['close_vision'] = (57,63)\n",
    "\n",
    "exam_by_stage[fpaths[17]]['greeting_setup'] = (0,7)\n",
    "exam_by_stage[fpaths[17]]['va_unaided'] = (7,17)\n",
    "exam_by_stage[fpaths[17]]['subjective_refraction'] = (17,55)\n",
    "exam_by_stage[fpaths[17]]['close_vision'] = (55,58)\n",
    "\n",
    "exam_by_stage[fpaths[18]]['greeting_setup'] = (0,5)\n",
    "exam_by_stage[fpaths[18]]['va_unaided'] = (5,19)\n",
    "exam_by_stage[fpaths[18]]['subjective_refraction'] = (19,49)\n",
    "exam_by_stage[fpaths[18]]['close_vision'] = (49,55)\n",
    "\n",
    "exam_by_stage[fpaths[19]]['greeting_setup'] = (0,3)\n",
    "exam_by_stage[fpaths[19]]['va_unaided'] = (3,15)\n",
    "exam_by_stage[fpaths[19]]['subjective_refraction'] = (15,49)\n",
    "exam_by_stage[fpaths[19]]['close_vision'] = (49,56)\n",
    "\n",
    "exam_by_stage[fpaths[20]]['greeting_setup'] = (0,7)\n",
    "exam_by_stage[fpaths[20]]['va_unaided'] = (7,33)\n",
    "exam_by_stage[fpaths[20]]['subjective_refraction'] = (33,63)\n",
    "exam_by_stage[fpaths[20]]['close_vision'] = (63,69)\n",
    "\n",
    "exam_by_stage[fpaths[21]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[21]]['va_unaided'] = (11,27)\n",
    "exam_by_stage[fpaths[21]]['subjective_refraction'] = (27,75)\n",
    "exam_by_stage[fpaths[21]]['close_vision'] = (75,81)\n",
    "\n",
    "exam_by_stage[fpaths[22]]['greeting_setup'] = (0,11)\n",
    "exam_by_stage[fpaths[22]]['va_unaided'] = (11,29)\n",
    "exam_by_stage[fpaths[22]]['subjective_refraction'] = (29,71)\n",
    "exam_by_stage[fpaths[22]]['close_vision'] = (71,83)\n",
    "\n",
    "exam_by_stage[fpaths[23]]['greeting_setup'] = (0,16)\n",
    "exam_by_stage[fpaths[23]]['va_unaided'] = (16,36)\n",
    "exam_by_stage[fpaths[23]]['subjective_refraction'] = (36,72)\n",
    "exam_by_stage[fpaths[23]]['close_vision'] = (72,78)\n",
    "\n",
    "exam_by_stage[fpaths[24]]['greeting_setup'] = (0,15)\n",
    "exam_by_stage[fpaths[24]]['va_unaided'] = (15,33)\n",
    "exam_by_stage[fpaths[24]]['subjective_refraction'] = (33,79)\n",
    "exam_by_stage[fpaths[24]]['close_vision'] = (79,85)\n",
    "\n",
    "exam_by_stage[fpaths[25]]['greeting_setup'] = (0,13)\n",
    "exam_by_stage[fpaths[25]]['va_unaided'] = (13,41)\n",
    "exam_by_stage[fpaths[25]]['subjective_refraction'] = (41,73)\n",
    "exam_by_stage[fpaths[25]]['close_vision'] = (73,81)\n",
    "\n",
    "exam_by_stage[fpaths[26]]['greeting_setup'] = (0,9)\n",
    "exam_by_stage[fpaths[26]]['va_unaided'] = (9,23)\n",
    "exam_by_stage[fpaths[26]]['subjective_refraction'] = (23,55)\n",
    "exam_by_stage[fpaths[26]]['close_vision'] = (55,59)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "greet_lens = []\n",
    "va_lens = []\n",
    "sr_lens = []\n",
    "cv_lens = []\n",
    "results = dict(greeting_setup=[],\n",
    "                va_unaided=[],\n",
    "                subjective_refraction=[],\n",
    "                close_vision=[],\n",
    "                cap_length=[]\n",
    ")\n",
    "\n",
    "for p in fpaths[6:27]:\n",
    "    for k in exam_by_stage[p].keys():\n",
    "        length = exam_by_stage[p][k][1] - exam_by_stage[p][k][0]\n",
    "        results[k].append(length)\n",
    "        # the endpoint of close_vision is the last index\n",
    "        if k == \"close_vision\":\n",
    "            # add 1 to last index to get length of dialogue\n",
    "            results[\"cap_length\"].append(exam_by_stage[p][k][1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greeting_setup 9.0\n",
      "va_unaided 14.0\n",
      "subjective_refraction 32.0\n",
      "close_vision 4.0\n",
      "cap_length 60.0\n"
     ]
    }
   ],
   "source": [
    "for k in results.keys():\n",
    "    avg = sum(results[k]) / len(results[k])\n",
    "    print(k,avg)\n",
    "    # 3364705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percent of each dialogue that each section represents:\n",
      "\n",
      "greeting_setup 15.0\n",
      "va_unaided 23.33\n",
      "subjective_refraction 53.33\n",
      "close_vision 6.67\n",
      "cap_length 100.0\n"
     ]
    }
   ],
   "source": [
    "avg_length = sum(results[\"cap_length\"]) / len(results[\"cap_length\"])\n",
    "\n",
    "print('Average percent of each dialogue that each section represents:\\n')\n",
    "for k in results.keys():\n",
    "    avg = sum(results[k]) / len(results[k])\n",
    "    print(k,round((avg/avg_length)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15+24+54+7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
