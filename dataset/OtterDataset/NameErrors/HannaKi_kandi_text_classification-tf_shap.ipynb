{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install the most recent versions of ðŸ¤— Transformers and ðŸ¤— Datasets. We will also need `scipy` and `scikit-learn` for some of the metrics. Uncomment the following cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOsHUjgdIrIW",
        "outputId": "fdece884-a0f6-439f-9742-45d4e4aab74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 4.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 48.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.8 MB 42.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61 kB 424 kB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243 kB 3.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132 kB 36.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 41.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160 kB 49.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192 kB 52.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 49.2 MB/s \n",
            "\u001b[?25h  Building wheel for datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip --quiet install git+https://github.com/huggingface/transformers.git\n",
        "! pip --quiet install git+https://github.com/huggingface/datasets.git\n",
        "! pip --quiet install scipy sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkiqvCSMAC8q",
        "outputId": "0b405f83-dec0-42ae-a604-54bc8869dc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.16.0.dev0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from google.colab import drive\n",
        "\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFASsisvIrIb"
      },
      "source": [
        "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/text-classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "# Fine-tuning a model on a text classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTCFado4IrIc"
      },
      "source": [
        "In this notebook, we will see how to fine-tune one of the [ðŸ¤— Transformers](https://github.com/huggingface/transformers) model to a text classification task of the [GLUE Benchmark](https://gluebenchmark.com/).\n",
        "\n",
        "The GLUE Benchmark is a group of nine classification tasks on sentences or pairs of sentences which are:\n",
        "\n",
        "- [CoLA](https://nyu-mll.github.io/CoLA/) (Corpus of Linguistic Acceptability) Determine if a sentence is grammatically correct or not.is a  dataset containing sentences labeled grammatically correct or not.\n",
        "- [MNLI](https://arxiv.org/abs/1704.05426) (Multi-Genre Natural Language Inference) Determine if a sentence entails, contradicts or is unrelated to a given hypothesis. (This dataset has two versions, one with the validation and test set coming from the same distribution, another called mismatched where the validation and test use out-of-domain data.)\n",
        "- [MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398) (Microsoft Research Paraphrase Corpus) Determine if two sentences are paraphrases from one another or not.\n",
        "- [QNLI](https://rajpurkar.github.io/SQuAD-explorer/) (Question-answering Natural Language Inference) Determine if the answer to a question is in the second sentence or not. (This dataset is built from the SQuAD dataset.)\n",
        "- [QQP](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) (Quora Question Pairs2) Determine if two questions are semantically equivalent or not.\n",
        "- [RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) (Recognizing Textual Entailment) Determine if a sentence entails a given hypothesis or not.\n",
        "- [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) Determine if the sentence has a positive or negative sentiment.\n",
        "- [STS-B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) (Semantic Textual Similarity Benchmark) Determine the similarity of two sentences with a score from 1 to 5.\n",
        "- [WNLI](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html) (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not. (This dataset is built from the Winograd Schema Challenge dataset.)\n",
        "\n",
        "We will see how to easily load the dataset for each one of those tasks and use the `Trainer` API to fine-tune a model on it. Each task is named by its acronym, with `mnli-mm` standing for the mismatched version of MNLI (so same training set as `mnli` but different validation and test sets):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YZbiBDuGIrId"
      },
      "outputs": [],
      "source": [
        "# GLUE_TASKS = [\n",
        "#     \"cola\",\n",
        "#     \"mnli\",\n",
        "#     \"mnli-mm\",\n",
        "#     \"mrpc\",\n",
        "#     \"qnli\",\n",
        "#     \"qqp\",\n",
        "#     \"rte\",\n",
        "#     \"sst2\",\n",
        "#     \"stsb\",\n",
        "#     \"wnli\",\n",
        "# ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RRkXuteIrIh"
      },
      "source": [
        "This notebook is built to run on any of the tasks in the list above, with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a classification head. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "outputs": [],
      "source": [
        "# task = \"sst2\"\n",
        "# model_checkpoint = \"distilbert-base-uncased\"\n",
        "model_checkpoint =\"bert-base-cased\" # name from Hugging Face repository\n",
        "batch_size = 6 # 16 too large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7QYTpxXIrIl"
      },
      "source": [
        "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKx2zKs5IrIq"
      },
      "source": [
        "Apart from `mnli-mm` being a special code, we can directly pass our task name to those functions. `load_dataset` will cache the dataset to avoid downloading it again the next time you run this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "s_AY1ATSIrIq"
      },
      "outputs": [],
      "source": [
        "# actual_task = \"mnli\" if task == \"mnli-mm\" else task\n",
        "# dataset = load_dataset(\"glue\", actual_task)\n",
        "# metric = load_metric(\"glue\", actual_task)\n",
        "\n",
        "# dataset = load_dataset(\"glue\", task)\n",
        "# metric = load_metric(\"glue\", task)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = datasets.load_dataset(\"imdb\", split=\"test\")\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "1988cfb7fa794eb4b396eaa53cbc5009",
            "42b59d9069284acbb645bdc9885a4e0c",
            "8a9bd000af1a412d8c869a14136cd646",
            "e11fa7955c7e43e38b608c8cbade8060",
            "4d090cd79fab487483f43ca69d5b15e9",
            "b13d84d0ea514624b89688b241b67367",
            "fe1fa96aeed14d7394aa24f4504f3d99",
            "e33748c0073e41f0a9fffe5a38331822",
            "05c61a93e1f44d80b9bb1bef5912dffc",
            "57eb186a1fb94c98bd4d136c76ebad11",
            "36e4b5ad2c9349b493dc7d322055839d"
          ]
        },
        "id": "z_Pl42tumPj0",
        "outputId": "560f9f04-d6d3-4d52-b864-3f1ccae946dd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1988cfb7fa794eb4b396eaa53cbc5009",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzfPtOMoIrIu"
      },
      "source": [
        "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of `mnli`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "outputId": "926b3715-4ef2-4d0f-cfc0-8fb868942a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3EtYfeHIrIz"
      },
      "source": [
        "To access an actual element, you need to select a split first, then give an index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "X6HrpprwIrIz",
        "outputId": "e26fd57e-859c-4861-bda0-3cd867515b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# num_labels=len(np.unique(dataset[\"train\"][\"label\"])) # luokkien lukumÃ¤Ã¤rÃ¤\n",
        "# print(np.unique(dataset[\"train\"][\"label\"]))\n",
        "# num_labels"
      ],
      "metadata": {
        "id": "Dfc_uXnVBxEz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUmphG3IrI3"
      },
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "outputs": [],
      "source": [
        "# import datasets\n",
        "# import random\n",
        "# import pandas as pd\n",
        "# from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# def show_random_elements(dataset, num_examples=10):\n",
        "#     assert num_examples <= len(\n",
        "#         dataset\n",
        "#     ), \"Can't pick more elements than there are in the dataset.\"\n",
        "#     picks = []\n",
        "#     for _ in range(num_examples):\n",
        "#         pick = random.randint(0, len(dataset) - 1)\n",
        "#         while pick in picks:\n",
        "#             pick = random.randint(0, len(dataset) - 1)\n",
        "#         picks.append(pick)\n",
        "\n",
        "#     df = pd.DataFrame(dataset[picks])\n",
        "#     for column, typ in dataset.features.items():\n",
        "#         if isinstance(typ, datasets.ClassLabel):\n",
        "#             df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "#     display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "SZy5tRB_IrI7"
      },
      "outputs": [],
      "source": [
        "# show_random_elements(dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,20000,4000):\n",
        "  print(dataset[\"train\"][\"label\"][i], \"\\t\", dataset[\"train\"][\"text\"][i])"
      ],
      "metadata": {
        "id": "t_YW3BSQOPHA",
        "outputId": "7b701f4b-07cb-40c2-b637-885c248a2012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \t I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "0 \t There is one really good scene in Faat Kine. The title character gets in an argument with another woman and after being threatened, Faat Kine sprays her in the face. The scene works because the act is so unexpected, bizarre, and rather funny at the same time. In that one instance, writer/director Ousmane Sembene gives the audience a character that is easy to root for, an interesting film character that could be worth watching for two hours. In the scene, he presents a brave woman who is bold in her actions. For the rest of the movie, the only other thing he seems to present is conflicting tones. <br /><br />The tone is all over the place. It's true not all movies have to clearly fit within a specific genre, but I don't think Faat Kine fits into any genre. Supposedly, it's a drama, though there are moments of such broad comedy (the aforementioned spraying in the face) that it cannot be taken seriously. On the other hand, the film is certainly not a comedy with the abundant amount of serious topics Sembene has crammed into the picture. There is a way to successfully mix comedy and drama together. Unfortunately, Semebene doesn't find that balance. Instead, one scene after another just drift into each other without much rhyme or reason, leaving two different tones hanging in the wind. <br /><br />Faat Kine also has the problem of running two hours long with an extremely drawn out finale. The film ends with a big party where all the characters' conflicts are resolved, only they aren't resolved quickly. The scene lasts longer than any other scene, going on for probably twenty minutes. Because the rest of the scenes up until this point have been meandering, the finale is particularly hard to endure with repetition beginning early on in the scene, making for a frustrating viewing experience.<br /><br />Perhaps I am being too hard on Faat Kine. I am not the right audience for it. I felt nothing towards the characters and had no connection to any part of the story. There are people who will probably find something meaningful in the story and see strong characters. However, I was unable to do so and thus cannot recommend it.\n",
            "0 \t this by far one of the worst movies I have ever seen in my life. I gave up to watch it after an hour and regretted that hour a lot. the acting is horrible and there is almost no plot. my guess is that someone came up with a strange shape of an animal and started to make a story around of it. borrowing some ideas from movies like Resident Evil and Aliens doesn't result in a movie like them. if this going to be a top Korean movie, I'd rather won't bother to see even a Korean movie trailer...<br /><br />By the way, this movies is a good reason to believe that not necessarily a high rating means the movie is promising. I think every Korean who has internet for online gaming rated this movie over the 8, even though has no clue what it is about.\n",
            "0 \t Billy Chung Siu Hung's (the bloody swordplay film Assassin from 1993) film Love To Kill (Hong Kong, 1993) is among the strongest products of the Category III boom that inhabited the HK cinema in early nineties. It consisted of films with strong sex, nudity and violence, more or less gratuitous and shock valued only. Love To Kill definitely belongs to the \"more\" category with some unforgettable ideas and pieces of celluloid sickness.<br /><br />The HK psycho Anthony Wong (from the award winning The Untold Story by Herman Yau, from the same year) plays a business man and a husband who likes to torture, humiliate and rape his young wife (Elizabeth Lee Mei Fung) who for some reason doesn't leave him and save herself and their little son from the disturbed tormentor. A policeman (Danny Lee, the famous police character actor from films like Dr. Lamb (1992) by Billy Tang (and co-directed by Lee) and The Killer (1989) by John Woo to name just a few) however sees the problem and starts to protect the wife and the son but Anthony naturally doesn't like this at all, and leads it all into the typical ultra-mean spirited and graphic finale during a rain storm.<br /><br />The film is almost completely without any serious merits as it's just a piece of exploitation in order to cash in when these kind of films were so popular. The imagery and happenings are something never found in the Western cinema, at least in mainstream, and it all becomes even more mind-blowing when some/most taboos for Westerners, like violence and perversions witnessed by a child, are broken in these films so often that reading the plotlines alone would make most viewers feel sick, and that goes perfectly especially for this film too.<br /><br />The film still has a rather interesting and creepy soundtrack in the tradition of the mentioned Dr. Lamb which practically started the whole boom in 1992. Usually the music and soundtrack in HK films is interesting and adds to the imagery, especially in these terror films. Also the cinematography is worth mentioning as the film bathes, especially in the finale, in blue colors and camera lenses (as does Assassin, too), and the raging storm is captured nicely on the camera. Otherwise there's nothing that would rate the film any higher other than on the nastiness-meter.<br /><br />The actors and actresses are talented and professional and so don't make the film any worse with their acting. Still the film has the usual HK humor in it which makes the sick goings-on even sicker as some \"humor\" is thrown into the soup. That includes some jokes about Danny Lee's erection and so on..Something that could never be found in the Western \"serious\" films either. And that thing usually destroys mane otherwise noteworthy HK films as the humor is just so obvious way and attempt to entertain the audience and masses.<br /><br />The film has a very high outrageousness level as it has numerous scenes depicting the abuse of Wong's wife in various ways. She gets raped and molested, beaten and kicked by her husband. We also get to see some flashbacks from Wong's own childhood which turns out to be equally violent as his own father killed too and turned his young son into what he is now. These flashback scenes, mostly at the end of the film, include also some totally unexpected experiences as the imagery is speeded up (for example the hits of an axe) and that creates completely insane and mean spirited atmosphere to the scene. Again something that only HK exploitation makers seem to be able to come up with. The ending itself includes plenty of sudden and shocking gore as the madman wields his axe and meets also some nails, for example, on his furious way.<br /><br />The film is also genuinely pretty \"suspicious\" in my opinion as the violence and terror is realistically painful and deals with things that should NEVER be taken as entertainment, mostly I mean rape. The version I saw (I've seen two versions) includes a very long and completely nauseating rape scene that just tries to be as sadistic as possible. I'm not sure does the HK audience really like imagery like this but I think no one with some sense for morality in films/entertainment would never accept or make something like it. Women get brutalized and killed in the most sadistic and low ways so that the fates of the men seem almost tame when compared to the females.<br /><br />The other version I saw, the newly released DVD in HK (without subtitles) has this \"table brutality\" scene in a much longer form than the subtitled Taiwanese DVD which is otherwise identical to the HK version. I've also heard that the old HK Laserdisc is different from these two and since the end credits are filled with scenes and images not found in the actual film, it is impossible to say how \"uncut\" versions these that have been released or shown theatrically are. Obviously plenty of footage has been cut out, possibly even before the theatrical release.<br /><br />The film is written by Law Gam Fai and Lau Wing Kin, the former having written also films like Dr. Lamb, The Untold Story and Gunmen (Kirk Wong, 1988) but out of his other films that I've seen, Love to Kill is the most gratuitous. Dr. Lamb and The Untold Story both are very brutal and violent but have also some attempt to some criticism towards the authorities and men in general as how it is easy to turn into a beast when chasing or fighting one. The harrowing torture imagery of The Untold Story, the victim being the criminal, is very strong and definitely has its impact to change something that may be rotten in the society and among the police for example. But there's none of this in Love to Kill, it is just honest, calculated and fastly made exploitation which is, by the way, produced by a veteran director Kirk \"Organized Crime & Triad Bureau (1993), Crime Story (1993)\" Wong!<br /><br />Love to Kill earns no more than 2/10 from me as I don't have too high appreciation on films like this. (HK) Cinema is meant to be and can be more and films like Love to Kill are only commercial parasites living among the real pieces of the art.\n",
            "1 \t Good: Engaging cinematic firefights, great presentation, vehicles are actually fun to drive, fairly appealing multiplayer, faithful to the movie, and the list goes on.<br /><br />Bad: Main missions are a bit short.<br /><br />This game defines what a \"good\" third person shooter(not necessarily a spy-game) is. Great firefights carry on the story and make you want to complete EVERY single mission through, and unlock all the genuine bonuses the game has to offer. The hype this game had, was lived up to, and I personally think you should buy it, and hook up with a couple of friends and play this one. Loads of fun. <br /><br />The sound in this game, is a rip-roaring achievement from a few previous bond games, and firing a weapon, really feels like you're firing a weapon. It ties in with the aspect that you are a deadly and ruthless spy.<br /><br />All in all, this game makes you excited and satisfied after you make it through, and some multiplayer that can compete with the standards of the crafty James Bond \"Nightfire\" game for gamecube.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"] = dataset[\"train\"].filter(lambda example, idx: idx % 10 == 0, with_indices=True)\n",
        "# if index is divisible with 10, select the instance\n",
        "\n",
        "len(dataset[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qax921F8D7V-",
        "outputId": "eb654bb3-d563-470a-cdf3-a035b3de1c59"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2bb51c6f00c9430b.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"validation\"] = dataset[\"test\"].filter(lambda example, idx: idx % 2 == 0, with_indices=True).filter(lambda example, idx: idx % 20 == 0, with_indices=True)\n",
        "dataset[\"test\"] = dataset[\"test\"].filter(lambda example, idx: idx % 2 != 0, with_indices=True).filter(lambda example, idx: idx % 20 == 0, with_indices=True)\n",
        "\n",
        "len(dataset[\"validation\"]), len(dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWFPsG0Jsq2E",
        "outputId": "9e4c45ea-1e30-411d-8da5-3372badb0c21"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-cf0a4bebe61b82c7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f5cee140a9f911b7.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2d010b75dc07ab97.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2beba353f71da13f.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(625, 625)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset[\"unsupervised\"]\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6-qVxMtvFes",
        "outputId": "60e97594-7f07-4487-c9b0-e71cb99c6583"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 625\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 625\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"].features)\n",
        "dataset[\"train\"].features[\"label\"].str2int(values=[\"neg\", \"pos\"]) # neg is encoded to 0 and pos to 1"
      ],
      "metadata": {
        "id": "m9sigIK4JyfA",
        "outputId": "4d023372-6f04-43d0-c2d1-18934b4a5712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['neg', 'pos'], names_file=None, id=None)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnjDIuQ3IrI-"
      },
      "source": [
        "The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5o4rUteaIrI_"
      },
      "outputs": [],
      "source": [
        "# metric\n",
        "# TODO: F1-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAWdqcUBIrJC"
      },
      "source": [
        "You can call its `compute` method with your predictions and labels directly and it will return a dictionary with the metric(s) value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "6XN1Rq0aIrJC"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# fake_preds = np.random.randint(0, 2, size=(64,))\n",
        "# fake_labels = np.random.randint(0, 2, size=(64,))\n",
        "# metric.compute(predictions=fake_preds, references=fake_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOCrQwPoIrJG"
      },
      "source": [
        "Note that `load_metric` has loaded the proper metric associated to your task, which is:\n",
        "\n",
        "- for CoLA: [Matthews Correlation Coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)\n",
        "- for MNLI (matched or mismatched): Accuracy\n",
        "- for MRPC: Accuracy and [F1 score](https://en.wikipedia.org/wiki/F1_score)\n",
        "- for QNLI: Accuracy\n",
        "- for QQP: Accuracy and [F1 score](https://en.wikipedia.org/wiki/F1_score)\n",
        "- for RTE: Accuracy\n",
        "- for SST-2: Accuracy\n",
        "- for STS-B: [Pearson Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and [Spearman's_Rank_Correlation_Coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)\n",
        "- for WNLI: Accuracy\n",
        "\n",
        "so the metric object only computes the one(s) needed for your task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9qywopnIrJH"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVx71GdAIrJH"
      },
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
        "\n",
        "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
        "- we download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "eXNLu_-nIrJI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rowT4iCLIrJK"
      },
      "source": [
        "You can directly call this tokenizer on one sentence or a pair of sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "a5hBlsrHIrJL",
        "outputId": "faa7be88-a221-4b68-e6eb-44e80a3b8304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 8667, 117, 1142, 1141, 5650, 106, 102, 1262, 1142, 5650, 2947, 1114, 1122, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_0B1M2IrJM"
      },
      "source": [
        "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
        "\n",
        "To preprocess our dataset, we will thus need the names of the columns containing the sentence(s). The following dictionary keeps track of the correspondence task to column names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "fyGdtK9oIrJM"
      },
      "outputs": [],
      "source": [
        "# task_to_keys = {\n",
        "#     \"cola\": (\"sentence\", None),\n",
        "#     \"mnli\": (\"premise\", \"hypothesis\"),\n",
        "#     \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
        "#     \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
        "#     \"qnli\": (\"question\", \"sentence\"),\n",
        "#     \"qqp\": (\"question1\", \"question2\"),\n",
        "#     \"rte\": (\"sentence1\", \"sentence2\"),\n",
        "#     \"sst2\": (\"sentence\", None),\n",
        "#     \"stsb\": (\"sentence1\", \"sentence2\"),\n",
        "#     \"wnli\": (\"sentence1\", \"sentence2\"),\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbqtC4MrIrJO"
      },
      "source": [
        "We can double check it does work on our current dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "19GG646uIrJO"
      },
      "outputs": [],
      "source": [
        "# sentence1_key, sentence2_key = task_to_keys[task]\n",
        "# if sentence2_key is None:\n",
        "#     print(f\"Sentence: {dataset['train'][0][sentence1_key]}\")\n",
        "# else:\n",
        "#     print(f\"Sentence 1: {dataset['train'][0][sentence1_key]}\")\n",
        "#     print(f\"Sentence 2: {dataset['train'][0][sentence2_key]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentence: {dataset['train'][0]['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5gA-zexq_Vw",
        "outputId": "cbb3cd89-664a-4048-8556-41008c96c2b8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C0hcmp9IrJQ"
      },
      "source": [
        "We can them write the function that will preprocess our samples. We just feed them to the `tokenizer` with the arguments `truncation=True` and `padding='longest`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model, and all inputs will be padded to the maximum input length to give us a single input array. A more performant method that reduces the number of padding tokens is to write a generator or `tf.data.Dataset` to only pad each *batch* to the maximum length in that batch, but most GLUE tasks are relatively quick on modern GPUs either way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      },
      "outputs": [],
      "source": [
        "# def preprocess_function(examples):\n",
        "#     if sentence2_key is None:\n",
        "#         return tokenizer(examples[sentence1_key], truncation=True)\n",
        "#     return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm8ozrJIrJR"
      },
      "source": [
        "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-b70jh26IrJS",
        "outputId": "d6c141d0-b647-43a7-f637-4f17026f2ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 146, 12765, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1121, 1139, 1888, 2984, 1272, 1104, 1155, 1103, 6392, 1115, 4405, 1122, 1165, 1122, 1108, 1148, 1308, 1107, 2573, 119, 146, 1145, 1767, 1115, 1120, 1148, 1122, 1108, 7842, 1118, 158, 119, 156, 119, 10148, 1191, 1122, 1518, 1793, 1106, 3873, 1142, 1583, 117, 3335, 1217, 170, 5442, 1104, 2441, 1737, 107, 6241, 107, 146, 1541, 1125, 1106, 1267, 1142, 1111, 1991, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1109, 4928, 1110, 8663, 1213, 170, 1685, 3619, 3362, 2377, 1417, 14960, 1150, 3349, 1106, 3858, 1917, 1131, 1169, 1164, 1297, 119, 1130, 2440, 1131, 3349, 1106, 2817, 1123, 2209, 1116, 1106, 1543, 1199, 3271, 1104, 4148, 1113, 1184, 1103, 1903, 156, 11547, 1162, 1354, 1164, 2218, 1741, 2492, 1216, 1112, 1103, 4357, 1414, 1105, 1886, 2492, 1107, 1103, 1244, 1311, 119, 1130, 1206, 4107, 8673, 1105, 6655, 10552, 3708, 2316, 1104, 8583, 1164, 1147, 11089, 1113, 4039, 117, 1131, 1144, 2673, 1114, 1123, 3362, 3218, 117, 22150, 117, 1105, 1597, 1441, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1327, 8567, 1143, 1164, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1110, 1115, 1969, 1201, 2403, 117, 1142, 1108, 1737, 185, 8456, 9597, 119, 8762, 117, 1103, 2673, 1105, 183, 17294, 2340, 4429, 1132, 1374, 1105, 1677, 1206, 117, 1256, 1173, 1122, 112, 188, 1136, 2046, 1176, 1199, 10928, 1193, 1189, 185, 8456, 1186, 119, 1799, 1139, 1583, 2354, 1713, 1525, 1122, 19196, 117, 1107, 3958, 2673, 1105, 183, 17294, 2340, 1132, 170, 1558, 22088, 1107, 3619, 7678, 119, 2431, 1130, 14721, 1197, 27644, 117, 18271, 1147, 2590, 1106, 1363, 1385, 2298, 1287, 4100, 117, 1125, 2673, 4429, 1107, 1117, 2441, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 146, 1202, 3254, 2354, 1181, 1103, 18992, 1111, 1103, 1864, 1115, 1251, 2673, 2602, 1107, 1103, 1273, 1110, 2602, 1111, 6037, 4998, 1897, 1190, 1198, 1106, 4900, 1234, 1105, 1294, 1948, 1106, 1129, 2602, 1107, 185, 8456, 9597, 13090, 1107, 1738, 119, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1110, 170, 1363, 1273, 1111, 2256, 5277, 1106, 2025, 1103, 6092, 1105, 15866, 113, 1185, 23609, 1179, 3005, 114, 1104, 3619, 7678, 119, 1252, 1541, 117, 1142, 1273, 2144, 112, 189, 1138, 1277, 1104, 170, 4928, 119, 102], [101, 1135, 1108, 1632, 1106, 1267, 1199, 1104, 1139, 5095, 2940, 1104, 1476, 1201, 2403, 1259, 1287, 25846, 117, 3096, 15109, 10582, 1105, 14707, 24340, 119, 1220, 1350, 2385, 7310, 119, 1252, 1115, 1108, 1122, 119, 1220, 1127, 1136, 1549, 1251, 2650, 1137, 1363, 2442, 1106, 1250, 1114, 119, 146, 4534, 4628, 1137, 8361, 1184, 1103, 2650, 1127, 1833, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1789, 1104, 1103, 2964, 2130, 3573, 1127, 2503, 117, 20033, 1124, 15703, 1105, 9518, 21180, 5503, 1127, 2385, 19555, 1105, 9588, 1107, 1147, 1353, 1334, 27982, 2192, 119, 1220, 2799, 1199, 5939, 1105, 1122, 1110, 6782, 1152, 1238, 112, 189, 1301, 1113, 1106, 2851, 1107, 1167, 1105, 1618, 2441, 119, 20572, 1193, 117, 146, 1238, 112, 189, 1341, 9771, 1457, 7625, 5208, 1400, 170, 2640, 1106, 2496, 1107, 1142, 1123, 1178, 1696, 1273, 1648, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1109, 1273, 2691, 1106, 1138, 1199, 3899, 117, 1105, 146, 1108, 1304, 1501, 118, 13767, 1165, 146, 1408, 2903, 1122, 119, 146, 1821, 170, 1992, 1943, 9326, 1403, 6778, 11748, 5442, 1105, 146, 4927, 1117, 1314, 2523, 117, 107, 8572, 112, 188, 2508, 4064, 107, 1105, 1155, 1117, 1346, 3200, 1121, 107, 18525, 1116, 107, 1106, 107, 3350, 26918, 2007, 1320, 107, 119, 1573, 117, 1122, 1541, 3753, 1143, 1115, 146, 1108, 3742, 1682, 1106, 1712, 8264, 2903, 1142, 1141, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1135, 1110, 22564, 1115, 1142, 2523, 1110, 1164, 170, 9140, 4792, 1187, 1103, 23641, 1105, 7550, 1243, 6376, 2716, 2017, 1114, 1296, 1168, 119, 4222, 1201, 1224, 117, 9326, 1403, 6778, 11748, 112, 188, 4252, 118, 6124, 117, 27688, 15197, 13444, 1125, 170, 1855, 1778, 1326, 1270, 107, 5148, 4568, 1158, 107, 11569, 1103, 1642, 1911, 1121, 9326, 1403, 6778, 11748, 119, 2096, 1736, 117, 1175, 1108, 170, 1632, 3719, 1107, 1115, 1103, 1326, 13892, 1113, 5606, 1104, 20787, 2340, 8556, 117, 1229, 1142, 4642, 1106, 1294, 1202, 1114, 15933, 23743, 1105, 170, 1374, 13084, 5892, 2442, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 19984, 1413, 131, 1135, 9562, 112, 189, 1185, 107, 11594, 5148, 107, 1105, 1178, 170, 1304, 4554, 1683, 1104, 107, 1327, 112, 188, 3725, 117, 11387, 107, 119, 102], [101, 1409, 1103, 3039, 1481, 107, 25249, 17758, 107, 1518, 2373, 1142, 117, 1303, 112, 188, 1199, 5566, 3713, 131, 133, 9304, 120, 135, 133, 9304, 120, 135, 122, 119, 1130, 170, 107, 157, 10073, 2050, 5135, 1158, 107, 118, 2076, 2523, 117, 1122, 112, 188, 1136, 170, 1363, 1911, 1106, 22884, 1601, 118, 12534, 1104, 142, 17145, 2069, 3663, 18581, 13821, 3048, 15969, 7462, 150, 2346, 23314, 2036, 1107, 1103, 2280, 6459, 119, 1337, 12246, 1106, 188, 5674, 2723, 1103, 24008, 117, 194, 112, 1221, 119, 119, 119, 136, 133, 9304, 120, 135, 133, 9304, 120, 135, 123, 119, 146, 1221, 1128, 1666, 1142, 1113, 170, 5743, 28108, 1105, 118, 1106, 1129, 4652, 118, 1128, 1589, 27658, 1114, 1240, 4788, 1133, 4268, 117, 11562, 1234, 1150, 1169, 2140, 2496, 119, 2926, 1120, 1655, 117, 2647, 117, 2037, 1105, 8982, 1120, 1103, 1269, 1159, 119, 2658, 11679, 9146, 2340, 117, 146, 112, 182, 1702, 1120, 1128, 119, 119, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 124, 119, 1409, 1128, 112, 1231, 1280, 1106, 1383, 170, 1226, 1104, 1240, 2523, 1107, 1103, 1763, 117, 1178, 1202, 1142, 1191, 1128, 1138, 1103, 21146, 1116, 1105, 13452, 1104, 1103, 1159, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 125, 119, 157, 10073, 2050, 25289, 1132, 3155, 1106, 1129, 170, 3774, 119, 6542, 117, 1195, 1274, 112, 189, 1328, 24008, 1115, 1294, 1185, 2305, 117, 1133, 2951, 21341, 1158, 1103, 107, 7063, 107, 1112, 1770, 1112, 1128, 8698, 170, 1959, 136, 1337, 112, 188, 1136, 170, 1632, 1911, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 23209, 12847, 1106, 1103, 3713, 1111, 1774, 117, 1133, 1107, 1155, 19242, 117, 146, 112, 173, 1897, 1152, 2018, 112, 189, 119, 119, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 2809, 1111, 16192, 3254, 7136, 12948, 1116, 119, 102], [101, 146, 1138, 1136, 1562, 1242, 1822, 4788, 2441, 178, 1538, 5890, 117, 1133, 1142, 1110, 1103, 4997, 2523, 1518, 1930, 117, 1103, 1514, 1959, 1103, 1385, 1299, 5029, 1176, 117, 1119, 1125, 170, 25338, 19937, 18574, 1105, 1575, 1103, 1540, 1106, 2936, 1167, 1190, 1141, 1937, 1451, 126, 3071, 117, 170, 126, 1214, 1385, 1180, 2496, 1618, 119, 1109, 1642, 1125, 1103, 1211, 9684, 4928, 117, 1105, 1218, 1103, 2306, 2564, 1125, 1508, 1184, 1119, 1354, 1108, 2306, 1176, 1105, 1173, 1198, 1355, 1166, 1103, 1499, 117, 178, 1178, 2542, 1122, 1106, 4046, 1120, 1293, 2213, 1122, 1108, 117, 1105, 4320, 1122, 1108, 2020, 2135, 1103, 1842, 2523, 119, 146, 1169, 1204, 2059, 1122, 1108, 1223, 1103, 123, 1480, 13519, 1645, 1120, 3510, 27338, 1116, 117, 1939, 1104, 170, 4268, 1321, 1142, 1111, 1714, 1105, 1243, 1122, 1149, 1104, 1412, 3617, 119, 146, 1341, 1175, 1108, 1141, 3533, 11858, 2811, 1168, 1190, 1103, 1590, 117, 178, 1341, 1103, 1178, 1645, 10899, 1114, 1103, 4788, 1108, 1103, 1294, 1146, 117, 1133, 1152, 1437, 1451, 1696, 2741, 1104, 1103, 1273, 1107, 1103, 2150, 1390, 2113, 119, 138, 2246, 2365, 2566, 9684, 119, 102], [101, 146, 1138, 2373, 1155, 1104, 1103, 2185, 3435, 19539, 1193, 2146, 119, 14881, 1554, 1218, 1115, 5558, 1169, 1136, 1329, 1155, 5402, 1104, 1103, 1520, 117, 1133, 2412, 1152, 1120, 1655, 1138, 1103, 1514, 1553, 1104, 1103, 1520, 119, 146, 1108, 3023, 9333, 1107, 1142, 2523, 119, 1109, 1178, 1645, 1115, 1152, 1138, 1107, 1142, 2523, 1115, 1110, 1107, 1103, 1520, 1110, 1115, 3056, 1183, 112, 188, 1401, 2502, 1106, 3143, 117, 113, 1780, 1107, 1103, 1520, 1241, 2153, 1435, 114, 119, 1337, 1110, 1155, 119, 1109, 1642, 1413, 1108, 1177, 6061, 1105, 1677, 21616, 1105, 4208, 117, 6782, 117, 1121, 1103, 1520, 117, 1115, 146, 1198, 1577, 112, 189, 5548, 1122, 119, 2431, 1191, 146, 1238, 112, 189, 2373, 1103, 1520, 1122, 1108, 1315, 6782, 119, 146, 1202, 1221, 1115, 14589, 1297, 1108, 5902, 117, 1133, 1103, 2006, 2523, 1108, 170, 1205, 1200, 119, 1109, 5261, 1110, 1111, 1515, 1103, 1269, 1266, 10592, 1104, 1103, 1273, 1115, 2228, 1172, 1632, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "preprocess_function(dataset[\"train\"][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-6iXTkIrJT"
      },
      "source": [
        "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "outputId": "b6414786-90eb-49ec-e715-ccc5ed119384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-39ee2938194f3dcb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b42357f7309e11a0.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-7fe0e4608da9e213.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns added by tokenizer: ['attention_mask', 'input_ids', 'token_type_ids']\n"
          ]
        }
      ],
      "source": [
        "pre_tokenizer_columns = set(dataset[\"train\"].features)\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "tokenizer_columns = list(set(encoded_dataset[\"train\"].features) - pre_tokenizer_columns)\n",
        "print(\"Columns added by tokenizer:\", tokenizer_columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset[\"train\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPy00P_ZLPTx",
        "outputId": "3da50547-a076-4d9d-8417-ae31cfd641bf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in encoded_dataset[\"train\"][0].items():\n",
        "  print(k, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcFE2eMvLalM",
        "outputId": "0b2d2c74-d12b-449e-dd49-67305609bc52"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "input_ids [101, 146, 12765, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1121, 1139, 1888, 2984, 1272, 1104, 1155, 1103, 6392, 1115, 4405, 1122, 1165, 1122, 1108, 1148, 1308, 1107, 2573, 119, 146, 1145, 1767, 1115, 1120, 1148, 1122, 1108, 7842, 1118, 158, 119, 156, 119, 10148, 1191, 1122, 1518, 1793, 1106, 3873, 1142, 1583, 117, 3335, 1217, 170, 5442, 1104, 2441, 1737, 107, 6241, 107, 146, 1541, 1125, 1106, 1267, 1142, 1111, 1991, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1109, 4928, 1110, 8663, 1213, 170, 1685, 3619, 3362, 2377, 1417, 14960, 1150, 3349, 1106, 3858, 1917, 1131, 1169, 1164, 1297, 119, 1130, 2440, 1131, 3349, 1106, 2817, 1123, 2209, 1116, 1106, 1543, 1199, 3271, 1104, 4148, 1113, 1184, 1103, 1903, 156, 11547, 1162, 1354, 1164, 2218, 1741, 2492, 1216, 1112, 1103, 4357, 1414, 1105, 1886, 2492, 1107, 1103, 1244, 1311, 119, 1130, 1206, 4107, 8673, 1105, 6655, 10552, 3708, 2316, 1104, 8583, 1164, 1147, 11089, 1113, 4039, 117, 1131, 1144, 2673, 1114, 1123, 3362, 3218, 117, 22150, 117, 1105, 1597, 1441, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1327, 8567, 1143, 1164, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1110, 1115, 1969, 1201, 2403, 117, 1142, 1108, 1737, 185, 8456, 9597, 119, 8762, 117, 1103, 2673, 1105, 183, 17294, 2340, 4429, 1132, 1374, 1105, 1677, 1206, 117, 1256, 1173, 1122, 112, 188, 1136, 2046, 1176, 1199, 10928, 1193, 1189, 185, 8456, 1186, 119, 1799, 1139, 1583, 2354, 1713, 1525, 1122, 19196, 117, 1107, 3958, 2673, 1105, 183, 17294, 2340, 1132, 170, 1558, 22088, 1107, 3619, 7678, 119, 2431, 1130, 14721, 1197, 27644, 117, 18271, 1147, 2590, 1106, 1363, 1385, 2298, 1287, 4100, 117, 1125, 2673, 4429, 1107, 1117, 2441, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 146, 1202, 3254, 2354, 1181, 1103, 18992, 1111, 1103, 1864, 1115, 1251, 2673, 2602, 1107, 1103, 1273, 1110, 2602, 1111, 6037, 4998, 1897, 1190, 1198, 1106, 4900, 1234, 1105, 1294, 1948, 1106, 1129, 2602, 1107, 185, 8456, 9597, 13090, 1107, 1738, 119, 146, 6586, 140, 19556, 19368, 13329, 118, 162, 21678, 2162, 17056, 1110, 170, 1363, 1273, 1111, 2256, 5277, 1106, 2025, 1103, 6092, 1105, 15866, 113, 1185, 23609, 1179, 3005, 114, 1104, 3619, 7678, 119, 1252, 1541, 117, 1142, 1273, 2144, 112, 189, 1138, 1277, 1104, 170, 4928, 119, 102]\n",
            "label 0\n",
            "text I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLGHbYzKAC9I"
      },
      "source": [
        "Finally, we convert our datasets to `tf.data.Dataset`. There's a built-in method for this, so all you need to do is specify the columns you want (both for the inputs and the labels), whether the data should be shuffled, the batch size, and an optional collation function, that controls how a batch of samples is combined.\n",
        "\n",
        "We'll need to supply a `DataCollator` for this. The `DataCollator` handles grouping each batch of samples together, and different tasks will require different data collators. In this case, we will use the `DataCollatorWithPadding`, because our samples need to be padded to the same length to form a batch. Remember to supply the `return_tensors` argument too - our data collators can handle multiple frameworks, so you need to be clear that you want TensorFlow tensors back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "dPaWZGZ9AC9J"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
        "\n",
        "tf_train_dataset = encoded_dataset[\"train\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns,\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "tf_validation_dataset = encoded_dataset[\"validation\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns,\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "tf_test_dataset = encoded_dataset[\"test\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns,\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To connect Google account to Colab\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "op3iVc_t7oVO",
        "outputId": "72d64caf-40cd-4d8e-8194-121943ecc006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# cd gdrive/MyDrive/bachelor_thesis\n",
        "# mkdir model_checkpoints\n",
        "# ls"
      ],
      "metadata": {
        "id": "isynxYFU8b8U"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path=\"/content/gdrive/MyDrive/bachelor_thesis/model_checkpoints/model.hdf5\""
      ],
      "metadata": {
        "id": "Kiu6TOiG9FNV"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBiW8UpKIrJW"
      },
      "source": [
        "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about sentence classification, we use the `TFAutoModelForSequenceClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which is always 2, except for STS-B which is a regression problem and MNLI where we have 3 labels). We also need to get the appropriate loss function (SparseCategoricalCrossentropy for every task except STSB, which as a regression problem requires MeanSquaredError).\n",
        "\n",
        "Note that all models in `transformers` compute loss internally too, and you can train on this loss value. This can be very helpful when the loss is not easy to specify yourself. To use this, pass the labels as a `labels` key in the input dictionary, and then compile the model without specifying a loss. You can see examples of this approach in several of the other TensorFlow notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "outputId": "165afec0-3112-4994-996c-561582810608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
        "# from_logits: Whether y_pred is expected to be a logits tensor. \n",
        "# By default, we assume that y_pred encodes a probability distribution (from_logits=False). \n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, \n",
        "    num_labels=dataset[\"train\"].features[\"label\"].num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CczA5lJlIrJX"
      },
      "source": [
        "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics to follow while training\n",
        "metrics = [\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc')\n",
        "]"
      ],
      "metadata": {
        "id": "PtANRhwfL3Ce"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "tr27FjrTAC9L"
      },
      "outputs": [],
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "num_epochs = 2 #5\n",
        "batches_per_epoch = len(encoded_dataset[\"train\"]) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=optimizer, \n",
        "    loss=loss,\n",
        "    metrics=metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQLGFIFAC9M"
      },
      "source": [
        "The `create_optimizer` function in the Transformers library creates a very useful `AdamW` optimizer with weight and learning rate decay. This performs very well for training most transformer networks - we recommend using it as your default unless you have a good reason not to! Note, however, that because it decays the learning rate over the course of training, it needs to know how many batches it will see during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Bliy8zgjIrJY"
      },
      "outputs": [],
      "source": [
        "# metric_name = \"accuracy\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km3pGVdTIrJc"
      },
      "source": [
        "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the `Trainer` to load the best model it saved (according to `metric_name`) at the end of training.\n",
        "\n",
        "The last two arguments are to setup everything so we can push the model to the [Hub](https://huggingface.co/models) at the end of training. Remove the two of them if you didn't follow the installation steps at the top of the notebook, otherwise you can change the value of `push_to_hub_model_id` to something you would prefer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sZOdRlRIrJd"
      },
      "source": [
        "The last thing to define is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, the only preprocessing we have to do is to take the argmax of our predicted logits (our just squeeze the last axis in the case of STS-B):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(predictions, labels):\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "#     # Partly adapted from UTU Textual Data Analysis course material:\n",
        "\n",
        "# def compute_metrics(pred):\n",
        "#     y_pred = pred.predictions.argmax(axis=1) \n",
        "#     # we get the probability distribution out and the highest is selected with argmax\n",
        "#     y_true = pred.label_ids\n",
        "#     TP = len([a and b for a, b in zip(y_pred, y_true) if a == 1 and b == 1])\n",
        "#     TN = len([a and b for a, b in zip(y_pred, y_true) if a == 0 and b == 0])\n",
        "#     FN = len([a and b for a, b in zip(y_pred, y_true) if a == 0 and b == 1])\n",
        "#     FP = len([a and b for a, b in zip(y_pred, y_true) if a == 1 and b == 0])\n",
        "\n",
        "#     ACC = (TP+TN)/(TP+FP+FN+TN) # Overall accuracy\n",
        "#     PRE = TP/(TP+FP) # Precision: share of relevant items\n",
        "#     REC = TP/(TP+FN) # Recall: proportion of relevant items found\n",
        "#     F1 = (2*((PRE*REC)/(PRE+REC))) # Balance between precision and recall\n",
        "#     return {'accuracy': ACC,\n",
        "#             'precision': PRE, \n",
        "#             'recall': REC,\n",
        "#             'F1-score':F1\n",
        "#             }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JwrJaGAAC9N"
      },
      "source": [
        "We can now finetune our model by just calling the `fit` method. Be sure to pass the TF datasets, and not the original datasets! We can also add a callback to sync up our model with the Hub - this allows us to resume training from other machines and even test the model's inference quality midway through training! Make sure to change the `username` if you do. If you don't want to do this, simply remove the callbacks argument in the call to `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "imY1oC3SIrJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "51235b97-35e0-425a-af87-039d297db06f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-6d1b417ceed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_validation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     ) \n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# TODO: early stopping, save best\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                  save_weights_only=True,\n",
        "#                                                  verbose=1)\n",
        "mc_cb = ModelCheckpoint(filepath=file_path, \n",
        "                        monitor='val_loss', # true positive better metrics!\n",
        "                        # monitor='auc',\n",
        "                        verbose=1, \n",
        "                        save_best_only=True, \n",
        "                        save_weights_only=True, # only the weights are saved. To use them a model is needed but it can be saved elsewhere or restored from this notebook\n",
        "                        save_freq='epoch', # save after every epoch\n",
        "                        mode='auto')\n",
        "\n",
        "history = model.fit(\n",
        "    tf_train_dataset,\n",
        "    verbose=1,\n",
        "    epochs=3, \n",
        "    validation_data=tf_validation_dataset,\n",
        "    callbacks=[mc_cb],\n",
        "    ) \n",
        "\n",
        "# model.fit(\n",
        "#     tf_train_dataset,\n",
        "#     validation_data=tf_validation_dataset,\n",
        "#     epochs=2#3,\n",
        "#     # callbacks=[callback],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(history):\n",
        "  metrics =  ['loss']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.plot(figsize=(6,6))\n",
        "    plt.plot(history.epoch, history.history[metric], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.ylabel(name)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2beWJ5dNWE0B"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(history)\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "for k, v in history.history.items():\n",
        "  print(k, v)\n"
      ],
      "metadata": {
        "id": "l_t0YqXyY-JX",
        "outputId": "b7db969b-2e9d-47f0-edbe-89d10d874aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n",
            "loss [0.39979517459869385, 0.14169131219387054]\n",
            "val_loss [0.3041481077671051, 0.2552860677242279]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(history)"
      ],
      "metadata": {
        "id": "pi5TUT7gWQMN",
        "outputId": "d97d139c-d91b-4a52-9821-511dfa2a5d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKASz-2vIrJi"
      },
      "source": [
        "We can add Keras metrics during compilation above if we want to get live readouts during training, or we can use the `compute_metrics` function after training to compute the metrics specified for each task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "UOUcBkX8IrJi"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(tf_test_dataset)[\"logits\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "bazu6d8fAC9P",
        "outputId": "965bb3d3-1bdf-47af-992e-63b00f50484e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-047466705bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# compute_metrics(predictions, np.array(encoded_dataset[validation_key][\"label\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_metrics' is not defined"
          ]
        }
      ],
      "source": [
        "compute_metrics(predictions, np.array(encoded_dataset[\"test\"][\"label\"]))\n",
        "# compute_metrics(predictions, np.array(encoded_dataset[validation_key][\"label\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP"
      ],
      "metadata": {
        "id": "iB1be03DHndB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip --quiet install shap"
      ],
      "metadata": {
        "id": "qmw-aVgyIJMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html?highlight=return_all_scores\n",
        "# https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html?highlight=return_all_scores#\n",
        "\n",
        "# classifier = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n",
        "# classifier(short_data[:2])\n",
        "\n",
        "classifier = transformers.pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer, return_all_scores=True)\n",
        "short_data = [v[:500] for v in dataset[\"test\"][\"text\"][:20]] # first 500 lettres from the first 20 test split texts\n",
        "classifier(short_data[:2]) # pipeline predictions for the 2 first samples in the \"short_data\"\n",
        "# Labels need to be int for the model, thus 'LABEL_0' and 'LABEL_1'\n",
        "# TODO: fix labels"
      ],
      "metadata": {
        "id": "R069ZDNAojGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(short_data)"
      ],
      "metadata": {
        "id": "_jdIl53xVCgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the explainer\n",
        "explainer = shap.Explainer(classifier)"
      ],
      "metadata": {
        "id": "a-pwXs_tToic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explain the predictions of the pipeline on the first two samples\n",
        "shap_values = explainer(short_data[:2])"
      ],
      "metadata": {
        "id": "oet4p9OtTpfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values[:,:,\"LABEL_0\"])"
      ],
      "metadata": {
        "id": "fQXpelXnT7RJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Text Classification on GLUE",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1988cfb7fa794eb4b396eaa53cbc5009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42b59d9069284acbb645bdc9885a4e0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a9bd000af1a412d8c869a14136cd646",
              "IPY_MODEL_e11fa7955c7e43e38b608c8cbade8060",
              "IPY_MODEL_4d090cd79fab487483f43ca69d5b15e9"
            ]
          }
        },
        "42b59d9069284acbb645bdc9885a4e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a9bd000af1a412d8c869a14136cd646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b13d84d0ea514624b89688b241b67367",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe1fa96aeed14d7394aa24f4504f3d99"
          }
        },
        "e11fa7955c7e43e38b608c8cbade8060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e33748c0073e41f0a9fffe5a38331822",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05c61a93e1f44d80b9bb1bef5912dffc"
          }
        },
        "4d090cd79fab487483f43ca69d5b15e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57eb186a1fb94c98bd4d136c76ebad11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 56.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36e4b5ad2c9349b493dc7d322055839d"
          }
        },
        "b13d84d0ea514624b89688b241b67367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe1fa96aeed14d7394aa24f4504f3d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e33748c0073e41f0a9fffe5a38331822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05c61a93e1f44d80b9bb1bef5912dffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57eb186a1fb94c98bd4d136c76ebad11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36e4b5ad2c9349b493dc7d322055839d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}