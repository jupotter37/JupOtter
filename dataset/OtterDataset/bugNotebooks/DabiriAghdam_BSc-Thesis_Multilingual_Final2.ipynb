{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo7kpNZnRzoB"
      },
      "source": [
        "# Multi-task Training with Hugging Face Transformers and NLP\n",
        "\n",
        "### Or: A recipe for multi-task training with Transformers' Trainer and NLP datasets\n",
        "\n",
        "\n",
        "\n",
        "Hugging Face has been building a lot of exciting new NLP functionality lately. The newly released [NLP](https://github.com/huggingface/nlp) provides a wide coverage of task data sets and metrics, as well as a simple interface for processing and caching the inputs extremely efficiently. They have also recently introduced a [Trainer](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py) class to the Transformers library that handles all of the training and validation logic.\n",
        "\n",
        "However, one feature that is not currently supported in Hugging Face's current offerings is *multi-task training*. While there has been some discussion about the best way to support multi-task training ([1](https://github.com/huggingface/transformers/issues/4340), [2](https://github.com/huggingface/nlp/issues/217)), the community has not yet settled on a convention for doing so. Multi-task training has been shown to improve task performance ([1](https://www.aclweb.org/anthology/P19-1441/), [2](https://arxiv.org/abs/1910.10683)) and is a common experimental setting for NLP researchers.\n",
        "\n",
        "In this Colab notebook, we will show how to use both the new NLP library as well as the Trainer for a **multi-task** training scheme.\n",
        "\n",
        "So let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL26RIVZTgGf",
        "outputId": "3d3d2292-58a4-4416-a175-e9a5577caec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n90H9I0cMQvY"
      },
      "source": [
        "## Library setup\n",
        "\n",
        "First up, we will install libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlICaYzQan59",
        "outputId": "ec0f32e3-8ddd-480d-a9b0-7d205d3349b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers==4.28.1\n",
        "!pip install -q datasets==2.12.0\n",
        "!pip install -q import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejhYiFELazOd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import logging\n",
        "import import_ipynb\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import dataclasses\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# from transformers.training_args import is_tpu_available\n",
        "# from transformers.trainer import get_tpu_sampler\n",
        "from transformers.data.data_collator import DataCollator, InputDataClass\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "import pickle\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from contextlib import contextmanager\n",
        "from pathlib import Path\n",
        "from typing import Callable, Dict, List, Optional, Tuple\n",
        "\n",
        "from numpy import savetxt, loadtxt\n",
        "from packaging import version\n",
        "from torch import nn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "from transformers.data.data_collator import DataCollator, DefaultDataCollator\n",
        "from transformers.modeling_utils import PreTrainedModel\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR, EvalPrediction, PredictionOutput, TrainOutput\n",
        "from transformers.training_args import TrainingArguments\n",
        "\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YohsLXwjiUOx"
      },
      "source": [
        "**dataset_code is an indication of each of the available tasks (datasets):**\n",
        "\n",
        "*  dataset_code = 0: the corresponding French *task/dataset*\n",
        "*  dataset_code = 1: the corresponding English *task/dataset*\n",
        "*  dataset_code = 2: the corresponding Farsi *task/dataset*\n",
        "\n",
        "\n",
        "\n",
        "**Combination** is an integer number ranging from 0 to 2, pointing out to one of the possible options in multi-task mode:\n",
        "\n",
        "\n",
        "\n",
        "*   Combination = 0: We are considering => *English & French*\n",
        "*   Combination = 1: We are considering => *English & Farsi*\n",
        "*   Combination = 2: We are considering => *French & Farsi*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46WkDrq1vkb5"
      },
      "source": [
        "# Set the required configuration\n",
        "\n",
        "This process is done by calling another notebook from diffrent location in Google drive (The notebook was named as **\"Fetching_required_status\"**)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Inside this notebook, there exist several practical functions, each of which is kind of dealing with setting our overall status (eg. fine-tune, the dataset type, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkoCAfOcuDMr",
        "outputId": "0f6ff079-f7be-42e6-b2e8-63ff5de4ada5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/17KSuF77xEb0EV_xu89tbzatr7bcePtCI/NLP Bachelors' Project/Notebooks/Forgettable\n",
            "importing Jupyter notebook from Fetching_required_status_multilingual2.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/NLP Bachelors' Project/Notebooks/Forgettable\"\n",
        "import Fetching_required_status_multilingual2 as Fetching_required_status_multilingual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Ul_cr0AVPI"
      },
      "outputs": [],
      "source": [
        "Fine_tune, Combination, dataset_code = Fetching_required_status_multilingual.set_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPeyGHJO9Jy6"
      },
      "outputs": [],
      "source": [
        "path_to_checkpoint, path_to_pretrained_weight = Fetching_required_status_multilingual.set_path(Fine_tune, Combination, dataset_code, from_gdrive = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ_TXPJm7a1d"
      },
      "outputs": [],
      "source": [
        "len(os.listdir(path_to_checkpoint))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEGbnI1DzbZ9"
      },
      "outputs": [],
      "source": [
        "Last_Actual_checkpoint = Fetching_required_status_multilingual.return_last_checkpoint(path_to_checkpoint)\n",
        "Last_PreTrained_checkpoint = Fetching_required_status_multilingual.return_last_checkpoint(path_to_pretrained_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7mzw-5zAVUs"
      },
      "outputs": [],
      "source": [
        "Last_Actual_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCamBNJGAWJd"
      },
      "outputs": [],
      "source": [
        "Last_PreTrained_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNgGsQB_E8tW"
      },
      "outputs": [],
      "source": [
        "model_name = Fetching_required_status_multilingual.return_model_name(Fine_tune, path_to_pretrained_weight, Last_PreTrained_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z14oVnHVVK0-"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Rn7NprxjnA"
      },
      "outputs": [],
      "source": [
        "dataset_dict = Fetching_required_status_multilingual.return_dataset(dataset_code, Combination, Fine_tune, drop_unlearned = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wbV_-8mybSz"
      },
      "outputs": [],
      "source": [
        "dataset_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYjeiCL9hb-0"
      },
      "outputs": [],
      "source": [
        "# from datasets import Dataset\n",
        "# dataset_dict['English']['train'] = Dataset.from_dict(dataset_dict['English']['train'][:50])\n",
        "# dataset_dict['French']['train'] = Dataset.from_dict(dataset_dict['French']['train'][:50])\n",
        "# dataset_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxrm9NE7PZ9h"
      },
      "source": [
        "\n",
        "## Selecting Hyperparameters (Global parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pS1jO_bPa4A"
      },
      "outputs": [],
      "source": [
        "num_labels = {'French2': 31, 'English2': 151, 'Farsi': 60} # Number of labels in each dataset\n",
        "num_epochs = 3 # Number of epoch\n",
        "B_size = 16 # Number of batch size\n",
        "EP_saved = 3 # Saved checkpoints per EP_saved epochs\n",
        "max_length = 256 # The maximum length for the pre-processing step\n",
        "lr = (2.4e-5)/24 # the specified learning rate during the learning procedure.   #2.4e-5\n",
        "lg_step = math.ceil(len(dataset_dict[list(dataset_dict.keys())[0]]['train'])/B_size) + math.ceil(len(dataset_dict[list(dataset_dict.keys())[1]]['train'])/B_size)\n",
        "# the number of step before showing info during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdVzvWW9-HhS"
      },
      "source": [
        "## Creating a Multi-task Model using share encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A47O_QfGHXyt"
      },
      "outputs": [],
      "source": [
        "class MultitaskModel(transformers.PreTrainedModel):\n",
        "    def __init__(self, encoder, taskmodels_dict):\n",
        "        \"\"\"\n",
        "        Setting MultitaskModel up as a PretrainedModel allows us\n",
        "        to take better advantage of Trainer features\n",
        "        \"\"\"\n",
        "        super().__init__(transformers.PretrainedConfig())\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, model_name, model_type_dict, model_config_dict):\n",
        "        \"\"\"\n",
        "        This creates a MultitaskModel using the model class and config objects\n",
        "        from single-task models.\n",
        "\n",
        "        We do this by creating each single-task model, and having them share\n",
        "        the same encoder transformer.\n",
        "        \"\"\"\n",
        "        shared_encoder = None\n",
        "        taskmodels_dict = {}\n",
        "        for task_name, model_type in model_type_dict.items():\n",
        "            model = model_type.from_pretrained(\n",
        "                model_name,\n",
        "                config=model_config_dict[task_name],\n",
        "            )\n",
        "\n",
        "            if shared_encoder is None:\n",
        "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
        "            else:\n",
        "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
        "\n",
        "            taskmodels_dict[task_name] = model\n",
        "\n",
        "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
        "\n",
        "    @classmethod\n",
        "    def get_encoder_attr_name(cls, model):\n",
        "        \"\"\"\n",
        "        The encoder transformer is named differently in each model \"architecture\".\n",
        "        This method lets us get the name of the encoder attribute\n",
        "        \"\"\"\n",
        "        model_class_name = model.__class__.__name__\n",
        "        if model_class_name.startswith(\"Bert\"):\n",
        "            return \"bert\"\n",
        "        elif model_class_name.startswith(\"Roberta\"):\n",
        "            return \"roberta\"\n",
        "        elif model_class_name.startswith(\"Albert\"):\n",
        "            return \"albert\"\n",
        "        elif model_class_name.startswith(\"XLMRoberta\"):\n",
        "            return \"roberta\"\n",
        "        else:\n",
        "            raise KeyError(f\"Add support for new model {model_class_name}\")\n",
        "\n",
        "    def forward(self, task_name, **kwargs):\n",
        "        return self.taskmodels_dict[task_name](**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zSZsp8Cb7gd"
      },
      "source": [
        "As described above, the `MultitaskModel` class consists of only two components - the shared \"encoder\", a dictionary to the individual task models. Now, we can simply create the corresponding task models by supplying the invidual model classes and model configs. We will use Transformers' AutoModels to further automate the choice of model class given a model architecture (in our case, let's use `roberta-base`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu4_fECeRF8V"
      },
      "source": [
        "# Create model or using pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_sosFINo24B"
      },
      "outputs": [],
      "source": [
        "multitask_model = MultitaskModel.create(\n",
        "    model_name=model_name,\n",
        "    model_type_dict={\n",
        "        list(dataset_dict.keys())[0]: transformers.AutoModelForSequenceClassification,\n",
        "        list(dataset_dict.keys())[1]: transformers.AutoModelForSequenceClassification,\n",
        "    },\n",
        "    model_config_dict={\n",
        "        list(dataset_dict.keys())[0]: transformers.AutoConfig.from_pretrained(model_name, num_labels=num_labels[list(dataset_dict.keys())[0]]),\n",
        "        list(dataset_dict.keys())[1]: transformers.AutoConfig.from_pretrained(model_name, num_labels=num_labels[list(dataset_dict.keys())[1]]),\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxSAQ6q4O-uL"
      },
      "source": [
        "To confirm that all three task-models use the same encoder, we can check the data pointers of the respective encoders. In this case, we'll check that the word embeddings in each model all point to the same memory location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PujQR2HkPTRk"
      },
      "source": [
        "## Processing our task data\n",
        "\n",
        "We have created a dictionary of NLP datasets above, but we need to do a little more work to convert the respective task data into model inputs.\n",
        "\n",
        "We'll start by first getting the tokenizer corresponding to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx8Z8Y9B49Zo"
      },
      "outputs": [],
      "source": [
        "def set_feature_input_mode(example_batch, task_order):\n",
        "\n",
        "  '''\n",
        "  Task_order specifies two different modes for our function, \"1\" as passing the first multi-task task,\n",
        "  and \"2\" as passing the second multi-task task.\n",
        "  '''\n",
        "\n",
        "  Input = {} # Input initialization\n",
        "  Label = {\"French2\": \"intent\", \"English2\": \"intent\",\"Farsi\": \"intent\"} # label encoding\n",
        "  #---------------------------------------------------------------------------------------#\n",
        "\n",
        "  if Combination == 0:\n",
        "    if task_order == 1:\n",
        "      Input[\"English2\"] = list(example_batch['utt'])\n",
        "    else:\n",
        "      Input[\"French2\"] = list(example_batch['utt'])\n",
        "  elif Combination == 1:\n",
        "    if task_order == 1:\n",
        "      Input[\"English2\"] = list(example_batch['utt'])\n",
        "    else:\n",
        "      Input[\"Farsi\"] = list(example_batch['utt'])\n",
        "  else:\n",
        "    if task_order == 1:\n",
        "      Input[\"French2\"] = list(example_batch['utt'])\n",
        "    else:\n",
        "      Input[\"Farsi\"] = list(example_batch['utt'])\n",
        "\n",
        "  return Input[list(dataset_dict.keys())[task_order - 1]], Label[list(dataset_dict.keys())[task_order - 1]]\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------#\n",
        "def Convert_To_Features_Task1(example_batch):\n",
        "  Input, Label = set_feature_input_mode(example_batch, task_order = 1)\n",
        "  Feature = tokenizer.batch_encode_plus(Input, max_length=max_length, pad_to_max_length=True)\n",
        "  Feature[\"labels\"] = example_batch[Label]\n",
        "  return Feature\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------#\n",
        "def Convert_To_Features_Task2(example_batch):\n",
        "  Input, Label = set_feature_input_mode(example_batch, task_order = 2)\n",
        "  Feature = tokenizer.batch_encode_plus(Input, max_length=max_length, pad_to_max_length=True)\n",
        "  Feature[\"labels\"] = example_batch[Label]\n",
        "  return Feature\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------#\n",
        "convert_func_dict = {\n",
        "    list(dataset_dict.keys())[0]: Convert_To_Features_Task1,\n",
        "    list(dataset_dict.keys())[1]: Convert_To_Features_Task2,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eULIAQ9WRYXn"
      },
      "source": [
        "Now that we have defined the above functions, we can use `dataset.map` method available in the NLP library to apply the functions over our entire datasets. The NLP library that handles the mapping efficiently and caches the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcLnS85Hkhbf"
      },
      "outputs": [],
      "source": [
        "columns_dict = {\n",
        "    list(dataset_dict.keys())[0]: ['input_ids', 'attention_mask', 'labels'],\n",
        "    list(dataset_dict.keys())[1]: ['input_ids', 'attention_mask', 'labels'],\n",
        "}\n",
        "\n",
        "features_dict = {}\n",
        "for task_name, dataset in dataset_dict.items():\n",
        "    features_dict[task_name] = {}\n",
        "    for phase, phase_dataset in dataset.items():\n",
        "        features_dict[task_name][phase] = phase_dataset.map(\n",
        "            convert_func_dict[task_name],\n",
        "            batched=True,\n",
        "            load_from_cache_file=False,\n",
        "        )\n",
        "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
        "        features_dict[task_name][phase].set_format(\n",
        "            type=\"torch\",\n",
        "            columns=columns_dict[task_name],\n",
        "        )\n",
        "    print(\"\\n\")\n",
        "        #print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33Yu15nSurv"
      },
      "source": [
        "As a recap:\n",
        "\n",
        "* We have created our multi-task model by fusing several single-task Transformer models\n",
        "* We have created a (cached) dictionary of featurized inputs for each of our tasks, using NLP dataset\n",
        "\n",
        "Next up, we need to\n",
        "\n",
        "1. Set up our data loading\n",
        "2. Set up our Trainer\n",
        "3. Start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4N7IF9hTR7m"
      },
      "source": [
        "## Preparing a multi-task data loader and Trainer\n",
        "\n",
        "Setting up a multi-task data loader should be simple in principle - we simply need to sample from multiple single-task data loaders with some probability, and feed each batch to the multi-task model above. Of course, along with each batch, we also need to tell the model what task it is for, so `MultitaskModel` knows to use the right corresponding task-model.\n",
        "\n",
        "However, because we want to use the built-in `Trainer` class in Transformers, this gets a little tricky, since the `Trainer` expects a single data loader, and expects a very specific format of per-batch data. This slice of code is somewhat of a hack around that constraint. (This can become a lot more streamlined with some tweaks to the Trainer code from the Hugging Face folks =))\n",
        "\n",
        "We need to define a `MultitaskDataloader` that combines several data loaders into a single \"data loader\" - not so different from our multi-task model above! This `MultitaskDataloader` should do what we described: sample from different single-task data loaders, and yield a task batch and the corresponding task name (we're going to add the `task_name` to the batch data).\n",
        "\n",
        "We will also need to override the `get_train_dataloader` method of the `Trainer` to play well with our `MultitaskDataloader`. We do this with a `MultitaskTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6-8FzlzHf5l"
      },
      "outputs": [],
      "source": [
        "# Integrations must be imported before ML frameworks:\n",
        "from transformers.integrations import hp_params\n",
        "import dataclasses\n",
        "import collections\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "from transformers.data.data_collator import DataCollator, InputDataClass, DefaultDataCollator\n",
        "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
        "from transformers.trainer_callback import TrainerState\n",
        "from transformers.trainer_pt_utils import IterableDatasetShard\n",
        "from transformers.file_utils import WEIGHTS_NAME, CONFIG_NAME\n",
        "from transformers.utils import logging\n",
        "from transformers.configuration_utils import PretrainedConfig\n",
        "from transformers import __version__\n",
        "from transformers.trainer_utils import speed_metrics, get_last_checkpoint, ShardedDDPOption, TrainOutput\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import warnings\n",
        "if TYPE_CHECKING:\n",
        "    import optuna\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "class NLPDataCollator:\n",
        "    \"\"\"\n",
        "    Extending the existing DataCollator to work with NLP dataset batches\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self, features: List[Union[InputDataClass, Dict]]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        first = features[0]\n",
        "        if isinstance(first, dict):\n",
        "            # NLP data sets current works presents features as lists of dictionary\n",
        "            # (one per example), so we  will adapt the collate_batch logic for that\n",
        "            if \"labels\" in first and first[\"labels\"] is not None:\n",
        "                if first[\"labels\"].dtype == torch.int64:\n",
        "                    labels = torch.tensor(\n",
        "                        [f[\"labels\"] for f in features], dtype=torch.long\n",
        "                    )\n",
        "                else:\n",
        "                    labels = torch.tensor(\n",
        "                        [f[\"labels\"] for f in features], dtype=torch.float\n",
        "                    )\n",
        "                batch = {\"labels\": labels}\n",
        "            for k, v in first.items():\n",
        "                if k != \"labels\" and v is not None and not isinstance(v, str):\n",
        "                    batch[k] = torch.stack([f[k] for f in features])\n",
        "            return batch\n",
        "        else:\n",
        "            # otherwise, revert to using the default collate_batch\n",
        "            return DefaultDataCollator().collate_batch(features)\n",
        "\n",
        "\n",
        "class StrIgnoreDevice(str):\n",
        "    \"\"\"\n",
        "    This is a hack. The Trainer is going call .to(device) on every input\n",
        "    value, but we need to pass in an additional `task_name` string.\n",
        "    This prevents it from throwing an error\n",
        "    \"\"\"\n",
        "\n",
        "    def to(self, device):\n",
        "        return self\n",
        "\n",
        "\n",
        "class DataLoaderWithTaskname:\n",
        "    \"\"\"\n",
        "    Wrapper around a DataLoader to also yield a task name\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_name, data_loader):\n",
        "        self.task_name = task_name\n",
        "        self.data_loader = data_loader\n",
        "\n",
        "        self.batch_size = data_loader.batch_size\n",
        "        self.dataset = data_loader.dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_loader)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in self.data_loader:\n",
        "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
        "            yield batch\n",
        "\n",
        "\n",
        "class MultitaskDataloader:\n",
        "    \"\"\"\n",
        "    Data loader that combines and samples from multiple single-task\n",
        "    data loaders.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataloader_dict):\n",
        "        self.dataloader_dict = dataloader_dict\n",
        "        self.num_batches_dict = {\n",
        "            task_name: len(dataloader)\n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        self.task_name_list = list(self.dataloader_dict)\n",
        "        self.dataset = [None] * sum(\n",
        "            len(dataloader.dataset) for dataloader in self.dataloader_dict.values()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(self.num_batches_dict.values())\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        For each batch, sample a task, and yield a batch from the respective\n",
        "        task Dataloader.\n",
        "\n",
        "        We use size-proportional sampling, but you could easily modify this\n",
        "        to sample from some-other distribution.\n",
        "        \"\"\"\n",
        "        task_choice_list = []\n",
        "        for i, task_name in enumerate(self.task_name_list):\n",
        "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
        "        task_choice_list = np.array(task_choice_list)\n",
        "        np.random.shuffle(task_choice_list)\n",
        "        dataloader_iter_dict = {\n",
        "            task_name: iter(dataloader)\n",
        "            for task_name, dataloader in self.dataloader_dict.items()\n",
        "        }\n",
        "        for task_choice in task_choice_list:\n",
        "            task_name = self.task_name_list[task_choice]\n",
        "            yield next(dataloader_iter_dict[task_name])\n",
        "\n",
        "\n",
        "class MultitaskTrainer(transformers.Trainer):\n",
        "\n",
        "    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Perform a training step on a batch of inputs.\n",
        "        Subclass and override to inject custom behavior.\n",
        "        Args:\n",
        "            model (:obj:`nn.Module`):\n",
        "                The model to train.\n",
        "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
        "                The inputs and targets of the model.\n",
        "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
        "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
        "        Return:\n",
        "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
        "        \"\"\"\n",
        "        model.train()\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "        # if is_sagemaker_mp_enabled():\n",
        "        #     scaler = self.scaler if self.use_amp else None\n",
        "        #     loss_mb = smp_forward_backward(model, inputs, self.args.gradient_accumulation_steps, scaler=scaler)\n",
        "        #     return loss_mb.reduce_mean().detach().to(self.args.device)\n",
        "\n",
        "        # if self.use_amp:\n",
        "        #     with autocast():\n",
        "        #         (loss, outputs) = self.compute_loss(model, inputs, return_outputs=True)\n",
        "        # else:\n",
        "        #     (loss, outputs) = self.compute_loss(model, inputs, return_outputs=True)\n",
        "        (loss, outputs) = self.compute_loss(model, inputs, return_outputs=True)\n",
        "\n",
        "        if self.args.n_gpu > 1:\n",
        "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "\n",
        "        if self.args.gradient_accumulation_steps > 1 and not self.deepspeed:\n",
        "            # deepspeed handles loss scaling by gradient_accumulation_steps in its `backward`\n",
        "            loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "        if self.use_amp:\n",
        "            self.scaler.scale(loss).backward()\n",
        "        # elif self.use_apex:\n",
        "        #     with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
        "                # scaled_loss.backward()\n",
        "        elif self.deepspeed:\n",
        "            # loss gets scaled under gradient_accumulation_steps in deepspeed\n",
        "            loss = self.deepspeed.backward(loss)\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        logits = outputs[\"logits\"] if isinstance(outputs, dict) else outputs[1]\n",
        "\n",
        "        return loss.detach(), logits.detach() #detach()?\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        resume_from_checkpoint: Optional[Union[str, bool]] = None,\n",
        "        resume_from_pretrained: Optional[Union[str, bool]] = None,\n",
        "        evaluate_during_training: Optional[Union[str, bool]] = None,\n",
        "        trial: Union[\"optuna.Trial\", Dict[str, Any]] = None,\n",
        "        ignore_keys_for_eval: Optional[List[str]] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Main training entry point.\n",
        "        Args:\n",
        "            resume_from_checkpoint (:obj:`str` or :obj:`bool`, `optional`):\n",
        "                If a :obj:`str`, local path to a saved checkpoint as saved by a previous instance of\n",
        "                :class:`~transformers.Trainer`. If a :obj:`bool` and equals `True`, load the last checkpoint in\n",
        "                `args.output_dir` as saved by a previous instance of :class:`~transformers.Trainer`. If present,\n",
        "                training will resume from the model/optimizer/scheduler states loaded here.\n",
        "            trial (:obj:`optuna.Trial` or :obj:`Dict[str, Any]`, `optional`):\n",
        "                The trial run or the hyperparameter dictionary for hyperparameter search.\n",
        "            ignore_keys_for_eval (:obj:`List[str]`, `optional`)\n",
        "                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
        "                gathering predictions for evaluation during the training.\n",
        "            kwargs:\n",
        "                Additional keyword arguments used to hide deprecated arguments\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        self.use_amp = False #workaround!!!!\n",
        "\n",
        "        ########################################################## Loading probabilities form array ###########################################################\n",
        "\n",
        "        Prob_per_epoch_first_task, Prob_per_epoch_second_task = Fetching_required_status_multilingual.check_directory_status(dataset_dict, resume_from_checkpoint, path_to_checkpoint, Combination, dataset_code, num_epochs, None, None, Mode = 1)\n",
        "        # print(Prob_per_epoch_first_task)\n",
        "\n",
        "        ################################################################ END #################################################################################\n",
        "\n",
        "        resume_from_checkpoint = None if not resume_from_checkpoint else resume_from_checkpoint\n",
        "\n",
        "        # memory metrics - must set up as early as possible\n",
        "        self._memory_tracker.start()\n",
        "\n",
        "        args = self.args\n",
        "\n",
        "        self.is_in_train = True\n",
        "\n",
        "        # do_train is not a reliable argument, as it might not be set and .train() still called, so\n",
        "        # the following is a workaround:\n",
        "        if args.fp16_full_eval and not args.do_train:\n",
        "            self._move_model_to_device(self.model, args.device)\n",
        "\n",
        "        if \"model_path\" in kwargs:\n",
        "            resume_from_checkpoint = kwargs.pop(\"model_path\")\n",
        "            warnings.warn(\n",
        "                \"`model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` \"\n",
        "                \"instead.\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "        if len(kwargs) > 0:\n",
        "            raise TypeError(f\"train() received got unexpected keyword arguments: {', '.join(list(kwargs.keys()))}.\")\n",
        "        # This might change the seed so needs to run first.\n",
        "        self._hp_search_setup(trial)\n",
        "\n",
        "        # Model re-init\n",
        "        model_reloaded = False\n",
        "        if self.model_init is not None:\n",
        "            # Seed must be set before instantiating the model when using model_init.\n",
        "            set_seed(args.seed)\n",
        "            self.model = self.call_model_init(trial)\n",
        "            model_reloaded = True\n",
        "            # Reinitializes optimizer and scheduler\n",
        "            self.optimizer, self.lr_scheduler = None, None\n",
        "\n",
        "        # Load potential model checkpoint\n",
        "        if isinstance(resume_from_checkpoint, bool) and resume_from_checkpoint:\n",
        "            resume_from_checkpoint = get_last_checkpoint(args.output_dir)\n",
        "            if resume_from_checkpoint is None:\n",
        "                raise ValueError(f\"No valid checkpoint found in output directory ({args.output_dir})\")\n",
        "\n",
        "        ################################# Resume from pretrained for fine-tuning ###################################################\n",
        "\n",
        "        if resume_from_pretrained is not None and resume_from_checkpoint is None:\n",
        "            print(\"loading from the pretrained weights ... \\n\")\n",
        "            if not os.path.isfile(os.path.join(resume_from_pretrained, WEIGHTS_NAME)):\n",
        "                raise ValueError(f\"Can't find a valid checkpoint at {resume_from_pretrained}\")\n",
        "\n",
        "            logger.info(f\"Loading model from {resume_from_checkpoint}).\")\n",
        "\n",
        "            if os.path.isfile(os.path.join(resume_from_pretrained, CONFIG_NAME)):\n",
        "                config = PretrainedConfig.from_json_file(os.path.join(resume_from_pretrained, CONFIG_NAME))\n",
        "                checkpoint_version = config.transformers_version\n",
        "                if checkpoint_version is not None and checkpoint_version != __version__:\n",
        "                    logger.warn(\n",
        "                        f\"You are resuming training from a checkpoint trained with {checkpoint_version} of \"\n",
        "                        f\"Transformers but your current version is {__version__}. This is not recommended and could \"\n",
        "                        \"yield to errors or unwanted behaviors.\"\n",
        "                    )\n",
        "\n",
        "            state_dict = torch.load(os.path.join(resume_from_pretrained, WEIGHTS_NAME), map_location=\"cpu\")\n",
        "            # If the model is on the GPU, it still works!\n",
        "            load_result = self.model.load_state_dict(state_dict, strict=True)\n",
        "            # release memory\n",
        "            del state_dict\n",
        "\n",
        "        ############################################### END ###############################################\n",
        "\n",
        "        if resume_from_checkpoint is not None:\n",
        "            # print(WEIGHTS_NAME)\n",
        "            print(resume_from_checkpoint)\n",
        "            if not os.path.isfile(os.path.join(resume_from_checkpoint, WEIGHTS_NAME)):\n",
        "                raise ValueError(f\"Can't find a valid checkpoint at {resume_from_checkpoint}\")\n",
        "\n",
        "            logger.info(f\"Loading model from {resume_from_checkpoint}).\")\n",
        "\n",
        "            if os.path.isfile(os.path.join(resume_from_checkpoint, CONFIG_NAME)):\n",
        "                config = PretrainedConfig.from_json_file(os.path.join(resume_from_checkpoint, CONFIG_NAME))\n",
        "                checkpoint_version = config.transformers_version\n",
        "                if checkpoint_version is not None and checkpoint_version != __version__:\n",
        "                    logger.warn(\n",
        "                        f\"You are resuming training from a checkpoint trained with {checkpoint_version} of \"\n",
        "                        f\"Transformers but your current version is {__version__}. This is not recommended and could \"\n",
        "                        \"yield to errors or unwanted behaviors.\"\n",
        "                    )\n",
        "\n",
        "            if args.deepspeed:\n",
        "                # will be resumed in deepspeed_init\n",
        "                pass\n",
        "            else:\n",
        "                # We load the model state dict on the CPU to avoid an OOM error.\n",
        "                state_dict = torch.load(os.path.join(resume_from_checkpoint, WEIGHTS_NAME), map_location=\"cpu\")\n",
        "                # If the model is on the GPU, it still works!\n",
        "                # self._load_state_dict_in_model(state_dict) #?????????\n",
        "                load_result = self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "                # release memory\n",
        "                del state_dict\n",
        "\n",
        "        # If model was re-initialized, put it on the right device and update self.model_wrapped\n",
        "        if model_reloaded:\n",
        "            if self.place_model_on_device:\n",
        "                self._move_model_to_device(self.model, args.device)\n",
        "            self.model_wrapped = self.model\n",
        "\n",
        "        # Keeping track whether we can can len() on the dataset or not\n",
        "        train_dataset_is_sized = isinstance(self.train_dataset, collections.abc.Sized)\n",
        "\n",
        "        # Data loader and number of training steps\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "\n",
        "        # Setting up training control variables:\n",
        "        # number of training epochs: num_train_epochs\n",
        "        # number of training steps per epoch: num_update_steps_per_epoch\n",
        "        # total number of training steps to execute: max_steps\n",
        "        total_train_batch_size = args.train_batch_size * args.gradient_accumulation_steps * args.world_size\n",
        "        if train_dataset_is_sized:\n",
        "            num_update_steps_per_epoch = len(train_dataloader) // args.gradient_accumulation_steps\n",
        "            num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
        "            if args.max_steps > 0:\n",
        "                max_steps = args.max_steps\n",
        "                num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
        "                    args.max_steps % num_update_steps_per_epoch > 0\n",
        "                )\n",
        "                # May be slightly incorrect if the last batch in the training datalaoder has a smaller size but it's\n",
        "                # the best we can do.\n",
        "                num_train_samples = args.max_steps * total_train_batch_size\n",
        "            else:\n",
        "                max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
        "                num_train_epochs = math.ceil(args.num_train_epochs)\n",
        "                num_train_samples = len(self.train_dataset) * args.num_train_epochs\n",
        "        else:\n",
        "            # see __init__. max_steps is set when the dataset has no __len__\n",
        "            max_steps = args.max_steps\n",
        "            # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
        "            num_train_epochs = sys.maxsize\n",
        "            num_update_steps_per_epoch = max_steps\n",
        "            num_train_samples = args.max_steps * total_train_batch_size\n",
        "\n",
        "        if DebugOption.UNDERFLOW_OVERFLOW in self.args.debug:\n",
        "            if self.args.n_gpu > 1:\n",
        "                # nn.DataParallel(model) replicates the model, creating new variables and module\n",
        "                # references registered here no longer work on other gpus, breaking the module\n",
        "                raise ValueError(\n",
        "                    \"Currently --debug underflow_overflow is not supported under DP. Please use DDP (torch.distributed.launch).\"\n",
        "                )\n",
        "            else:\n",
        "                debug_overflow = DebugUnderflowOverflow(self.model)  # noqa\n",
        "\n",
        "        delay_optimizer_creation = self.sharded_ddp is not None and self.sharded_ddp != ShardedDDPOption.SIMPLE\n",
        "        # if args.deepspeed:\n",
        "        #     deepspeed_engine, optimizer, lr_scheduler = deepspeed_init(\n",
        "        #         self, num_training_steps=max_steps, resume_from_checkpoint=resume_from_checkpoint\n",
        "        #     )\n",
        "        #     self.model = deepspeed_engine.module\n",
        "        #     self.model_wrapped = deepspeed_engine\n",
        "        #     self.deepspeed = deepspeed_engine\n",
        "        #     self.optimizer = optimizer\n",
        "        #     self.lr_scheduler = lr_scheduler\n",
        "        # elif not delay_optimizer_creation:\n",
        "        if not delay_optimizer_creation:\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        self.state = TrainerState()\n",
        "        self.state.is_hyper_param_search = trial is not None\n",
        "\n",
        "        model = self._wrap_model(self.model_wrapped)\n",
        "\n",
        "        # for the rest of this function `model` is the outside model, whether it was wrapped or not\n",
        "        if model is not self.model:\n",
        "            self.model_wrapped = model\n",
        "\n",
        "        if delay_optimizer_creation:\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        # Check if saved optimizer or scheduler states exist\n",
        "        self._load_optimizer_and_scheduler(resume_from_checkpoint)\n",
        "\n",
        "        # important: at this point:\n",
        "        # self.model         is the Transformers Model\n",
        "        # self.model_wrapped is DDP(Transformers Model), Deepspeed(Transformers Model), etc.\n",
        "\n",
        "        # Train!\n",
        "        num_examples = (\n",
        "            self.num_examples(train_dataloader) if train_dataset_is_sized else total_train_batch_size * args.max_steps\n",
        "        )\n",
        "\n",
        "        logger.info(\"***** Running training *****\")\n",
        "        logger.info(f\"  Num examples = {num_examples}\")\n",
        "        logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
        "        logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
        "        logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size}\")\n",
        "        logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "        logger.info(f\"  Total optimization steps = {max_steps}\")\n",
        "\n",
        "        self.state.epoch = 0\n",
        "        start_time = time.time()\n",
        "        epochs_trained = 0\n",
        "        steps_trained_in_current_epoch = 0\n",
        "        steps_trained_progress_bar = None\n",
        "\n",
        "        # Check if continuing training from a checkpoint\n",
        "        if resume_from_checkpoint is not None and os.path.isfile(\n",
        "            os.path.join(resume_from_checkpoint, \"trainer_state.json\")\n",
        "        ):\n",
        "            self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, \"trainer_state.json\"))\n",
        "            epochs_trained = self.state.global_step // num_update_steps_per_epoch\n",
        "            if not args.ignore_data_skip:\n",
        "                steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n",
        "                steps_trained_in_current_epoch *= args.gradient_accumulation_steps\n",
        "            else:\n",
        "                steps_trained_in_current_epoch = 0\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
        "            logger.info(f\"  Continuing training from global step {self.state.global_step}\")\n",
        "            if not args.ignore_data_skip:\n",
        "                logger.info(\n",
        "                    f\"  Will skip the first {epochs_trained} epochs then the first {steps_trained_in_current_epoch} \"\n",
        "                    \"batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` \"\n",
        "                    \"flag to your launch command, but you will resume the training on data already seen by your model.\"\n",
        "                )\n",
        "                if self.is_local_process_zero() and not args.disable_tqdm:\n",
        "                    steps_trained_progress_bar = tqdm(total=steps_trained_in_current_epoch)\n",
        "                    steps_trained_progress_bar.set_description(\"Skipping the first batches\")\n",
        "\n",
        "        # Update the references\n",
        "        self.callback_handler.model = self.model\n",
        "        self.callback_handler.optimizer = self.optimizer\n",
        "        self.callback_handler.lr_scheduler = self.lr_scheduler\n",
        "        self.callback_handler.train_dataloader = train_dataloader\n",
        "        self.state.trial_name = self.hp_name(trial) if self.hp_name is not None else None\n",
        "        self.state.trial_params = hp_params(trial) if trial is not None else None\n",
        "        # This should be the same if the state has been saved but in case the training arguments changed, it's safer\n",
        "        # to set this after the load.\n",
        "        self.state.max_steps = max_steps\n",
        "        self.state.num_train_epochs = num_train_epochs\n",
        "        self.state.is_local_process_zero = self.is_local_process_zero()\n",
        "        self.state.is_world_process_zero = self.is_world_process_zero()\n",
        "\n",
        "        # tr_loss is a tensor to avoid synchronization of TPUs through .item()\n",
        "        tr_loss = torch.tensor(0.0).to(args.device)\n",
        "        # _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses\n",
        "        self._total_loss_scalar = 0.0\n",
        "        self._globalstep_last_logged = self.state.global_step\n",
        "        model.zero_grad()\n",
        "\n",
        "        self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
        "\n",
        "        # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\n",
        "        if not args.ignore_data_skip:\n",
        "            for epoch in range(epochs_trained):\n",
        "                # We just need to begin an iteration to create the randomization of the sampler.\n",
        "                for _ in train_dataloader:\n",
        "                    break\n",
        "\n",
        "        for epoch in range(epochs_trained, num_train_epochs):\n",
        "            if isinstance(train_dataloader, DataLoader) and isinstance(train_dataloader.sampler, DistributedSampler):\n",
        "                train_dataloader.sampler.set_epoch(epoch)\n",
        "            elif isinstance(train_dataloader.dataset, IterableDatasetShard):\n",
        "                train_dataloader.dataset.set_epoch(epoch)\n",
        "\n",
        "            # if is_torch_tpu_available():\n",
        "            #     parallel_loader = pl.ParallelLoader(train_dataloader, [args.device]).per_device_loader(args.device)\n",
        "            #     epoch_iterator = parallel_loader\n",
        "            # else:\n",
        "            #     epoch_iterator = train_dataloader\n",
        "            epoch_iterator = train_dataloader\n",
        "\n",
        "            train_preds_dict = {list(dataset_dict.keys())[0]: None, list(dataset_dict.keys())[1]: None} #TODO: automatic generation with for ...\n",
        "\n",
        "            # Reset the past mems state at the beginning of each epoch if necessary.\n",
        "            if args.past_index >= 0:\n",
        "                self._past = None\n",
        "\n",
        "            steps_in_epoch = (\n",
        "                len(epoch_iterator) if train_dataset_is_sized else args.max_steps * args.gradient_accumulation_steps\n",
        "            )\n",
        "            self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n",
        "\n",
        "            for step, inputs in enumerate(epoch_iterator):\n",
        "\n",
        "                # Skip past any already trained steps if resuming training\n",
        "                if steps_trained_in_current_epoch > 0:\n",
        "                    steps_trained_in_current_epoch -= 1\n",
        "                    if steps_trained_progress_bar is not None:\n",
        "                        steps_trained_progress_bar.update(1)\n",
        "                    if steps_trained_in_current_epoch == 0:\n",
        "                        self._load_rng_state(resume_from_checkpoint)\n",
        "                    continue\n",
        "                elif steps_trained_progress_bar is not None:\n",
        "                    steps_trained_progress_bar.close()\n",
        "                    steps_trained_progress_bar = None\n",
        "\n",
        "                if step % args.gradient_accumulation_steps == 0:\n",
        "                    self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n",
        "\n",
        "                if (\n",
        "                    ((step + 1) % args.gradient_accumulation_steps != 0)\n",
        "                    and args.local_rank != -1\n",
        "                    and args._no_sync_in_gradient_accumulation\n",
        "                ):\n",
        "                    # Avoid unnecessary DDP synchronization since there will be no backward pass on this example.\n",
        "                    with model.no_sync():\n",
        "                        (temp_loss, label_logits) = self.training_step(model, inputs)\n",
        "                        tr_loss += temp_loss\n",
        "                        # tr_loss += self.training_step(model, inputs)\n",
        "                else:\n",
        "                    (temp_loss, label_logits) = self.training_step(model, inputs)\n",
        "                    tr_loss += temp_loss\n",
        "                    # tr_loss += self.training_step(model, inputs)\n",
        "\n",
        "                ################################## Extracting samples'probability ###############################################\n",
        "\n",
        "                preds = nn.Softmax(dim=1)(label_logits) # convert to probability\n",
        "\n",
        "                # # Move preds to the CPU\n",
        "                train_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "                if train_preds_dict[inputs[\"task_name\"]] is None:  # first batch\n",
        "                     train_preds_dict[inputs[\"task_name\"]] = train_preds\n",
        "                else:\n",
        "                   train_preds_dict[inputs[\"task_name\"]] = np.vstack((train_preds_dict[inputs[\"task_name\"]], train_preds))\n",
        "\n",
        "                ######################################################## END ##################################################\n",
        "\n",
        "                self.current_flos += float(self.floating_point_ops(inputs))\n",
        "\n",
        "                # Optimizer step for deepspeed must be called on every step regardless of the value of gradient_accumulation_steps\n",
        "                if self.deepspeed:\n",
        "                    self.deepspeed.step()\n",
        "\n",
        "                if (step + 1) % args.gradient_accumulation_steps == 0 or (\n",
        "                    # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
        "                    steps_in_epoch <= args.gradient_accumulation_steps\n",
        "                    and (step + 1) == steps_in_epoch\n",
        "                ):\n",
        "                    # Gradient clipping\n",
        "                    if args.max_grad_norm is not None and args.max_grad_norm > 0 and not self.deepspeed:\n",
        "                        # deepspeed does its own clipping\n",
        "\n",
        "                        if self.use_amp:\n",
        "                            # AMP: gradients need unscaling\n",
        "                            self.scaler.unscale_(self.optimizer)\n",
        "\n",
        "                        if hasattr(self.optimizer, \"clip_grad_norm\"):\n",
        "                            # Some optimizers (like the sharded optimizer) have a specific way to do gradient clipping\n",
        "                            self.optimizer.clip_grad_norm(args.max_grad_norm)\n",
        "                        elif hasattr(model, \"clip_grad_norm_\"):\n",
        "                            # Some models (like FullyShardedDDP) have a specific way to do gradient clipping\n",
        "                            model.clip_grad_norm_(args.max_grad_norm)\n",
        "                        else:\n",
        "                            # Revert to normal clipping otherwise, handling Apex or full precision\n",
        "                            nn.utils.clip_grad_norm_(\n",
        "                                # amp.master_params(self.optimizer) if self.use_apex else model.parameters(),\n",
        "                                model.parameters(),\n",
        "                                args.max_grad_norm,\n",
        "                            )\n",
        "\n",
        "                    # Optimizer step\n",
        "                    optimizer_was_run = True\n",
        "                    if self.deepspeed:\n",
        "                        pass  # called outside the loop\n",
        "                    # elif is_torch_tpu_available():\n",
        "                    #     xm.optimizer_step(self.optimizer)\n",
        "                    elif self.use_amp:\n",
        "                        scale_before = self.scaler.get_scale()\n",
        "                        self.scaler.step(self.optimizer)\n",
        "                        self.scaler.update()\n",
        "                        scale_after = self.scaler.get_scale()\n",
        "                        optimizer_was_run = scale_before <= scale_after\n",
        "                    else:\n",
        "                        self.optimizer.step()\n",
        "\n",
        "                    if optimizer_was_run and not self.deepspeed:\n",
        "                        self.lr_scheduler.step()\n",
        "\n",
        "                    model.zero_grad()\n",
        "                    self.state.global_step += 1\n",
        "                    self.state.epoch = epoch + (step + 1) / steps_in_epoch\n",
        "                    self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n",
        "\n",
        "                    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "                else:\n",
        "                    self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n",
        "\n",
        "                if self.control.should_epoch_stop or self.control.should_training_stop:\n",
        "                    break\n",
        "\n",
        "\n",
        "            #################################################### Saving tensors of probabilities per epoch and evaluating #####################################################\n",
        "\n",
        "            Prob_per_epoch_first_task[epoch][:,:] = train_preds_dict[list(dataset_dict.keys())[0]]\n",
        "            Prob_per_epoch_second_task[epoch][:,:] = train_preds_dict[list(dataset_dict.keys())[1]]\n",
        "\n",
        "            Fetching_required_status_multilingual.check_directory_status(dataset_dict, resume_from_checkpoint, path_to_checkpoint, Combination, dataset_code, num_epochs, Prob_per_epoch_first_task, Prob_per_epoch_second_task, Mode = 0)\n",
        "\n",
        "            # savetxt(os.path.join(path_to_checkpoint, 'Prob_per_epoch_Sentiment.csv'), Prob_per_epoch_Sentiment.reshape(Prob_per_epoch_Sentiment.shape[0], -1), delimiter=',')\n",
        "            # savetxt(os.path.join(path_to_checkpoint, 'Prob_per_epoch_Paraphrase.csv'), Prob_per_epoch_Paraphrase.reshape(Prob_per_epoch_Paraphrase.shape[0],-1), delimiter=',')\n",
        "\n",
        "            if (evaluate_during_training):\n",
        "                print(\"\\nEvaluating on test dataset: (epoch %d)\" %(epoch + 1))\n",
        "                Fetching_required_status_multilingual.multitask_eval_fn(model, features_dict, model_name, dataset_dict, self, tokenizer, max_length, batch_size = B_size)\n",
        "\n",
        "\n",
        "            ######################################################################### END ########################################################################\n",
        "\n",
        "            self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n",
        "            self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "\n",
        "            if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
        "                # if is_torch_tpu_available():\n",
        "                #     # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
        "                #     xm.master_print(met.metrics_report())\n",
        "                # else:\n",
        "                logger.warning(\n",
        "                        \"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"\n",
        "                        \"configured. Check your training configuration if this is unexpected.\"\n",
        "                    )\n",
        "            if self.control.should_training_stop:\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "        if args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of training\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        logger.info(\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\")\n",
        "        if args.load_best_model_at_end and self.state.best_model_checkpoint is not None:\n",
        "            # Wait for everyone to get here so we are sur the model has been saved by process 0.\n",
        "            # if is_torch_tpu_available():\n",
        "            #     xm.rendezvous(\"load_best_model_at_end\")\n",
        "            # elif args.local_rank != -1:\n",
        "            if args.local_rank != -1:\n",
        "                dist.barrier()\n",
        "\n",
        "            logger.info(\n",
        "                f\"Loading best model from {self.state.best_model_checkpoint} (score: {self.state.best_metric}).\"\n",
        "            )\n",
        "\n",
        "            best_model_path = os.path.join(self.state.best_model_checkpoint, WEIGHTS_NAME)\n",
        "            if os.path.exists(best_model_path):\n",
        "                # We load the model state dict on the CPU to avoid an OOM error.\n",
        "                state_dict = torch.load(best_model_path, map_location=\"cpu\")\n",
        "                # If the model is on the GPU, it still works!\n",
        "                # self._load_state_dict_in_model(state_dict) ##?????\n",
        "                load_result = self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            else:\n",
        "                logger.warn(\n",
        "                    f\"Could not locate the best model at {best_model_path}, if you are running a distributed training \"\n",
        "                    \"on multiple nodes, you should activate `--save_on_each_node`.\"\n",
        "                )\n",
        "\n",
        "            if self.deepspeed:\n",
        "                self.deepspeed.load_checkpoint(\n",
        "                    self.state.best_model_checkpoint, load_optimizer_states=False, load_lr_scheduler_states=False\n",
        "                )\n",
        "\n",
        "        # add remaining tr_loss\n",
        "        self._total_loss_scalar += tr_loss.item()\n",
        "        train_loss = self._total_loss_scalar / self.state.global_step\n",
        "\n",
        "        metrics = speed_metrics(\"train\", start_time, num_samples=num_train_samples, num_steps=self.state.max_steps)\n",
        "        self.store_flos()\n",
        "        metrics[\"total_flos\"] = self.state.total_flos\n",
        "        metrics[\"train_loss\"] = train_loss\n",
        "\n",
        "        self.is_in_train = False\n",
        "\n",
        "        self._memory_tracker.stop_and_update_metrics(metrics)\n",
        "\n",
        "        self.log(metrics)\n",
        "\n",
        "        self.control = self.callback_handler.on_train_end(args, self.state, self.control)\n",
        "\n",
        "        # return TrainOutput(self.state.global_step, train_loss, metrics)\n",
        "        return TrainOutput(self.state.global_step, train_loss, metrics), Prob_per_epoch_first_task, Prob_per_epoch_second_task ### / self.global_step?? seems ok!!!\n",
        "\n",
        "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
        "        \"\"\"\n",
        "        Create a single-task data loader that also yields task names\n",
        "        \"\"\"\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "\n",
        "        ### change\n",
        "        # train_sampler = (\n",
        "        #     RandomSampler(train_dataset)\n",
        "        #     if self.args.local_rank == -1\n",
        "        #     else DistributedSampler(train_dataset)\n",
        "        # )\n",
        "        train_sampler = SequentialSampler(train_dataset)\n",
        "\n",
        "\n",
        "        data_loader = DataLoaderWithTaskname(\n",
        "            task_name=task_name,\n",
        "            data_loader=DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=self.args.train_batch_size,\n",
        "                sampler=train_sampler,\n",
        "                collate_fn=self.data_collator,\n",
        "            ),\n",
        "        )\n",
        "        return data_loader\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
        "        but an iterable that returns a generator that samples from each\n",
        "        task Dataloader\n",
        "        \"\"\"\n",
        "        return MultitaskDataloader(\n",
        "            {\n",
        "                task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
        "                for task_name, task_dataset in self.train_dataset.items()\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AtQfkWxVUSJ"
      },
      "source": [
        "## Time to train!\n",
        "\n",
        "Okay, we have done all the hard work, now it is time for it to pay off. We can now simply create our `MultitaskTrainer`, and start training!\n",
        "\n",
        "(This takes about ~45 minutes for me on Colab, but it will depend on the GPU you are allocated.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVwsaHyXY5Ft"
      },
      "outputs": [],
      "source": [
        "# !pip install -q wandb\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCJLhmJATUtO"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "  with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzMIxSGnTW-r"
      },
      "outputs": [],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LEQoSCAj99y"
      },
      "outputs": [],
      "source": [
        "train_dataset = {\n",
        "    task_name: dataset[\"train\"]\n",
        "    for task_name, dataset in features_dict.items()\n",
        "}\n",
        "\n",
        "eval_dataset = features_dict\n",
        "\n",
        "\n",
        "trainer = MultitaskTrainer(\n",
        "    model=multitask_model,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir = path_to_checkpoint,\n",
        "        overwrite_output_dir = True,\n",
        "        learning_rate = lr,\n",
        "        do_train = True,\n",
        "        num_train_epochs = num_epochs,\n",
        "        per_device_train_batch_size = B_size,\n",
        "        save_steps = lg_step * EP_saved,\n",
        "        logging_steps = lg_step\n",
        "    ),\n",
        "    data_collator = NLPDataCollator(),\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset\n",
        ")\n",
        "an = trainer.train(resume_from_checkpoint = (None if Last_Actual_checkpoint == None else os.path.join(path_to_checkpoint,Last_Actual_checkpoint)),\n",
        "                   resume_from_pretrained = (None if Last_PreTrained_checkpoint == None else os.path.join(path_to_pretrained_weight, Last_PreTrained_checkpoint)),\n",
        "                   evaluate_during_training = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM7QQ36jfMpJ"
      },
      "source": [
        "# Saving the probabilies extracted during the model's training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtiMZkdr61Kq"
      },
      "outputs": [],
      "source": [
        "[Prob_per_epoch_first_task, Prob_per_epoch_second_task] = an[1:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVyZgrOl_VoD"
      },
      "outputs": [],
      "source": [
        "print(Prob_per_epoch_first_task.shape)\n",
        "print(Prob_per_epoch_second_task.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMlP3IHyeB6T"
      },
      "outputs": [],
      "source": [
        "Fetching_required_status_multilingual.save_final_prop(dataset_code, Fine_tune, Combination, Prob_per_epoch_first_task, Prob_per_epoch_second_task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQQVj67j7kn"
      },
      "source": [
        "All done! Now, we can evaluate our multi-task model on all three tasks. In this case, we can simply use single-task data loaders, since we are evaluating each task individually.\n",
        "\n",
        "We will use the (private) `_prediction_loop` method from the Trainer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1isCBpsX-Ky"
      },
      "source": [
        "# **Evaluation** on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBzCV6VNYI76"
      },
      "outputs": [],
      "source": [
        "Fetching_required_status_multilingual.multitask_eval_fn(multitask_model, features_dict, model_name, dataset_dict, trainer, tokenizer, max_length, batch_size = B_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-RSc6zEookQ"
      },
      "source": [
        "### Copying from unlimited drive to limited drive as a backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUXBNwGFn4Wn"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/drive/Shareddrives/Gdrive/NLP Bachelors' Project/checkpoint/MLL(French,Farsi)/checkpoint-14400\"  \"/content/drive/MyDrive/NLP Bachelors' Project/checkpoint/MLL(French,Farsi)/\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}