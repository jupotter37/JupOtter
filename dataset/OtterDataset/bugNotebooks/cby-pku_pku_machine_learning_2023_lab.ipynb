{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "### 环境准备\n",
    "请确保完成以下依赖包的安装，并且通过下面代码来导入与验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备\n",
    "我们将使用以下数据集进行决策树的构建。该数据集包括7个特征，以及一个标签“是否适合读博”，这些特征描述了适合读博的各种条件，如love doing research,I absolutely want to be a college professor等。\n",
    "\n",
    "请运行下面的代码来加载数据集。\n",
    "\n",
    "（防侵权说明）参考https://zhuanlan.zhihu.com/p/372884253，数据集来源GPT4，但构造的决策树不一定与参考内容完全一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read decision_tree_datasets.csv\n",
    "train_data = pd.read_csv('train_phd_data.csv')\n",
    "test_data = pd.read_csv('test_phd_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树构建 (10 分)\n",
    "在这个部分，你将学习并完成决策树的构建。注意：不考虑剪枝，决策树构建停止条件是数据所有实例属于同一类或者特征不可再分（即每个特征值都一样）。\n",
    "\n",
    "我们采用信息增益率作为分类标准，同时也允许使用其他指标，如基尼系数。\n",
    "\n",
    "请完成以下函数：\n",
    "\n",
    "1. **计算数据的信息熵** `getInfoEntropy()`\n",
    "2. **根据选取的特征进行数据分割** `split_data()`\n",
    "3. **根据分类标准找到最优特征** `find_best_feature()`\n",
    "\n",
    "你可能会用到`pandas`库函数，请参考 [pandas官方文档](https://pandas.pydata.org/docs/reference/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfoEntropy(data):\n",
    "    ''' \n",
    "        calculate the information entropy of the data\n",
    "\n",
    "    Args:\n",
    "        data: the data set, the last column is the label, the other columns are the features\n",
    "\n",
    "    Returns:\n",
    "        Entropy: float, the information entropy of the data\n",
    "    '''\n",
    "    \n",
    "    Entropy = 0.0\n",
    "    \n",
    "    # TODO: 1. count the number of different labels samples (each class has how many samples) -- count_class\n",
    "    ## hint: use pd.value_counts() to count the number of different labels samples\n",
    "    ## hint: use data.iloc[:,-1] to get the last column of the data\n",
    "    count_class = data.iloc[:, -1].value_counts()\n",
    "    #print(count_class)\n",
    "    # 0 : 20 || 1: 7\n",
    "    \n",
    "    # TODO: 2. calculate the number of data\n",
    "    data_count = len(data)\n",
    "\n",
    "    \n",
    "    # NOTE use count_class.index here to iteration to avoid iterator i causing more troubles (of course in guarantee of right code and no cheating )\n",
    "    for class_label in count_class.index:\n",
    "        # TODO: 3. calculate the probability of each class\n",
    "        #print(f\"count_class[i]: {count_class[i]}\")\n",
    "        #print(f\"data_count:{data_count}\")\n",
    "        # print(f\"debug for count_class: {count_class}\")\n",
    "        #print(f\"debug for i:{i}\")\n",
    "        # print(\"*\"*30)\n",
    "        #print(f\"debug for count_class[i]:{count_class[i]}\")\n",
    "        # print(f\"debug for data_count:{data_count}\")\n",
    "        #if isinstance(count_class[i],pd.Series):\n",
    "        #    label_count = count_class[i].value_counts()\n",
    "        #    p = label_count.idxmax() / data_count\n",
    "        #else:\n",
    "        p = count_class[class_label] / data_count\n",
    "        # TODO: 4. calculate the entropy of each class\n",
    "        #print(f\"p : {p}\")\n",
    "        Entropy += -p * np.log2( p + 1e-5 )\n",
    "    #print('当前数据集的信息熵为：',Entropy)\n",
    "    return Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8255976726326857\n"
     ]
    }
   ],
   "source": [
    "## test getInfoEntropy\n",
    "print(getInfoEntropy(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, column):\n",
    "    ''' \n",
    "        split the data set according to the feature column\n",
    "\n",
    "        Args:\n",
    "            data: the data set, the last column is the label, the other columns are the features\n",
    "            column: the feature column\n",
    "        Returns:\n",
    "            splt_datas: Series, the data set after splitting\n",
    "    '''\n",
    "    # 1. construct a Series to save the data set after splitting\n",
    "    splt_datas = pd.Series()  \n",
    "    # 2. get the unique values of the feature column\n",
    "    str_values = data.iloc[:,column].unique()  \n",
    "    # 3. find the data set corresponding to each unique value\n",
    "    for i in range(len(str_values)):   \n",
    "        df = data.loc[data.iloc[:,column] == str_values[i]]\n",
    "\n",
    "        splt_datas[str(i)] = df\n",
    "    return splt_datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(data):\n",
    "\n",
    "    '''  \n",
    "        find the best feature to split the data set\n",
    "\n",
    "        Args:\n",
    "            data: the data set, the last column is the label, the other columns are the features\n",
    "        Returns:\n",
    "            best_feature: the best feature\n",
    "            best_Series: Series, the data set after splitting\n",
    "    '''\n",
    "    best_feature_index = 0    \n",
    "    baseEnt = getInfoEntropy(data)  \n",
    "    bestInfoGain_ratio = 0.0\n",
    "    numFeatures = data.shape[1] - 1   \n",
    "    InfoGain = 0.0 \n",
    "\n",
    "    best_Series = pd.Series(dtype=\"object\") # FIXME it cannot use dataframe format\n",
    "    #print(f\"numFeatures:{numFeatures}\")\n",
    "    # Loop through each feature to calculate information gain ratio.\n",
    "    for i in range(numFeatures):\n",
    "        newEnt = 0.0\n",
    "        # avoid div 0 error\n",
    "        IV = 1e-5\n",
    "        # TODO: 1. split the data set according to the feature column\n",
    "        series = split_data(data, i)\n",
    "        #print(f\"series:{series}\")\n",
    "        # 2. calculate the information entropy of each data set, and calculate the weighted average information entropy\n",
    "        for j in range(len(series)):\n",
    "            df = series[j]\n",
    "            # TODO: 3. calculate the probability of each data set\n",
    "            prob = len(df) / len(data)\n",
    "            # TODO: 4. calculate the weighted average information entropy\n",
    "            newEnt += prob * getInfoEntropy(df)\n",
    "            # print(f\"debug for newEnt:{newEnt}\")\n",
    "            # TODO: 5. calculate the entropy of class labels IV\n",
    "            # FIXME\n",
    "            IV += -prob * np.log2(prob + 1e-10)\n",
    "        \n",
    "        # TODO: 6. calculate the information gain \n",
    "        InfoGain = baseEnt - newEnt\n",
    "        \n",
    "        # TODO: 7. calculate the information gain ratio\n",
    "        \n",
    "        InfoGain_ratio = InfoGain / (IV + 1e-5) \n",
    "        #print(u\"第%d个特征的信息增益率为：%.3f\" % (i, InfoGain_ratio))\n",
    "\n",
    "        # \n",
    "        if InfoGain_ratio > bestInfoGain_ratio:\n",
    "            bestInfoGain_ratio = InfoGain_ratio\n",
    "            best_feature_index = i\n",
    "            best_Series = series\n",
    "        \n",
    "    return data.columns[best_feature_index], best_Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create decision tree\n",
    "def creat_Tree(data):\n",
    "\n",
    "    '''\n",
    "        create decision tree\n",
    "\n",
    "        Args:\n",
    "            data: the data set, the last column is the label, the other columns are the features\n",
    "        Returns:\n",
    "            Tree: dict, the decision tree\n",
    "    '''\n",
    "    # get the class labels of the data set\n",
    "    y_values = data.iloc[:,-1].unique()   \n",
    "\n",
    "    # TODO: 1. If there is only one class label, stop splitting and return the class label.\n",
    "    #print(f\"y_values:{len(y_values)}\")\n",
    "    if len(y_values)==1:\n",
    "        return y_values[0]\n",
    "    \n",
    "    # 2. Check if the value of each feature is the same. If so, return the class label with the most samples.\n",
    "    flag = 0\n",
    "    for i in range(data.shape[1] - 1):   \n",
    "        #print(f\"data_iloc{data.iloc[:,i]}\")\n",
    "        if(len(data.iloc[:,i].unique()) != 1):\n",
    "            flag = 1\n",
    "            break\n",
    "    \n",
    "    # TODO: 3. If all features are identical, return the class label with the most samples.If the samples number are same return the first one\n",
    "    \n",
    "    if(flag == 0):\n",
    "        value_count = data.iloc[:,-1].value_counts()\n",
    "        # print(f\"value_count:{value_count}\")\n",
    "        # print(f\"value_count.idxmax: {value_count.idxmax()}\")\n",
    "        return value_count.idxmax()\n",
    "\n",
    "    # 4. TODO: Find the best feature to split the data set.\n",
    "    best_feature, best_Series = find_best_feature(data) \n",
    "    best_feature=str(best_feature)\n",
    "    #print(f\"best_features:{best_feature}; best_Series:{best_Series}\")\n",
    "    Tree = {best_feature:{}}\n",
    "    #print(f\"Tempoarl Tree:{Tree}\")\n",
    "    # 5. Build the tree recursively. \n",
    "    for j in range(len(best_Series)):  \n",
    "        #print(\"1111\")\n",
    "        #print(f\"current value: {value} for best Series\")  \n",
    "        #print(f\"current split_data: {split_data} for best Series\")\n",
    "        split_data = best_Series.iloc[j]\n",
    "        \n",
    "        # NOTE there is seemingly some bugs so I refined the code here\n",
    "\n",
    "        value = split_data.loc[:,best_feature].unique()[0]\n",
    "        # delete the best feature \n",
    "        split_data = split_data.drop(best_feature, axis = 1) \n",
    "        #print(f\"current value: {value} for best_seri {j}\")\n",
    "        #print(f\"split_data: {split_data}\")\n",
    "\n",
    "        # TODO: 6. recursively call the function to build the tree\n",
    "        #print(f\"value:{value}\")\n",
    "        \n",
    "        Tree[best_feature][value] = creat_Tree(split_data)\n",
    "    return Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree:{'I absolutely want to be a college professor': {0: {'I work 9-5 Mon-Fri': {0: {'I am OK being with judged all the time': {0: 0, 1: {'I need a clear target and immediate feedback': {0: 1, 1: 0}}}}, 1: 0}}, 1: {'I love doing research': {1: {'I am OK being with judged all the time': {1: 1, 0: {'I can deal with extreme stress and competition': {1: 0, 0: 1}}}}, 0: 0}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n",
      "/tmp/ipykernel_1145458/2186281649.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  splt_datas = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "Tree = creat_Tree(train_data)\n",
    "print(f\"Tree:{Tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.svg'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize decision tree\n",
    "from graphviz import Digraph\n",
    "\n",
    "# NOTE : Since I run the code on server which don't have SUDO ROOT right, so I have made offline installation of graphviz according to https://blog.csdn.net/a19990412/article/details/115674086\n",
    "# NOTE : also can use brew install graphviz, but unfortunately on my server it failed ! https://docs.brew.sh/Homebrew-on-Linux#requirements\n",
    "\n",
    "\n",
    "def plot_tree(tree, parent_name, node_id=0, graph=None, edge_label=''):\n",
    "    \n",
    "    \n",
    "    if graph is None:\n",
    "        graph = Digraph(comment='Decision Tree')\n",
    "\n",
    "    \n",
    "    if not isinstance(tree, dict):\n",
    "        current_node_name = f'node{node_id}' \n",
    "        graph.node(current_node_name, label=str(tree))\n",
    "        graph.edge(parent_name, current_node_name, label=edge_label)\n",
    "        node_id += 1\n",
    "        return node_id\n",
    "    \n",
    "    for k, v in tree.items():\n",
    "        current_node_name = f'node{node_id}' \n",
    "        node_label = f'{k}' if isinstance(v, (str, int)) else k\n",
    "        graph.node(current_node_name, label=node_label)\n",
    "        graph.edge(parent_name, current_node_name, label=str(edge_label))\n",
    "\n",
    "        if isinstance(v, dict):\n",
    "            for key in v:\n",
    "                # 假设分支可以用 '0' 和 '1' 来区分\n",
    "                node_id += 1\n",
    "                node_id = plot_tree(v[key], current_node_name, node_id, graph, edge_label=str(key))\n",
    "                \n",
    "    return node_id\n",
    "\n",
    "# plot decision tree\n",
    "tree_graph = Digraph(comment='Decision Tree')\n",
    "plot_tree(Tree, 'Root', 0, tree_graph)\n",
    "\n",
    "\n",
    "# NOTE I have changed the format into SVG, because my version of graphviz doesn't support PNG format\n",
    "# NOTE please see [decision_tree.svg] in this work folder\n",
    "tree_graph.render('decision_tree', format='svg', cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I have changed the format into SVG, because my version of graphviz doesn't support PNG format \\\n",
    " please see [decision_tree.svg] in this work folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classfiy test data\n",
    "def classify(tree, test_data):\n",
    "    ''' \n",
    "        classify test data\n",
    "\n",
    "        Args:\n",
    "            tree: dict, the decision tree\n",
    "            test_data: the test data set, the last column is the label, the other columns are the features\n",
    "        Returns:\n",
    "            class_label: the predicted class label\n",
    "    '''\n",
    "    ## get the checked feature of the decision tree\n",
    "    first_str = list(tree.keys())[0]\n",
    "\n",
    "\n",
    "    key = test_data[first_str]\n",
    "    #print(f\"key:{key}\")\n",
    "    # TODO: get the subtree corresponding to the value of the feature\n",
    "    #print(f\"tree[first_str]:{tree[str(first_str)]}\")\n",
    "    sub_tree = tree[first_str]\n",
    "    #print(f\"sub_tree:{sub_tree}\")\n",
    "    # TODO: recursively call the function to classify the test data\n",
    "    # hint: if the value of the feature is not a dict, it means that the decision tree has reached the leaf node, and the value of the feature is the predicted class label\n",
    "    if isinstance(sub_tree[key],dict):\n",
    "        return classify(sub_tree[key],test_data)\n",
    "    else:\n",
    "        return sub_tree[key]\n",
    "\n",
    "    \n",
    "\n",
    "def test(test_data, tree):\n",
    "    # NOTE I have rewritten the code here to enhance efficiency\n",
    "    correct_predictions = sum(classify(tree, sample) == sample[-1] for _, sample in test_data.iterrows())\n",
    "    accuracy = correct_predictions / len(test_data)\n",
    "    print('accuracy: ', accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8571428571428571\n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test(test_data, Tree)\n",
    "test(train_data, Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们将进行一项小测试，目的在于评估您是否适合攻读博士学位。\n",
    "\n",
    "请注意！这仅仅是基于假设的模型，无法准确预测实际情况。请将其视为一次轻松的尝试，仅供娱乐之用，不要用其来替代对自身状况的思考与决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! According to the model, you are likely to gain admission for Ph.D.\n"
     ]
    }
   ],
   "source": [
    "# You can input your profile to predict your phd admission result\n",
    "# input your profile about \"I love doing research,I absolutely want to be a college professor,Money is important to me,I can deal with extreme stress and competition,I am OK being with judged all the time,I need a clear target and immediate feedback,I work 9-5 Mon-Fri\"\n",
    "loving = input('Do you love research? (1/0)')\n",
    "professor = input('Do you want to be a professor? (1/0)')\n",
    "money = input('Is money important to you? (1/0)')\n",
    "stress = input('Can you deal with stress? (1/0)')\n",
    "judge = input('Can you deal with being judged all the time? (1/0)')\n",
    "feedback = input('Do you need a clear target and immediate feedback? (1/0)')\n",
    "work = input('Do you work 9-5 Mon-Fri? (1/0)')\n",
    "\n",
    "# Combine the user's responses into a single data frame\n",
    "test_data = pd.Series({\n",
    "    'I love doing research': int(loving),\n",
    "    'I absolutely want to be a college professor': int(professor),\n",
    "    'Money is important to me': int(money),\n",
    "    'I can deal with extreme stress and competition': int(stress),\n",
    "    'I am OK being with judged all the time': int(judge),\n",
    "    'I need a clear target and immediate feedback': int(feedback),\n",
    "    'I work 9-5 Mon-Fri': int(work)\n",
    "})\n",
    "# Use the decision tree to predict the result \n",
    "result = classify(Tree, test_data)\n",
    "# Print the result to the user\n",
    "if result == 1:\n",
    "    print(\"Congratulations! According to the model, you are likely to gain admission for Ph.D.\")\n",
    "elif result == 0: \n",
    "    print(\"Unfortunately, according to the model, you are unlikely to gain admission for Ph.D.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished at 12-21 @Boyuan  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
