{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoJanini/seq2seq/blob/feature%2Fuse_beam_search/notebooks/seq2seq_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heOekHXdFLvS"
      },
      "source": [
        "## Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNPKl6i8FJes",
        "outputId": "f68df76e-2725-4896-bb5e-0b8cf1eb66fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ai0mx9U9Zc"
      },
      "source": [
        "## Install Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIAA6KzFWMpq",
        "outputId": "dd3720ba-2799-4ed3-aad2-db3c7fdaaba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `pip install tensorboard>'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchtext) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=6698afaa80f2a5f7f63f61f08516fb1f2668ed62da5899de78209e1f7f56ec88\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 46.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install tqdm\n",
        "!pip install tensorboard>\n",
        "!pip install torchtext\n",
        "!pip install pandas\n",
        "!pip install requests\n",
        "!pip install sklearn\n",
        "!pip install torchmetrics\n",
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGHFjYn7W-Sp"
      },
      "source": [
        "# Sequence to Sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhJKl4xsPOqj"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PpHKuKLbPMs9"
      },
      "outputs": [],
      "source": [
        "from re import I\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "\n",
        "WIRELINE_LOGS = [\n",
        "    \"WELL\",\n",
        "    \"DEPTH_MD\",\n",
        "    \"X_LOC\",\n",
        "    \"Y_LOC\",\n",
        "    \"Z_LOC\",\n",
        "    \"GROUP\",\n",
        "    \"FORMATION\",\n",
        "    \"CALI\",\n",
        "    \"RSHA\",\n",
        "    \"RMED\",\n",
        "    \"RDEP\",\n",
        "    \"RHOB\",\n",
        "    \"GR\",\n",
        "    \"SGR\",\n",
        "    \"NPHI\",\n",
        "    \"PEF\",\n",
        "    \"DTC\",\n",
        "    \"SP\",\n",
        "    \"BS\",\n",
        "    \"ROP\",\n",
        "    \"DTS\",\n",
        "    \"DCAL\",\n",
        "    \"DRHO\",\n",
        "    \"MUDWEIGHT\",\n",
        "    \"RMIC\",\n",
        "    \"ROPA\",\n",
        "    \"RXO\",\n",
        "]\n",
        "\n",
        "original_lithology_numbers = {\n",
        "    30000: 0,\n",
        "    65030: 1,\n",
        "    65000: 2,\n",
        "    80000: 3,\n",
        "    74000: 4,\n",
        "    70000: 5,\n",
        "    70032: 6,\n",
        "    88000: 7,\n",
        "    86000: 8,\n",
        "    99000: 9,\n",
        "    90000: 10,\n",
        "    93000: 11,\n",
        "}\n",
        "\n",
        "\n",
        "class WellsDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        sequence_len=5,\n",
        "        model_type=\"seq2seq\",\n",
        "        dataset_type=\"train\",\n",
        "        download_data_locally=True,\n",
        "        path=\"data\",\n",
        "        label_columns=[\"FORCE_2020_LITHOFACIES_LITHOLOGY\"],\n",
        "        feature_columns=WIRELINE_LOGS,\n",
        "        scaler=None,\n",
        "        output_len=None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Dataset objects for training datasets and test datasets\n",
        "        :param path: dataset path\n",
        "        :param dataset_type: distinguish whether to get the training set or the test set\n",
        "        :param download_data_locally: whether to download the data locally or to just get it from the url everytime\n",
        "        :param label_columns: the header of the target column\n",
        "\n",
        "        \"\"\"\n",
        "        urls = {\n",
        "            \"train\": \"https://github.com/bolgebrygg/Force-2020-Machine-Learning-competition/raw/master/lithology_competition/data/train.zip\",\n",
        "            \"test\": \"https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/master/lithology_competition/data/hidden_test.csv\",\n",
        "        }\n",
        "\n",
        "        super(WellsDataset, self).__init__()\n",
        "        self.dataset_type = dataset_type\n",
        "        self.download_data_locally = download_data_locally\n",
        "        self.path = f\"{path}/{dataset_type}.csv\"\n",
        "        self.url = urls[self.dataset_type]\n",
        "        self.data_df = self.download_data()\n",
        "        self.feature_columns = feature_columns\n",
        "        self.target = label_columns\n",
        "        self.model_type = model_type\n",
        "        self.sequence_len = sequence_len\n",
        "        self.scaler = scaler\n",
        "        self.output_len = output_len\n",
        "        # Define special symbols and indices\n",
        "        self.UNK_IDX, self.PAD_IDX, self.BOS_IDX, self.EOS_IDX = 0, 1, 2, 3\n",
        "        # Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "        self.special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "        if self.output_len == None:\n",
        "            self.output_len = len(tuple(set(self.data_df[self.target[0]].to_numpy())))\n",
        "\n",
        "        self.wells = list(self.data_df[\"WELL\"].unique())\n",
        "        self.data = self.data_df[[\"WELL\"] + label_columns + feature_columns].dropna()\n",
        "        self.well_indexes = pd.DataFrame(\n",
        "            self.data[\"WELL\"].apply(lambda x: self.wells.index(x)), columns=[\"WELL\"]\n",
        "        )\n",
        "        self.X = self.prepare_X()\n",
        "        self.y = self.prepare_y()\n",
        "\n",
        "        if self.model_type == \"seq2seq\":\n",
        "            self.X, self.y = self.separate_by_well()\n",
        "            (\n",
        "                self.train_len,\n",
        "                self.input_len,\n",
        "                self.channel_len,\n",
        "                self.train_dataset,\n",
        "                self.train_label,\n",
        "            ) = self.prepare_sequences_to_sequences()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.train_dataset[index], self.train_label[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_len\n",
        "\n",
        "    def download_data(self):\n",
        "        if self.download_data_locally:\n",
        "            try:\n",
        "                data = self.load_data(self.path)\n",
        "            except:\n",
        "                data = self.load_data(self.url)\n",
        "                data.to_csv(self.path, sep=\";\")\n",
        "        else:\n",
        "            data = self.load_data(self.url)\n",
        "        return data\n",
        "\n",
        "    def load_data(self, path):\n",
        "        data = pd.read_csv(path, sep=\";\")\n",
        "        return data\n",
        "\n",
        "    def prepare_X(self):\n",
        "        X = self.data[self.feature_columns]\n",
        "        if self.scaler == None:\n",
        "            self.scaler = preprocessing.StandardScaler().fit(X)\n",
        "        scaled_X = self.scaler.transform(X)\n",
        "        X_df = pd.DataFrame(scaled_X, columns=X.columns, index=X.index)\n",
        "        return X_df\n",
        "\n",
        "    def prepare_y(self):\n",
        "        y = self.data[self.target]\n",
        "        y_tmp = (\n",
        "            y[self.target[0]]\n",
        "            .apply(lambda x: self.get_lithology_numbers()[x])\n",
        "            .to_numpy()\n",
        "        )\n",
        "        # encoded_yi = np.array(torch.nn.functional.one_hot(torch.Tensor(y_tmp).reshape(-1, 1).long(), self.output_len)).squeeze()\n",
        "        encoded_yi = np.array(torch.Tensor(y_tmp).reshape(-1, 1).long()).squeeze()\n",
        "\n",
        "        y_df = pd.DataFrame(encoded_yi, index=y.index)\n",
        "        return y_df\n",
        "\n",
        "    def separate_by_well(self):\n",
        "        training_data = []\n",
        "        training_labels = []\n",
        "        wells = list(self.well_indexes[\"WELL\"].unique())\n",
        "        for well_index, _ in enumerate(wells):\n",
        "            well_rows_index = self.well_indexes[\n",
        "                self.well_indexes[\"WELL\"] == well_index\n",
        "            ].index\n",
        "            xi = self.X.loc[well_rows_index].to_numpy()\n",
        "            yi = self.y.loc[well_rows_index].to_numpy()\n",
        "            training_data.append(xi)\n",
        "            training_labels.append(yi)\n",
        "        return training_data, training_labels\n",
        "\n",
        "    def prepare_sequences_to_sequences(self):\n",
        "        train_dataset = []\n",
        "        train_label = []\n",
        "        for x1, y1 in zip(self.X, self.y):\n",
        "            train_dataset = (\n",
        "                train_dataset\n",
        "                + list(torch.split(torch.as_tensor(x1).float(), self.sequence_len))[:-1]\n",
        "            )\n",
        "            train_label = (\n",
        "                train_label\n",
        "                + list(torch.split(torch.as_tensor(y1).float(), self.sequence_len))[:-1]\n",
        "            )\n",
        "        train_dataset = torch.stack(train_dataset, dim=0).permute(0, 1, 2)\n",
        "        train_label = torch.stack(train_label, dim=0).permute(0, 1, 2).long().squeeze()\n",
        "        train_len = train_dataset.shape[0]\n",
        "        channel_len = train_dataset[0].shape[-1]\n",
        "        input_len = train_dataset[0].shape[-2]\n",
        "        return train_len, input_len, channel_len, train_dataset, train_label\n",
        "\n",
        "    def get_lithology_numbers(self):\n",
        "        lithology_numbers = {\n",
        "            self.UNK_IDX: self.UNK_IDX,\n",
        "            self.PAD_IDX: self.PAD_IDX,\n",
        "            self.BOS_IDX: self.BOS_IDX,\n",
        "            self.EOS_IDX: self.EOS_IDX,\n",
        "            30000: 4,\n",
        "            65030: 5,\n",
        "            65000: 6,\n",
        "            80000: 7,\n",
        "            74000: 8,\n",
        "            70000: 9,\n",
        "            70032: 10,\n",
        "            88000: 11,\n",
        "            86000: 12,\n",
        "            99000: 13,\n",
        "            90000: 14,\n",
        "            93000: 15,\n",
        "        }\n",
        "        return lithology_numbers\n",
        "\n",
        "    def get_lithology_names(self):\n",
        "        # Define special symbols and indices\n",
        "        lithology_names = {\n",
        "            self.UNK_IDX: \"<unk>\",\n",
        "            self.PAD_IDX: \"<pad>\",\n",
        "            self.BOS_IDX: \"<bos>\",\n",
        "            self.EOS_IDX: \"<eos>\",\n",
        "            30000: \"Sandstone\",\n",
        "            65030: \"Sandstone/Shale\",\n",
        "            65000: \"Shale\",\n",
        "            80000: \"Marl\",\n",
        "            74000: \"Dolomite\",\n",
        "            70000: \"Limestone\",\n",
        "            70032: \"Chalk\",\n",
        "            88000: \"Halite\",\n",
        "            86000: \"Anhydrite\",\n",
        "            99000: \"Tuff\",\n",
        "            90000: \"Coal\",\n",
        "            93000: \"Basement\",\n",
        "        }\n",
        "        return lithology_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS0whwJhOWzW"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5W7TdmxiOWzX"
      },
      "outputs": [],
      "source": [
        "from transformers import PretrainedConfig\n",
        "from typing import List\n",
        "from transformers import PreTrainedModel\n",
        "\"\"\" PyTorch Facies model.\"\"\"\n",
        "from typing import List, Optional, Tuple, Union\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import PreTrainedModel\n",
        "import torch.utils.checkpoint\n",
        "from torch.nn import Transformer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "from transformers.modeling_outputs import (\n",
        "    Seq2SeqModelOutput,\n",
        "    Seq2SeqLMOutput,\n",
        "    BaseModelOutput,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jlwMDu21OWzY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FaciesConfig(PretrainedConfig):\n",
        "    r\"\"\"\n",
        "    This is the configuration class to store the configuration of a [`FaciesModel`]. It is used to instantiate a Facies\n",
        "    model according to the specified arguments, defining the model architecture. Instantiating a configuration with the\n",
        "    defaults will yield a similar configuration to that of the Facies\n",
        "    [facebook/Facies-large](https://huggingface.co/facebook/Facies-large) architecture.\n",
        "    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n",
        "    documentation from [`PretrainedConfig`] for more information.\n",
        "    Args:\n",
        "        vocab_size (`int`, *optional*, defaults to 50265):\n",
        "            Vocabulary size of the Facies model. Defines the number of different tokens that can be represented by the\n",
        "            `inputs_ids` passed when calling [`FaciesModel`] or [`TFFaciesModel`].\n",
        "        d_model (`int`, *optional*, defaults to 1024):\n",
        "            Dimensionality of the layers and the pooler layer.\n",
        "        encoder_layers (`int`, *optional*, defaults to 12):\n",
        "            Number of encoder layers.\n",
        "        decoder_layers (`int`, *optional*, defaults to 12):\n",
        "            Number of decoder layers.\n",
        "        encoder_attention_heads (`int`, *optional*, defaults to 16):\n",
        "            Number of attention heads for each attention layer in the Transformer encoder.\n",
        "        decoder_attention_heads (`int`, *optional*, defaults to 16):\n",
        "            Number of attention heads for each attention layer in the Transformer decoder.\n",
        "        decoder_ffn_dim (`int`, *optional*, defaults to 4096):\n",
        "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
        "        encoder_ffn_dim (`int`, *optional*, defaults to 4096):\n",
        "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
        "        activation_function (`str` or `function`, *optional*, defaults to `\"gelu\"`):\n",
        "            The non-linear activation function (function or string) in the encoder and pooler. If string, `\"gelu\"`,\n",
        "            `\"relu\"`, `\"silu\"` and `\"gelu_new\"` are supported.\n",
        "        dropout (`float`, *optional*, defaults to 0.1):\n",
        "            The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.\n",
        "        attention_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for the attention probabilities.\n",
        "        activation_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for activations inside the fully connected layer.\n",
        "        classifier_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for classifier.\n",
        "        max_position_embeddings (`int`, *optional*, defaults to 1024):\n",
        "            The maximum sequence length that this model might ever be used with. Typically set this to something large\n",
        "            just in case (e.g., 512 or 1024 or 2048).\n",
        "        init_std (`float`, *optional*, defaults to 0.02):\n",
        "            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
        "        encoder_layerdrop (`float`, *optional*, defaults to 0.0):\n",
        "            The LayerDrop probability for the encoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556)\n",
        "            for more details.\n",
        "        decoder_layerdrop (`float`, *optional*, defaults to 0.0):\n",
        "            The LayerDrop probability for the decoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556)\n",
        "            for more details.\n",
        "        scale_embedding (`bool`, *optional*, defaults to `False`):\n",
        "            Scale embeddings by diving by sqrt(d_model).\n",
        "        use_cache (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not the model should return the last key/values attentions (not used by all models).\n",
        "        num_labels (`int`, *optional*, defaults to 3):\n",
        "            The number of labels to use in [`FaciesForSequenceClassification`].\n",
        "        forced_eos_token_id (`int`, *optional*, defaults to 2):\n",
        "            The id of the token to force as the last generated token when `max_length` is reached. Usually set to\n",
        "            `eos_token_id`.\n",
        "    Example:\n",
        "    ```python\n",
        "    >>> from transformers import FaciesConfig, FaciesModel\n",
        "    >>> # Initializing a Facies facebook/Facies-large style configuration\n",
        "    >>> configuration = FaciesConfig()\n",
        "    >>> # Initializing a model (with random weights) from the facebook/Facies-large style configuration\n",
        "    >>> model = FaciesModel(configuration)\n",
        "    >>> # Accessing the model configuration\n",
        "    >>> configuration = model.config\n",
        "    ```\"\"\"\n",
        "    model_type = \"facies_transformer_seq_2_seq\"\n",
        "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
        "    attribute_map = {\n",
        "        \"num_attention_heads\": \"encoder_attention_heads\",\n",
        "        \"hidden_size\": \"d_model\",\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=12,\n",
        "        max_position_embeddings=1024,\n",
        "        encoder_layers=12,\n",
        "        encoder_ffn_dim=4096,\n",
        "        encoder_attention_heads=16,\n",
        "        decoder_layers=12,\n",
        "        decoder_ffn_dim=4096,\n",
        "        decoder_attention_heads=16,\n",
        "        encoder_layerdrop=0.0,\n",
        "        decoder_layerdrop=0.0,\n",
        "        activation_function=\"gelu\",\n",
        "        d_model=1024,\n",
        "        d_input=2,\n",
        "        dropout=0.1,\n",
        "        attention_dropout=0.0,\n",
        "        activation_dropout=0.0,\n",
        "        init_std=0.02,\n",
        "        classifier_dropout=0.0,\n",
        "        scale_embedding=False,\n",
        "        use_cache=True,\n",
        "        num_labels=3,\n",
        "        pad_token_id=1,\n",
        "        bos_token_id=0,\n",
        "        eos_token_id=2,\n",
        "        is_encoder_decoder=True,\n",
        "        decoder_start_token_id=2,\n",
        "        forced_eos_token_id=2,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_input = d_input\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.d_model = d_model\n",
        "        self.encoder_ffn_dim = encoder_ffn_dim\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.encoder_attention_heads = encoder_attention_heads\n",
        "        self.decoder_ffn_dim = decoder_ffn_dim\n",
        "        self.decoder_layers = decoder_layers\n",
        "        self.decoder_attention_heads = decoder_attention_heads\n",
        "        self.dropout = dropout\n",
        "        self.attention_dropout = attention_dropout\n",
        "        self.activation_dropout = activation_dropout\n",
        "        self.activation_function = activation_function\n",
        "        self.init_std = init_std\n",
        "        self.encoder_layerdrop = encoder_layerdrop\n",
        "        self.decoder_layerdrop = decoder_layerdrop\n",
        "        self.classifier_dropout = classifier_dropout\n",
        "        self.use_cache = use_cache\n",
        "        self.num_hidden_layers = encoder_layers\n",
        "        self.scale_embedding = (\n",
        "            scale_embedding  # scale factor will be sqrt(d_model) if True\n",
        "        )\n",
        "\n",
        "        super().__init__(\n",
        "            num_labels=num_labels,\n",
        "            pad_token_id=pad_token_id,\n",
        "            bos_token_id=bos_token_id,\n",
        "            eos_token_id=eos_token_id,\n",
        "            is_encoder_decoder=is_encoder_decoder,\n",
        "            decoder_start_token_id=decoder_start_token_id,\n",
        "            forced_eos_token_id=forced_eos_token_id,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        if self.forced_bos_token_id is None and kwargs.get(\n",
        "            \"force_bos_token_to_be_generated\", False\n",
        "        ):\n",
        "            self.forced_bos_token_id = self.bos_token_id\n",
        "            warnings.warn(\n",
        "                f\"Please make sure the config includes `forced_bos_token_id={self.bos_token_id}` in future versions. \"\n",
        "                \"The config can simply be saved and uploaded again to be fixed.\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ETmACxadOWzc"
      },
      "outputs": [],
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float, maxlen: int = 6400):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, d_model))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(\n",
        "            token_embedding + self.pos_embedding[: token_embedding.size(0), :]\n",
        "        )\n",
        "\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.d_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SD8agkGvOWzd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def shift_tokens_right(\n",
        "    input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Shift input ids one token to the right.\n",
        "    \"\"\"\n",
        "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
        "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
        "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
        "\n",
        "    if pad_token_id is None:\n",
        "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
        "    # replace possible -100 values in labels by `pad_token_id`\n",
        "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
        "\n",
        "    return shifted_input_ids\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = torch.triu(torch.ones((sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = (\n",
        "        mask.float()\n",
        "        .masked_fill(mask == 0, float(\"-inf\"))\n",
        "        .masked_fill(mask == 1, float(0.0))\n",
        "    )\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt, PAD_IDX=None, DEVICE=None):\n",
        "    src_mask = None\n",
        "    src_padding_mask = None\n",
        "    if src is not None:\n",
        "        src_seq_len = src.shape[1]\n",
        "        src_mask = torch.zeros((src_seq_len, src_seq_len)).type(torch.bool)\n",
        "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "\n",
        "    if tgt is not None:\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "        tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "\n",
        "        tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "\n",
        "class FaciesPretrainedModel(PreTrainedModel):\n",
        "    config_class = FaciesConfig\n",
        "    base_model_prefix = \"model\"\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = self.config.init_std\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "\n",
        "    @property\n",
        "    def dummy_inputs(self):\n",
        "        pad_token = self.config.pad_token_id\n",
        "        input_ids = torch.tensor(\n",
        "            [[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device\n",
        "        )\n",
        "        dummy_inputs = {\n",
        "            \"attention_mask\": input_ids.ne(pad_token),\n",
        "            \"input_ids\": input_ids,\n",
        "        }\n",
        "        return dummy_inputs\n",
        "\n",
        "class FaciesModelEncoder(FaciesPretrainedModel):\n",
        "    def __init__(self, config: FaciesConfig, model):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "\n",
        "        self.model = model.encoder\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            config.d_model, dropout=config.dropout\n",
        "        )\n",
        "\n",
        "        self.embedding_input = torch.nn.Linear(config.d_input, config.d_model)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqModelOutput]:\n",
        "\n",
        "        channel_encoding = self.embedding_input(input_ids.transpose(-1, -2))\n",
        "\n",
        "        output_encoder = self.model(\n",
        "            channel_encoding, mask=None, src_key_padding_mask=None\n",
        "        )\n",
        "\n",
        "        return BaseModelOutput(last_hidden_state=output_encoder)\n",
        "\n",
        "class FaciesModel(FaciesPretrainedModel):\n",
        "    def __init__(self, config: FaciesConfig):\n",
        "        super().__init__(config)\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "        self.model = Transformer(\n",
        "            d_model=config.d_model,\n",
        "            num_encoder_layers=config.encoder_layers,\n",
        "            nhead=config.decoder_attention_heads,\n",
        "            num_decoder_layers=config.decoder_layers,\n",
        "            dim_feedforward=config.encoder_ffn_dim,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.encoder = FaciesModelEncoder(config, self.model)\n",
        "\n",
        "        self.decoder = self.model.decoder\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            config.d_model, dropout=config.dropout\n",
        "        )\n",
        "        self.decoder_inputs_embeds = TokenEmbedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.shared\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.shared = value\n",
        "        self.encoder.embed_tokens = self.shared\n",
        "        self.decoder.embed_tokens = self.decoder_inputs_embed\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.decoder\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqModelOutput]:\n",
        "\n",
        "        decoder_input_ids = self.positional_encoding(\n",
        "            self.decoder_inputs_embeds(decoder_input_ids)\n",
        "        )\n",
        "\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids\n",
        "            )\n",
        "        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0]\n",
        "            )\n",
        "\n",
        "        decoder_output = self.decoder(\n",
        "            decoder_input_ids,\n",
        "            encoder_outputs.last_hidden_state,\n",
        "            tgt_mask=decoder_attention_mask,\n",
        "            memory_mask=None,\n",
        "            tgt_key_padding_mask=None,\n",
        "            memory_key_padding_mask=None,\n",
        "        )\n",
        "\n",
        "        decoder_outputs = BaseModelOutput(last_hidden_state=decoder_output)\n",
        "\n",
        "        return Seq2SeqModelOutput(\n",
        "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "        )\n",
        "\n",
        "\n",
        "class FaciesForConditionalGeneration(FaciesPretrainedModel):\n",
        "    base_model_prefix = \"model\"\n",
        "\n",
        "    def __init__(self, config: FaciesConfig):\n",
        "        super().__init__(config)\n",
        "        self.model = FaciesModel(config)\n",
        "        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.model.get_encoder()\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.get_decoder()\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
        "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
        "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        return_dict = (\n",
        "            return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        )\n",
        "\n",
        "        if labels is not None:\n",
        "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
        "                decoder_input_ids = shift_tokens_right(\n",
        "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "                )\n",
        "\n",
        "        (\n",
        "            head_mask,\n",
        "            decoder_attention_mask,\n",
        "            attention_mask,\n",
        "            decoder_head_mask,\n",
        "        ) = create_mask(\n",
        "            input_ids,\n",
        "            decoder_input_ids,\n",
        "            PAD_IDX=self.config.pad_token_id,\n",
        "            DEVICE=decoder_input_ids.device,\n",
        "        )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            attention_mask=None,\n",
        "            decoder_attention_mask=decoder_attention_mask.to(device=decoder_input_ids.device),\n",
        "            decoder_head_mask=None,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "        )\n",
        "\n",
        "        lm_logits = self.lm_head(outputs[0])\n",
        "\n",
        "        masked_lm_loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(\n",
        "                lm_logits.view(-1, self.config.vocab_size), labels.view(-1)\n",
        "            )\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + outputs[1:]\n",
        "            return (\n",
        "                ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
        "            )\n",
        "\n",
        "        return Seq2SeqLMOutput(loss=masked_lm_loss, logits=lm_logits)\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        decoder_input_ids,\n",
        "        past=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        decoder_head_mask=None,\n",
        "        cross_attn_head_mask=None,\n",
        "        use_cache=None,\n",
        "        encoder_outputs=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # cut decoder_input_ids if past is used\n",
        "        if past is not None:\n",
        "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "            \"past_key_values\": past,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"head_mask\": head_mask,\n",
        "            \"decoder_head_mask\": decoder_head_mask,\n",
        "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
        "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
        "        }\n",
        "\n",
        "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
        "        return shift_tokens_right(\n",
        "            labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Een9iuOWze"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6luvD4_OWzf"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TOGIfSQ3OWzf"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, logging\n",
        "import torchmetrics\n",
        "import math\n",
        "import time\n",
        "from torch import nn, optim\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NfFNumGOWzf"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T3SWlbhnOWzf"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        tgt_batch.append(tgt_sample)\n",
        "        src_batch.append(src_sample)\n",
        "\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "\n",
        "    model_input = {\"input_ids\": src_batch, \"labels\": tgt_batch}\n",
        "    return model_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "To_SxwoJSImv"
      },
      "outputs": [],
      "source": [
        "%mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tazk83WoOWzg",
        "outputId": "a5f39d18-c68d-4eca-b6c0-cc1c82c5613a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/Coding/HuggingFaceSeq2Seq//facies-transformer-config/config.json\n",
            "loading configuration file /content/drive/MyDrive/Coding/HuggingFaceSeq2Seq//facies-transformer-config/config.json\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2', '3': 'LABEL_3', '4': 'LABEL_4', '5': 'LABEL_5', '6': 'LABEL_6', '7': 'LABEL_7', '8': 'LABEL_8', '9': 'LABEL_9', '10': 'LABEL_10', '11': 'LABEL_11', '12': 'LABEL_12', '13': 'LABEL_13', '14': 'LABEL_14', '15': 'LABEL_15'}. The number of labels wil be overwritten to 16.\n",
            "Model config FaciesConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_input\": 20,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 4,\n",
            "  \"decoder_ffn_dim\": 1024,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 4,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 4,\n",
            "  \"encoder_ffn_dim\": 1024,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 4,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"forced_eos_token_id\": 3,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"facies_transformer_seq_2_seq\",\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 16\n",
            "}\n",
            "\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 34401\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 640\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 640\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 216\n",
            "  Number of trainable parameters = 21066240\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 12/216 00:03 < 01:08, 2.96 it/s, Epoch 0.20/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-162b401e84da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m )\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2526\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# GPU device setting\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"saved_models/model_\"\n",
        "model_path = \"/content/drive/MyDrive/Coding/HuggingFaceSeq2Seq/\"\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "SEQUENCE_LEN = 20\n",
        "TRAINING_RATIO = 0.90\n",
        "WIRELINE_LOGS_HEADER = [\"DEPTH_MD\", \"GR\", \"NPHI\"]\n",
        "LABEL_COLUMN_HEADER = [\"FORCE_2020_LITHOFACIES_LITHOLOGY\"]\n",
        "\n",
        "train_dataset = WellsDataset(\n",
        "    dataset_type=\"train\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        ")\n",
        "\n",
        "DATA_LEN = train_dataset.train_len\n",
        "d_input = train_dataset.input_len\n",
        "d_output = train_dataset.output_len\n",
        "d_channel = train_dataset.channel_len\n",
        "tgt_vocab_size = train_dataset.output_len + len(train_dataset.special_symbols)\n",
        "TRAIN_DATA_LEN = int(DATA_LEN * TRAINING_RATIO)\n",
        "\n",
        "facies_config = {\n",
        "    \"vocab_size\": tgt_vocab_size,\n",
        "    \"max_position_embeddings\": 1024,\n",
        "    \"encoder_layers\": 4,\n",
        "    \"encoder_ffn_dim\": 1024,\n",
        "    \"encoder_attention_heads\": 4,\n",
        "    \"decoder_layers\": 4,\n",
        "    \"decoder_ffn_dim\": 1024,\n",
        "    \"decoder_attention_heads\": 4,\n",
        "    \"encoder_layerdrop\": 0.0,\n",
        "    \"decoder_layerdrop\": 0.0,\n",
        "    \"activation_function\": \"relu\",\n",
        "    \"d_model\": 512,\n",
        "    \"d_input\": d_input,\n",
        "    \"dropout\": 0.1,\n",
        "    \"attention_dropout\": 0.0,\n",
        "    \"activation_dropout\": 0.0,\n",
        "    \"init_std\": 0.02,\n",
        "    \"classifier_dropout\": 0.0,\n",
        "    \"scale_embedding\": False,\n",
        "    \"use_cache\": False,\n",
        "    \"num_labels\": tgt_vocab_size,\n",
        "    \"pad_token_id\": PAD_IDX,\n",
        "    \"bos_token_id\": BOS_IDX,\n",
        "    \"eos_token_id\": EOS_IDX,\n",
        "    \"is_encoder_decoder\": True,\n",
        "    \"decoder_start_token_id\": 2,\n",
        "    \"forced_eos_token_id\": EOS_IDX,\n",
        "}\n",
        "\n",
        "train_data, validation_data = random_split(\n",
        "    train_dataset, lengths=[TRAIN_DATA_LEN, DATA_LEN - TRAIN_DATA_LEN]\n",
        ")\n",
        "\n",
        "facies_transformer_config = FaciesConfig(**facies_config)\n",
        "facies_transformer_config.save_pretrained(f\"{model_path}/facies-transformer-config/\")\n",
        "facies_transformer_config = FaciesConfig.from_pretrained(f\"{model_path}/facies-transformer-config/\")\n",
        "facies_transformer = FaciesForConditionalGeneration(facies_transformer_config)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 640\n",
        "NUM_TRAIN_EPOCHS = 4\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{model_path}/saved_models/\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=facies_transformer,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    data_collator=collate_fn,\n",
        "    args=training_args,\n",
        ")\n",
        "result = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJD9-qMeOWzg"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9ducnEzOWzg",
        "outputId": "3abbbdbb-d0c5-4b9a-c5fd-27c2a6051591"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.13 64-bit' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3.9 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "test_dataset = WellsDataset(\n",
        "    dataset_type=\"test\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        "    scaler=train_dataset.scaler,\n",
        "    output_len=train_dataset.output_len,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "\n",
        "# Loop for generating the output of a sequence for all the data in the test dataloader using model.generate\n",
        "for i, batch in enumerate(test_loader):\n",
        "    input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "    outputs = facies_transformer.generate(\n",
        "        input_ids=input_ids,\n",
        "        num_beams=8,\n",
        "        num_return_sequences=1,\n",
        "        max_new_tokens=SEQUENCE_LEN+1\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "99c6707e6b461d11f09cb1797f7e40511c3362fe9c917a4510d9e5853ba54b32"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
