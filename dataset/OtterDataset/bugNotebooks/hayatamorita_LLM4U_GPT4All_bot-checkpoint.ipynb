{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f542594",
   "metadata": {},
   "outputs": [],
   "source": [
    " !export LANGCHAIN_API_KEY=\"ls__9681b332c51f4fc08bb63f90c3cc64cf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89849c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.llms import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6d375ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm model\n",
    "# model = GPT4All(model=\"../model/mistral-7b-openorca.gguf2.Q4_0.gguf\", n_threads=8)\n",
    "model = GPT4All(model=\"../model/gpt4all-falcon-newbpe-q4_0.gguf\", n_threads=8)\n",
    "llm = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c848bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithAuthError('Authentication failed for https://api.smith.langchain.com/runs/batch. HTTPError(\\'401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Invalid API key\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "response = model(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73c122f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab613bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithAuthError('Authentication failed for https://api.smith.langchain.com/runs/batch. HTTPError(\\'401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Invalid API key\"}\\')')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"hello, who are you. what you are name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1565a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Not RAG\n",
    "response = llm.invoke(\"how can langsmith help with testing?\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47718b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2001122",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc5f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d746c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57364010",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea22d3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithAuthError('Authentication failed for https://api.smith.langchain.com/runs/batch. HTTPError(\\'401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Invalid API key\"}\\')')\n",
      "Failed to batch ingest runs: LangSmithAuthError('Authentication failed for https://api.smith.langchain.com/runs/batch. HTTPError(\\'401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Invalid API key\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the provided context, LangSmith can help with testing in several ways:\n",
      "\n",
      "1. Debugging: When developing new LLM applications, LangSmith's tracing feature can be enabled by default to quickly understand how the model is performing and debug where it is failing.\n",
      "2. Test cases: LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\n",
      "3. Custom evaluations: LangSmith makes it easy to run custom evaluations (both LLM and heuristic-based) to score test results. This helps developers track regressions with respect to their initial test cases.\n",
      "4. Comparison view: When prototyping different versions of an application, LangSmith's comparison view allows users to see whether or not they have regressed with respect to their initial test cases. This helps diagnose regressions in test scores across multiple revisions of the application.\n",
      "5. Playground environment: LangSmith provides a playground environment for rapid iteration and experimentation, allowing developers to quickly test out different prompts and models without having to create new traces.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb54eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the provided context, LangSmith can help with testing in several ways:\n",
      "\n",
      "1. Debugging: When developing new LLM applications, LangSmith's tracing feature can be enabled by default to quickly understand how the model is performing and debug where it is failing.\n",
      "2. Test cases: LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\n",
      "3. Custom evaluations: LangSmith makes it easy to run custom evaluations (both LLM and heuristic-based) to score test results. This helps developers track regressions with respect to their initial test cases.\n",
      "4. Comparison view: When prototyping different versions of an application, LangSmith's comparison view allows users to see whether or not they have regressed with respect to their initial test cases. This helps diagnose regressions in test scores across multiple revisions of the application.\n",
      "5. Playground environment: LangSmith provides a playground environment for rapid iteration and experimentation, allowing developers to quickly test out different prompts and models without having to create new traces.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3e938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "jp",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "jp",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
