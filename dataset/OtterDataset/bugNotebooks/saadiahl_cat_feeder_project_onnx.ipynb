{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 model_inspect.py \\\n",
    "    --runmode saved_model \\\n",
    "    --model_name efficientdet-d5 \\\n",
    "    --ckpt_path /Users/arif/Downloads/efficientdet-d5 \\\n",
    "    --saved_model_dir \"/Users/arif/Documents/Pet Feeder/Software/AI/cat_feeder_project/od_tf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 create_onnx.py \\\n",
    "    --input_size 1280,1280 \\\n",
    "    --saved_model \"/Users/arif/Documents/Pet Feeder/Software/AI/cat_feeder_project/od_tf\" \\\n",
    "    --onnx \"/Users/arif/Documents/Pet Feeder/Software/AI/cat_feeder_project/effdet_d5.onnx\" \\\n",
    "    --input_format NCHW \\\n",
    "    --preprocessor scale_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging config 1-time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class CurrentModuleFilter(logging.Filter):\n",
    "    def __init__(self, module_name):\n",
    "        super().__init__()\n",
    "        self.module_name = module_name\n",
    "\n",
    "    def filter(self, record):\n",
    "        # Only allow log messages from the specified module\n",
    "        return record.name == self.module_name\n",
    "\n",
    "\n",
    "# Create a logger with a specific name (usually the name of the module)\n",
    "logger_name = \"onnx\"  # Replace with your module's name\n",
    "logger = logging.getLogger(logger_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "\n",
    "# Create a logging handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create and set the custom filter\n",
    "module_filter = CurrentModuleFilter(logger_name)\n",
    "console_handler.addFilter(module_filter)\n",
    "\n",
    "log_format = \"%(lineno)d : %(message)s\"\n",
    "formatter = logging.Formatter(log_format)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Test the logger\n",
    "logger.debug(f\"This message is from the {logger_name} module.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw.cpufamily: 458787763 , size = 4\n",
      "The device support i8sdot:1, support fp16:1, support i8mm: 0\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import OxfordIIITPet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = OxfordIIITPet(\n",
    "    root=\"/Users/arif/Downloads/data\",\n",
    "    split=\"trainval\",\n",
    "    target_types=\"category\",\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "test_set = OxfordIIITPet(\n",
    "    root=\"/Users/arif/Downloads/data\",\n",
    "    split=\"test\",\n",
    "    target_types=\"category\",\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mYour model contains \"Tile\" ops or/and \"ConstantOfShape\" ops. Folding these ops \u001b[0m\n",
      "\u001b[1;35mcan make the simplified model much larger. If it is not expected, please specify\u001b[0m\n",
      "\u001b[1;35m\"--no-large-tensor\" (which will lose some optimization chances)\u001b[0m\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 72             │ \u001b[1;32m32              \u001b[0m │\n",
      "│ ArgMin            │ 1              │ 1                │\n",
      "│ Cast              │ 96             │ \u001b[1;32m1               \u001b[0m │\n",
      "│ Ceil              │ 20             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Clip              │ 20             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Concat            │ 31             │ \u001b[1;32m1               \u001b[0m │\n",
      "│ Constant          │ 569            │ \u001b[1;32m239             \u001b[0m │\n",
      "│ ConstantOfShape   │ 10             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Conv              │ 230            │ 230              │\n",
      "│ Div               │ 36             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Equal             │ 4              │ 4                │\n",
      "│ Flatten           │ 2              │ 2                │\n",
      "│ Gather            │ 30             │ \u001b[1;32m4               \u001b[0m │\n",
      "│ GlobalAveragePool │ 2              │ 2                │\n",
      "│ Identity          │ 138            │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Mul               │ 204            │ \u001b[1;32m184             \u001b[0m │\n",
      "│ NonZero           │ 4              │ 4                │\n",
      "│ Pad               │ 10             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Pow               │ 2              │ 2                │\n",
      "│ ReduceMean        │ 50             │ 50               │\n",
      "│ ReduceSum         │ 1              │ 1                │\n",
      "│ Reshape           │ 20             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Shape             │ 26             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Sigmoid           │ 184            │ 184              │\n",
      "│ Slice             │ 10             │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Sub               │ 71             │ \u001b[1;32m1               \u001b[0m │\n",
      "│ Transpose         │ 14             │ \u001b[1;32m4               \u001b[0m │\n",
      "│ Unsqueeze         │ 82             │ \u001b[1;32m2               \u001b[0m │\n",
      "│ Model Size        │ 29.6MiB        │ \u001b[1;32m29.5MiB         \u001b[0m │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# !onnxsim /Users/arif/Downloads/edgenext_base_usi_in1k_support.onnx /Users/arif/Downloads/edgenext_base_usi_in1k_support_opt.onnx 5 --enable-onnxruntime-optimization\n",
    "# !onnxsim /Users/arif/Downloads/edgenext_base_usi_in1k_query.onnx /Users/arif/Downloads/edgenext_base_usi_in1k_query_opt.onnx 5 --enable-onnxruntime-optimization\n",
    "!onnxsim ./test.onnx ./test_opt.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = onnx.load(\"./test_opt.onnx\")\n",
    "onnx.checker.check_model(test_model, full_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ort_sess = ort.InferenceSession(\"./test_opt.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 : image (torch.float32, torch.Size([3, 260, 260]), tensor(1.1152), tensor(0.9671))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2, InterpolationMode\n",
    "\n",
    "image = Image.open(\"/Users/arif/Downloads/beignets-task-guide.png\").convert(\"RGB\")\n",
    "\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.uint8, scale=True),\n",
    "        v2.Resize([292, 292], interpolation=InterpolationMode.BICUBIC, antialias=None),\n",
    "        v2.CenterCrop(260),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = transforms(image)\n",
    "logger.info(f\"image {image.dtype, image.shape, image.mean(), image.std()}\")\n",
    "\n",
    "# model = timm.create_model(\n",
    "#     'timm/tf_efficientnet_b2.ns_jft_in1k',\n",
    "#     # 'edgenext_base.usi_in1k',\n",
    "#     pretrained=True,\n",
    "#     num_classes=0,\n",
    "#     exportable=True\n",
    "# )\n",
    "# model = model.eval()\n",
    "# torch_outputs = model(transforms(image).unsqueeze(0)).detach().numpy()\n",
    "# logger.info(f\"torch_output {torch_outputs.dtype, torch_outputs.shape, torch_outputs.mean(), torch_outputs.std(), torch_outputs.max(), torch_outputs.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 : image (dtype('float32'), (1, 3, 1152, 1152), 84.842224, 46.15985)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([   9,   33, 1548, 1545], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image):\n",
    "    mean = np.asarray([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.asarray([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (1152, 1152), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # w, h = 260, 260\n",
    "    # y, x = (image.shape[0] - h) // 2, (image.shape[1] - w) // 2\n",
    "    # image = image[y:y + h, x:x + w]\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "    # image = image.astype(np.float32) / 255.0\n",
    "    # image = (image - mean) / std\n",
    "    image = image.transpose([2, 0, 1])\n",
    "\n",
    "    image = np.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "# image = cv2.imread(\"/Users/arif/Downloads/beignets-task-guide.png\", cv2.IMREAD_COLOR)\n",
    "# image = cv2.imread(\"/Users/arif/Downloads/149096135_38da34403d_z.jpg\", cv2.IMREAD_COLOR)\n",
    "image = cv2.imread(\n",
    "    \"/Users/arif/Downloads/2126259110_79df1cde52_z.jpg\", cv2.IMREAD_COLOR\n",
    ")\n",
    "# image = cv2.imread(\"/Users/arif/Downloads/148363573_db510f0e0a_z.jpg\", cv2.IMREAD_COLOR)\n",
    "image = cv2.imread(\"CatDataset/support/jico/lp_image.jpeg\", cv2.IMREAD_COLOR)\n",
    "image_proc = preprocess_image(image)\n",
    "logger.info(\n",
    "    f\"image {image_proc.dtype, image_proc.shape, image_proc.mean(), image_proc.std()}\"\n",
    ")\n",
    "\n",
    "# support_ort_sess = ort.InferenceSession(\"./yolov6n_opt.onnx\")\n",
    "support_ort_sess = ort.InferenceSession(\"/Users/arif/Downloads/yolov6n.onnx\")\n",
    "# outputTensors = ['det_boxes']\n",
    "# output_names=['num_det', 'det_boxes', 'det_scores', 'det_classes']\n",
    "# outputTensors = ['x0', 'y0', 'x1', 'y1', 'det_score']\n",
    "# try:\n",
    "#     cv2_outputs = support_ort_sess.run(None, {'x.1': image})\n",
    "# except:\n",
    "all = support_ort_sess.run(None, {\"images\": image_proc})\n",
    "# x0, y0, x1, y1, det_scores = support_ort_sess.run(None, {'images': image_proc})\n",
    "# x0, y0, x1, y1 = [int(coord) for coord in (x0, y0, x1, y1)]\n",
    "print(all)\n",
    "# print(x0, y0, x1, y1, det_scores)\n",
    "\n",
    "# Define the color of the box and its thickness\n",
    "color = (0, 255, 0)  # Green\n",
    "thickness = 2  # Thickness of the lines used to draw the box\n",
    "\n",
    "# Draw the rectangle on the image\n",
    "image = cv2.imread(\n",
    "    \"/Users/arif/Downloads/2126259110_79df1cde52_z.jpg\", cv2.IMREAD_COLOR\n",
    ")\n",
    "# cv2.rectangle(image, (x0[0], y0[0]), (x1[0], y1[0]), color, thickness)\n",
    "\n",
    "# Display the image\n",
    "# cv2.imshow('Image with Bounding Box', image)\n",
    "\n",
    "# logger.info(f\"cv2_output {cv2_outputs.dtype, cv2_outputs.shape, cv2_outputs.mean(), cv2_outputs.std(), cv2_outputs.max(), cv2_outputs.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  4,  13, 638, 637], dtype=int32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cv = cv2.imread(\"CatDataset/support/jico/jico_test.jpeg\", cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 123.24284443344645 55.43454773061126 233 0\n",
      "dtype.uint8 123.06302642822266 55.38330078125 233 0\n"
     ]
    }
   ],
   "source": [
    "import MNN.nn as nn\n",
    "import MNN.cv as cv\n",
    "import MNN.numpy as np\n",
    "import numpy as np2\n",
    "import MNN.expr as expr\n",
    "\n",
    "print(image_cv.dtype, image_cv.mean(), image_cv.std(), image_cv.max(), image_cv.min())\n",
    "image = np.asarray(image_cv.tolist(), dtype=np.uint8)\n",
    "print(image.dtype, image.mean(dtype=np.float64), image.std(), image.max(), image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 1920, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype.uint8 123.06302642822266 55.38330078125 233 0\n"
     ]
    }
   ],
   "source": [
    "image = expr.const(image_cv.tolist(), [884, 1920, 3], expr.NHWC, expr.uint8)\n",
    "print(image.dtype, image.mean(dtype=np.float64), image.std(), image.max(), image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image cvt dtype.uint8 [884, 1920, 3] 123.06107330322266 55.382450103759766\n",
      "image rsz dtype.uint8 [640, 640, 3] 123.24080657958984 55.43525314331055\n",
      "image 255 dtype.float [640, 640, 3] 0.4832761883735657 0.2172865867614746\n",
      "image norm dtype.float [640, 640, 3] 0.15166887640953064 0.948476254940033\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.asarray([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "# image = image[:, :, ::-1]\n",
    "# image = image[:,[2,1,0],...]\n",
    "print(\"image cvt\", image.dtype, image.shape, image.mean(), image.std())\n",
    "# image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "# image = cv.cvtColor(image, cv.COLOR_GRAY2RGB)\n",
    "image = cv.resize(image, (640, 640), interpolation=cv.INTER_CUBIC)\n",
    "print(\"image rsz\", image.dtype, image.shape, image.mean(), image.std())\n",
    "\n",
    "# w, h = 640, 640\n",
    "# y, x = (image.shape[0] - h) // 2, (image.shape[1] - w) // 2\n",
    "# image = image[y:y + h, x:x + w]\n",
    "\n",
    "image = image.astype(np.float32) / 255.0\n",
    "print(\"image 255\", image.dtype, image.shape, image.mean(), image.std())\n",
    "image = (image - mean) / std\n",
    "print(\"image norm\", image.dtype, image.shape, image.mean(), image.std())\n",
    "# image = image.transpose([2, 0, 1]) #! only for onnx\n",
    "\n",
    "image = np.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0, x1, y1 = [int(coord) for coord in (x0, y0, x1, y1)]\n",
    "\n",
    "# Define the color of the box and its thickness\n",
    "color = (0, 255, 0)  # Green\n",
    "thickness = 2  # Thickness of the lines used to draw the box\n",
    "\n",
    "# Draw the rectangle on the image\n",
    "image = cv2.imread(\n",
    "    \"/Users/arif/Downloads/2126259110_79df1cde52_z.jpg\", cv2.IMREAD_COLOR\n",
    ")\n",
    "cv2.rectangle(image, (x0, y0), (x1, y1), color, thickness)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image with Bounding Box\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = det_boxes[..., 2] - det_boxes[..., 0]\n",
    "heights = det_boxes[..., 3] - det_boxes[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.Tensor(widths) * torch.Tensor(heights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_det\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet_boxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cat([torch.tensor(num_det), torch.tensor(det_boxes), torch.tensor(det_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(image.transpose(1, 2, 0))\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtol = 0.1  # Relative tolerance\n",
    "# atol = 0.1  # Absolute tolerance\n",
    "\n",
    "# # Compare arrays\n",
    "# are_close = np.allclose(cv2_outputs, torch_outputs, rtol=rtol, atol=atol)\n",
    "# print(are_close)\n",
    "\n",
    "# # Element-wise comparison\n",
    "# close_elements = np.isclose(cv2_outputs, torch_outputs, rtol=rtol, atol=atol)\n",
    "# print(close_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_for_label(z_support, support_labels, label):\n",
    "    return np.mean(z_support[support_labels[support_labels == label]], axis=0)\n",
    "\n",
    "\n",
    "def fsl_model(support_net, query_net, support_images, support_labels, query_images):\n",
    "    logger.info(\n",
    "        f\"support_images {support_images.shape, support_images.mean(), support_images.std()}\"\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"query_images {query_images.shape, query_images.mean(), query_images.std()}\"\n",
    "    )\n",
    "\n",
    "    # try:\n",
    "    z_support = support_net.run(None, {\"input.1\": support_images})[0]\n",
    "    z_query = query_net.run(None, {\"input.1\": query_images})[0]\n",
    "    # except:\n",
    "    #     z_support = support_net.run([\"efficientnet-b2/model/head/dropout/Identity\"], {'images': support_images})[0]\n",
    "    #     z_query = query_net.run([\"efficientnet-b2/model/head/dropout/Identity\"], {'images': query_images})[0]\n",
    "\n",
    "    logger.info(f\"z_support {z_support.shape, z_support.mean(), z_support.std()}\")\n",
    "    logger.info(f\"z_query {z_query.shape, z_query.mean(), z_query.std()}\")\n",
    "\n",
    "    n_way = len(np.unique(support_labels))\n",
    "    logger.debug(f\"support_labels {support_labels}\")\n",
    "    logger.info(f\"n_way {n_way}\")\n",
    "\n",
    "    z_proto = Parallel(n_jobs=1)(\n",
    "        delayed(calculate_mean_for_label)(z_support, support_labels, label)\n",
    "        for label in range(n_way)\n",
    "    )\n",
    "    z_proto = np.stack(z_proto)\n",
    "\n",
    "    logger.info(f\"z_proto {z_proto.shape, z_proto.mean(), z_proto.std()}\")\n",
    "    logger.debug(f\"z_proto {z_proto}\")\n",
    "\n",
    "    # Compute the euclidean distance from queries to prototypes\n",
    "    # dists = cdist(z_query, z_proto)\n",
    "    dists = np.linalg.norm(z_query[:, np.newaxis] - z_proto, axis=2)\n",
    "    logger.info(f\"dists {dists.shape, dists.mean(), dists.std()}\")\n",
    "    logger.debug(f\"dists {dists}\")\n",
    "\n",
    "    # And here is the super complicated operation to transform those distances into classification scores!\n",
    "    scores = -dists\n",
    "    logger.info(f\"scores {scores.shape, scores.mean(), scores.std()}\")\n",
    "    logger.debug(f\"scores {scores}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 4  # Number of classes in a task\n",
    "N_SHOT = 5  # Number of images per class in the support set\n",
    "N_QUERY = 30  # Number of images per class in the query set\n",
    "N_EVALUATION_TASKS = 100\n",
    "\n",
    "# The sampler needs a dataset with a \"get_labels\" method. Check the code if you have any doubt!\n",
    "test_set.get_labels = lambda: test_set._labels\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "(\n",
    "    example_support_images,\n",
    "    example_support_labels,\n",
    "    example_query_images,\n",
    "    example_query_labels,\n",
    "    example_class_ids,\n",
    ") = next(iter(test_loader))\n",
    "\n",
    "logger.info(\n",
    "    f\"{len(example_support_images), len(example_support_labels), len(example_query_images), len(example_query_labels), len(example_class_ids)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:20<00:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested on 100 tasks.\n",
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_on_one_task(\n",
    "    support_images, support_labels, query_images, query_labels, n_way\n",
    "):\n",
    "    # Get model predictions\n",
    "    # predictions = np.argmax(fsl_model(support_ort_sess, query_ort_sess, support_images, support_labels, query_images), 1)\n",
    "    predictions = test_ort_sess.run(\n",
    "        None,\n",
    "        {\"x.1\": support_images, \"onnx::Cast_1\": support_labels, \"x.149\": query_images},\n",
    "    )[0]\n",
    "    logger.info(f\"predictions {predictions}\")\n",
    "    logger.info(f\"query_labels {query_labels}\")\n",
    "    # query_labels = torch.from_numpy(query_labels)\n",
    "    accuracy = np.sum(predictions == query_labels) / len(query_labels)\n",
    "\n",
    "    return accuracy * 100\n",
    "\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    for episode_index, (\n",
    "        support_images,\n",
    "        support_labels,\n",
    "        query_images,\n",
    "        query_labels,\n",
    "        class_ids,\n",
    "    ) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        accuracy = evaluate_on_one_task(\n",
    "            support_images, support_labels, query_images, query_labels, len(class_ids)\n",
    "        )\n",
    "        # break\n",
    "\n",
    "    print(f\"Model tested on {len(data_loader)} tasks.\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "I0129 20:31:38.170017 8057855040 efficientnet_builder.py:225] global_params= GlobalParams(batch_norm_momentum=0.99, batch_norm_epsilon=0.001, dropout_rate=0.3, data_format='channels_last', num_classes=1000, width_coefficient=1.1, depth_coefficient=1.2, depth_divisor=8, min_depth=None, survival_prob=0.8, relu_fn=<function swish at 0x11e4c8ee0>, batch_norm=<function eval_batch_norm at 0x15f6314c0>, use_se=True, se_coefficient=None, local_pooling=None, condconv_num_experts=None, clip_projection_output=False, blocks_args=['r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25', 'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25', 'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25', 'r1_k3_s11_e6_i192_o320_se0.25'], fix_head_stem=None, use_bfloat16=None)\n",
      "I0129 20:31:38.173455 8057855040 efficientnet_model.py:121] round_filter input=32 output=32\n",
      "I0129 20:31:38.176726 8057855040 efficientnet_model.py:121] round_filter input=32 output=32\n",
      "I0129 20:31:38.176765 8057855040 efficientnet_model.py:121] round_filter input=16 output=16\n",
      "I0129 20:31:38.202416 8057855040 efficientnet_model.py:121] round_filter input=16 output=16\n",
      "I0129 20:31:38.202497 8057855040 efficientnet_model.py:121] round_filter input=24 output=24\n",
      "I0129 20:31:38.239041 8057855040 efficientnet_model.py:121] round_filter input=24 output=24\n",
      "I0129 20:31:38.239119 8057855040 efficientnet_model.py:121] round_filter input=40 output=48\n",
      "I0129 20:31:38.275959 8057855040 efficientnet_model.py:121] round_filter input=40 output=48\n",
      "I0129 20:31:38.276044 8057855040 efficientnet_model.py:121] round_filter input=80 output=88\n",
      "I0129 20:31:38.330254 8057855040 efficientnet_model.py:121] round_filter input=80 output=88\n",
      "I0129 20:31:38.330343 8057855040 efficientnet_model.py:121] round_filter input=112 output=120\n",
      "I0129 20:31:38.379882 8057855040 efficientnet_model.py:121] round_filter input=112 output=120\n",
      "I0129 20:31:38.379966 8057855040 efficientnet_model.py:121] round_filter input=192 output=208\n",
      "I0129 20:31:38.441244 8057855040 efficientnet_model.py:121] round_filter input=192 output=208\n",
      "I0129 20:31:38.441326 8057855040 efficientnet_model.py:121] round_filter input=320 output=352\n",
      "I0129 20:31:38.465479 8057855040 efficientnet_model.py:121] round_filter input=1280 output=1408\n",
      "I0129 20:31:38.803127 8057855040 api.py:460] Built stem layers with output shape: (1, 130, 130, 32)\n",
      "I0129 20:31:38.811216 8057855040 api.py:460] block_0 survival_prob: 1.0\n",
      "I0129 20:31:38.930660 8057855040 api.py:460] Block mb_conv_block input shape: (1, 130, 130, 32)\n",
      "I0129 20:31:38.943627 8057855040 api.py:460] DWConv shape: (1, 130, 130, 32)\n",
      "I0129 20:31:38.992176 8057855040 api.py:460] Built SE mb_conv_block : (1, 1, 1, 32)\n",
      "I0129 20:31:39.005458 8057855040 api.py:460] Project shape: (1, 130, 130, 16)\n",
      "I0129 20:31:39.016648 8057855040 api.py:460] block_1 survival_prob: 0.991304347826087\n",
      "I0129 20:31:39.016980 8057855040 api.py:460] Block mb_conv_block_1 input shape: (1, 130, 130, 16)\n",
      "I0129 20:31:39.030122 8057855040 api.py:460] DWConv shape: (1, 130, 130, 16)\n",
      "I0129 20:31:39.047077 8057855040 api.py:460] Built SE mb_conv_block_1 : (1, 1, 1, 16)\n",
      "I0129 20:31:39.084764 8057855040 api.py:460] Project shape: (1, 130, 130, 16)\n",
      "I0129 20:31:39.085669 8057855040 api.py:460] block_2 survival_prob: 0.9826086956521739\n",
      "I0129 20:31:39.085903 8057855040 api.py:460] Block mb_conv_block_2 input shape: (1, 130, 130, 16)\n",
      "I0129 20:31:39.101405 8057855040 api.py:460] Expand shape: (1, 130, 130, 96)\n",
      "I0129 20:31:39.115746 8057855040 api.py:460] DWConv shape: (1, 65, 65, 96)\n",
      "I0129 20:31:39.131546 8057855040 api.py:460] Built SE mb_conv_block_2 : (1, 1, 1, 96)\n",
      "I0129 20:31:39.145426 8057855040 api.py:460] Project shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.146469 8057855040 api.py:460] block_3 survival_prob: 0.9739130434782609\n",
      "I0129 20:31:39.146758 8057855040 api.py:460] Block mb_conv_block_3 input shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.161802 8057855040 api.py:460] Expand shape: (1, 65, 65, 144)\n",
      "I0129 20:31:39.176726 8057855040 api.py:460] DWConv shape: (1, 65, 65, 144)\n",
      "I0129 20:31:39.194557 8057855040 api.py:460] Built SE mb_conv_block_3 : (1, 1, 1, 144)\n",
      "I0129 20:31:39.210598 8057855040 api.py:460] Project shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.211435 8057855040 api.py:460] block_4 survival_prob: 0.9652173913043478\n",
      "I0129 20:31:39.211674 8057855040 api.py:460] Block mb_conv_block_4 input shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.226870 8057855040 api.py:460] Expand shape: (1, 65, 65, 144)\n",
      "I0129 20:31:39.242271 8057855040 api.py:460] DWConv shape: (1, 65, 65, 144)\n",
      "I0129 20:31:39.261635 8057855040 api.py:460] Built SE mb_conv_block_4 : (1, 1, 1, 144)\n",
      "I0129 20:31:39.277702 8057855040 api.py:460] Project shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.278565 8057855040 api.py:460] block_5 survival_prob: 0.9565217391304348\n",
      "I0129 20:31:39.278805 8057855040 api.py:460] Block mb_conv_block_5 input shape: (1, 65, 65, 24)\n",
      "I0129 20:31:39.295344 8057855040 api.py:460] Expand shape: (1, 65, 65, 144)\n",
      "I0129 20:31:39.312618 8057855040 api.py:460] DWConv shape: (1, 33, 33, 144)\n",
      "I0129 20:31:39.330456 8057855040 api.py:460] Built SE mb_conv_block_5 : (1, 1, 1, 144)\n",
      "I0129 20:31:39.348670 8057855040 api.py:460] Project shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.349765 8057855040 api.py:460] block_6 survival_prob: 0.9478260869565217\n",
      "I0129 20:31:39.350027 8057855040 api.py:460] Block mb_conv_block_6 input shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.369010 8057855040 api.py:460] Expand shape: (1, 33, 33, 288)\n",
      "I0129 20:31:39.386479 8057855040 api.py:460] DWConv shape: (1, 33, 33, 288)\n",
      "I0129 20:31:39.408101 8057855040 api.py:460] Built SE mb_conv_block_6 : (1, 1, 1, 288)\n",
      "I0129 20:31:39.427916 8057855040 api.py:460] Project shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.428879 8057855040 api.py:460] block_7 survival_prob: 0.9391304347826087\n",
      "I0129 20:31:39.429157 8057855040 api.py:460] Block mb_conv_block_7 input shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.448658 8057855040 api.py:460] Expand shape: (1, 33, 33, 288)\n",
      "I0129 20:31:39.467925 8057855040 api.py:460] DWConv shape: (1, 33, 33, 288)\n",
      "I0129 20:31:39.489748 8057855040 api.py:460] Built SE mb_conv_block_7 : (1, 1, 1, 288)\n",
      "I0129 20:31:39.510022 8057855040 api.py:460] Project shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.510967 8057855040 api.py:460] block_8 survival_prob: 0.9304347826086956\n",
      "I0129 20:31:39.511219 8057855040 api.py:460] Block mb_conv_block_8 input shape: (1, 33, 33, 48)\n",
      "I0129 20:31:39.531600 8057855040 api.py:460] Expand shape: (1, 33, 33, 288)\n",
      "I0129 20:31:39.552186 8057855040 api.py:460] DWConv shape: (1, 17, 17, 288)\n",
      "I0129 20:31:39.575450 8057855040 api.py:460] Built SE mb_conv_block_8 : (1, 1, 1, 288)\n",
      "I0129 20:31:39.595226 8057855040 api.py:460] Project shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.596331 8057855040 api.py:460] block_9 survival_prob: 0.9217391304347826\n",
      "I0129 20:31:39.596601 8057855040 api.py:460] Block mb_conv_block_9 input shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.617666 8057855040 api.py:460] Expand shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.638865 8057855040 api.py:460] DWConv shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.661437 8057855040 api.py:460] Built SE mb_conv_block_9 : (1, 1, 1, 528)\n",
      "I0129 20:31:39.682674 8057855040 api.py:460] Project shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.683538 8057855040 api.py:460] block_10 survival_prob: 0.9130434782608696\n",
      "I0129 20:31:39.683823 8057855040 api.py:460] Block mb_conv_block_10 input shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.705137 8057855040 api.py:460] Expand shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.728127 8057855040 api.py:460] DWConv shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.753477 8057855040 api.py:460] Built SE mb_conv_block_10 : (1, 1, 1, 528)\n",
      "I0129 20:31:39.776485 8057855040 api.py:460] Project shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.777350 8057855040 api.py:460] block_11 survival_prob: 0.9043478260869565\n",
      "I0129 20:31:39.777584 8057855040 api.py:460] Block mb_conv_block_11 input shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.799116 8057855040 api.py:460] Expand shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.820502 8057855040 api.py:460] DWConv shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.844271 8057855040 api.py:460] Built SE mb_conv_block_11 : (1, 1, 1, 528)\n",
      "I0129 20:31:39.866472 8057855040 api.py:460] Project shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.867295 8057855040 api.py:460] block_12 survival_prob: 0.8956521739130435\n",
      "I0129 20:31:39.867560 8057855040 api.py:460] Block mb_conv_block_12 input shape: (1, 17, 17, 88)\n",
      "I0129 20:31:39.890594 8057855040 api.py:460] Expand shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.912099 8057855040 api.py:460] DWConv shape: (1, 17, 17, 528)\n",
      "I0129 20:31:39.937973 8057855040 api.py:460] Built SE mb_conv_block_12 : (1, 1, 1, 528)\n",
      "I0129 20:31:39.959586 8057855040 api.py:460] Project shape: (1, 17, 17, 120)\n",
      "I0129 20:31:39.960494 8057855040 api.py:460] block_13 survival_prob: 0.8869565217391304\n",
      "I0129 20:31:39.960736 8057855040 api.py:460] Block mb_conv_block_13 input shape: (1, 17, 17, 120)\n",
      "I0129 20:31:39.984661 8057855040 api.py:460] Expand shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.007974 8057855040 api.py:460] DWConv shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.034282 8057855040 api.py:460] Built SE mb_conv_block_13 : (1, 1, 1, 720)\n",
      "I0129 20:31:40.058090 8057855040 api.py:460] Project shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.058971 8057855040 api.py:460] block_14 survival_prob: 0.8782608695652174\n",
      "I0129 20:31:40.059226 8057855040 api.py:460] Block mb_conv_block_14 input shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.083271 8057855040 api.py:460] Expand shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.111194 8057855040 api.py:460] DWConv shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.140143 8057855040 api.py:460] Built SE mb_conv_block_14 : (1, 1, 1, 720)\n",
      "I0129 20:31:40.164932 8057855040 api.py:460] Project shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.165944 8057855040 api.py:460] block_15 survival_prob: 0.8695652173913044\n",
      "I0129 20:31:40.166193 8057855040 api.py:460] Block mb_conv_block_15 input shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.194211 8057855040 api.py:460] Expand shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.221573 8057855040 api.py:460] DWConv shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.251702 8057855040 api.py:460] Built SE mb_conv_block_15 : (1, 1, 1, 720)\n",
      "I0129 20:31:40.279131 8057855040 api.py:460] Project shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.280021 8057855040 api.py:460] block_16 survival_prob: 0.8608695652173913\n",
      "I0129 20:31:40.280269 8057855040 api.py:460] Block mb_conv_block_16 input shape: (1, 17, 17, 120)\n",
      "I0129 20:31:40.308649 8057855040 api.py:460] Expand shape: (1, 17, 17, 720)\n",
      "I0129 20:31:40.335340 8057855040 api.py:460] DWConv shape: (1, 9, 9, 720)\n",
      "I0129 20:31:40.366107 8057855040 api.py:460] Built SE mb_conv_block_16 : (1, 1, 1, 720)\n",
      "I0129 20:31:40.393045 8057855040 api.py:460] Project shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.394217 8057855040 api.py:460] block_17 survival_prob: 0.8521739130434782\n",
      "I0129 20:31:40.394490 8057855040 api.py:460] Block mb_conv_block_17 input shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.425812 8057855040 api.py:460] Expand shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.457593 8057855040 api.py:460] DWConv shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.488373 8057855040 api.py:460] Built SE mb_conv_block_17 : (1, 1, 1, 1248)\n",
      "I0129 20:31:40.518528 8057855040 api.py:460] Project shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.519514 8057855040 api.py:460] block_18 survival_prob: 0.8434782608695652\n",
      "I0129 20:31:40.519766 8057855040 api.py:460] Block mb_conv_block_18 input shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.551334 8057855040 api.py:460] Expand shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.584300 8057855040 api.py:460] DWConv shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.616626 8057855040 api.py:460] Built SE mb_conv_block_18 : (1, 1, 1, 1248)\n",
      "I0129 20:31:40.646410 8057855040 api.py:460] Project shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.647444 8057855040 api.py:460] block_19 survival_prob: 0.8347826086956522\n",
      "I0129 20:31:40.647855 8057855040 api.py:460] Block mb_conv_block_19 input shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.681945 8057855040 api.py:460] Expand shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.714796 8057855040 api.py:460] DWConv shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.747055 8057855040 api.py:460] Built SE mb_conv_block_19 : (1, 1, 1, 1248)\n",
      "I0129 20:31:40.778053 8057855040 api.py:460] Project shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.778991 8057855040 api.py:460] block_20 survival_prob: 0.8260869565217391\n",
      "I0129 20:31:40.779257 8057855040 api.py:460] Block mb_conv_block_20 input shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.811898 8057855040 api.py:460] Expand shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.847413 8057855040 api.py:460] DWConv shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.881493 8057855040 api.py:460] Built SE mb_conv_block_20 : (1, 1, 1, 1248)\n",
      "I0129 20:31:40.912698 8057855040 api.py:460] Project shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.913592 8057855040 api.py:460] block_21 survival_prob: 0.8173913043478261\n",
      "I0129 20:31:40.913832 8057855040 api.py:460] Block mb_conv_block_21 input shape: (1, 9, 9, 208)\n",
      "I0129 20:31:40.947781 8057855040 api.py:460] Expand shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:40.981261 8057855040 api.py:460] DWConv shape: (1, 9, 9, 1248)\n",
      "I0129 20:31:41.014758 8057855040 api.py:460] Built SE mb_conv_block_21 : (1, 1, 1, 1248)\n",
      "I0129 20:31:41.046320 8057855040 api.py:460] Project shape: (1, 9, 9, 352)\n",
      "I0129 20:31:41.047116 8057855040 api.py:460] block_22 survival_prob: 0.808695652173913\n",
      "I0129 20:31:41.047363 8057855040 api.py:460] Block mb_conv_block_22 input shape: (1, 9, 9, 352)\n",
      "I0129 20:31:41.080853 8057855040 api.py:460] Expand shape: (1, 9, 9, 2112)\n",
      "I0129 20:31:41.114602 8057855040 api.py:460] DWConv shape: (1, 9, 9, 2112)\n",
      "I0129 20:31:41.148479 8057855040 api.py:460] Built SE mb_conv_block_22 : (1, 1, 1, 2112)\n",
      "I0129 20:31:41.179135 8057855040 api.py:460] Project shape: (1, 9, 9, 352)\n",
      "2024-01-29 20:31:41.251406: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-29 20:31:41.637048: W tensorflow/c/c_api.cc:305] Operation '{name:'efficientnet-b2/head/dense/bias/Assign' id:4156 op device:{requested: '', assigned: ''} def:{{{node efficientnet-b2/head/dense/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](efficientnet-b2/head/dense/bias, efficientnet-b2/head/dense/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "INFO:tensorflow:Restoring parameters from /Users/arif/Downloads/noisy_student_efficientnet-b2/model.ckpt\n",
      "I0129 20:31:42.151894 8057855040 saver.py:1413] Restoring parameters from /Users/arif/Downloads/noisy_student_efficientnet-b2/model.ckpt\n",
      "WARNING:tensorflow:From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:225: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "W0129 20:31:42.428183 8057855040 deprecation.py:50] From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:225: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0129 20:31:42.429125 8057855040 builder_impl.py:651] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0129 20:31:42.429173 8057855040 builder_impl.py:469] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./FSL Models/test_1/saved_model.pb\n",
      "I0129 20:31:44.715568 8057855040 builder_impl.py:433] SavedModel written to: ./FSL Models/test_1/saved_model.pb\n",
      "Saved model written to ./FSL Models/test_1\n",
      "2024-01-29 20:31:46.050353: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-01-29 20:31:46.051415: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "WARNING:tensorflow:From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/lite/python/util.py:305: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "W0129 20:31:46.769521 8057855040 deprecation.py:50] From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/lite/python/util.py:305: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "W0129 20:31:46.769639 8057855040 deprecation.py:50] From /Users/arif/anaconda3/envs/mnn/lib/python3.9/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "I0129 20:31:47.440681 8057855040 lite.py:2426] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
      "2024-01-29 20:31:47.556834: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-29 20:31:47.556854: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 231, Total Ops 573, % non-converted = 40.31 %\n",
      " * 231 ARITH ops\n",
      "\n",
      "- arith.constant:  231 occurrences  (f32: 230, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 16)\n",
      "  (f32: 92)\n",
      "  (f32: 23)\n",
      "  (f32: 92)\n",
      "  (f32: 24)\n",
      "  (f32: 92)\n",
      "2024-01-29 20:31:47.796222: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 2.813 G  ops, equivalently 1.407 G  MACs\n",
      "tflite model written to ./FSL Models/test_1.tflite\n"
     ]
    }
   ],
   "source": [
    "!python3 /Users/arif/Documents/tpu/models/official/efficientnet/export_model.py --model_name=efficientnet-b2 --ckpt_dir=/Users/arif/Downloads/noisy_student_efficientnet-b2 --output_saved_model_dir=\"./FSL Models/test_1\" --output_tflite=\"./FSL Models/test_1.tflite\" --endpoint_name \"global_pool\" --image_size 260 --batch_size 1 --quantize=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support and query TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /Users/arif/Documents/tpu/models/official/efficientnet/export_model.py --model_name=efficientnet-b2 --ckpt_dir=/Users/arif/Downloads/noisy_student_efficientnet-b2 --output_saved_model_dir=\"./FSL Models/support_20\" --output_tflite=\"./FSL Models/support_20.tflite\" --endpoint_name \"global_pool\" --image_size 260 --batch_size 20 --quantize=False -v 0\n",
    "!python3 /Users/arif/Documents/tpu/models/official/efficientnet/export_model.py --model_name=efficientnet-b2 --ckpt_dir=/Users/arif/Downloads/noisy_student_efficientnet-b2 --output_saved_model_dir=\"./FSL Models/support_20\" --output_tflite=\"./FSL Models/support_20.tflite\" --endpoint_name \"global_pool\" --image_size 260 --batch_size 20 --quantize=False -v 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFlite to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 19:35:25,908 - WARNING - tf2onnx: ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 19:35:25,908 - INFO - tf2onnx: inputs: None\n",
      "2024-01-29 19:35:25,908 - INFO - tf2onnx: outputs: None\n",
      "2024-01-29 19:35:25,909 - INFO - tf2onnx.tfonnx: Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 19:35:25,909 - INFO - tf2onnx.tfonnx: Using opset <onnx, 18>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-01-29 19:35:26,029 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2024-01-29 19:35:26,161 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2024-01-29 19:35:26,316 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 231, 'TFL_CONV_2D': 92, 'TFL_LOGISTIC': 92, 'TFL_MUL': 92, 'TFL_MEAN': 24, 'TFL_DEPTHWISE_CONV_2D': 23, 'TFL_ADD': 16, 'Placeholder': 1, 'Identity': 1})\n",
      "\ttensorflow attr: Counter({'value': 231, 'fused_activation_function': 223, 'dilation_h_factor': 115, 'dilation_w_factor': 115, 'padding': 115, 'stride_h': 115, 'stride_w': 115, 'keep_dims': 24, 'depth_multiplier': 23, 'pot_scale_int16': 16})\n",
      "\tonnx mapped: Counter({'Const': 231, 'Conv2D': 92, 'Sigmoid': 92, 'Mul': 92, 'Mean': 24, 'DepthwiseConv2dNative': 23, 'Add': 16, 'Placeholder': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2024-01-29 19:35:26,316 - INFO - tf2onnx.optimizer: Optimizing ONNX model\n",
      "2024-01-29 19:35:26,317 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 19:35:26,943 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Const +88 (254->342), Reshape +88 (23->111), Transpose -120 (461->341)\n",
      "2024-01-29 19:35:26,943 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 19:35:26,995 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 19:35:26,995 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 19:35:27,333 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -24 (24->0), Const -22 (342->320), Reshape -45 (111->66), Transpose -208 (341->133)\n",
      "2024-01-29 19:35:27,333 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 19:35:27,381 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 19:35:27,381 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 19:35:27,430 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 19:35:27,430 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 19:35:27,499 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -65 (320->255)\n",
      "2024-01-29 19:35:27,499 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 19:35:27,718 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 19:35:27,718 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 19:35:27,755 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 19:35:27,755 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 19:35:27,793 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 19:35:27,793 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 19:35:27,832 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Identity -1 (1->0)\n",
      "2024-01-29 19:35:27,832 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 19:35:28,008 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: Const -7 (255->248), Reshape -20 (66->46), Transpose -106 (133->27)\n",
      "2024-01-29 19:35:28,008 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 19:35:28,040 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 19:35:28,041 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 19:35:28,092 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Const +49 (248->297), Reshape +26 (46->72), Transpose -26 (27->1)\n",
      "2024-01-29 19:35:28,092 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 19:35:28,127 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 19:35:28,127 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 19:35:28,300 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2024-01-29 19:35:28,300 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 19:35:28,334 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 19:35:28,334 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 19:35:28,367 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 19:35:28,367 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 19:35:28,401 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -37 (297->260)\n",
      "2024-01-29 19:35:28,401 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 19:35:28,432 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 19:35:28,432 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 19:35:28,602 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 19:35:28,602 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 19:35:28,631 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 19:35:28,631 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 19:35:28,662 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2024-01-29 19:35:28,662 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 19:35:28,695 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: Const -11 (260->249), Reshape -26 (72->46)\n",
      "2024-01-29 19:35:28,695 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 19:35:28,857 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 19:35:28,857 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 19:35:28,890 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2024-01-29 19:35:28,890 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 19:35:28,919 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 19:35:28,919 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 19:35:28,949 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2024-01-29 19:35:28,949 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 19:35:28,980 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 19:35:28,980 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 19:35:29,144 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 19:35:29,144 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 19:35:29,176 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: no change\n",
      "2024-01-29 19:35:29,176 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 19:35:29,207 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 19:35:29,207 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 19:35:29,238 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 19:35:29,238 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 19:35:29,269 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 19:35:29,269 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 19:35:29,430 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2024-01-29 19:35:29,430 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 19:35:29,460 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2024-01-29 19:35:29,460 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 19:35:29,489 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 19:35:29,493 - INFO - tf2onnx.optimizer: After optimization: Cast -24 (24->0), Const -5 (254->249), Identity -1 (1->0), Reshape +23 (23->46), Transpose -460 (461->1)\n",
      "2024-01-29 19:35:29,535 - INFO - tf2onnx: \n",
      "2024-01-29 19:35:29,535 - INFO - tf2onnx: Successfully converted TensorFlow model ./FSL Models/test_1.tflite to ONNX\n",
      "2024-01-29 19:35:29,535 - INFO - tf2onnx: Model inputs: ['images']\n",
      "2024-01-29 19:35:29,535 - INFO - tf2onnx: Model outputs: ['efficientnet-b2/model/head/dropout/Identity']\n",
      "2024-01-29 19:35:29,535 - INFO - tf2onnx: ONNX model is saved at ./FSL Models/test_1_tflite.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 18 --tflite \"./FSL Models/test_1.tflite\" --output \"./FSL Models/test_1_tflite.onnx\" --inputs-as-nchw images --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 19:02:03,678 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 19:02:03,683 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 19:02:03,684 - INFO - Using opset <onnx, 18>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-01-29 19:02:04,091 - INFO - Optimizing ONNX model\n",
      "2024-01-29 19:02:07,357 - INFO - After optimization: Cast -24 (24->0), Const -5 (254->249), Identity -1 (1->0), Reshape +23 (23->46), Transpose -460 (461->1)\n",
      "2024-01-29 19:02:07,404 - INFO - \n",
      "2024-01-29 19:02:07,404 - INFO - Successfully converted TensorFlow model ./FSL Models/support_20.tflite to ONNX\n",
      "2024-01-29 19:02:07,405 - INFO - Model inputs: ['images']\n",
      "2024-01-29 19:02:07,405 - INFO - Model outputs: ['efficientnet-b2/model/head/dropout/Identity']\n",
      "2024-01-29 19:02:07,405 - INFO - ONNX model is saved at ./FSL Models/support_20_tflite.onnx\n",
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 19:02:10,365 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 19:02:10,366 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 19:02:10,366 - INFO - Using opset <onnx, 18>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-01-29 19:02:10,752 - INFO - Optimizing ONNX model\n",
      "2024-01-29 19:02:13,765 - INFO - After optimization: Cast -24 (24->0), Const -5 (254->249), Identity -1 (1->0), Reshape +22 (23->45), Transpose -460 (461->1)\n",
      "2024-01-29 19:02:13,805 - INFO - \n",
      "2024-01-29 19:02:13,805 - INFO - Successfully converted TensorFlow model ./FSL Models/query_160.tflite to ONNX\n",
      "2024-01-29 19:02:13,805 - INFO - Model inputs: ['images']\n",
      "2024-01-29 19:02:13,805 - INFO - Model outputs: ['efficientnet-b2/model/head/dropout/Identity']\n",
      "2024-01-29 19:02:13,805 - INFO - ONNX model is saved at ./FSL Models/query_160_tflite.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 18 --tflite \"./FSL Models/support_20.tflite\" --output \"./FSL Models/support_20_tflite.onnx\" --inputs-as-nchw images\n",
    "!python3 -m tf2onnx.convert --opset 18 --tflite \"./FSL Models/query_160.tflite\" --output \"./FSL Models/query_160_tflite.onnx\" --inputs-as-nchw images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/bin/python3: Error while finding module specification for 'tf2.inspector' (ModuleNotFoundError: No module named 'tf2')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2.inspector --mode=export --model_name=efficientdet-d5 \\\n",
    "    --model_dir=\"/Users/arif/Downloads/efficientdet-d5\" \\\n",
    "    --image_size=1280 \\\n",
    "    --saved_model_dir=\"/Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf\" \\\n",
    "    --hparams=\"nms_configs.method='hard', nms_configs.iou_thresh=0.5, nms_configs.sigma=0.0, mean_rgb=0.0, stddev_rgb=1.0, scale_range=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "usage: convert.py [-h] [--input INPUT] [--graphdef GRAPHDEF]\n",
      "                  [--saved-model SAVED_MODEL] [--tag TAG]\n",
      "                  [--signature_def SIGNATURE_DEF]\n",
      "                  [--concrete_function CONCRETE_FUNCTION]\n",
      "                  [--checkpoint CHECKPOINT] [--keras KERAS] [--tflite TFLITE]\n",
      "                  [--tfjs TFJS] [--large_model] [--output OUTPUT]\n",
      "                  [--inputs INPUTS] [--outputs OUTPUTS]\n",
      "                  [--ignore_default IGNORE_DEFAULT]\n",
      "                  [--use_default USE_DEFAULT] [--rename-inputs RENAME_INPUTS]\n",
      "                  [--rename-outputs RENAME_OUTPUTS] [--use-graph-names]\n",
      "                  [--opset OPSET] [--dequantize] [--custom-ops CUSTOM_OPS]\n",
      "                  [--extra_opset EXTRA_OPSET]\n",
      "                  [--load_op_libraries LOAD_OP_LIBRARIES]\n",
      "                  [--target {rs4,rs5,rs6,caffe2,tensorrt,nhwc}]\n",
      "                  [--continue_on_error] [--verbose] [--debug]\n",
      "                  [--output_frozen_graph OUTPUT_FROZEN_GRAPH]\n",
      "                  [--inputs-as-nchw INPUTS_AS_NCHW]\n",
      "                  [--outputs-as-nchw OUTPUTS_AS_NCHW]\n",
      "\n",
      "Convert tensorflow graphs to ONNX.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --input INPUT         input from graphdef\n",
      "  --graphdef GRAPHDEF   input from graphdef\n",
      "  --saved-model SAVED_MODEL\n",
      "                        input from saved model\n",
      "  --tag TAG             tag to use for saved_model\n",
      "  --signature_def SIGNATURE_DEF\n",
      "                        signature_def from saved_model to use\n",
      "  --concrete_function CONCRETE_FUNCTION\n",
      "                        For TF2.x saved_model, index of func signature in\n",
      "                        __call__ (--signature_def is ignored)\n",
      "  --checkpoint CHECKPOINT\n",
      "                        input from checkpoint\n",
      "  --keras KERAS         input from keras model\n",
      "  --tflite TFLITE       input from tflite model\n",
      "  --tfjs TFJS           input from tfjs model\n",
      "  --large_model         use the large model format (for models > 2GB)\n",
      "  --output OUTPUT       output model file\n",
      "  --inputs INPUTS       model input_names (optional for saved_model, keras,\n",
      "                        and tflite)\n",
      "  --outputs OUTPUTS     model output_names (optional for saved_model, keras,\n",
      "                        and tflite)\n",
      "  --ignore_default IGNORE_DEFAULT\n",
      "                        comma-separated list of names of\n",
      "                        PlaceholderWithDefault ops to change into Placeholder\n",
      "                        ops\n",
      "  --use_default USE_DEFAULT\n",
      "                        comma-separated list of names of\n",
      "                        PlaceholderWithDefault ops to change into Identity ops\n",
      "                        using their default value\n",
      "  --rename-inputs RENAME_INPUTS\n",
      "                        input names to use in final model (optional)\n",
      "  --rename-outputs RENAME_OUTPUTS\n",
      "                        output names to use in final model (optional)\n",
      "  --use-graph-names     (saved model only) skip renaming io using signature\n",
      "                        names\n",
      "  --opset OPSET         opset version to use for onnx domain\n",
      "  --dequantize          remove quantization from model. Only supported for\n",
      "                        tflite currently.\n",
      "  --custom-ops CUSTOM_OPS\n",
      "                        comma-separated map of custom ops to domains in format\n",
      "                        OpName:domain. Domain 'ai.onnx.converters.tensorflow'\n",
      "                        is used by default.\n",
      "  --extra_opset EXTRA_OPSET\n",
      "                        extra opset with format like domain:version, e.g.\n",
      "                        com.microsoft:1\n",
      "  --load_op_libraries LOAD_OP_LIBRARIES\n",
      "                        comma-separated list of tf op library paths to\n",
      "                        register before loading model\n",
      "  --target {rs4,rs5,rs6,caffe2,tensorrt,nhwc}\n",
      "                        target platform\n",
      "  --continue_on_error   continue_on_error\n",
      "  --verbose, -v         verbose output, option is additive\n",
      "  --debug               debug mode\n",
      "  --output_frozen_graph OUTPUT_FROZEN_GRAPH\n",
      "                        output frozen tf graph to file\n",
      "  --inputs-as-nchw INPUTS_AS_NCHW\n",
      "                        transpose inputs as from nhwc to nchw\n",
      "  --outputs-as-nchw OUTPUTS_AS_NCHW\n",
      "                        transpose outputs as from nhwc to nchw\n",
      "\n",
      "Usage Examples:\n",
      "\n",
      "python -m tf2onnx.convert --saved-model saved_model_dir --output model.onnx\n",
      "python -m tf2onnx.convert --input frozen_graph.pb  --inputs X:0 --outputs output:0 --output model.onnx\n",
      "python -m tf2onnx.convert --checkpoint checkpoint.meta  --inputs X:0 --outputs output:0 --output model.onnx\n",
      "\n",
      "For help and additional information see:\n",
      "    https://github.com/onnx/tensorflow-onnx\n",
      "\n",
      "If you run into issues, open an issue here:\n",
      "    https://github.com/onnx/tensorflow-onnx/issues\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python3 -m tf2onnx.convert --saved-model=\"/Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf\" \\\n",
    "    --output=\"/Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf.onnx\" \\\n",
    "    --opset=18 \\\n",
    "    --inputs-as-nchw images \\\n",
    "    --signature_def serving_default \\\n",
    "    --tag serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-02-19 16:14:18,927 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-02-19 16:14:30,651 - WARNING - Importing a function (__inference_predict_71870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:35,395 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_154075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,275 - WARNING - Importing a function (__inference_blocks_36_layer_call_and_return_conditional_losses_181183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,297 - WARNING - Importing a function (__inference_blocks_16_layer_call_and_return_conditional_losses_175116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,335 - WARNING - Importing a function (__inference_blocks_29_layer_call_and_return_conditional_losses_179058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,371 - WARNING - Importing a function (__inference_blocks_31_layer_call_and_return_conditional_losses_179670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,397 - WARNING - Importing a function (__inference_blocks_33_layer_call_and_return_conditional_losses_180282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,432 - WARNING - Importing a function (__inference_box_net_layer_call_and_return_conditional_losses_169360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,577 - WARNING - Importing a function (__inference_blocks_13_layer_call_and_return_conditional_losses_174300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,607 - WARNING - Importing a function (__inference_class_net_layer_call_and_return_conditional_losses_168259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,747 - WARNING - Importing a function (__inference_blocks_19_layer_call_and_return_conditional_losses_92213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,782 - WARNING - Importing a function (__inference_blocks_15_layer_call_and_return_conditional_losses_98976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,810 - WARNING - Importing a function (__inference_blocks_21_layer_call_and_return_conditional_losses_176730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,831 - WARNING - Importing a function (__inference_blocks_23_layer_call_and_return_conditional_losses_177240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,857 - WARNING - Importing a function (__inference_blocks_20_layer_call_and_return_conditional_losses_92353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,885 - WARNING - Importing a function (__inference_blocks_30_layer_call_and_return_conditional_losses_93906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,917 - WARNING - Importing a function (__inference_blocks_37_layer_call_and_return_conditional_losses_181590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,952 - WARNING - Importing a function (__inference_blocks_9_layer_call_and_return_conditional_losses_172992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:36,987 - WARNING - Importing a function (__inference_blocks_38_layer_call_and_return_conditional_losses_95145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,019 - WARNING - Importing a function (__inference_blocks_11_layer_call_and_return_conditional_losses_173706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,071 - WARNING - Importing a function (__inference_blocks_16_layer_call_and_return_conditional_losses_91742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,104 - WARNING - Importing a function (__inference_blocks_30_layer_call_and_return_conditional_losses_101089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,142 - WARNING - Importing a function (__inference_class_net_layer_call_and_return_conditional_losses_121401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,308 - WARNING - Importing a function (__inference_blocks_7_layer_call_and_return_conditional_losses_90363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,349 - WARNING - Importing a function (__inference_blocks_0_layer_call_and_return_conditional_losses_170445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,373 - WARNING - Importing a function (__inference_blocks_21_layer_call_and_return_conditional_losses_99821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,420 - WARNING - Importing a function (__inference_blocks_5_layer_call_and_return_conditional_losses_97568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,447 - WARNING - Importing a function (__inference_blocks_9_layer_call_and_return_conditional_losses_98131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,473 - WARNING - Importing a function (__inference_stem_layer_call_and_return_conditional_losses_96860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,495 - WARNING - Importing a function (__inference_blocks_33_layer_call_and_return_conditional_losses_94377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,527 - WARNING - Importing a function (__inference_blocks_11_layer_call_and_return_conditional_losses_98413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,553 - WARNING - Importing a function (__inference_blocks_18_layer_call_and_return_conditional_losses_175830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,574 - WARNING - Importing a function (__inference_blocks_18_layer_call_and_return_conditional_losses_99399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,600 - WARNING - Importing a function (__inference_blocks_38_layer_call_and_return_conditional_losses_181794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,630 - WARNING - Importing a function (__inference_blocks_27_layer_call_and_return_conditional_losses_178447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,672 - WARNING - Importing a function (__inference_blocks_18_layer_call_and_return_conditional_losses_175728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,708 - WARNING - Importing a function (__inference_blocks_16_layer_call_and_return_conditional_losses_175218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:37,754 - WARNING - Importing a function (__inference_predict_45988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,665 - WARNING - Importing a function (__inference_blocks_19_layer_call_and_return_conditional_losses_99540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,697 - WARNING - Importing a function (__inference_blocks_22_layer_call_and_return_conditional_losses_92667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,735 - WARNING - Importing a function (__inference_blocks_25_layer_call_and_return_conditional_losses_93138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,768 - WARNING - Importing a function (__inference_blocks_29_layer_call_and_return_conditional_losses_93749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,800 - WARNING - Importing a function (__inference_blocks_37_layer_call_and_return_conditional_losses_181488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,825 - WARNING - Importing a function (__inference_blocks_24_layer_call_and_return_conditional_losses_177648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:39,874 - WARNING - Importing a function (__inference___call___29241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,786 - WARNING - Importing a function (__inference_blocks_17_layer_call_and_return_conditional_losses_99258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,812 - WARNING - Importing a function (__inference_blocks_14_layer_call_and_return_conditional_losses_98835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,839 - WARNING - Importing a function (__inference_blocks_36_layer_call_and_return_conditional_losses_181284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,860 - WARNING - Importing a function (__inference_blocks_36_layer_call_and_return_conditional_losses_94831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,894 - WARNING - Importing a function (__inference_blocks_19_layer_call_and_return_conditional_losses_176034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,919 - WARNING - Importing a function (__inference_blocks_30_layer_call_and_return_conditional_losses_179466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,947 - WARNING - Importing a function (__inference_blocks_24_layer_call_and_return_conditional_losses_92981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:45,982 - WARNING - Importing a function (__inference_blocks_34_layer_call_and_return_conditional_losses_180588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:46,033 - WARNING - Importing a function (__inference_blocks_15_layer_call_and_return_conditional_losses_91585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:46,066 - WARNING - Importing a function (__inference_blocks_34_layer_call_and_return_conditional_losses_94534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:46,116 - WARNING - Importing a function (__inference_fpn_cells_layer_call_and_return_conditional_losses_119599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:46,877 - WARNING - Importing a function (__inference_blocks_7_layer_call_and_return_conditional_losses_97850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:46,905 - WARNING - Importing a function (__inference_box_net_layer_call_and_return_conditional_losses_134271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,067 - WARNING - Importing a function (__inference_blocks_2_layer_call_and_return_conditional_losses_89605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,118 - WARNING - Importing a function (__inference_blocks_11_layer_call_and_return_conditional_losses_173604) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,148 - WARNING - Importing a function (__inference_blocks_20_layer_call_and_return_conditional_losses_176323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,169 - WARNING - Importing a function (__inference_blocks_8_layer_call_and_return_conditional_losses_172687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,190 - WARNING - Importing a function (__inference_blocks_3_layer_call_and_return_conditional_losses_89735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:47,247 - WARNING - Importing a function (__inference_tflite_80296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:48,898 - WARNING - Importing a function (__inference_blocks_28_layer_call_and_return_conditional_losses_100807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:48,933 - WARNING - Importing a function (__inference_blocks_31_layer_call_and_return_conditional_losses_179772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:48,992 - WARNING - Importing a function (__inference_blocks_6_layer_call_and_return_conditional_losses_172194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:49,018 - WARNING - Importing a function (__inference_blocks_27_layer_call_and_return_conditional_losses_93435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:49,068 - WARNING - Importing a function (__inference_class_net_layer_call_and_return_conditional_losses_167572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,204 - WARNING - Importing a function (__inference_blocks_20_layer_call_and_return_conditional_losses_176424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,223 - WARNING - Importing a function (__inference_blocks_17_layer_call_and_return_conditional_losses_175524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,243 - WARNING - Importing a function (__inference_blocks_10_layer_call_and_return_conditional_losses_173298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,283 - WARNING - Importing a function (__inference_blocks_13_layer_call_and_return_conditional_losses_174199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,322 - WARNING - Importing a function (__inference_blocks_22_layer_call_and_return_conditional_losses_177036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,342 - WARNING - Importing a function (__inference_blocks_34_layer_call_and_return_conditional_losses_101653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,384 - WARNING - Importing a function (__inference_blocks_24_layer_call_and_return_conditional_losses_177546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,410 - WARNING - Importing a function (__inference_blocks_1_layer_call_and_return_conditional_losses_97051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,440 - WARNING - Importing a function (__inference_box_net_layer_call_and_return_conditional_losses_122283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,634 - WARNING - Importing a function (__inference_blocks_31_layer_call_and_return_conditional_losses_101230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,671 - WARNING - Importing a function (__inference_blocks_4_layer_call_and_return_conditional_losses_171582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,698 - WARNING - Importing a function (__inference_blocks_30_layer_call_and_return_conditional_losses_179364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,724 - WARNING - Importing a function (__inference_blocks_17_layer_call_and_return_conditional_losses_91899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:53,786 - WARNING - Importing a function (__inference_tflite_37667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,749 - WARNING - Importing a function (__inference_blocks_6_layer_call_and_return_conditional_losses_172092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,774 - WARNING - Importing a function (__inference_blocks_12_layer_call_and_return_conditional_losses_91131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,805 - WARNING - Importing a function (__inference_blocks_2_layer_call_and_return_conditional_losses_170912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,826 - WARNING - Importing a function (__inference_blocks_4_layer_call_and_return_conditional_losses_171480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,856 - WARNING - Importing a function (__inference_blocks_35_layer_call_and_return_conditional_losses_101794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,886 - WARNING - Importing a function (__inference_stem_layer_call_and_return_conditional_losses_89277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,896 - WARNING - Importing a function (__inference_blocks_37_layer_call_and_return_conditional_losses_102075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,921 - WARNING - Importing a function (__inference_blocks_10_layer_call_and_return_conditional_losses_90817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,952 - WARNING - Importing a function (__inference_blocks_7_layer_call_and_return_conditional_losses_172398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:55,992 - WARNING - Importing a function (__inference_blocks_8_layer_call_and_return_conditional_losses_90503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,019 - WARNING - Importing a function (__inference_blocks_22_layer_call_and_return_conditional_losses_99962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,044 - WARNING - Importing a function (__inference_blocks_38_layer_call_and_return_conditional_losses_181896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,065 - WARNING - Importing a function (__inference_blocks_15_layer_call_and_return_conditional_losses_174810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,092 - WARNING - Importing a function (__inference_blocks_35_layer_call_and_return_conditional_losses_94691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,130 - WARNING - Importing a function (__inference_blocks_5_layer_call_and_return_conditional_losses_90049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,162 - WARNING - Importing a function (__inference_blocks_25_layer_call_and_return_conditional_losses_177954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,198 - WARNING - Importing a function (__inference_fpn_cells_layer_call_and_return_conditional_losses_166471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,831 - WARNING - Importing a function (__inference_blocks_1_layer_call_and_return_conditional_losses_89484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,860 - WARNING - Importing a function (__inference_blocks_1_layer_call_and_return_conditional_losses_170754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,879 - WARNING - Importing a function (__inference_blocks_29_layer_call_and_return_conditional_losses_100948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,909 - WARNING - Importing a function (__inference_blocks_34_layer_call_and_return_conditional_losses_180690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,931 - WARNING - Importing a function (__inference_blocks_24_layer_call_and_return_conditional_losses_100244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,964 - WARNING - Importing a function (__inference_blocks_4_layer_call_and_return_conditional_losses_89892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:56,997 - WARNING - Importing a function (__inference_blocks_36_layer_call_and_return_conditional_losses_101934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,024 - WARNING - Importing a function (__inference_blocks_0_layer_call_and_return_conditional_losses_170520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,058 - WARNING - Importing a function (__inference_blocks_32_layer_call_and_return_conditional_losses_180078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,079 - WARNING - Importing a function (__inference_blocks_5_layer_call_and_return_conditional_losses_171786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,110 - WARNING - Importing a function (__inference_blocks_29_layer_call_and_return_conditional_losses_179160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,139 - WARNING - Importing a function (__inference_blocks_9_layer_call_and_return_conditional_losses_173094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,186 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_157847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,904 - WARNING - Importing a function (__inference_blocks_28_layer_call_and_return_conditional_losses_178752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:57,940 - WARNING - Importing a function (__inference_fpn_cells_layer_call_and_return_conditional_losses_163286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,581 - WARNING - Importing a function (__inference_blocks_25_layer_call_and_return_conditional_losses_100385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,608 - WARNING - Importing a function (__inference_blocks_32_layer_call_and_return_conditional_losses_179976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,633 - WARNING - Importing a function (__inference_blocks_10_layer_call_and_return_conditional_losses_173400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,656 - WARNING - Importing a function (__inference_blocks_28_layer_call_and_return_conditional_losses_178854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,678 - WARNING - Importing a function (__inference_blocks_10_layer_call_and_return_conditional_losses_98272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,706 - WARNING - Importing a function (__inference_blocks_26_layer_call_and_return_conditional_losses_100526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,742 - WARNING - Importing a function (__inference_blocks_26_layer_call_and_return_conditional_losses_93295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,783 - WARNING - Importing a function (__inference_blocks_2_layer_call_and_return_conditional_losses_97156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,804 - WARNING - Importing a function (__inference_blocks_26_layer_call_and_return_conditional_losses_178158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,849 - WARNING - Importing a function (__inference_blocks_7_layer_call_and_return_conditional_losses_172500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,874 - WARNING - Importing a function (__inference_blocks_27_layer_call_and_return_conditional_losses_178548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,895 - WARNING - Importing a function (__inference_blocks_12_layer_call_and_return_conditional_losses_174012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,916 - WARNING - Importing a function (__inference_blocks_8_layer_call_and_return_conditional_losses_97990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:14:58,942 - WARNING - Importing a function (__inference_blocks_25_layer_call_and_return_conditional_losses_177852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,085 - WARNING - Importing a function (__inference_blocks_35_layer_call_and_return_conditional_losses_180996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,105 - WARNING - Importing a function (__inference_blocks_23_layer_call_and_return_conditional_losses_177342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,132 - WARNING - Importing a function (__inference_blocks_5_layer_call_and_return_conditional_losses_171888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,154 - WARNING - Importing a function (__inference_blocks_14_layer_call_and_return_conditional_losses_91428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,186 - WARNING - Importing a function (__inference_stem_layer_call_and_return_conditional_losses_170137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,193 - WARNING - Importing a function (__inference_blocks_32_layer_call_and_return_conditional_losses_94220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,223 - WARNING - Importing a function (__inference_blocks_21_layer_call_and_return_conditional_losses_176628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,249 - WARNING - Importing a function (__inference_blocks_32_layer_call_and_return_conditional_losses_101371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,276 - WARNING - Importing a function (__inference_blocks_23_layer_call_and_return_conditional_losses_92824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,315 - WARNING - Importing a function (__inference_blocks_13_layer_call_and_return_conditional_losses_91271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:03,354 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_126890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,205 - WARNING - Importing a function (__inference_blocks_2_layer_call_and_return_conditional_losses_170988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,227 - WARNING - Importing a function (__inference_blocks_20_layer_call_and_return_conditional_losses_99680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,252 - WARNING - Importing a function (__inference_blocks_27_layer_call_and_return_conditional_losses_100666) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,299 - WARNING - Importing a function (__inference_blocks_18_layer_call_and_return_conditional_losses_92056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,330 - WARNING - Importing a function (__inference_blocks_6_layer_call_and_return_conditional_losses_90206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,368 - WARNING - Importing a function (__inference_blocks_12_layer_call_and_return_conditional_losses_173910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,393 - WARNING - Importing a function (__inference_blocks_3_layer_call_and_return_conditional_losses_171175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,440 - WARNING - Importing a function (__inference_blocks_12_layer_call_and_return_conditional_losses_98554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:04,488 - WARNING - Importing a function (__inference_fpn_cells_layer_call_and_return_conditional_losses_131587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,227 - WARNING - Importing a function (__inference_box_net_layer_call_and_return_conditional_losses_170047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,365 - WARNING - Importing a function (__inference_blocks_1_layer_call_and_return_conditional_losses_170678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,387 - WARNING - Importing a function (__inference_blocks_14_layer_call_and_return_conditional_losses_174504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,416 - WARNING - Importing a function (__inference_blocks_16_layer_call_and_return_conditional_losses_99117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,442 - WARNING - Importing a function (__inference_blocks_31_layer_call_and_return_conditional_losses_94063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,484 - WARNING - Importing a function (__inference_blocks_3_layer_call_and_return_conditional_losses_97286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,530 - WARNING - Importing a function (__inference_blocks_19_layer_call_and_return_conditional_losses_176136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,550 - WARNING - Importing a function (__inference_blocks_4_layer_call_and_return_conditional_losses_97427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,576 - WARNING - Importing a function (__inference_blocks_6_layer_call_and_return_conditional_losses_97709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,606 - WARNING - Importing a function (__inference_blocks_33_layer_call_and_return_conditional_losses_101512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:05,658 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_114902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,456 - WARNING - Importing a function (__inference_stem_layer_call_and_return_conditional_losses_170107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,470 - WARNING - Importing a function (__inference_blocks_22_layer_call_and_return_conditional_losses_176934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,495 - WARNING - Importing a function (__inference_blocks_14_layer_call_and_return_conditional_losses_174606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,515 - WARNING - Importing a function (__inference_blocks_17_layer_call_and_return_conditional_losses_175422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,562 - WARNING - Importing a function (__inference_blocks_11_layer_call_and_return_conditional_losses_90974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,593 - WARNING - Importing a function (__inference_blocks_21_layer_call_and_return_conditional_losses_92510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,625 - WARNING - Importing a function (__inference_blocks_9_layer_call_and_return_conditional_losses_90660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:07,656 - WARNING - Importing a function (__inference_blocks_28_layer_call_and_return_conditional_losses_93592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:08,652 - WARNING - Importing a function (__inference_blocks_8_layer_call_and_return_conditional_losses_172788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:08,672 - WARNING - Importing a function (__inference_blocks_26_layer_call_and_return_conditional_losses_178260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:13,221 - WARNING - Importing a function (__inference_blocks_37_layer_call_and_return_conditional_losses_94988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:13,265 - WARNING - Importing a function (__inference_blocks_38_layer_call_and_return_conditional_losses_102216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:13,321 - WARNING - Importing a function (__inference___call___63549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:15,079 - WARNING - Importing a function (__inference_blocks_3_layer_call_and_return_conditional_losses_171276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:15,111 - WARNING - Importing a function (__inference_blocks_15_layer_call_and_return_conditional_losses_174912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:15,131 - WARNING - Importing a function (__inference_blocks_23_layer_call_and_return_conditional_losses_100103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:15,208 - WARNING - Importing a function (__inference_blocks_35_layer_call_and_return_conditional_losses_180894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:15,266 - WARNING - Importing a function (__inference__wrapped_model_89244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:17,060 - WARNING - Importing a function (__inference_blocks_13_layer_call_and_return_conditional_losses_98694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:17,099 - WARNING - Importing a function (__inference_class_net_layer_call_and_return_conditional_losses_133389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:18,753 - WARNING - Importing a function (__inference_blocks_33_layer_call_and_return_conditional_losses_180384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:23,832 - WARNING - Importing a function (__inference_blocks_0_layer_call_and_return_conditional_losses_96946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:23,852 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_102297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:24,189 - WARNING - Importing a function (__inference_blocks_0_layer_call_and_return_conditional_losses_89363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:24,206 - WARNING - Importing a function (__inference_efficientnet-b5_layer_call_and_return_conditional_losses_96828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2024-02-19 16:15:28,436 - INFO - Signatures found in model: [serving_default,tflite,predict].\n",
      "2024-02-19 16:15:28,437 - INFO - Output names: ['output_0', 'output_1', 'output_2', 'output_3']\n",
      "2024-02-19 16:15:48,947 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-02-19 16:15:48,947 - INFO - Using opset <onnx, 17>\n",
      "2024-02-19 16:15:50,572 - INFO - Computed 4 values for constant folding\n",
      "2024-02-19 16:15:51,454 - INFO - folding node using tf type=Sub, name=StatefulPartitionedCall/sub_1\n",
      "2024-02-19 16:15:51,454 - INFO - folding node using tf type=Sub, name=StatefulPartitionedCall/sub_2\n",
      "2024-02-19 16:15:51,455 - INFO - folding node using tf type=Mul, name=StatefulPartitionedCall/truediv_4\n",
      "2024-02-19 16:15:51,455 - INFO - folding node using tf type=Mul, name=StatefulPartitionedCall/truediv_5\n",
      "2024-02-19 16:15:51,480 - INFO - folding node type=Range, name=StatefulPartitionedCall/range\n",
      "2024-02-19 16:15:56,310 - INFO - Optimizing ONNX model\n",
      "2024-02-19 16:16:27,437 - INFO - After optimization: BatchNormalization -121 (217->96), Cast -26 (41->15), Concat -1 (9->8), Const -862 (2010->1148), GlobalAveragePool +39 (0->39), GlobalMaxPool +1 (0->1), Identity -10 (10->0), Mul -2 (381->379), ReduceMax -1 (1->0), ReduceMean -39 (39->0), Reshape -77 (167->90), Shape -1 (6->5), Squeeze -2 (17->15), Transpose -1486 (1505->19), Unsqueeze -7 (26->19)\n",
      "2024-02-19 16:16:27,633 - INFO - \n",
      "2024-02-19 16:16:27,634 - INFO - Successfully converted TensorFlow model /Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf2 to ONNX\n",
      "2024-02-19 16:16:27,634 - INFO - Model inputs: ['images']\n",
      "2024-02-19 16:16:27,634 - INFO - Model outputs: ['output_0', 'output_1', 'output_2', 'output_3']\n",
      "2024-02-19 16:16:27,634 - INFO - ONNX model is saved at ./od_tf3.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --saved-model=\"/Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf\" \\\n",
    "    --output=\"/Users/arif/Documents/Pet_Feeder/Software/AI/cat_feeder_project/od_tf.onnx\" \\\n",
    "    --opset=17 \\\n",
    "    --inputs-as-nchw images \\\n",
    "    --signature_def serving_default \\\n",
    "    --tag serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-02-18 19:48:47,178 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-02-18 19:48:47,184 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-02-18 19:49:38,915 - INFO - Fingerprint not found. Saved model loading will continue.\n",
      "2024-02-18 19:49:38,915 - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2024-02-18 19:49:39,039 - INFO - Signatures found in model: [serving_default].\n",
      "2024-02-18 19:49:39,039 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2024-02-18 19:49:39,042 - INFO - Output names: ['detections:0']\n",
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-02-18 19:49:44,798 - WARNING - Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing moving_average_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-02-18 19:49:44,799 - WARNING - Issue encountered when serializing moving_average_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-02-18 19:49:44,800 - WARNING - Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-02-18 19:49:44,800 - WARNING - Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-02-18 19:50:04,144 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-02-18 19:50:04,144 - INFO - Using opset <onnx, 17>\n",
      "2024-02-18 19:50:05,131 - INFO - Computed 4 values for constant folding\n",
      "2024-02-18 19:50:05,887 - INFO - folding node using tf type=Sub, name=sub_2\n",
      "2024-02-18 19:50:05,888 - INFO - folding node using tf type=Sub, name=sub_3\n",
      "2024-02-18 19:50:05,888 - INFO - folding node using tf type=Mul, name=truediv_4\n",
      "2024-02-18 19:50:05,888 - INFO - folding node using tf type=Mul, name=truediv_5\n",
      "2024-02-18 19:50:05,914 - INFO - folding node type=Range, name=range_1\n",
      "2024-02-18 19:50:08,981 - INFO - Optimizing ONNX model\n",
      "2024-02-18 19:50:43,220 - INFO - After optimization: BatchNormalization -121 (217->96), Cast -26 (40->14), Concat -1 (10->9), Const -887 (2044->1157), GlobalAveragePool +39 (0->39), GlobalMaxPool +1 (0->1), Identity -1 (1->0), Mul -2 (381->379), ReduceMax -1 (1->0), ReduceMean -39 (39->0), ReduceSum -1 (1->0), Reshape -76 (166->90), Shape -1 (6->5), Squeeze -6 (21->15), Transpose -1486 (1504->18), Unsqueeze -12 (32->20)\n",
      "2024-02-18 19:50:43,433 - INFO - \n",
      "2024-02-18 19:50:43,433 - INFO - Successfully converted TensorFlow model /Users/arif/Documents/Pet Feeder/Software/AI/cat_feeder_project/od_tf to ONNX\n",
      "2024-02-18 19:50:43,433 - INFO - Model inputs: ['image_arrays_0']\n",
      "2024-02-18 19:50:43,433 - INFO - Model outputs: ['detections:0']\n",
      "2024-02-18 19:50:43,433 - INFO - ONNX model is saved at od_tf.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 17 --saved-model \"/Users/arif/Documents/Pet Feeder/Software/AI/cat_feeder_project/od_tf\" --output od_tf.onnx --inputs-as-nchw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 20:33:51,395 - WARNING - tf2onnx: ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 20:33:51,396 - WARNING - tf2onnx.tf_loader: '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-01-29 20:33:56,101 - INFO - absl: Fingerprint not found. Saved model loading will continue.\n",
      "2024-01-29 20:33:56,102 - INFO - absl: path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2024-01-29 20:33:56,111 - INFO - tf2onnx.tf_loader: Signatures found in model: [serving_default].\n",
      "2024-01-29 20:33:56,111 - WARNING - tf2onnx.tf_loader: '--signature_def' not specified, using first signature: serving_default\n",
      "2024-01-29 20:33:56,112 - INFO - tf2onnx.tf_loader: Output names: ['output']\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 20:33:56,192 - WARNING - tensorflow: Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 20:33:56,192 - WARNING - tensorflow: Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 20:33:58,990 - INFO - tf2onnx: inputs: ['images:0']\n",
      "2024-01-29 20:33:58,990 - INFO - tf2onnx: outputs: ['efficientnet-b2/model/head/dropout/Identity:0']\n",
      "2024-01-29 20:33:59,100 - INFO - tf2onnx.tfonnx: Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 20:33:59,100 - INFO - tf2onnx.tfonnx: Using opset <onnx, 18>\n",
      "2024-01-29 20:33:59,335 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding\n",
      "2024-01-29 20:33:59,630 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2024-01-29 20:33:59,866 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 461, 'Conv2D': 92, 'Sigmoid': 92, 'Mul': 92, 'FusedBatchNormV3': 69, 'BiasAdd': 46, 'Mean': 24, 'DepthwiseConv2dNative': 23, 'AddV2': 16, 'Identity': 2, 'Placeholder': 1})\n",
      "\ttensorflow attr: Counter({'dtype': 462, 'value': 461, 'data_format': 230, 'dilations': 115, 'padding': 115, 'strides': 115, 'explicit_paddings': 115, 'epsilon': 69, 'exponential_avg_factor': 69, 'is_training': 69, 'Tidx': 24, 'keep_dims': 24, 'shape': 1})\n",
      "\tonnx mapped: Counter({'Const': 461, 'Conv2D': 92, 'Sigmoid': 92, 'Mul': 92, 'FusedBatchNormV3': 69, 'Mean': 24, 'DepthwiseConv2dNative': 23, 'AddV2': 16, 'Placeholder': 1, 'Identity': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2024-01-29 20:33:59,867 - INFO - tf2onnx.optimizer: Optimizing ONNX model\n",
      "2024-01-29 20:33:59,868 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 20:34:00,531 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Const +40 (484->524), Reshape +40 (23->63), Transpose -95 (392->297)\n",
      "2024-01-29 20:34:00,531 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 20:34:00,593 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 20:34:00,593 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 20:34:00,893 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -24 (24->0), Transpose -23 (297->274)\n",
      "2024-01-29 20:34:00,893 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 20:34:00,952 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 20:34:00,953 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 20:34:01,017 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 20:34:01,017 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 20:34:01,274 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -61 (524->463)\n",
      "2024-01-29 20:34:01,275 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 20:34:01,336 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 20:34:01,336 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 20:34:01,398 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 20:34:01,398 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 20:34:01,613 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 20:34:01,613 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 20:34:01,671 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Identity -2 (2->0)\n",
      "2024-01-29 20:34:01,671 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 20:34:01,889 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: BatchNormalization -69 (69->0), Const -212 (463->251), Reshape -18 (63->45), Transpose -244 (274->30)\n",
      "2024-01-29 20:34:01,889 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 20:34:01,919 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 20:34:01,919 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 20:34:01,971 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Const +51 (251->302), Reshape +28 (45->73), Transpose -28 (30->2)\n",
      "2024-01-29 20:34:01,971 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 20:34:02,007 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 20:34:02,007 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 20:34:02,220 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2024-01-29 20:34:02,220 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 20:34:02,257 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 20:34:02,257 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 20:34:02,295 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 20:34:02,295 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 20:34:02,350 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -40 (302->262)\n",
      "2024-01-29 20:34:02,350 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 20:34:02,386 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 20:34:02,386 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 20:34:02,595 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 20:34:02,595 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 20:34:02,631 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 20:34:02,631 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 20:34:02,667 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2024-01-29 20:34:02,667 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 20:34:02,703 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: Const -13 (262->249), Reshape -27 (73->46)\n",
      "2024-01-29 20:34:02,703 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 20:34:02,734 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 20:34:02,735 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2024-01-29 20:34:02,930 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Const +1 (249->250), Reshape +1 (46->47), Transpose -1 (2->1)\n",
      "2024-01-29 20:34:02,930 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2024-01-29 20:34:02,963 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2024-01-29 20:34:02,963 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2024-01-29 20:34:02,997 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2024-01-29 20:34:02,998 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2024-01-29 20:34:03,035 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2024-01-29 20:34:03,035 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2024-01-29 20:34:03,218 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2024-01-29 20:34:03,218 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2024-01-29 20:34:03,252 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: no change\n",
      "2024-01-29 20:34:03,252 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2024-01-29 20:34:03,287 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2024-01-29 20:34:03,287 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2024-01-29 20:34:03,319 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2024-01-29 20:34:03,319 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2024-01-29 20:34:03,352 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2024-01-29 20:34:03,352 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2024-01-29 20:34:03,556 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2024-01-29 20:34:03,557 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2024-01-29 20:34:03,591 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: Const -1 (250->249), Reshape -1 (47->46)\n",
      "2024-01-29 20:34:03,591 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2024-01-29 20:34:03,625 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2024-01-29 20:34:03,631 - INFO - tf2onnx.optimizer: After optimization: BatchNormalization -69 (69->0), Cast -24 (24->0), Const -235 (484->249), Identity -2 (2->0), Reshape +23 (23->46), Transpose -391 (392->1)\n",
      "2024-01-29 20:34:03,673 - INFO - tf2onnx: \n",
      "2024-01-29 20:34:03,673 - INFO - tf2onnx: Successfully converted TensorFlow model ./FSL Models/test_1 to ONNX\n",
      "2024-01-29 20:34:03,673 - INFO - tf2onnx: Model inputs: ['input']\n",
      "2024-01-29 20:34:03,673 - INFO - tf2onnx: Model outputs: ['output']\n",
      "2024-01-29 20:34:03,673 - INFO - tf2onnx: ONNX model is saved at test_1_tf.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 18 --saved-model \"./FSL Models/test_1\" --output test_1_tf.onnx --inputs-as-nchw input --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 18:46:51,843 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 18:46:51,844 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-01-29 18:46:56,438 - INFO - Fingerprint not found. Saved model loading will continue.\n",
      "2024-01-29 18:46:56,439 - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2024-01-29 18:46:56,447 - INFO - Signatures found in model: [serving_default].\n",
      "2024-01-29 18:46:56,447 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2024-01-29 18:46:56,448 - INFO - Output names: ['output']\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:46:56,529 - WARNING - Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:46:56,530 - WARNING - Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:46:59,527 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 18:46:59,527 - INFO - Using opset <onnx, 18>\n",
      "2024-01-29 18:46:59,759 - INFO - Computed 0 values for constant folding\n",
      "2024-01-29 18:47:00,300 - INFO - Optimizing ONNX model\n",
      "2024-01-29 18:47:04,106 - INFO - After optimization: BatchNormalization -69 (69->0), Cast -24 (24->0), Const -235 (484->249), Identity -2 (2->0), Reshape +23 (23->46), Transpose -391 (392->1)\n",
      "2024-01-29 18:47:04,148 - INFO - \n",
      "2024-01-29 18:47:04,148 - INFO - Successfully converted TensorFlow model ./FSL Models/support_20 to ONNX\n",
      "2024-01-29 18:47:04,148 - INFO - Model inputs: ['input']\n",
      "2024-01-29 18:47:04,148 - INFO - Model outputs: ['output']\n",
      "2024-01-29 18:47:04,148 - INFO - ONNX model is saved at support_20_tf.onnx\n",
      "/Users/arif/anaconda3/envs/mnn/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-01-29 18:47:07,200 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2024-01-29 18:47:07,200 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2024-01-29 18:47:11,993 - INFO - Fingerprint not found. Saved model loading will continue.\n",
      "2024-01-29 18:47:11,994 - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2024-01-29 18:47:12,002 - INFO - Signatures found in model: [serving_default].\n",
      "2024-01-29 18:47:12,002 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2024-01-29 18:47:12,003 - INFO - Output names: ['output']\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:47:12,087 - WARNING - Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:47:12,087 - WARNING - Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "This operation is not supported when eager execution is enabled.\n",
      "2024-01-29 18:47:15,263 - INFO - Using tensorflow=2.15.0, onnx=1.15.0, tf2onnx=1.16.1/15c810\n",
      "2024-01-29 18:47:15,263 - INFO - Using opset <onnx, 18>\n",
      "2024-01-29 18:47:15,501 - INFO - Computed 0 values for constant folding\n",
      "2024-01-29 18:47:16,047 - INFO - Optimizing ONNX model\n",
      "2024-01-29 18:47:19,719 - INFO - After optimization: BatchNormalization -69 (69->0), Cast -24 (24->0), Const -235 (484->249), Identity -2 (2->0), Reshape +23 (23->46), Transpose -391 (392->1)\n",
      "2024-01-29 18:47:19,761 - INFO - \n",
      "2024-01-29 18:47:19,761 - INFO - Successfully converted TensorFlow model ./FSL Models/query_160 to ONNX\n",
      "2024-01-29 18:47:19,761 - INFO - Model inputs: ['input']\n",
      "2024-01-29 18:47:19,761 - INFO - Model outputs: ['output']\n",
      "2024-01-29 18:47:19,761 - INFO - ONNX model is saved at query_160_tf.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 18 --saved-model \"./FSL Models/support_20\" --output support_20_tf.onnx --inputs-as-nchw input\n",
    "!python3 -m tf2onnx.convert --opset 18 --saved-model \"./FSL Models/query_160\" --output query_160_tf.onnx --inputs-as-nchw input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
