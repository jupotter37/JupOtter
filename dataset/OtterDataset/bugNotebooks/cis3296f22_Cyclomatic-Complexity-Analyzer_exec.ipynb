{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import features\n",
    "import lizard\n",
    "from git.repo.base import Repo\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import shutil\n",
    "import stat\n",
    "import urllib.request\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "GitCommandError",
     "evalue": "Cmd('git') failed due to: exit code(128)\n  cmdline: git clone -v https://github.com/lucidrains/DALLE2-pytorch C:\\Programming\\College\\software_design\\Cyclomatic-Complexity-Analyzer\\tmp\\lucidrains\\DALLE2-pytorch\n  stderr: 'fatal: destination path 'C:\\Programming\\College\\software_design\\Cyclomatic-Complexity-Analyzer\\tmp\\lucidrains\\DALLE2-pytorch' already exists and is not an empty directory.\n'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGitCommandError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m working_dir \u001B[38;5;241m=\u001B[39m Path(os\u001B[38;5;241m.\u001B[39mgetcwd())\n\u001B[0;32m      5\u001B[0m temp_dir \u001B[38;5;241m=\u001B[39m working_dir \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtmp\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m/\u001B[39m user_name \u001B[38;5;241m/\u001B[39m repo_name\n\u001B[1;32m----> 6\u001B[0m \u001B[43mRepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp_dir\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\Cyclomatic-Complexity-Analyzer-i-SsC1CN\\lib\\site-packages\\git\\repo\\base.py:1275\u001B[0m, in \u001B[0;36mRepo.clone_from\u001B[1;34m(cls, url, to_path, progress, env, multi_options, **kwargs)\u001B[0m\n\u001B[0;32m   1273\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m env \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1274\u001B[0m     git\u001B[38;5;241m.\u001B[39mupdate_environment(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39menv)\n\u001B[1;32m-> 1275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_clone(git, url, to_path, GitCmdObjectDB, progress, multi_options, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.virtualenvs\\Cyclomatic-Complexity-Analyzer-i-SsC1CN\\lib\\site-packages\\git\\repo\\base.py:1194\u001B[0m, in \u001B[0;36mRepo._clone\u001B[1;34m(cls, git, url, path, odb_default_type, progress, multi_options, **kwargs)\u001B[0m\n\u001B[0;32m   1191\u001B[0m     cmdline \u001B[38;5;241m=\u001B[39m remove_password_if_present(cmdline)\n\u001B[0;32m   1193\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCmd(\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms unused stdout: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, cmdline, stdout)\n\u001B[1;32m-> 1194\u001B[0m     \u001B[43mfinalize_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstderr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1196\u001B[0m \u001B[38;5;66;03m# our git command could have a different working dir than our actual\u001B[39;00m\n\u001B[0;32m   1197\u001B[0m \u001B[38;5;66;03m# environment, hence we prepend its working dir if required\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m osp\u001B[38;5;241m.\u001B[39misabs(path):\n",
      "File \u001B[1;32m~\\.virtualenvs\\Cyclomatic-Complexity-Analyzer-i-SsC1CN\\lib\\site-packages\\git\\util.py:419\u001B[0m, in \u001B[0;36mfinalize_process\u001B[1;34m(proc, **kwargs)\u001B[0m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;124;03m\"\"\"Wait for the process (clone, fetch, pull or push) and handle its errors accordingly\"\"\"\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;66;03m# TODO: No close proc-streams??\u001B[39;00m\n\u001B[1;32m--> 419\u001B[0m proc\u001B[38;5;241m.\u001B[39mwait(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.virtualenvs\\Cyclomatic-Complexity-Analyzer-i-SsC1CN\\lib\\site-packages\\git\\cmd.py:559\u001B[0m, in \u001B[0;36mGit.AutoInterrupt.wait\u001B[1;34m(self, stderr)\u001B[0m\n\u001B[0;32m    557\u001B[0m     errstr \u001B[38;5;241m=\u001B[39m read_all_from_possibly_closed_stream(p_stderr)\n\u001B[0;32m    558\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoInterrupt wait stderr: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (errstr,))\n\u001B[1;32m--> 559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GitCommandError(remove_password_if_present(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs), status, errstr)\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status\n",
      "\u001B[1;31mGitCommandError\u001B[0m: Cmd('git') failed due to: exit code(128)\n  cmdline: git clone -v https://github.com/lucidrains/DALLE2-pytorch C:\\Programming\\College\\software_design\\Cyclomatic-Complexity-Analyzer\\tmp\\lucidrains\\DALLE2-pytorch\n  stderr: 'fatal: destination path 'C:\\Programming\\College\\software_design\\Cyclomatic-Complexity-Analyzer\\tmp\\lucidrains\\DALLE2-pytorch' already exists and is not an empty directory.\n'"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/lucidrains/DALLE2-pytorch'\n",
    "\n",
    "[user_name, repo_name] = url.rsplit('/', 2)[1:]\n",
    "working_dir = Path(os.getcwd())\n",
    "temp_dir = working_dir / \"tmp\" / user_name / repo_name\n",
    "Repo.clone_from(url, temp_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def flatten_nested_functions(funcs: list[features.Function]):\n",
    "    i = 0\n",
    "    while i < len(funcs):\n",
    "        func = funcs[i]\n",
    "        for nested_func in func.nested_funcs:\n",
    "            nested_func.name = f\"{func.name}.{nested_func.name}\"\n",
    "            funcs.append(nested_func)\n",
    "        func.nested_funcs.clear()\n",
    "        i += 1\n",
    "\n",
    "file_name_prefix_len = len(str(temp_dir))\n",
    "\n",
    "files = glob.glob(str(temp_dir / \"**\" / \"*.py\"))\n",
    "outp = dict()\n",
    "files_data = []\n",
    "for file in files:\n",
    "    name = file.split('/')[-1][:-3]\n",
    "    if name == '__init__':\n",
    "        continue\n",
    "    lizard_analysis = lizard.analyze_file(file)\n",
    "    extra_analysis: features.SourceFile = features.analyze_file(file)\n",
    "    extra_functions = extra_analysis.functions\n",
    "    flatten_nested_functions(extra_functions)\n",
    "    extra_analysis: dict[tuple[str, int], features.Function] = {(func.name, func.start_line): func for func in extra_functions}\n",
    "    functions = []\n",
    "    for func in lizard_analysis.function_list:\n",
    "        key = (func.name, func.start_line)\n",
    "        extra = extra_analysis[key]\n",
    "        functions.append({\n",
    "            'name': func.name,\n",
    "            'start_line': func.start_line,\n",
    "            'nloc': func.nloc,\n",
    "            'CCN': func.cyclomatic_complexity,\n",
    "            'enclosing_class': extra.enclosing_class,\n",
    "            'max_depth': extra.max_depth,\n",
    "            'branches': extra.branches,\n",
    "            'calls': extra.calls,\n",
    "            'returns': extra.returns,\n",
    "            'raises': extra.raises,\n",
    "            'assertions': extra.assertions,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data=functions, columns=['name', 'start_line', 'nloc', 'CCN', 'enclosing_class', 'max_depth', 'branches', 'calls', 'returns', 'raises', 'assertions'])\n",
    "    pretty_file_name = file[len(str(temp_dir)):]\n",
    "    outp[file[file_name_prefix_len:]] = df\n",
    "    if '\\\\' in pretty_file_name:\n",
    "        [file_dir, file_name] = pretty_file_name.rsplit('\\\\', 1)\n",
    "    else:\n",
    "        [file_dir, file_name] = pretty_file_name.rsplit('/', 1)\n",
    "    files_data.append({\n",
    "        'file_dir': file_dir,\n",
    "        'file_name': file_name,\n",
    "        'nloc': lizard_analysis.nloc,\n",
    "        'CCN': lizard_analysis.CCN,\n",
    "        'func_token': lizard_analysis.token_count,\n",
    "    })\n",
    "files_df = pd.DataFrame(data=files_data, columns=['file_dir', 'file_name', 'nloc', 'CCN', 'func_token'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\dalle2_pytorch\\cli.py:\n",
      "      name  start_line  nloc  CCN enclosing_class  max_depth  branches  calls  \\\n",
      "0  safeget           9     2    2            None          0         0      2   \n",
      "\n",
      "   returns  raises  assertions  \n",
      "0        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\dalle2_pytorch.py:\n",
      "                          name  start_line  nloc  CCN    enclosing_class  \\\n",
      "138                   __init__        1840   168   29               Unet   \n",
      "145                   __init__        2459   154   27            Decoder   \n",
      "141                    forward        2150   124   27               Unet   \n",
      "155         p_sample_loop_ddim        2891    76   18            Decoder   \n",
      "158                     sample        3108    72   16            Decoder   \n",
      "..                         ...         ...   ...  ...                ...   \n",
      "48                       clear         331     4    2  OpenAIClipAdapter   \n",
      "58                       clear         402     4    2    OpenClipAdapter   \n",
      "85             p2_reweigh_loss         665     4    2     NoiseScheduler   \n",
      "17   set_module_requires_grad_         141     3    2               None   \n",
      "12              is_float_dtype         103     2    2               None   \n",
      "\n",
      "     max_depth  branches  calls  returns  raises  assertions  \n",
      "138          2        22    101        0       0           1  \n",
      "145          2        19     81        0       1          13  \n",
      "141          2        19     77        1       0           5  \n",
      "155          3        16     39        1       0           0  \n",
      "158          3         9     30        1       0           7  \n",
      "..         ...       ...    ...      ...     ...         ...  \n",
      "48           1         1      1        1       0           0  \n",
      "58           1         1      1        1       0           0  \n",
      "85           1         1      1        2       0           0  \n",
      "17           1         1      1        0       0           0  \n",
      "12           0         0      1        1       0           0  \n",
      "\n",
      "[70 rows x 11 columns]\n",
      "\n",
      "\\dalle2_pytorch\\optimizer.py:\n",
      "                               name  start_line  nloc  CCN enclosing_class  \\\n",
      "1                     get_optimizer          10    21    4            None   \n",
      "0  separate_weight_decayable_params           3     6    3            None   \n",
      "\n",
      "   max_depth  branches  calls  returns  raises  assertions  \n",
      "1          1         3      5        2       0           0  \n",
      "0          2         2      1        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\tokenizer.py:\n",
      "                name  start_line  nloc  CCN  enclosing_class  max_depth  \\\n",
      "6                bpe          75    37   11  SimpleTokenizer          3   \n",
      "8             decode         124     8    8  SimpleTokenizer          1   \n",
      "5           __init__          53    19    6  SimpleTokenizer          1   \n",
      "9           tokenize         134    13    6  SimpleTokenizer          3   \n",
      "13          tokenize         176    13    5    YttmTokenizer          3   \n",
      "1   bytes_to_unicode          22    11    4             None          2   \n",
      "7             encode         116     7    4  SimpleTokenizer          1   \n",
      "2          get_pairs          34     7    2             None          1   \n",
      "11            decode         166     4    2    YttmTokenizer          1   \n",
      "\n",
      "    branches  calls  returns  raises  assertions  \n",
      "6         12     14        3       0           0  \n",
      "8          4      6        1       0           0  \n",
      "5          1     23        0       0           0  \n",
      "9          5      8        1       1           0  \n",
      "13         5      8        1       1           0  \n",
      "1          2     18        1       0           0  \n",
      "7          1      9        1       0           0  \n",
      "2          1      2        1       0           0  \n",
      "11         1      4        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\trackers.py:\n",
      "                 name  start_line  nloc  CCN   enclosing_class  max_depth  \\\n",
      "61               save         559    26   12           Tracker          3   \n",
      "60   _save_state_dict         517    38    9           Tracker          3   \n",
      "51               init         446    23    7           Tracker          2   \n",
      "35           __init__         276    18    5         BaseSaver          0   \n",
      "49  _load_auto_resume         414    17    5           Tracker          2   \n",
      "15               init         110    20    4       WandbLogger          2   \n",
      "48           __init__         402    11    4           Tracker          3   \n",
      "58        save_config         501     8    4           Tracker          2   \n",
      "45               init         360    12    3  HuggingfaceSaver          2   \n",
      "32               init         245     9    3       WandbLoader          1   \n",
      "21      create_logger         168     8    3              None          1   \n",
      "34      create_loader         266     8    3              None          1   \n",
      "47       create_saver         391     8    3              None          1   \n",
      "29               init         227     3    3       LocalLoader          1   \n",
      "62         can_recall         590     2    3           Tracker          0   \n",
      "42               init         332    10    2        WandbSaver          1   \n",
      "40          save_file         317     7    2        LocalSaver          1   \n",
      "17         log_images         138     6    2       WandbLogger          0   \n",
      "63             recall         594     5    2           Tracker          1   \n",
      "16                log         133     4    2       WandbLogger          1   \n",
      "18           log_file         145     4    2       WandbLogger          1   \n",
      "19          log_error         151     4    2       WandbLogger          1   \n",
      "39               init         311     4    2        LocalSaver          1   \n",
      "55                log         486     4    2           Tracker          1   \n",
      "56         log_images         491     4    2           Tracker          1   \n",
      "57           log_file         496     4    2           Tracker          1   \n",
      "\n",
      "    branches  calls  returns  raises  assertions  \n",
      "61        10     11        2       0           0  \n",
      "60         9     12        1       1           1  \n",
      "51         6     11        1       0           2  \n",
      "35         0      1        0       0           2  \n",
      "49         4      9        3       1           0  \n",
      "15         3      5        0       0           3  \n",
      "48         3      4        0       0           1  \n",
      "58         3      4        1       0           0  \n",
      "45         3     10        0       1           0  \n",
      "32         1      1        0       0           3  \n",
      "21         3      3        1       2           0  \n",
      "34         3      3        1       2           0  \n",
      "47         3      3        1       2           0  \n",
      "29         1      2        0       1           0  \n",
      "62         0      0        1       0           0  \n",
      "42         3      4        0       0           1  \n",
      "40         1      6        0       0           0  \n",
      "17         0      3        0       0           0  \n",
      "63         2      2        1       1           0  \n",
      "16         1      2        0       0           0  \n",
      "18         1      4        0       0           0  \n",
      "19         1      2        0       0           0  \n",
      "39         1      3        0       0           0  \n",
      "55         1      1        1       0           0  \n",
      "56         1      1        1       0           0  \n",
      "57         1      1        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\trainer.py:\n",
      "                               name  start_line  nloc  CCN  \\\n",
      "28                         __init__         434    77   12   \n",
      "9           cast_torch_tensor.inner          76    27   12   \n",
      "19                             load         295    24    9   \n",
      "17                         __init__         174    55    8   \n",
      "32                  load_state_dict         589    22    8   \n",
      "40                          forward         709    29    6   \n",
      "31                             save         560    21    6   \n",
      "14            split_args_and_kwargs         138    18    5   \n",
      "20                           update         350    12    5   \n",
      "26   decoder_sample_in_chunks.inner         419    10    5   \n",
      "18                             save         266    22    4   \n",
      "36                           update         642    17    4   \n",
      "37                           sample         670    17    4   \n",
      "12                            split         120     8    4   \n",
      "25                          forward         395    15    3   \n",
      "13                       find_first         132     5    3   \n",
      "15     prior_sample_in_chunks.inner         165     5    3   \n",
      "29  validate_and_return_unet_number         549     5    3   \n",
      "1                           default          33     4    3   \n",
      "4                 group_dict_by_key          45     7    2   \n",
      "8                     num_to_groups          64     7    2   \n",
      "11                   split_iterable         113     6    2   \n",
      "21                    p_sample_loop         372     3    2   \n",
      "22                           sample         379     3    2   \n",
      "23                sample_batch_size         384     3    2   \n",
      "2                        cast_tuple          38     2    2   \n",
      "34                            unets         633     2    2   \n",
      "\n",
      "          enclosing_class  max_depth  branches  calls  returns  raises  \\\n",
      "28         DecoderTrainer          3        15     42        0       0   \n",
      "9                    None          3         5     19        1       0   \n",
      "19  DiffusionPriorTrainer          3         8     19        1       0   \n",
      "17  DiffusionPriorTrainer          1         6     23        0       0   \n",
      "32         DecoderTrainer          2         7     17        1       0   \n",
      "40         DecoderTrainer          2         8      8        2       0   \n",
      "31         DecoderTrainer          2         4     17        0       0   \n",
      "14                   None          1         2     19        1       0   \n",
      "20  DiffusionPriorTrainer          2         4      9        0       0   \n",
      "26                   None          1         3      8        2       0   \n",
      "18  DiffusionPriorTrainer          2         2     14        0       0   \n",
      "36         DecoderTrainer          1         3     13        0       0   \n",
      "37         DecoderTrainer          1         2      9        2       0   \n",
      "12                   None          1         3      5        4       0   \n",
      "25  DiffusionPriorTrainer          2         2      5        1       0   \n",
      "13                   None          2         2      1        2       0   \n",
      "15                   None          1         1      5        2       0   \n",
      "29         DecoderTrainer          1         1      2        1       0   \n",
      "1                    None          1         2      3        2       0   \n",
      "4                    None          1         1      6        1       0   \n",
      "8                    None          1         1      1        1       0   \n",
      "11                   None          1         1      4        1       0   \n",
      "21  DiffusionPriorTrainer          1         1      1        1       0   \n",
      "22  DiffusionPriorTrainer          1         1      1        1       0   \n",
      "23  DiffusionPriorTrainer          1         1      1        1       0   \n",
      "2                    None          1         1      1        1       0   \n",
      "34         DecoderTrainer          0         0      1        1       0   \n",
      "\n",
      "    assertions  \n",
      "28           3  \n",
      "9            0  \n",
      "19           2  \n",
      "17           2  \n",
      "32           1  \n",
      "40           0  \n",
      "31           1  \n",
      "14           1  \n",
      "20           0  \n",
      "26           0  \n",
      "18           1  \n",
      "36           0  \n",
      "37           0  \n",
      "12           0  \n",
      "25           0  \n",
      "13           0  \n",
      "15           0  \n",
      "29           1  \n",
      "1            0  \n",
      "4            0  \n",
      "8            0  \n",
      "11           0  \n",
      "21           0  \n",
      "22           0  \n",
      "23           0  \n",
      "2            0  \n",
      "34           0  \n",
      "\n",
      "\\dalle2_pytorch\\train_configs.py:\n",
      "                               name  start_line  nloc  CCN  \\\n",
      "16             check_has_embeddings         352    18   10   \n",
      "7                            create         119    13    5   \n",
      "6                            create          95    12    4   \n",
      "13  img_preproc._get_transformation         296     7    4   \n",
      "11                           create         257     9    3   \n",
      "14                      img_preproc         295     7    3   \n",
      "9                            create         176     9    2   \n",
      "2                      validate_all          42     5    2   \n",
      "4                            create          69     5    2   \n",
      "12                check_image_sizes         271     4    2   \n",
      "1                           default          27     2    2   \n",
      "\n",
      "         enclosing_class  max_depth  branches  calls  returns  raises  \\\n",
      "16    TrainDecoderConfig          2         6     10        2       0   \n",
      "7          AdapterConfig          1         5      9        4       1   \n",
      "6          TrackerConfig          2         4     11        1       0   \n",
      "13                  None          1         3      3        3       0   \n",
      "11         DecoderConfig          1         1      7        1       0   \n",
      "14     DecoderDataConfig          2         2      5        1       0   \n",
      "9   DiffusionPriorConfig          1         1      7        1       0   \n",
      "2       TrainSplitConfig          1         1      3        1       1   \n",
      "4      TrackerLoadConfig          1         1      2        2       0   \n",
      "12         DecoderConfig          1         1      4        1       1   \n",
      "1                   None          1         1      1        1       0   \n",
      "\n",
      "    assertions  \n",
      "16           4  \n",
      "7            0  \n",
      "6            0  \n",
      "13           0  \n",
      "11           0  \n",
      "14           0  \n",
      "9            0  \n",
      "2            0  \n",
      "4            0  \n",
      "12           0  \n",
      "1            0  \n",
      "\n",
      "\\dalle2_pytorch\\utils.py:\n",
      "                    name  start_line  nloc  CCN enclosing_class  max_depth  \\\n",
      "5  import_or_print_error          29     7    3            None          2   \n",
      "\n",
      "   branches  calls  returns  raises  assertions  \n",
      "5         3      4        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\vqgan_vae.py:\n",
      "                 name  start_line  nloc  CCN         enclosing_class  \\\n",
      "64            forward         677    50   11                VQGanVAE   \n",
      "55           __init__         546    67    9                VQGanVAE   \n",
      "28           __init__         223    46    8            ResnetEncDec   \n",
      "27            forward         200    15    3  ContinuousPositionBias   \n",
      "4    remove_vgg.inner          43     9    3                    None   \n",
      "24           __init__         152    22    2           Discriminator   \n",
      "43           __init__         433    17    2             Transformer   \n",
      "26           __init__         189     8    2  ContinuousPositionBias   \n",
      "58      copy_for_eval         640     8    2                VQGanVAE   \n",
      "7   group_dict_by_key          63     7    2                    None   \n",
      "63             decode         667     6    2                VQGanVAE   \n",
      "44            forward         452     5    2             Transformer   \n",
      "25            forward         178     4    2           Discriminator   \n",
      "31             encode         292     4    2            ResnetEncDec   \n",
      "32             decode         297     4    2            ResnetEncDec   \n",
      "1             default          27     2    2                    None   \n",
      "\n",
      "    max_depth  branches  calls  returns  raises  assertions  \n",
      "64          2         8     21        7       0           4  \n",
      "55          1        10     14        1       1           0  \n",
      "28          2         6     37        0       0           4  \n",
      "27          1         2     16        1       0           0  \n",
      "4           1         2      3        1       0           0  \n",
      "24          1         1     16        0       0           0  \n",
      "43          1         1      9        0       0           0  \n",
      "26          1         1     15        0       0           0  \n",
      "58          1         1      6        1       0           0  \n",
      "7           1         1      6        1       0           0  \n",
      "63          1         1      2        2       0           0  \n",
      "44          1         1      3        1       0           0  \n",
      "25          1         1      2        1       0           0  \n",
      "31          1         1      1        1       0           0  \n",
      "32          1         1      1        1       0           0  \n",
      "1           1         1      1        1       0           0  \n",
      "\n",
      "\\dalle2_pytorch\\vqgan_vae_trainer.py:\n",
      "          name  start_line  nloc  CCN  enclosing_class  max_depth  branches  \\\n",
      "10  train_step         171    58    7  VQGanVAETrainer          2         6   \n",
      "9     __init__          85    64    4  VQGanVAETrainer          1         4   \n",
      "6     __init__          53    18    4     ImageDataset          0         0   \n",
      "2        cycle          32     4    3             None          2         2   \n",
      "11       train         271     6    2  VQGanVAETrainer          1         1   \n",
      "5    accum_log          44     5    2             None          1         1   \n",
      "3   cast_tuple          37     2    2             None          1         1   \n",
      "\n",
      "    calls  returns  raises  assertions  \n",
      "10     56        1       0           0  \n",
      "9      34        0       0           1  \n",
      "6      11        0       0           0  \n",
      "2       0        1       0           0  \n",
      "11      5        0       0           0  \n",
      "5       2        1       0           0  \n",
      "3       1        1       0           0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (file, funcs) in outp.items():\n",
    "    funcs = funcs[funcs.CCN > 1]\n",
    "    if not funcs.empty:\n",
    "        print(f\"{file}:\\n{funcs.sort_values(by=['CCN', 'nloc'], ascending=[False, False])}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           file_dir             file_name  nloc  CCN  func_token\n",
      "0   \\dalle2_pytorch                cli.py    40    6         326\n",
      "1   \\dalle2_pytorch     dalle2_pytorch.py  2284  479       19142\n",
      "2   \\dalle2_pytorch          optimizer.py    28    7         189\n",
      "3   \\dalle2_pytorch          tokenizer.py   152   53        1370\n",
      "4   \\dalle2_pytorch           trackers.py   479  131        3436\n",
      "5   \\dalle2_pytorch            trainer.py   511  137        4235\n",
      "6   \\dalle2_pytorch      train_configs.py   306   45        1928\n",
      "7   \\dalle2_pytorch              utils.py    21    8         119\n",
      "8   \\dalle2_pytorch            version.py     1    0           3\n",
      "9   \\dalle2_pytorch          vqgan_vae.py   557  105        4312\n",
      "10  \\dalle2_pytorch  vqgan_vae_trainer.py   189   29        1425\n",
      "11  \\dalle2_pytorch           __init__.py     6    0          46\n"
     ]
    }
   ],
   "source": [
    "print(files_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def remove_readonly(f, path, _):\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    f(path)\n",
    "\n",
    "shutil.rmtree(working_dir / \"tmp\", onerror=remove_readonly)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
