{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7VhCe9mNLd8",
        "outputId": "571f6821-79fb-4507-8f24-ba9246fd4511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (1.34.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\win 11\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "import openai\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import subprocess\n",
        "import os\n",
        "import pathlib\n",
        "import textwrap\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "# from  google.colab import drive\n",
        "# from google.colab import userdata\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F_12EUZNMaB",
        "outputId": "c41f9721-183f-4c1f-e7b0-f1f415481acb"
      },
      "outputs": [],
      "source": [
        "#if using colab\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "fPHXHopBNW4r"
      },
      "outputs": [],
      "source": [
        "with open('D:/LLM_GPT/APPCAIR/expDetails.json','r') as openfile:\n",
        "  expDetails = json.load(openfile)\n",
        "\n",
        "EXP_NAME = expDetails['ExpName']\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "GOOGLE_API_KEY=expDetails['GeminiAPIKEY']\n",
        "#CLAUDE_API_KEY= expDetails['ClaudeAPIKEY']\n",
        "GPT_API_KEY = expDetails['GPTAPIKEY']\n",
        "os.environ['OPENAI_API_KEY'] = GPT_API_KEY\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "Gmodel = genai.GenerativeModel(expDetails['GeminiModel'])\n",
        "\n",
        "GPTModel = expDetails['GPTModel']\n",
        "openai.api_key = GPT_API_KEY\n",
        "client = OpenAI()\n",
        "\n",
        "RunCount = expDetails['RunCount']\n",
        "RunCount = str(RunCount)\n",
        "\n",
        "json_object = json.dumps(expDetails,indent = 4)\n",
        "with open('D:/LLM_GPT/APPCAIR/expDetails.json','w') as openfile:\n",
        "  openfile.write(json_object)\n",
        "\n",
        "def fileReader(pathToFile):\n",
        "  f = open(pathToFile,'r')\n",
        "  s = f.read()\n",
        "  f.close()\n",
        "  return s\n",
        "\n",
        "idea = fileReader(expDetails['ideaFilePath'])\n",
        "context = fileReader(expDetails['contextFilePath'])\n",
        "libraries = fileReader(expDetails['librariesPath'])\n",
        "methodology =fileReader(expDetails['methodology'])\n",
        "miscellaneous=fileReader(expDetails['miscellenous'])\n",
        "idea = methodology+\"\\n\\n\"+ idea\n",
        "Dataset = fileReader(expDetails['datasetLoadingCode'])\n",
        "custom_dataset=expDetails['dataset']\n",
        "packages=fileReader(expDetails['packages'])\n",
        "model_methodology=fileReader(expDetails['model_methodology'])\n",
        "model_refined_methodology=fileReader(expDetails['model_refined_methodology'])\n",
        "model_refined_methodology=model_methodology+model_refined_methodology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E07Pna2EOjzH",
        "outputId": "0c92255d-9ae0-43cc-fb62-00de888afc08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!pip install -q numerapi umap-learn pandas pyarrow matplotlib lightgbm scikit-learn cloudpickle scipy==1.10.1 tabpfn'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6iCCNwjO0y1",
        "outputId": "5b24933e-1ecc-4c62-ad76-9dd8f8194c82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['pip', 'install', '-q', 'numerapi', 'umap-learn', 'pandas', 'pyarrow', 'matplotlib', 'lightgbm', 'scikit-learn', 'cloudpickle', 'scipy==1.10.1', 'tabpfn'], returncode=1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "packages = packages.replace('!', '')\n",
        "subprocess.run(packages.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vDc_3OGvO1q-"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(custom_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dj246Hw5O2pt"
      },
      "outputs": [],
      "source": [
        "SampleModelCode = fileReader(expDetails['sampleModelCode'])\n",
        "Model = fileReader(expDetails['Model'])\n",
        "filepath = expDetails['basecode_path']\n",
        "with open(filepath, 'r') as f:\n",
        "  Sample_code=f.read()\n",
        "  Sample_code = Sample_code.strip()\n",
        "# Remove single quotes if they are at the beginning and end of the string\n",
        "  if Sample_code.startswith(\"'\") and Sample_code.endswith(\"'\"):\n",
        "    Sample_code = Sample_code[1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "exec(Sample_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tBBW8MaerDd1"
      },
      "outputs": [],
      "source": [
        "with open('D:/LLM_GPT/APPCAIR/Docs/inputs/prompts/high_level_idea.txt','r') as f:\n",
        "  Model_Idea = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gICfcczoPlrG",
        "outputId": "344d9db2-64cc-462e-f750-6f46b49014bf"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "          {\n",
        "                \"role\":\"system\",\n",
        "                \"content\":f\"You are a Machine Learning engineer. Your task is to Replace the existing models used in the given Python code using the {model_refined_methodology}\\n\\n\"\n",
        "            },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Replace only the models used in \\n\\n {Sample_code} \\n\\nwith \\n\\n{Model} whose sample usage is given in \\n\\n {SampleModelCode}\\n\\n.Generate the entire code again.Data already loaded in 'train' variable\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Code=completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Your task is to generate Python code  for :{model_refined_methodology}. Avoid assumptions and be creative in applying various ML techniques tailored to {Model_Idea}.Sample usage is given in:{SampleModelCode}.Don't blinldy copy paste the sample cod,use it for referebce only. Provide a comprehensive and detailed implementation without using placeholders or assumptions.Build up on \\n\\n{Code} \\n\\n\"\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "Code2=completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0V2FU7KpZLa",
        "outputId": "7821c065-fc00-4d34-88f5-14308202978a"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "          {\n",
        "                \"role\":\"system\",\n",
        "                \"content\":f\"You are a Machine Learning engineer at an organization.\"\n",
        "            },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Your job is to make changes in the  code \\n\\n{Code2}\\n\\n.Your task is to  change the Python code as per \\n\\n{Model_Idea}\\n\\n such that it's consistent with {model_refined_methodology}.Don't change the strcuture of code at all.Just make the code compatible with the {Model_Idea} \\n\\n\"\n",
        "        },\n",
        "        {\n",
        "             \"role\": \"user\",\n",
        "            \"content\": f\"Don't assume anything and you are allowed to be creative by using different ML techniques to fit the :{Model_Idea}.Data already loaded in 'train' variable.NO BREVITY,PLACEHOLDES,ASSUMPTON.Give FULL IMPLEMENTATION\"\n",
        "        }\n",
        "        \n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "Interimcode=completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHI3AobBP-b-",
        "outputId": "260f8123-4c55-49e0-a041-d54b84d6d178"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "with open('completion[0].txt', 'w') as f:\n",
        "    f.write(Interimcode)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Message content has been saved to 'completion[0].txt' file.\")\n",
        "\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Message content has been saved to 'completion[0].txt' file.\")\n",
        "\n",
        "# Read the content of the text file\n",
        "with open('completion[0].txt', 'r') as file:\n",
        "    text_content = file.read()\n",
        "\n",
        "# Extract Python code blocks using regular expressions\n",
        "python_code_blocks = re.findall(r'```python\\s*([\\s\\S]+?)\\s*```', text_content)\n",
        "\n",
        "# Remove pip installs from Python code blocks\n",
        "python_code_blocks_cleaned = []\n",
        "for code_block in python_code_blocks:\n",
        "    cleaned_block = re.sub(r'^!pip install .*\\n', '', code_block, flags=re.MULTILINE)\n",
        "    python_code_blocks_cleaned.append(cleaned_block)\n",
        "\n",
        "# Write the cleaned Python code blocks to a new file\n",
        "with open('extracted_final_code_cleaned.py', 'w') as file:\n",
        "    for code_block in python_code_blocks_cleaned:\n",
        "        file.write(code_block + '\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "9C08Q6JCW2IM"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "import re\n",
        "def debug_error(error_message, code):\n",
        "    # Define the prompt with the error message\n",
        "    prompt = f\"Error message: {error_message}\\n\\nDebugging suggestions:\"\n",
        "\n",
        "    # Generate suggestions using GPT\n",
        "    completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    #system=\"You are a data scientist.I have encountered an error.Please fix the error in a logical way and dont assume anything.Regenerate the entire code again.If you need any clarifications ask.Output the entire code again after error rectification\"\"\",\n",
        "    messages=[       {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a data scientist.I have encountered an error.Please fix the error in a logical way and don't assume anything.Regenerate the entire code again.Output the entire rectified code again after error rectification\",\n",
        "            },\n",
        "        {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"[Error]:{prompt}\\n\\n [code]:{code}.Please fix the error.Don't comment out anything.Generate the complete code\"\n",
        "            },\n",
        "                     {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"[Context]:{context}\\n\\n [Idea]:{model_refined_methodology} [libraries]:{libraries}\\n\\n\"\n",
        "            }\n",
        "                     ]\n",
        "\n",
        ")\n",
        "    # Extract and return the debugging suggestions\n",
        "    suggestions = completion.choices[0].message.content\n",
        "    print(\"Debugging suggestions:\")\n",
        "    print(suggestions)\n",
        "    python_code_match = re.search(r'```python(.+?)```', suggestions, re.DOTALL)\n",
        "    python_code = python_code_match.group(1) if python_code_match else \"\"\n",
        "\n",
        "    return python_code\n",
        "\n",
        "\n",
        "\n",
        "with open('extracted_final_code_cleaned.py', 'r') as f:\n",
        "  python_code = f.read()\n",
        "# Extract Python code from the provided message (example)\n",
        "  python_code_blocks = re.findall(r'```python(.+?)```', python_code)\n",
        "  \n",
        "\n",
        "\n",
        "    # Prepare the code for execution\n",
        "  code = \"\"\"{}\n",
        "         \"\"\".format(python_code_blocks)\n",
        "\n",
        "  error_message = \"\"\n",
        "  while True:\n",
        "      try:\n",
        "        # Execute the code\n",
        "        print(code)\n",
        "        exec(code)\n",
        "        # If execution is successful, break the loop\n",
        "        print(\"Code executed successfully. No errors.\")\n",
        "        base_folder = expDetails['FolderName'].lstrip('/').replace('/', '\\\\')\n",
        "        expname = expDetails['ExpName'] + RunCount\n",
        "        filepath = os.path.join(base_folder, expname, 'Iterative.py')\n",
        "        # Ensure the directory exists\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "        with open(filepath, 'w') as f:  # Changed 'r' to 'w' for writing\n",
        "          f.write(code)\n",
        "        print(f\"Successfully wrote to {filepath}\")\n",
        "        expDetails['final'] = filepath\n",
        "        with open('D:\\LLM_GPT\\APPCAIR\\expDetails.json', 'w') as json_file:\n",
        "          json.dump(expDetails, json_file, indent=2)\n",
        "\n",
        "        break\n",
        "\n",
        "      except (ValueError, Exception) as e:\n",
        "            # Extract the error message\n",
        "        error_message = str(e) + \"\\n\" + traceback.format_exc()\n",
        "        print(\"Error message:\", error_message)\n",
        "\n",
        "            # Debug the error message\n",
        "        corrected_code = debug_error(error_message, code)\n",
        "        print(error_message)\n",
        "\n",
        "        if corrected_code:\n",
        "          code = corrected_code\n",
        "        else:\n",
        "          print(\"Error correction failed. Exiting.\")\n",
        "          break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJFLphKoXUbM"
      },
      "source": [
        "HUMAN INTERFERENCE\n",
        "For instances of where manual feedback was required.\n",
        "For example in the case of Conpred if the model was not ensembling or datascaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gMDlEOxyXuZF"
      },
      "outputs": [],
      "source": [
        "base_folder = expDetails['FolderName'].lstrip('/').replace('/', '\\\\')\n",
        "expname = expDetails['ExpName'] + RunCount\n",
        "filepath = os.path.join(base_folder, expname, 'Iterative.py')\n",
        "with open(filepath, 'r') as f:\n",
        "  final = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E2PRgFoX_JM"
      },
      "outputs": [],
      "source": [
        "Prompt=\"\"\"\n",
        "Ensemble the models used in the code and do weighted average\n",
        "\"\"\"\n",
        "##this prompt can be changed as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F-C_lSgXT51",
        "outputId": "bac05ebf-225b-41ab-8f86-7dc31a38b80a"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=[\n",
        "          {\n",
        "                \"role\":\"system\",\n",
        "                \"content\":f\"You are a Machine Learning engineer. Your task is do as per the prompt \\n\\n\"\n",
        "            },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Do:\\n{Prompt} for {python_code}.Do not modify any segment any other segments of code.Generate the entire code again.Don't miss out on anything\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "expDetails['RunCount']=expDetails['RunCount']+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
