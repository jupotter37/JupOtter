{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnamikaMangore/anamika-ka-project/blob/main/POV_Alexa_Rule_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cc_kAYiKHdh0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc_kAYiKHdh0",
        "outputId": "fcfaa399-3876-47d0-9e96-583c94f4a6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.1/990.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install stanza sacrebleu evaluate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xR2_FhGaaFL",
        "outputId": "8881ec22-b271-44b2-f209-1dcf41517fc7"
      },
      "id": "5xR2_FhGaaFL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.15.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.11.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.4\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.3.3\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.6.2\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.4\n",
            "colorama                         0.4.6\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     42.0.8\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.4\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.10\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "datasets                         2.20.0\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "dill                             0.3.8\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.4\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.409\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "emoji                            2.12.1\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "evaluate                         0.4.2\n",
            "exceptiongroup                   1.2.1\n",
            "fastai                           2.7.15\n",
            "fastcore                         1.5.48\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.14.0\n",
            "fonttools                        4.53.0\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.6.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.32.1\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.4\n",
            "google-api-core                  2.16.2\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.0\n",
            "google-cloud-aiplatform          1.57.0\n",
            "google-cloud-bigquery            3.21.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.15.0\n",
            "google-cloud-language            2.13.3\n",
            "google-cloud-pubsub              2.21.5\n",
            "google-cloud-resource-manager    1.12.3\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.5.4\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.1\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.52\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.23.4\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.0.0\n",
            "importlib_resources              6.4.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.4\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.0.4\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpickle                       3.2.2\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.14\n",
            "kagglehub                        0.2.5\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.4.0\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2023.1067\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.6\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multiprocess                     0.70.16\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.58.1\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.25.2\n",
            "nvidia-cublas-cu12               12.1.3.1\n",
            "nvidia-cuda-cupti-cu12           12.1.105\n",
            "nvidia-cuda-nvrtc-cu12           12.1.105\n",
            "nvidia-cuda-runtime-cu12         12.1.105\n",
            "nvidia-cudnn-cu12                8.9.2.26\n",
            "nvidia-cufft-cu12                11.0.2.54\n",
            "nvidia-curand-cu12               10.3.2.106\n",
            "nvidia-cusolver-cu12             11.4.5.107\n",
            "nvidia-cusparse-cu12             12.1.0.106\n",
            "nvidia-nccl-cu12                 2.20.5\n",
            "nvidia-nvjitlink-cu12            12.5.82\n",
            "nvidia-nvtx-cu12                 12.1.105\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        24.1\n",
            "pandas                           2.0.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     2.0.3.230814\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.3.8\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.5\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portalocker                      2.10.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          16.1.0\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.0\n",
            "pydantic_core                    2.20.0\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.2.4\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.1.0\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2023.4\n",
            "pyviz_comms                      3.0.2\n",
            "PyWavelets                       1.6.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.32.3\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rpds-py                          0.18.1\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "sacrebleu                        2.4.2\n",
            "safetensors                      0.4.3\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.5\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.4\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.7.5\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.8\n",
            "sphinxcontrib-devhelp            1.0.6\n",
            "sphinxcontrib-htmlhelp           2.0.5\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.7\n",
            "sphinxcontrib-serializinghtml    1.1.10\n",
            "SQLAlchemy                       2.0.31\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.0\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.0\n",
            "stanza                           1.8.2\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.12.1\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.4.2\n",
            "tensorboard                      2.15.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.0\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.23.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.15.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.6.18\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.0+cu121\n",
            "torchaudio                       2.3.0+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.0+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.4\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.41.2\n",
            "triton                           2.3.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.12.3\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 70.3.0.20240710\n",
            "typing_extensions                4.12.2\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.6.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.43.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.0.3\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.40\n",
            "zict                             3.0.0\n",
            "zipp                             3.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7JEDsfia9zHt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JEDsfia9zHt",
        "outputId": "e7075c15-3463-4f7a-926a-8061c050c78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 11 16:40:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "## Check for cuda\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WSLrL5t5F6qV",
      "metadata": {
        "id": "WSLrL5t5F6qV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "b5d61953-5bf7-4832-fd28-738bd77949e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be863d9c-c5b8-4ccc-b5cf-c43107773354",
      "metadata": {
        "id": "be863d9c-c5b8-4ccc-b5cf-c43107773354"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import spacy\n",
        "import stanza\n",
        "import evaluate\n",
        "from spacy import displacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# set options\n",
        "pd.set_option('max_colwidth', None) # show full text\n",
        "random.seed(42)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "path=\"/content/drive/MyDrive/alexa-point-of-view-dataset-main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb6a791-077b-4d22-ab76-bf7851196c29",
      "metadata": {
        "id": "0cb6a791-077b-4d22-ab76-bf7851196c29"
      },
      "outputs": [],
      "source": [
        "## Data\n",
        "train = pd.read_csv(f\"/content/drive/MyDrive/alexa-point-of-view-dataset-main/data/train.tsv\", sep=\"\\t\", dtype={\"input\": str, \"output\": str})\n",
        "test = pd.read_csv(f\"/content/drive/MyDrive/alexa-point-of-view-dataset-main/data/test.tsv\", sep=\"\\t\", dtype={\"input\": str, \"output\": str})\n",
        "dev = pd.read_csv(f\"/content/drive/MyDrive/alexa-point-of-view-dataset-main/data/dev.tsv\", sep=\"\\t\", dtype={\"input\": str, \"output\": str})\n",
        "total = pd.read_csv(f\"/content/drive/MyDrive/alexa-point-of-view-dataset-main/data/total.tsv\", sep=\"\\t\", dtype={\"input\": str, \"output\": str})\n",
        "print(\"Train\", train.shape)\n",
        "print(\"Test\", test.shape)\n",
        "print(\"Dev\", dev.shape)\n",
        "print(\"Total\", total.shape)\n",
        "\n",
        "## Preprocess\n",
        "train.input = train.input.str.replace(\"@CN@\",\"Bob\")\n",
        "train.output = train.output.str.replace(\"@CN@\",\"Bob\")\n",
        "train.output = train.output.str.replace(\"@SCN@\", \"John\")\n",
        "\n",
        "train.reset_index(drop=False, inplace=True)\n",
        "train.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yjnyNYWdF06O",
      "metadata": {
        "id": "yjnyNYWdF06O"
      },
      "outputs": [],
      "source": [
        "# Accessing the new index column\n",
        "first_index_value = train.at[5, 'index']\n",
        "\n",
        "# print(first_index_value)\n",
        "print(train.input[first_index_value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rSRE3YBzGDaW",
      "metadata": {
        "id": "rSRE3YBzGDaW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mi7MGhp5IMHa",
      "metadata": {
        "id": "mi7MGhp5IMHa"
      },
      "outputs": [],
      "source": [
        "train= train[0:7000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20ca14a-eb7e-45bc-817b-bbdb7aec1919",
      "metadata": {
        "id": "e20ca14a-eb7e-45bc-817b-bbdb7aec1919"
      },
      "source": [
        "### Classifying questions using rules\n",
        "\n",
        "There are 4 message types invovled here:\n",
        "\n",
        "- AskWH messages: includes wh-words such as who, what, when, where\n",
        "- AskYN messages: includes phrases such as ask if, ask whether or questions starting with are, is, can\n",
        "- Req messages: includes phrases like tell to, ask to, remind to, etc.\n",
        "- Statement messages: includes tell that, message that, remind that"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b54347-793b-49a0-a9f6-f591a5572774",
      "metadata": {
        "id": "b8b54347-793b-49a0-a9f6-f591a5572774"
      },
      "source": [
        "### Lets check if by checking of these above words we can cover all the question types in the data or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3e12ad-bdcf-4bf0-b5dc-1536a9209c7a",
      "metadata": {
        "id": "6c3e12ad-bdcf-4bf0-b5dc-1536a9209c7a"
      },
      "outputs": [],
      "source": [
        "ask_wh = [\"who\", \"what\", \"when\", \"where\"]\n",
        "ask_yn = [\"ask if\", \"ask whether\"]\n",
        "ask_yn_starts_with = (\"is\", \"are\", \"can\", \"could\", \"will\")\n",
        "ask_req = [\"tell.*to\", \"ask.*to\", \"remind.*to\", \"ask.*for\"]\n",
        "statements = [\"tell.*that\", \"message.*that\", \"remind.*that\", \"know.*that\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fafae638-9c4f-4fd7-acdb-246fd7bcff33",
      "metadata": {
        "id": "fafae638-9c4f-4fd7-acdb-246fd7bcff33"
      },
      "source": [
        "### Ask WH Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9625bac-87fd-43bd-847e-d2eb6873d270",
      "metadata": {
        "id": "d9625bac-87fd-43bd-847e-d2eb6873d270"
      },
      "outputs": [],
      "source": [
        "## Identify WH questions\n",
        "##print('|'.join(ask_wh))\n",
        "train_ask_wh_questions = train[train.input.str.contains('|'.join(ask_wh), regex=True)]\n",
        "print(\"Ask WH Questions\", train_ask_wh_questions.shape[0])\n",
        "train_ask_wh_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e4bf88-ada1-4312-bb65-94c31ac0cce0",
      "metadata": {
        "id": "a4e4bf88-ada1-4312-bb65-94c31ac0cce0"
      },
      "source": [
        "### Ask YN Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6e2cdf-961a-48fc-a08d-1a7e287decb0",
      "metadata": {
        "id": "fd6e2cdf-961a-48fc-a08d-1a7e287decb0"
      },
      "outputs": [],
      "source": [
        "## Identify YN questions\n",
        "train_ask_yn_questions_1 = train[train.input.str.contains('|'.join(ask_yn), regex=True)]\n",
        "train_ask_yn_questions_2 = train[train.input.str.startswith(ask_yn_starts_with)]\n",
        "train_ask_yn_questions = pd.concat([train_ask_yn_questions_1, train_ask_yn_questions_2])\n",
        "print(\"Ask YN Questions\", train_ask_yn_questions.shape[0])\n",
        "train_ask_yn_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c097ad06-aca0-4f8c-af71-a3b906aca87c",
      "metadata": {
        "id": "c097ad06-aca0-4f8c-af71-a3b906aca87c"
      },
      "source": [
        "### Ask Req Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f40a7c-f203-4fba-8a80-c858583b822c",
      "metadata": {
        "id": "07f40a7c-f203-4fba-8a80-c858583b822c"
      },
      "outputs": [],
      "source": [
        "## Identify Req questions\n",
        "train_ask_req_questions = train[train.input.str.contains('|'.join(ask_req), regex=True)]\n",
        "print(\"Ask Req Questions\", train_ask_req_questions.shape[0])\n",
        "train_ask_req_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "895af54c-c869-40b1-b520-e91acc2a1a6d",
      "metadata": {
        "id": "895af54c-c869-40b1-b520-e91acc2a1a6d"
      },
      "source": [
        "### Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f550877c-3cab-4e56-9c67-5b6ae9d09924",
      "metadata": {
        "id": "f550877c-3cab-4e56-9c67-5b6ae9d09924"
      },
      "outputs": [],
      "source": [
        "## Identify Statements\n",
        "train_ask_stmt_questions = train[train.input.str.contains('|'.join(statements), regex=True)]\n",
        "print(\"Ask Statement Questions\", train_ask_stmt_questions.shape[0])\n",
        "train_ask_stmt_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334377fc-bcd2-4cf0-87bd-2f08de0ec0c3",
      "metadata": {
        "id": "334377fc-bcd2-4cf0-87bd-2f08de0ec0c3"
      },
      "source": [
        "### Check if we have any common question in these categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abae512-7b3c-447d-a3d8-3cb0e106a131",
      "metadata": {
        "id": "8abae512-7b3c-447d-a3d8-3cb0e106a131"
      },
      "outputs": [],
      "source": [
        "train_ask_wh_questions.index.intersection(train_ask_yn_questions.index).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4deba588-104c-4314-adb7-4632be706204",
      "metadata": {
        "id": "4deba588-104c-4314-adb7-4632be706204"
      },
      "outputs": [],
      "source": [
        "train_ask_req_questions.index.intersection(train_ask_wh_questions.index).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffcc8610-aef0-4706-be92-aa858944342f",
      "metadata": {
        "id": "ffcc8610-aef0-4706-be92-aa858944342f"
      },
      "outputs": [],
      "source": [
        "train_ask_req_questions.index.intersection(train_ask_yn_questions.index).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ehr-oz6gzHtI",
      "metadata": {
        "id": "Ehr-oz6gzHtI"
      },
      "outputs": [],
      "source": [
        "train_ask_stmt_questions.index.intersection(train_ask_yn_questions.index).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jk8dlmiQzMsn",
      "metadata": {
        "id": "Jk8dlmiQzMsn"
      },
      "outputs": [],
      "source": [
        "train_ask_stmt_questions.index.intersection(train_ask_req_questions.index).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zx_gCA9UzPqv",
      "metadata": {
        "id": "zx_gCA9UzPqv"
      },
      "outputs": [],
      "source": [
        "train_ask_stmt_questions.index.intersection(train_ask_wh_questions.index).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc55c8e3-3744-4359-af0a-c5002340b0cd",
      "metadata": {
        "id": "cc55c8e3-3744-4359-af0a-c5002340b0cd"
      },
      "source": [
        "As we can observe there are many common question in Ask WH and Req messages, the paper uses TFIDF and a custom list of stop words to reduce these number of common questions, but for now I will ignore them and perform processing for each one of them individually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a274db-e049-446d-a19e-fb4303ea999f",
      "metadata": {
        "id": "72a274db-e049-446d-a19e-fb4303ea999f"
      },
      "outputs": [],
      "source": [
        "train[\"ask_wh\"] = train.input.str.contains('|'.join(ask_wh), regex=True)\n",
        "train[\"ask_yn\"] = train.input.str.contains('|'.join(ask_yn), regex=True) | train.input.str.startswith(ask_yn_starts_with)\n",
        "train[\"ask_req\"] = train.input.str.contains('|'.join(ask_req), regex=True)\n",
        "train[\"stmt\"] = train.input.str.contains('|'.join(statements), regex=True)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d055cb-fd2a-45de-9c34-24b459e60473",
      "metadata": {
        "id": "62d055cb-fd2a-45de-9c34-24b459e60473"
      },
      "source": [
        "### Total how many of these question from the total were we able to classify?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c71f0e6e-5d1b-4d12-a5c9-a6de439ba916",
      "metadata": {
        "id": "c71f0e6e-5d1b-4d12-a5c9-a6de439ba916"
      },
      "outputs": [],
      "source": [
        "len(train_ask_wh_questions) + len(train_ask_yn_questions) + len(train_ask_req_questions) + len(train_ask_stmt_questions), len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ec5c97-8f90-4856-ae97-7b656c4bdd8a",
      "metadata": {
        "id": "e2ec5c97-8f90-4856-ae97-7b656c4bdd8a"
      },
      "source": [
        "### POS Tagging\n",
        "\n",
        "The POS tagging will help identify direct questions from indirect ones, the indriect question come with the label SQ tagging. The sentence level tags (S, S', SQ) are crucial in determining whether the word order between the subject and the auxillary is reversed. The word level tags (VB, VBP, VBZ0 indicate which verb needs to be changed as part of POV conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b962a57-c88c-4a76-bfbf-632a022783bc",
      "metadata": {
        "id": "5b962a57-c88c-4a76-bfbf-632a022783bc"
      },
      "outputs": [],
      "source": [
        "## NLTK POS Tagging\n",
        "random_sentence = random.choice(train[\"input\"].values)\n",
        "\n",
        "words = nltk.word_tokenize(random_sentence)\n",
        "\n",
        "tagging = nltk.pos_tag(words)\n",
        "print(tagging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd550ba0-3e19-421b-af7d-ab2d31d00350",
      "metadata": {
        "id": "cd550ba0-3e19-421b-af7d-ab2d31d00350"
      },
      "outputs": [],
      "source": [
        "## Standford nlp\n",
        "stanford_nlp = stanza.Pipeline('en')\n",
        "stanford_doc = stanford_nlp(random_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tHYVgLrBJEgH",
      "metadata": {
        "id": "tHYVgLrBJEgH"
      },
      "outputs": [],
      "source": [
        "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in stanford_doc.sentences for word in sent.words], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9811c55f-6b75-406d-ad85-cfd8e3e0d29d",
      "metadata": {
        "id": "9811c55f-6b75-406d-ad85-cfd8e3e0d29d"
      },
      "outputs": [],
      "source": [
        "## Spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# doc = nlp(random_sentence)\n",
        "doc = nlp(\"ask Bob, when are you coming for dinner\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)\n",
        "displacy.render(doc, style = \"dep\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac2806f-763d-4cec-bf18-1dcdb97bc43a",
      "metadata": {
        "id": "1ac2806f-763d-4cec-bf18-1dcdb97bc43a"
      },
      "source": [
        "### Constituent Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JDaikvT7O7Xb",
      "metadata": {
        "id": "JDaikvT7O7Xb"
      },
      "source": [
        "| POS Tag | Info |\n",
        "\n",
        "| S | Simple Declarative Clause |\n",
        "\n",
        "| SBAR (S') | Clause introduced by subordinating conjunction |\n",
        "\n",
        "| SQ | Inverted yes/no question |\n",
        "\n",
        "| VB | verb, base form |\n",
        "\n",
        "| VBP | verb, non-3rd person singular present |\n",
        "\n",
        "| VBZ | verb, third person singular present |\n",
        "\n",
        "| VP | verb phrase |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e3e513-3efc-4a75-b535-6bc6fa1291cb",
      "metadata": {
        "id": "41e3e513-3efc-4a75-b535-6bc6fa1291cb"
      },
      "outputs": [],
      "source": [
        "## Constituency parsing\n",
        "import stanza\n",
        "\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
        "# random_sentence = random.choice(train[\"input\"].values)\n",
        "random_sentence = \"ask Bob, when are you coming for dinner\"\n",
        "doc = nlp(random_sentence)\n",
        "for sentence in doc.sentences:\n",
        "    print(sentence.constituency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca458f4f-168f-4676-9adc-4d1e9908dfd4",
      "metadata": {
        "id": "ca458f4f-168f-4676-9adc-4d1e9908dfd4"
      },
      "outputs": [],
      "source": [
        "## Constituency tree - Direct example\n",
        "tree = doc.sentences[0].constituency\n",
        "tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "giCBjfC1N3Di",
      "metadata": {
        "id": "giCBjfC1N3Di"
      },
      "outputs": [],
      "source": [
        "## Constituency tree - Indirect example\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
        "doc_2 = nlp(\"ask Bob, when he is coming for dinner\")\n",
        "tree_2 = doc_2.sentences[0].constituency\n",
        "print(\"Tree:\")\n",
        "tree_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MXnl3kKuNfop",
      "metadata": {
        "id": "MXnl3kKuNfop"
      },
      "outputs": [],
      "source": [
        "## Check if it's a direct or indirect question\n",
        "\"SQ\" in str(tree_2), \"SQ\" in str(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aiE6LIaFOk0p",
      "metadata": {
        "id": "aiE6LIaFOk0p"
      },
      "outputs": [],
      "source": [
        "## Run over all examples to classify direct and indirect questions\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', verbose=False, use_gpu=True)\n",
        "def check_direct(text):\n",
        "  doc = nlp(text)\n",
        "  tree = doc.sentences[0].constituency\n",
        "  return \"SQ\" in str(tree)\n",
        "\n",
        "train[\"is_direct\"] = train.input.apply(lambda x: check_direct(str(x)))\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oiJDbtbyPF8y",
      "metadata": {
        "id": "oiJDbtbyPF8y"
      },
      "outputs": [],
      "source": [
        "input_values = train.input.values[:7000]\n",
        "train[\"is_direct\"] = [check_direct(str(x)) for x in input_values]\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hCO6Bq13dX-l",
      "metadata": {
        "id": "hCO6Bq13dX-l"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7xp-OTL0Dgle",
      "metadata": {
        "id": "7xp-OTL0Dgle"
      },
      "outputs": [],
      "source": [
        "# import stanza\n",
        "# nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', verbose=False, use_gpu=True)\n",
        "# out_docs = nlp.bulk_process(train.input.values) # Call the neural pipeline on this list of documents\n",
        "# print(out_docs[1]) # The output is also a list of stanza.Document objects, each output corresponding to an input Document object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lg2co-mCQJEF",
      "metadata": {
        "id": "Lg2co-mCQJEF"
      },
      "outputs": [],
      "source": [
        "train.is_direct.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yvdnz6yjNxOT",
      "metadata": {
        "id": "yvdnz6yjNxOT"
      },
      "outputs": [],
      "source": [
        "train.to_csv(f\"{path}/train_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PtRAJtB_62EI",
      "metadata": {
        "id": "PtRAJtB_62EI"
      },
      "outputs": [],
      "source": [
        "train_processed = pd.read_csv(f\"{path}/train_processed.csv\")\n",
        "print(train_processed.shape)\n",
        "train_processed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZMr0MjbZSv7I",
      "metadata": {
        "id": "ZMr0MjbZSv7I"
      },
      "source": [
        "### Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gzau3oEWsK1F",
      "metadata": {
        "id": "Gzau3oEWsK1F"
      },
      "source": [
        "1. `Changing word order`:\n",
        "\n",
        "This step only applies to direct questions in AskYN and AskWH messages. During this process, multiple types of grammatical changes may apply, including do-deletion, and subject-auxiliary reversal (are you → you are).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U7UFpAOYQPjA",
      "metadata": {
        "id": "U7UFpAOYQPjA"
      },
      "outputs": [],
      "source": [
        "## Reverse the subject-auxillary order\n",
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text message\n",
        "random_direct_yn_row = train_processed.iloc[927]\n",
        "\n",
        "print(\"Original Message:\", random_direct_yn_row.input)\n",
        "print(\"Expected response:\", random_direct_yn_row.output)\n",
        "\n",
        "def change_word_order(sentence):\n",
        "  # Tokenize the text\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  # Process each sentence\n",
        "  for sentence in doc.sents:\n",
        "      subject = None\n",
        "      verb = None\n",
        "      verb_form = None\n",
        "\n",
        "      # Identify the subject and verb\n",
        "      for token in sentence:\n",
        "          if (\"subj\" in token.dep_) or (\"nsubj\" in token.dep_):\n",
        "              subject = token\n",
        "          if (\"aux\" in token.dep_) and (token.text.lower() in [\"is\", \"are\"]):\n",
        "              verb = token\n",
        "              verb_form = token.text.lower()\n",
        "          if not verb and (\"ccomp\" in token.dep_):\n",
        "              verb = token\n",
        "              verb_form = token.text.lower()\n",
        "\n",
        "      # Check for subject-verb disagreement and reorder if needed\n",
        "      if subject and verb and (verb_form in [\"is\", \"are\"]):\n",
        "          # Swap the subject and verb\n",
        "          new_sentence = f\"hey Bob, {subject} {verb} {sentence[max(subject.i, verb.i) + 1:]}\"\n",
        "          transformed_sentence = new_sentence\n",
        "      else:\n",
        "          # No correction needed\n",
        "          transformed_sentence = sentence.text\n",
        "  return transformed_sentence\n",
        "\n",
        "transformed_sentence = change_word_order(random_direct_yn_row.input)\n",
        "print(\"Transformed sentence:\", transformed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSMes3yBlxnQ",
      "metadata": {
        "id": "JSMes3yBlxnQ"
      },
      "outputs": [],
      "source": [
        "direct_yn_ids = [24, 25, 5043, 3258, 1801, 2452]\n",
        "for sent in train_processed.loc[direct_yn_ids].itertuples():\n",
        "  print(\"Org:\",sent.input)\n",
        "  print(\"Exp:\", sent.output)\n",
        "  print(\"Transformed:\", change_word_order(sent.input))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hts6H2GCshEq",
      "metadata": {
        "id": "hts6H2GCshEq"
      },
      "source": [
        "2. `Swapping pronouns/contact names`:\n",
        "\n",
        "We use rules to convert a first person (I) to a third person (he/she) and a third person (he/she) to a second person (you). In cases where the contact name resides inside the message content, the rules would find it and switch it with a second person pronoun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jyw-oHj_smsh",
      "metadata": {
        "id": "Jyw-oHj_smsh"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text message\n",
        "random_wh_row = train_processed.iloc[2497]\n",
        "\n",
        "print(\"Original Message:\", random_wh_row.input)\n",
        "print(\"Expected response:\", random_wh_row.output)\n",
        "\n",
        "def swap_pronouns(sentence):\n",
        "  # Tokenize the text\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  # Define a set of pronouns to consider\n",
        "  first_person_pronouns = {\"I\": \"he\", \"me\": \"him\", \"my\": \"his\"}\n",
        "  third_person_pronouns = {\"he\": \"you\", \"she\": \"you\", \"him\": \"you\", \"his\": \"your\", \"hers\": \"you\"}\n",
        "\n",
        "  # Apply rules to modify pronouns\n",
        "  modified_text = []\n",
        "  for token in doc:\n",
        "      if token.text in first_person_pronouns:\n",
        "          modified_text.append(first_person_pronouns[token.text])\n",
        "      elif token.text in third_person_pronouns:\n",
        "          modified_text.append(third_person_pronouns[token.text])\n",
        "      else:\n",
        "          modified_text.append(token.text)\n",
        "\n",
        "  # Generate the modified text\n",
        "  modified_text_message = \" \".join(modified_text)\n",
        "  return modified_text_message\n",
        "\n",
        "transformed_sentence = swap_pronouns(change_word_order(random_wh_row.input))\n",
        "print(\"Transformed sentence:\", transformed_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P1nh4KoxsnGz",
      "metadata": {
        "id": "P1nh4KoxsnGz"
      },
      "source": [
        "3. `Fixing verb agreement`:\n",
        "\n",
        "This step is to make sure the main verb/auxiliary agrees with the converted subject pronoun in person and number. In sentences with present tense, if we switch the subject she to you, we must change the main verb to its base form (is → are, wants → want, VBZ → VBP) as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AHVqChXms6bn",
      "metadata": {
        "id": "AHVqChXms6bn"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text message\n",
        "text_message = \"can you ask if she wants icecream ?\"\n",
        "\n",
        "def fix_verb_agreement(sentence):\n",
        "  # Tokenize the text\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "\n",
        "  verb_agreement_rules = {\n",
        "      \"is\": \"are\",\n",
        "      \"wants\": \"want\",\n",
        "      \"has\": \"have\"\n",
        "  }\n",
        "\n",
        "  if \"you\" in sentence:\n",
        "      for word, change in verb_agreement_rules.items():\n",
        "        sentence = sentence.replace(word.lower(), change)\n",
        "\n",
        "print(\"Org:\", text_message)\n",
        "fix_verb_agreement(text_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qtm1xhScs9nw",
      "metadata": {
        "id": "qtm1xhScs9nw"
      },
      "source": [
        "4. `Adding prepending rules to reconstructed message content`:\n",
        "\n",
        "We add the source contact name and appropriate reporting verbs to the beginning of each output, among other things. Each type of message has a different set of prepend rules and the VA can randomly choose prepends in the same set to sound more spontaneous. For example, an AskYN message with a direct question would need a prepend rule like@SCN@ asks if or @SCN@ is wondering whether. Similarly, a Req messages might use @SCN@ asks you to or @SCN@ would like to remind you to as prepends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8p-BsieMs-V7",
      "metadata": {
        "id": "8p-BsieMs-V7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Example text message\n",
        "random_wh_row = train_processed.iloc[3269]\n",
        "\n",
        "print(\"Original Message:\", random_wh_row.input)\n",
        "print(\"Expected response:\", random_wh_row.output)\n",
        "\n",
        "def extract_message(text, prepend_suggestion):\n",
        "  message = random.choice([\"Hey\", \"Hi\"]) + \" Bob, John \" + prepend_suggestion\n",
        "  # text = str(text.replace(\"@CN@\", \"John\")).replace(\"to\", \"\").replace(\"that\",\"\")\n",
        "  doc = nlp(text)\n",
        "  end_index = [e.end_char for e in doc.ents if e.label_ == \"PERSON\"]\n",
        "  if len(end_index) > 0:\n",
        "    message += text[end_index[0]:].replace(\",\",\"\")\n",
        "  return message\n",
        "\n",
        "def reconstruct_message(sentence, message_types):\n",
        "  # Define prepend rules for different message types\n",
        "  prepend_suggestions = [\"\"]\n",
        "  if message_types.ask_yn and message_types.is_direct:\n",
        "    prepend_suggestions = [\"asks if\", \"is wondering whether\", \"wants to know if\", \"would like to know whether\"]\n",
        "  elif message_types.ask_req:\n",
        "    prepend_suggestions = [\"asks you to\", \"would like to remind you to\", \"requests that\"]\n",
        "  elif message_types.stmt:\n",
        "    prepend_suggestions = [\"shares that\", \"provides information that\", \"tells you that\"]\n",
        "\n",
        "  # Randomly select a prepend from the rules for the given message type\n",
        "  selected_prepend = random.choice(prepend_suggestions)\n",
        "\n",
        "  # Extract the message\n",
        "  message = extract_message(sentence, selected_prepend)\n",
        "\n",
        "  return message\n",
        "\n",
        "modified_sentence = reconstruct_message(swap_pronouns(change_word_order(random_wh_row.input)), random_wh_row)\n",
        "print(\"Transformed:\", modified_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14xtTJIt4tFi",
      "metadata": {
        "id": "14xtTJIt4tFi"
      },
      "outputs": [],
      "source": [
        "## Apply all the preprocessing sequentially\n",
        "\n",
        "# Step 1:\n",
        "train_processed[\"transformed\"] = train_processed.apply(lambda row: change_word_order(row.input) if row['ask_yn'] and row['is_direct'] else row.input, axis=1)\n",
        "train_processed[\"transformed\"] = train_processed.input.apply(swap_pronouns)\n",
        "train_processed[\"transformed\"] = train_processed.input.apply(fix_verb_agreement)\n",
        "train_processed[\"transformed\"] = train_processed.apply(lambda row: reconstruct_message(row.input, row), axis=1)\n",
        "train_processed.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gtALc3miOVtt",
      "metadata": {
        "id": "gtALc3miOVtt"
      },
      "outputs": [],
      "source": [
        "# Save the transformations\n",
        "train_processed.to_csv(f\"{path}/train_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4wWzR2HYae8",
      "metadata": {
        "id": "K4wWzR2HYae8"
      },
      "outputs": [],
      "source": [
        "pd.read_csv(f\"{path}/train_processed.csv\").sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OWKO-xTqwJly",
      "metadata": {
        "id": "OWKO-xTqwJly"
      },
      "source": [
        "### Check the results for rule-based approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O3wOEK8ewLgJ",
      "metadata": {
        "id": "O3wOEK8ewLgJ"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "metric.compute(predictions=train_processed.transformed.values, references=train_processed.output.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xUtQEimLwPHo",
      "metadata": {
        "id": "xUtQEimLwPHo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random_row = train_processed.loc[random.randint(0,len(train_processed))]\n",
        "predictions = [random_row.transformed]\n",
        "references = [[random_row.output]]\n",
        "print(\"Input:\", random_row.input)\n",
        "print(\"Output:\", random_row.output)\n",
        "print(\"Rule based output:\", random_row.transformed)\n",
        "metric.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pYI3eJ5PUswC",
      "metadata": {
        "id": "pYI3eJ5PUswC"
      },
      "outputs": [],
      "source": [
        "train_processed[\"bleu_score\"] = train_processed.apply(lambda row: metric.compute(predictions=[row[\"transformed\"]], references=[[row[\"output\"]]])[\"score\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lPCGBVFXcnJa",
      "metadata": {
        "id": "lPCGBVFXcnJa"
      },
      "outputs": [],
      "source": [
        "train_processed.to_csv(f\"{path}/train_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pKbW-w2DkQsB",
      "metadata": {
        "id": "pKbW-w2DkQsB"
      },
      "outputs": [],
      "source": [
        "train_processed = pd.read_csv(f\"{path}/train_processed.csv\")\n",
        "train_processed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x-oh53VUbqaE",
      "metadata": {
        "id": "x-oh53VUbqaE"
      },
      "outputs": [],
      "source": [
        "## Distribution of BLEU scores for rule-based approach\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(train_processed.bleu_score, kde=True)\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(train_processed, y=\"bleu_score\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WaAA5JHlI0Pa",
      "metadata": {
        "id": "WaAA5JHlI0Pa"
      },
      "outputs": [],
      "source": [
        "## Sort by the BLEU score\n",
        "train_processed_sorted = train_processed.sort_values(\"bleu_score\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vibrLeLFci3u",
      "metadata": {
        "id": "vibrLeLFci3u"
      },
      "source": [
        "### Check examples that went wrong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z3Zs1hhgbwYu",
      "metadata": {
        "id": "z3Zs1hhgbwYu"
      },
      "outputs": [],
      "source": [
        "train_processed_sorted.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mz24d9J-IZ_4",
      "metadata": {
        "id": "Mz24d9J-IZ_4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}