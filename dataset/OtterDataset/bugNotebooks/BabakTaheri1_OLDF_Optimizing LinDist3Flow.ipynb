{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14a829a",
   "metadata": {},
   "source": [
    "# Read Normally distributed scenarios an makes them ready for training LDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class LoadScenarioGeneration:\n",
    "    def __init__(self, dss_file, output_dir=\"results\", S_base=500):\n",
    "        self.dss_file = dss_file\n",
    "        self.output_dir = output_dir\n",
    "        self.S_base = S_base \n",
    "        self.load_data = []\n",
    "        self.bus_index = {}\n",
    "        self.reference_bus = None\n",
    "        self.P_scenarios = {}\n",
    "        self.Q_scenarios = {}\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        logging.basicConfig(filename=os.path.join(self.output_dir, 'log.txt'), level=logging.INFO)\n",
    "\n",
    "    def load_system(self):\n",
    "        \"\"\"Load the DSS system file and solve the power flow.\"\"\"\n",
    "        try:\n",
    "            dss.run_command(f'Redirect \"{self.dss_file}\"')\n",
    "            dss.Solution.Solve()\n",
    "            logging.info(f'Successfully loaded and solved DSS file: {self.dss_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading DSS file: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_line_data(self, line_data_file):\n",
    "        \"\"\"Load line data from a JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(line_data_file, \"r\") as f:\n",
    "                self.line_data = json.load(f)\n",
    "            logging.info(f'Successfully loaded line data from {line_data_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def generate_bus_index_from_lines(self):\n",
    "        \"\"\"Generate a bus index from the line data.\"\"\"\n",
    "        try:\n",
    "            buses = []\n",
    "            seen_buses = set()\n",
    "            for line, data in self.line_data.items():\n",
    "                bus1 = data['FromBus']\n",
    "                bus2 = data['ToBus']\n",
    "                if bus1 not in seen_buses:\n",
    "                    buses.append(bus1)\n",
    "                    seen_buses.add(bus1)\n",
    "                if bus2 not in seen_buses:\n",
    "                    buses.append(bus2)\n",
    "                    seen_buses.add(bus2)\n",
    "\n",
    "            self.bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "            self.reference_bus = buses[0] if buses else None\n",
    "            logging.info('Successfully generated bus index from line data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error generating bus index from line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_scenarios(self, test_case):\n",
    "        \"\"\"Load previously saved P and Q scenarios.\"\"\"\n",
    "        try:\n",
    "            self.P_scenarios = np.load(os.path.join(self.output_dir, f\"P_OpenDSS_normal_{test_case}.npy\"), allow_pickle=True).item()\n",
    "            self.Q_scenarios = np.load(os.path.join(self.output_dir, f\"Q_OpenDSS_normal_{test_case}.npy\"), allow_pickle=True).item()\n",
    "            logging.info(f'Successfully loaded scenarios for {test_case}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading scenarios: {e}')\n",
    "            raise\n",
    "\n",
    "    def extract_load_data(self):\n",
    "        \"\"\"Extract load data from the DSS system.\"\"\"\n",
    "        try:\n",
    "            loads = dss.Loads.AllNames()\n",
    "            for load in loads:\n",
    "                dss.Loads.Name(load)\n",
    "                bus = dss.CktElement.BusNames()[0].split('.')[0]\n",
    "                phases = dss.Loads.Phases()\n",
    "                conn = 'Delta' if dss.Loads.IsDelta() else 'Wye'\n",
    "                kV = dss.Loads.kV()\n",
    "\n",
    "                P_scenarios = self.P_scenarios.get(load, [])\n",
    "                Q_scenarios = self.Q_scenarios.get(load, [])\n",
    "\n",
    "                for scenario_idx in range(len(P_scenarios)):\n",
    "                    P = P_scenarios[scenario_idx]\n",
    "                    Q = Q_scenarios[scenario_idx]\n",
    "                    S = np.sqrt(P**2 + Q**2)\n",
    "                    power_factor = P / S if S != 0 else 1.0\n",
    "\n",
    "                    if bus in self.bus_index:\n",
    "                        self.load_data.append({\n",
    "                            'name': load,\n",
    "                            'bus': bus,\n",
    "                            'phases': phases,\n",
    "                            'connection': conn,\n",
    "                            'P': P,\n",
    "                            'Q': Q,\n",
    "                            'kV': kV,\n",
    "                            'power_factor': power_factor,\n",
    "                            'bus_full': dss.CktElement.BusNames()[0],\n",
    "                            'scenario': scenario_idx\n",
    "                        })\n",
    "            logging.info('Successfully extracted load data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error extracting load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def organize_power_data(self):\n",
    "        \"\"\"Organize power data by bus and phase.\"\"\"\n",
    "        try:\n",
    "            scenario_count = len(next(iter(self.P_scenarios.values())))\n",
    "            P_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "            Q_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "\n",
    "            for scenario_idx in range(scenario_count):\n",
    "                for load in self.load_data:\n",
    "                    if load['scenario'] == scenario_idx:\n",
    "                        bus = load['bus']\n",
    "                        connection = load['connection']\n",
    "                        phase_indices = [int(phase) - 1 for phase in load['bus_full'].split('.')[1:] if phase.isdigit()]\n",
    "\n",
    "                        P = load['P']\n",
    "                        Q = load['Q']\n",
    "\n",
    "                        if connection == 'Delta' and len(phase_indices) == 3:\n",
    "                            for phase in phase_indices:\n",
    "                                P_bus_phase[bus][scenario_idx][phase] = P / 3\n",
    "                                Q_bus_phase[bus][scenario_idx][phase] = Q / 3\n",
    "                        else:\n",
    "                            if phase_indices:\n",
    "                                first_phase_index = phase_indices[0]\n",
    "                                P_bus_phase[bus][scenario_idx][first_phase_index] = P\n",
    "                                Q_bus_phase[bus][scenario_idx][first_phase_index] = Q\n",
    "\n",
    "            logging.info('Successfully organized power data')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error organizing power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def convert_to_pu(self, P_bus_phase, Q_bus_phase):\n",
    "        \"\"\"Convert power data to per unit values.\"\"\"\n",
    "        try:\n",
    "            P_bus_phase_pu = {bus: P / self.S_base for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase_pu = {bus: Q / self.S_base for bus, Q in Q_bus_phase.items()}\n",
    "            logging.info('Successfully converted power data to per unit values')\n",
    "            return P_bus_phase_pu, Q_bus_phase_pu\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to per unit values: {e}')\n",
    "            raise\n",
    "\n",
    "    def remove_reference_bus_columns(self, P_bus_phase, Q_bus_phase):\n",
    "        \"\"\"Remove reference bus columns from the power data.\"\"\"\n",
    "        try:\n",
    "            if self.reference_bus in P_bus_phase:\n",
    "                del P_bus_phase[self.reference_bus]\n",
    "            if self.reference_bus in Q_bus_phase:\n",
    "                del Q_bus_phase[self.reference_bus]\n",
    "            logging.info(f'Successfully removed reference bus {self.reference_bus} from power data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error removing reference bus from power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_power_data(self, P_bus_phase, Q_bus_phase, suffix=\"\", test_case=\"\"):\n",
    "        \"\"\"Save power data to JSON files.\"\"\"\n",
    "        try:\n",
    "            P_bus_phase = {bus: P.tolist() for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase = {bus: Q.tolist() for bus, Q in Q_bus_phase.items()}\n",
    "\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_normal{suffix}.json\"), \"w\") as fp:\n",
    "                json.dump(P_bus_phase, fp, indent=4)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_normal{suffix}.json\"), \"w\") as fq:\n",
    "                json.dump(Q_bus_phase, fq, indent=4)\n",
    "            logging.info(f'P and Q data saved to {self.output_dir} as {suffix}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_load_data(self, test_case=\"\"):\n",
    "        \"\"\"Save load data to a JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_load_data.json\"), \"w\") as fl:\n",
    "                json.dump(self.load_data, fl, indent=4)\n",
    "            logging.info(f'Load data saved to {self.output_dir}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_power_data(self, suffix=\"\", test_case=\"\"):\n",
    "        \"\"\"Load power data from JSON files.\"\"\"\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_normal{suffix}.json\"), \"r\") as fp:\n",
    "                P_bus_phase = json.load(fp)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_normal{suffix}.json\"), \"r\") as fq:\n",
    "                Q_bus_phase = json.load(fq)\n",
    "            logging.info(f'Successfully loaded power data with suffix {suffix}')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def power_data_to_matrix(self, power_data, scenario_idx):\n",
    "        \"\"\"Convert power data to a matrix format.\"\"\"\n",
    "        power_matrix = np.zeros((len(self.bus_index) - 1, 3))  # Adjust for removed reference bus\n",
    "        try:\n",
    "            for bus, idx in self.bus_index.items():\n",
    "                if bus != self.reference_bus and bus in power_data:\n",
    "                    power_matrix[idx - (1 if idx > self.bus_index[self.reference_bus] else 0), :] = power_data[bus][scenario_idx]\n",
    "            logging.info('Successfully converted power data to matrix')\n",
    "            return power_matrix\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to matrix: {e}')\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        TestCase = '37Bus'\n",
    "        #TestCase = '13Bus'\n",
    "\n",
    "        simulator = LoadScenarioGeneration(\n",
    "            dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/ieee37.dss\",\n",
    "            #dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/IEEE13Nodeckt.dss\",\n",
    "            S_base=500\n",
    "        )\n",
    "\n",
    "        simulator.load_system()\n",
    "        simulator.load_line_data(line_data_file=f\"results/{TestCase}_line_data.json\")  # Update with correct file path\n",
    "        simulator.generate_bus_index_from_lines()\n",
    "        simulator.load_scenarios(TestCase)\n",
    "        simulator.extract_load_data()\n",
    "        P_bus_phase, Q_bus_phase = simulator.organize_power_data()\n",
    "        \n",
    "        simulator.remove_reference_bus_columns(P_bus_phase, Q_bus_phase)\n",
    "\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.convert_to_pu(P_bus_phase, Q_bus_phase)\n",
    "        \n",
    "        simulator.save_power_data(P_bus_phase, Q_bus_phase, suffix=\"\", test_case=TestCase)\n",
    "        simulator.save_power_data(P_bus_phase_pu, Q_bus_phase_pu, suffix=\"_pu\", test_case=TestCase)\n",
    "        simulator.save_load_data(test_case=TestCase)\n",
    "\n",
    "        P_bus_phase, Q_bus_phase = simulator.load_power_data(suffix=\"\", test_case=TestCase)\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.load_power_data(suffix=\"_pu\", test_case=TestCase)\n",
    "\n",
    "        scenario_idx = 0\n",
    "        P_matrix = simulator.power_data_to_matrix(P_bus_phase, scenario_idx)\n",
    "        Q_matrix = simulator.power_data_to_matrix(Q_bus_phase, scenario_idx)\n",
    "        P_matrix_pu = simulator.power_data_to_matrix(P_bus_phase_pu, scenario_idx)\n",
    "        Q_matrix_pu = simulator.power_data_to_matrix(Q_bus_phase_pu, scenario_idx)\n",
    "\n",
    "        print(\"Bus index:\\n\", simulator.bus_index)\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in main execution: {e}')\n",
    "        print(f'Error in main execution: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfaa582",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "import time\n",
    "\n",
    "class OptimizedLindist3FlowTraining:\n",
    "    def __init__(self, path, test_case, optimization_method):\n",
    "        self.path = path\n",
    "        self.test_case = test_case\n",
    "        self.optimization_method = optimization_method\n",
    "        self.Ref_V = np.array([0.9890**2, 1.0245**2, 1.0146**2])  # IEEE 37 Bus reference voltages\n",
    "        #self.Ref_V = np.array([1.056**2, 1.0374**2, 1.056**2]) # IEEE 13 Bus\n",
    "        self.line_data = None\n",
    "        self.buses = None\n",
    "        self.phases = None\n",
    "        self.bus_index = None\n",
    "        self.incidence_matrix = None\n",
    "        self.incidence_df = None\n",
    "        self.A = None\n",
    "        self.F = None\n",
    "        self.block_diagonal_matrix_hp = None\n",
    "        self.block_diagonal_matrix_hq = None\n",
    "        self.P_data = None\n",
    "        self.Q_data = None\n",
    "        self.V_AC = None\n",
    "\n",
    "    def load_dss_master_file(self):\n",
    "        \"\"\"Load the DSS master file.\"\"\"\n",
    "        dss_master_file_path = f\"{self.path}/data/IEEETestCases/{self.test_case}Bus/ieee37.dss\"\n",
    "        dss.run_command(\"Clear\")\n",
    "        dss.run_command(f'Redirect \"{dss_master_file_path}\"')\n",
    "        if dss.Circuit.Name() == \"\":\n",
    "            raise Exception(\"No active circuit. Please check the DSS master file.\")\n",
    "\n",
    "    def load_line_data_from_json(self):\n",
    "        \"\"\"Load line data from a JSON file.\"\"\"\n",
    "        file_path = f\"{self.path}/results/{self.test_case}Bus_line_data.json\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.line_data = json.load(file)\n",
    "\n",
    "    def extract_buses_and_phases(self):\n",
    "        \"\"\"Extract bus and phase information from line data.\"\"\"\n",
    "        buses = []\n",
    "        phases = {'1', '2', '3'}\n",
    "        seen_buses = set()\n",
    "        for line_info in self.line_data.values():\n",
    "            bus1_base = line_info['FromBus'].split('.')[0]\n",
    "            bus2_base = line_info['ToBus'].split('.')[0]\n",
    "            if bus1_base not in seen_buses:\n",
    "                buses.append(bus1_base)\n",
    "                seen_buses.add(bus1_base)\n",
    "            if bus2_base not in seen_buses:\n",
    "                buses.append(bus2_base)\n",
    "                seen_buses.add(bus2_base)\n",
    "        self.buses = buses\n",
    "        self.phases = phases\n",
    "        self.bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "\n",
    "    def create_incidence_matrix(self):\n",
    "        \"\"\"Create the incidence matrix.\"\"\"\n",
    "        incidence_matrix = np.zeros((len(self.buses) * len(self.phases), len(self.line_data) * len(self.phases)), dtype=int)\n",
    "        for line_idx, (line_id, line_info) in enumerate(self.line_data.items()):\n",
    "            bus1 = line_info['FromBus']\n",
    "            bus2 = line_info['ToBus']\n",
    "            bus1_phases = line_info['Bus1Phases']\n",
    "            bus2_phases = line_info['Bus2Phases']\n",
    "            for phase in self.phases:\n",
    "                if phase in bus1_phases:\n",
    "                    row_idx_bus1 = self.bus_index[bus1] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus1, line_idx * 3 + int(phase) - 1] = 1\n",
    "                if phase in bus2_phases:\n",
    "                    row_idx_bus2 = self.bus_index[bus2] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus2, line_idx * 3 + int(phase) - 1] = -1\n",
    "        self.incidence_matrix = incidence_matrix.T\n",
    "\n",
    "    def prepare_incidence_df(self):\n",
    "        \"\"\"Prepare the incidence DataFrame.\"\"\"\n",
    "        incidence_df = pd.DataFrame(self.incidence_matrix, columns=[f\"{bus}.{phase}\" for bus in self.buses for phase in self.phases])\n",
    "        incidence_df.index = [f\"{line_name}.{phase}\" for line_name in self.line_data.keys() for phase in self.phases]\n",
    "        reference_bus = self.buses[0]\n",
    "        reference_columns = [f\"{reference_bus}.{phase}\" for phase in self.phases]\n",
    "        incidence_df.drop(columns=reference_columns, inplace=True)\n",
    "        self.incidence_df = incidence_df\n",
    "\n",
    "    def compute_pseudo_inverse(self):\n",
    "        \"\"\"Compute the pseudo-inverse of the incidence matrix.\"\"\"\n",
    "        A = self.incidence_df.to_numpy()\n",
    "        F = np.linalg.pinv(A)\n",
    "        self.A = A\n",
    "        self.F = F\n",
    "\n",
    "    def load_data_from_files(self):\n",
    "        \"\"\"Load required data from files.\"\"\"\n",
    "        self.block_diagonal_matrix_hp = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hp.npy')\n",
    "        self.block_diagonal_matrix_hq = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hq.npy')\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_P_LDF_normal_pu.json', 'r') as f:\n",
    "            self.P_data = json.load(f)\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_Q_LDF_normal_pu.json', 'r') as f:\n",
    "            self.Q_data = json.load(f)\n",
    "        with open(f\"{self.path}/results/{self.test_case}Bus_normal_voltages.json\", \"r\") as file:\n",
    "            self.V_AC = json.load(file)\n",
    "\n",
    "    def LinDist3Flow(self, H_p, H_q, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, F, A, P_inj, Q_inj, V_AC, Batch_size, Ref_V, scenario_idx):\n",
    "        \"\"\"Compute the 3-phase LinDistFlow and sensitivities.\"\"\"\n",
    "        gamma = gamma.reshape(n_buses_3ph, 1)\n",
    "        rho = rho.reshape(n_buses_3ph, 1)\n",
    "        varrho = varrho.reshape(n_buses_3ph, 1)\n",
    "\n",
    "        Ref_V_expanded = np.tile(Ref_V, n_buses_3ph // 3).reshape(-1, 1)\n",
    "        v = Ref_V_expanded - F @ H_p @ F.T @ (-P_inj + rho) - F @ H_q @ F.T @ (-Q_inj + varrho) + gamma\n",
    "\n",
    "        P = A.T @ A\n",
    "        B = np.zeros((len(A), 1))\n",
    "        for i in range(len(A)):\n",
    "            if np.any(P[i, :] != 0):\n",
    "                B[i] = 1\n",
    "        v = np.multiply(B, v)\n",
    "\n",
    "        dvdH_p = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * np.kron(F.T,  (F.T @ (-P_inj + rho)))\n",
    "        dvdH_q = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * np.kron(F.T,  (F.T @ (-Q_inj + varrho)))\n",
    "        dvdrho = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * F @ H_p @ F.T\n",
    "        dvdvarrho = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * F @ H_q @ F.T\n",
    "        dvdgamma = (1 / n_buses_3ph) * (1 / Batch_size) * np.eye(n_buses_3ph)\n",
    "\n",
    "        v_AC = np.array(V_AC[f\"scenario_{scenario_idx}\"])\n",
    "        v_AC = v_AC[3:]\n",
    "        v_AC = np.array(v_AC).reshape((n_buses_3ph, 1))\n",
    "        v = np.reshape(v, (n_buses_3ph, 1))\n",
    "\n",
    "        gradient_H_p = dvdH_p @ (v - v_AC**2)\n",
    "        gradient_H_q = dvdH_q @ (v - v_AC**2)\n",
    "        gradient_rho = dvdrho @ (v - v_AC**2)\n",
    "        gradient_varrho = dvdvarrho @ (v - v_AC**2)\n",
    "        gradient_gamma = dvdgamma @ (v - v_AC**2)\n",
    "\n",
    "        return v, v_AC, gradient_H_p, gradient_H_q, gradient_gamma, gradient_rho, gradient_varrho\n",
    "\n",
    "    def objective_function(self, params):\n",
    "        \"\"\"Objective function for the optimization process.\"\"\"\n",
    "        global gradient_Dr, gradient_Dx, gradient_gamma_P, gradient_gamma_Q, gradient_bias, v, v_AC\n",
    "\n",
    "        n_buses_3ph = self.A.shape[0]\n",
    "        n_branches = n_buses_3ph // 3\n",
    "\n",
    "        H_p = params[:len(self.block_diagonal_matrix_hp)**2].reshape((len(self.block_diagonal_matrix_hp), len(self.block_diagonal_matrix_hp)))\n",
    "        H_q = params[len(self.block_diagonal_matrix_hp)**2:2 * len(self.block_diagonal_matrix_hp)**2].reshape((len(self.block_diagonal_matrix_hp), len(self.block_diagonal_matrix_hp)))\n",
    "        gamma = params[2 * len(self.block_diagonal_matrix_hp)**2:2 * len(self.block_diagonal_matrix_hp)**2 + n_buses_3ph].reshape((n_buses_3ph, 1))\n",
    "        rho = params[2 * len(self.block_diagonal_matrix_hp)**2 + n_buses_3ph:2 * len(self.block_diagonal_matrix_hp)**2 + 2 * n_buses_3ph].reshape((n_buses_3ph, 1))\n",
    "        varrho = params[2 * len(self.block_diagonal_matrix_hp)**2 + 2 * n_buses_3ph:].reshape((n_buses_3ph, 1))\n",
    "\n",
    "        ref_bus = 0\n",
    "        Batch_size = 20\n",
    "        scen_start = 1\n",
    "        scen_final = 21\n",
    "        v_results, v_AC_results, gradient_H_p, gradient_H_q, gradient_gamma, gradient_rho, gradient_varrho = zip(*Parallel(n_jobs=-1)(delayed(self.LinDist3Flow)(\n",
    "            H_p, H_q, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, self.F, self.A, np.array([values[scenario_idx] for values in self.P_data.values()]).flatten().reshape(-1, 1), np.array([values[scenario_idx] for values in self.Q_data.values()]).flatten().reshape(-1, 1), self.V_AC, Batch_size, self.Ref_V, s) for s in random.sample(range(scen_start-1, scen_final-1), Batch_size)))\n",
    "\n",
    "        Gradient_Dr = np.sum(gradient_H_p, axis=0)\n",
    "        Gradient_Dx = np.sum(gradient_H_q, axis=0)\n",
    "        Gradient_gamma_P = np.sum(gradient_rho, axis=0)\n",
    "        Gradient_gamma_Q = np.sum(gradient_varrho, axis=0)\n",
    "        Gradient_bias = np.sum(gradient_gamma, axis=0)\n",
    "\n",
    "        Jac = np.concatenate((Gradient_Dr, Gradient_Dx, Gradient_gamma_P, Gradient_gamma_Q, Gradient_bias))\n",
    "        V_LDF = np.concatenate(v_results)\n",
    "        V_DF = np.concatenate(v_AC_results)\n",
    "\n",
    "        objective = (1 / n_buses_3ph) * (1 / Batch_size) * np.sum((V_LDF - V_DF**2)**2)\n",
    "\n",
    "        return objective, Jac.flatten()\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"Optimize the parameters.\"\"\"\n",
    "        H_p = self.block_diagonal_matrix_hp.flatten()\n",
    "        H_q = self.block_diagonal_matrix_hq.flatten()\n",
    "        rho = np.zeros(self.A.shape[0])\n",
    "        varrho = np.zeros(self.A.shape[0])\n",
    "        gamma = np.zeros(self.A.shape[0])\n",
    "\n",
    "        initial_params = np.concatenate((H_p, H_q, rho, varrho, gamma))\n",
    "\n",
    "        result = minimize(\n",
    "            fun=self.objective_function,\n",
    "            x0=initial_params,\n",
    "            jac=True,\n",
    "            method=self.optimization_method,\n",
    "            options={'gtol': 1e-16, 'disp': True}\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def save_results(self, result):\n",
    "        \"\"\"Save the optimization results.\"\"\"\n",
    "        optimized_params = result.x\n",
    "\n",
    "        H_p = optimized_params[:len(self.block_diagonal_matrix_hp)**2]\n",
    "        H_q = optimized_params[len(self.block_diagonal_matrix_hp)**2:2 * len(self.block_diagonal_matrix_hp)**2]\n",
    "        gamma_P_MIN = optimized_params[2 * len(self.block_diagonal_matrix_hp)**2:2 * len(self.block_diagonal_matrix_hp)**2 + self.A.shape[0]]\n",
    "        gamma_Q_MIN = optimized_params[2 * len(self.block_diagonal_matrix_hp)**2 + self.A.shape[0]:2 * len(self.block_diagonal_matrix_hp)**2 + 2 * self.A.shape[0]]\n",
    "        bias_Min = optimized_params[2 * len(self.block_diagonal_matrix_hp)**2 + 2 * self.A.shape[0]:]\n",
    "\n",
    "        np.savetxt(f\"{self.path}/parameters/H_p_{self.test_case}bus_{self.optimization_method}.txt\", H_p, fmt='%f')\n",
    "        np.savetxt(f\"{self.path}/parameters/H_q_{self.test_case}bus_{self.optimization_method}.txt\", H_q, fmt='%f')\n",
    "        np.savetxt(f\"{self.path}/parameters/gamma_P_{self.test_case}bus_{self.optimization_method}.txt\", gamma_P_MIN, fmt='%f')\n",
    "        np.savetxt(f\"{self.path}/parameters/gamma_Q_{self.test_case}bus_{self.optimization_method}.txt\", gamma_Q_MIN, fmt='%f')\n",
    "        np.savetxt(f\"{self.path}/parameters/bias_{self.test_case}bus_{self.optimization_method}.txt\", bias_Min, fmt='%f')\n",
    "\n",
    "def main():\n",
    "    path = '/Users/babaktaheri/Desktop/OLDF/Multi-phase'\n",
    "    test_case = '37'\n",
    "    optimization_method = 'TNC'\n",
    "    voltage_optimizer = OptimizedLindist3FlowTraining(path, test_case, optimization_method)\n",
    "    \n",
    "    voltage_optimizer.load_dss_master_file()\n",
    "    voltage_optimizer.load_line_data_from_json()\n",
    "    voltage_optimizer.extract_buses_and_phases()\n",
    "    voltage_optimizer.create_incidence_matrix()\n",
    "    voltage_optimizer.prepare_incidence_df()\n",
    "    voltage_optimizer.compute_pseudo_inverse()\n",
    "    voltage_optimizer.load_data_from_files()\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    result = voltage_optimizer.optimize()\n",
    "    end_time = time.process_time()\n",
    "    \n",
    "    execution_time = end_time - start_time\n",
    "    print(f'Total execution time: {execution_time} seconds')\n",
    "    \n",
    "    voltage_optimizer.save_results(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2f1e3",
   "metadata": {},
   "source": [
    "# Train by leveragating the block diagonal structure of H matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import time\n",
    "\n",
    "class OLDFWithBlockDiagonal:\n",
    "    def __init__(self, test_case, optimization_method, path):\n",
    "        self.TEST_CASE = test_case\n",
    "        self.OPTIMIZATION_METHOD = optimization_method\n",
    "        self.PATH = path\n",
    "        self.Ref_V = None\n",
    "        self.line_data = None\n",
    "        self.buses = None\n",
    "        self.phases = None\n",
    "        self.bus_index = None\n",
    "        self.incidence_df = None\n",
    "        self.A = None\n",
    "        self.F = None\n",
    "        self.block_diagonal_matrix_hp = None\n",
    "        self.block_diagonal_matrix_hq = None\n",
    "        self.P_data = None\n",
    "        self.Q_data = None\n",
    "        self.V_AC = None\n",
    "\n",
    "    def load_dss_master_file(self, dss_master_file_path):\n",
    "        dss.run_command(\"Clear\")\n",
    "        dss.run_command(f'Redirect \"{dss_master_file_path}\"')\n",
    "        if dss.Circuit.Name() == \"\":\n",
    "            raise Exception(\"No active circuit. Please check the DSS master file.\")\n",
    "\n",
    "    def load_line_data_from_json(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.line_data = json.load(file)\n",
    "\n",
    "    def extract_buses_and_phases(self):\n",
    "        self.buses = []\n",
    "        self.phases = {'1', '2', '3'}\n",
    "        seen_buses = set()\n",
    "        for line_info in self.line_data.values():\n",
    "            bus1_base = line_info['FromBus'].split('.')[0]\n",
    "            bus2_base = line_info['ToBus'].split('.')[0]\n",
    "            if bus1_base not in seen_buses:\n",
    "                self.buses.append(bus1_base)\n",
    "                seen_buses.add(bus1_base)\n",
    "            if bus2_base not in seen_buses:\n",
    "                self.buses.append(bus2_base)\n",
    "                seen_buses.add(bus2_base)\n",
    "        self.bus_index = {bus: i for i, bus in enumerate(self.buses)}\n",
    "\n",
    "    def create_incidence_matrix(self):\n",
    "        incidence_matrix = np.zeros((len(self.buses) * len(self.phases), len(self.line_data) * len(self.phases)), dtype=int)\n",
    "        for line_idx, (line_id, line_info) in enumerate(self.line_data.items()):\n",
    "            bus1 = line_info['FromBus']\n",
    "            bus2 = line_info['ToBus']\n",
    "            bus1_phases = line_info['Bus1Phases']\n",
    "            bus2_phases = line_info['Bus2Phases']\n",
    "            for phase in self.phases:\n",
    "                if phase in bus1_phases:\n",
    "                    row_idx_bus1 = self.bus_index[bus1] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus1, line_idx * 3 + int(phase) - 1] = 1\n",
    "                if phase in bus2_phases:\n",
    "                    row_idx_bus2 = self.bus_index[bus2] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus2, line_idx * 3 + int(phase) - 1] = -1\n",
    "        return incidence_matrix.T\n",
    "\n",
    "    def prepare_incidence_df(self, incidence_matrix):\n",
    "        incidence_df = pd.DataFrame(incidence_matrix, columns=[f\"{bus}.{phase}\" for bus in self.buses for phase in self.phases])\n",
    "        incidence_df.index = [f\"{line_name}.{phase}\" for line_name in self.line_data.keys() for phase in self.phases]\n",
    "        reference_bus = self.buses[0]\n",
    "        reference_columns = [f\"{reference_bus}.{phase}\" for phase in self.phases]\n",
    "        incidence_df.drop(columns=reference_columns, inplace=True)\n",
    "        self.incidence_df = incidence_df\n",
    "\n",
    "    def compute_pseudo_inverse(self):\n",
    "        A = self.incidence_df.to_numpy()\n",
    "        F = np.linalg.pinv(A)\n",
    "        self.A = A\n",
    "        self.F = F\n",
    "\n",
    "    def load_data_from_files(self):\n",
    "        self.block_diagonal_matrix_hp = np.load(f'{self.PATH}/results/{self.TEST_CASE}Bus_block_diagonal_matrix_hp.npy')\n",
    "        self.block_diagonal_matrix_hq = np.load(f'{self.PATH}/results/{self.TEST_CASE}Bus_block_diagonal_matrix_hq.npy')\n",
    "        with open(f'{self.PATH}/results/{self.TEST_CASE}Bus_P_LDF_normal_pu.json', 'r') as f:\n",
    "            self.P_data = json.load(f)\n",
    "        with open(f'{self.PATH}/results/{self.TEST_CASE}Bus_Q_LDF_normal_pu.json', 'r') as f:\n",
    "            self.Q_data = json.load(f)\n",
    "\n",
    "    def extract_block_diagonal_elements(self, block_diagonal_matrix):\n",
    "        block_size = 3\n",
    "        num_blocks = block_diagonal_matrix.shape[0] // block_size\n",
    "        blocks = []\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            start_index = i * block_size\n",
    "            end_index = start_index + block_size\n",
    "            \n",
    "            block = block_diagonal_matrix[start_index:end_index, start_index:end_index]\n",
    "            blocks.append(block)\n",
    "        \n",
    "        concatenated_blocks = np.concatenate([block.flatten() for block in blocks])\n",
    "        return concatenated_blocks\n",
    "\n",
    "    def reconstruct_block_diagonal_matrix(self, concatenated_blocks, block_size, num_blocks):\n",
    "        expected_length = block_size * block_size * num_blocks\n",
    "        if len(concatenated_blocks) != expected_length:\n",
    "            raise ValueError(f\"Expected length {expected_length}, but got {len(concatenated_blocks)}\")\n",
    "        \n",
    "        reshaped_blocks = np.reshape(concatenated_blocks, (num_blocks, block_size, block_size))\n",
    "        initial_matrix_size = block_size * num_blocks\n",
    "        initial_matrix = np.zeros((initial_matrix_size, initial_matrix_size))\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            start_index = i * block_size\n",
    "            end_index = start_index + block_size\n",
    "            \n",
    "            block = reshaped_blocks[i]\n",
    "            initial_matrix[start_index:end_index, start_index:end_index] = block\n",
    "        \n",
    "        return initial_matrix\n",
    "\n",
    "    def LinDist3Flow(self, H_p_blocks, H_q_blocks, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, F, A, P_inj, Q_inj, V_AC, Batch_size, Ref_V, scenario_idx):\n",
    "        block_size  = 3\n",
    "        num_blocks  = n_branches\n",
    "\n",
    "        H_p = self.reconstruct_block_diagonal_matrix(H_p_blocks, block_size, num_blocks)\n",
    "        H_q = self.reconstruct_block_diagonal_matrix(H_q_blocks, block_size, num_blocks)\n",
    "\n",
    "        gamma = gamma.reshape(n_buses_3ph, 1)\n",
    "        rho = rho.reshape(n_buses_3ph, 1)\n",
    "        varrho = varrho.reshape(n_buses_3ph, 1)\n",
    "\n",
    "        Ref_V_expanded = np.tile(Ref_V, n_buses_3ph // 3).reshape(-1, 1)\n",
    "        v = Ref_V_expanded - F @ H_p @ F.T @ (-P_inj + rho) - F @ H_q @ F.T @ (-Q_inj + varrho) + gamma\n",
    "\n",
    "        P = A.T @ A\n",
    "        B = np.zeros((len(A), 1))\n",
    "        for i in range(len(A)):\n",
    "            if np.any(P[i, :] != 0):\n",
    "                B[i] = 1\n",
    "        v = np.multiply(B, v)\n",
    "\n",
    "        dvdH_p = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * np.kron(F.T, (F.T @ (-P_inj + rho)))\n",
    "        dvdH_q = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * np.kron(F.T, (F.T @ (-Q_inj + varrho)))\n",
    "        dvdrho = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * F @ H_p @ F.T\n",
    "        dvdvarrho = -2 * (1 / n_buses_3ph) * (1 / Batch_size) * F @ H_q @ F.T\n",
    "        dvdgamma = (1 / n_buses_3ph) * (1 / Batch_size) * np.eye(n_buses_3ph)\n",
    "\n",
    "        v_AC = np.array(V_AC[f\"scenario_{scenario_idx}\"])\n",
    "        v_AC = v_AC[3:]  # delete the reference bus\n",
    "        v_AC = np.array(v_AC).reshape((n_buses_3ph, 1))\n",
    "        v = np.reshape(v, (n_buses_3ph, 1))\n",
    "\n",
    "        gradient_H_p = dvdH_p @ (v - v_AC**2)\n",
    "        gradient_H_q = dvdH_q @ (v - v_AC**2)\n",
    "        gradient_rho = dvdrho @ (v - v_AC**2)\n",
    "        gradient_varrho = dvdvarrho @ (v - v_AC**2)\n",
    "        gradient_gamma = dvdgamma @ (v - v_AC**2)\n",
    "\n",
    "        return v, v_AC, gradient_H_p, gradient_H_q, gradient_gamma, gradient_rho, gradient_varrho\n",
    "\n",
    "    def objective_function(self, params, A, F, P_data, Q_data, Ref_V, V_AC, Batch_size, scen_start, scen_final):\n",
    "        Gradient_Dr = 0\n",
    "        Gradient_Dx = 0\n",
    "        Gradient_gamma_P = 0\n",
    "        Gradient_gamma_Q = 0\n",
    "        Gradient_bias = 0\n",
    "\n",
    "        V_LDF = []\n",
    "        V_DF = []\n",
    "        n_buses_3ph = A.shape[0]\n",
    "        n_branches = n_buses_3ph // 3\n",
    "\n",
    "        size_blocks = n_branches * 9\n",
    "        H_p_blocks = params[:size_blocks].reshape((size_blocks, 1))  \n",
    "        H_q_blocks = params[size_blocks:2*size_blocks].reshape((size_blocks, 1))\n",
    "\n",
    "        gamma  = params[2*size_blocks:2*size_blocks + n_buses_3ph].reshape((n_buses_3ph, 1))\n",
    "        rho    = params[2*size_blocks + n_buses_3ph:2*size_blocks + 2 * n_buses_3ph].reshape((n_buses_3ph, 1))\n",
    "        varrho = params[2*size_blocks + 2 * n_buses_3ph:].reshape((n_buses_3ph, 1))\n",
    "\n",
    "        scenario_indices = random.sample(range(scen_start - 1, scen_final - 1), Batch_size)\n",
    "        ref_bus = 0\n",
    "        for idx in scenario_indices:\n",
    "            v_result, v_AC_result, gradient_H_p, gradient_H_q, gradient_gamma, gradient_rho, gradient_varrho = self.LinDist3Flow(\n",
    "                H_p_blocks, H_q_blocks, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, F, A, \n",
    "                np.array([values[idx] for values in P_data.values()]).flatten().reshape(-1, 1), \n",
    "                np.array([values[idx] for values in Q_data.values()]).flatten().reshape(-1, 1), V_AC, Batch_size, Ref_V, idx)\n",
    "            V_LDF.append(v_result)\n",
    "            V_DF.append(v_AC_result)\n",
    "            Gradient_Dr += gradient_H_p\n",
    "            Gradient_Dx += gradient_H_q\n",
    "            Gradient_gamma_P += gradient_rho\n",
    "            Gradient_gamma_Q += gradient_varrho\n",
    "            Gradient_bias += gradient_gamma\n",
    "\n",
    "        V_LDF = np.concatenate(V_LDF)\n",
    "        V_DF = np.concatenate(V_DF)\n",
    "\n",
    "        Gradient_Dr = Gradient_Dr.reshape((A.shape[0], A.shape[0]))\n",
    "        Gradient_Dx = Gradient_Dx.reshape((A.shape[0], A.shape[0]))\n",
    "\n",
    "        Gradient_Dr = self.extract_block_diagonal_elements(Gradient_Dr)\n",
    "        Gradient_Dx = self.extract_block_diagonal_elements(Gradient_Dx)  \n",
    "\n",
    "        Gradient_Dr = Gradient_Dr.reshape(-1, 1)\n",
    "        Gradient_Dx = Gradient_Dx.reshape(-1, 1)\n",
    "\n",
    "        Gradient_gamma_P = Gradient_gamma_P.reshape(-1, 1)\n",
    "        Gradient_gamma_Q = Gradient_gamma_Q.reshape(-1, 1)\n",
    "        Gradient_bias = Gradient_bias.reshape(-1, 1)\n",
    "\n",
    "        Jac = np.concatenate((Gradient_Dr, Gradient_Dx, Gradient_gamma_P, Gradient_gamma_Q, Gradient_bias))\n",
    "\n",
    "        objective = (1 / n_buses_3ph) * (1 / Batch_size) * np.sum((V_LDF - V_DF**2)**2)\n",
    "\n",
    "        return objective, Jac.flatten()\n",
    "\n",
    "\n",
    "    def run_optimization(self):\n",
    "        dss_master_file_path = f\"{self.PATH}/data/IEEETestCases/{self.TEST_CASE}Bus/ieee37.dss\"\n",
    "        self.load_dss_master_file(dss_master_file_path)\n",
    "\n",
    "        self.Ref_V = np.array([0.9890**2, 1.0245**2, 1.0146**2])  # IEEE 37 Bus\n",
    "\n",
    "        self.load_line_data_from_json(f\"{self.PATH}/results/{self.TEST_CASE}Bus_line_data.json\")\n",
    "        self.extract_buses_and_phases()\n",
    "        incidence_matrix = self.create_incidence_matrix()\n",
    "        self.prepare_incidence_df(incidence_matrix)\n",
    "        self.compute_pseudo_inverse()\n",
    "        self.load_data_from_files()\n",
    "\n",
    "        with open(f\"results/{self.TEST_CASE}Bus_normal_voltages.json\", \"r\") as file:\n",
    "            self.V_AC = json.load(file)\n",
    "            \n",
    "        ref_bus    = 0\n",
    "        scen_start = 1\n",
    "        scen_final = 21\n",
    "        Batch_size = 20\n",
    "\n",
    "        H_p = self.extract_block_diagonal_elements(self.block_diagonal_matrix_hp)\n",
    "        H_q = self.extract_block_diagonal_elements(self.block_diagonal_matrix_hq)\n",
    "        rho = np.zeros(self.A.shape[0])\n",
    "        varrho = np.zeros(self.A.shape[0])\n",
    "        gamma = np.zeros(self.A.shape[0])\n",
    "\n",
    "        initial_params = np.concatenate((H_p, H_q, rho, varrho, gamma))\n",
    "\n",
    "        start_time = time.process_time()\n",
    "\n",
    "        result = minimize(\n",
    "            fun=self.objective_function,\n",
    "            x0=initial_params,\n",
    "            args=(self.A, self.F, self.P_data, self.Q_data, self.Ref_V, self.V_AC, Batch_size, scen_start, scen_final),\n",
    "            jac=True,\n",
    "            method=self.OPTIMIZATION_METHOD,\n",
    "            options={'gtol': 1e-16, 'disp': True}\n",
    "        )\n",
    "\n",
    "        optimized_params = result.x\n",
    "        end_time = time.process_time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f'Total execution time: {execution_time} seconds')\n",
    "\n",
    "        size_hp = 3 * self.A.shape[0]\n",
    "        H_p = optimized_params[:size_hp]\n",
    "        H_q = optimized_params[size_hp:2*size_hp]\n",
    "        gamma_P_MIN = optimized_params[2*size_hp:2*size_hp + self.A.shape[0]]\n",
    "        gamma_Q_MIN = optimized_params[2*size_hp + self.A.shape[0]:2*size_hp + 2*self.A.shape[0]]\n",
    "        bias_Min = optimized_params[2*size_hp + 2*self.A.shape[0]:]\n",
    "\n",
    "        print(f'Best H_p {self.TEST_CASE}bus:\\n', H_p)\n",
    "        print(f'Best H_q {self.TEST_CASE}bus:\\n', H_q)\n",
    "        print(f'Best gamma_P {self.TEST_CASE}bus:\\n', gamma_P_MIN)\n",
    "        print(f'Best gamma_Q {self.TEST_CASE}bus:\\n', gamma_Q_MIN)\n",
    "        print(f'Best bias {self.TEST_CASE}bus\\n:', bias_Min)\n",
    "\n",
    "        np.savetxt(f\"{self.PATH}/parameters/H_p_{self.TEST_CASE}bus_{self.OPTIMIZATION_METHOD}.txt\", H_p, fmt='%f')\n",
    "        np.savetxt(f\"{self.PATH}/parameters/H_q_{self.TEST_CASE}bus_{self.OPTIMIZATION_METHOD}.txt\", H_q, fmt='%f')\n",
    "        np.savetxt(f\"{self.PATH}/parameters/gamma_P_{self.TEST_CASE}bus_{self.OPTIMIZATION_METHOD}.txt\", gamma_P_MIN, fmt='%f')\n",
    "        np.savetxt(f\"{self.PATH}/parameters/gamma_Q_{self.TEST_CASE}bus_{self.OPTIMIZATION_METHOD}.txt\", gamma_Q_MIN, fmt='%f')\n",
    "        np.savetxt(f\"{self.PATH}/parameters/bias_{self.TEST_CASE}bus_{self.OPTIMIZATION_METHOD}.txt\", bias_Min, fmt='%f')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_case = '37'  # Replace with '13' if needed\n",
    "    optimization_method = 'TNC'\n",
    "    path = '/Users/babaktaheri/Desktop/OLDF/Multi-phase'\n",
    "    \n",
    "    optimizer = OLDFWithBlockDiagonal(test_case, optimization_method, path)\n",
    "    optimizer.run_optimization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00933de4",
   "metadata": {},
   "source": [
    "# Read uniform scenarios and make them ready for testing LinDist3Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class LoadScenarioGeneration:\n",
    "    def __init__(self, dss_file, output_dir=\"results\", S_base=500):\n",
    "        self.dss_file = dss_file\n",
    "        self.output_dir = output_dir\n",
    "        self.S_base = S_base\n",
    "        self.load_data = []\n",
    "        self.bus_index = {}\n",
    "        self.reference_bus = None\n",
    "        self.P_scenarios = {}\n",
    "        self.Q_scenarios = {}\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        logging.basicConfig(filename=os.path.join(self.output_dir, 'log.txt'), level=logging.INFO)\n",
    "\n",
    "    def load_system(self):\n",
    "        try:\n",
    "            dss.run_command(f'Redirect \"{self.dss_file}\"')\n",
    "            dss.Solution.Solve()\n",
    "            logging.info(f'Successfully loaded and solved DSS file: {self.dss_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading DSS file: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_line_data(self, line_data_file):\n",
    "        try:\n",
    "            with open(line_data_file, \"r\") as f:\n",
    "                self.line_data = json.load(f)\n",
    "            logging.info(f'Successfully loaded line data from {line_data_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def generate_bus_index_from_lines(self):\n",
    "        try:\n",
    "            buses = []  # Use a list to maintain the order\n",
    "            seen_buses = set()  # Helper set to avoid duplicates while maintaining order\n",
    "            for line, data in self.line_data.items():\n",
    "                bus1 = data['FromBus']\n",
    "                bus2 = data['ToBus']\n",
    "                if bus1 not in seen_buses:\n",
    "                    buses.append(bus1)\n",
    "                    seen_buses.add(bus1)\n",
    "                if bus2 not in seen_buses:\n",
    "                    buses.append(bus2)\n",
    "                    seen_buses.add(bus2)\n",
    "\n",
    "            self.bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "\n",
    "            # Identify reference bus (typically the first one unless specified otherwise)\n",
    "            self.reference_bus = buses[0] if buses else None\n",
    "            logging.info('Successfully generated bus index from line data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error generating bus index from line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_scenarios(self, test_case):\n",
    "        try:\n",
    "            self.P_scenarios = np.load(os.path.join(self.output_dir, f\"P_OpenDSS_uniform_{test_case}.npy\"), allow_pickle=True).item()\n",
    "            self.Q_scenarios = np.load(os.path.join(self.output_dir, f\"Q_OpenDSS_uniform_{test_case}.npy\"), allow_pickle=True).item()\n",
    "\n",
    "            logging.info(f'Successfully loaded scenarios for {test_case}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading scenarios: {e}')\n",
    "            raise\n",
    "\n",
    "    def extract_load_data(self):\n",
    "        try:\n",
    "            loads = dss.Loads.AllNames()\n",
    "            for load in loads:\n",
    "                dss.Loads.Name(load)\n",
    "                bus = dss.CktElement.BusNames()[0].split('.')[0]  # Get only the base bus name\n",
    "                phases = dss.Loads.Phases()\n",
    "                conn = 'Delta' if dss.Loads.IsDelta() else 'Wye'\n",
    "                kV = dss.Loads.kV()\n",
    "\n",
    "                P_scenarios = self.P_scenarios.get(load, [])\n",
    "                Q_scenarios = self.Q_scenarios.get(load, [])\n",
    "\n",
    "                for scenario_idx in range(len(P_scenarios)):\n",
    "                    P = P_scenarios[scenario_idx]\n",
    "                    Q = Q_scenarios[scenario_idx]\n",
    "                    #print(f\"Load: {load}, Scenario: {scenario_idx}, P: {P}, Q: {Q}\")\n",
    "\n",
    "                    S = np.sqrt(P**2 + Q**2)  # Apparent power\n",
    "                    power_factor = P / S if S != 0 else 1.0  # Power factor\n",
    "\n",
    "                    if bus in self.bus_index:  # Ensure the bus is part of the indexed buses\n",
    "                        self.load_data.append({\n",
    "                            'name': load,\n",
    "                            'bus': bus,\n",
    "                            'phases': phases,\n",
    "                            'connection': conn,\n",
    "                            'P': P,\n",
    "                            'Q': Q,\n",
    "                            'kV': kV,\n",
    "                            'power_factor': power_factor,\n",
    "                            'bus_full': dss.CktElement.BusNames()[0],  # Full bus name with phases\n",
    "                            'scenario': scenario_idx\n",
    "                        })\n",
    "            logging.info('Successfully extracted load data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error extracting load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def organize_power_data(self):\n",
    "        try:\n",
    "            scenario_count = len(next(iter(self.P_scenarios.values())))  # Assuming uniform scenario counts\n",
    "            P_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "            Q_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "\n",
    "            for scenario_idx in range(scenario_count):\n",
    "                for load in self.load_data:\n",
    "                    if load['scenario'] == scenario_idx:\n",
    "                        bus = load['bus']\n",
    "                        connection = load['connection']\n",
    "                        phase_indices = [int(phase) - 1 for phase in load['bus_full'].split('.')[1:] if phase.isdigit()]\n",
    "\n",
    "                        P = load['P']\n",
    "                        Q = load['Q']\n",
    "\n",
    "                        if connection == 'Delta' and len(phase_indices) == 3:\n",
    "                            # If three-phase Delta, distribute the load evenly across all three phases\n",
    "                            for phase in phase_indices:\n",
    "                                P_bus_phase[bus][scenario_idx][phase] = P / 3\n",
    "                                Q_bus_phase[bus][scenario_idx][phase] = Q / 3\n",
    "                        else:\n",
    "                            # Otherwise, assign all the load to the first appearing phase\n",
    "                            if phase_indices:\n",
    "                                first_phase_index = phase_indices[0]\n",
    "                                P_bus_phase[bus][scenario_idx][first_phase_index] = P\n",
    "                                Q_bus_phase[bus][scenario_idx][first_phase_index] = Q\n",
    "\n",
    "            logging.info('Successfully organized power data')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error organizing power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def convert_to_pu(self, P_bus_phase, Q_bus_phase):\n",
    "        try:\n",
    "            P_bus_phase_pu = {bus: P / self.S_base for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase_pu = {bus: Q / self.S_base for bus, Q in Q_bus_phase.items()}\n",
    "            logging.info('Successfully converted power data to per unit values')\n",
    "            return P_bus_phase_pu, Q_bus_phase_pu\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to per unit values: {e}')\n",
    "            raise\n",
    "\n",
    "    def remove_reference_bus_columns(self, P_bus_phase, Q_bus_phase):\n",
    "        try:\n",
    "            if self.reference_bus in P_bus_phase:\n",
    "                del P_bus_phase[self.reference_bus]\n",
    "            if self.reference_bus in Q_bus_phase:\n",
    "                del Q_bus_phase[self.reference_bus]\n",
    "            logging.info(f'Successfully removed reference bus {self.reference_bus} from power data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error removing reference bus from power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_power_data(self, P_bus_phase, Q_bus_phase, suffix=\"\", test_case=\"\"):\n",
    "        try:\n",
    "            P_bus_phase = {bus: P.tolist() for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase = {bus: Q.tolist() for bus, Q in Q_bus_phase.items()}\n",
    "\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_uniform{suffix}.json\"), \"w\") as fp:\n",
    "                json.dump(P_bus_phase, fp, indent=4)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_uniform{suffix}.json\"), \"w\") as fq:\n",
    "                json.dump(Q_bus_phase, fq, indent=4)\n",
    "            logging.info(f'P and Q data saved to {self.output_dir} as {suffix}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_load_data(self, test_case=\"\"):\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_load_data.json\"), \"w\") as fl:\n",
    "                json.dump(self.load_data, fl, indent=4)\n",
    "            logging.info(f'Load data saved to {self.output_dir}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_power_data(self, suffix=\"\", test_case=\"\"):\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_uniform{suffix}.json\"), \"r\") as fp:\n",
    "                P_bus_phase = json.load(fp)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_uniform{suffix}.json\"), \"r\") as fq:\n",
    "                Q_bus_phase = json.load(fq)\n",
    "            logging.info(f'Successfully loaded power data with suffix {suffix}')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def power_data_to_matrix(self, power_data, scenario_idx):\n",
    "        power_matrix = np.zeros((len(self.bus_index) - 1, 3))  # Adjust for removed reference bus\n",
    "        try:\n",
    "            for bus, idx in self.bus_index.items():\n",
    "                if bus != self.reference_bus and bus in power_data:\n",
    "                    power_matrix[idx - (1 if idx > self.bus_index[self.reference_bus] else 0), :] = power_data[bus][scenario_idx]\n",
    "            logging.info('Successfully converted power data to matrix')\n",
    "            return power_matrix\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to matrix: {e}')\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        #TestCase = '13Bus'\n",
    "        TestCase = '37Bus'\n",
    "\n",
    "        #simulator = LoadScenarioGeneration(dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/IEEE13Nodeckt.dss\", S_base=500.0)\n",
    "        simulator = LoadScenarioGeneration(dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/ieee37.dss\", S_base=500.0)\n",
    "\n",
    "        simulator.load_system()\n",
    "        simulator.load_line_data(line_data_file=f\"results/{TestCase}_line_data.json\")  # Update with correct file path\n",
    "        simulator.generate_bus_index_from_lines()\n",
    "        simulator.load_scenarios(TestCase)\n",
    "        simulator.extract_load_data()\n",
    "        P_bus_phase, Q_bus_phase = simulator.organize_power_data()\n",
    "        \n",
    "        # Remove reference bus columns\n",
    "        simulator.remove_reference_bus_columns(P_bus_phase, Q_bus_phase)\n",
    "\n",
    "        # Convert to per unit values\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.convert_to_pu(P_bus_phase, Q_bus_phase)\n",
    "        \n",
    "        simulator.save_power_data(P_bus_phase, Q_bus_phase, suffix=\"\", test_case=TestCase)\n",
    "        simulator.save_power_data(P_bus_phase_pu, Q_bus_phase_pu, suffix=\"_pu\", test_case=TestCase)\n",
    "        simulator.save_load_data(test_case=TestCase)\n",
    "\n",
    "        P_bus_phase, Q_bus_phase = simulator.load_power_data(suffix=\"\", test_case=TestCase)\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.load_power_data(suffix=\"_pu\", test_case=TestCase)\n",
    "\n",
    "        # Example: Displaying the power data matrix for the first scenario (index 0)\n",
    "        scenario_idx = 0\n",
    "        P_matrix = simulator.power_data_to_matrix(P_bus_phase, scenario_idx)\n",
    "        Q_matrix = simulator.power_data_to_matrix(Q_bus_phase, scenario_idx)\n",
    "        P_matrix_pu = simulator.power_data_to_matrix(P_bus_phase_pu, scenario_idx)\n",
    "        Q_matrix_pu = simulator.power_data_to_matrix(Q_bus_phase_pu, scenario_idx)\n",
    "\n",
    "        #print(f\"P matrix for scenario {scenario_idx} (in kW):\\n\", P_matrix)\n",
    "        #print(f\"Q matrix for scenario {scenario_idx} (in kVar):\\n\", Q_matrix)\n",
    "        #print(f\"P matrix for scenario {scenario_idx} (in pu):\\n\", P_matrix_pu)\n",
    "        #print(f\"Q matrix for scenario {scenario_idx} (in pu):\\n\", Q_matrix_pu)\n",
    "        print(\"Bus index:\\n\", simulator.bus_index)\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in main execution: {e}')\n",
    "        print(f'Error in main execution: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a46fb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "\n",
    "class OLDFTesting:\n",
    "    def __init__(self, test_case='37', optimization_method='TNC', path='/Users/babaktaheri/Desktop/OLDF/Multi-phase'):\n",
    "        self.test_case = test_case\n",
    "        self.optimization_method = optimization_method\n",
    "        self.path = path\n",
    "        self.dss_master_file_path = f\"{self.path}/data/IEEETestCases/{self.test_case}Bus/ieee37.dss\"\n",
    "        #self.reference_voltages = np.array([1.056, 1.0374, 1.056]) #IEEE 13Bus\n",
    "        self.reference_voltages = np.array([0.9890, 1.0245, 1.0146])  # IEEE 37 Bus\n",
    "        self.load_system()\n",
    "        self.line_data = self.load_line_data_from_json(f\"{self.path}/results/{self.test_case}Bus_line_data.json\")\n",
    "        self.buses, self.phases, self.bus_index = self.extract_buses_and_phases(self.line_data)\n",
    "        self.incidence_matrix = self.create_incidence_matrix(self.buses, self.phases, self.bus_index, self.line_data)\n",
    "        self.incidence_df = self.prepare_incidence_df(self.incidence_matrix, self.buses, self.phases, self.line_data)\n",
    "        self.A, self.F = self.compute_pseudo_inverse(self.incidence_df)\n",
    "        self.block_diagonal_matrix_hp, self.block_diagonal_matrix_hq, self.P_data, self.Q_data = self.load_data_from_files()\n",
    "        self.scen_start = 1\n",
    "        self.scen_final = 10000\n",
    "        self.H_p = self.block_diagonal_matrix_hp\n",
    "        self.H_q = self.block_diagonal_matrix_hq\n",
    "        self.rho = np.zeros(self.A.shape[0])\n",
    "        self.varrho = np.zeros(self.A.shape[0])\n",
    "        self.gamma = np.zeros(self.A.shape[0])\n",
    "\n",
    "    def load_system(self):\n",
    "        dss.run_command(\"Clear\")\n",
    "        dss.run_command(f'Redirect \"{self.dss_master_file_path}\"')\n",
    "        if dss.Circuit.Name() == \"\":\n",
    "            raise Exception(\"No active circuit. Please check the DSS master file.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_line_data_from_json(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            line_data = json.load(file)\n",
    "        return line_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_buses_and_phases(line_data):\n",
    "        buses = []\n",
    "        phases = {'1', '2', '3'}\n",
    "        seen_buses = set()\n",
    "        for line_info in line_data.values():\n",
    "            bus1_base = line_info['FromBus'].split('.')[0]\n",
    "            bus2_base = line_info['ToBus'].split('.')[0]\n",
    "            if bus1_base not in seen_buses:\n",
    "                buses.append(bus1_base)\n",
    "                seen_buses.add(bus1_base)\n",
    "            if bus2_base not in seen_buses:\n",
    "                buses.append(bus2_base)\n",
    "                seen_buses.add(bus2_base)\n",
    "        bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "        return buses, phases, bus_index\n",
    "\n",
    "    @staticmethod\n",
    "    def create_incidence_matrix(buses, phases, bus_index, line_data):\n",
    "        incidence_matrix = np.zeros((len(buses) * len(phases), len(line_data) * len(phases)), dtype=int)\n",
    "        for line_idx, (line_id, line_info) in enumerate(line_data.items()):\n",
    "            bus1 = line_info['FromBus']\n",
    "            bus2 = line_info['ToBus']\n",
    "            bus1_phases = line_info['Bus1Phases']\n",
    "            bus2_phases = line_info['Bus2Phases']\n",
    "            for phase in phases:\n",
    "                if phase in bus1_phases:\n",
    "                    row_idx_bus1 = bus_index[bus1] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus1, line_idx * 3 + int(phase) - 1] = 1\n",
    "                if phase in bus2_phases:\n",
    "                    row_idx_bus2 = bus_index[bus2] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus2, line_idx * 3 + int(phase) - 1] = -1\n",
    "        return incidence_matrix.T\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_incidence_df(incidence_matrix, buses, phases, line_data):\n",
    "        incidence_df = pd.DataFrame(incidence_matrix, columns=[f\"{bus}.{phase}\" for bus in buses for phase in phases])\n",
    "        incidence_df.index = [f\"{line_name}.{phase}\" for line_name in line_data.keys() for phase in phases]\n",
    "        reference_bus = buses[0]\n",
    "        reference_columns = [f\"{reference_bus}.{phase}\" for phase in phases]\n",
    "        incidence_df.drop(columns=reference_columns, inplace=True)\n",
    "        return incidence_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_pseudo_inverse(incidence_df):\n",
    "        A = incidence_df.to_numpy()\n",
    "        F = np.linalg.pinv(A)\n",
    "        return A, F\n",
    "\n",
    "    def load_data_from_files(self):\n",
    "        block_diagonal_matrix_hp = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hp.npy')\n",
    "        block_diagonal_matrix_hq = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hq.npy')\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_P_LDF_uniform_pu.json', 'r') as f:\n",
    "            P_data = json.load(f)\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_Q_LDF_uniform_pu.json', 'r') as f:\n",
    "            Q_data = json.load(f)\n",
    "        return block_diagonal_matrix_hp, block_diagonal_matrix_hq, P_data, Q_data\n",
    "\n",
    "    @staticmethod\n",
    "    def LinDist3Flow(H_p, H_q, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, F, A, P_inj, Q_inj, V_AC, scenario_idx):\n",
    "        \"\"\"Compute the 3-phase LinDistFlow and sensitivities\"\"\"\n",
    "        H_p = H_p.reshape(3 * n_branches, 3 * n_branches)\n",
    "        H_q = H_q.reshape(3 * n_branches, 3 * n_branches)\n",
    "\n",
    "        gamma = gamma.reshape(n_buses_3ph, 1)\n",
    "        rho = rho.reshape(n_buses_3ph, 1)\n",
    "        varrho = varrho.reshape(n_buses_3ph, 1)\n",
    "        #Ref_V = np.array([1.056**2, 1.0374**2, 1.056**2])  # IEEE 13 BUS\n",
    "        Ref_V = np.array([0.9890**2, 1.0245**2, 1.0146**2])  # IEEE 37 Bus\n",
    "\n",
    "        Ref_V_expanded = np.tile(Ref_V, n_buses_3ph // 3).reshape(-1, 1)\n",
    "        v = Ref_V_expanded - F @ H_p @ F.T @ (-P_inj + rho) - F @ H_q @ F.T @ (-Q_inj + varrho) + gamma\n",
    "\n",
    "        P = A.T @ A\n",
    "        B = np.zeros((len(A), 1))\n",
    "        for i in range(len(A)):\n",
    "            if np.any(P[i, :] != 0):\n",
    "                B[i] = 1\n",
    "        v = np.multiply(B, v)\n",
    "        v_AC = np.array(V_AC[f\"scenario_{scenario_idx}\"])\n",
    "        v_AC = v_AC[3:]  # delete the reference bus\n",
    "        v_AC = np.array(v_AC).reshape((n_buses_3ph, 1))\n",
    "        v = np.reshape(v, (n_buses_3ph, 1))\n",
    "\n",
    "        return v, v_AC\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_voltage_matrix(v, bus_index, A, reference_voltages):\n",
    "        V_matrix = np.ones((len(A) + 3, 1))\n",
    "        ref_bus_idx = 0\n",
    "        V_matrix[ref_bus_idx * 3:(ref_bus_idx + 1) * 3] = np.array(reference_voltages).reshape(-1, 1)\n",
    "        start_idx = 0\n",
    "        for bus, idx in bus_index.items():\n",
    "            if idx > 0:\n",
    "                V_matrix[idx * 3:(idx + 1) * 3] = v[start_idx:start_idx + 3].reshape(-1, 1)\n",
    "                start_idx += 3\n",
    "        return V_matrix\n",
    "\n",
    "    def objective_function(self, H_p, H_q, rho, varrho, gamma, scen_start, scen_final):\n",
    "        V_LDF = []\n",
    "        V_DF = []\n",
    "        n_buses_3ph = self.A.shape[0]\n",
    "        n_branches = n_buses_3ph // 3\n",
    "\n",
    "        P_pu = np.array([values[scenario_idx] for values in self.P_data.values()])\n",
    "        Q_pu = np.array([values[scenario_idx] for values in self.Q_data.values()])\n",
    "\n",
    "        P_flat_pu = P_pu.flatten().reshape(-1, 1)\n",
    "        Q_flat_pu = Q_pu.flatten().reshape(-1, 1)\n",
    "\n",
    "        v_results, v_AC_results = zip(*Parallel(n_jobs=-1)(delayed(self.LinDist3Flow)(\n",
    "            H_p, H_q, gamma, rho, varrho, 0, n_buses_3ph, n_branches, self.F, self.A, P_flat_pu, Q_flat_pu, self.V_AC, s) for s in range(scen_start - 1, scen_final - 1)))\n",
    "\n",
    "        V_LDF = np.concatenate(v_results)\n",
    "        V_DF = np.concatenate(v_AC_results)\n",
    "\n",
    "        Batch_size = scen_final - scen_start\n",
    "\n",
    "        V_LDF = V_LDF ** 0.5\n",
    "\n",
    "        objective = (1 / Batch_size) * (1 / (n_buses_3ph)) * np.linalg.norm(V_LDF - V_DF, 1)\n",
    "        inf_norm_error = np.linalg.norm(V_LDF - V_DF, np.inf)\n",
    "\n",
    "        # objective = (1/(n_buses_3ph)) *(1/Batch_size)* np.sum((V_LDF-V_DF**2)**2)\n",
    "\n",
    "        return objective, inf_norm_error, V_LDF, V_DF\n",
    "\n",
    "    def run_optimization(self):\n",
    "        with open(f\"results/{self.test_case}Bus_uniform_voltages.json\", \"r\") as file:\n",
    "            self.V_AC = json.load(file)\n",
    "\n",
    "        \"\"\"Initial parameters\"\"\"\n",
    "        H_p      = block_diagonal_matrix_hp\n",
    "        H_q      = block_diagonal_matrix_hq\n",
    "        rho      = np.zeros(A.shape[0])\n",
    "        varrho   = np.zeros(A.shape[0])\n",
    "        gamma    = np.zeros(A.shape[0])\n",
    "    \n",
    "        \"\"\"Optimized parameters\"\"\"\n",
    "        #H_p = np.loadtxt(f\"{self.path}/parameters/H_p_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #H_q = np.loadtxt(f\"{self.path}/parameters/H_q_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #rho = np.loadtxt(f\"{self.path}/parameters/gamma_P_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #varrho = np.loadtxt(f\"{self.path}/parameters/gamma_Q_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #gamma = np.loadtxt(f\"{self.path}/parameters/bias_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "\n",
    "        H_p = H_p.flatten()\n",
    "        H_q = H_q.flatten()\n",
    "        rho = np.reshape(rho, (self.A.shape[0],))\n",
    "        varrho = np.reshape(varrho, (self.A.shape[0],))\n",
    "        gamma = np.reshape(gamma, (self.A.shape[0],))\n",
    "\n",
    "        start_time = time.process_time()\n",
    "\n",
    "        objective, inf_norm_error, V_LDF, V_DF = self.objective_function(H_p, H_q, rho, varrho, gamma, self.scen_start, self.scen_final)\n",
    "        print(f'Avg error {self.test_case} Bus: ', objective)\n",
    "        print(f'Max  Error: {inf_norm_error}')\n",
    "\n",
    "        end_time = time.process_time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f'Total execution time: {execution_time} seconds')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimizer = OLDFTesting()\n",
    "    optimizer.run_optimization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e54f0",
   "metadata": {},
   "source": [
    "# Read High load scenarios an makes them ready for testing high load LDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b856be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class LoadScenarioGeneration:\n",
    "    def __init__(self, dss_file, output_dir=\"results\", S_base=500.0):\n",
    "        self.dss_file = dss_file\n",
    "        self.output_dir = output_dir\n",
    "        self.S_base = S_base  # System base power in kVA (500 kVA)\n",
    "        self.load_data = []\n",
    "        self.bus_index = {}\n",
    "        self.reference_bus = None\n",
    "        self.P_scenarios = {}\n",
    "        self.Q_scenarios = {}\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        logging.basicConfig(filename=os.path.join(self.output_dir, 'log.txt'), level=logging.INFO)\n",
    "\n",
    "    def load_system(self):\n",
    "        try:\n",
    "            dss.run_command(f'Redirect \"{self.dss_file}\"')\n",
    "            dss.Solution.Solve()\n",
    "            logging.info(f'Successfully loaded and solved DSS file: {self.dss_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading DSS file: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_line_data(self, line_data_file):\n",
    "        try:\n",
    "            with open(line_data_file, \"r\") as f:\n",
    "                self.line_data = json.load(f)\n",
    "            logging.info(f'Successfully loaded line data from {line_data_file}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def generate_bus_index_from_lines(self):\n",
    "        try:\n",
    "            buses = []  # Use a list to maintain the order\n",
    "            seen_buses = set()  # Helper set to avoid duplicates while maintaining order\n",
    "            for line, data in self.line_data.items():\n",
    "                bus1 = data['FromBus']\n",
    "                bus2 = data['ToBus']\n",
    "                if bus1 not in seen_buses:\n",
    "                    buses.append(bus1)\n",
    "                    seen_buses.add(bus1)\n",
    "                if bus2 not in seen_buses:\n",
    "                    buses.append(bus2)\n",
    "                    seen_buses.add(bus2)\n",
    "\n",
    "            self.bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "\n",
    "            # Identify reference bus (typically the first one unless specified otherwise)\n",
    "            self.reference_bus = buses[0] if buses else None\n",
    "            logging.info('Successfully generated bus index from line data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error generating bus index from line data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_scenarios(self, test_case):\n",
    "        try:\n",
    "            self.P_scenarios = np.load(os.path.join(self.output_dir, f\"P_high_load_{test_case}.npy\"), allow_pickle=True).item()\n",
    "            self.Q_scenarios = np.load(os.path.join(self.output_dir, f\"Q_high_load_{test_case}.npy\"), allow_pickle=True).item()\n",
    "\n",
    "            # Debug prints\n",
    "            #print(\"Loaded P_scenarios:\")\n",
    "            #for load, scenarios in self.P_scenarios.items():\n",
    "                #print(f\"{load}: {scenarios}\")\n",
    "\n",
    "            #print(\"\\nLoaded Q_scenarios:\")\n",
    "            #for load, scenarios in self.Q_scenarios.items():\n",
    "                #print(f\"{load}: {scenarios}\")\n",
    "\n",
    "            logging.info(f'Successfully loaded scenarios for {test_case}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading scenarios: {e}')\n",
    "            raise\n",
    "\n",
    "    def extract_load_data(self):\n",
    "        try:\n",
    "            loads = dss.Loads.AllNames()\n",
    "            for load in loads:\n",
    "                dss.Loads.Name(load)\n",
    "                bus = dss.CktElement.BusNames()[0].split('.')[0]  # Get only the base bus name\n",
    "                phases = dss.Loads.Phases()\n",
    "                conn = 'Delta' if dss.Loads.IsDelta() else 'Wye'\n",
    "                kV = dss.Loads.kV()\n",
    "\n",
    "                P_scenarios = self.P_scenarios.get(load, [])\n",
    "                Q_scenarios = self.Q_scenarios.get(load, [])\n",
    "\n",
    "                for scenario_idx in range(len(P_scenarios)):\n",
    "                    P = P_scenarios[scenario_idx]\n",
    "                    Q = Q_scenarios[scenario_idx]\n",
    "                    #print(f\"Load: {load}, Scenario: {scenario_idx}, P: {P}, Q: {Q}\")\n",
    "\n",
    "                    S = np.sqrt(P**2 + Q**2)  # Apparent power\n",
    "                    power_factor = P / S if S != 0 else 1.0  # Power factor\n",
    "\n",
    "                    if bus in self.bus_index:  # Ensure the bus is part of the indexed buses\n",
    "                        self.load_data.append({\n",
    "                            'name': load,\n",
    "                            'bus': bus,\n",
    "                            'phases': phases,\n",
    "                            'connection': conn,\n",
    "                            'P': P,\n",
    "                            'Q': Q,\n",
    "                            'kV': kV,\n",
    "                            'power_factor': power_factor,\n",
    "                            'bus_full': dss.CktElement.BusNames()[0],  # Full bus name with phases\n",
    "                            'scenario': scenario_idx\n",
    "                        })\n",
    "            logging.info('Successfully extracted load data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error extracting load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def organize_power_data(self):\n",
    "        try:\n",
    "            scenario_count = len(next(iter(self.P_scenarios.values())))  # Assuming uniform scenario counts\n",
    "            P_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "            Q_bus_phase = {bus: np.zeros((scenario_count, 3)) for bus in self.bus_index}\n",
    "\n",
    "            for scenario_idx in range(scenario_count):\n",
    "                for load in self.load_data:\n",
    "                    if load['scenario'] == scenario_idx:\n",
    "                        bus = load['bus']\n",
    "                        connection = load['connection']\n",
    "                        phase_indices = [int(phase) - 1 for phase in load['bus_full'].split('.')[1:] if phase.isdigit()]\n",
    "\n",
    "                        P = load['P']\n",
    "                        Q = load['Q']\n",
    "\n",
    "                        if connection == 'Delta' and len(phase_indices) == 3:\n",
    "                            # If three-phase Delta, distribute the load evenly across all three phases\n",
    "                            for phase in phase_indices:\n",
    "                                P_bus_phase[bus][scenario_idx][phase] = P / 3\n",
    "                                Q_bus_phase[bus][scenario_idx][phase] = Q / 3\n",
    "                        else:\n",
    "                            # Otherwise, assign all the load to the first appearing phase\n",
    "                            if phase_indices:\n",
    "                                first_phase_index = phase_indices[0]\n",
    "                                P_bus_phase[bus][scenario_idx][first_phase_index] = P\n",
    "                                Q_bus_phase[bus][scenario_idx][first_phase_index] = Q\n",
    "\n",
    "            logging.info('Successfully organized power data')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error organizing power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def convert_to_pu(self, P_bus_phase, Q_bus_phase):\n",
    "        try:\n",
    "            P_bus_phase_pu = {bus: P / self.S_base for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase_pu = {bus: Q / self.S_base for bus, Q in Q_bus_phase.items()}\n",
    "            logging.info('Successfully converted power data to per unit values')\n",
    "            return P_bus_phase_pu, Q_bus_phase_pu\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to per unit values: {e}')\n",
    "            raise\n",
    "\n",
    "    def remove_reference_bus_columns(self, P_bus_phase, Q_bus_phase):\n",
    "        try:\n",
    "            if self.reference_bus in P_bus_phase:\n",
    "                del P_bus_phase[self.reference_bus]\n",
    "            if self.reference_bus in Q_bus_phase:\n",
    "                del Q_bus_phase[self.reference_bus]\n",
    "            logging.info(f'Successfully removed reference bus {self.reference_bus} from power data')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error removing reference bus from power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_power_data(self, P_bus_phase, Q_bus_phase, suffix=\"\", test_case=\"\"):\n",
    "        try:\n",
    "            P_bus_phase = {bus: P.tolist() for bus, P in P_bus_phase.items()}\n",
    "            Q_bus_phase = {bus: Q.tolist() for bus, Q in Q_bus_phase.items()}\n",
    "\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_High{suffix}.json\"), \"w\") as fp:\n",
    "                json.dump(P_bus_phase, fp, indent=4)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_High{suffix}.json\"), \"w\") as fq:\n",
    "                json.dump(Q_bus_phase, fq, indent=4)\n",
    "            logging.info(f'P and Q data saved to {self.output_dir} as {suffix}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def save_load_data(self, test_case=\"\"):\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_load_data.json\"), \"w\") as fl:\n",
    "                json.dump(self.load_data, fl, indent=4)\n",
    "            logging.info(f'Load data saved to {self.output_dir}')\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error saving load data: {e}')\n",
    "            raise\n",
    "\n",
    "    def load_power_data(self, suffix=\"\", test_case=\"\"):\n",
    "        try:\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_P_LDF_High{suffix}.json\"), \"r\") as fp:\n",
    "                P_bus_phase = json.load(fp)\n",
    "            with open(os.path.join(self.output_dir, f\"{test_case}_Q_LDF_High{suffix}.json\"), \"r\") as fq:\n",
    "                Q_bus_phase = json.load(fq)\n",
    "            logging.info(f'Successfully loaded power data with suffix {suffix}')\n",
    "            return P_bus_phase, Q_bus_phase\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error loading power data: {e}')\n",
    "            raise\n",
    "\n",
    "    def power_data_to_matrix(self, power_data, scenario_idx):\n",
    "        power_matrix = np.zeros((len(self.bus_index) - 1, 3))  # Adjust for removed reference bus\n",
    "        try:\n",
    "            for bus, idx in self.bus_index.items():\n",
    "                if bus != self.reference_bus and bus in power_data:\n",
    "                    power_matrix[idx - (1 if idx > self.bus_index[self.reference_bus] else 0), :] = power_data[bus][scenario_idx]\n",
    "            logging.info('Successfully converted power data to matrix')\n",
    "            return power_matrix\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error converting power data to matrix: {e}')\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        TestCase = '13Bus'\n",
    "        TestCase = '37Bus'\n",
    "\n",
    "        #simulator = LoadScenarioGeneration(dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/IEEE13Nodeckt.dss\", S_base=500.0)\n",
    "        simulator = LoadScenarioGeneration(dss_file=f\"/Users/babaktaheri/Desktop/OLDF/Multi-phase/data/IEEETestCases/{TestCase}/ieee37.dss\", S_base=500.0)\n",
    "\n",
    "        simulator.load_system()\n",
    "        simulator.load_line_data(line_data_file=f\"results/{TestCase}_line_data.json\")  # Update with correct file path\n",
    "        simulator.generate_bus_index_from_lines()\n",
    "        simulator.load_scenarios(TestCase)\n",
    "        simulator.extract_load_data()\n",
    "        P_bus_phase, Q_bus_phase = simulator.organize_power_data()\n",
    "        \n",
    "        # Remove reference bus columns\n",
    "        simulator.remove_reference_bus_columns(P_bus_phase, Q_bus_phase)\n",
    "\n",
    "        # Convert to per unit values\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.convert_to_pu(P_bus_phase, Q_bus_phase)\n",
    "        \n",
    "        simulator.save_power_data(P_bus_phase, Q_bus_phase, suffix=\"\", test_case=TestCase)\n",
    "        simulator.save_power_data(P_bus_phase_pu, Q_bus_phase_pu, suffix=\"_pu\", test_case=TestCase)\n",
    "        simulator.save_load_data(test_case=TestCase)\n",
    "\n",
    "        P_bus_phase, Q_bus_phase = simulator.load_power_data(suffix=\"\", test_case=TestCase)\n",
    "        P_bus_phase_pu, Q_bus_phase_pu = simulator.load_power_data(suffix=\"_pu\", test_case=TestCase)\n",
    "\n",
    "        # Example: Displaying the power data matrix for the first scenario (index 0)\n",
    "        scenario_idx = 0\n",
    "        P_matrix = simulator.power_data_to_matrix(P_bus_phase, scenario_idx)\n",
    "        Q_matrix = simulator.power_data_to_matrix(Q_bus_phase, scenario_idx)\n",
    "        P_matrix_pu = simulator.power_data_to_matrix(P_bus_phase_pu, scenario_idx)\n",
    "        Q_matrix_pu = simulator.power_data_to_matrix(Q_bus_phase_pu, scenario_idx)\n",
    "\n",
    "        #print(f\"P matrix for scenario {scenario_idx} (in kW):\\n\", P_matrix)\n",
    "        #print(f\"Q matrix for scenario {scenario_idx} (in kVar):\\n\", Q_matrix)\n",
    "        #print(f\"P matrix for scenario {scenario_idx} (in pu):\\n\", P_matrix_pu)\n",
    "        #print(f\"Q matrix for scenario {scenario_idx} (in pu):\\n\", Q_matrix_pu)\n",
    "        print(\"Bus index:\\n\", simulator.bus_index)\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error in main execution: {e}')\n",
    "        print(f'Error in main execution: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b5b01",
   "metadata": {},
   "source": [
    "# High Load Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f02c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from opendssdirect import dss\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "\n",
    "class VoltageProfileOptimizer:\n",
    "    def __init__(self, test_case='37', optimization_method='TNC', path='/Users/babaktaheri/Desktop/OLDF/Multi-phase'):\n",
    "        self.test_case = test_case\n",
    "        self.optimization_method = optimization_method\n",
    "        self.path = path\n",
    "        self.dss_master_file_path = f\"{self.path}/data/IEEETestCases/{self.test_case}Bus/ieee37.dss\"\n",
    "        #self.reference_voltages = np.array([1.056, 1.0374, 1.056]) #IEEE 13Bus\n",
    "        self.reference_voltages = np.array([0.9890, 1.0245, 1.0146])  # IEEE 37 Bus\n",
    "        self.load_system()\n",
    "        self.line_data = self.load_line_data_from_json(f\"{self.path}/results/{self.test_case}Bus_line_data.json\")\n",
    "        self.buses, self.phases, self.bus_index = self.extract_buses_and_phases(self.line_data)\n",
    "        self.incidence_matrix = self.create_incidence_matrix(self.buses, self.phases, self.bus_index, self.line_data)\n",
    "        self.incidence_df = self.prepare_incidence_df(self.incidence_matrix, self.buses, self.phases, self.line_data)\n",
    "        self.A, self.F = self.compute_pseudo_inverse(self.incidence_df)\n",
    "        self.block_diagonal_matrix_hp, self.block_diagonal_matrix_hq, self.P_data, self.Q_data = self.load_data_from_files()\n",
    "        self.scen_start = 1\n",
    "        self.scen_final = 31\n",
    "        self.H_p = self.block_diagonal_matrix_hp\n",
    "        self.H_q = self.block_diagonal_matrix_hq\n",
    "        self.rho = np.zeros(self.A.shape[0])\n",
    "        self.varrho = np.zeros(self.A.shape[0])\n",
    "        self.gamma = np.zeros(self.A.shape[0])\n",
    "\n",
    "    def load_system(self):\n",
    "        dss.run_command(\"Clear\")\n",
    "        dss.run_command(f'Redirect \"{self.dss_master_file_path}\"')\n",
    "        if dss.Circuit.Name() == \"\":\n",
    "            raise Exception(\"No active circuit. Please check the DSS master file.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_line_data_from_json(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            line_data = json.load(file)\n",
    "        return line_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_buses_and_phases(line_data):\n",
    "        buses = []\n",
    "        phases = {'1', '2', '3'}\n",
    "        seen_buses = set()\n",
    "        for line_info in line_data.values():\n",
    "            bus1_base = line_info['FromBus'].split('.')[0]\n",
    "            bus2_base = line_info['ToBus'].split('.')[0]\n",
    "            if bus1_base not in seen_buses:\n",
    "                buses.append(bus1_base)\n",
    "                seen_buses.add(bus1_base)\n",
    "            if bus2_base not in seen_buses:\n",
    "                buses.append(bus2_base)\n",
    "                seen_buses.add(bus2_base)\n",
    "        bus_index = {bus: i for i, bus in enumerate(buses)}\n",
    "        return buses, phases, bus_index\n",
    "\n",
    "    @staticmethod\n",
    "    def create_incidence_matrix(buses, phases, bus_index, line_data):\n",
    "        incidence_matrix = np.zeros((len(buses) * len(phases), len(line_data) * len(phases)), dtype=int)\n",
    "        for line_idx, (line_id, line_info) in enumerate(line_data.items()):\n",
    "            bus1 = line_info['FromBus']\n",
    "            bus2 = line_info['ToBus']\n",
    "            bus1_phases = line_info['Bus1Phases']\n",
    "            bus2_phases = line_info['Bus2Phases']\n",
    "            for phase in phases:\n",
    "                if phase in bus1_phases:\n",
    "                    row_idx_bus1 = bus_index[bus1] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus1, line_idx * 3 + int(phase) - 1] = 1\n",
    "                if phase in bus2_phases:\n",
    "                    row_idx_bus2 = bus_index[bus2] * 3 + int(phase) - 1\n",
    "                    incidence_matrix[row_idx_bus2, line_idx * 3 + int(phase) - 1] = -1\n",
    "        return incidence_matrix.T\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_incidence_df(incidence_matrix, buses, phases, line_data):\n",
    "        incidence_df = pd.DataFrame(incidence_matrix, columns=[f\"{bus}.{phase}\" for bus in buses for phase in phases])\n",
    "        incidence_df.index = [f\"{line_name}.{phase}\" for line_name in line_data.keys() for phase in phases]\n",
    "        reference_bus = buses[0]\n",
    "        reference_columns = [f\"{reference_bus}.{phase}\" for phase in phases]\n",
    "        incidence_df.drop(columns=reference_columns, inplace=True)\n",
    "        return incidence_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_pseudo_inverse(incidence_df):\n",
    "        A = incidence_df.to_numpy()\n",
    "        F = np.linalg.pinv(A)\n",
    "        return A, F\n",
    "\n",
    "    def load_data_from_files(self):\n",
    "        block_diagonal_matrix_hp = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hp.npy')\n",
    "        block_diagonal_matrix_hq = np.load(f'{self.path}/results/{self.test_case}Bus_block_diagonal_matrix_hq.npy')\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_P_LDF_High_pu.json', 'r') as f:\n",
    "            P_data = json.load(f)\n",
    "        with open(f'{self.path}/results/{self.test_case}Bus_Q_LDF_High_pu.json', 'r') as f:\n",
    "            Q_data = json.load(f)\n",
    "        return block_diagonal_matrix_hp, block_diagonal_matrix_hq, P_data, Q_data\n",
    "\n",
    "    @staticmethod\n",
    "    def LinDist3Flow(H_p, H_q, gamma, rho, varrho, ref_bus, n_buses_3ph, n_branches, F, A, P_inj, Q_inj, V_AC, scenario_idx):\n",
    "        \"\"\"Compute the 3-phase LinDistFlow and sensitivities\"\"\"\n",
    "        H_p = H_p.reshape(3 * n_branches, 3 * n_branches)\n",
    "        H_q = H_q.reshape(3 * n_branches, 3 * n_branches)\n",
    "\n",
    "        gamma = gamma.reshape(n_buses_3ph, 1)\n",
    "        rho = rho.reshape(n_buses_3ph, 1)\n",
    "        varrho = varrho.reshape(n_buses_3ph, 1)\n",
    "        # Ref_V = np.array([1.056**2, 1.0374**2, 1.056**2]) #IEEE 13Bus\n",
    "        Ref_V = np.array([0.9890**2, 1.0245**2, 1.0146**2])  # IEEE 37 Bus\n",
    "\n",
    "        Ref_V_expanded = np.tile(Ref_V, n_buses_3ph // 3).reshape(-1, 1)\n",
    "        v = Ref_V_expanded - F @ H_p @ F.T @ (-P_inj + rho) - F @ H_q @ F.T @ (-Q_inj + varrho) + gamma\n",
    "\n",
    "        P = A.T @ A\n",
    "        B = np.zeros((len(A), 1))\n",
    "        for i in range(len(A)):\n",
    "            if np.any(P[i, :] != 0):\n",
    "                B[i] = 1\n",
    "        v = np.multiply(B, v)\n",
    "        v_AC = np.array(V_AC[f\"scenario_{scenario_idx}\"])\n",
    "        v_AC = v_AC[3:]  # delete the reference bus\n",
    "        v_AC = np.array(v_AC).reshape((n_buses_3ph, 1))\n",
    "        v = np.reshape(v, (n_buses_3ph, 1))\n",
    "\n",
    "        return v, v_AC\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_voltage_matrix(v, bus_index, A, reference_voltages):\n",
    "        V_matrix = np.ones((len(A) + 3, 1))\n",
    "        ref_bus_idx = 0\n",
    "        V_matrix[ref_bus_idx * 3:(ref_bus_idx + 1) * 3] = np.array(reference_voltages).reshape(-1, 1)\n",
    "        start_idx = 0\n",
    "        for bus, idx in bus_index.items():\n",
    "            if idx > 0:\n",
    "                V_matrix[idx * 3:(idx + 1) * 3] = v[start_idx:start_idx + 3].reshape(-1, 1)\n",
    "                start_idx += 3\n",
    "        return V_matrix\n",
    "\n",
    "    def objective_function(self, H_p, H_q, rho, varrho, gamma, scen_start, scen_final):\n",
    "        V_LDF = []\n",
    "        V_DF = []\n",
    "        n_buses_3ph = self.A.shape[0]\n",
    "        n_branches = n_buses_3ph // 3\n",
    "\n",
    "        P_pu = np.array([values[scenario_idx] for values in self.P_data.values()])\n",
    "        Q_pu = np.array([values[scenario_idx] for values in self.Q_data.values()])\n",
    "\n",
    "        P_flat_pu = P_pu.flatten().reshape(-1, 1)\n",
    "        Q_flat_pu = Q_pu.flatten().reshape(-1, 1)\n",
    "\n",
    "        v_results, v_AC_results = zip(*Parallel(n_jobs=-1)(delayed(self.LinDist3Flow)(\n",
    "            H_p, H_q, gamma, rho, varrho, 0, n_buses_3ph, n_branches, self.F, self.A, P_flat_pu, Q_flat_pu, self.V_AC, s) for s in range(scen_start - 1, scen_final - 1)))\n",
    "\n",
    "        V_LDF = np.concatenate(v_results)\n",
    "        V_DF = np.concatenate(v_AC_results)\n",
    "\n",
    "        Batch_size = scen_final - scen_start\n",
    "\n",
    "        V_LDF = V_LDF ** 0.5\n",
    "\n",
    "        objective = (1 / Batch_size) * (1 / (n_buses_3ph)) * np.linalg.norm(V_LDF - V_DF, 1)\n",
    "        inf_norm_error = np.linalg.norm(V_LDF - V_DF, np.inf)\n",
    "\n",
    "        # objective = (1/(n_buses_3ph)) *(1/Batch_size)* np.sum((V_LDF-V_DF**2)**2)\n",
    "\n",
    "        return objective, inf_norm_error, V_LDF, V_DF\n",
    "\n",
    "    def run_optimization(self):\n",
    "        with open(f\"results/{self.test_case}Bus_High_voltages.json\", \"r\") as file:\n",
    "            self.V_AC = json.load(file)\n",
    "\n",
    "        \"\"\"Initial parameters\"\"\"\n",
    "        H_p      = block_diagonal_matrix_hp\n",
    "        H_q      = block_diagonal_matrix_hq\n",
    "        rho      = np.zeros(A.shape[0])\n",
    "        varrho   = np.zeros(A.shape[0])\n",
    "        gamma    = np.zeros(A.shape[0])    \n",
    "            \n",
    "        #H_p = np.loadtxt(f\"{self.path}/parameters/H_p_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #H_q = np.loadtxt(f\"{self.path}/parameters/H_q_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #rho = np.loadtxt(f\"{self.path}/parameters/gamma_P_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #varrho = np.loadtxt(f\"{self.path}/parameters/gamma_Q_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "        #gamma = np.loadtxt(f\"{self.path}/parameters/bias_{self.test_case}bus_{self.optimization_method}.txt\")\n",
    "\n",
    "        H_p = H_p.flatten()\n",
    "        H_q = H_q.flatten()\n",
    "        rho = np.reshape(rho, (self.A.shape[0],))\n",
    "        varrho = np.reshape(varrho, (self.A.shape[0],))\n",
    "        gamma = np.reshape(gamma, (self.A.shape[0],))\n",
    "\n",
    "        start_time = time.process_time()\n",
    "\n",
    "        objective, inf_norm_error, V_LDF, V_DF = self.objective_function(H_p, H_q, rho, varrho, gamma, self.scen_start, self.scen_final)\n",
    "        print(f'Avg error {self.test_case} Bus: ', objective)\n",
    "        print(f'Max  Error: {inf_norm_error}')\n",
    "\n",
    "        end_time = time.process_time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f'Total execution time: {execution_time} seconds')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimizer = VoltageProfileOptimizer()\n",
    "    optimizer.run_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
