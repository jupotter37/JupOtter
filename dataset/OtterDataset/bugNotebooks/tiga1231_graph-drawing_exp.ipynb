{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom\n",
    "import lovasz_losses as L\n",
    "\n",
    "## sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "## numeric\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## vis\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import collections  as mc\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "## notebook\n",
    "from IPython import display\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph_3d(ax, x, G, grad=None):\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2])\n",
    "    # ax.view_init(elev=20.0, azim=0)\n",
    "\n",
    "    edgeLines = [(x[e0][:3], x[e1][:3]) for e0,e1 in G.edges]\n",
    "    lc = Line3DCollection(edgeLines, linewidths=1)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    if grad is not None:\n",
    "        ax.quiver(x[:,0], x[:,1], x[:,2], \n",
    "                 -grad[:,0], -grad[:,1], -grad[:,2], length=4, colors='C1')\n",
    "    return ax\n",
    "\n",
    "def colorScale2cmap(domain, range1):\n",
    "    domain = np.array(domain)\n",
    "    domain = (domain-domain.min())/(domain.max()-domain.min())\n",
    "    range1 = np.array(range1)/255.0\n",
    "    \n",
    "    red = [r[0] for r in range1]\n",
    "    green = [r[1] for r in range1]\n",
    "    blue = [r[2] for r in range1]\n",
    "    red = tuple((d,r,r) for d,r in zip(domain, red))\n",
    "    green = tuple((d,r,r) for d,r in zip(domain, green))\n",
    "    blue = tuple((d,r,r) for d,r in zip(domain, blue))\n",
    "    return LinearSegmentedColormap('asdasdas', {'red':red, 'green': green, 'blue':blue})\n",
    "    \n",
    "colors = [\n",
    "    [44,52,179],\n",
    "    [0,0,0],\n",
    "    [174,33,57],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065/3\n",
    "def pairwise_distances(x, y=None, w=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    \n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is None:\n",
    "        y = x\n",
    "        y_t = y.t()\n",
    "        y_norm = x_norm\n",
    "    if w is not None:\n",
    "        x = x * w    \n",
    "        y = y * w    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    return torch.clamp(dist, 0.0, np.inf)\n",
    "\n",
    "\n",
    "def file2graph(fn='./facebook/0.edges'):\n",
    "    with open(fn) as f:\n",
    "        lines = [l.split()[:2] for l in f.readlines()]\n",
    "        edges = [tuple(int(i) for i in l) for l in lines]\n",
    "        nodes = set(sum(edges, ())) ## SLOW?\n",
    "#         edges += [(-1, n) for n in nodes]\n",
    "#         nodes.update({-1})\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(nodes))\n",
    "    G.add_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "\n",
    "def dict2tensor(d, fill=None):\n",
    "    n = len(d.keys())\n",
    "    k2i = {k:i for i,k in enumerate(sorted(d.keys()))}\n",
    "    res = torch.zeros(len(d.keys()), len(d.keys()), device=device)\n",
    "    for src_node, dst_nodes in d.items():\n",
    "        for dst_node, distance in dst_nodes.items():\n",
    "            if fill is not None:\n",
    "                res[k2i[src_node],k2i[dst_node]] = fill\n",
    "            else:\n",
    "                res[k2i[src_node],k2i[dst_node]] = distance\n",
    "    return res, k2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stress_minimization(X, D, Adj, optimizer, max_iter=10):\n",
    "#     def stress(x, d, adjacency):\n",
    "#         pdist = pairwise_distances(x)\n",
    "#         s = ((pdist - d)**2).mean()\n",
    "#         return s\n",
    "\n",
    "#     for i in range(max_iter):\n",
    "#         s = stress(X, D, Adj)\n",
    "#         s.backward()\n",
    "#         optimizer.step()\n",
    "#         X.grad.data.fill_(0)\n",
    "#     return X, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard index: 0.5\n",
      " jaccard loss: 0.5\n",
      "  lovasz loss: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "def neighbor_preservation_bce(X, Adj, optimizer, max_iter=10, w=None):\n",
    "    \n",
    "    sigmoid = nn.Sigmoid()\n",
    "    neighborSizes = Adj.sum(dim=1).int()\n",
    "    nodeCount = Adj.shape[0]\n",
    "    \n",
    "    def euclidean_neighbor(x):\n",
    "        pdist = pairwise_distances(x, w=w)\n",
    "        res = torch.zeros([x.shape[0],x.shape[0]], device=device)\n",
    "        for i, [distances, ns] in enumerate(zip(pdist, neighborSizes)):\n",
    "#             print(distances.shape, nodeCount, ns.item())\n",
    "            topk = distances.topk(nodeCount-ns.item())\n",
    "            thresh = topk.values[-2:].mean()\n",
    "            scale = 2.0\n",
    "            res[i,:] = 1-sigmoid((distances-thresh) * scale)\n",
    "        return res\n",
    "\n",
    "    bce = nn.BCELoss()\n",
    "#     jaccard_loss = L.lovasz_softmax\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        if X.grad is not None:\n",
    "            X.grad.data.fill_(0)\n",
    "        pred = euclidean_neighbor(X)\n",
    "        truth = Adj\n",
    "        eye = torch.eye(pred.shape[0], device=device)\n",
    "        pred *= (1-eye)\n",
    "        loss = bce(pred, truth)\n",
    "#         loss = jaccard_loss(pred.view(1,*pred.shape), truth, classes=[1])\n",
    "        loss.backward()\n",
    "        X.grad.data[X.grad.data.abs()>0.01].sign_() ## (optional) fast gradient sign method\n",
    "        optimizer.step()\n",
    "        \n",
    "    return X, loss, pred\n",
    "\n",
    "\n",
    "\n",
    "def neighbor_preservation_jaccard(X, Adj, optimizer, max_iter=10, w=None):\n",
    "    \n",
    "    sigmoid = nn.Sigmoid()\n",
    "    neighborSizes = Adj.sum(dim=1).int()\n",
    "    nodeCount = Adj.shape[0]\n",
    "\n",
    "    def model(x):\n",
    "        pdist = pairwise_distances(x, w=w)\n",
    "        maxDist = pdist.max()\n",
    "        res = torch.zeros([x.shape[0], x.shape[0]], device=device)\n",
    "        for i, [distances, ns] in enumerate(zip(pdist, neighborSizes)):\n",
    "            topk = distances.topk(nodeCount-ns.item())\n",
    "            thresh = topk.values[-2:].mean()\n",
    "            res[i,:] = thresh - pdist[i,:]\n",
    "        return res\n",
    "\n",
    "#     jaccard_loss = lovasz(hingeError) #option 3 (slow and does not work as expected)\n",
    "    jaccard_loss = L.lovasz_hinge #option 4 the official lovasz hinge!\n",
    "    \n",
    "    eye = torch.eye(Adj.shape[0], device=device)\n",
    "    truth = Adj + eye\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        if X.grad is not None:\n",
    "            X.grad.data.fill_(0)\n",
    "        pred = model(X)\n",
    "#         pred *= (1-eye)\n",
    "        loss = jaccard_loss(pred.view(-1), truth.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return X, loss, pred\n",
    "\n",
    "\n",
    "relu = nn.ReLU()\n",
    "def hingeError(logits, target):\n",
    "    logits = logits*2-1\n",
    "    target = target*2-1\n",
    "    return relu(1-logits*target)\n",
    "\n",
    "\n",
    "def lovasz(error_func=hingeError):\n",
    "    def jaccardLoss(error, target):\n",
    "        union = (error+target)#.clamp(0,1)\n",
    "        if error.sum()==0:\n",
    "            return torch.tensor(0.0)\n",
    "        else:\n",
    "            return error.sum() / union.sum()\n",
    "    \n",
    "    def f(logits, target):\n",
    "        error = error_func(logits, target)\n",
    "        sorted_error = torch.sort(error)\n",
    "        values, indices = sorted_error.values, sorted_error.indices\n",
    "        loss = 0\n",
    "        jaccardLosses = []\n",
    "        for i in range(0,values.shape[0]+1):\n",
    "            error_i = error.clone()\n",
    "            error_i[indices[:i]] = 0\n",
    "            error_i[indices[i:]] = 1\n",
    "            jl = jaccardLoss(error_i, target)\n",
    "            jaccardLosses.append(jl)\n",
    "        \n",
    "        for i in range(values.shape[0], 0, -1):\n",
    "            jl0 = jaccardLosses[i]\n",
    "            jl1 = jaccardLosses[i-1]\n",
    "            weight = values[i-1]\n",
    "            margin = jl1 - jl0\n",
    "            loss += weight * margin\n",
    "        return loss\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "## test:\n",
    "def jaccardIndex(pred, target):\n",
    "    intersect = pred*target\n",
    "    union = (pred+target).clamp(0,1)\n",
    "    if intersect.sum() == 0:\n",
    "        return torch.tensor(0.0)\n",
    "    else:\n",
    "        return intersect.sum() / union.sum()\n",
    "\n",
    "logits = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "target = torch.tensor([1.0, 1.0])\n",
    "f = lovasz()\n",
    "# f = L.lovasz_hinge\n",
    "\n",
    "print('jaccard index:', jaccardIndex(logits, target).item())\n",
    "print(' jaccard loss:', 1-jaccardIndex(logits, target).item())\n",
    "print('  lovasz loss:', f(logits, target).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## test\n",
    "\n",
    "# ground_truth = torch.tensor([0.0, 0.0])\n",
    "# steps = 19\n",
    "# x,y = np.meshgrid(np.linspace(-2,2,steps).astype('float32'), np.linspace(-2,2,steps).astype('float32'))\n",
    "# z = []\n",
    "# for logits in np.c_[x.ravel(), y.ravel()]:\n",
    "#     logits = torch.tensor(logits, requires_grad=True)\n",
    "#     loss = f(logits, ground_truth).item()\n",
    "#     z.append(loss)\n",
    "# z = np.array(z)\n",
    "\n",
    "# x = x.reshape([steps,steps])\n",
    "# y = y.reshape([steps,steps])\n",
    "# z = z.reshape([steps,steps])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')\n",
    "# ax.plot_surface(x,y,z, cmap='viridis')\n",
    "# ax.view_init(elev=20.0, azim=210)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph...\n",
      "calculating all pairs shortest path...\n",
      "40 nodes\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 112 ms, sys: 436 µs, total: 112 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('generating graph...')\n",
    "# G = nx.path_graph(10)\n",
    "# G = nx.cycle_graph(10)\n",
    "G = nx.balanced_tree(3,3)\n",
    "# G = nx.connected_watts_strogatz_graph(10,5,0.5)\n",
    "# G = file2graph('./facebook/0.edges')\n",
    "\n",
    "print('calculating all pairs shortest path...')\n",
    "D,k2i = dict2tensor(dict(nx.all_pairs_shortest_path_length(G)))\n",
    "Adj,_ = dict2tensor(dict(G.adjacency()), fill=1)\n",
    "\n",
    "print(len(G.nodes), 'nodes')\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize via Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r fig\n",
    "!mkdir fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(len(G.nodes), 3, requires_grad = True, device=device)\n",
    "\n",
    "# stress_optimizer = optim.SGD([X], lr=0.01)\n",
    "# neighbor_optimizer = optim.SGD([X], lr=0.03) ## works for cycle graph, jaccard loss\n",
    "# neighbor_optimizer = optim.SGD([X], lr=0.5)## for jaccard loss\n",
    "# neighbor_optimizer = optim.SGD([X], lr=0.5)## for bce loss\n",
    "neighbor_optimizer = optim.Adam([X], lr=0.1)## for bce loss\n",
    "lossHistory = []\n",
    "\n",
    "# def schedule(i, n):\n",
    "#     return np.exp(-i/n*2)\n",
    "# niter = 200\n",
    "# i=np.linspace(0, niter, niter+1)\n",
    "# plt.plot(i, schedule(i, niter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e55c1cb2124ec4812f9a152bf1d9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6263233423233032\n",
      "max grad: 0.02267475612461567\n",
      "loss: 0.45497316122055054\n",
      "max grad: 0.03127071261405945\n",
      "loss: 0.33995646238327026\n",
      "max grad: 0.03460439294576645\n",
      "loss: 0.2924215495586395\n",
      "max grad: 0.016093028709292412\n",
      "loss: 0.27986443042755127\n",
      "max grad: 0.011121461167931557\n",
      "loss: 0.2693791687488556\n",
      "max grad: 0.009518582373857498\n",
      "loss: 0.260297030210495\n",
      "max grad: 0.010846502147614956\n",
      "loss: 0.2529999017715454\n",
      "max grad: 0.010002418421208858\n",
      "loss: 0.24558748304843903\n",
      "max grad: 0.010891210287809372\n",
      "loss: 0.2384827733039856\n",
      "max grad: 0.011976135894656181\n",
      "loss: 0.23078852891921997\n",
      "max grad: 0.00683437567204237\n",
      "loss: 0.2230801284313202\n",
      "max grad: 0.011432328261435032\n",
      "loss: 0.21376268565654755\n",
      "max grad: 0.008773665875196457\n",
      "loss: 0.20523102581501007\n",
      "max grad: 0.008309494704008102\n",
      "loss: 0.19592680037021637\n",
      "max grad: 0.007674236781895161\n",
      "loss: 0.18805405497550964\n",
      "max grad: 0.014590760692954063\n",
      "loss: 0.17981551587581635\n",
      "max grad: 0.010350048542022705\n",
      "loss: 0.172564297914505\n",
      "max grad: 0.008708300068974495\n",
      "loss: 0.16365912556648254\n",
      "max grad: 0.0074388450011610985\n",
      "loss: 0.15572796761989594\n",
      "max grad: 0.0077348011545836926\n",
      "loss: 0.15061353147029877\n",
      "max grad: 0.008617699146270752\n",
      "loss: 0.14752808213233948\n",
      "max grad: 0.006578057538717985\n",
      "loss: 0.14604006707668304\n",
      "max grad: 0.00917777605354786\n",
      "loss: 0.14486970007419586\n",
      "max grad: 0.008604073897004128\n",
      "loss: 0.14187057316303253\n",
      "max grad: 0.008916891179978848\n",
      "loss: 0.13844914734363556\n",
      "max grad: 0.0070914579555392265\n",
      "loss: 0.13639967143535614\n",
      "max grad: 0.007388184778392315\n",
      "loss: 0.13351847231388092\n",
      "max grad: 0.00900823064148426\n",
      "loss: 0.13159722089767456\n",
      "max grad: 0.0069768731482326984\n",
      "loss: 0.12986034154891968\n",
      "max grad: 0.011530471965670586\n",
      "loss: 0.12839442491531372\n",
      "max grad: 0.006282879039645195\n",
      "loss: 0.12655717134475708\n",
      "max grad: 0.00781542994081974\n",
      "loss: 0.12415696680545807\n",
      "max grad: 0.005067105870693922\n",
      "loss: 0.12091051042079926\n",
      "max grad: 0.006452338770031929\n",
      "loss: 0.11756012588739395\n",
      "max grad: 0.00989852286875248\n",
      "loss: 0.11343813687562943\n",
      "max grad: 0.00814933143556118\n",
      "loss: 0.10919002443552017\n",
      "max grad: 0.007010926958173513\n",
      "loss: 0.10639480501413345\n",
      "max grad: 0.0100599629804492\n",
      "loss: 0.10399966686964035\n",
      "max grad: 0.005758068524301052\n",
      "loss: 0.10110385715961456\n",
      "max grad: 0.0080234594643116\n",
      "loss: 0.09756289422512054\n",
      "max grad: 0.007179310079663992\n",
      "loss: 0.09552635997533798\n",
      "max grad: 0.006497301161289215\n",
      "loss: 0.09250257909297943\n",
      "max grad: 0.006611555814743042\n",
      "loss: 0.09031788259744644\n",
      "max grad: 0.005955774337053299\n",
      "loss: 0.08745307475328445\n",
      "max grad: 0.006515106651932001\n",
      "loss: 0.08649880439043045\n",
      "max grad: 0.00650809658691287\n",
      "loss: 0.08416911214590073\n",
      "max grad: 0.008558863773941994\n",
      "loss: 0.08242706209421158\n",
      "max grad: 0.005955961067229509\n",
      "loss: 0.08124590665102005\n",
      "max grad: 0.00727042555809021\n",
      "loss: 0.08013460040092468\n",
      "max grad: 0.005892513319849968\n",
      "loss: 0.07898914068937302\n",
      "max grad: 0.005384655203670263\n",
      "loss: 0.07775265723466873\n",
      "max grad: 0.005693135317414999\n",
      "loss: 0.0762643814086914\n",
      "max grad: 0.0058732107281684875\n",
      "loss: 0.0748915746808052\n",
      "max grad: 0.006463040132075548\n",
      "loss: 0.07337233424186707\n",
      "max grad: 0.007978961803019047\n",
      "loss: 0.07311441749334335\n",
      "max grad: 0.006199564319103956\n",
      "loss: 0.07279742509126663\n",
      "max grad: 0.00747320894151926\n",
      "loss: 0.070914626121521\n",
      "max grad: 0.00900820828974247\n",
      "loss: 0.07044512778520584\n",
      "max grad: 0.0068612778559327126\n",
      "loss: 0.07039570063352585\n",
      "max grad: 0.009292639791965485\n",
      "loss: 0.06894249469041824\n",
      "max grad: 0.007957397028803825\n",
      "loss: 0.06857060641050339\n",
      "max grad: 0.006333520635962486\n",
      "loss: 0.0675467923283577\n",
      "max grad: 0.00560113787651062\n",
      "loss: 0.0676264539361\n",
      "max grad: 0.005796519573777914\n",
      "loss: 0.06730719655752182\n",
      "max grad: 0.006981080397963524\n",
      "loss: 0.06648863852024078\n",
      "max grad: 0.006827537901699543\n",
      "loss: 0.06652915477752686\n",
      "max grad: 0.008015681058168411\n",
      "loss: 0.06585801392793655\n",
      "max grad: 0.009023369289934635\n",
      "loss: 0.06596379727125168\n",
      "max grad: 0.006976038217544556\n",
      "loss: 0.0654434934258461\n",
      "max grad: 0.0055013056844472885\n",
      "loss: 0.0653906911611557\n",
      "max grad: 0.008042164146900177\n",
      "loss: 0.06500345468521118\n",
      "max grad: 0.0059439633041620255\n",
      "loss: 0.06518661975860596\n",
      "max grad: 0.006804437376558781\n",
      "loss: 0.06485159695148468\n",
      "max grad: 0.004830447491258383\n",
      "loss: 0.0648200735449791\n",
      "max grad: 0.006724604405462742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "niter = 150\n",
    "iterBar = tqdm(range(niter))\n",
    "for i in iterBar:\n",
    "    \n",
    "    ## option 1: stress minimization\n",
    "#     X, stress = stress_minimization(X, D, Adj, stress_optimizer, max_iter=10)\n",
    "\n",
    "    ## option 2: neighbor preservation\n",
    "#     w = torch.tensor([1.0, 1.0, schedule(i, niter), schedule(i, niter)], device=device)\n",
    "    X, loss, pred = neighbor_preservation_jaccard(X, Adj, neighbor_optimizer, max_iter=1, w=None)\n",
    "#     X, loss, pred = neighbor_preservation_bce(X, Adj, neighbor_optimizer, max_iter=5, w=None)\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        iterBar.set_postfix({'loss': loss.item()})\n",
    "    ## debug & vis\n",
    "    lossHistory.append(loss.item())\n",
    "#     if i%10==9:\n",
    "\n",
    "    if i%2==0:\n",
    "        x = X.detach().cpu().numpy()\n",
    "        grad = X.grad.data.cpu().numpy()\n",
    "        \n",
    "        print(f'loss: {loss.item()}')\n",
    "        print(f'max grad: {np.abs(grad).max()}')\n",
    "        \n",
    "        fig = plt.figure(figsize=[14,10])\n",
    "#         display.clear_output(wait=True)\n",
    "        \n",
    "        ## graph\n",
    "        if x.shape[1] == 2:\n",
    "            plt.subplot(221)\n",
    "            nx.draw_networkx(G, pos={k: x[k2i[k],:2] for k in G.nodes}, font_color='white')\n",
    "            plt.quiver(x[:,0], x[:,1], \n",
    "                       -grad[:,0], -grad[:,1], \n",
    "                       units='inches', label=f'neg grad (max={np.linalg.norm(grad, axis=1).max():.2e})')\n",
    "            plt.axis('equal')\n",
    "            plt.legend()  \n",
    "        else:\n",
    "            ax = fig.add_subplot(2,2,1, projection='3d')\n",
    "            ax = draw_graph_3d(ax, x, G, grad)\n",
    "        plt.title('epoch: {}'.format(i))\n",
    "\n",
    "        ## loss\n",
    "        plt.subplot(222)\n",
    "        plt.plot(lossHistory)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        ## pred vs truth\n",
    "        plt.subplot(234)\n",
    "        pdist = pairwise_distances(X)\n",
    "        pdist = pdist.detach().cpu()\n",
    "        plt.imshow(pdist.max()-pdist-np.eye(pdist.shape[0]))\n",
    "        plt.title('max - distance')\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.subplot(235)\n",
    "        pred = pred.detach().cpu()\n",
    "        vmax = min(pred.max(), -pred.min())\n",
    "        cmap = colorScale2cmap([-1, 0, 1], colors)\n",
    "        plt.imshow(pred, cmap=cmap, vmin=-1, vmax=1)\n",
    "        plt.title('Prediction')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(236)\n",
    "        cmap = colorScale2cmap([0, 0.5, 1], colors)\n",
    "        plt.imshow(Adj.detach().cpu(), cmap=cmap)\n",
    "        plt.colorbar()\n",
    "        plt.title('Ground Truth')\n",
    "        \n",
    "        plt.savefig(f'fig/epoch{i}.png')\n",
    "        plt.close()\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "\n",
    "# Create the frames\n",
    "frames = []\n",
    "imgs = natsorted(glob('fig/*.png'))\n",
    "\n",
    "for img in imgs:\n",
    "    new_frame = Image.open(img)\n",
    "    frames.append(new_frame)\n",
    "\n",
    "# Save into a GIF file that loops forever\n",
    "frames[0].save('anim6.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=60, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# from natsort import natsorted\n",
    "# from glob import glob\n",
    "\n",
    "# fig = plt.figure(figsize=[14,10])\n",
    "\n",
    "# ims = []\n",
    "# for fn in natsorted(glob('fig/epoch*.png')):\n",
    "#     im = imageio.imread(fn)\n",
    "#     im = plt.imshow(im, animated=True)\n",
    "#     ims.append([im])\n",
    "\n",
    "# ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "#                                 repeat_delay=1000)\n",
    "\n",
    "# # ani.save('dynamic_images.mp4')\n",
    "\n",
    "# display.HTML(ani.to_jshtml())\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph...\n",
      "calculating all pairs shortest path...\n",
      "100 nodes\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 645 ms, sys: 3.89 ms, total: 649 ms\n",
      "Wall time: 647 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('generating graph...')\n",
    "# G = nx.path_graph(10)\n",
    "G = nx.cycle_graph(100)\n",
    "# G = nx.balanced_tree(3,4)\n",
    "# G = nx.connected_watts_strogatz_graph(10,5,0.5)\n",
    "# G = file2graph('./facebook/0.edges')\n",
    "\n",
    "print('calculating all pairs shortest path...')\n",
    "D,k2i = dict2tensor(dict(nx.all_pairs_shortest_path_length(G)))\n",
    "Adj,_ = dict2tensor(dict(G.adjacency()), fill=1)\n",
    "\n",
    "print(len(G.nodes), 'nodes')\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage2/mwli/envs/env3/lib/python3.6/site-packages/umap/umap_.py:1503: UserWarning: using precomputed metric; transform will be unavailable for new data and inverse_transform will be unavailable for all data\n",
      "  \"using precomputed metric; transform will be unavailable for new data and inverse_transform \"\n"
     ]
    }
   ],
   "source": [
    "# from umap import UMAP\n",
    "\n",
    "model = UMAP(metric='precomputed', unique=True, \n",
    "             min_dist=0.9,\n",
    "             n_neighbors=5, n_epochs=200)\n",
    "# dist = (1-Adj.cpu().numpy())*(1-np.eye(dist.shape[0]))\n",
    "# dist = torch.tanh(D).cpu().numpy()\n",
    "dist = (D**0.4).cpu().numpy()\n",
    "xy = model.fit_transform(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[8,8])\n",
    "nx.draw_networkx(G, pos={k: xy[k2i[k],:2] for k in G.nodes}, font_color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
