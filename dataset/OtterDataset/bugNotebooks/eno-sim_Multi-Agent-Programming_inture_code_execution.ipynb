{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from dotenv import load_dotenv\n",
    "from typing import Callable\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Global generation config\n",
    "GENERATION_CONFIG = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 1000,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name: str, system_instruction: str):\n",
    "        self.id = str(uuid.uuid4())\n",
    "        self.name = name\n",
    "        self.system_instruction = system_instruction\n",
    "        self.memory: List[Dict[str, Any]] = [] # Memory should be overridden in the subclass\n",
    "\n",
    "    # TO BE OVERRIDDEN\n",
    "    def process_message(self, message: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        raise NotImplementedError(\"process_message method must be implemented in the subclass\")\n",
    "\n",
    "\n",
    "    def send_message(self, recipient: 'Agent', content: str):\n",
    "        return recipient.process_message(content)\n",
    "\n",
    "class GeminiAgent(Agent):\n",
    "    def __init__(self, name: str, system_instruction: str, end_condition = False, tools = []):\n",
    "        super().__init__(name, system_instruction)\n",
    "        self.model = self.create_gemini_model(tools=tools, system_instruction=system_instruction)\n",
    "        self.chat_session = self.model.start_chat(enable_automatic_function_calling=True)\n",
    "        self.memory = self.chat_session.history\n",
    "        self.end_condition = end_condition\n",
    "\n",
    "    def create_gemini_model(self, tools, system_instruction: str = \"\"):\n",
    "        return genai.GenerativeModel(\n",
    "            model_name=\"gemini-1.5-flash\",\n",
    "            generation_config=GENERATION_CONFIG,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            },\n",
    "            system_instruction=system_instruction,\n",
    "            tools=tools,\n",
    "        )\n",
    "    \n",
    "    def process_message(self, message: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Append user message to history\n",
    "        self.chat_session.history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [message],\n",
    "        })\n",
    "        \n",
    "        response = self.chat_session.send_message(message)\n",
    "        \n",
    "        # Append model response to history\n",
    "        self.chat_session.history.append({\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": [response.text],\n",
    "        })\n",
    "        \n",
    "        return response.text\n",
    "\n",
    "class UserAgent(Agent):\n",
    "    def __init__(self, name: str, system_instruction: str):\n",
    "        super().__init__(name, system_instruction)\n",
    "        self.memory = []\n",
    "\n",
    "    def process_message(self, message: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Append user message to history\n",
    "        #print(\"[debug:useragent] Do nothing for now\")\n",
    "        return \n",
    "    \n",
    "    def send_message(self, recipient: 'Agent', content: str):\n",
    "        if content.startswith(\"[input]\"):\n",
    "            input_content = input(content)\n",
    "        else:\n",
    "            input_content = content\n",
    "        message = input_content\n",
    "        # Append user message to memory\n",
    "        self.memory.append({\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [input_content],\n",
    "        })\n",
    "        return recipient.process_message(message)\n",
    "\n",
    "class Mediator:\n",
    "    def __init__(self):\n",
    "        self.agents: Dict[str, Agent] = {}\n",
    "        self.agents[\"user\"] = UserAgent(\"User\", \"\") # Add an user agent as a default agent\n",
    "\n",
    "    def add_agent(self, agent: Agent):\n",
    "        self.agents[agent.id] = agent\n",
    "\n",
    "    def get_agent(self, agent_id: str) -> Agent:\n",
    "        return self.agents.get(agent_id)\n",
    "\n",
    "    def send(self, sender_id: str, recipient_id: str, content: str):\n",
    "        sender = self.get_agent(sender_id)\n",
    "        recipient = self.get_agent(recipient_id)\n",
    "        if sender and recipient:\n",
    "            return sender.send_message(recipient, content)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sender or recipient ID\")\n",
    "    \n",
    "    def chat(self, sender_id: str, recipient_id: str, content: str, str_condition: str = \"\", max_turns: int = 4):\n",
    "        sender = self.get_agent(sender_id)\n",
    "        recipient = self.get_agent(recipient_id)\n",
    "        res_recipient = content\n",
    "        res_sender = \" \"\n",
    "        counter = 0\n",
    "        end = False\n",
    "    \n",
    "        # Repeat for max_turns or until recipient.end_condition is true\n",
    "        while counter < max_turns and not end:\n",
    "            res_recipient = self.send(sender_id, recipient_id, res_recipient if counter == 0 else res_sender)\n",
    "            print(f'[{recipient.name}]', res_recipient)\n",
    "            if str_condition and str_condition in res_recipient:\n",
    "                break\n",
    "            \n",
    "            if callable(getattr(recipient, 'end_condition', False)):\n",
    "                end = recipient.end_condition()\n",
    "            \n",
    "            if end:\n",
    "                break\n",
    "                \n",
    "            res_sender = self.send(recipient_id, sender_id, res_recipient)\n",
    "            print(f'[{sender.name}]', res_sender)\n",
    "            if str_condition and str_condition in res_sender:\n",
    "                break\n",
    "\n",
    "            # Check if receiver has a function as end_condition\n",
    "            if callable(getattr(sender, 'end_condition', False)):\n",
    "                end = sender.end_condition()\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        return res_sender\n",
    "    \n",
    "    def user_chat(self, sender_id: str, recipient_id: str, hint: str=\"Write your message\", str_condition: str = \"\",  max_turns: int = 4):\n",
    "        sender = self.get_agent(sender_id)\n",
    "        res_sender = self.send(\"user\", sender_id, hint)\n",
    "        print(f'[{sender.name}]', res_sender)\n",
    "        res = self.chat(sender_id, recipient_id, content=res_sender, str_condition=str_condition, max_turns=4)\n",
    "        return res\n",
    "    \n",
    "    def conductor_chat(self, sender_id: str, recipient_id: str, conductor_id: str, content: str, hint: str=\"Write your message\", max_turns: int = 4, independent: bool = False):\n",
    "        # Validate agents\n",
    "        sender = self.get_agent(sender_id)\n",
    "        recipient = self.get_agent(recipient_id)\n",
    "        conductor = self.get_agent(conductor_id)\n",
    "        if not sender or not recipient or not conductor:\n",
    "            raise ValueError(\"Invalid sender, recipient, or conductor ID\")\n",
    "        counter = 0\n",
    "        \n",
    "        res_sender = self.send(conductor_id, sender_id, content=content) # coductor_id is irrelevant\n",
    "        print(f'[{sender.name}]', res_sender)\n",
    "        res = res_sender\n",
    "\n",
    "        while counter < max_turns:\n",
    "            # Chat operations\n",
    "            res_filtered_sender = self.chat(sender_id, conductor_id, res, max_turns=max_turns)\n",
    "            res_filtered_recipient = self.chat(conductor_id, recipient_id, res_filtered_sender, max_turns=max_turns)\n",
    "            \n",
    "            # Update response based on the independent flag\n",
    "            res = \" \" if independent else res_filtered_recipient\n",
    "\n",
    "            counter += 1\n",
    "            print(f\"turn {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_executor = GeminiAgent(\n",
    "    name=\"Code Executor\",\n",
    "    system_instruction=\"Execute the code that is provided and return just the full code and the output.\"\n",
    "    \"If it is told you what you are doing is wrong, try to fix it and run the code again.\"\n",
    "    \"Do not explain nothing about the code, just execute it.\",\n",
    "    #tools=['code_execution']\n",
    ")\n",
    "\n",
    "code_verifier = GeminiAgent(\n",
    "    name=\"Code Verifier\",\n",
    "    system_instruction=\"Verify the output of the code that is provided.\"\n",
    "    \"If the output is correct, tell the user 'the code is correct.', otherwise, tell the user 'the code is incorrect.' and provide a short hint.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m\n\u001b[1;32m     27\u001b[0m fun_to_execute_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124mdef is_prime(n):\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mChecks if a number is prime.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124mis_prime(7)\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#res = mediator.user_chat(\"user\", code_executor.id, hint=\"Write a code snippet to execute\", str_condition=\"exit\", max_turns=1)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#res = mediator.chat(code_verifier.id, code_executor.id, content=f'The function to execute is this, run it like this do not edit: \\n${fun_to_execute_error}', str_condition=\"code is correct\", max_turns=8)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#res = mediator.send(\"user\", code_executor.id, content=f'The function to execute: \\n${fun_to_execute}')\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmediator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[0;32mIn[15], line 115\u001b[0m, in \u001b[0;36mMediator.send\u001b[0;34m(self, sender_id, recipient_id, content)\u001b[0m\n\u001b[1;32m    113\u001b[0m recipient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_agent(recipient_id)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sender \u001b[38;5;129;01mand\u001b[39;00m recipient:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid sender or recipient ID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 98\u001b[0m, in \u001b[0;36mUserAgent.send_message\u001b[0;34m(self, recipient, content)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Append user message to memory\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [input_content],\n\u001b[1;32m     97\u001b[0m })\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 67\u001b[0m, in \u001b[0;36mGeminiAgent.process_message\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Append user message to history\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_session\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [message],\n\u001b[1;32m     65\u001b[0m     })\n\u001b[0;32m---> 67\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Append model response to history\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_session\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response\u001b[38;5;241m.\u001b[39mtext],\n\u001b[1;32m     73\u001b[0m     })\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/generativeai/generative_models.py:578\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[0;32m--> 578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:827\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/nlp-project/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting"
     ]
    }
   ],
   "source": [
    "mediator = Mediator()\n",
    "\n",
    "mediator.add_agent(code_executor)\n",
    "mediator.add_agent(code_verifier)\n",
    "\n",
    "fun_to_execute = \"\"\"\n",
    "def is_prime(n):\n",
    "  \\\"\\\"\\\"Checks if a number is prime.\\\"\\\"\\\"\n",
    "  if n <= 1:\n",
    "    return False\n",
    "  for i in range(2, int(n**0.5) + 1):\n",
    "    if n % i == 0:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "is_prime(7)\n",
    "\"\"\"\n",
    "\n",
    "fun_2 = \"\"\"\n",
    "def sum(a, b):\n",
    "  \\\"\\\"\\\"Sums two numbers.\\\"\\\"\\\"\n",
    "  return a + b\n",
    "\n",
    "sum(2, 3)\n",
    "\"\"\"\n",
    "\n",
    "fun_to_execute_error = \"\"\"\n",
    "def is_prime(n):\n",
    "  \\\"\\\"\\\"Checks if a number is prime.\\\"\\\"\\\"\n",
    "  if n <= 1:\n",
    "    return False\n",
    "  for i in range(2, int(n**0.5) + 1):\n",
    "    if n % i == 0:\n",
    "      return True\n",
    "  return True\n",
    "\n",
    "is_prime(7)\n",
    "\"\"\"\n",
    "\n",
    "#res = mediator.user_chat(\"user\", code_executor.id, hint=\"Write a code snippet to execute\", str_condition=\"exit\", max_turns=1)\n",
    "#res = mediator.chat(code_verifier.id, code_executor.id, content=f'The function to execute is this, run it like this do not edit: \\n${fun_to_execute_error}', str_condition=\"code is correct\", max_turns=8)\n",
    "#res = mediator.send(\"user\", code_executor.id, content=f'The function to execute: \\n${fun_to_execute}')\n",
    "res = mediator.send(\"user\", code_executor.id, content=fun_2)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
