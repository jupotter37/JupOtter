{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9e901e-a366-464c-b2d0-b2807e332ff4",
   "metadata": {},
   "source": [
    "# Letterboxd movie and user data scraping project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e4b3bc-9e3f-43c2-894d-82d98caa828c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from base64 import b64decode\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "from typing import Any, Hashable\n",
    "\n",
    "from crawlbase import CrawlingAPI\n",
    "import requests\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049f124-0b29-4d2a-afa4-3e5245fbb4b6",
   "metadata": {},
   "source": [
    "## Helper functions, constants, and web scraping APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca724c9d-1cf7-42bc-b686-af4eb2974c28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions and constants\n",
    "\n",
    "WEB_PREFIX = 'https://letterboxd.com'\n",
    "USER_REVIEWS_PATH = os.path.join(os.getcwd(), 'user_reviews/')\n",
    "\n",
    "# keys for various web scraping APIs\n",
    "ZYTE_API_KEY = 'API_KEY'\n",
    "ZYTE_API_KET = 'API_KEY'\n",
    "\n",
    "CRAWLBASE_API_KEY = 'API_KEY'\n",
    "CRAWLBASE_API_KEY = 'API_KEY'\n",
    "\n",
    "SCRAPER_API_KEY = 'API_KEY'\n",
    "SCRAPER_API_KEY = 'API_KEY'\n",
    "\n",
    "WEBSCRAPERAPI_API_KEY = 'API_KEY'\n",
    "\n",
    "# converts a star rating to its float equivalent\n",
    "def convert_rating_to_float(rating):\n",
    "    int_rating = 0\n",
    "    for c in rating:\n",
    "        if c == '★':\n",
    "            int_rating += 1.0\n",
    "        if c == '½':\n",
    "            int_rating += 0.5\n",
    "\n",
    "    return int_rating\n",
    "\n",
    "# get a list of all users who have been scraped\n",
    "def get_used_users():\n",
    "    with open('used_users.txt', 'r') as u:\n",
    "        used_users = [line.split(',')[0].replace('\\n', '') for line in u.readlines()]\n",
    "    return used_users\n",
    "\n",
    "# returns True iff this user has been scraped already\n",
    "def is_user_used(user):\n",
    "    return user in get_used_users()\n",
    "\n",
    "# return a user using requests library\n",
    "def get_request(link):\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# return a request passed through Zyte API\n",
    "def get_request_zyte(link):\n",
    "    api_response = requests.post(\n",
    "        'https://api.zyte.com/v1/extract',\n",
    "        auth=(ZYTE_API_KEY, ''),\n",
    "        json={\n",
    "            'url': link,\n",
    "            'httpResponseBody': True,\n",
    "            },\n",
    "    )\n",
    "    http_response_body: bytes = b64decode(\n",
    "        api_response.json()['httpResponseBody']\n",
    "    )\n",
    "    \n",
    "    page = http_response_body.decode('utf-8')\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "# return a request passed through Crawlbase's Crawling API\n",
    "def get_request_crawlbase(link):\n",
    "    api = CrawlingAPI({'token': CRAWLBASE_API_KEY})\n",
    "    response = api.get(link)\n",
    "    if response['status_code'] == 200:\n",
    "        soup = BeautifulSoup(response['body'], 'html.parser')\n",
    "        return soup\n",
    "    raise Exception(f'Error: {response}')\n",
    "\n",
    "# return a request passed through\n",
    "def get_request_scraperapi(link):\n",
    "    params = {'api_key': SCRAPER_API_KEY, 'url': link}\n",
    "    response = requests.get('http://api.scraperapi.com/', params=parse.urlencode(params))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_request_webscrapingapi(link):\n",
    "    API_KEY = WEBSCRAPERAPI_API_KEY\n",
    "    scraper_url = 'https://api.webscrapingapi.com/v2'\n",
    "    \n",
    "    params = {\n",
    "        \"api_key\":WEBSCRAPINGAPI_API_KEY,\n",
    "        \"url\": link,\n",
    "    }\n",
    "    \n",
    "    response = requests.get(scraper_url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458162e-fcab-4abd-809f-26770d42ea20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Scraping Letterboxd reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1232fcd6-4d05-4755-8ca0-0b7285576fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes the diary provided at `link`\n",
    "def scrape_review(link, debug=False):\n",
    "    # review = requests.get(link)    \n",
    "    # soup = get_request_zyte(link)\n",
    "    # soup = get_request_crawlbase(link)\n",
    "    # soup = get_request_scraperapi(link)\n",
    "    soup = get_request(link)\n",
    "    \n",
    "    user = soup.find(class_='person-summary').find('a')['href'][1:-1]\n",
    "    movie = soup.find(class_='film-title-wrapper').find('a').get_text(strip=True)\n",
    "    movie_id = soup.find(class_='film-title-wrapper').find('a')['href'].split('/')[2]\n",
    "    movie_year = int(soup.find(class_='film-title-wrapper').find('small', class_='metadata').find('a').get_text(strip=True))\n",
    "\n",
    "    if debug:\n",
    "        print(f'[DEBUG] Scraping \"{movie}\" ({movie_year}) review for user {user}')\n",
    "    \n",
    "    watch_metadata = soup.find(class_='film-viewing-info-wrapper')\n",
    "\n",
    "    # get rating\n",
    "    rating_qualifier = watch_metadata.find('span', class_='rating')\n",
    "\n",
    "    try:\n",
    "        rating = convert_rating_to_float(rating_qualifier.get_text(strip=True))\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        rating = 0\n",
    "\n",
    "    # get other watch metadata\n",
    "    liked = 1 if type(watch_metadata.find('span', class_='has-icon')) is Tag else 0\n",
    "    when_watched = watch_metadata.find('meta', content=True)['content']\n",
    "    rewatched = 1 if 'Rewatched' in watch_metadata.find(class_='view-date date-links').get_text(strip=True) else 0\n",
    "\n",
    "    # get review\n",
    "    review_div = soup.find('div', class_='review body-text -prose -hero -loose')\n",
    "    review_text = ' '.join([p.get_text() for p in review_div.find_all('p')])\n",
    "    num_likes = int(soup.find('p', class_='like-link-target')['data-count'])\n",
    "\n",
    "    # get tags\n",
    "    tags_section = soup.find('ul', class_='tags')\n",
    "    if tags_section is not None:\n",
    "        tags = [t.get_text(strip=True) for t in tags_section.find_all('li')]\n",
    "    else:\n",
    "        tags = []\n",
    "\n",
    "    all_liked_reviews = soup.find('ul', id='liked-reviews')\n",
    "    liked_reviews = {}\n",
    "    \n",
    "    if all_liked_reviews is not None:\n",
    "        for r in all_liked_reviews.find_all('li'):\n",
    "                liked_review_rating = r.find('a').find(class_='rating')\n",
    "        if liked_review_rating is not None:\n",
    "            liked_review_rating = convert_rating_to_float(liked_review_rating.get_text(strip=True))\n",
    "        else:\n",
    "            liked_review_rating = 0\n",
    "        liked_reviews[r.find('a')['href']] = liked_review_rating\n",
    "\n",
    "    # getting the href link for this review\n",
    "    split_link = link.split('/')[3:]\n",
    "    review_link = ['']\n",
    "    review_link.extend(split_link)\n",
    "    review_link = '/'.join(review_link)\n",
    "    \n",
    "    result = {'user': user, \n",
    "              'movie': movie, \n",
    "              'movie_id': movie_id,\n",
    "              'movie_year': movie_year, \n",
    "              'rating': rating, \n",
    "              'liked': liked,\n",
    "              'when_watched': when_watched, \n",
    "              'rewatched': rewatched,\n",
    "              'review': review_text,\n",
    "              'num_likes': num_likes,\n",
    "              'tags': tags,\n",
    "              'liked_reviews': liked_reviews,\n",
    "              'review_link': review_link\n",
    "             }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2aaae-7829-4a15-a9d8-78f329dd895d",
   "metadata": {},
   "source": [
    "## Scraping Letterboxd diary - 50 most recent watched films"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736df5f9-9240-4c81-9717-5fe3a9867933",
   "metadata": {},
   "source": [
    "### Scrape user diary from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b87f533-e62a-4c6d-a058-436bcd222dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_diary(link, debug=False):\n",
    "    # soup = get_request_zyte(link)\n",
    "    # soup = get_request_crawlbase(link)\n",
    "    # soup = get_request_scraperapi(link)\n",
    "    soup = get_request(link)\n",
    "    table = soup.find('table', id='diary-table')\n",
    "    rows = []\n",
    "    curr_month = ''\n",
    "\n",
    "    # iterate each row in the table of diary entries\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        try:\n",
    "            user = soup.find(class_='profile-mini-person').find('a')['href'][1:-1]\n",
    "            \n",
    "            if debug:\n",
    "                print(f'[DEBUG] Loading diary for user {user}')\n",
    "                \n",
    "            movie = row.find('h3', class_='headline-3 prettify').get_text()\n",
    "            movie_id = row.find('h3', class_='headline-3 prettify').find('a')['href'].split('/')[3]\n",
    "            movie_year = int(row.find(class_='td-released center').get_text())\n",
    "        \n",
    "            # getting date due to weird date formatting on Letterboxd\n",
    "            month = row.find(class_='td-calendar').get_text().strip()\n",
    "            if month != '':\n",
    "                curr_month = month\n",
    "            else:\n",
    "                month = curr_month\n",
    "        \n",
    "            day = row.find(class_='td-day diary-day center').get_text(strip=True)\n",
    "            \n",
    "            date = str(day) + ' ' + month\n",
    "            when_watched = dt.datetime.strptime(date, '%d %b %Y').strftime('%Y-%m-%d')\n",
    "        \n",
    "            rewatched = 1 if type(row.find(class_='td-rewatch center')) == Tag else 0\n",
    "            rating = convert_rating_to_float(row.find(class_='hide-for-owner').find(class_='rating').get_text(strip=True))\n",
    "            liked = 1 if type(row.find(class_='has-icon icon-16 large-liked icon-liked hide-for-owner')) is Tag else 0\n",
    "            is_reviewed = type(row.find(class_='has-icon icon-review icon-16 tooltip')) is Tag\n",
    "\n",
    "            review_link = row.find('h3', class_='headline-3 prettify').find('a')['href']\n",
    "        \n",
    "            # if reviewed, scrape from review page\n",
    "            if is_reviewed:\n",
    "                review_link = WEB_PREFIX + row.find(class_='has-icon icon-review icon-16 tooltip')['href']\n",
    "                result = scrape_review(review_link)\n",
    "            else:\n",
    "                result = {'user': user,\n",
    "                          'movie': movie,\n",
    "                          'movie_id': movie_id,\n",
    "                          'movie_year': movie_year,\n",
    "                          'rating': rating,\n",
    "                          'liked': liked,\n",
    "                          'when_watched': when_watched,\n",
    "                          'rewatched': rewatched,\n",
    "                          'review': '',\n",
    "                          'num_likes': 0,\n",
    "                          'tags': [],\n",
    "                          'liked_reviews': {},\n",
    "                          'review_link': review_link\n",
    "                          }\n",
    "            rows.append(result)\n",
    "        except ValueError as e:\n",
    "            print(f'Error for movie {movie} for user {user}: {e} ({link})')\n",
    "            continue\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03f4da-7ac2-4737-bde9-df5019a7d63f",
   "metadata": {},
   "source": [
    "### Save user diary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2344640a-ed66-4b25-b8c6-6beaad335511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves `user`'s diary at the given page number, where the diary is sorted by review activity\n",
    "def save_user_diary(user, page, folder_name, debug=True):\n",
    "    diary_link = WEB_PREFIX + '/' + user + '/films/diary/page/' + str(page) + '/'\n",
    "        \n",
    "    file_path = f'{folder_name}/{user}_recent_reviews_{page}.json'\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\n[DEBUG] Loading diary for user {user}: {file_path}')\n",
    "    recent_50_watches = scrape_diary(diary_link)\n",
    "        \n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(recent_50_watches, json_file)\n",
    "\n",
    "    if debug:\n",
    "        print(f'[DEBUG] Saved to file {file_path}')\n",
    "        \n",
    "    return recent_50_watches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166dccf2-85e7-4faa-a7a3-196c93055819",
   "metadata": {},
   "source": [
    "## Scrape Letterboxd movie page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7558a38-a0bc-4db9-8d06-91f5e95f350b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scrape letterboxd homepage for a movie\n",
    "def scrape_letterboxd_movie_page(movie_name):\n",
    "    movie_link = WEB_PREFIX + '/film/' + movie_name\n",
    "    # soup = get_request_zyte(movie_link)\n",
    "    # soup = get_request_crawlbase(movie_link)\n",
    "    # soup = get_request_scraperapi(movie_link)\n",
    "    soup = get_request(movie_link)\n",
    "\n",
    "    # get basic movie details\n",
    "    movie_id = movie_name\n",
    "    movie_name = soup.find('h1', class_='headline-1 filmtitle').get_text()\n",
    "    movie_year = int(soup.find(class_='releaseyear').get_text())\n",
    "\n",
    "    # get tagline and description\n",
    "    has_tagline = soup.find(class_='tagline')\n",
    "    if has_tagline is not None:\n",
    "        movie_tagline = has_tagline.get_text()\n",
    "    else:\n",
    "        movie_tagline = ''\n",
    "\n",
    "    movie_desc = soup.find(class_='truncate')\n",
    "    if movie_desc is not None:\n",
    "        movie_desc = movie_desc.get_text(strip=True)\n",
    "    else:\n",
    "        movie_desc = ''\n",
    "\n",
    "    # get movie length and IMDB\n",
    "    details_footer = soup.find('p', class_='text-link text-footer')\n",
    "    \n",
    "    if details_footer is not None:\n",
    "        try:\n",
    "            movie_len = int(details_footer.get_text(strip=True).split('min')[0][:-1])\n",
    "        except ValueError:\n",
    "            movie_len = 0\n",
    "    else:\n",
    "        movie_len = 0\n",
    "\n",
    "    imdb_id = 0\n",
    "    tmdb_id = 0\n",
    "    \n",
    "    for id in details_footer.find_all('a'):\n",
    "        if id.get('data-track-action') == 'IMDb':\n",
    "            imdb_id = int(id['href'].split('/')[4][2:])\n",
    "        elif id.get('data-track-action') == 'TMDb':\n",
    "            try:\n",
    "                tmdb_id = int(id['href'].split('/')[4])\n",
    "            except IndexError:\n",
    "                tmdb_id = 0\n",
    "            \n",
    "\n",
    "    # get genres and top keywords\n",
    "    has_genres = soup.find(id='tab-genres')\n",
    "    if has_genres is not None:\n",
    "        has_genres = has_genres.find_all('div')\n",
    "        if len(has_genres) == 2:\n",
    "            genres_html = soup.find(id='tab-genres').find_all('div')[0]\n",
    "            genres = [g.get_text() for g in genres_html.find_all('a')]\n",
    "            \n",
    "            keywords_html = soup.find(id='tab-genres').find_all('div')[1]\n",
    "            top_keywords = [k.get_text() for k in keywords_html.find_all('a') if 'Show All' not in k.get_text()]\n",
    "        elif len(has_genres) == 1:\n",
    "            genres_html = soup.find(id='tab-genres').find_all('div')[0]\n",
    "            genres = [g.get_text() for g in genres_html.find_all('a')]\n",
    "            top_keywords = []\n",
    "        elif len(has_genres) > 2:\n",
    "            print(f'[DEBUG] PAGE FOR {movie_name} HAS ADDITIONAL INFO')\n",
    "    else:\n",
    "        top_keywords = []\n",
    "        genres = []\n",
    "\n",
    "    # get (if any) related films\n",
    "    has_collection = soup.find('section', id='related')\n",
    "    if has_collection is not None:\n",
    "        in_collection = 1\n",
    "        collection_name = has_collection.find('h2', class_='section-heading').find('a')['href'].split('/')[3]\n",
    "    else:\n",
    "        in_collection = 0\n",
    "        collection_name = ''\n",
    "\n",
    "    # get production details\n",
    "    prod_details = soup.find(id='tab-details')\n",
    "\n",
    "    studios = {}\n",
    "    countries = {}\n",
    "    primary_language = ''\n",
    "    spoken_languages = []\n",
    "    if prod_details is not None:\n",
    "        has_studios = prod_details.find('h3', string=lambda t: 'Studios' in t)\n",
    "        for detail in prod_details.find_all('a'):\n",
    "            details = detail['href'].split('/')\n",
    "            if details[1] == 'studio':\n",
    "                studios[details[2]] = detail.get_text(strip=True)\n",
    "            if details[2] == 'country':\n",
    "                countries[details[3]] = detail.get_text(strip=True)\n",
    "            if details[2] == 'language':\n",
    "                if primary_language == '':\n",
    "                    primary_language = detail.get_text(strip=True)\n",
    "                else:\n",
    "                    spoken_languages.append(detail.get_text(strip=True))\n",
    "\n",
    "    # get cast and crew\n",
    "    has_cast = soup.find(class_='cast-list')\n",
    "    if has_cast is not None:\n",
    "        cast = {c.get_text(): c.get('data-original-title') for c in has_cast.find_all('a') if 'Show All' not in c.get_text()}\n",
    "    else:\n",
    "        cast = {}\n",
    "\n",
    "    has_crew = soup.find(id='tab-crew')\n",
    "    if has_crew is not None:\n",
    "        crew_html = [c.find_all('a') for c in has_crew.find_all(class_='text-sluglist')]\n",
    "        crew = defaultdict(list)\n",
    "        \n",
    "        for line in crew_html:\n",
    "            role = line[0]['href'].split('/')[1]\n",
    "            for member in line:\n",
    "                crew[member.get_text()].append(role)\n",
    "        \n",
    "        crew = dict(crew)\n",
    "    else:\n",
    "        crew = {}\n",
    "    \n",
    "    result = {'movie_name': movie_name,\n",
    "              'movie_id': movie_id,\n",
    "              'movie_year': movie_year,\n",
    "              'movie_tagline': movie_tagline,\n",
    "              'movie_desc': movie_desc,\n",
    "              'movie_len': movie_len,\n",
    "              'genres': genres,\n",
    "              'top_keywords': top_keywords,\n",
    "              'in_collection': in_collection,\n",
    "              'collection_name': collection_name,\n",
    "              'studios': studios,\n",
    "              'countries': countries,\n",
    "              'primary_language': primary_language,\n",
    "              'spoken_langauges': spoken_languages,\n",
    "              'imdb_id': imdb_id,\n",
    "              'tmdb_id': tmdb_id,\n",
    "              'cast': cast,\n",
    "              'crew': crew\n",
    "              }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# get letterboxed-specific user-movie interaction stats from consumer data integration page\n",
    "def get_movie_interaction_stats(movie_name):\n",
    "    movie_link = WEB_PREFIX + '/csi/film/' + movie_name + '/stats/'\n",
    "    # soup = get_request_zyte(movie_link)\n",
    "    # soup = get_request_crawlbase(movie_link)\n",
    "    # soup = get_request_scraperapi(movie_link)\n",
    "    soup = get_request(movie_link)\n",
    "    num_watched = soup.find(class_='stat filmstat-watches').find('a')['title'][11:-8].replace(',', '')\n",
    "    num_listed = soup.find(class_='stat filmstat-lists').find('a')['title'][11:-6].replace(',', '')\n",
    "    num_liked = soup.find(class_='stat filmstat-likes').find('a')['title'][9:-8].replace(',', '')\n",
    "    top_250_rank = soup.find(class_='stat filmstat-top250')\n",
    "\n",
    "    if top_250_rank is not None:\n",
    "        top_250_rank = int(top_250_rank.find('a').get_text(strip=True))\n",
    "    else:\n",
    "        top_250_rank = 0\n",
    "    \n",
    "    result = {'num_watched': num_watched,\n",
    "              'num_listed': num_listed,\n",
    "              'num_liked': num_liked,\n",
    "              'top_250_rank': top_250_rank\n",
    "             }\n",
    "    return result\n",
    "\n",
    "# get letterboxd-specific user ratings for movies from consumer data integration page\n",
    "def get_movie_hist(movie_name):\n",
    "    movie_rating_dist_link = WEB_PREFIX + '/csi/film/' + movie_name + '/rating-histogram/'\n",
    "    # soup = get_request_zyte(movie_rating_dist_link)\n",
    "    # soup = get_request_crawlbase(movie_rating_dist_link)\n",
    "    # soup = get_request_scraperapi(movie_rating_dist_link)\n",
    "    soup = get_request(movie_rating_dist_link)\n",
    "    \n",
    "    hist_keys = ['num_half_star', 'num_one_star', 'num_one_half_star', 'num_two_star', 'num_two_half_star', \n",
    "                 'num_three_star', 'num_three_half_star', 'num_four_star', 'num_four_half_star', 'num_five_star']\n",
    "    hist_vals = []\n",
    "    for i in soup.find_all('li'):\n",
    "        value = i.get_text(strip=True)\n",
    "        if value != '':\n",
    "            hist_vals.append(int(value.split('\\xa0')[0].replace(',', '')))\n",
    "        else:\n",
    "            hist_vals.append(0)\n",
    "    \n",
    "    result = {pair[0]: pair[1] for pair in zip(hist_keys, hist_vals)}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# get all letterboxd data for a movie; scrapes three separate pages\n",
    "def get_letterboxd_stats(movie_name):\n",
    "    # get stats from a movie from homepage and CDI page\n",
    "    basic_movie_info = scrape_letterboxd_movie_page(movie_name)\n",
    "    movie_interaction_stats = get_movie_interaction_stats(movie_name)\n",
    "    movie_hist = get_movie_hist(movie_name)\n",
    "\n",
    "    # combine dictionaries\n",
    "    basic_movie_info.update(movie_interaction_stats)\n",
    "    basic_movie_info.update(movie_hist)\n",
    "\n",
    "    return basic_movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ad9fd-912e-4a19-87e0-230f1dab78c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Processing list of user IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165afe33-3048-407b-b51e-4190dc00fb89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### A list of user IDs from approximately the top 5000 reviewers on Letterboxd.com was scraped, and from each of those, (up to) the top 250 reviews for each user was collected into a set of 5 .json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a5d4a870-b709-4c78-b3b7-3916e3837807",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_data_copy = []\n",
    "for x in movie_data:\n",
    "    movie_data_copy.append(x)\n",
    "\n",
    "for i in range(len(movie_data_copy)):\n",
    "    for key, value in movie_data_copy[i].items():\n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                if isinstance(v, set):\n",
    "                    movie_data_copy[i][key][k] = list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ffda6f61-5dea-4fee-974d-943fba51e462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_movie_ids = []\n",
    "for id in all_movie_ids:\n",
    "    if id not in scraped_movie_ids:\n",
    "        unused_movie_ids.append(id)\n",
    "\n",
    "len(unused_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d35060-2e3f-4c99-804e-48c4f1e85c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of popular reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "885be9b4-ae45-4535-9cd9-9add7caff9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_users = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "57acb7de-a39c-49f7-aa8e-be03c981553f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, 1000):\n",
    "    pop_reviewers = f'https://letterboxd.com/reviewers/popular/page/{i}/'\n",
    "    soup = get_request(pop_reviewers)\n",
    "    unused_users.update(set([u['href'].replace('/', '') for u in soup.find_all(class_='avatar')]))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d626f510-b161-4b47-b63a-bcf66c14ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_users_list = list(unused_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "259d0284-3c5c-4de7-a825-00b299023158",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_use = []\n",
    "for u in unused_users_list:\n",
    "    if not is_user_used(u):\n",
    "        users_to_use.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "d501a36c-48ec-4f20-a0cf-872eaf8c25dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('users_to_use.txt', 'w') as f:\n",
    "    for user in users_to_use:\n",
    "        f.write(user + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "b9da8949-3a66-4f09-99b2-749f57f838d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unused_users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "884efdd8-5616-4714-ad4d-6d66373ab50b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('users_to_use.txt', 'r') as u:\n",
    "        users_to_use = [line.split(',')[0].replace('\\n', '') for line in u.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55bc2abc-edd1-4a41-8299-d053ef0beac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2831"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2d561f0-e7ed-49a4-99c2-cd3950af95a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['believeitornot',\n",
       " 'layanadelrey',\n",
       " 'ashleepradella',\n",
       " 'cinemaconsumer',\n",
       " 'mrmichaeldjones']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_to_use[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "979e94a8-5fea-45a8-9643-5d862070aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(users_to_use)):\n",
    "    if users_to_use[i] == 'jbouie':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c2e21ce-d852-497c-bbab-d8c197a0f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users_to_use.txt', 'w') as f:\n",
    "    for user in users_to_use:\n",
    "        f.write(user + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e960ac39-9c3d-49c4-a5f5-97a188f90c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(users_to_use)):\n",
    "    if users_to_use[i]=='jay525':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20e36ea3-c144-422e-af19-b37da371d6eb",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_1.json\n",
      "Error for movie Stiletto for user thejoelynch: invalid literal for int() with base 10: '' (https://letterboxd.com/thejoelynch/films/diary/page/1/)\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_2.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_3.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_4.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_5.json\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_6.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_7.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_8.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_9.json\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user thejoelynch: reviews_10/thejoelynch_recent_reviews_10.json\n",
      "[DEBUG] Saved to file reviews_10/thejoelynch_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_1.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_2.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_3.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_4.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_5.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_6.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_7.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_8.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_9.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user realjackattack: reviews_10/realjackattack_recent_reviews_10.json\n",
      "[DEBUG] Saved to file reviews_10/realjackattack_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_1.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_2.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_3.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_4.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_5.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_6.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_7.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_8.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_9.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user dissolvedpet: reviews_10/dissolvedpet_recent_reviews_10.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/dissolvedpet_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_1.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_2.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_3.json\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_4.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_5.json\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_6.json\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_7.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_8.json\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_9.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user j3fcostello: reviews_10/j3fcostello_recent_reviews_10.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/j3fcostello_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_1.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_2.json\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_3.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_4.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_5.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_6.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_7.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_8.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_9.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "Error for movie A Conversation About Cheating With My Time Travelling Future Self for user jpsig: invalid literal for int() with base 10: '' (https://letterboxd.com/jpsig/films/diary/page/9/)\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user jpsig: reviews_10/jpsig_recent_reviews_10.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/jpsig_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_1.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_2.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_3.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_4.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_5.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_6.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_7.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_8.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_9.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user annreinking: reviews_10/annreinking_recent_reviews_10.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/annreinking_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_1.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_2.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_3.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_4.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_5.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_6.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_7.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_8.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_9.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user nycsubwayrat: reviews_10/nycsubwayrat_recent_reviews_10.json\n",
      "[DEBUG] Saved to file reviews_10/nycsubwayrat_recent_reviews_10.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_1.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_1.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_2.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_2.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_3.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_3.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_4.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_4.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_5.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_5.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_6.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_6.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_7.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_7.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_8.json\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_8.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_9.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_9.json\n",
      "\n",
      "[DEBUG] Loading diary for user darknstormy: reviews_10/darknstormy_recent_reviews_10.json\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "[DEBUG] Saved to file reviews_10/darknstormy_recent_reviews_10.json\n"
     ]
    }
   ],
   "source": [
    "for i in range(1417, 1425):\n",
    "    user_to_save = users_to_use[i]\n",
    "    for j in range(1,11):\n",
    "        try:\n",
    "            save_user_diary(user_to_save, j, 'reviews_10')\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4e0e1-c614-4bfd-b29b-08b1d8c27f09",
   "metadata": {},
   "source": [
    "# Create cleaned .json and compressed .json (gzip) from individual .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3f491c29-a7d7-469a-a589-da62c3505915",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 9978 files from reviews_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9978/9978 [05:48<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 9892 files from reviews_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 9892/9892 [1:35:22<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 4314 files from reviews_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4314/4314 [43:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 0 files from reviews_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 4933 files from reviews_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4933/4933 [00:15<00:00, 324.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 7731 files from reviews_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 7731/7731 [00:09<00:00, 844.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 4926 files from reviews_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4926/4926 [00:06<00:00, 804.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 4998 files from reviews_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4998/4998 [00:04<00:00, 1121.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 4998 files from reviews_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4998/4998 [00:06<00:00, 751.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading 3296 files from reviews_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3296/3296 [31:46<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "folders = [f'reviews_{i}' for i in range(4, 14)]\n",
    "\n",
    "for folder in folders:\n",
    "    json_files = glob.glob(os.path.join(folder, '*.json'))\n",
    "    print(f'[DEBUG] Loading {len(json_files)} files from {folder}')\n",
    "    for json_file in tqdm(json_files):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            combined_data.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d6b4c4-2e87-4bb5-96dd-d6be541f666f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_hashable(value: Any) -> Hashable:\n",
    "    if isinstance(value, dict):\n",
    "        return frozenset((key, make_hashable(val)) for key, val in value.items())\n",
    "    elif isinstance(value, list):\n",
    "        return tuple(make_hashable(item) for item in value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def convert_from_frozenset(value: Any) -> Any:\n",
    "    if isinstance(value, frozenset):\n",
    "        if all(isinstance(item, tuple) and len(item) == 2 for item in value):\n",
    "            return {convert_from_frozenset(k): convert_from_frozenset(v) for k, v in value}\n",
    "        else:\n",
    "            return [convert_from_frozenset(item) for item in value]\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        return [convert_from_frozenset(item) for item in value]\n",
    "    elif isinstance(value, dict):\n",
    "        return {k: convert_from_frozenset(v) for k, v in value.items()}\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685b955-dab3-43c9-921e-4c5d7419b1cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 68325 duplicates were removed to produce a collection of just over 2 million diary entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77687e71-3c46-4f72-8b00-8fb89ece3c8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_data = list({make_hashable(d) for d in combined_data})\n",
    "unique_data = [dict(fs) for fs in unique_data]\n",
    "unique_data = [convert_from_frozenset(d) for d in unique_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35225209-cc7e-4520-8caa-4a951ee1353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gzip\n",
    "with gzip.open('all_letterboxd_reviews_unfiltered.json.gz', 'wt', encoding='utf-8') as f:\n",
    "    json.dump(combined_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3cb2a042-cdd0-422c-9da8-f2160bae64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json\n",
    "with open('all_letterboxd_reviews_unfiltered.json', 'w') as f:\n",
    "    json.dump(combined_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7363bab-9d20-4339-b456-f5b4f20305cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08310637-f574-4aea-b172-fc84e73cd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_new_letterboxd_reviews_unfiltered.json', 'r') as f:\n",
    "    temp_data = json.load(f)\n",
    "    all_data.extend(temp_data)\n",
    "\n",
    "with open('2_letterboxd_reviews.json', 'r') as f:\n",
    "    temp_data = json.load(f)\n",
    "    all_data.extend(temp_data)\n",
    "\n",
    "with open('1_letterboxd_reviews.json', 'r') as f:\n",
    "    temp_data = json.load(f)\n",
    "    all_data.extend(temp_data)\n",
    "\n",
    "with open('new_letterboxd_reviews_unfiltered.json', 'r') as f:\n",
    "    temp_data = json.load(f)\n",
    "    all_data.extend(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4464475-4b23-4448-a49f-e38d290fc27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5423863"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a313947-1dff-4e3c-a102-78228bf8f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 5423863/5423863 [05:51<00:00, 15444.95it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_data = set()\n",
    "for d in tqdm(all_data):\n",
    "    unique_data.add(make_hashable(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588ba6c1-654b-49f7-8ac2-faf9169e4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_list = list(unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd337695-c9d7-412f-b20d-e1ad104d6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 3582031/3582031 [13:37<00:00, 4384.14it/s]\n"
     ]
    }
   ],
   "source": [
    "new_unique_data = []\n",
    "for fs in tqdm(unique_data_list):\n",
    "    new_unique_data.append(dict(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ff22a8-50f1-4692-9813-63ef8c80360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 3582031/3582031 [17:23<00:00, 3432.76it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_data = []\n",
    "\n",
    "for d in tqdm(new_unique_data):\n",
    "    unique_data.append(convert_from_frozenset(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdbad017-9a73-4a02-b319-7505ac0b26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_letterboxd_reviews.json', 'w') as f:\n",
    "    json.dump(unique_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11700f38-7513-4775-aeaf-4a393aae926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('final_letterboxd_reviews.json.gz', 'wt', encoding='utf-8') as f:\n",
    "    json.dump(unique_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af7452a8-2dcb-4b10-ba36-7a3403411e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3582031"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c055f0a-9b32-4ae2-b673-72f4b00d81bd",
   "metadata": {},
   "source": [
    "# Scrape movie pages for movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397c3b4b-36e7-488a-a9fd-90471e568f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('letterboxd_movies.json', 'r') as movie_data_file:\n",
    "    movie_data_raw = json.load(movie_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fda5f14-f789-4935-b94d-7e08c236b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the-substance'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data_raw[0]['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f5e2132-320b-477a-8fae-ef68f9c71870",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_movie_ids = list({x['movie_id'] for x in movie_data_raw})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4800d358-79f1-4342-a304-3271f3242278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73070"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e3cb36-1279-4f3a-bd68-c20c54ecbaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the-blind-2023'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_movie_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d13e42-7d43-4611-bc08-c234c0c31401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('final_letterboxd_reviews.json', 'r') as f:\n",
    "#     raw_reviews = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(unique_data)\n",
    "\n",
    "# get all unique movie_id values\n",
    "\n",
    "all_ids = set(df['movie_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7c020-fd55-4b25-a706-d5d003bdb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df95cd34-dc40-4336-83d2-ded269937aad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('new_used_movie_ids.txt', 'r') as m:\n",
    "    to_use = [line.split(',')[0].replace('\\n', '') for line in m.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0a5202-460e-45b6-ab1e-e36efb06a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_movie_ids = set(used_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b828fde-51e6-4409-8d25-6da52eaca653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173022"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_movie_ids) + len(unused_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bd85abc-b196-40f1-ad0c-e296c7c8ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = set(to_use)\n",
    "unused_ids = []\n",
    "\n",
    "for d in to_use:\n",
    "    if d not in used_movie_ids:\n",
    "        unused_ids.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6330c8e7-335c-4afd-9456-46a9eb56b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_ids = set(unused_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c86fa42c-f34c-4820-aa28-561d0c1ce702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99952"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unused_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837865a6-237b-4149-8654-db50211f9e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unused_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_unused_ids.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43munused_ids\u001b[49m:\n\u001b[1;32m      3\u001b[0m         m\u001b[38;5;241m.\u001b[39mwrite(item \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unused_ids' is not defined"
     ]
    }
   ],
   "source": [
    "with open('new_unused_ids.txt', 'w') as m:\n",
    "    for item in unused_ids:\n",
    "        m.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31062a35-a74c-4359-890f-6e4aeb538c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01562049-971c-4e5b-b8d7-d864a45b7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_ids = list(unused_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ebf962-0466-4bad-8d39-4e6e75ba51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_unused_ids.txt', 'r') as m:\n",
    "    all_movie_ids = [line.split(',')[0].replace('\\n', '') for line in m.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f49304f-9714-4407-a1c2-a8566ecf7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98951\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_movie_ids)):\n",
    "    if all_movie_ids[i] == 'underground':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a5acdfb-f3c2-40f8-a8ac-3bd1127316c2",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Appending to `movie_data`: overwatch-be-the-hero\n",
      "[DEBUG] Appending to `movie_data`: most-likely-to-murder-2019\n",
      "[DEBUG] Appending to `movie_data`: first-day-of-work\n",
      "[DEBUG] Appending to `movie_data`: banning\n",
      "[DEBUG] Appending to `movie_data`: the-damned-2013\n",
      "[DEBUG] Appending to `movie_data`: invaders\n",
      "[DEBUG] Appending to `movie_data`: buster-and-billie\n",
      "[DEBUG] Appending to `movie_data`: tragedy-in-a-temporary-town-1956\n",
      "[DEBUG] Appending to `movie_data`: quantez\n",
      "[DEBUG] Appending to `movie_data`: habitat-2014\n",
      "[DEBUG] Appending to `movie_data`: la-riviere-de-diamants\n",
      "[DEBUG] Appending to `movie_data`: maid-of-honor-2006\n",
      "[DEBUG] Appending to `movie_data`: fastball\n",
      "[DEBUG] Appending to `movie_data`: omg-o-manchi-ghost\n",
      "[DEBUG] Appending to `movie_data`: so-this-is-london-1930\n",
      "[DEBUG] Appending to `movie_data`: the-scream-1993\n",
      "[DEBUG] Appending to `movie_data`: mnemonics-of-shape-and-reason\n",
      "[DEBUG] Appending to `movie_data`: tears-of-god\n",
      "[DEBUG] Appending to `movie_data`: aayiram-porkaasugal\n",
      "[DEBUG] Appending to `movie_data`: another-nice-mess\n",
      "[DEBUG] Appending to `movie_data`: boys-light-up\n",
      "[DEBUG] Appending to `movie_data`: omega-rising-women-of-rastafari\n",
      "[DEBUG] Appending to `movie_data`: cleaver-rise-of-the-killer-clown\n",
      "[DEBUG] Appending to `movie_data`: the-sunset-special\n",
      "[DEBUG] Appending to `movie_data`: camp-ricstar\n",
      "[DEBUG] Appending to `movie_data`: trick-bag\n",
      "[DEBUG] Appending to `movie_data`: espers-light\n",
      "[DEBUG] Appending to `movie_data`: dust-narrative\n",
      "[DEBUG] Appending to `movie_data`: the-hall-honoring-the-greats-of-stand-up\n",
      "[DEBUG] Appending to `movie_data`: don-2006\n",
      "[DEBUG] Appending to `movie_data`: split\n",
      "[DEBUG] Appending to `movie_data`: the-trouble-with-kanye\n",
      "[DEBUG] Appending to `movie_data`: give-me-the-colours\n",
      "[DEBUG] Appending to `movie_data`: sajjan-singh-rangroot\n",
      "[DEBUG] Appending to `movie_data`: dr-broadway\n",
      "[DEBUG] Appending to `movie_data`: baby-face-nelson\n",
      "[DEBUG] Appending to `movie_data`: visions-in-meditation-2-mesa-verde\n",
      "[DEBUG] Appending to `movie_data`: the-critic-1982\n",
      "[DEBUG] Appending to `movie_data`: beyond-gravity\n",
      "[DEBUG] Appending to `movie_data`: rush-clockwork-angels-tour\n",
      "[DEBUG] Appending to `movie_data`: a-demonstration\n",
      "[DEBUG] Appending to `movie_data`: depeche-mode-1983-teenagers-growing-up-bad-government-and-all-that-stuff-2007\n",
      "[DEBUG] Appending to `movie_data`: tampon\n",
      "[DEBUG] Appending to `movie_data`: zwolf-madchen-und-ein-mann\n",
      "[DEBUG] Appending to `movie_data`: drud\n",
      "[DEBUG] Appending to `movie_data`: massacre-of-the-mormons\n",
      "[DEBUG] Appending to `movie_data`: the-secret-rivals\n",
      "[DEBUG] Appending to `movie_data`: knight-rider-knight-of-the-phoenix\n",
      "[DEBUG] Appending to `movie_data`: porcelain-2024-1\n",
      "[DEBUG] Appending to `movie_data`: the-garden-1995\n",
      "[DEBUG] Appending to `movie_data`: the-rambler\n",
      "[DEBUG] Appending to `movie_data`: apat\n",
      "[DEBUG] Appending to `movie_data`: fireworks-archives\n",
      "[DEBUG] Appending to `movie_data`: strawberries-will-save-the-world\n",
      "[DEBUG] Appending to `movie_data`: 1-99-shorts\n",
      "[DEBUG] Appending to `movie_data`: retina-psykosis\n",
      "[DEBUG] Appending to `movie_data`: kim-dotcom-caught-in-the-web\n",
      "[DEBUG] Appending to `movie_data`: the-barbershop\n",
      "[DEBUG] Appending to `movie_data`: isolated-2015\n",
      "[DEBUG] Appending to `movie_data`: haiti\n",
      "[DEBUG] Appending to `movie_data`: panoramic-view-aisle-b-westinghouse-works\n",
      "[DEBUG] Appending to `movie_data`: flowerboys\n",
      "[DEBUG] Appending to `movie_data`: everything-worthwhile-is-done-with-other-people\n",
      "[DEBUG] Appending to `movie_data`: creation-of-the-daleks\n",
      "[DEBUG] Appending to `movie_data`: 10umentary-behind-the-scenes-of-starkid-homecoming\n",
      "[DEBUG] Appending to `movie_data`: murder-on-the-blackpool-express\n",
      "[DEBUG] Appending to `movie_data`: long-arm-of-the-law-iv-underground-express\n",
      "[DEBUG] Appending to `movie_data`: lasso-thrower\n",
      "[DEBUG] Appending to `movie_data`: the-rock-con-artists\n",
      "[DEBUG] Appending to `movie_data`: roman-numeral-vii\n",
      "[DEBUG] Appending to `movie_data`: refuge-2023-1\n",
      "[DEBUG] Appending to `movie_data`: behind-the-bars\n",
      "[DEBUG] Appending to `movie_data`: low-life-2004\n",
      "[DEBUG] Appending to `movie_data`: opposite-direction\n",
      "[DEBUG] Appending to `movie_data`: will-tura-hoop-doet-leven\n",
      "[DEBUG] Appending to `movie_data`: once-in-a-lifetime-sessions-with-noel-gallagher\n",
      "[DEBUG] Appending to `movie_data`: flappy\n",
      "[DEBUG] Appending to `movie_data`: april-snow-2010\n",
      "[DEBUG] Appending to `movie_data`: perazhagan\n",
      "[DEBUG] Appending to `movie_data`: the-mirror-of-fate\n",
      "[DEBUG] Appending to `movie_data`: nadunisi-naaygal\n",
      "[DEBUG] Appending to `movie_data`: my-husbands-double-life\n",
      "[DEBUG] Appending to `movie_data`: break-through-2021\n",
      "[DEBUG] Appending to `movie_data`: italiani-e-severamente-proibito-servirsi-della-toilette-durante-le-fermate\n",
      "[DEBUG] Appending to `movie_data`: emo-philips-live-at-the-hasty-pudding-theatre\n",
      "[DEBUG] Appending to `movie_data`: duane-hopwood\n",
      "[DEBUG] Appending to `movie_data`: my-dad-is-a-sausage\n",
      "[DEBUG] Appending to `movie_data`: my-world-dies-screaming\n",
      "[DEBUG] Appending to `movie_data`: full-fathom-five\n",
      "[DEBUG] Appending to `movie_data`: aakhri-cheekh\n",
      "[DEBUG] Appending to `movie_data`: house-of-bodies\n",
      "[DEBUG] Appending to `movie_data`: the-wife\n",
      "[DEBUG] Appending to `movie_data`: the-scapegoat-2021\n",
      "[DEBUG] Appending to `movie_data`: company-of-killers\n",
      "[DEBUG] Appending to `movie_data`: errand-boy-for-rhythm\n",
      "[DEBUG] Appending to `movie_data`: simeon\n",
      "[DEBUG] Appending to `movie_data`: king-lear-1953\n",
      "[DEBUG] Appending to `movie_data`: special-female-force\n",
      "[DEBUG] Appending to `movie_data`: never-let-me-go\n",
      "[DEBUG] Appending to `movie_data`: stiletto\n",
      "[DEBUG] Appending to `movie_data`: tokyo-videos-of-horror-10\n",
      "[DEBUG] Appending to `movie_data`: the-stone-flower\n",
      "[DEBUG] Appending to `movie_data`: how-to-build-a-life\n",
      "[DEBUG] Appending to `movie_data`: resistance-they-fought-back\n",
      "[DEBUG] Appending to `movie_data`: great-barrier-reef-with-david-attenborough\n",
      "[DEBUG] Appending to `movie_data`: vision-of-a-future-passed-the-prophecy-of-2001\n",
      "[DEBUG] Appending to `movie_data`: rise-of-the-black-bat\n",
      "[DEBUG] Appending to `movie_data`: noblesse\n",
      "[DEBUG] Appending to `movie_data`: miss-julie-1999-1\n",
      "[DEBUG] Appending to `movie_data`: blutige-exzesse-im-fuhrerbunker\n",
      "[DEBUG] Appending to `movie_data`: children-1957\n",
      "[DEBUG] Appending to `movie_data`: the-innocent-1976\n",
      "[DEBUG] Appending to `movie_data`: i-have-a-date-with-spring-2018\n",
      "[DEBUG] Appending to `movie_data`: sociedade-do-medo\n",
      "[DEBUG] Appending to `movie_data`: motvind\n",
      "[DEBUG] Appending to `movie_data`: the-9-11-tapes-chaos-in-the-sky\n",
      "[DEBUG] Appending to `movie_data`: midnight-kiss\n",
      "[DEBUG] Appending to `movie_data`: breakfast-the-three-siblings\n",
      "[DEBUG] Appending to `movie_data`: malvada\n",
      "[DEBUG] Appending to `movie_data`: the-return-of-gentleman-jim\n",
      "[DEBUG] Appending to `movie_data`: muddy-track\n",
      "[DEBUG] Appending to `movie_data`: kopf-oder-zahl\n",
      "[DEBUG] Appending to `movie_data`: heavenly-mission\n",
      "[DEBUG] Appending to `movie_data`: 100-usda-certified-organic-homemade-tofu\n",
      "[DEBUG] Appending to `movie_data`: wieners-and-buns-musical\n",
      "[DEBUG] Appending to `movie_data`: adventures-of-a-taxi-driver\n",
      "[DEBUG] Appending to `movie_data`: requiem-for-the-20th-century\n",
      "[DEBUG] Appending to `movie_data`: jepoy\n",
      "[DEBUG] Appending to `movie_data`: love-letters-1942\n",
      "[DEBUG] Appending to `movie_data`: blutiger-sonntag\n",
      "[DEBUG] Appending to `movie_data`: un-caso-di-coscienza\n",
      "[DEBUG] Appending to `movie_data`: lhomme-qui-tousse\n",
      "[DEBUG] Appending to `movie_data`: the-witness-2024-1\n",
      "[DEBUG] Appending to `movie_data`: a-carta-2024\n",
      "[DEBUG] Appending to `movie_data`: proof-2005\n",
      "[DEBUG] Appending to `movie_data`: ring-wandering\n",
      "[DEBUG] Appending to `movie_data`: meet-you-at-the-light\n",
      "[DEBUG] Appending to `movie_data`: from-dreams-to-tragedy-the-fire-that-shook-brazilian-football\n",
      "[DEBUG] Appending to `movie_data`: persuasion\n",
      "[DEBUG] Appending to `movie_data`: damiana-kryygi\n",
      "[DEBUG] Appending to `movie_data`: your-mountain-is-waiting\n",
      "[DEBUG] Appending to `movie_data`: me-and-my-pal\n",
      "[DEBUG] Appending to `movie_data`: night-trains-from-kosice\n",
      "[DEBUG] Appending to `movie_data`: leap-to-the-future\n",
      "[DEBUG] Appending to `movie_data`: hells-angels-forever\n",
      "[DEBUG] Appending to `movie_data`: a-few-quick-facts-voting-for-service-men-overseas\n",
      "[DEBUG] Appending to `movie_data`: perfect-city-the-bravest-kid\n",
      "[DEBUG] Appending to `movie_data`: baby-talk\n",
      "[DEBUG] Appending to `movie_data`: plan-c-2023\n",
      "[DEBUG] Appending to `movie_data`: charleston-chain-gang\n",
      "[DEBUG] Appending to `movie_data`: the-watershow-extravaganza\n",
      "[DEBUG] Appending to `movie_data`: meanwhile-on-earth\n",
      "[DEBUG] Appending to `movie_data`: skzflix\n",
      "[DEBUG] Appending to `movie_data`: slumlord-millionaire\n",
      "[DEBUG] Appending to `movie_data`: tiger-claws-iii\n",
      "[DEBUG] Appending to `movie_data`: moon-2024\n",
      "[DEBUG] Appending to `movie_data`: ari-my-life-with-a-king\n",
      "[DEBUG] Appending to `movie_data`: carlos-2023\n",
      "[DEBUG] Appending to `movie_data`: the-men-next-door\n",
      "[DEBUG] Appending to `movie_data`: mystery-of-easter-island\n",
      "[DEBUG] Appending to `movie_data`: the-last-picture-show-2023\n",
      "[DEBUG] Appending to `movie_data`: a-star-so-close-and-distant\n",
      "[DEBUG] Appending to `movie_data`: the-corrupted\n",
      "[DEBUG] Appending to `movie_data`: an-all-around-feel-good\n",
      "[DEBUG] Appending to `movie_data`: the-boxcar-children\n",
      "[DEBUG] Appending to `movie_data`: the-days-that-never-were\n",
      "[DEBUG] Appending to `movie_data`: the-blue-balloon\n",
      "[DEBUG] Appending to `movie_data`: kids-on-fire-2020\n",
      "[DEBUG] Appending to `movie_data`: i-am-phenomenal\n",
      "[DEBUG] Appending to `movie_data`: catch-me-if-you-can\n",
      "[DEBUG] Appending to `movie_data`: night-song\n",
      "[DEBUG] Appending to `movie_data`: all-the-young-dudes\n",
      "[DEBUG] Appending to `movie_data`: in-the-cinema\n",
      "[DEBUG] Appending to `movie_data`: lady-of-vengeance\n",
      "[DEBUG] Appending to `movie_data`: martin-scorsese-litalo-americain\n",
      "[DEBUG] Appending to `movie_data`: the-wrath-of-god\n",
      "[DEBUG] Appending to `movie_data`: the-blank-page-2020\n",
      "[DEBUG] Appending to `movie_data`: floating-in-between\n",
      "[DEBUG] Appending to `movie_data`: paul-is-dead-2018\n",
      "[DEBUG] Appending to `movie_data`: common-pursuit\n",
      "[DEBUG] Appending to `movie_data`: diet-of-the-living-dead\n",
      "[DEBUG] Appending to `movie_data`: fishing-without-nets\n",
      "[DEBUG] Appending to `movie_data`: the-nightside-of-the-sky\n",
      "[DEBUG] Appending to `movie_data`: foret-debussy\n",
      "[DEBUG] Appending to `movie_data`: hitlers-ss-portrait-in-evil\n",
      "[DEBUG] Appending to `movie_data`: high-boot-benny\n",
      "[DEBUG] Appending to `movie_data`: absolute-beginners-2023\n",
      "[DEBUG] Appending to `movie_data`: a-new-life-2024\n",
      "[DEBUG] Appending to `movie_data`: stau-jetzt-gehts-los\n",
      "[DEBUG] Appending to `movie_data`: lightning-trap-leina-laika\n",
      "[DEBUG] Appending to `movie_data`: the-angry-earth\n",
      "[DEBUG] Appending to `movie_data`: secrets-of-the-unknown-tornadoes\n",
      "[DEBUG] Appending to `movie_data`: underground\n"
     ]
    }
   ],
   "source": [
    "for id_ in list(all_movie_ids)[98759:98952]:\n",
    "    print(f'[DEBUG] Appending to `movie_data`: {id_}')\n",
    "    page = get_letterboxd_stats(id_)\n",
    "    movie_data.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e40bd5d-22c9-4252-9071-ba0b0d9e519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98758\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_movie_ids)):\n",
    "    if all_movie_ids[i] == 'two-sisters':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4b2a535-a7d3-4a77-9422-4b3c5caebfbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('new_movie_data_last2.json', 'w') as json_file:\n",
    "        json.dump(movie_data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c81cb-3127-4008-b4ab-ed8796f0b290",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Save and collect into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "87c863d6-eecb-4bf1-8b7b-3be1a3d6b46f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del movie_data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "89e6afdf-cbe9-44d1-8dd5-50d94d696fcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_data = []\n",
    "files = ['movie_data.json', 'updated_movie_data_0.json', 'updated_movie_data_1.json', \n",
    "         'updated_movie_data_2.json', 'updated_movie_data_3.json', 'updated_movie_data_4.json', 'updated_movie_data_5.json']\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        temp_data = json.load(f)\n",
    "        movie_data.extend(temp_data)\n",
    "\n",
    "with open('letterboxd_movies.json', 'w') as f:\n",
    "    json.dump(movie_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cae9d6bb-26f8-452b-becf-d86bb00c9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [00:26<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "all_movie_data = []\n",
    "files = ['letterboxd_movies.json', 'new_movie_data_0_6899.json', 'new_movie_data_10000_16606.json',\n",
    "         'new_movie_data_20000_28560.json', 'new_movie_data_30000_38196.json', 'new_movie_data_38196_40000.json',\n",
    "         'new_movie_data_40000_50000.json', 'new_movie_data_50000_60000.json', 'new_movie_data_60000_77008.json',\n",
    "         'new_movie_data_6899_10000.json', 'new_movie_data_last1.json', 'new_movie_data_last3.json', 'new_movie_data_last2.json',\n",
    "        ]\n",
    "for file in tqdm(files):\n",
    "    with open(file, 'r') as f:\n",
    "        temp_data = json.load(f)\n",
    "        all_movie_data.extend(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47463d17-b60e-48b5-b25a-381fde8330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_letterboxd_movies.json', 'w') as f:\n",
    "    json.dump(all_movie_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
