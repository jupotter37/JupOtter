{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import struct\n",
    "\n",
    "class AudioRecorder:\n",
    "    def __init__(self):\n",
    "        # Audio configuration\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000  # WebRTC VAD requires 16000Hz\n",
    "        self.CHUNK = 480   # 30ms at 16000Hz - WebRTC VAD expects 10, 20, or 30ms frames\n",
    "        self.SILENCE_THRESHOLD = 3  # Number of silent chunks before stopping\n",
    "        \n",
    "        # Initialize PyAudio\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        \n",
    "        # Initialize VAD\n",
    "        self.vad = webrtcvad.Vad()\n",
    "        self.vad.set_mode(1)  # 0: Least aggressive, 3: Most aggressive\n",
    "        \n",
    "    def is_speech(self, frame):\n",
    "        \"\"\"Check if a frame contains speech.\"\"\"\n",
    "        try:\n",
    "            return self.vad.is_speech(frame, self.RATE)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def record_audio(self, silence_timeout=2):\n",
    "        \"\"\"Record audio when speech is detected.\"\"\"\n",
    "        frames = []\n",
    "        recording = False\n",
    "        silent_chunks = 0\n",
    "        \n",
    "        # Open stream\n",
    "        stream = self.audio.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.RATE,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.CHUNK\n",
    "        )\n",
    "        \n",
    "        print(\"Listening for speech...\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                frame = stream.read(self.CHUNK, exception_on_overflow=False)\n",
    "                \n",
    "                # Check if frame contains speech\n",
    "                is_speech = self.is_speech(frame)\n",
    "                \n",
    "                if is_speech:\n",
    "                    if not recording:\n",
    "                        print(\"Speech detected - Recording started.\")\n",
    "                        recording = True\n",
    "                    frames.append(frame)\n",
    "                    silent_chunks = 0\n",
    "                elif recording:\n",
    "                    silent_chunks += 1\n",
    "                    frames.append(frame)\n",
    "                    \n",
    "                    # Stop recording after silence_timeout seconds of silence\n",
    "                    if silent_chunks > (silence_timeout * self.RATE) // self.CHUNK:\n",
    "                        print(\"Silence detected - Recording stopped.\")\n",
    "                        break\n",
    "                        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nRecording interrupted by user\")\n",
    "        finally:\n",
    "            # Clean up\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            \n",
    "        return frames\n",
    "        \n",
    "    def save_audio(self, frames, filename=\"output.wav\"):\n",
    "        \"\"\"Save recorded frames to a WAV file.\"\"\"\n",
    "        if not frames:\n",
    "            print(\"No audio frames to save\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            with wave.open(filename, 'wb') as wf:\n",
    "                wf.setnchannels(self.CHANNELS)\n",
    "                wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))\n",
    "                wf.setframerate(self.RATE)\n",
    "                wf.writeframes(b''.join(frames))\n",
    "            print(f\"Audio saved as {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving audio: {e}\")\n",
    "            \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up PyAudio resources.\"\"\"\n",
    "        self.audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    recorder = AudioRecorder()\n",
    "    try:\n",
    "        frames = recorder.record_audio()\n",
    "        recorder.save_audio(frames)\n",
    "    finally:\n",
    "        recorder.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def recognize_speech_from_microphone():\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError:\n",
    "        print(\"Could not request results from Google Web Speech API\")\n",
    "\n",
    "recognize_speech_from_microphone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def speak_text(text, lang='hi'):\n",
    "    \"\"\"\n",
    "    Convert text to speech and play it directly without saving to file\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The text to convert to speech\n",
    "    lang (str): Language code (default: 'en' for English)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create a BytesIO buffer\n",
    "    mp3_fp = BytesIO()\n",
    "    \n",
    "    # Convert text to speech and write to buffer\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.write_to_fp(mp3_fp)\n",
    "    mp3_fp.seek(0)\n",
    "    \n",
    "    # Convert to audio and play\n",
    "    audio = AudioSegment.from_mp3(mp3_fp)\n",
    "    play(audio)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the function\n",
    "    text = \"Aapp kaise hoooo yar\"\n",
    "    speak_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "class AudioChat:\n",
    "    \"\"\"\n",
    "    A class to handle text-to-speech and speech-to-text conversion.\n",
    "    \n",
    "    Attributes:\n",
    "        lang (str): Language code for text-to-speech conversion (default: 'en')\n",
    "        logger (logging.Logger): Logger instance for the class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lang: str = 'en'):\n",
    "        \"\"\"\n",
    "        Initialize AudioChat with specified language.\n",
    "        \n",
    "        Args:\n",
    "            lang (str): Language code for text-to-speech (e.g., 'en' for English, 'hi' for Hindi)\n",
    "        \"\"\"\n",
    "        self.lang = lang\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def speak_text(self, text: str) -> None:\n",
    "        \"\"\"\n",
    "        Convert text to speech and play it directly without saving to file.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to convert to speech\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If text is empty or not a string\n",
    "            RuntimeError: If audio playback fails\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Text must be a non-empty string\")\n",
    "            \n",
    "        try:\n",
    "            self.logger.info(f\"Converting text to speech: {text[:50]}...\")\n",
    "            \n",
    "            # Create a BytesIO buffer\n",
    "            mp3_fp = BytesIO()\n",
    "            \n",
    "            # Convert text to speech and write to buffer\n",
    "            tts = gTTS(text=text, lang=self.lang)\n",
    "            tts.write_to_fp(mp3_fp)\n",
    "            mp3_fp.seek(0)\n",
    "            \n",
    "            # Convert to audio and play\n",
    "            audio = AudioSegment.from_mp3(mp3_fp)\n",
    "            play(audio)\n",
    "            \n",
    "            self.logger.info(\"Text-to-speech playback completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in text-to-speech conversion: {str(e)}\")\n",
    "            raise RuntimeError(f\"Failed to convert or play text: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            mp3_fp.close()\n",
    "\n",
    "    def recognize_speech(self, timeout: Optional[float] = None, phrase_time_limit: Optional[float] = None) -> str:\n",
    "        \"\"\"\n",
    "        Record speech from microphone and convert to text.\n",
    "        \n",
    "        Args:\n",
    "            timeout (float, optional): Maximum number of seconds for waiting for phrase to start\n",
    "            phrase_time_limit (float, optional): Maximum number of seconds for a phrase\n",
    "            \n",
    "        Returns:\n",
    "            str: The recognized text\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If speech recognition fails\n",
    "            TimeoutError: If recording times out\n",
    "        \"\"\"\n",
    "        recognizer = sr.Recognizer()\n",
    "        \n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                self.logger.info(\"Adjusting for ambient noise...\")\n",
    "                recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                \n",
    "                self.logger.info(\"Listening for speech...\")\n",
    "                audio = recognizer.listen(source, \n",
    "                                        timeout=timeout,\n",
    "                                        phrase_time_limit=phrase_time_limit)\n",
    "                \n",
    "                self.logger.info(\"Processing speech...\")\n",
    "                text = recognizer.recognize_google(audio, language=self.lang)\n",
    "                self.logger.info(f\"Successfully recognized: {text}\")\n",
    "                return text\n",
    "                \n",
    "        except sr.WaitTimeoutError:\n",
    "            self.logger.error(\"Timeout occurred while waiting for speech\")\n",
    "            raise TimeoutError(\"No speech detected within timeout period\")\n",
    "            \n",
    "        except sr.UnknownValueError:\n",
    "            self.logger.error(\"Speech was not understood\")\n",
    "            raise RuntimeError(\"Could not understand audio\")\n",
    "            \n",
    "        except sr.RequestError as e:\n",
    "            self.logger.error(f\"Could not request results from speech recognition service: {str(e)}\")\n",
    "            raise RuntimeError(f\"Speech recognition service error: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Unexpected error in speech recognition: {str(e)}\")\n",
    "            raise RuntimeError(f\"Speech recognition failed: {str(e)}\")\n",
    "\n",
    "    def have_conversation(self, initial_prompt: str = \"Speak something...\") -> None:\n",
    "        \"\"\"\n",
    "        Conduct a conversation by alternating between speech recognition and text-to-speech.\n",
    "        \n",
    "        Args:\n",
    "            initial_prompt (str): The initial prompt to speak\n",
    "            \n",
    "        Note:\n",
    "            Press Ctrl+C to end the conversation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.speak_text(initial_prompt)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    # Listen for user input\n",
    "                    user_text = self.recognize_speech(timeout=5, phrase_time_limit=10)\n",
    "                    \n",
    "                    if user_text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                        self.speak_text(\"Goodbye!\")\n",
    "                        break\n",
    "                        \n",
    "                    # Here you can add your chatbot logic to process user_text\n",
    "                    # For now, we'll just echo back\n",
    "                    response = f\"You said: {user_text}\"\n",
    "                    self.speak_text(response)\n",
    "                    \n",
    "                except TimeoutError:\n",
    "                    self.speak_text(\"I didn't hear anything. Could you please speak again?\")\n",
    "                except RuntimeError as e:\n",
    "                    self.speak_text(\"I'm having trouble understanding. Could you please repeat?\")\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            self.speak_text(\"Conversation ended. Goodbye!\")\n",
    "            self.logger.info(\"Conversation ended by user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import logging\n",
    "from typing import Optional\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import audioop\n",
    "import math\n",
    "\n",
    "class ContinuousListener(sr.AudioSource):\n",
    "    \"\"\"\n",
    "    A custom audio source that continuously records until a significant pause is detected.\n",
    "    \"\"\"\n",
    "    def __init__(self, device_index=None, sample_rate=16000, chunk_size=1024,\n",
    "                 pause_threshold=0.8, min_speech_duration=0.3):\n",
    "        \"\"\"\n",
    "        Initialize continuous listener.\n",
    "        \n",
    "        Args:\n",
    "            device_index: Index of input device\n",
    "            sample_rate: Audio sample rate\n",
    "            chunk_size: Size of audio chunks to process\n",
    "            pause_threshold: Duration of silence (in seconds) to mark end of speech\n",
    "            min_speech_duration: Minimum duration of speech to consider valid\n",
    "        \"\"\"\n",
    "        self.device_index = device_index\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.pause_threshold = pause_threshold\n",
    "        self.min_speech_duration = min_speech_duration\n",
    "        \n",
    "        self.stream = None\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.stream = self.audio.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            input_device_index=self.device_index,\n",
    "            stream_callback=self._callback\n",
    "        )\n",
    "        self.stream.start_stream()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.audio.terminate()\n",
    "        \n",
    "    def _callback(self, in_data, frame_count, time_info, status):\n",
    "        self.audio_queue.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "class AudioChat:\n",
    "    \"\"\"\n",
    "    A class to handle text-to-speech and continuous speech-to-text conversion.\n",
    "    \n",
    "    Attributes:\n",
    "        lang (str): Language code for text-to-speech conversion (default: 'en')\n",
    "        logger (logging.Logger): Logger instance for the class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lang: str = 'en', \n",
    "                 pause_threshold: float = 0.8,\n",
    "                 min_speech_duration: float = 0.3,\n",
    "                 energy_threshold: int = 1000):\n",
    "        \"\"\"\n",
    "        Initialize AudioChat with specified parameters.\n",
    "        \n",
    "        Args:\n",
    "            lang (str): Language code for text-to-speech\n",
    "            pause_threshold (float): Duration of silence (in seconds) to mark end of speech\n",
    "            min_speech_duration (float): Minimum duration of speech to consider valid\n",
    "            energy_threshold (int): Minimum audio energy to consider as speech\n",
    "        \"\"\"\n",
    "        self.lang = lang\n",
    "        self.pause_threshold = pause_threshold\n",
    "        self.min_speech_duration = min_speech_duration\n",
    "        self.energy_threshold = energy_threshold\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def speak_text(self, text: str) -> None:\n",
    "        \"\"\"Convert text to speech and play it.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Text must be a non-empty string\")\n",
    "            \n",
    "        try:\n",
    "            self.logger.info(f\"Converting text to speech: {text[:50]}...\")\n",
    "            mp3_fp = BytesIO()\n",
    "            tts = gTTS(text=text, lang=self.lang)\n",
    "            tts.write_to_fp(mp3_fp)\n",
    "            mp3_fp.seek(0)\n",
    "            audio = AudioSegment.from_mp3(mp3_fp)\n",
    "            play(audio)\n",
    "        finally:\n",
    "            mp3_fp.close()\n",
    "\n",
    "    def recognize_continuous_speech(self) -> str:\n",
    "        \"\"\"\n",
    "        Record speech continuously until a significant pause is detected.\n",
    "        \n",
    "        Returns:\n",
    "            str: The recognized text\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If speech recognition fails\n",
    "        \"\"\"\n",
    "        recognizer = sr.Recognizer()\n",
    "        recognizer.energy_threshold = self.energy_threshold\n",
    "        \n",
    "        # Buffer to store audio data\n",
    "        audio_data = []\n",
    "        speech_started = False\n",
    "        silence_start = None\n",
    "        speech_start = None\n",
    "        \n",
    "        with sr.Microphone() as source:\n",
    "            self.logger.info(\"Adjusting for ambient noise...\")\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            \n",
    "            self.logger.info(\"Listening for continuous speech...\")\n",
    "            \n",
    "            try:\n",
    "                while True:\n",
    "                    audio_chunk = source.stream.read(source.CHUNK)\n",
    "                    energy = audioop.rms(audio_chunk, 2)\n",
    "                    \n",
    "                    # Detect speech start\n",
    "                    if not speech_started and energy > recognizer.energy_threshold:\n",
    "                        speech_started = True\n",
    "                        speech_start = time.time()\n",
    "                        silence_start = None\n",
    "                        self.logger.debug(\"Speech started\")\n",
    "                    \n",
    "                    # Detect silence\n",
    "                    if speech_started and energy < recognizer.energy_threshold:\n",
    "                        if silence_start is None:\n",
    "                            silence_start = time.time()\n",
    "                        elif time.time() - silence_start > self.pause_threshold:\n",
    "                            # Check if speech duration meets minimum requirement\n",
    "                            if time.time() - speech_start > self.min_speech_duration:\n",
    "                                break\n",
    "                    else:\n",
    "                        silence_start = None\n",
    "                    \n",
    "                    audio_data.append(audio_chunk)\n",
    "                \n",
    "                # Convert audio data to AudioData object\n",
    "                audio = sr.AudioData(b''.join(audio_data), \n",
    "                                   source.SAMPLE_RATE,\n",
    "                                   source.SAMPLE_WIDTH)\n",
    "                \n",
    "                self.logger.info(\"Processing speech...\")\n",
    "                text = recognizer.recognize_google(audio, language=self.lang)\n",
    "                self.logger.info(f\"Successfully recognized: {text}\")\n",
    "                return text\n",
    "                \n",
    "            except sr.UnknownValueError:\n",
    "                self.logger.error(\"Speech was not understood\")\n",
    "                raise RuntimeError(\"Could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                self.logger.error(f\"Could not request results: {str(e)}\")\n",
    "                raise RuntimeError(f\"Speech recognition service error: {str(e)}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Unexpected error: {str(e)}\")\n",
    "                raise RuntimeError(f\"Speech recognition failed: {str(e)}\")\n",
    "\n",
    "    def have_continuous_conversation(self, initial_prompt: str = \"Speak something...\") -> None:\n",
    "        \"\"\"\n",
    "        Conduct a conversation using continuous speech recognition.\n",
    "        \n",
    "        Args:\n",
    "            initial_prompt (str): The initial prompt to speak\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.speak_text(initial_prompt)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    # Listen for user input continuously\n",
    "                    user_text = self.recognize_continuous_speech()\n",
    "                    \n",
    "                    if user_text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                        self.speak_text(\"Goodbye!\")\n",
    "                        break\n",
    "                    \n",
    "                    # Here you can add your chatbot logic to process user_text\n",
    "                    # For now, we'll just echo back\n",
    "                    response = f\"You said: {user_text}\"\n",
    "                    story = \"\"\"Once upon a time in a small, vibrant village nestled between two rivers, there lived a young girl named Lira. Lira had a unique gift: she could understand the language of plants. From a young age, she'd spent countless hours wandering through the forest, listening to the trees, flowers, and even the blades of grass. They whispered secrets of the earth, told tales of seasons past, and shared wisdom that had been passed down for centuries.\"\"\"\n",
    "                    self.speak_text(story)\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    self.speak_text(\"I'm having trouble understanding. Could you please repeat?\")\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            self.speak_text(\"Conversation ended. Goodbye!\")\n",
    "            self.logger.info(\"Conversation ended by user\")\n",
    "\n",
    "def main():\n",
    "    # Example usage with custom parameters\n",
    "    chat = AudioChat(\n",
    "        lang='en',\n",
    "        pause_threshold=0.8,  # Wait for 0.8 seconds of silence before stopping\n",
    "        min_speech_duration=0.5,  # Minimum speech duration to consider valid\n",
    "        energy_threshold=1000  # Adjust based on your microphone and environment\n",
    "    )\n",
    "    # Start continuous conversation\n",
    "    chat.have_continuous_conversation(\"Please start speaking. I'll listen until you pause.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import logging\n",
    "from typing import Optional\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import audioop\n",
    "import math\n",
    "import pyaudio\n",
    "\n",
    "class AudioPlayer:\n",
    "    \"\"\"Handles audio playback with interruption capability.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.current_playback = None\n",
    "        self.should_stop = threading.Event()\n",
    "        \n",
    "    def play_audio(self, audio_segment):\n",
    "        \"\"\"Play audio with ability to stop.\"\"\"\n",
    "        self.should_stop.clear()\n",
    "        chunk_ms = 50  # Size of chunks to play\n",
    "        \n",
    "        for i in range(0, len(audio_segment), chunk_ms):\n",
    "            if self.should_stop.is_set():\n",
    "                break\n",
    "            chunk = audio_segment[i:i + chunk_ms]\n",
    "            play(chunk)\n",
    "    \n",
    "    def stop_playback(self):\n",
    "        \"\"\"Stop current audio playback.\"\"\"\n",
    "        self.should_stop.set()\n",
    "\n",
    "class AudioChat:\n",
    "    def __init__(self, lang='en', energy_threshold=1000):\n",
    "        self.lang = lang\n",
    "        self.energy_threshold = energy_threshold\n",
    "        self.logger = self._setup_logger()\n",
    "        self.audio_player = AudioPlayer()\n",
    "        self.speech_detected = threading.Event()\n",
    "        self.is_speaking = False\n",
    "        \n",
    "    def _setup_logger(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.setLevel(logging.INFO)\n",
    "        return logger\n",
    "    \n",
    "    def _monitor_audio(self, audio_queue):\n",
    "        \"\"\"Continuously monitor audio input for speech.\"\"\"\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=pyaudio.paInt16,\n",
    "                       channels=1,\n",
    "                       rate=16000,\n",
    "                       input=True,\n",
    "                       frames_per_buffer=1024,\n",
    "                       stream_callback=lambda in_data, frame_count, time_info, status: \n",
    "                           (self._audio_callback(in_data), pyaudio.paContinue))\n",
    "        \n",
    "        stream.start_stream()\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(0.1)\n",
    "        finally:\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            p.terminate()\n",
    "    \n",
    "    def _audio_callback(self, in_data):\n",
    "        \"\"\"Process incoming audio data.\"\"\"\n",
    "        energy = audioop.rms(in_data, 2)\n",
    "        \n",
    "        if energy > self.energy_threshold and not self.is_speaking:\n",
    "            self.logger.info(\"Speech detected!\")\n",
    "            self.speech_detected.set()\n",
    "            self.audio_player.stop_playback()\n",
    "        return in_data\n",
    "    \n",
    "    def speak_text(self, text: str) -> None:\n",
    "        \"\"\"Convert text to speech and play it.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            raise ValueError(\"Text must be a non-empty string\")\n",
    "        \n",
    "        try:\n",
    "            self.logger.info(f\"Converting text to speech: {text[:50]}...\")\n",
    "            mp3_fp = BytesIO()\n",
    "            tts = gTTS(text=text, lang=self.lang)\n",
    "            tts.write_to_fp(mp3_fp)\n",
    "            mp3_fp.seek(0)\n",
    "            audio = AudioSegment.from_mp3(mp3_fp)\n",
    "            \n",
    "            self.is_speaking = True\n",
    "            self.audio_player.play_audio(audio)\n",
    "            self.is_speaking = False\n",
    "            \n",
    "        finally:\n",
    "            mp3_fp.close()\n",
    "    \n",
    "    def have_continuous_conversation(self):\n",
    "        \"\"\"Handle continuous conversation with interruption capability.\"\"\"\n",
    "        story = \"\"\"Once upon a time in a small, vibrant village nestled between two rivers, \n",
    "                  there lived a young girl named Lira. Lira had a unique gift: she could \n",
    "                  understand the language of plants. From a young age, she'd spent countless \n",
    "                  hours wandering through the forest, listening to the trees, flowers, and \n",
    "                  even the blades of grass.\"\"\"\n",
    "        \n",
    "        # Start audio monitoring in a separate thread\n",
    "        audio_queue = queue.Queue()\n",
    "        monitor_thread = threading.Thread(target=self._monitor_audio, \n",
    "                                       args=(audio_queue,),\n",
    "                                       daemon=True)\n",
    "        monitor_thread.start()\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                self.speech_detected.clear()\n",
    "                self.speak_text(story)\n",
    "                \n",
    "                # Wait for speech detection\n",
    "                if self.speech_detected.wait(timeout=1.0):\n",
    "                    # Process the speech here\n",
    "                    recognizer = sr.Recognizer()\n",
    "                    with sr.Microphone() as source:\n",
    "                        audio = recognizer.listen(source)\n",
    "                        try:\n",
    "                            text = recognizer.recognize_google(audio)\n",
    "                            self.logger.info(f\"Recognized: {text}\")\n",
    "                            \n",
    "                            if text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                                self.speak_text(\"Goodbye!\")\n",
    "                                break\n",
    "                        except sr.UnknownValueError:\n",
    "                            self.logger.error(\"Could not understand audio\")\n",
    "                        except sr.RequestError as e:\n",
    "                            self.logger.error(f\"Could not request results: {str(e)}\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Conversation ended by user\")\n",
    "            self.speak_text(\"Goodbye!\")\n",
    "\n",
    "def main():\n",
    "    chat = AudioChat(energy_threshold=1000)\n",
    "    chat.have_continuous_conversation()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import time\n",
    "import logging\n",
    "from tempfile import NamedTemporaryFile\n",
    "import os\n",
    "\n",
    "class SmoothAudioChat:\n",
    "    def __init__(self, sample_rate=44100, cooldown_time=0.5):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.is_playing = False\n",
    "        self.should_stop = False\n",
    "        self.is_speaking = False\n",
    "        self.cooldown_time = cooldown_time  # Cooldown after playback to avoid feedback\n",
    "        self.playback_lock = threading.Lock()\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        \n",
    "        # Audio detection parameters\n",
    "        self.silence_threshold = 300  # Adjust based on your microphone\n",
    "        self.speech_buffer = []\n",
    "        self.speech_detected = False\n",
    "\n",
    "    def _audio_callback(self, indata, frames, time, status):\n",
    "        \"\"\"Handle incoming audio data\"\"\"\n",
    "        if status:\n",
    "            self.logger.warning(f\"Audio input status: {status}\")\n",
    "        \n",
    "        # Calculate audio energy\n",
    "        energy = np.sqrt(np.mean(indata**2))\n",
    "        \n",
    "        # Check for speech detection\n",
    "        if energy > self.silence_threshold and not self.is_speaking:\n",
    "            if not self.speech_detected:\n",
    "                self.speech_detected = True\n",
    "                self.stop_playback()  # Stop playback if speech detected\n",
    "                self.speech_buffer = []\n",
    "            self.speech_buffer.extend(indata.flatten())\n",
    "            \n",
    "        elif self.speech_detected and energy <= self.silence_threshold:\n",
    "            # Process captured speech\n",
    "            self._process_speech()\n",
    "            self.speech_detected = False\n",
    "\n",
    "    def _process_speech(self):\n",
    "        \"\"\"Process captured speech buffer\"\"\"\n",
    "        if not self.speech_buffer:\n",
    "            return\n",
    "            \n",
    "        # Save speech buffer to temporary WAV file\n",
    "        with NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            sf.write(temp_file.name, self.speech_buffer, self.sample_rate)\n",
    "        \n",
    "        # Use speech recognition\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(temp_file.name) as source:\n",
    "            try:\n",
    "                audio = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                self.logger.info(f\"Recognized: {text}\")\n",
    "                \n",
    "                if text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                    self.should_stop = True\n",
    "                    return\n",
    "                \n",
    "                response = f\"You said: {text}\"\n",
    "                audio_data, sample_rate = self.text_to_speech(response)\n",
    "                self.play_audio(audio_data, sample_rate)\n",
    "                    \n",
    "            except sr.UnknownValueError:\n",
    "                self.logger.info(\"Speech not understood\")\n",
    "            except sr.RequestError as e:\n",
    "                self.logger.error(f\"Recognition error: {e}\")\n",
    "            finally:\n",
    "                os.unlink(temp_file.name)\n",
    "\n",
    "    def start_listening(self):\n",
    "        \"\"\"Start continuous audio input monitoring\"\"\"\n",
    "        try:\n",
    "            with sd.InputStream(callback=self._audio_callback,\n",
    "                                channels=1,\n",
    "                                samplerate=self.sample_rate):\n",
    "                while not self.should_stop:\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in audio input stream: {e}\")\n",
    "            \n",
    "    def play_audio(self, audio_data, sample_rate):\n",
    "        \"\"\"Play audio data with smooth playback\"\"\"\n",
    "        with self.playback_lock:\n",
    "            self.is_speaking = True\n",
    "            sd.play(audio_data, sample_rate)\n",
    "            sd.wait()\n",
    "            self.is_speaking = False\n",
    "            # Cooldown period to avoid feedback\n",
    "            time.sleep(self.cooldown_time)\n",
    "            \n",
    "    def stop_playback(self):\n",
    "        \"\"\"Stop current audio playback if running\"\"\"\n",
    "        with self.playback_lock:\n",
    "            sd.stop()\n",
    "            self.is_speaking = False\n",
    "            \n",
    "    def text_to_speech(self, text):\n",
    "        \"\"\"Convert text to speech with high quality\"\"\"\n",
    "        with NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n",
    "            # Generate speech with gTTS\n",
    "            tts = gTTS(text=text, lang='en')\n",
    "            tts.save(temp_file.name)\n",
    "            \n",
    "            # Load audio file with better quality\n",
    "            audio_data, sample_rate = sf.read(temp_file.name)\n",
    "            \n",
    "            # Remove temporary file\n",
    "            os.unlink(temp_file.name)\n",
    "            \n",
    "            return audio_data, sample_rate\n",
    "            \n",
    "    def run_conversation(self):\n",
    "        \"\"\"Run the main conversation loop, listening for user input and repeating recognized speech\"\"\"\n",
    "        # Start listening thread\n",
    "        listen_thread = threading.Thread(target=self.start_listening, daemon=True)\n",
    "        listen_thread.start()\n",
    "        \n",
    "        try:\n",
    "            while not self.should_stop:\n",
    "                time.sleep(0.1)  # Small delay to prevent CPU overuse\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Conversation ended by user\")\n",
    "        finally:\n",
    "            self.should_stop = True\n",
    "            self.stop_playback()\n",
    "            \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.p.terminate()\n",
    "\n",
    "def main():\n",
    "    audio_chat = SmoothAudioChat()\n",
    "    try:\n",
    "        audio_chat.run_conversation()\n",
    "    finally:\n",
    "        audio_chat.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import time\n",
    "import logging\n",
    "from tempfile import NamedTemporaryFile\n",
    "import os\n",
    "\n",
    "class SmoothAudioChat:\n",
    "    def __init__(self, sample_rate=44100, cooldown_time=0.5):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.is_playing = False\n",
    "        self.should_stop = False\n",
    "        self.is_speaking = False\n",
    "        self.cooldown_time = cooldown_time  # Cooldown after playback to avoid feedback\n",
    "        self.playback_lock = threading.Lock()\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        \n",
    "        # Audio detection parameters\n",
    "        self.silence_threshold = 300  # Adjust based on your microphone\n",
    "        self.speech_buffer = []\n",
    "        self.speech_detected = False\n",
    "\n",
    "    def _audio_callback(self, indata, frames, time, status):\n",
    "        \"\"\"Handle incoming audio data\"\"\"\n",
    "        if status:\n",
    "            self.logger.warning(f\"Audio input status: {status}\")\n",
    "        \n",
    "        # Calculate audio energy\n",
    "        energy = np.sqrt(np.mean(indata**2))\n",
    "        \n",
    "        # Check for speech detection\n",
    "        if energy > self.silence_threshold and not self.is_speaking:\n",
    "            if not self.speech_detected:\n",
    "                self.speech_detected = True\n",
    "                self.stop_playback()  # Stop playback if speech detected\n",
    "                self.speech_buffer = []\n",
    "            self.speech_buffer.extend(indata.flatten())\n",
    "            \n",
    "        elif self.speech_detected and energy <= self.silence_threshold:\n",
    "            # Process captured speech\n",
    "            self._process_speech()\n",
    "            self.speech_detected = False\n",
    "\n",
    "    def start_listening(self):\n",
    "        \"\"\"Start continuous audio input monitoring\"\"\"\n",
    "        try:\n",
    "            with sd.InputStream(callback=self._audio_callback,\n",
    "                                channels=1,\n",
    "                                samplerate=self.sample_rate):\n",
    "                while not self.should_stop:\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in audio input stream: {e}\")\n",
    "            \n",
    "            \n",
    "    def stop_playback(self):\n",
    "        \"\"\"Stop current audio playback if running\"\"\"\n",
    "        with self.playback_lock:\n",
    "            sd.stop()\n",
    "            self.is_speaking = False\n",
    "            \n",
    "    def text_to_speech(self, text):\n",
    "        \"\"\"Convert text to speech with high quality\"\"\"\n",
    "        with NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n",
    "            # Generate speech with gTTS\n",
    "            tts = gTTS(text=text, lang='en')\n",
    "            tts.save(temp_file.name)\n",
    "            \n",
    "            # Load audio file with better quality\n",
    "            audio_data, sample_rate = sf.read(temp_file.name)\n",
    "            \n",
    "            # Remove temporary file\n",
    "            os.unlink(temp_file.name)\n",
    "            \n",
    "            return audio_data, sample_rate\n",
    "            \n",
    "    def run_conversation(self):\n",
    "        \"\"\"Run the main conversation loop, listening for user input and repeating recognized speech\"\"\"\n",
    "        # Start listening thread\n",
    "        listen_thread = threading.Thread(target=self.start_listening, daemon=True)\n",
    "        listen_thread.start()\n",
    "        \n",
    "        try:\n",
    "            while not self.should_stop:\n",
    "                time.sleep(0.1)  # Small delay to prevent CPU overuse\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Conversation ended by user\")\n",
    "        finally:\n",
    "            self.should_stop = True\n",
    "            self.stop_playback()\n",
    "    \n",
    "    def _process_speech(self):\n",
    "        \"\"\"Process captured speech buffer\"\"\"\n",
    "        if not self.speech_buffer:\n",
    "            return\n",
    "            \n",
    "        # Save speech buffer to temporary WAV file\n",
    "        with NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            sf.write(temp_file.name, self.speech_buffer, self.sample_rate)\n",
    "        \n",
    "        # Use speech recognition\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(temp_file.name) as source:\n",
    "            try:\n",
    "                audio = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                self.logger.info(f\"Recognized: {text}\")\n",
    "                \n",
    "                if text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                    self.should_stop = True\n",
    "                    return\n",
    "                \n",
    "                response = f\"You said: {text}\"\n",
    "                self.logger.info(f\"Response text: {response}\")\n",
    "                \n",
    "                audio_data, sample_rate = self.text_to_speech(response)\n",
    "                self.logger.info(\"Text-to-speech conversion completed.\")\n",
    "                \n",
    "                # Play response\n",
    "                self.play_audio(audio_data, sample_rate)\n",
    "                    \n",
    "            except sr.UnknownValueError:\n",
    "                self.logger.info(\"Speech not understood\")\n",
    "            except sr.RequestError as e:\n",
    "                self.logger.error(f\"Recognition error: {e}\")\n",
    "            finally:\n",
    "                os.unlink(temp_file.name)\n",
    "\n",
    "    def play_audio(self, audio_data, sample_rate):\n",
    "        \"\"\"Play audio data with smooth playback\"\"\"\n",
    "        with self.playback_lock:\n",
    "            self.is_speaking = True\n",
    "            self.logger.info(\"Starting playback.\")\n",
    "            sd.play(audio_data, sample_rate)\n",
    "            sd.wait()\n",
    "            self.logger.info(\"Playback finished.\")\n",
    "            self.is_speaking = False\n",
    "            # Cooldown period to avoid feedback\n",
    "            time.sleep(self.cooldown_time)\n",
    "\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.p.terminate()\n",
    "\n",
    "def main():\n",
    "    audio_chat = SmoothAudioChat()\n",
    "    try:\n",
    "        audio_chat.run_conversation()\n",
    "    finally:\n",
    "        audio_chat.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.12.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 14:51:01,712 - INFO - Starting voice chat system...\n",
      "2024-11-10 14:51:01,726 - INFO - Adjusting for ambient noise...\n",
      "2024-11-10 14:51:02,758 - INFO - Ready to listen!\n",
      "2024-11-10 14:51:02,759 - INFO - Listening...\n",
      "2024-11-10 14:51:05,946 - INFO - Recognized: hello\n",
      "2024-11-10 14:51:05,948 - INFO - Listening...\n",
      "2024-11-10 14:51:11,739 - INFO - Listening...\n",
      "2024-11-10 14:51:15,098 - INFO - Recognized: tell me a story\n",
      "2024-11-10 14:51:15,100 - INFO - Listening...\n",
      "2024-11-10 14:51:20,296 - INFO - Recognized: tell me a story\n",
      "2024-11-10 14:51:20,297 - INFO - Listening...\n",
      "2024-11-10 14:51:26,181 - INFO - Recognized: tell me a story in Hindi\n",
      "2024-11-10 14:51:26,181 - INFO - Listening...\n",
      "2024-11-10 14:51:34,117 - INFO - Listening...\n",
      "2024-11-10 14:51:52,576 - INFO - Recognized: tell me about AI\n",
      "2024-11-10 14:51:52,578 - INFO - Listening...\n",
      "2024-11-10 14:52:12,236 - INFO - Recognized: tell me about machine learning\n",
      "2024-11-10 14:52:12,238 - INFO - Listening...\n",
      "2024-11-10 14:52:17,059 - INFO - Listening...\n",
      "2024-11-10 14:52:21,498 - INFO - Listening...\n",
      "2024-11-10 14:52:29,542 - INFO - Recognized: tell me about reinforcement learning\n",
      "2024-11-10 14:52:29,544 - INFO - Listening...\n",
      "2024-11-10 14:52:35,512 - INFO - Listening...\n",
      "2024-11-10 14:52:38,541 - INFO - Listening...\n",
      "2024-11-10 14:52:44,390 - INFO - Recognized: why we use auto cost 12 l l m training\n",
      "2024-11-10 14:52:44,392 - INFO - Listening...\n",
      "2024-11-10 14:52:52,962 - INFO - Listening...\n",
      "2024-11-10 14:52:58,931 - INFO - Recognized: why we use auto cost while training\n",
      "2024-11-10 14:52:58,933 - INFO - Listening...\n",
      "2024-11-10 14:53:04,013 - INFO - Listening...\n",
      "2024-11-10 14:53:07,767 - INFO - Listening...\n",
      "2024-11-10 14:53:11,948 - INFO - Listening...\n",
      "2024-11-10 14:53:13,783 - INFO - Listening...\n",
      "2024-11-10 14:53:21,370 - INFO - Stopping system...\n",
      "2024-11-10 14:53:21,980 - INFO - System stopped\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "import pygame\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import signal\n",
    "import os\n",
    "import numpy as np\n",
    "from threading import Event, Lock\n",
    "from langchain_ollama import ChatOllama\n",
    "import webrtcvad\n",
    "from langdetect import detect\n",
    "from collections import deque\n",
    "import sounddevice as sd\n",
    "\n",
    "class VoiceChatSystem:\n",
    "    def __init__(self, model_name=\"llama2:13b\"):\n",
    "        self.logger = self._setup_logger()\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.energy_threshold = 300  # Lowered threshold for better detection\n",
    "        self.text_queue = queue.Queue()\n",
    "        self.sentence_queue = queue.Queue()\n",
    "        self.audio_queue = deque(maxlen=10)  # Queue for batch audio processing\n",
    "        self.is_listening = True\n",
    "        self.current_task_id = 0\n",
    "        self.interrupt_event = Event()\n",
    "        self.speaking_event = Event()\n",
    "        self.speaking_lock = Lock()\n",
    "        self.is_system_speaking = False\n",
    "        self.last_system_audio_end = 0\n",
    "        self.silence_duration = 0.8  # Adjusted for better pause detection\n",
    "        self.current_sound = None\n",
    "        \n",
    "        # Initialize audio settings\n",
    "        pygame.mixer.init(frequency=16000, channels=2)\n",
    "        pygame.mixer.set_num_channels(4)\n",
    "        sd.default.samplerate = 16000\n",
    "        sd.default.channels = 2\n",
    "        \n",
    "        self.vad = webrtcvad.Vad(2)  # Reduced aggressiveness for better detection\n",
    "        self.model = ChatOllama(model=model_name)\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        logger = logging.getLogger('VoiceChatSystem')\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.setLevel(logging.INFO)\n",
    "        return logger\n",
    "\n",
    "    def is_valid_human_speech(self, audio_data, timestamp):\n",
    "        try:\n",
    "            raw_data = np.frombuffer(audio_data.frame_data, dtype=np.int16)\n",
    "            \n",
    "            # Calculate audio energy\n",
    "            audio_energy = np.abs(raw_data).mean()\n",
    "            \n",
    "            # Time since last system audio ended\n",
    "            time_since_system_audio = timestamp - self.last_system_audio_end\n",
    "            \n",
    "            # Adjust energy threshold based on system speech\n",
    "            energy_threshold = self.energy_threshold\n",
    "            if self.is_system_speaking or time_since_system_audio < 0.2:\n",
    "                energy_threshold *= 2\n",
    "            \n",
    "            if audio_energy < energy_threshold:\n",
    "                return False\n",
    "            \n",
    "            # VAD analysis\n",
    "            frame_duration = 30  # ms\n",
    "            frames = len(raw_data) // (16000 * frame_duration // 1000)\n",
    "            \n",
    "            if frames == 0:\n",
    "                return False\n",
    "                \n",
    "            speech_frames = 0\n",
    "            for i in range(frames):\n",
    "                start = i * (16000 * frame_duration // 1000)\n",
    "                end = start + (16000 * frame_duration // 1000)\n",
    "                frame = raw_data[start:end].tobytes()\n",
    "                \n",
    "                try:\n",
    "                    if self.vad.is_speech(frame, 16000):\n",
    "                        speech_frames += 1\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            speech_ratio = speech_frames / frames\n",
    "            min_speech_ratio = 0.3\n",
    "            \n",
    "            if self.is_system_speaking or time_since_system_audio < 0.2:\n",
    "                min_speech_ratio = 0.5\n",
    "            \n",
    "            return speech_ratio > min_speech_ratio\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in speech validation: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def speak_text(self, text, task_id):\n",
    "        if task_id != self.current_task_id or not text.strip():\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            if self.interrupt_event.is_set():\n",
    "                return False\n",
    "                \n",
    "            with self.speaking_lock:\n",
    "                self.is_system_speaking = True\n",
    "                self.speaking_event.set()\n",
    "                \n",
    "                lang = self.detect_language(text)\n",
    "                mp3_fp = BytesIO()\n",
    "                tts = gTTS(text=text, lang=lang)\n",
    "                tts.write_to_fp(mp3_fp)\n",
    "                mp3_fp.seek(0)\n",
    "                \n",
    "                temp_file = f\"temp_audio_{task_id}_{time.time()}.mp3\"\n",
    "                try:\n",
    "                    with open(temp_file, 'wb') as f:\n",
    "                        f.write(mp3_fp.getvalue())\n",
    "                    \n",
    "                    self.current_sound = pygame.mixer.Sound(temp_file)\n",
    "                    channel = pygame.mixer.find_channel()\n",
    "                    \n",
    "                    if channel is None:\n",
    "                        # Force stop all channels if none available\n",
    "                        for i in range(pygame.mixer.get_num_channels()):\n",
    "                            pygame.mixer.Channel(i).stop()\n",
    "                        channel = pygame.mixer.Channel(0)\n",
    "                    \n",
    "                    channel.play(self.current_sound)\n",
    "                    \n",
    "                    while channel.get_busy() and not self.interrupt_event.is_set():\n",
    "                        pygame.time.wait(10)\n",
    "                    \n",
    "                    channel.stop()\n",
    "                    self.current_sound = None\n",
    "                    \n",
    "                finally:\n",
    "                    if os.path.exists(temp_file):\n",
    "                        os.remove(temp_file)\n",
    "                \n",
    "                self.last_system_audio_end = time.time()\n",
    "                return not self.interrupt_event.is_set()\n",
    "                \n",
    "        finally:\n",
    "            self.is_system_speaking = False\n",
    "            self.speaking_event.clear()\n",
    "            mp3_fp.close()\n",
    "\n",
    "    def _clear_queues(self):\n",
    "        \"\"\"Clear all queues\"\"\"\n",
    "        try:\n",
    "            # Clear text queue\n",
    "            while True:\n",
    "                self.text_queue.get_nowait()\n",
    "                self.text_queue.task_done()\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Clear sentence queue\n",
    "            while True:\n",
    "                self.sentence_queue.get_nowait()\n",
    "                self.sentence_queue.task_done()\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        \n",
    "        self.logger.debug(\"Queues cleared\")\n",
    "\n",
    "    def immediate_interrupt(self):\n",
    "        self.interrupt_event.set()\n",
    "        \n",
    "        with self.speaking_lock:\n",
    "            # Stop current sound if exists\n",
    "            if self.current_sound is not None:\n",
    "                for i in range(pygame.mixer.get_num_channels()):\n",
    "                    pygame.mixer.Channel(i).stop()\n",
    "                self.current_sound = None\n",
    "            \n",
    "            # Clear audio queue\n",
    "            self.audio_queue.clear()\n",
    "            \n",
    "            # Clear all other queues\n",
    "            self._clear_queues()\n",
    "        \n",
    "        self.interrupt_event.clear()\n",
    "        self.is_system_speaking = False\n",
    "        self.last_system_audio_end = time.time()\n",
    "        self.logger.debug(\"System interrupted and all queues cleared\")\n",
    "\n",
    "    def listen_continuously(self):\n",
    "        with sr.Microphone() as source:\n",
    "            self.logger.info(\"Adjusting for ambient noise...\")\n",
    "            self.recognizer.dynamic_energy_threshold = True\n",
    "            self.recognizer.energy_threshold = self.energy_threshold\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            self.logger.info(\"Ready to listen!\")\n",
    "            \n",
    "            while self.is_listening:\n",
    "                try:\n",
    "                    self.logger.info(\"Listening...\")\n",
    "                    audio = self.recognizer.listen(source, phrase_time_limit=3)\n",
    "                    current_time = time.time()\n",
    "                    \n",
    "                    if not self.is_valid_human_speech(audio, current_time):\n",
    "                        continue\n",
    "                    \n",
    "                    # Interrupt and clear queues if new speech detected while system is speaking\n",
    "                    # or there's pending text in the queue\n",
    "                    if self.is_system_speaking or not self.text_queue.empty():\n",
    "                        self.immediate_interrupt()\n",
    "                    \n",
    "                    text = None\n",
    "                    for lang in ['en', 'hi', 'kn']:\n",
    "                        try:\n",
    "                            text = self.recognizer.recognize_google(audio, language=lang)\n",
    "                            if text:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if not text:\n",
    "                        continue\n",
    "                        \n",
    "                    if text.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
    "                        self.stop_system()\n",
    "                        break\n",
    "                    \n",
    "                    self.logger.info(f\"Recognized: {text}\")\n",
    "                    \n",
    "                    self.current_task_id += 1\n",
    "                    self.text_queue.put((text, self.current_task_id))\n",
    "                    \n",
    "                except sr.UnknownValueError:\n",
    "                    continue\n",
    "                except sr.RequestError as e:\n",
    "                    self.logger.error(f\"Could not request results: {str(e)}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error in listening: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    def process_text(self):\n",
    "        while self.is_listening:\n",
    "            try:\n",
    "                text, task_id = self.text_queue.get(timeout=1)\n",
    "                \n",
    "                if self.interrupt_event.is_set():\n",
    "                    continue\n",
    "                \n",
    "                current_sentence = \"\"\n",
    "                stream = self.model.stream(text)\n",
    "                \n",
    "                for chunk in stream:\n",
    "                    if self.interrupt_event.is_set() or task_id != self.current_task_id:\n",
    "                        break\n",
    "                    \n",
    "                    current_sentence += chunk.content\n",
    "                    sentences = re.split(r'([.!?]+)', current_sentence)\n",
    "                    \n",
    "                    while len(sentences) >= 2 and not self.interrupt_event.is_set():\n",
    "                        sentence = sentences.pop(0) + sentences.pop(0)\n",
    "                        if sentence.strip():\n",
    "                            self.sentence_queue.put((sentence, task_id))\n",
    "                    \n",
    "                    current_sentence = ''.join(sentences)\n",
    "                \n",
    "                if current_sentence.strip() and not self.interrupt_event.is_set():\n",
    "                    self.sentence_queue.put((current_sentence, task_id))\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in processing: {str(e)}\")\n",
    "\n",
    "    def speak_responses(self):\n",
    "        while self.is_listening:\n",
    "            try:\n",
    "                batch_text = \"\"\n",
    "                current_task_id = None\n",
    "                \n",
    "                # Collect sentences for batch processing\n",
    "                try:\n",
    "                    while len(batch_text.split()) < 50:  # Limit batch size\n",
    "                        sentence, task_id = self.sentence_queue.get_nowait()\n",
    "                        \n",
    "                        if current_task_id is None:\n",
    "                            current_task_id = task_id\n",
    "                        \n",
    "                        if task_id != current_task_id:\n",
    "                            # If task ID changes, process current batch first\n",
    "                            if batch_text.strip():\n",
    "                                self.audio_queue.append((batch_text.strip(), current_task_id))\n",
    "                            batch_text = sentence\n",
    "                            current_task_id = task_id\n",
    "                        else:\n",
    "                            batch_text += \" \" + sentence\n",
    "                        \n",
    "                except queue.Empty:\n",
    "                    if batch_text.strip():\n",
    "                        self.audio_queue.append((batch_text.strip(), current_task_id))\n",
    "                \n",
    "                # Process audio queue\n",
    "                while self.audio_queue and not self.interrupt_event.is_set():\n",
    "                    text, task_id = self.audio_queue.popleft()\n",
    "                    if not self.speak_text(text, task_id):\n",
    "                        break\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in speaking: {str(e)}\")\n",
    "\n",
    "    def detect_language(self, text):\n",
    "        try:\n",
    "            detected_lang = detect(text)\n",
    "            return detected_lang\n",
    "        except:\n",
    "            return 'en'\n",
    "\n",
    "    def stop_system(self):\n",
    "        self.logger.info(\"Stopping system...\")\n",
    "        self.is_listening = False\n",
    "        self.immediate_interrupt()\n",
    "        pygame.mixer.quit()\n",
    "\n",
    "    def start(self):\n",
    "        self.logger.info(\"Starting voice chat system...\")\n",
    "        threads = [\n",
    "            threading.Thread(target=self.listen_continuously, name=\"ListenThread\"),\n",
    "            threading.Thread(target=self.process_text, name=\"ProcessThread\"),\n",
    "            threading.Thread(target=self.speak_responses, name=\"SpeakThread\")\n",
    "        ]\n",
    "        \n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        \n",
    "        try:\n",
    "            while self.is_listening:\n",
    "                time.sleep(0.1)\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Keyboard interrupt detected, stopping...\")\n",
    "            self.stop_system()\n",
    "        \n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "        self.logger.info(\"System stopped\")\n",
    "\n",
    "def main():\n",
    "    system = VoiceChatSystem(model_name=\"llama3.2:1b\")\n",
    "    system.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
