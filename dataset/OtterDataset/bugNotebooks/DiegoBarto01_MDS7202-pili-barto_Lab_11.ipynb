{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyPTffTLug7i"
   },
   "source": [
    "# **Laboratorio 11: LLM y Agentes Autónomos 🤖**\n",
    "\n",
    "MDS7202: Laboratorio de Programación Científica para Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbWVyntzbvL"
   },
   "source": [
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6ikgVYzghB"
   },
   "source": [
    "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados**\n",
    "\n",
    "- Nombre de alumno 1: Diego Bartolucci\n",
    "- Nombre de alumno 2: Pilar Nilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMJ-owchzjFf"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/DiegoBarto01/MDS7202-pili-barto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUuwsXrKzmkK"
   },
   "source": [
    "## **Temas a tratar**\n",
    "\n",
    "- Reinforcement Learning\n",
    "- Large Language Models\n",
    "\n",
    "## **Reglas:**\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### **Objetivos principales del laboratorio**\n",
    "\n",
    "- Resolución de problemas secuenciales usando Reinforcement Learning\n",
    "- Habilitar un Chatbot para entregar respuestas útiles usando Large Language Models.\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hmHHQ9BuyAG"
   },
   "source": [
    "## **1. Reinforcement Learning (2.0 puntos)**\n",
    "\n",
    "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOcejYb6uzOO"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq gymnasium stable_baselines3\n",
    "!pip install -qqq swig\n",
    "!pip install -qqq gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBPet_Mq8dX9"
   },
   "source": [
    "### **1.1 Blackjack (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "La idea de esta subsección es que puedan implementar métodos de RL y así generar una estrategia para jugar el clásico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpZ8bBKk9ZlU"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(FlattenObservation, self).__init__(env)\n",
    "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.array(observation).flatten()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6J1_-Y9nHO"
   },
   "source": [
    "#### **1.1.1 Descripción de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRGtYpDwrL31"
   },
   "source": [
    "*Respuesta*\n",
    "\n",
    "El ambiente es una partida de BlackJack donde el objetivo es vencer al 'dealer' obteniendo cartas que sumen lo más cercano a 21 sin pasarse. La idea es lograr alcanzar una mejor mano de cartas que las del 'dealer', cumpliendo la retricción de los 21 puntos.\n",
    "\n",
    "\n",
    "Su formulción en MDP es la siguiente:\n",
    "\n",
    "\n",
    "\n",
    "*   Estados: tenemos estado inicial y final\n",
    "\n",
    "Inicial: se inicia el juego, el jugador suma sus cartas para que luego el 'Dealer' muestre las suyas y finalmente se puede utilizar un As.\n",
    "\n",
    "Final: el final del juego sucede cuando el jugador pide una carta más y la suma resulta ser mayor a 21. Otro caso es cuando el jugador se queda con las cartas que tiene en mano.\n",
    "*   Acciones: Hay dos acciones posibles\n",
    "\n",
    "0: Pegar/Stick donde se queda con las cartas actuales\n",
    "\n",
    "1: Golpear/Hit que implica robar una carta\n",
    "*   Recompensas:\n",
    "\n",
    "Las recompensas incluyen ganar 1 pto si se gana el juego, perder 1 pto si se pierde, 0 pts si se llega a un empate y 1.5 pts si se gana el juego con un natural blackjack.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcX6bRC9agQ"
   },
   "source": [
    "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 5000 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política? ¿Cómo podría interpretar las recompensas obtenidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p2PrLLR9yju"
   },
   "outputs": [],
   "source": [
    "#simulacion de escenario donde se escojen acciones aleatorias\n",
    "def simul_escenario(env, episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = env.action_space.sample()\n",
    "      obs, reward, done,_, info = env.step(action)\n",
    "      recompensas.append(reward)\n",
    "  return recompensas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8G1wIW8FyXC",
    "outputId": "dcde8597-53f9-436a-8644-0da98265e6eb"
   },
   "outputs": [],
   "source": [
    "#repeticion de la simulacion 5000 veces + promedio y desviasion de las recompensas\n",
    "repeat_5000=simul_escenario(env,5000)\n",
    "#saco promedio y desv estandar\n",
    "promedio=np.mean(repeat_5000)\n",
    "desviacion=np.std(repeat_5000)\n",
    "print(f\"El promedio de las recompensas es: {promedio}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOK1DsPqF4sK"
   },
   "source": [
    "*Respuesta*\n",
    "\n",
    "La performance de esta politica no es buena ya que el promedio de las recompensas es negativo indicando un escenario poco favorecedor ya que según los parametros de recompensas perdió la mayoría de las partidas jugadas. Además, la desviación estandar es alta lo que indica alta variación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEO_dY4x_SJu"
   },
   "source": [
    "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fe5ec97f9d9d41658645681bc46feb81",
      "a016f1af4e064a15af582d2f6ff4e730"
     ]
    },
    "id": "m9JsFA1wGmnH",
    "outputId": "44fb2e73-68ce-4ed4-bc88-26bd25e7768a"
   },
   "outputs": [],
   "source": [
    "#estoy entre box y multiProcessing\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "modelo=PPO(\"MlpPolicy\",env,verbose=1)\n",
    "modelo.learn(total_timesteps=int(2e5), progress_bar=True)\n",
    "modelo.save(\"modelo_blackjack_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bpdb8wZID1"
   },
   "source": [
    "#### **1.1.4 Evaluación de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-d7d8GFf7F6",
    "outputId": "919edd8a-c787-456b-c4a0-5ef70dc74a10"
   },
   "outputs": [],
   "source": [
    "#simulacion de 5000 veces más promedio y desviacion\n",
    "def simul_escenario_2(env,modelo,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs,_ = env.reset()\n",
    "    episodio_recompensa=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action,_state= modelo.predict(obs, deterministic=True)\n",
    "      obs, reward, done,truncated,info= env.step(action)\n",
    "      episodio_recompensa+=reward\n",
    "      recompensas.append(episodio_recompensa)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSVAZIPqUORA",
    "outputId": "061eb170-0d07-452b-9b0c-e122e01fc2e1"
   },
   "outputs": [],
   "source": [
    "repeat_5000_v2=simul_escenario_2(env,modelo,5000)\n",
    "#saco promedio y desv estandar\n",
    "promedio_2=np.mean(repeat_5000_v2)\n",
    "desviacion_2=np.std(repeat_5000_v2)\n",
    "print(f\"El promedio de las recompensas es: {promedio_2}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXYf8ElcB_m"
   },
   "source": [
    "*Comparación de escenarios*\n",
    "\n",
    "La performance del agente es mejor que el baseline ya que es más cercano a 0, pero sigue siendo un escenario desfavorable ya que indica que está perdiendo o empatando la mayoría de las jugadas.\n",
    "\n",
    "Lo que si, baja la variabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO-EsAaPAYEm"
   },
   "source": [
    "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
    "\n",
    "Genere una función que reciba un estado y retorne la accion del agente. Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
    "\n",
    "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
    "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
    "\n",
    "¿Son coherentes sus acciones con las reglas del juego?\n",
    "\n",
    "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8XlGyzwtRp"
   },
   "outputs": [],
   "source": [
    "#funcion que reciba un estado y retorne la accion del agente.\n",
    "def get_return_action(model,state):\n",
    "  action,_states= model.predict(state, deterministic=True)\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJGILrwhGKwD"
   },
   "outputs": [],
   "source": [
    "#escenario 1: suma de las cartas es 6, dealer muestra un 7, agente no tiene un as\n",
    "escenario_1=np.array([6,7,0])\n",
    "#escenario 2: suma de las cartas del agente es 19, dealer muestra un 3, agente tiene un as\n",
    "escenario_2=np.array([19,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aoDSByRhBlV",
    "outputId": "0ffef154-3f9d-4b5c-c2fd-526bc4ae916f"
   },
   "outputs": [],
   "source": [
    "#accion del escenario 1\n",
    "accion_1=get_return_action(modelo,escenario_1)\n",
    "#accion del escenario 2\n",
    "accion_2=get_return_action(modelo,escenario_2)\n",
    "print(f\"La accion del escenario 1 es: {accion_1}\")\n",
    "print(f\"La accion del escenario 2 es: {accion_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWM_lJMGZYb"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "Si, son coherentes con las reglas del juego ya que en el primer escenario el dealer tiene mayor puntaje y pide otra carta para poder ganar y en el segundo escenario el dealer no supera la cantidad del agente por lo cual no se necesita de otra carta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqCTqqroh03"
   },
   "source": [
    "### **1.2 LunarLander**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
    "\n",
    "Comencemos preparando el ambiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq16l2-0u1o8"
   },
   "source": [
    "*Se tuvo que utilizar LunarLander-v3 ya que arrojaba error la version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvQUyuZ_FtZ4",
    "outputId": "1c7989d7-dadd-452f-8995-78defcc691da"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBU4lGX3wpN6"
   },
   "source": [
    "Noten que se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?\n",
    "\n",
    "Además, se le facilita la función `export_gif` para el ejercicio 2.2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRiWpSo9yfr9",
    "outputId": "ce3438fc-b15c-4db7-9001-7b0fd8b7d6c3"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def export_gif(model, n = 5):\n",
    "  '''\n",
    "  función que exporta a gif el comportamiento del agente en n episodios\n",
    "  '''\n",
    "  images = []\n",
    "  for episode in range(n):\n",
    "    obs = model.env.reset()\n",
    "    img = model.env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "      images.append(img)\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, reward, done, info = model.env.step(action)\n",
    "      img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfOGQOYQGh7Y"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "El continuos=True indica que necesitamos tener un espacio de acción continuo en lugar de uno discreto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk5VJVppXh3N"
   },
   "source": [
    "#### **1.2.1 Descripción de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
    "\n",
    "Nota: recuerde que se especificó el parámetro `continuous = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdSFEQFeGncD"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "El ambiente LunarLander es un problema de optimización de trayectoria de cohete.\n",
    "\n",
    "Su formulacion en MDP se compone de:\n",
    "\n",
    "*  Estados:\n",
    "  * Inicial: la nave se encuentra en el centro superior de la ventana gráfica.\n",
    "  * Final: el episodio termina el los siguientes casos--> a) aterrizaje y se estrella;\n",
    "  b) aterrizaje sale de la ventana gráfica; c) modulo de aterrizaje no está despierto, i.e no se mueve y no choca con ningun otro cuerpo.\n",
    "*  Acciones: Existen 4 tipos de acciones\n",
    "    * 0: no hace nada\n",
    "    * 1: se enciendo propulsor de orientación izquierda\n",
    "    * 2: encender propulsor central\n",
    "    * 3: encender propulsor de orientación derecha\n",
    "*  Recompensas:\n",
    "  * aumenta/disminuye cuanto más lento/rápido se mueve el modulo de aterrizaje de la plataforma de aterrizaje\n",
    "  * aumenta/disminuye cuanto más lento/rápido se mueve el modulo de aterrizaje\n",
    "  * disminuye cuanto más se inclina el modulo de aterrizaje (angulo no horizontal)\n",
    "  * +10 puntos por cada pierna qu esté en contacto con el suelo\n",
    "  * -0.03 puntos cada cuadro en que se activa un motor lateral\n",
    "  * -0.3 puntos cada vez que se activa el motor principal\n",
    "  * El episodio recibe +100/-100 por aterrizar de forma segura o estrellarse respectivamente.\n",
    "  * Episodio se considera solución si obtiene al menos 200pts.\n",
    "\n",
    "\n",
    "La diferencia con el ambiente black jack es que a partir de los puntos obtenidos en recompensas se considera si un episodio es optimo o no y con ello la solución, no así en el ambiente de black jack donde no requiere de un óptimo para definir una solución. Tambien las acciones disponibles para cada ambiente son distintas, en blackJack son 2 y en LunarLander 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChodtNQwzG2"
   },
   "source": [
    "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwc3A0GX7a8"
   },
   "outputs": [],
   "source": [
    "#simulacion de escenario con acciones aleatorias\n",
    "def simul_lunar_lander( env,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs = env.reset()\n",
    "    recompensa_episodios=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = env.action_space.sample()\n",
    "      obs, reward, done,_, info = env.step(action)\n",
    "      recompensa_episodios+=reward\n",
    "      recompensas.append(recompensa_episodios)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4RIy-xFHBM2",
    "outputId": "639b78f4-2778-494e-e627-f43a0a7b00b8"
   },
   "outputs": [],
   "source": [
    "#simulacion repetida 10 veces + promedio y desviacion estandar\n",
    "repeat_10=simul_lunar_lander(env,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_3=np.mean(repeat_10)\n",
    "desviacion_3=np.std(repeat_10)\n",
    "print(f\"El promedio de las recompensas es: {promedio_3}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udWCFjkZHEtA"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "La perfomance de la politica no es favorable ya que indica que en promedio se mueve lento el modulo de aterrizaje, quizás se estrelló o simplemente una mala ejecución dentro del episodio ya que el promedio es negativo.\n",
    "\n",
    "La desviación estandar indica que tiene alta variabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrZVQflX_5f"
   },
   "source": [
    "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "cb825334821247da82da7b8092d583b1",
      "24672228afdf43a7ac291d34e40fc5dc"
     ]
    },
    "id": "y_6Ia9uoF7Hs",
    "outputId": "68c13cff-316b-4dbc-8318-3a6110c19645"
   },
   "outputs": [],
   "source": [
    "modelo_lunar=PPO('MlpPolicy',env,verbose=0)\n",
    "modelo_lunar.learn(total_timesteps=int(1e4),progress_bar=True)\n",
    "modelo_lunar.save(\"modelo_lunar_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z-oIUSrlAsY"
   },
   "source": [
    "#### **1.2.4 Evaluación de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophyU3KrWrwl"
   },
   "outputs": [],
   "source": [
    "def simul_lunar_lander_2(env,modelo,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs,_ = env.reset()\n",
    "    episodio_recompensa=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action,_state= modelo.predict(obs, deterministic=True)\n",
    "      obs, reward, done,truncated,info= env.step(action)\n",
    "      episodio_recompensa+=reward\n",
    "    recompensas.append(episodio_recompensa)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nj2_XqCusfTg",
    "outputId": "532b8428-97e8-4233-b854-5551c5c18345"
   },
   "outputs": [],
   "source": [
    "recompensa_lunar=simul_lunar_lander_2(env,modelo_lunar,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_4=np.mean(recompensa_lunar)\n",
    "desviacion_4=np.std(recompensa_lunar)\n",
    "print(f\"El promedio de las recompensas es: {promedio_4}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLgpHP9mZvdp"
   },
   "source": [
    "la perfomance mejora en cuanto al promedio ya que indica que se cometen menos errores en la obtencion de las recompensas.\n",
    "\n",
    "En cambio la desviacion estandar baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6Xw4YHT3P5d"
   },
   "source": [
    "#### **1.2.5 Optimización de modelo (0.2 puntos)**\n",
    "\n",
    "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
    "- `total_timesteps`\n",
    "- `learning_rate`\n",
    "- `batch_size`\n",
    "\n",
    "Una vez optimizado el modelo, use la función `export_gif` para estudiar el comportamiento de su agente en la resolución del ambiente y comente sobre sus resultados.\n",
    "\n",
    "Adjunte el gif generado en su entrega (mejor aún si además adjuntan el gif en el markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "960232292ef34a69892c6c82fd9002b0",
      "f510e51d696b40b4a3e39a6639842c3e"
     ]
    },
    "id": "aItYF6sr6F_6",
    "outputId": "6f6d2f46-c850-4641-fdc0-1e71a5e70340"
   },
   "outputs": [],
   "source": [
    "modelo_modificado=PPO('MlpPolicy',env,verbose=0,learning_rate=0.0001,batch_size=32,seed=400)\n",
    "modelo_modificado.learn(total_timesteps=int(1e6),progress_bar=True)\n",
    "modelo_modificado.save(\"modelo_lunar_modificado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0L_aTq4s6RO"
   },
   "outputs": [],
   "source": [
    "recompensa_modelo_modificado=simul_lunar_lander_2(env,modelo_modificado,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_5=np.mean(recompensa_modelo_modificado)\n",
    "desviacion_5=np.std(recompensa_modelo_modificado)\n",
    "print(f\"El promedio de las recompensas es: {promedio_5}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPUY-Ktgf2BO"
   },
   "source": [
    "## **2. Large Language Models (4.0 puntos)**\n",
    "\n",
    "En esta sección se enfocarán en habilitar un Chatbot que nos permita responder preguntas útiles a través de LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4fPRRihGLe"
   },
   "source": [
    "### **2.0 Configuración Inicial**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Como siempre, cargamos todas nuestras API KEY al entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ud2Xm_k-hFJn",
    "outputId": "03ef03be-df2f-4be0-8b83-68a798e7537d"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tX4LAylx9n5A",
    "outputId": "b7768356-cf65-4e01-cd5c-fbf1a9db3fed"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbIwNXUXCzgi",
    "outputId": "7603ca29-f99b-46d6-8417-6f3dca19a4dd"
   },
   "outputs": [],
   "source": [
    "# Se carga el modelo visto en clases\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
    "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
    "    max_tokens=None, # sin tope de tokens\n",
    "    timeout=None, # sin timeout\n",
    "    max_retries=2, # número máximo de intentos\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9JvQUsgZZJ"
   },
   "source": [
    "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsección es que habiliten un chatbot que pueda responder preguntas usando información contenida en documentos PDF a través de **Retrieval Augmented Generation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxOQroVnaZ5"
   },
   "source": [
    "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
    "\n",
    "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
    "  - 2 documentos .pdf como mínimo.\n",
    "  - 50 páginas de contenido como mínimo entre todos los documentos.\n",
    "  - Ideas para documentos: Documentos relacionados a temas académicos, laborales o de ocio. Aprovechen este ejercicio para construir algo útil y/o relevante para ustedes!\n",
    "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
    "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
    "  - **Recuerden adjuntar los documentos en su entrega**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5D1tIRCi4oJJ",
    "outputId": "a33ade8a-0a78-4136-995d-2be1f6c26cec"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzq2TjWCnu15"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "doc_paths = ['53701409.pdf','Super_Mario_Bros.pdf','Mario_interior_OK_MK.0.pdf', 'Mario_fuera_del_reino_de_Nintendo.pdf','Descripcion_Mario_Bros.pdf'] # rellenar con los path a sus documentos\n",
    "\n",
    "assert len(doc_paths) >= 2, \"Deben adjuntar un mínimo de 2 documentos\"\n",
    "\n",
    "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
    "assert total_paginas >= 50, f\"Páginas insuficientes: {total_paginas}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGkAOKlP-iZC",
    "outputId": "b8e79060-4a80-4173-a51c-5131d8f67031"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet faiss-cpu langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11cIpkozFhFV",
    "outputId": "40226817-bc23-4e3b-8f7a-5a8be2794c97"
   },
   "outputs": [],
   "source": [
    "#Se guardan los documentos en una lista\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "docus = []\n",
    "for doc in doc_paths:\n",
    "  loader = PyPDFLoader(doc)\n",
    "  docus += loader.load()\n",
    "  print(f\"Se cargó el documento {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EmVy9GIGChX",
    "outputId": "fc9d73e0-2d23-455a-f2ad-f1e4bca2ef7b"
   },
   "outputs": [],
   "source": [
    "len(docus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zdr-oFmz_B-Y",
    "outputId": "3f2698b7-fee2-413d-96e0-5e127add7d8e"
   },
   "outputs": [],
   "source": [
    "docus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r811-P71nizA"
   },
   "source": [
    "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
    "\n",
    "Vectorice los documentos y almacene sus representaciones de manera acorde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-yXAdCSn4JM",
    "outputId": "e2e4a79a-e2b7-4166-ad87-143530a34611"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docus)\n",
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlvgsx4RGQLB",
    "outputId": "d2931fba-be03-4cf8-fca0-43d26f4952bc"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUkP5zrnyBK"
   },
   "source": [
    "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
    "\n",
    "Habilite la solución RAG a través de una *chain* y guárdela en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPIySdDFn99l",
    "outputId": "62f4cc0f-0d81-4ab9-8354-8c04cf665958"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", # método de búsqueda\n",
    "                                     search_kwargs={\"k\": 3}, # n° documentos a recuperar\n",
    "                                     )\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6naFAlSXS86o"
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever_chain = retriever | format_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycg5S5i_n-kL"
   },
   "source": [
    "#### **2.1.4 Verificación de respuestas (0.5 puntos)**\n",
    "\n",
    "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su solución para cada una. ¿Su solución RAG entrega las respuestas que esperaba?\n",
    "\n",
    "Ejemplo de tupla:\n",
    "- Pregunta: ¿Quién es el presidente de Chile?\n",
    "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_UiEn1hoZYR"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# noten como ahora existe el parámetro de context!\n",
    "rag_template = '''\n",
    "Eres un asistente experto en los videojuegos, específicamente en el videojuego llamado \"Super Mario Bros\" y su historia.\n",
    "Tu único rol es contestar preguntas del usuario a partir de información relevante que te sea proporcionada.\n",
    "Responde siempre de la forma más completa posible y usando toda la información entregada.\n",
    "Responde sólo lo que te pregunten a partir de la información relevante, NUNCA inventes una respuesta.\n",
    "\n",
    "Información relevante: {context}\n",
    "Pregunta: {question}\n",
    "Respuesta útil:\n",
    "'''\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CcKzcGAvY5-"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasará directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos sólo la respuesta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h51tdM5v1sg",
    "outputId": "e0e17776-8a12-4277-b67c-161ac6c46195"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 1\n",
    "question1 = \"Quién en Mario?\"\n",
    "res_esp1 = \"Mario es el protagonista de la saga de juegos Super Mario Bros e icono de la compañía de videojuegos Japonesa Nintendo.\"\n",
    "response1 = rag_chain.invoke(question1)\n",
    "print(\"Respuesta esperada: \" + str(res_esp1))\n",
    "print(\"Respuesta obtenida: \" + str(response1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT39Hpi85xE3",
    "outputId": "990468c3-3727-4f23-d219-31d30646fc67"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 2\n",
    "question2 = \"Qué relación tiene Mario con Luigi?\"\n",
    "res_esp2 = \"Luigi es el hermano menor de Mario\"\n",
    "response2 = rag_chain.invoke(question2)\n",
    "print(\"Respuesta esperada: \" + str(res_esp2))\n",
    "print(\"Respuesta obtenida: \" + str(response2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTItqtgE5wtg",
    "outputId": "6c1ef23b-f0fe-4dc3-a1d7-455dda42f700"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 3\n",
    "question3 = \"Quién es Bowser?\"\n",
    "res_esp3 = \"Bowser es el enemigo de Mario\"\n",
    "response3= rag_chain.invoke(question3)\n",
    "print(\"Respuesta esperada: \" + str(res_esp3))\n",
    "print(\"Respuesta obtenida: \" + str(response3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK0HSKigNSHq"
   },
   "source": [
    "Observando las respuestas se puede concluir que responde correctamente la pregunta realizada e incluso desarrolla más aún la idea con los datos proporcionados utilizando la mayor cantidad de información que posee.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8d5zTMHoUgF"
   },
   "source": [
    "#### **2.1.5 Sensibilidad de Hiperparámetros (0.5 puntos)**\n",
    "\n",
    "Extienda el análisis del punto 2.1.4 analizando cómo cambian las respuestas entregadas cambiando los siguientes hiperparámetros:\n",
    "- `Tamaño del chunk`. (*¿Cómo repercute que los chunks sean mas grandes o chicos?*)\n",
    "- `La cantidad de chunks recuperados`. (*¿Qué pasa si se devuelven muchos/pocos chunks?*)\n",
    "- `El tipo de búsqueda`. (*¿Cómo afecta el tipo de búsqueda a las respuestas de mi RAG?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDh_QgeXLGHc"
   },
   "outputs": [],
   "source": [
    "#Empezamos generando listas con las preguntas a hacer y respuestas esperadas\n",
    "questions_list = [question1, question2, question3]\n",
    "expected_answers = [res_esp1, res_esp2, res_esp3]\n",
    "\n",
    "#Posteriormente creamos una función para evaluar el funcionamiento cambiando parámetros\n",
    "#Se crea esta función para no tener que repetir el código una y otra vez\n",
    "def sensibilidad(chunk_size: int = 500, cant_chunks: int = 3, search_type: str = 'similarity'):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "  splits = text_splitter.split_documents(docus)\n",
    "\n",
    "  embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "  vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
    "\n",
    "  retriever = vectorstore.as_retriever(search_type=search_type, # método de búsqueda\n",
    "                                     search_kwargs={\"k\": cant_chunks}, # n° documentos a recuperar\n",
    "                                     )\n",
    "  retriever_chain = retriever | format_docs\n",
    "\n",
    "  rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasará directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos sólo la respuesta\n",
    "  )\n",
    "\n",
    "  for i in range(len(questions_list)):\n",
    "    response = rag_chain.invoke(questions_list[i])\n",
    "    print(\"Pregunta: \" + str(questions_list[i]))\n",
    "    print(\"Respuesta esperada: \" + str(expected_answers[i]))\n",
    "    print(\"Respuesta obtenida: \" + str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIId1d-wnKpb"
   },
   "source": [
    "**SENSIBILIDAD ANTE EL TAMAÑO DE LOS CHUNKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U64hVREbmjuu",
    "outputId": "2309d091-c5e1-4a78-fbf3-d8eef5098b65"
   },
   "outputs": [],
   "source": [
    "#Ahora empezamos a variar los parámetros para evaluar la sensibilidad del modelo a estos\n",
    "sensibilidad(chunk_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_RVGdxpm9FK",
    "outputId": "c36e61ca-b003-4f83-8fae-785231c725d4"
   },
   "outputs": [],
   "source": [
    "sensibilidad(chunk_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hoAkFg0nJGd"
   },
   "source": [
    "Se observa que al achicar el tamaño de los chunks las respuestas son más precisas pero sujetas a mucho detalle repercutiendo en respuestas que nos entregan información que no pedimos. Al aumentar el tamaño de los chunks se ven respuestas más concisas y precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YXkFMPsnokG"
   },
   "source": [
    "**SENSIBILIDAD ANTE LA CANTIDAD DE CHUNKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDK7keMsnxTK",
    "outputId": "f3ee21a8-e749-4a50-ffd6-4c11e9aca29d"
   },
   "outputs": [],
   "source": [
    "sensibilidad(cant_chunks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFRMKc7Sn1eF",
    "outputId": "1519ab34-3ed8-4b19-b7d1-df8dcb80f883"
   },
   "outputs": [],
   "source": [
    "sensibilidad(cant_chunks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6dWSGdxn3Pu"
   },
   "source": [
    "Se observa que al disminuir la cantidad de chunks la información recopilada de los documentos es menor, llegando a entregar respuestas que, a pesar de estar la información, están incompletas o bien incorrectas. Al aumentar la cantidad de chunks se observa como las respuestas entregadas son más completas ya que se abarca más información presente en los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3uG7GE4n48S"
   },
   "source": [
    "**SENSIBILIDAD ANTE EL TIPO DE BÚSQUEDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdWFqlhin8kp",
    "outputId": "d1fc18e7-00e8-48af-8a42-210382a4292c"
   },
   "outputs": [],
   "source": [
    "sensibilidad(search_type='mmr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qplFFWlooAil"
   },
   "source": [
    "Se observan respuestas similares al uso de similarity, pero se puede observar una mayor diversidad en el contenido de la respuesta que con este otro método. Esto debido a que usando mmr se utilizan chunks distintos entre sí generando una respuesta más variada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJiPPM0giX8"
   },
   "source": [
    "### **2.2 Agentes (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la sección anterior, en esta sección se busca habilitar **Agentes** para obtener información a través de tools y así responder la pregunta del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47l7Mjfrk0N"
   },
   "source": [
    "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas al motor de búsqueda **Tavily**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6SLKwcWr0AG"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool_tavily = TavilySearchResults(max_results = 1) # inicializamos tool\n",
    "tools = []\n",
    "tools.append(tool_tavily) # guardamos las tools en una lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonB1A-9rtRq"
   },
   "source": [
    "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
    "\n",
    "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9_slKnVPOuc",
    "outputId": "c0ef5342-4729-47a9-b342-914920187b49"
   },
   "outputs": [],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehJJpoqsr26-"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(lang='es', top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "tools.append(wiki_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUIMdX6r0ne"
   },
   "source": [
    "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
    "\n",
    "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Asegúrese que su agente responda en español. Por último, guarde el agente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pD1_n0wrsDI5",
    "outputId": "7edd7d1e-916a-4191-e4d1-b71da6a8b487"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "react_prompt = hub.pull(\"hwchase17/react\") # template de ReAct\n",
    "print(react_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLNmImEmy-ma",
    "outputId": "3bc38eb7-d3c2-44e5-fb32-ce90b95e8f8d"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # lo transformamos a AgentExecutor para habilitar la ejecución de tools\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKV0JxK3r-XG"
   },
   "source": [
    "#### **2.2.4 Verificación de respuestas (0.3 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente y asegúrese que el agente esté ocupando correctamente las tools disponibles. ¿En qué casos el agente debería ocupar la tool de Tavily? ¿En qué casos debería ocupar la tool de Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pqo2dsxvywW_",
    "outputId": "4d751706-4e7e-4b41-85b9-e11b17aa434a"
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Quién es Taylor Swift?\"}) #Hacer una pregunta\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ypJC8dhzcie",
    "outputId": "e087dffc-2aec-45c8-da07-ee39da7dedd4"
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Quién dijo en una película la frase: Santa cachucha ya dijo la frase?\"}) #Hacer otra pregunta\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIxAi4eISbV8"
   },
   "source": [
    "El agente debería utilizar wikipedia en casos que la información se pueda encontrar ahí como casos de historia, ciencia, etc. Mientras que tavily debería ser utilizado para casos más específicos pudiendo encontrar esta información en la web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbDTYiogquv"
   },
   "source": [
    "### **2.3 Multi Agente (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
    "\" width=\"450\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsección es encapsular las funcionalidades creadas en una solución multiagente con un **supervisor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-iUfH0WvI6m"
   },
   "source": [
    "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
    "\n",
    "Transforme la solución RAG de la sección 2.1 y el agente de la sección 2.2 a *tools* (una tool por cada uno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw1cfTtvv1AZ"
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def RAG(input:str) -> str:\n",
    "  \"\"\"Usa el modelo RAG para responder el input\"\"\"\n",
    "  return rag_chain.invoke(input)\n",
    "\n",
    "@tool\n",
    "def agent(input:str) -> str:\n",
    "  \"\"\"Usa el modelo ReAct para responder el input\"\"\"\n",
    "  return agent_executor.invoke({\"input\": input})[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQYNjT_0vPCg"
   },
   "source": [
    "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
    "\n",
    "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "yv2ZY0BAv1RD",
    "outputId": "18dbd83e-9f34-4c9f-9812-f2266021f0f8"
   },
   "outputs": [],
   "source": [
    "supervisor_agent_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un supervisor de preguntas.\n",
    "    Tu único rol es seleccionar que acción tomar para responder correctamente la pregunta:\n",
    "    - 'mario': Cuando la pregunta esté relacionada con Super Mario Bros, sus personajes o los videojuegos.\n",
    "    - 'internet': Cuando la pregunta es de conocimiento general y puede ser respondida utilizando wikipedia o usando tavily.\n",
    "    - 'otro': Todo aquella pregunta que no esté contenida en las categorías anteriores.\n",
    "\n",
    "    No respondas con más de una palabra y no incluyas.\n",
    "\n",
    "\n",
    "    {question}\n",
    "\n",
    "\n",
    "    Categoría:\"\"\"\n",
    ")\n",
    "\n",
    "supervisor_agent_chain = (\n",
    "    supervisor_agent_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "supervisor_agent_chain.invoke({\"question\": \"Quién fue Mozart??\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "8FKSvYwmfGlq",
    "outputId": "a2d2e6b8-7ae2-49d8-d0a1-3b5478166a2d"
   },
   "outputs": [],
   "source": [
    "redirect_agent_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un asistente de redireccionamiento de preguntas de usuarios.\n",
    "    Vas a recibir una pregunta del usuario, tu único rol es indicar cuando no puedes responder su pregunta y redireccionar al usuario\n",
    "    para que te pregunte sobre videojuegos, sobre tu videojuego favorito Super Mario Bros o bien información de cultura general que\n",
    "    pueda ser encontrada en wikipedia o usando tavily.\n",
    "\n",
    "    Recuerda ser amable y cordial en tu respuesta.\n",
    "\n",
    "    Pregunta: {question}\n",
    "    Respuesta cordial:\"\"\"\n",
    ")\n",
    "\n",
    "redirect_agent_chain = (\n",
    "    redirect_agent_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "redirect_agent_chain.invoke({\"question\": \"Quién fue Mozart?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNxi4sYpfliI"
   },
   "outputs": [],
   "source": [
    "def route_question(question):\n",
    "  '''\n",
    "  Recibe una pregunta de usuario.\n",
    "  Rutea la pregunta al agente respectivo y responde de manera acorde.\n",
    "  '''\n",
    "\n",
    "  topic = supervisor_agent_chain.invoke({\"question\": question}) # enrutamiento\n",
    "\n",
    "  if \"mario\" in topic: # si la pregunta es de mario o videojuegos, utilizar rag\n",
    "      return rag_chain.invoke(question)\n",
    "  elif \"internet\" in topic: # si la pregunta es de cultura general, utilizar agente\n",
    "      return agent_executor.invoke({\"input\": question})[\"output\"]\n",
    "  else: # de lo contrario, redireccionar pregunta\n",
    "      return redirect_agent_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3zWlvyvY7K"
   },
   "source": [
    "#### **2.3.3 Verificación de respuestas (0.25 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¿Cómo varían las respuestas bajo este enfoque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "6_1t0zkgv1qW",
    "outputId": "2ed79a6b-bee5-4930-c316-a69cff3fff65"
   },
   "outputs": [],
   "source": [
    "route_question(\"Quién en Mario?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8yknRPNWRdt2",
    "outputId": "9ced8d5a-f538-446c-e848-9ff0836a7937"
   },
   "outputs": [],
   "source": [
    "route_question(\"Qué relación tiene Mario con Luigi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "B0tnuj7uRjtm",
    "outputId": "c163b143-613f-419d-d1da-a63ca075fd12"
   },
   "outputs": [],
   "source": [
    "route_question(\"Quién es Taylor Swift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "OeIZgxYmRbnv",
    "outputId": "36451a3b-fb87-46f3-d1b4-186d84ab286a"
   },
   "outputs": [],
   "source": [
    "route_question(\"Quién dijo en una película la frase: Santa cachucha ya dijo la frase?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvm8MeXvSFRu"
   },
   "source": [
    "Las respuestas entregadas no varían mucho, siendo la mayor diferencia que no constesta la última pregunta al ser muy rebuscada a pesar de que se encuentra en internet usando Tavily considera que corresponde a la categoría de \"otro\", principalmente porque no considera que esta respuesta sea conocimiento general como le fue pedido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8bdAmYvgwn"
   },
   "source": [
    "#### **2.3.4 Análisis (0.25 puntos)**\n",
    "\n",
    "¿Qué diferencias tiene este enfoque con la solución *Router* vista en clases? Nombre al menos una ventaja y desventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAUlJxqoLK5r"
   },
   "source": [
    "El agente supervisor utiliza un modelo de lenguaje para razonar de manera dinámica y decidir qué herramientas emplear, lo que le permite adaptarse con facilidad a diferentes situaciones y resolver problemas en tiempo real. En contraste, el Router opera siguiendo un conjunto de reglas establecidas, lo que lo hace más rápido y eficiente, pero menos capaz de enfrentar escenarios ambiguos o no planificados. Aunque el agente supervisor destaca por su capacidad para abordar casos complejos sin depender de reglas fijas, este enfoque requiere un mayor esfuerzo computacional debido a su uso constante del modelo de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWVSuWiZ8Mj"
   },
   "source": [
    "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
    "\n",
    "- Pregunta 1: \"Hola! mi nombre es Sebastián\"\n",
    "  - Respuesta esperada: \"Hola Sebastián! ...\"\n",
    "- Pregunta 2: \"Cual es mi nombre?\"\n",
    "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
    "  - **Respuesta esperada: \"Tu nombre es Sebastián\"**\n",
    "\n",
    "Para solucionar esto, se les solicita agregar un componente de **memoria** a la solución entregada en el punto 2.3.\n",
    "\n",
    "**Nota: El Bonus es válido <u>sólo para la sección 2 de Large Language Models.</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iqwj4e_JTUVj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFc3jBT5g0kT"
   },
   "source": [
    "### **2.5 Despliegue (0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a través de `gradio`, una librería especializada en el levantamiento rápido de demos basadas en ML.\n",
    "\n",
    "Primero instalamos la librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8TsvnCPbkIA"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJBztEUovKsF"
   },
   "source": [
    "Luego sólo deben ejecutar el siguiente código e interactuar con la interfaz a través del notebook o del link generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3KedQSvg1-n"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def agent_response(message, history):\n",
    "  '''\n",
    "  Función para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
    "  '''\n",
    "  # get chatbot response\n",
    "  response = ... # rellenar con la respuesta de su chat\n",
    "\n",
    "  # assert\n",
    "  assert type(response) == str, \"output de route_question debe ser string\"\n",
    "\n",
    "  # \"streaming\" response\n",
    "  for i in range(len(response)):\n",
    "    time.sleep(0.015)\n",
    "    yield response[: i+1]\n",
    "\n",
    "gr.ChatInterface(\n",
    "    agent_response,\n",
    "    type=\"messages\",\n",
    "    title=\"Chatbot MDS7202 - PiliBarto\", # Pueden cambiar esto si lo desean\n",
    "    description=\"Hola! Soy un chatbot muy útil >:)\", # también la descripción\n",
    "    theme=\"soft\",\n",
    "    ).launch(\n",
    "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
    "        debug = False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24672228afdf43a7ac291d34e40fc5dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "960232292ef34a69892c6c82fd9002b0": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f510e51d696b40b4a3e39a6639842c3e",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">1,001,445/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:19:59</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">253 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1,001,445/1,000,000 \u001b[0m [ \u001b[33m1:19:59\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m253 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "a016f1af4e064a15af582d2f6ff4e730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb825334821247da82da7b8092d583b1": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_24672228afdf43a7ac291d34e40fc5dc",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,218/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:22</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">438 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10,218/10,000 \u001b[0m [ \u001b[33m0:00:22\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m438 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "f510e51d696b40b4a3e39a6639842c3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe5ec97f9d9d41658645681bc46feb81": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_a016f1af4e064a15af582d2f6ff4e730",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">200,648/200,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:09:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">371 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200,648/200,000 \u001b[0m [ \u001b[33m0:09:16\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m371 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
