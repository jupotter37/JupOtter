{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyPTffTLug7i"
   },
   "source": [
    "# **Laboratorio 11: LLM y Agentes Aut칩nomos 游뱄**\n",
    "\n",
    "MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbWVyntzbvL"
   },
   "source": [
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6ikgVYzghB"
   },
   "source": [
    "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados**\n",
    "\n",
    "- Nombre de alumno 1: Diego Bartolucci\n",
    "- Nombre de alumno 2: Pilar Nilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMJ-owchzjFf"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/DiegoBarto01/MDS7202-pili-barto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUuwsXrKzmkK"
   },
   "source": [
    "## **Temas a tratar**\n",
    "\n",
    "- Reinforcement Learning\n",
    "- Large Language Models\n",
    "\n",
    "## **Reglas:**\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### **Objetivos principales del laboratorio**\n",
    "\n",
    "- Resoluci칩n de problemas secuenciales usando Reinforcement Learning\n",
    "- Habilitar un Chatbot para entregar respuestas 칰tiles usando Large Language Models.\n",
    "\n",
    "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hmHHQ9BuyAG"
   },
   "source": [
    "## **1. Reinforcement Learning (2.0 puntos)**\n",
    "\n",
    "En esta secci칩n van a usar m칠todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOcejYb6uzOO"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq gymnasium stable_baselines3\n",
    "!pip install -qqq swig\n",
    "!pip install -qqq gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBPet_Mq8dX9"
   },
   "source": [
    "### **1.1 Blackjack (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "La idea de esta subsecci칩n es que puedan implementar m칠todos de RL y as칤 generar una estrategia para jugar el cl치sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de c칩digo transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpZ8bBKk9ZlU"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(FlattenObservation, self).__init__(env)\n",
    "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.array(observation).flatten()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6J1_-Y9nHO"
   },
   "source": [
    "#### **1.1.1 Descripci칩n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci칩n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRGtYpDwrL31"
   },
   "source": [
    "*Respuesta*\n",
    "\n",
    "El ambiente es una partida de BlackJack donde el objetivo es vencer al 'dealer' obteniendo cartas que sumen lo m치s cercano a 21 sin pasarse. La idea es lograr alcanzar una mejor mano de cartas que las del 'dealer', cumpliendo la retricci칩n de los 21 puntos.\n",
    "\n",
    "\n",
    "Su formulci칩n en MDP es la siguiente:\n",
    "\n",
    "\n",
    "\n",
    "*   Estados: tenemos estado inicial y final\n",
    "\n",
    "Inicial: se inicia el juego, el jugador suma sus cartas para que luego el 'Dealer' muestre las suyas y finalmente se puede utilizar un As.\n",
    "\n",
    "Final: el final del juego sucede cuando el jugador pide una carta m치s y la suma resulta ser mayor a 21. Otro caso es cuando el jugador se queda con las cartas que tiene en mano.\n",
    "*   Acciones: Hay dos acciones posibles\n",
    "\n",
    "0: Pegar/Stick donde se queda con las cartas actuales\n",
    "\n",
    "1: Golpear/Hit que implica robar una carta\n",
    "*   Recompensas:\n",
    "\n",
    "Las recompensas incluyen ganar 1 pto si se gana el juego, perder 1 pto si se pierde, 0 pts si se llega a un empate y 1.5 pts si se gana el juego con un natural blackjack.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcX6bRC9agQ"
   },
   "source": [
    "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 5000 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica? 쮺칩mo podr칤a interpretar las recompensas obtenidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p2PrLLR9yju"
   },
   "outputs": [],
   "source": [
    "#simulacion de escenario donde se escojen acciones aleatorias\n",
    "def simul_escenario(env, episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = env.action_space.sample()\n",
    "      obs, reward, done,_, info = env.step(action)\n",
    "      recompensas.append(reward)\n",
    "  return recompensas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8G1wIW8FyXC",
    "outputId": "dcde8597-53f9-436a-8644-0da98265e6eb"
   },
   "outputs": [],
   "source": [
    "#repeticion de la simulacion 5000 veces + promedio y desviasion de las recompensas\n",
    "repeat_5000=simul_escenario(env,5000)\n",
    "#saco promedio y desv estandar\n",
    "promedio=np.mean(repeat_5000)\n",
    "desviacion=np.std(repeat_5000)\n",
    "print(f\"El promedio de las recompensas es: {promedio}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOK1DsPqF4sK"
   },
   "source": [
    "*Respuesta*\n",
    "\n",
    "La performance de esta politica no es buena ya que el promedio de las recompensas es negativo indicando un escenario poco favorecedor ya que seg칰n los parametros de recompensas perdi칩 la mayor칤a de las partidas jugadas. Adem치s, la desviaci칩n estandar es alta lo que indica alta variaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEO_dY4x_SJu"
   },
   "source": [
    "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fe5ec97f9d9d41658645681bc46feb81",
      "a016f1af4e064a15af582d2f6ff4e730"
     ]
    },
    "id": "m9JsFA1wGmnH",
    "outputId": "44fb2e73-68ce-4ed4-bc88-26bd25e7768a"
   },
   "outputs": [],
   "source": [
    "#estoy entre box y multiProcessing\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "modelo=PPO(\"MlpPolicy\",env,verbose=1)\n",
    "modelo.learn(total_timesteps=int(2e5), progress_bar=True)\n",
    "modelo.save(\"modelo_blackjack_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bpdb8wZID1"
   },
   "source": [
    "#### **1.1.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-d7d8GFf7F6",
    "outputId": "919edd8a-c787-456b-c4a0-5ef70dc74a10"
   },
   "outputs": [],
   "source": [
    "#simulacion de 5000 veces m치s promedio y desviacion\n",
    "def simul_escenario_2(env,modelo,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs,_ = env.reset()\n",
    "    episodio_recompensa=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action,_state= modelo.predict(obs, deterministic=True)\n",
    "      obs, reward, done,truncated,info= env.step(action)\n",
    "      episodio_recompensa+=reward\n",
    "      recompensas.append(episodio_recompensa)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSVAZIPqUORA",
    "outputId": "061eb170-0d07-452b-9b0c-e122e01fc2e1"
   },
   "outputs": [],
   "source": [
    "repeat_5000_v2=simul_escenario_2(env,modelo,5000)\n",
    "#saco promedio y desv estandar\n",
    "promedio_2=np.mean(repeat_5000_v2)\n",
    "desviacion_2=np.std(repeat_5000_v2)\n",
    "print(f\"El promedio de las recompensas es: {promedio_2}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXYf8ElcB_m"
   },
   "source": [
    "*Comparaci칩n de escenarios*\n",
    "\n",
    "La performance del agente es mejor que el baseline ya que es m치s cercano a 0, pero sigue siendo un escenario desfavorable ya que indica que est치 perdiendo o empatando la mayor칤a de las jugadas.\n",
    "\n",
    "Lo que si, baja la variabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO-EsAaPAYEm"
   },
   "source": [
    "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
    "\n",
    "Genere una funci칩n que reciba un estado y retorne la accion del agente. Luego, use esta funci칩n para entregar la acci칩n escogida frente a los siguientes escenarios:\n",
    "\n",
    "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
    "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
    "\n",
    "쯉on coherentes sus acciones con las reglas del juego?\n",
    "\n",
    "Hint: 쮸 que clase de python pertenecen los estados? Pruebe a usar el m칠todo `.reset` para saberlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8XlGyzwtRp"
   },
   "outputs": [],
   "source": [
    "#funcion que reciba un estado y retorne la accion del agente.\n",
    "def get_return_action(model,state):\n",
    "  action,_states= model.predict(state, deterministic=True)\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJGILrwhGKwD"
   },
   "outputs": [],
   "source": [
    "#escenario 1: suma de las cartas es 6, dealer muestra un 7, agente no tiene un as\n",
    "escenario_1=np.array([6,7,0])\n",
    "#escenario 2: suma de las cartas del agente es 19, dealer muestra un 3, agente tiene un as\n",
    "escenario_2=np.array([19,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aoDSByRhBlV",
    "outputId": "0ffef154-3f9d-4b5c-c2fd-526bc4ae916f"
   },
   "outputs": [],
   "source": [
    "#accion del escenario 1\n",
    "accion_1=get_return_action(modelo,escenario_1)\n",
    "#accion del escenario 2\n",
    "accion_2=get_return_action(modelo,escenario_2)\n",
    "print(f\"La accion del escenario 1 es: {accion_1}\")\n",
    "print(f\"La accion del escenario 2 es: {accion_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWM_lJMGZYb"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "Si, son coherentes con las reglas del juego ya que en el primer escenario el dealer tiene mayor puntaje y pide otra carta para poder ganar y en el segundo escenario el dealer no supera la cantidad del agente por lo cual no se necesita de otra carta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqCTqqroh03"
   },
   "source": [
    "### **1.2 LunarLander**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci칩n 2.1, en esta secci칩n usted se encargar치 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
    "\n",
    "Comencemos preparando el ambiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq16l2-0u1o8"
   },
   "source": [
    "*Se tuvo que utilizar LunarLander-v3 ya que arrojaba error la version2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvQUyuZ_FtZ4",
    "outputId": "1c7989d7-dadd-452f-8995-78defcc691da"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el par치metro continuous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBU4lGX3wpN6"
   },
   "source": [
    "Noten que se especifica el par치metro `continuous = True`. 쯈ue implicancias tiene esto sobre el ambiente?\n",
    "\n",
    "Adem치s, se le facilita la funci칩n `export_gif` para el ejercicio 2.2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRiWpSo9yfr9",
    "outputId": "ce3438fc-b15c-4db7-9001-7b0fd8b7d6c3"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def export_gif(model, n = 5):\n",
    "  '''\n",
    "  funci칩n que exporta a gif el comportamiento del agente en n episodios\n",
    "  '''\n",
    "  images = []\n",
    "  for episode in range(n):\n",
    "    obs = model.env.reset()\n",
    "    img = model.env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "      images.append(img)\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, reward, done, info = model.env.step(action)\n",
    "      img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfOGQOYQGh7Y"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "El continuos=True indica que necesitamos tener un espacio de acci칩n continuo en lugar de uno discreto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk5VJVppXh3N"
   },
   "source": [
    "#### **1.2.1 Descripci칩n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci칩n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. 쮺omo se distinguen las acciones de este ambiente en comparaci칩n a `Blackjack`?\n",
    "\n",
    "Nota: recuerde que se especific칩 el par치metro `continuous = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdSFEQFeGncD"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "El ambiente LunarLander es un problema de optimizaci칩n de trayectoria de cohete.\n",
    "\n",
    "Su formulacion en MDP se compone de:\n",
    "\n",
    "*  Estados:\n",
    "  * Inicial: la nave se encuentra en el centro superior de la ventana gr치fica.\n",
    "  * Final: el episodio termina el los siguientes casos--> a) aterrizaje y se estrella;\n",
    "  b) aterrizaje sale de la ventana gr치fica; c) modulo de aterrizaje no est치 despierto, i.e no se mueve y no choca con ningun otro cuerpo.\n",
    "*  Acciones: Existen 4 tipos de acciones\n",
    "    * 0: no hace nada\n",
    "    * 1: se enciendo propulsor de orientaci칩n izquierda\n",
    "    * 2: encender propulsor central\n",
    "    * 3: encender propulsor de orientaci칩n derecha\n",
    "*  Recompensas:\n",
    "  * aumenta/disminuye cuanto m치s lento/r치pido se mueve el modulo de aterrizaje de la plataforma de aterrizaje\n",
    "  * aumenta/disminuye cuanto m치s lento/r치pido se mueve el modulo de aterrizaje\n",
    "  * disminuye cuanto m치s se inclina el modulo de aterrizaje (angulo no horizontal)\n",
    "  * +10 puntos por cada pierna qu est칠 en contacto con el suelo\n",
    "  * -0.03 puntos cada cuadro en que se activa un motor lateral\n",
    "  * -0.3 puntos cada vez que se activa el motor principal\n",
    "  * El episodio recibe +100/-100 por aterrizar de forma segura o estrellarse respectivamente.\n",
    "  * Episodio se considera soluci칩n si obtiene al menos 200pts.\n",
    "\n",
    "\n",
    "La diferencia con el ambiente black jack es que a partir de los puntos obtenidos en recompensas se considera si un episodio es optimo o no y con ello la soluci칩n, no as칤 en el ambiente de black jack donde no requiere de un 칩ptimo para definir una soluci칩n. Tambien las acciones disponibles para cada ambiente son distintas, en blackJack son 2 y en LunarLander 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChodtNQwzG2"
   },
   "source": [
    "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 10 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwc3A0GX7a8"
   },
   "outputs": [],
   "source": [
    "#simulacion de escenario con acciones aleatorias\n",
    "def simul_lunar_lander( env,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs = env.reset()\n",
    "    recompensa_episodios=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action = env.action_space.sample()\n",
    "      obs, reward, done,_, info = env.step(action)\n",
    "      recompensa_episodios+=reward\n",
    "      recompensas.append(recompensa_episodios)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4RIy-xFHBM2",
    "outputId": "639b78f4-2778-494e-e627-f43a0a7b00b8"
   },
   "outputs": [],
   "source": [
    "#simulacion repetida 10 veces + promedio y desviacion estandar\n",
    "repeat_10=simul_lunar_lander(env,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_3=np.mean(repeat_10)\n",
    "desviacion_3=np.std(repeat_10)\n",
    "print(f\"El promedio de las recompensas es: {promedio_3}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udWCFjkZHEtA"
   },
   "source": [
    "*respuesta*\n",
    "\n",
    "La perfomance de la politica no es favorable ya que indica que en promedio se mueve lento el modulo de aterrizaje, quiz치s se estrell칩 o simplemente una mala ejecuci칩n dentro del episodio ya que el promedio es negativo.\n",
    "\n",
    "La desviaci칩n estandar indica que tiene alta variabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrZVQflX_5f"
   },
   "source": [
    "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "cb825334821247da82da7b8092d583b1",
      "24672228afdf43a7ac291d34e40fc5dc"
     ]
    },
    "id": "y_6Ia9uoF7Hs",
    "outputId": "68c13cff-316b-4dbc-8318-3a6110c19645"
   },
   "outputs": [],
   "source": [
    "modelo_lunar=PPO('MlpPolicy',env,verbose=0)\n",
    "modelo_lunar.learn(total_timesteps=int(1e4),progress_bar=True)\n",
    "modelo_lunar.save(\"modelo_lunar_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z-oIUSrlAsY"
   },
   "source": [
    "#### **1.2.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophyU3KrWrwl"
   },
   "outputs": [],
   "source": [
    "def simul_lunar_lander_2(env,modelo,episodios):\n",
    "  recompensas=[]\n",
    "  for episode in range(episodios):\n",
    "    obs,_ = env.reset()\n",
    "    episodio_recompensa=0\n",
    "    done = False\n",
    "    while not done:\n",
    "      action,_state= modelo.predict(obs, deterministic=True)\n",
    "      obs, reward, done,truncated,info= env.step(action)\n",
    "      episodio_recompensa+=reward\n",
    "    recompensas.append(episodio_recompensa)\n",
    "  return recompensas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nj2_XqCusfTg",
    "outputId": "532b8428-97e8-4233-b854-5551c5c18345"
   },
   "outputs": [],
   "source": [
    "recompensa_lunar=simul_lunar_lander_2(env,modelo_lunar,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_4=np.mean(recompensa_lunar)\n",
    "desviacion_4=np.std(recompensa_lunar)\n",
    "print(f\"El promedio de las recompensas es: {promedio_4}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLgpHP9mZvdp"
   },
   "source": [
    "la perfomance mejora en cuanto al promedio ya que indica que se cometen menos errores en la obtencion de las recompensas.\n",
    "\n",
    "En cambio la desviacion estandar baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6Xw4YHT3P5d"
   },
   "source": [
    "#### **1.2.5 Optimizaci칩n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par치metros como:\n",
    "- `total_timesteps`\n",
    "- `learning_rate`\n",
    "- `batch_size`\n",
    "\n",
    "Una vez optimizado el modelo, use la funci칩n `export_gif` para estudiar el comportamiento de su agente en la resoluci칩n del ambiente y comente sobre sus resultados.\n",
    "\n",
    "Adjunte el gif generado en su entrega (mejor a칰n si adem치s adjuntan el gif en el markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "960232292ef34a69892c6c82fd9002b0",
      "f510e51d696b40b4a3e39a6639842c3e"
     ]
    },
    "id": "aItYF6sr6F_6",
    "outputId": "6f6d2f46-c850-4641-fdc0-1e71a5e70340"
   },
   "outputs": [],
   "source": [
    "modelo_modificado=PPO('MlpPolicy',env,verbose=0,learning_rate=0.0001,batch_size=32,seed=400)\n",
    "modelo_modificado.learn(total_timesteps=int(1e6),progress_bar=True)\n",
    "modelo_modificado.save(\"modelo_lunar_modificado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0L_aTq4s6RO"
   },
   "outputs": [],
   "source": [
    "recompensa_modelo_modificado=simul_lunar_lander_2(env,modelo_modificado,10)\n",
    "#saco promedio y desv estandar\n",
    "promedio_5=np.mean(recompensa_modelo_modificado)\n",
    "desviacion_5=np.std(recompensa_modelo_modificado)\n",
    "print(f\"El promedio de las recompensas es: {promedio_5}\")\n",
    "print(f\"La desviacion estandar de las recompensas es: {desviacion_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPUY-Ktgf2BO"
   },
   "source": [
    "## **2. Large Language Models (4.0 puntos)**\n",
    "\n",
    "En esta secci칩n se enfocar치n en habilitar un Chatbot que nos permita responder preguntas 칰tiles a trav칠s de LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4fPRRihGLe"
   },
   "source": [
    "### **2.0 Configuraci칩n Inicial**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Como siempre, cargamos todas nuestras API KEY al entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ud2Xm_k-hFJn",
    "outputId": "03ef03be-df2f-4be0-8b83-68a798e7537d"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tX4LAylx9n5A",
    "outputId": "b7768356-cf65-4e01-cd5c-fbf1a9db3fed"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbIwNXUXCzgi",
    "outputId": "7603ca29-f99b-46d6-8417-6f3dca19a4dd"
   },
   "outputs": [],
   "source": [
    "# Se carga el modelo visto en clases\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
    "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
    "    max_tokens=None, # sin tope de tokens\n",
    "    timeout=None, # sin timeout\n",
    "    max_retries=2, # n칰mero m치ximo de intentos\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9JvQUsgZZJ"
   },
   "source": [
    "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci칩n es que habiliten un chatbot que pueda responder preguntas usando informaci칩n contenida en documentos PDF a trav칠s de **Retrieval Augmented Generation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxOQroVnaZ5"
   },
   "source": [
    "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
    "\n",
    "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
    "  - 2 documentos .pdf como m칤nimo.\n",
    "  - 50 p치ginas de contenido como m칤nimo entre todos los documentos.\n",
    "  - Ideas para documentos: Documentos relacionados a temas acad칠micos, laborales o de ocio. Aprovechen este ejercicio para construir algo 칰til y/o relevante para ustedes!\n",
    "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
    "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
    "  - **Recuerden adjuntar los documentos en su entrega**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5D1tIRCi4oJJ",
    "outputId": "a33ade8a-0a78-4136-995d-2be1f6c26cec"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzq2TjWCnu15"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "doc_paths = ['53701409.pdf','Super_Mario_Bros.pdf','Mario_interior_OK_MK.0.pdf', 'Mario_fuera_del_reino_de_Nintendo.pdf','Descripcion_Mario_Bros.pdf'] # rellenar con los path a sus documentos\n",
    "\n",
    "assert len(doc_paths) >= 2, \"Deben adjuntar un m칤nimo de 2 documentos\"\n",
    "\n",
    "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
    "assert total_paginas >= 50, f\"P치ginas insuficientes: {total_paginas}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGkAOKlP-iZC",
    "outputId": "b8e79060-4a80-4173-a51c-5131d8f67031"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet faiss-cpu langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11cIpkozFhFV",
    "outputId": "40226817-bc23-4e3b-8f7a-5a8be2794c97"
   },
   "outputs": [],
   "source": [
    "#Se guardan los documentos en una lista\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "docus = []\n",
    "for doc in doc_paths:\n",
    "  loader = PyPDFLoader(doc)\n",
    "  docus += loader.load()\n",
    "  print(f\"Se carg칩 el documento {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EmVy9GIGChX",
    "outputId": "fc9d73e0-2d23-455a-f2ad-f1e4bca2ef7b"
   },
   "outputs": [],
   "source": [
    "len(docus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zdr-oFmz_B-Y",
    "outputId": "3f2698b7-fee2-413d-96e0-5e127add7d8e"
   },
   "outputs": [],
   "source": [
    "docus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r811-P71nizA"
   },
   "source": [
    "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
    "\n",
    "Vectorice los documentos y almacene sus representaciones de manera acorde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-yXAdCSn4JM",
    "outputId": "e2e4a79a-e2b7-4166-ad87-143530a34611"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docus)\n",
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlvgsx4RGQLB",
    "outputId": "d2931fba-be03-4cf8-fca0-43d26f4952bc"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUkP5zrnyBK"
   },
   "source": [
    "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
    "\n",
    "Habilite la soluci칩n RAG a trav칠s de una *chain* y gu치rdela en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPIySdDFn99l",
    "outputId": "62f4cc0f-0d81-4ab9-8354-8c04cf665958"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
    "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
    "                                     )\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6naFAlSXS86o"
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever_chain = retriever | format_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycg5S5i_n-kL"
   },
   "source": [
    "#### **2.1.4 Verificaci칩n de respuestas (0.5 puntos)**\n",
    "\n",
    "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci칩n para cada una. 쯉u soluci칩n RAG entrega las respuestas que esperaba?\n",
    "\n",
    "Ejemplo de tupla:\n",
    "- Pregunta: 쯈ui칠n es el presidente de Chile?\n",
    "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_UiEn1hoZYR"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# noten como ahora existe el par치metro de context!\n",
    "rag_template = '''\n",
    "Eres un asistente experto en los videojuegos, espec칤ficamente en el videojuego llamado \"Super Mario Bros\" y su historia.\n",
    "Tu 칰nico rol es contestar preguntas del usuario a partir de informaci칩n relevante que te sea proporcionada.\n",
    "Responde siempre de la forma m치s completa posible y usando toda la informaci칩n entregada.\n",
    "Responde s칩lo lo que te pregunten a partir de la informaci칩n relevante, NUNCA inventes una respuesta.\n",
    "\n",
    "Informaci칩n relevante: {context}\n",
    "Pregunta: {question}\n",
    "Respuesta 칰til:\n",
    "'''\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CcKzcGAvY5-"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h51tdM5v1sg",
    "outputId": "e0e17776-8a12-4277-b67c-161ac6c46195"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 1\n",
    "question1 = \"Qui칠n en Mario?\"\n",
    "res_esp1 = \"Mario es el protagonista de la saga de juegos Super Mario Bros e icono de la compa침칤a de videojuegos Japonesa Nintendo.\"\n",
    "response1 = rag_chain.invoke(question1)\n",
    "print(\"Respuesta esperada: \" + str(res_esp1))\n",
    "print(\"Respuesta obtenida: \" + str(response1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT39Hpi85xE3",
    "outputId": "990468c3-3727-4f23-d219-31d30646fc67"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 2\n",
    "question2 = \"Qu칠 relaci칩n tiene Mario con Luigi?\"\n",
    "res_esp2 = \"Luigi es el hermano menor de Mario\"\n",
    "response2 = rag_chain.invoke(question2)\n",
    "print(\"Respuesta esperada: \" + str(res_esp2))\n",
    "print(\"Respuesta obtenida: \" + str(response2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTItqtgE5wtg",
    "outputId": "6c1ef23b-f0fe-4dc3-a1d7-455dda42f700"
   },
   "outputs": [],
   "source": [
    "#Pregunta y respuesta 3\n",
    "question3 = \"Qui칠n es Bowser?\"\n",
    "res_esp3 = \"Bowser es el enemigo de Mario\"\n",
    "response3= rag_chain.invoke(question3)\n",
    "print(\"Respuesta esperada: \" + str(res_esp3))\n",
    "print(\"Respuesta obtenida: \" + str(response3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK0HSKigNSHq"
   },
   "source": [
    "Observando las respuestas se puede concluir que responde correctamente la pregunta realizada e incluso desarrolla m치s a칰n la idea con los datos proporcionados utilizando la mayor cantidad de informaci칩n que posee.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8d5zTMHoUgF"
   },
   "source": [
    "#### **2.1.5 Sensibilidad de Hiperpar치metros (0.5 puntos)**\n",
    "\n",
    "Extienda el an치lisis del punto 2.1.4 analizando c칩mo cambian las respuestas entregadas cambiando los siguientes hiperpar치metros:\n",
    "- `Tama침o del chunk`. (*쮺칩mo repercute que los chunks sean mas grandes o chicos?*)\n",
    "- `La cantidad de chunks recuperados`. (*쯈u칠 pasa si se devuelven muchos/pocos chunks?*)\n",
    "- `El tipo de b칰squeda`. (*쮺칩mo afecta el tipo de b칰squeda a las respuestas de mi RAG?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDh_QgeXLGHc"
   },
   "outputs": [],
   "source": [
    "#Empezamos generando listas con las preguntas a hacer y respuestas esperadas\n",
    "questions_list = [question1, question2, question3]\n",
    "expected_answers = [res_esp1, res_esp2, res_esp3]\n",
    "\n",
    "#Posteriormente creamos una funci칩n para evaluar el funcionamiento cambiando par치metros\n",
    "#Se crea esta funci칩n para no tener que repetir el c칩digo una y otra vez\n",
    "def sensibilidad(chunk_size: int = 500, cant_chunks: int = 3, search_type: str = 'similarity'):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "  splits = text_splitter.split_documents(docus)\n",
    "\n",
    "  embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "  vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
    "\n",
    "  retriever = vectorstore.as_retriever(search_type=search_type, # m칠todo de b칰squeda\n",
    "                                     search_kwargs={\"k\": cant_chunks}, # n춿 documentos a recuperar\n",
    "                                     )\n",
    "  retriever_chain = retriever | format_docs\n",
    "\n",
    "  rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
    "  )\n",
    "\n",
    "  for i in range(len(questions_list)):\n",
    "    response = rag_chain.invoke(questions_list[i])\n",
    "    print(\"Pregunta: \" + str(questions_list[i]))\n",
    "    print(\"Respuesta esperada: \" + str(expected_answers[i]))\n",
    "    print(\"Respuesta obtenida: \" + str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIId1d-wnKpb"
   },
   "source": [
    "**SENSIBILIDAD ANTE EL TAMA칌O DE LOS CHUNKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U64hVREbmjuu",
    "outputId": "2309d091-c5e1-4a78-fbf3-d8eef5098b65"
   },
   "outputs": [],
   "source": [
    "#Ahora empezamos a variar los par치metros para evaluar la sensibilidad del modelo a estos\n",
    "sensibilidad(chunk_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_RVGdxpm9FK",
    "outputId": "c36e61ca-b003-4f83-8fae-785231c725d4"
   },
   "outputs": [],
   "source": [
    "sensibilidad(chunk_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hoAkFg0nJGd"
   },
   "source": [
    "Se observa que al achicar el tama침o de los chunks las respuestas son m치s precisas pero sujetas a mucho detalle repercutiendo en respuestas que nos entregan informaci칩n que no pedimos. Al aumentar el tama침o de los chunks se ven respuestas m치s concisas y precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YXkFMPsnokG"
   },
   "source": [
    "**SENSIBILIDAD ANTE LA CANTIDAD DE CHUNKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDK7keMsnxTK",
    "outputId": "f3ee21a8-e749-4a50-ffd6-4c11e9aca29d"
   },
   "outputs": [],
   "source": [
    "sensibilidad(cant_chunks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFRMKc7Sn1eF",
    "outputId": "1519ab34-3ed8-4b19-b7d1-df8dcb80f883"
   },
   "outputs": [],
   "source": [
    "sensibilidad(cant_chunks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6dWSGdxn3Pu"
   },
   "source": [
    "Se observa que al disminuir la cantidad de chunks la informaci칩n recopilada de los documentos es menor, llegando a entregar respuestas que, a pesar de estar la informaci칩n, est치n incompletas o bien incorrectas. Al aumentar la cantidad de chunks se observa como las respuestas entregadas son m치s completas ya que se abarca m치s informaci칩n presente en los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3uG7GE4n48S"
   },
   "source": [
    "**SENSIBILIDAD ANTE EL TIPO DE B칔SQUEDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdWFqlhin8kp",
    "outputId": "d1fc18e7-00e8-48af-8a42-210382a4292c"
   },
   "outputs": [],
   "source": [
    "sensibilidad(search_type='mmr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qplFFWlooAil"
   },
   "source": [
    "Se observan respuestas similares al uso de similarity, pero se puede observar una mayor diversidad en el contenido de la respuesta que con este otro m칠todo. Esto debido a que usando mmr se utilizan chunks distintos entre s칤 generando una respuesta m치s variada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJiPPM0giX8"
   },
   "source": [
    "### **2.2 Agentes (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci칩n anterior, en esta secci칩n se busca habilitar **Agentes** para obtener informaci칩n a trav칠s de tools y as칤 responder la pregunta del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47l7Mjfrk0N"
   },
   "source": [
    "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas al motor de b칰squeda **Tavily**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6SLKwcWr0AG"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool_tavily = TavilySearchResults(max_results = 1) # inicializamos tool\n",
    "tools = []\n",
    "tools.append(tool_tavily) # guardamos las tools en una lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonB1A-9rtRq"
   },
   "source": [
    "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
    "\n",
    "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9_slKnVPOuc",
    "outputId": "c0ef5342-4729-47a9-b342-914920187b49"
   },
   "outputs": [],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehJJpoqsr26-"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(lang='es', top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "tools.append(wiki_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUIMdX6r0ne"
   },
   "source": [
    "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
    "\n",
    "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg칰rese que su agente responda en espa침ol. Por 칰ltimo, guarde el agente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pD1_n0wrsDI5",
    "outputId": "7edd7d1e-916a-4191-e4d1-b71da6a8b487"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "react_prompt = hub.pull(\"hwchase17/react\") # template de ReAct\n",
    "print(react_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLNmImEmy-ma",
    "outputId": "3bc38eb7-d3c2-44e5-fb32-ce90b95e8f8d"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # lo transformamos a AgentExecutor para habilitar la ejecuci칩n de tools\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKV0JxK3r-XG"
   },
   "source": [
    "#### **2.2.4 Verificaci칩n de respuestas (0.3 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente y aseg칰rese que el agente est칠 ocupando correctamente las tools disponibles. 쮼n qu칠 casos el agente deber칤a ocupar la tool de Tavily? 쮼n qu칠 casos deber칤a ocupar la tool de Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pqo2dsxvywW_",
    "outputId": "4d751706-4e7e-4b41-85b9-e11b17aa434a"
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Qui칠n es Taylor Swift?\"}) #Hacer una pregunta\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ypJC8dhzcie",
    "outputId": "e087dffc-2aec-45c8-da07-ee39da7dedd4"
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Qui칠n dijo en una pel칤cula la frase: Santa cachucha ya dijo la frase?\"}) #Hacer otra pregunta\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIxAi4eISbV8"
   },
   "source": [
    "El agente deber칤a utilizar wikipedia en casos que la informaci칩n se pueda encontrar ah칤 como casos de historia, ciencia, etc. Mientras que tavily deber칤a ser utilizado para casos m치s espec칤ficos pudiendo encontrar esta informaci칩n en la web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbDTYiogquv"
   },
   "source": [
    "### **2.3 Multi Agente (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
    "\" width=\"450\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci칩n es encapsular las funcionalidades creadas en una soluci칩n multiagente con un **supervisor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-iUfH0WvI6m"
   },
   "source": [
    "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
    "\n",
    "Transforme la soluci칩n RAG de la secci칩n 2.1 y el agente de la secci칩n 2.2 a *tools* (una tool por cada uno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw1cfTtvv1AZ"
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def RAG(input:str) -> str:\n",
    "  \"\"\"Usa el modelo RAG para responder el input\"\"\"\n",
    "  return rag_chain.invoke(input)\n",
    "\n",
    "@tool\n",
    "def agent(input:str) -> str:\n",
    "  \"\"\"Usa el modelo ReAct para responder el input\"\"\"\n",
    "  return agent_executor.invoke({\"input\": input})[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQYNjT_0vPCg"
   },
   "source": [
    "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
    "\n",
    "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "yv2ZY0BAv1RD",
    "outputId": "18dbd83e-9f34-4c9f-9812-f2266021f0f8"
   },
   "outputs": [],
   "source": [
    "supervisor_agent_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un supervisor de preguntas.\n",
    "    Tu 칰nico rol es seleccionar que acci칩n tomar para responder correctamente la pregunta:\n",
    "    - 'mario': Cuando la pregunta est칠 relacionada con Super Mario Bros, sus personajes o los videojuegos.\n",
    "    - 'internet': Cuando la pregunta es de conocimiento general y puede ser respondida utilizando wikipedia o usando tavily.\n",
    "    - 'otro': Todo aquella pregunta que no est칠 contenida en las categor칤as anteriores.\n",
    "\n",
    "    No respondas con m치s de una palabra y no incluyas.\n",
    "\n",
    "\n",
    "    {question}\n",
    "\n",
    "\n",
    "    Categor칤a:\"\"\"\n",
    ")\n",
    "\n",
    "supervisor_agent_chain = (\n",
    "    supervisor_agent_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "supervisor_agent_chain.invoke({\"question\": \"Qui칠n fue Mozart??\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "8FKSvYwmfGlq",
    "outputId": "a2d2e6b8-7ae2-49d8-d0a1-3b5478166a2d"
   },
   "outputs": [],
   "source": [
    "redirect_agent_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un asistente de redireccionamiento de preguntas de usuarios.\n",
    "    Vas a recibir una pregunta del usuario, tu 칰nico rol es indicar cuando no puedes responder su pregunta y redireccionar al usuario\n",
    "    para que te pregunte sobre videojuegos, sobre tu videojuego favorito Super Mario Bros o bien informaci칩n de cultura general que\n",
    "    pueda ser encontrada en wikipedia o usando tavily.\n",
    "\n",
    "    Recuerda ser amable y cordial en tu respuesta.\n",
    "\n",
    "    Pregunta: {question}\n",
    "    Respuesta cordial:\"\"\"\n",
    ")\n",
    "\n",
    "redirect_agent_chain = (\n",
    "    redirect_agent_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "redirect_agent_chain.invoke({\"question\": \"Qui칠n fue Mozart?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNxi4sYpfliI"
   },
   "outputs": [],
   "source": [
    "def route_question(question):\n",
    "  '''\n",
    "  Recibe una pregunta de usuario.\n",
    "  Rutea la pregunta al agente respectivo y responde de manera acorde.\n",
    "  '''\n",
    "\n",
    "  topic = supervisor_agent_chain.invoke({\"question\": question}) # enrutamiento\n",
    "\n",
    "  if \"mario\" in topic: # si la pregunta es de mario o videojuegos, utilizar rag\n",
    "      return rag_chain.invoke(question)\n",
    "  elif \"internet\" in topic: # si la pregunta es de cultura general, utilizar agente\n",
    "      return agent_executor.invoke({\"input\": question})[\"output\"]\n",
    "  else: # de lo contrario, redireccionar pregunta\n",
    "      return redirect_agent_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3zWlvyvY7K"
   },
   "source": [
    "#### **2.3.3 Verificaci칩n de respuestas (0.25 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. 쮺칩mo var칤an las respuestas bajo este enfoque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "6_1t0zkgv1qW",
    "outputId": "2ed79a6b-bee5-4930-c316-a69cff3fff65"
   },
   "outputs": [],
   "source": [
    "route_question(\"Qui칠n en Mario?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8yknRPNWRdt2",
    "outputId": "9ced8d5a-f538-446c-e848-9ff0836a7937"
   },
   "outputs": [],
   "source": [
    "route_question(\"Qu칠 relaci칩n tiene Mario con Luigi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "B0tnuj7uRjtm",
    "outputId": "c163b143-613f-419d-d1da-a63ca075fd12"
   },
   "outputs": [],
   "source": [
    "route_question(\"Qui칠n es Taylor Swift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "OeIZgxYmRbnv",
    "outputId": "36451a3b-fb87-46f3-d1b4-186d84ab286a"
   },
   "outputs": [],
   "source": [
    "route_question(\"Qui칠n dijo en una pel칤cula la frase: Santa cachucha ya dijo la frase?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvm8MeXvSFRu"
   },
   "source": [
    "Las respuestas entregadas no var칤an mucho, siendo la mayor diferencia que no constesta la 칰ltima pregunta al ser muy rebuscada a pesar de que se encuentra en internet usando Tavily considera que corresponde a la categor칤a de \"otro\", principalmente porque no considera que esta respuesta sea conocimiento general como le fue pedido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8bdAmYvgwn"
   },
   "source": [
    "#### **2.3.4 An치lisis (0.25 puntos)**\n",
    "\n",
    "쯈u칠 diferencias tiene este enfoque con la soluci칩n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAUlJxqoLK5r"
   },
   "source": [
    "El agente supervisor utiliza un modelo de lenguaje para razonar de manera din치mica y decidir qu칠 herramientas emplear, lo que le permite adaptarse con facilidad a diferentes situaciones y resolver problemas en tiempo real. En contraste, el Router opera siguiendo un conjunto de reglas establecidas, lo que lo hace m치s r치pido y eficiente, pero menos capaz de enfrentar escenarios ambiguos o no planificados. Aunque el agente supervisor destaca por su capacidad para abordar casos complejos sin depender de reglas fijas, este enfoque requiere un mayor esfuerzo computacional debido a su uso constante del modelo de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWVSuWiZ8Mj"
   },
   "source": [
    "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
    "\n",
    "- Pregunta 1: \"Hola! mi nombre es Sebasti치n\"\n",
    "  - Respuesta esperada: \"Hola Sebasti치n! ...\"\n",
    "- Pregunta 2: \"Cual es mi nombre?\"\n",
    "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
    "  - **Respuesta esperada: \"Tu nombre es Sebasti치n\"**\n",
    "\n",
    "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci칩n entregada en el punto 2.3.\n",
    "\n",
    "**Nota: El Bonus es v치lido <u>s칩lo para la secci칩n 2 de Large Language Models.</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iqwj4e_JTUVj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFc3jBT5g0kT"
   },
   "source": [
    "### **2.5 Despliegue (0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav칠s de `gradio`, una librer칤a especializada en el levantamiento r치pido de demos basadas en ML.\n",
    "\n",
    "Primero instalamos la librer칤a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8TsvnCPbkIA"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJBztEUovKsF"
   },
   "source": [
    "Luego s칩lo deben ejecutar el siguiente c칩digo e interactuar con la interfaz a trav칠s del notebook o del link generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3KedQSvg1-n"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def agent_response(message, history):\n",
    "  '''\n",
    "  Funci칩n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
    "  '''\n",
    "  # get chatbot response\n",
    "  response = ... # rellenar con la respuesta de su chat\n",
    "\n",
    "  # assert\n",
    "  assert type(response) == str, \"output de route_question debe ser string\"\n",
    "\n",
    "  # \"streaming\" response\n",
    "  for i in range(len(response)):\n",
    "    time.sleep(0.015)\n",
    "    yield response[: i+1]\n",
    "\n",
    "gr.ChatInterface(\n",
    "    agent_response,\n",
    "    type=\"messages\",\n",
    "    title=\"Chatbot MDS7202 - PiliBarto\", # Pueden cambiar esto si lo desean\n",
    "    description=\"Hola! Soy un chatbot muy 칰til >:)\", # tambi칠n la descripci칩n\n",
    "    theme=\"soft\",\n",
    "    ).launch(\n",
    "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
    "        debug = False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24672228afdf43a7ac291d34e40fc5dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "960232292ef34a69892c6c82fd9002b0": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f510e51d696b40b4a3e39a6639842c3e",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較</span> <span style=\"color: #008000; text-decoration-color: #008000\">1,001,445/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:19:59</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">253 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m1,001,445/1,000,000 \u001b[0m [ \u001b[33m1:19:59\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m253 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "a016f1af4e064a15af582d2f6ff4e730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb825334821247da82da7b8092d583b1": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_24672228afdf43a7ac291d34e40fc5dc",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,218/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:22</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">438 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m10,218/10,000 \u001b[0m [ \u001b[33m0:00:22\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m438 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "f510e51d696b40b4a3e39a6639842c3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe5ec97f9d9d41658645681bc46feb81": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_a016f1af4e064a15af582d2f6ff4e730",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較</span> <span style=\"color: #008000; text-decoration-color: #008000\">200,648/200,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:09:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">371 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m200,648/200,000 \u001b[0m [ \u001b[33m0:09:16\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m371 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
