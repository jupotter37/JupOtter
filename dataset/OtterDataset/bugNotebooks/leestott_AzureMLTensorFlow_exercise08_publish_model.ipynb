{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise08 : Publish as a Web Service\n",
    "\n",
    "Finally we publish our model as a web service with a few steps.\n",
    "\n",
    "*back to [index](/Readme.md)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace settings\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](/notebooks/exercise01_prepare_config.ipynb)\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/username/azure-ml-tensorflow-complete-sample/notebooks/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Let's train in your local environment and create model. (The model is saved in \"```./outputs```\" folder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-efb70ae39d77>:187: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe5b0367198>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './logs'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From <ipython-input-2-efb70ae39d77>:25: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-efb70ae39d77>:26: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-2-efb70ae39d77>:40: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.328045, step = 1\n",
      "INFO:tensorflow:global_step/sec: 37.8612\n",
      "INFO:tensorflow:loss = 0.54863036, step = 101 (2.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.6768\n",
      "INFO:tensorflow:loss = 0.38292968, step = 201 (1.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1188\n",
      "INFO:tensorflow:loss = 0.27989933, step = 301 (1.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.064\n",
      "INFO:tensorflow:loss = 0.50519747, step = 401 (1.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7731\n",
      "INFO:tensorflow:loss = 0.26806074, step = 501 (1.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1997\n",
      "INFO:tensorflow:loss = 0.30144972, step = 601 (2.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.332\n",
      "INFO:tensorflow:loss = 0.3718782, step = 701 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5184\n",
      "INFO:tensorflow:loss = 0.24973571, step = 801 (1.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.7348\n",
      "INFO:tensorflow:loss = 0.234337, step = 901 (1.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.0187\n",
      "INFO:tensorflow:loss = 0.29297516, step = 1001 (1.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-17-01:13:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-17-01:13:52\n",
      "INFO:tensorflow:Saving dict for global step 1100: accuracy = 0.933, global_step = 1100, loss = 0.22561485\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1100: ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Loss for final step: 0.27009854.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "WARNING:tensorflow:From /anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./outputs/temp-b'1547687632'/saved_model.pb\n",
      "current working directory is  /data/home/tsmatsuz/azure-ml-tensorflow-complete-sample/notebooks\n",
      "model is saved  b'./outputs/1547687632'\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
    " \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.contrib.learn.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive your model as model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/home/tsmatsuz/azure-ml-tensorflow-complete-sample/notebooks/model.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('model', 'zip', root_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model into model management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model sample_model\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "registered_model = Model.register(\n",
    "    model_path = './model.zip',\n",
    "    model_name = 'sample_model',\n",
    "    workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you generate your scoring source. (See \"[Exercise03 : Just Train in Your Working Machine](/notebooks/exercise03_train_simple.ipynb)\" for the original source code.)    \n",
    "This should include ```init()``` and ```run()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global pred_fn\n",
    "    model_path = Model.get_model_path(model_name='sample_model')\n",
    "    with zipfile.ZipFile(model_path) as target_zip:\n",
    "        target_zip.extractall('extracted_model')\n",
    "    pred_fn = tf.contrib.predictor.from_saved_model('./extracted_model')\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "       data = json.loads(raw_data)['data']\n",
    "       result = pred_fn({'inputs': data})\n",
    "       return result['classes'].tolist()\n",
    "    except Exception as e:\n",
    "       result = str(e)\n",
    "       return 'Internal Exception : ' + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create deploy configuration for preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aci_conf = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1,\n",
    "    memory_gb=1, \n",
    "    description='This is a tensorflow example.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create image configuration for preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Generate conda dependency file\n",
    "conda_dependency = CondaDependencies.create()\n",
    "conda_dependency.add_pip_package('tensorflow')\n",
    "### Or you can also write as follows (make sure to insert 'azureml-defaults' module)\n",
    "#conda_dependency = CondaDependencies.create(pip_packages=['azureml-defaults', 'tensorflow'])\n",
    "with open('myenv.yml', 'w') as f:\n",
    "    f.write(conda_dependency.serialize_to_string())\n",
    "\n",
    "# Create image configuration\n",
    "image_conf = ContainerImage.image_configuration(\n",
    "    execution_script=\"score.py\",\n",
    "    runtime=\"python\",\n",
    "    conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy as a web service !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image my-mnist-service:2, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "svc = Webservice.deploy_from_model(\n",
    "    name='my-mnist-service',\n",
    "    deployment_config=aci_conf,\n",
    "    models=[registered_model],\n",
    "    image_config=image_conf,\n",
    "    workspace=ws)\n",
    "svc.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-17T01:25:22,616134526+00:00 - iot-server/run \n",
      "2019-01-17T01:25:22,615549923+00:00 - nginx/run \n",
      "2019-01-17T01:25:22,616288827+00:00 - gunicorn/run \n",
      "ok: run: rsyslog: (pid 11) 0s\n",
      "ok: run: gunicorn: (pid 13) 0s\n",
      "ok: run: nginx: (pid 10) 0s\n",
      "ok: run: rsyslog: (pid 11) 0s\n",
      "2019-01-17T01:25:22,618526338+00:00 - rsyslog/run \n",
      "ok: run: rsyslog: (pid 11) 0s\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-01-17T01:25:22,756793250+00:00 - iot-server/finish 1 0\n",
      "2019-01-17T01:25:22,757890556+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "{\"timestamp\": \"2019-01-17T01:25:22.991277Z\", \"message\": \"Starting gunicorn 19.6.0\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Starting gunicorn %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:22.991869Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (13)\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Listening at: %s (%s)\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:22.991959Z\", \"message\": \"Using worker: sync\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Using worker: %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:22.992516Z\", \"message\": \"worker timeout is set to 300\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:22.993255Z\", \"message\": \"Booting worker with pid: 40\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Booting worker with pid: %s\", \"stack_info\": null}\n",
      "Initializing logger\n",
      "{\"timestamp\": \"2019-01-17T01:25:27.298905Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insights client\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:27.299070Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up request id generator\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:27.299184Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insight hooks\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:27.299288Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Invoking user's init function\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "2019-01-17 01:25:27,299 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run., switching offline: False\n",
      "2019-01-17 01:25:27,299 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-01-17 01:25:27,299 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "2019-01-17 01:25:27,300 | azureml.core.model | DEBUG | version is None. Latest version is 3\n",
      "2019-01-17 01:25:27,300 | azureml.core.model | DEBUG | Found model path at azureml-models/sample_model/3/model.zip\n",
      "2019-01-17 01:25:32.088044: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "{\"timestamp\": \"2019-01-17T01:25:32.110224Z\", \"message\": \"Restoring parameters from ./extracted_model/variables/variables\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"tensorflow\", \"msg\": \"Restoring parameters from %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:32.122550Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Users's init has completed successfully\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:32.122918Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Scoring timeout setting is not found. Use default timeout: 3600000 ms\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:33.611640Z\", \"message\": \"127.0.0.1 - - [17/Jan/2019:01:25:33 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.access\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-17T01:25:36.133121Z\", \"message\": \"127.0.0.1 - - [17/Jan/2019:01:25:36 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"host\": \"wk-caas-e020a585d9e443fe9b77318caad99cc4-525dc63cf4bd585fe383b3\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.access\", \"stack_info\": null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See details, if error has occured\n",
    "print(svc.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check service url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://104.45.187.204:80/score'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :  [7, 2, 1]\n",
      "Actual    :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read data by tensor\n",
    "dataset = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "data_org = iterator.get_next()\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image.tolist())\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Invoke web service !\n",
    "headers = {'Content-Type':'application/json'}\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "# api_key = svc.get_key()\n",
    "# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "values = json.dumps(image_arr)\n",
    "input_data = \"{\\\"data\\\": \" + values + \"}\"\n",
    "http_res = requests.post(\n",
    "    svc.scoring_uri,\n",
    "    input_data,\n",
    "    headers = headers)\n",
    "print('Predicted : ', http_res.text)\n",
    "print('Actual    : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
