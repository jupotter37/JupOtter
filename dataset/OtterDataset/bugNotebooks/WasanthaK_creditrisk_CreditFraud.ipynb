{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Age  Gender MaritalStatus               Occupation  IncomeLevel  \\\n",
      "0   CUST0001   44    Male       Widowed  Private Sector Employee        54278   \n",
      "1   CUST0002   40  Female        Single      Government Employee        61471   \n",
      "2   CUST0003   43    Male        Single  Private Sector Employee        80036   \n",
      "3   CUST0004   21    Male      Divorced                  Student         2431   \n",
      "4   CUST0005   41  Female       Widowed      Government Employee        51298   \n",
      "\n",
      "   CreditLimit  CreditScore CardType  YearsWithBank  NumberOfCreditCards  \\\n",
      "0        11254          645     Gold              6                    2   \n",
      "1         5371          505   Silver             10                    2   \n",
      "2         5708          341   Silver              2                    2   \n",
      "3         4642          721     Gold              2                    2   \n",
      "4         7360          520   Silver              9                    1   \n",
      "\n",
      "   AverageMonthlySpending  LatePayments  CreditCardUsage MobileBankingUsage  \\\n",
      "0                    4951             3             0.44                Yes   \n",
      "1                    4619             6             0.86                 No   \n",
      "2                    4052             6             0.71                Yes   \n",
      "3                     696             0             0.15                Yes   \n",
      "4                    5814             8             0.79                Yes   \n",
      "\n",
      "   CustomerSatisfactionRating  \n",
      "0                           1  \n",
      "1                           2  \n",
      "2                           2  \n",
      "3                           2  \n",
      "4                           3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data\n",
    "data = pd.read_csv(\"10cus.csv\")\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Optionally, preprocess the data to create a feature set\n",
    "# For example, we can convert categorical columns into numerical labels\n",
    "# This would normally be necessary for embedding or more sophisticated processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"EMBEDDING_KEY\")\n",
    "endpoint = os.getenv(\"EMBEDDING_END_POINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_documents(documents, batch_size):\n",
    "    total_docs = len(documents)\n",
    "    for i in range(0, total_docs, batch_size):\n",
    "        yield documents[i:i + batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_documents_to_vectorstore_in_batches(documents, vectorstore, batch_size=64):\n",
    "    for batch in batch_documents(documents, batch_size):\n",
    "        texts = [doc.page_content for doc in batch]\n",
    "        metadatas = [doc.metadata for doc in batch]\n",
    "        vectorstore.add_texts(texts=texts, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data\n",
    "data = pd.read_csv('10cus.csv')\n",
    "\n",
    "# Prepare the list of documents\n",
    "documents = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    customer_info = f\"\"\"\n",
    "    Customer ID: {row['CustomerID']}\n",
    "    Age: {row['Age']}\n",
    "    Gender: {row['Gender']}\n",
    "    Marital Status: {row['MaritalStatus']}\n",
    "    Occupation: {row['Occupation']}\n",
    "    Income Level: {row['IncomeLevel']}\n",
    "    Credit Limit: {row['CreditLimit']}\n",
    "    Credit Score: {row['CreditScore']}\n",
    "    Card Type: {row['CardType']}\n",
    "    Years With Bank: {row['YearsWithBank']}\n",
    "    Number of Credit Cards: {row['NumberOfCreditCards']}\n",
    "    Average Monthly Spending: {row['AverageMonthlySpending']}\n",
    "    Late Payments: {row['LatePayments']}\n",
    "    Credit Card Usage: {row['CreditCardUsage']}\n",
    "    Mobile Banking Usage: {row['MobileBankingUsage']}\n",
    "    Customer Satisfaction Rating: {row['CustomerSatisfactionRating']}\n",
    "    \"\"\"\n",
    "    # Create a Document object\n",
    "    doc = Document(page_content=customer_info, metadata={\"CustomerID\": row['CustomerID']})\n",
    "    documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_base=f\"{endpoint}/openai/deployments\",  # Ensure correct formatting\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_version=\"2024-04-01-preview\"\n",
    ")\n",
    "# Initialize vector store\n",
    "\n",
    "CHROMA_DATA_PATH = \"./chroma_data\"\n",
    "os.makedirs(CHROMA_DATA_PATH, exist_ok=True)\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=CHROMA_DATA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add documents to the vector store in batches\u001b[39;00m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43madd_documents_to_vectorstore_in_batches\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocuments have been processed and stored in the vector store.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m, in \u001b[0;36madd_documents_to_vectorstore_in_batches\u001b[1;34m(documents, vectorstore, batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m      4\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m----> 5\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:508\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\creditanalysis\\new_venv\\Lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "# Add documents to the vector store in batches\n",
    "batch_size = 64  # Adjust as needed\n",
    "add_documents_to_vectorstore_in_batches (documents, vectorstore, batch_size)\n",
    "\n",
    "print(\"Documents have been processed and stored in the vector store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize embedding\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\", base_url=\"http://ollama_container:11434\")\n",
    "\n",
    "# Initialize vector store\n",
    "CHROMA_DATA_PATH = \"/data\"\n",
    "os.makedirs(CHROMA_DATA_PATH, exist_ok=True)\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=CHROMA_DATA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 similar customers at or above the risk threshold of 0.8.\n",
      "Risky customer 1 with similarity score 8590.0947265625:\n",
      "Customer ID: CUST0086\n",
      "\n",
      "    Customer ID: CUST0086\n",
      "    Age: 28\n",
      "    Gender: Female\n",
      "    Marital Status: Widowed\n",
      "    Occupation: Government Employee\n",
      "    Income Level: 66853407\n",
      "    Credit Limit: 11941292\n",
      "    Credit Score: 467\n",
      "    Card Type: Gold\n",
      "    Years With Bank: 12\n",
      "    Number of Credit Cards: 4\n",
      "    Average Monthly Spending: 3990211\n",
      "    Late Payments: 5\n",
      "    Credit Card Usage: 0.39\n",
      "    Mobile Banking Usage: Yes\n",
      "    Customer Satisfaction Rating: 5\n",
      "    \n",
      "Risky customer 2 with similarity score 8706.7578125:\n",
      "Customer ID: CUST0008\n",
      "\n",
      "    Customer ID: CUST0008\n",
      "    Age: 24\n",
      "    Gender: Other\n",
      "    Marital Status: Single\n",
      "    Occupation: Business Owner\n",
      "    Income Level: 63909529\n",
      "    Credit Limit: 17397951\n",
      "    Credit Score: 507\n",
      "    Card Type: Classic\n",
      "    Years With Bank: 7\n",
      "    Number of Credit Cards: 3\n",
      "    Average Monthly Spending: 3062615\n",
      "    Late Payments: 5\n",
      "    Credit Card Usage: 0.67\n",
      "    Mobile Banking Usage: No\n",
      "    Customer Satisfaction Rating: 5\n",
      "    \n",
      "Risky customer 3 with similarity score 8880.1640625:\n",
      "Customer ID: CUST0033\n",
      "\n",
      "    Customer ID: CUST0033\n",
      "    Age: 60\n",
      "    Gender: Male\n",
      "    Marital Status: Widowed\n",
      "    Occupation: Business Owner\n",
      "    Income Level: 48561778\n",
      "    Credit Limit: 16226310\n",
      "    Credit Score: 835\n",
      "    Card Type: Gold\n",
      "    Years With Bank: 10\n",
      "    Number of Credit Cards: 5\n",
      "    Average Monthly Spending: 4402239\n",
      "    Late Payments: 4\n",
      "    Credit Card Usage: 0.55\n",
      "    Mobile Banking Usage: Yes\n",
      "    Customer Satisfaction Rating: 5\n",
      "    \n",
      "Risky customer 4 with similarity score 8938.205078125:\n",
      "Customer ID: CUST0006\n",
      "\n",
      "    Customer ID: CUST0006\n",
      "    Age: 19\n",
      "    Gender: Female\n",
      "    Marital Status: Married\n",
      "    Occupation: Freelancer\n",
      "    Income Level: 91057558\n",
      "    Credit Limit: 13258120\n",
      "    Credit Score: 752\n",
      "    Card Type: Gold\n",
      "    Years With Bank: 4\n",
      "    Number of Credit Cards: 4\n",
      "    Average Monthly Spending: 699845\n",
      "    Late Payments: 1\n",
      "    Credit Card Usage: 0.45\n",
      "    Mobile Banking Usage: Yes\n",
      "    Customer Satisfaction Rating: 3\n",
      "    \n",
      "Risky customers identified: [(Document(metadata={'CustomerID': 'CUST0086'}, page_content='\\n    Customer ID: CUST0086\\n    Age: 28\\n    Gender: Female\\n    Marital Status: Widowed\\n    Occupation: Government Employee\\n    Income Level: 66853407\\n    Credit Limit: 11941292\\n    Credit Score: 467\\n    Card Type: Gold\\n    Years With Bank: 12\\n    Number of Credit Cards: 4\\n    Average Monthly Spending: 3990211\\n    Late Payments: 5\\n    Credit Card Usage: 0.39\\n    Mobile Banking Usage: Yes\\n    Customer Satisfaction Rating: 5\\n    '), 8590.0947265625), (Document(metadata={'CustomerID': 'CUST0008'}, page_content='\\n    Customer ID: CUST0008\\n    Age: 24\\n    Gender: Other\\n    Marital Status: Single\\n    Occupation: Business Owner\\n    Income Level: 63909529\\n    Credit Limit: 17397951\\n    Credit Score: 507\\n    Card Type: Classic\\n    Years With Bank: 7\\n    Number of Credit Cards: 3\\n    Average Monthly Spending: 3062615\\n    Late Payments: 5\\n    Credit Card Usage: 0.67\\n    Mobile Banking Usage: No\\n    Customer Satisfaction Rating: 5\\n    '), 8706.7578125), (Document(metadata={'CustomerID': 'CUST0033'}, page_content='\\n    Customer ID: CUST0033\\n    Age: 60\\n    Gender: Male\\n    Marital Status: Widowed\\n    Occupation: Business Owner\\n    Income Level: 48561778\\n    Credit Limit: 16226310\\n    Credit Score: 835\\n    Card Type: Gold\\n    Years With Bank: 10\\n    Number of Credit Cards: 5\\n    Average Monthly Spending: 4402239\\n    Late Payments: 4\\n    Credit Card Usage: 0.55\\n    Mobile Banking Usage: Yes\\n    Customer Satisfaction Rating: 5\\n    '), 8880.1640625), (Document(metadata={'CustomerID': 'CUST0006'}, page_content='\\n    Customer ID: CUST0006\\n    Age: 19\\n    Gender: Female\\n    Marital Status: Married\\n    Occupation: Freelancer\\n    Income Level: 91057558\\n    Credit Limit: 13258120\\n    Credit Score: 752\\n    Card Type: Gold\\n    Years With Bank: 4\\n    Number of Credit Cards: 4\\n    Average Monthly Spending: 699845\\n    Late Payments: 1\\n    Credit Card Usage: 0.45\\n    Mobile Banking Usage: Yes\\n    Customer Satisfaction Rating: 3\\n    '), 8938.205078125)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to search for risky customers based on similarity threshold\n",
    "def search_risk_in_vectorstore(vectorstore, new_customer_info, embeddings, threshold=0.8):\n",
    "    # Embed the new customer info using the same embedding model\n",
    "    new_customer_embedding = embeddings.embed_query(new_customer_info)  # FIX: Use embed_query for embedding\n",
    "    \n",
    "    # Search the vector store for similar documents (risk threshold can be adjusted)\n",
    "    results = vectorstore.similarity_search_with_score(query=new_customer_info)\n",
    "    \n",
    "    # Filter results based on similarity threshold\n",
    "    risky_customers = [result for result in results if result[1] >= threshold]\n",
    "    \n",
    "    if risky_customers:\n",
    "        print(f\"Found {len(risky_customers)} similar customers at or above the risk threshold of {threshold}.\")\n",
    "        for i, (doc, score) in enumerate(risky_customers, 1):\n",
    "            print(f\"Risky customer {i} with similarity score {score}:\")\n",
    "            print(f\"Customer ID: {doc.metadata['CustomerID']}\")\n",
    "            print(doc.page_content)\n",
    "    else:\n",
    "        print(\"No customers found that are similar enough to indicate risk.\")\n",
    "    \n",
    "    return risky_customers\n",
    "\n",
    "# Step 4: Perform risk search for a new customer profile\n",
    "new_customer_info = \"\"\"\n",
    "Customer ID: CUST0101\n",
    "Age: 35\n",
    "Gender: Female\n",
    "Marital Status: Single\n",
    "Occupation: Private Sector Employee\n",
    "Income Level: 25000000\n",
    "Credit Limit: 8000000\n",
    "Credit Score: 550\n",
    "Card Type: Gold\n",
    "Years With Bank: 5\n",
    "Number of Credit Cards: 2\n",
    "Average Monthly Spending: 1500000\n",
    "Late Payments: 6\n",
    "Credit Card Usage: 0.75\n",
    "Mobile Banking Usage: Yes\n",
    "Customer Satisfaction Rating: 3\n",
    "\"\"\"\n",
    "\n",
    "# Perform risk search based on similarity threshold\n",
    "risk_threshold = 0.8  # Define a similarity threshold to identify risky customers\n",
    "risky_customers = search_risk_in_vectorstore(vectorstore, new_customer_info, embeddings, threshold=risk_threshold)\n",
    "\n",
    "print(\"Risky customers identified:\", risky_customers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
