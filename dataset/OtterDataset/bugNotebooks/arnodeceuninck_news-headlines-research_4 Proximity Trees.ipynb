{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Proximity Trees\n",
    "This is an algorithm made up by Bart Goethals. It doesn't exist yet. It's bsed on another algorithm created for other purposes.\n",
    "\n",
    "You can read section 3 of [this paper](https://arxiv.org/pdf/1808.10594.pdf) (skip 3.1).\n",
    "Lucas, B., Shifaz, A., Pelletier, C., O’Neill, L., Zaidi, N., Goethals, B., ... & Webb, G. I. (2019). Proximity forest: an effective and scalable distance-based classifier for time series. Data Mining and Knowledge Discovery, 33(3), 607-635."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Branch:\n",
    "    def __init__(self, exemplar, class_label, subtree):\n",
    "        self.exemplar = exemplar  # An object, if from a node it is closest to this exemplar, it goes to given tree\n",
    "        self.subtree = subtree  # Should be an internal node or a leaf node\n",
    "\n",
    "        self.class_label = class_label  # The class label of the leaf node, not required for the algorithm, but might be useful for debuggin\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def print(self, depth):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class InternalNode(TreeNode):\n",
    "    def __init__(self, data_x, data_y, groups, depth, max_depth, splits_to_sample):\n",
    "        assert len(data_x) == len(data_y) == len(groups)\n",
    "        assert len(data_x) > 0\n",
    "\n",
    "        depth += 1\n",
    "\n",
    "        self.measure = lambda x, y: np.linalg.norm(x - y)\n",
    "        self.branches = []  # Contains internal nodes or leaf nodes\n",
    "\n",
    "        exemplars, closest_exemplars = get_split(data_x, data_y, groups, splits_to_sample, self.measure)\n",
    "\n",
    "        for i, exemplar in enumerate(exemplars):\n",
    "            closest_data_x = data_x[closest_exemplars == i]\n",
    "            closest_data_y = data_y[closest_exemplars == i]\n",
    "            closest_data_groups = groups[closest_exemplars == i]\n",
    "\n",
    "            if len(closest_data_x) == 0:\n",
    "                # If everything is closer to the other one, you don't need to create a node with 0 data points\n",
    "                continue\n",
    "\n",
    "            subtree = get_node(closest_data_x, closest_data_y, closest_data_groups, depth, max_depth, splits_to_sample)\n",
    "            self.branches.append(Branch(exemplar, i, subtree))  # TODO: Fix label somewhere here instead of i\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Return the label of the closest subtree to the data point\n",
    "        exemplar_distance = [self.measure(data, branch.exemplar) for branch in self.branches]\n",
    "        closest_exemplars = get_closest_exemplars(exemplar_distance, [data], self.measure)\n",
    "        branch = self.branches[closest_exemplars[0]]\n",
    "        return branch.subtree.predict(data)\n",
    "\n",
    "    def print(self, depth):\n",
    "        for branch in self.branches:\n",
    "            print(f\"{'-' * depth}Exemplar ({branch.class_label}): \" + str(branch.exemplar))\n",
    "            branch.subtree.print(depth + 1)\n",
    "\n",
    "\n",
    "# if all data reaching a node has the same class (node is pure), create_leaf function creates a new leaf node and assigns this class lbel to its field class\n",
    "class LeafNode(TreeNode):\n",
    "    def __init__(self, class_label):\n",
    "        self.class_label = class_label  # This label is assigned to all data reaching this node\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.class_label\n",
    "\n",
    "    def print(self, depth):\n",
    "        print(f\"{'-' * depth}Leaf ({self.class_label})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Splitting criteriaa\n",
    "class ProximityTreeClassifier:\n",
    "    def __init__(self, max_depth=5, num_features_to_keep=None, splits_to_sample=10):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.num_features_to_keep = num_features_to_keep\n",
    "        self.features_to_use_indices = None\n",
    "        self.splits_to_sample = splits_to_sample\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "\n",
    "        self.num_features = data_x.shape[1]  # Total number of features, not the number used!!!\n",
    "\n",
    "        self.features_to_use_indices = np.random.choice(len(data_x[0]), self.num_features_to_keep,\n",
    "                                                        replace=False) if self.num_features_to_keep is not None else np.arange(\n",
    "            len(data_x[0]))\n",
    "        data_x_reduced = subsample_features(data_x, self.features_to_use_indices)\n",
    "        # TODO: Reduce features inpredict\n",
    "        self.root = get_node(data_x_reduced, data_y, groups, depth=0, max_depth=self.max_depth,\n",
    "                             splits_to_sample=self.splits_to_sample)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        # Convert data to numpy array if not yet the case\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            data = np.array(data)\n",
    "        # If data is 1d, add a dimension to make it 2d\n",
    "        if data.ndim == 1:\n",
    "            data = data[np.newaxis, :]\n",
    "        assert self.root is not None, \"You must fit the model before predicting\"\n",
    "        assert data.shape[\n",
    "                   1] == self.num_features, \"The number of features in the data must match the number of features in the training data\"\n",
    "        data_reduced = subsample_features(data, self.features_to_use_indices)\n",
    "        predictions = np.apply_along_axis(self.root.predict, 1, data_reduced)\n",
    "        assert predictions.shape[0] == data.shape[0], \"The number of predictions must match the number of data points\"\n",
    "        return predictions\n",
    "\n",
    "    def print(self):\n",
    "        self.root.print(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def is_pure(data_y):\n",
    "    # Check if all data has the same class label\n",
    "    unique_y = np.unique(data_y)\n",
    "    return len(unique_y) == 1\n",
    "\n",
    "\n",
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))\n",
    "\n",
    "\n",
    "def subsample_features(data_x, feature_indices):\n",
    "    return data_x[:, feature_indices]\n",
    "\n",
    "\n",
    "def get_node(data_x, data_y, groups, depth, max_depth, splits_to_sample):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) > 0\n",
    "\n",
    "    if is_pure(data_y) or depth >= max_depth:\n",
    "        # class_label = data_y.iloc[0] # must use iloc here to get element of first row and not element at index 0\n",
    "        class_label = get_most_common_element(data_y)\n",
    "        return LeafNode(class_label)\n",
    "    else:\n",
    "        return InternalNode(data_x, data_y, groups, depth, max_depth, splits_to_sample)\n",
    "\n",
    "\n",
    "# Some util functions\n",
    "def random_pick_row(data):\n",
    "    return data[np.random.randint(0, data.shape[0])]\n",
    "    # return np.random.choice(group_x_with_label) # Can't use this for 2d arrays\n",
    "\n",
    "\n",
    "def get_from_group_if_exists_else_random(group_x, group_y, data_x, data_y, label):\n",
    "    # Get all elements of group_x where group_y == label\n",
    "    group_x_with_label = group_x[group_y == label]\n",
    "    if group_x_with_label.size != 0:\n",
    "        # sample random with same label\n",
    "        return random_pick_row(group_x_with_label)\n",
    "    else:\n",
    "        # If none exist, return a random element from data_x where data_y == label\n",
    "        data_x_with_label = data_x[data_y == label]\n",
    "        return random_pick_row(data_x_with_label)\n",
    "\n",
    "\n",
    "def get_group_data(data_x, data_y, groups, group_id):\n",
    "    random_group_indices = np.where(groups == group_id)[0]\n",
    "    group_x = np.take(data_x, random_group_indices)\n",
    "    group_y = np.take(data_y, random_group_indices)\n",
    "    return group_x, group_y\n",
    "\n",
    "\n",
    "def get_single_split(data_x, data_y, groups):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) != 0\n",
    "\n",
    "    # Sample uniformly any of the groups\n",
    "    # Get the unique values in groups\n",
    "    unique_groups = np.unique(groups)\n",
    "    random_group = np.random.choice(unique_groups)\n",
    "\n",
    "    random_group_x, random_group_y = get_group_data(data_x, data_y, groups, random_group)\n",
    "\n",
    "    assert len(random_group_x) == len(random_group_y) != 0\n",
    "\n",
    "    exemplar_winner = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 1)\n",
    "    exemplar_loser = get_from_group_if_exists_else_random(random_group_x, random_group_y, data_x, data_y, 0)\n",
    "    exemplars = [exemplar_loser, exemplar_winner]\n",
    "\n",
    "    return exemplars\n",
    "\n",
    "\n",
    "def gini(y, classes):\n",
    "    # Code from https://stackoverflow.com/questions/64741099/how-to-calculate-gini-index-using-two-numpy-arrays\n",
    "    if not y.shape[0]:\n",
    "        return 0\n",
    "\n",
    "    probs = []\n",
    "    for cls in classes:\n",
    "        probs.append((y == cls).sum() / y.shape[0])  # For each class c in classes compute class probabilities\n",
    "\n",
    "    p = np.array(probs)\n",
    "    return 1 - ((p * p).sum())\n",
    "\n",
    "\n",
    "def tree_gini_index(Y_left, Y_right):\n",
    "    classes = (0, 1)\n",
    "\n",
    "    # Code from https://stackoverflow.com/questions/64741099/how-to-calculate-gini-index-using-two-numpy-arrays\n",
    "    N = Y_left.shape[0] + Y_right.shape[0]\n",
    "    p_L = Y_left.shape[0] / N\n",
    "    p_R = Y_right.shape[0] / N\n",
    "\n",
    "    return p_L * gini(Y_left, classes) + p_R * gini(Y_right, classes)\n",
    "\n",
    "\n",
    "def get_split(data_x, data_y, groups, splits_to_sample, distance_measure):\n",
    "    assert len(data_x) == len(data_y) == len(groups)\n",
    "    assert len(data_x) != 0\n",
    "\n",
    "    min_gini_index = np.inf\n",
    "    for split in range(splits_to_sample):\n",
    "        exemplars = get_single_split(data_x, data_y, groups)\n",
    "\n",
    "        closest_exemplars = get_closest_exemplars(exemplars, data_x, distance_measure)\n",
    "        data_splits = []\n",
    "        # empty_split = False\n",
    "        for i, exemplar in enumerate(exemplars):\n",
    "            closest_data_y = data_y[closest_exemplars == i]\n",
    "            data_splits.append(closest_data_y)\n",
    "\n",
    "            # if len(closest_data_y) == 0:\n",
    "            #     empty_split = True\n",
    "            #     break\n",
    "\n",
    "        # if empty_split:\n",
    "        #     continue\n",
    "\n",
    "        gini_index = tree_gini_index(data_splits[0], data_splits[1])\n",
    "\n",
    "        if gini_index < min_gini_index:\n",
    "            min_gini_index = gini_index\n",
    "            best_exemplars = exemplars\n",
    "            best_closest_exemplars = closest_exemplars\n",
    "\n",
    "    # if min_gini_index == np.inf:\n",
    "    #     # If no split was found (all containing an empty split), return None\n",
    "    #     return None, None\n",
    "\n",
    "    return best_exemplars, best_closest_exemplars\n",
    "\n",
    "\n",
    "def get_distance_to_exemplars(data_x_row, exemplars, measure):\n",
    "    return [measure(data_x_row, exemplar) for exemplar in exemplars]\n",
    "\n",
    "\n",
    "def get_closest_exemplars(exemplars, data, measure):\n",
    "    # Return the index of the exemplar that is closest to the data point\n",
    "    distances = [get_distance_to_exemplars(data_row, exemplars, measure) for data_row in data]\n",
    "    closest_exemplar_indices = np.argmin(distances, axis=1)\n",
    "    assert len(closest_exemplar_indices) == len(data)\n",
    "    return closest_exemplar_indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test\n",
    "Just some random data example for debugging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_x = np.array([[0, 1, 0], [1, 0, 1], [0, 0, 0],  # 3 headlines for test 0\n",
    "                   [1, 0, 0], [1, 1, 0], [0, 1, 1]])  # 3 headlines for test 1\n",
    "\n",
    "data_y = np.array([0, 1, 0,  # test 0\n",
    "                   1, 0, 0])  # test 1\n",
    "\n",
    "groups = np.array([0, 0, 0,  # test 0\n",
    "                   1, 1, 1])  # test 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Pure node\n",
      "Exemplar (0): 0\n",
      "-Exemplar (0): 1\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0]\n",
      "--Exemplar (0): [0 0 0]\n",
      "---Exemplar (0): [0 0 0]\n",
      "----Exemplar (0): 0\n",
      "-----Leaf (0)\n",
      "----Exemplar (1): [1 0 0]\n",
      "-----Leaf (1)\n",
      "Exemplar (1): 1\n",
      "-Exemplar (0): [1 1 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): 1\n",
      "--Exemplar (0): 0\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 0 1]\n",
      "---Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(data_x, data_y, groups)\n",
    "\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, 1, 0, 0])"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0, 1, 1], [1, 0, 0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More test\n",
    "Let's take a larger test dataset from the real data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_y_features = get_manually_labeled_features(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_sm = train_x.head(7).to_numpy()\n",
    "train_y_sm = train_y.head(7)['Winner'].astype(int).to_numpy()\n",
    "groups_sm = groups.head(7).to_numpy()\n",
    "train_x_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "--Exemplar (0): [1 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "---Leaf (0)\n",
      "--Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "---Exemplar (0): [1 1 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
      "----Leaf (0)\n",
      "---Exemplar (1): [1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "----Leaf (1)\n",
      "Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-Exemplar (0): [1 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "--Leaf (0)\n",
      "-Exemplar (1): [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "--Leaf (1)\n"
     ]
    }
   ],
   "source": [
    "model = ProximityTreeClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_x_sm = test_x.head(4).to_numpy()\n",
    "test_x_features_only = get_manually_labeled_features(test_x.head(4)).to_numpy()\n",
    "test_y_sm = test_y.head(4)['Winner']\n",
    "groups_test_sm = test_x.head(4)['Test'].to_numpy()\n",
    "\n",
    "assert train_x_sm.shape[1] == test_x_features_only.shape[1]  # same number of features\n",
    "\n",
    "test_x_features_only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/3883669348.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_x_features_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_y_sm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroups_test_sm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mprediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Test {group} prediction: {prediction}, actual: {y}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[0mtree_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m         \u001B[0mmost_occuring\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_along_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_most_common_element\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtree_predictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmost_occuring\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36mget_predictions\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/2111324172.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_predictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_trees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for x, y, group in zip(test_x_features_only, test_y_sm, groups_test_sm):\n",
    "    prediction = model.predict(x)\n",
    "    print(f'Test {group} prediction: {prediction}, actual: {y}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This results in all the same predictions (all 0 or all 1) most of the time. (might be just coïncidence, it's also possible to predict the other number):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ProximityForestClassifier:\n",
    "    def __init__(self, n_trees=100, show_progress=True, use_bootstrapping=True, reduce_features=True,\n",
    "                 sample_multiple_splits=10, max_depth=5):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "        self.classes_ = None\n",
    "        self.show_progress = show_progress\n",
    "        self.use_bootstrapping = use_bootstrapping\n",
    "        self.reduce_features = reduce_features\n",
    "        self.sample_multiple_splits = sample_multiple_splits\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, data_x, data_y, groups):\n",
    "        data_x = self.preprocess_data(data_x)\n",
    "        data_y = self.preprocess_data(data_y.astype(int))\n",
    "        groups = self.preprocess_data(groups)\n",
    "\n",
    "        # multithreaded\n",
    "        iterator = tqdm(range(self.n_trees), disable=not self.show_progress, desc='Fitting')\n",
    "        self.trees = Parallel(n_jobs=32)(delayed(self.fit_tree)(data_x, data_y, groups) for i in iterator)\n",
    "\n",
    "        self.classes_ = np.unique(data_y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_tree(self, data_x, data_y, groups):\n",
    "        if self.use_bootstrapping:\n",
    "            data_x_bootstrap, data_y_bootstrap, groups_bootstrap = self.bootstrap(data_x, data_y, groups)\n",
    "        else:\n",
    "            data_x_bootstrap, data_y_bootstrap, groups_bootstrap = data_x, data_y, groups\n",
    "\n",
    "        if self.reduce_features:\n",
    "            num_features_to_keep = int(np.sqrt(data_x_bootstrap.shape[1]))\n",
    "        else:\n",
    "            num_features_to_keep = None\n",
    "            # assert num_features_to_keep <= len(data_x[0])\n",
    "\n",
    "        return ProximityTreeClassifier(num_features_to_keep=num_features_to_keep,\n",
    "                                       splits_to_sample=self.sample_multiple_splits, max_depth=self.max_depth)\\\n",
    "            .fit(data_x_bootstrap, data_y_bootstrap, groups_bootstrap)\n",
    "\n",
    "    def bootstrap(self, data_x, data_y, groups):\n",
    "        # Bootstrap some rows\n",
    "        indices = np.random.choice(len(data_x), size=int(len(data_x) * 0.1), replace=True)\n",
    "        data_x_bootstrap = data_x[indices]\n",
    "        data_y_bootstrap = data_y[indices]\n",
    "        groups_bootstrap = groups[indices]\n",
    "        return data_x_bootstrap, data_y_bootstrap, groups_bootstrap\n",
    "\n",
    "    def get_predictions(self, data):\n",
    "        data = self.preprocess_data(data)\n",
    "\n",
    "        iterator = tqdm(range(self.n_trees), disable=not self.show_progress, desc='Predicting')\n",
    "        predictions = Parallel(n_jobs=32)(delayed(self.trees[i].predict)(data) for i in iterator)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        # if data is a pandas dataframe, convert to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.replace({True: 1, False: 0})\n",
    "            data = data.to_numpy()\n",
    "        if isinstance(data, pd.Series):\n",
    "            data = data.replace({True: 1, False: 0})\n",
    "            data = data.to_numpy()\n",
    "        return data\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        tree_predictions = self.get_predictions(data)\n",
    "        most_occuring = np.apply_along_axis(get_most_common_element, 0, tree_predictions)\n",
    "        return most_occuring\n",
    "        # Get most occuring element for each column\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_most_common_element(array):\n",
    "    return np.argmax(np.bincount(array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x_sm, train_y_sm, groups_sm)\n",
    "model.predict(test_x_features_only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True,\n",
    "                                                              full_y_test=True)\n",
    "test_x_features = get_manually_labeled_features(test_x)\n",
    "\n",
    "model = ProximityForestClassifier()\n",
    "model.fit(train_x, train_y[\"Winner\"], groups)\n",
    "model.predict_proba(test_x_features)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Not all numbers are 0 (but quite a lot). This will hopefully be fixed once i add bagging and random subspace method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.15% (84/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without any bootstrpping or random subspace sampling, the accuracy is slightly better than random Accuracy: 46.15% (84/182) (+5%)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bootstrapping\n",
    "The code above has been updated to use bootstrapping. This means that for each tree we will sample a random subset of the data and use that to train the tree."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:07<00:00, 70.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.20% (95/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! Adding bootstrapping improved the accuracy by +7%. Accuracy: 53.30% (97/182)\n",
    "We're also using a lot less samples per tree (randomly sampling 10% of the dataset size for each tree)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random subspace sampling\n",
    "The code above has been updated to use random subspace sampling. For each internal node, we're only going to look at sqrt(num_features) features instead of all of them. Which features we look at per node, will randomly be fixed during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:06<00:00, 79.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.49% (101/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy: 55.49% (101/182). Again a slight increase, let's take a look at how bootstrapping without random subspace sampling works:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:47<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.75% (96/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500, use_bootstrapping=False)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy: 52.75% (96/182). An increase similar to the size of the increase of bootstrapping."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample multiple splits (select using gini)\n",
    "The code above has been updated to not just take a random test as split, but sample multiple tests and use the one with the lowest gini impurity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 500/500 [00:10<00:00, 47.00it/s]\n",
      "Predicting: 100%|██████████| 500/500 [00:22<00:00, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.34% (108/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=500)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters\n",
    "Just some playing around, still need to do a better search."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting: 100%|██████████| 32/32 [00:00<00:00, 175.82it/s]\n",
      "Predicting: 100%|██████████| 32/32 [00:00<00:00, 16001.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.95% (100/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=32)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 100/100 [00:00<00:00, 452.58it/s]\n",
      "Predicting: 100%|██████████| 100/100 [00:04<00:00, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.40% (98/182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=100)\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting...: 100%|██████████| 1000/1000 [00:25<00:00, 39.68it/s]\n",
      "Predicting: 100%|██████████| 1000/1000 [00:46<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.24% (106/182)\n"
     ]
    }
   ],
   "source": [
    "from util import fit_predict_print_wp, get_wpm_train_test\n",
    "\n",
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "model = ProximityForestClassifier(n_trees=1000)\n",
    "fit_predict_print_wp(model, train_x, train_y,\n",
    "                     test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Better search\n",
    "The hyperparameters we want to optimize are: n_trees, sample_multiple_splits and max_depth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from util import get_winners_only, predict_wp, evaluate_wp, get_wpm_train_test, get_manually_labeled_features\n",
    "\n",
    "train_x_full, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=False)\n",
    "train_x = get_manually_labeled_features(train_x_full)\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "\n",
    "def objective_cv(space):\n",
    "    # Change al floats in the space dict to ints\n",
    "    for key in space:\n",
    "        space[key] = int(space[key])\n",
    "\n",
    "    model = ProximityForestClassifier(show_progress=False, **space)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for train_index, val_index in group_kfold.split(train_x, train_y, groups=train_x_full['Test']):\n",
    "        train_x_small, train_y_small = train_x_full.iloc[train_index], train_y.iloc[train_index]\n",
    "        val_x, val_y = train_x_full.iloc[val_index], get_winners_only(train_y.iloc[val_index])\n",
    "        groups_train = train_x_full.iloc[train_index]['Test']\n",
    "\n",
    "        accuracy = fit_predict_print_wp(model, train_x_small, train_y_small,\n",
    "                     val_x, val_y, groups=groups_train, multiple_class_names=False, silent=True)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        break # Skip cross validation, only use one fold\n",
    "\n",
    "    accuracy_mean = np.mean(accuracies)\n",
    "    print(f\"Accuracy mean: {accuracy_mean} for parameters {space}\")\n",
    "\n",
    "    return {'loss': -accuracy_mean, 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 5, 'n_trees': 96, 'sample_multiple_splits': 18}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 63, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 5, 'n_trees': 91, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 9, 'n_trees': 160, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 3, 'n_trees': 102, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.512396694214876 for parameters {'max_depth': 3, 'n_trees': 49, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 2, 'n_trees': 54, 'sample_multiple_splits': 17}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 5, 'n_trees': 81, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 9, 'n_trees': 176, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 8, 'n_trees': 146, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 5, 'n_trees': 127, 'sample_multiple_splits': 17}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 3, 'n_trees': 175, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5041322314049587 for parameters {'max_depth': 8, 'n_trees': 46, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5840220385674931 for parameters {'max_depth': 7, 'n_trees': 42, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 10, 'n_trees': 84, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 8, 'n_trees': 156, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 5, 'n_trees': 52, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 5, 'n_trees': 51, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 7, 'n_trees': 191, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 4, 'n_trees': 128, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5371900826446281 for parameters {'max_depth': 2, 'n_trees': 73, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 4, 'n_trees': 113, 'sample_multiple_splits': 1}\n",
      "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 6, 'n_trees': 115, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 6, 'n_trees': 136, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5068870523415978 for parameters {'max_depth': 6, 'n_trees': 111, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 4, 'n_trees': 122, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 6, 'n_trees': 139, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 4, 'n_trees': 104, 'sample_multiple_splits': 20}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 3, 'n_trees': 98, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5068870523415978 for parameters {'max_depth': 7, 'n_trees': 67, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 6, 'n_trees': 154, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 4, 'n_trees': 167, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 91, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 2, 'n_trees': 119, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 5, 'n_trees': 136, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5950413223140496 for parameters {'max_depth': 3, 'n_trees': 33, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 10, 'n_trees': 196, 'sample_multiple_splits': 20}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 9, 'n_trees': 146, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 6, 'n_trees': 105, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 3, 'n_trees': 90, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 4, 'n_trees': 79, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 5, 'n_trees': 181, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 7, 'n_trees': 63, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 8, 'n_trees': 128, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 2, 'n_trees': 165, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 5, 'n_trees': 147, 'sample_multiple_splits': 18}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 3, 'n_trees': 110, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 6, 'n_trees': 95, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 8, 'n_trees': 74, 'sample_multiple_splits': 16}\n",
      "100%|██████████| 50/50 [06:29<00:00,  7.80s/trial, best loss: -0.6033057851239669]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'max_depth': 4.0, 'n_trees': 117.0, 'sample_multiple_splits': 4.0}"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "\n",
    "space = {\n",
    "    'n_trees': hp.quniform('n_trees', 32, 200, 1), # Chosen to keep this low to speed up the search\n",
    "    'sample_multiple_splits': hp.quniform('sample_multiple_splits', 1, 20, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 10, 1),\n",
    "}\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=50,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy mean: 0.6033057851239669 for parameters {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting: 100%|██████████| 117/117 [00:00<00:00, 1257.76it/s]\n",
      "Predicting: 100%|██████████| 117/117 [00:00<00:00, 1170.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.55% (92/182)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, groups = get_wpm_train_test(include_groups=True, x_train_features_only=True)\n",
    "\n",
    "best_params = {'max_depth': 4, 'n_trees': 117, 'sample_multiple_splits': 4}\n",
    "model = ProximityForestClassifier(**best_params)\n",
    "\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hmm, this is not good. Let's try changing the hyperparameter search space:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 26, 'n_trees': 227, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 475, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 12, 'n_trees': 255, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 32, 'n_trees': 268, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 9, 'n_trees': 406, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 28, 'n_trees': 250, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5647382920110193 for parameters {'max_depth': 32, 'n_trees': 341, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5426997245179064 for parameters {'max_depth': 26, 'n_trees': 206, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 12, 'n_trees': 209, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 7, 'n_trees': 264, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 13, 'n_trees': 299, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 25, 'n_trees': 395, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 5, 'n_trees': 385, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 7, 'n_trees': 370, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 20, 'n_trees': 328, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 10, 'n_trees': 417, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 20, 'n_trees': 203, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 19, 'n_trees': 437, 'sample_multiple_splits': 14}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 16, 'n_trees': 341, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 12, 'n_trees': 206, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5537190082644629 for parameters {'max_depth': 23, 'n_trees': 140, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5509641873278237 for parameters {'max_depth': 21, 'n_trees': 152, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5867768595041323 for parameters {'max_depth': 29, 'n_trees': 304, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 29, 'n_trees': 317, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 16, 'n_trees': 509, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.559228650137741 for parameters {'max_depth': 30, 'n_trees': 303, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 22, 'n_trees': 359, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 18, 'n_trees': 291, 'sample_multiple_splits': 6}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 24, 'n_trees': 334, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5619834710743802 for parameters {'max_depth': 27, 'n_trees': 173, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 16, 'n_trees': 466, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 30, 'n_trees': 235, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5785123966942148 for parameters {'max_depth': 15, 'n_trees': 277, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5482093663911846 for parameters {'max_depth': 32, 'n_trees': 440, 'sample_multiple_splits': 7}\n",
      "Accuracy mean: 0.581267217630854 for parameters {'max_depth': 24, 'n_trees': 362, 'sample_multiple_splits': 15}\n",
      "Accuracy mean: 0.5757575757575758 for parameters {'max_depth': 27, 'n_trees': 240, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 21, 'n_trees': 506, 'sample_multiple_splits': 16}\n",
      "Accuracy mean: 0.5454545454545454 for parameters {'max_depth': 31, 'n_trees': 319, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 14, 'n_trees': 281, 'sample_multiple_splits': 12}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 10, 'n_trees': 176, 'sample_multiple_splits': 5}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 26, 'n_trees': 251, 'sample_multiple_splits': 9}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 18, 'n_trees': 420, 'sample_multiple_splits': 3}\n",
      "Accuracy mean: 0.5730027548209367 for parameters {'max_depth': 4, 'n_trees': 377, 'sample_multiple_splits': 8}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 28, 'n_trees': 347, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 23, 'n_trees': 264, 'sample_multiple_splits': 11}\n",
      "Accuracy mean: 0.5647382920110193 for parameters {'max_depth': 20, 'n_trees': 480, 'sample_multiple_splits': 13}\n",
      "Accuracy mean: 0.5702479338842975 for parameters {'max_depth': 25, 'n_trees': 313, 'sample_multiple_splits': 2}\n",
      "Accuracy mean: 0.5564738292011019 for parameters {'max_depth': 9, 'n_trees': 401, 'sample_multiple_splits': 10}\n",
      "Accuracy mean: 0.5344352617079889 for parameters {'max_depth': 17, 'n_trees': 221, 'sample_multiple_splits': 4}\n",
      "Accuracy mean: 0.5674931129476584 for parameters {'max_depth': 32, 'n_trees': 333, 'sample_multiple_splits': 12}\n",
      "100%|██████████| 50/50 [59:06<00:00, 70.94s/trial, best loss: -0.5867768595041323]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'max_depth': 20.0, 'n_trees': 328.0, 'sample_multiple_splits': 2.0}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "\n",
    "space = {\n",
    "    'n_trees': hp.quniform('n_trees', 128, 512, 1), # Chosen to keep this low to speed up the search\n",
    "    'sample_multiple_splits': hp.quniform('sample_multiple_splits', 2, 16, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 32, 1),\n",
    "}\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(fn=objective_cv,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=50,\n",
    "                   trials=trials)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "100%|██████████| 50/50 [59:06<00:00, 70.94s/trial, best loss: -0.5867768595041323]\n",
    "{'max_depth': 20.0, 'n_trees': 328.0, 'sample_multiple_splits': 2.0}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting: 100%|██████████| 328/328 [00:14<00:00, 23.06it/s]\n",
      "Predicting: 100%|██████████| 328/328 [00:27<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.59% (103/182)\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': 20, 'n_trees': 328, 'sample_multiple_splits': 2}\n",
    "model = ProximityForestClassifier(**best_params)\n",
    "\n",
    "fit_predict_print_wp(model, train_x, train_y, test_x, test_y, groups=groups, multiple_class_names=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the parameters from trials\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the loss in function of n_trees (from trials)\n",
    "df = pd.DataFrame(trials)\n",
    "df['n_trees'] = df['misc'].apply(lambda x: x['vals']['n_trees'][0])\n",
    "df['sample_multiple_splits'] = df['misc'].apply(lambda x: x['vals']['sample_multiple_splits'][0])\n",
    "df['max_depth'] = df['misc'].apply(lambda x: x['vals']['max_depth'][0])\n",
    "df['loss'] = df['result'].apply(lambda x: x['loss']) * -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df, x='n_trees', y='loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcsklEQVR4nO3df3Qd5X3n8fdHtonAxkoCAqu2iXBCEpCDHVBYUkpaoKQum2OcwgIhycanm8OmCSUbkt1Ay8npsm7Lhl2abGGTsoZCNhx+rBNc0yb8WDbZtFkgFsQGCwIlrsF2ZSxMkA1EYEXf/eOOxNX16IdtjeY+up/XOT7cmbkz89XDSN97n5nn+ygiMDMzq9VUdgBmZlafnCDMzCyXE4SZmeVygjAzs1xOEGZmlmtm2QFMliOPPDLa29vLDsPMLCmPPvroixHRmrdt2iSI9vZ2urq6yg7DzCwpkp4bbZu7mMzMLJcThJmZ5XKCMDOzXE4QZmaWywnCzMxyTZunmA7U4GCwZdervLC7n6PnNtN+xGyamlR2WDZN+PqylDV0ghgcDO7t3sHld22gf+8gzbOauO6CpSzrmOdfYjtovr4sdQ3dxbRl16vDv7wA/XsHufyuDWzZ9WrJkdl04OvLUtfQCeKF3f3Dv7xD+vcOsnNPf0kR2XTi68tS19AJ4ui5zTTPGtkEzbOaOOrw5pIisunE15elrqETRPsRs7nugqXDv8RDfcTtR8wuOTKbDnx9Weo0XaYc7ezsjAOpxTT0lMnOPf0cdbifMrHJ5evL6p2kRyOiM29bQz/FBNDUJBa1zmFR65yyQ7FpyNeXpayhu5jMzGx0ThBmZpbLCcLMzHI5QZiZWS4nCDMzy+UEYWZmuZwgzMwslxOEmZnlcoIwM7NcThBmZpbLCcLMzHI5QZiZWS4nCDMzy9Xw1VzNijRU7vuF3f0cPbe+y32nFGtqUm1bJwizggwOBvd27xiel3powqBlHfPq7o9DSrGmJuW2dReTWUG27Hp1+I8CVOajvvyuDWzZ9WrJke0rpVhTk3LbOkGYFeSF3f3DfxSG9O8dZOee/pIiGl1KsaYm5bZ1gjAryNFzm4fnox7SPKuJow5vLimi0aUUa2pSbttCE4SkZZKelvSspCtytq+U1CtpQ/bv01XbviqpW9JTkv6bpPrurDOr0X7EbK67YOnwH4ehvuf2I2aXHNm+Uoo1NSm3rSKimANLM4BngLOBbcB64GMR8WTVe1YCnRFxac2+vw5cC3woW/UPwJUR8cPRztfZ2RldXV2T+SOYHbShp1d27unnqMPr++mVlGJNTT23raRHI6Izb1uRTzGdAjwbEZuzIO4AzgWeHHOvigCagUMAAbOAFwqK06wwTU1iUescFrXOKTuUcaUUa2pSbdsiu5jmA1urlrdl62qdJ+lxSWskLQSIiIeAHwA92b/7IuKp2h0lXSKpS1JXb2/v5P8EZmYNrOyb1PcA7RFxIvAAcCuApHcBxwMLqCSVMyWdXrtzRNwYEZ0R0dna2jqFYZuZTX9FJojtwMKq5QXZumERsSsiXs8WVwMnZ68/CjwcEa9ExCvA94EPFhirmZnVKDJBrAeOk3SspEOAi4B11W+Q1Fa1uBwY6kZ6HvhNSTMlzQJ+s2qb2aQbGBhk49ZfcO+mHjZufZmBgcHxdzKb5gq7SR0RA5IuBe4DZgA3R0S3pKuBrohYB1wmaTkwALwErMx2XwOcCTxB5Yb1vRFxT1GxWmMbGBhk7cbtXLV203AphFUrFrNiyXxmziy7F9asPIU95jrV/JirHaiNW3/BhTc+PGK0a/OsJu685FSWLHxbiZGZFW+sx1z98cgaXk9ffimEHX31XwrBrEhOENbw2loOzS2FMK+l/kshmBXJCcIaXkfbXFatWDyiFMKqFYvpaGspOTKzcnk+CGt4M2c2sWLJfI47ag47+vqZ19JMR1uLb1Bbw3OCMKOSJJYsfBtLFo7/XrNG4Y9IZmaWywnCzMxyuYspIalOfG5p8PVltZwgEpHyxOdW/3x9WR53MSUi5YnPrf75+rI8ThCJSHnic6t/vr4sjxNEIlKe+Nzqn68vy+MEkYiUJz63+ufry/K4mmtC6nnic0ufr6/GNFY1Vz/FlJBUJz63NPj6slruYjIzs1xOEGZmlstdTMbAwCDdPX309PXT1nIoHW1zG66SqUcRp9cGRcVbxHFTa9shThANzvMxexQxpNcGRcVbxHFTa9tqjfEXwEbV3dM3nBygMjjqqrWb6O7pKzmyqeNRxOm1QVHxFnHc1Nq2mhNEg/N8zB5FDOm1QVHxFnHc1Nq2mhNEg/N8zB5FDOm1QVHxFnHc1Nq2mhNEg/N8zB5FDOm1QVHxFnHc1Nq2mkdS2/BTTI08H7NHEafXBkXFW8Rx67ltxxpJ7QRhZtbAxkoQjfUx0czMJswJwszMcjlBmJlZrkIThKRlkp6W9KykK3K2r5TUK2lD9u/T2fozqtZtkNQvaUURMQ4MDLJx6y+4d1MPG7e+zMDA4Pg7mU3Q4GCwufcVHvr5i2zufYXBwcm551fUcYuQUqw2UmGlNiTNAG4Azga2AeslrYuIJ2veemdEXFq9IiJ+ACzNjvN24Fng/smO0WUmrEgplYMoSkqx2r6K/Ct4CvBsRGyOiDeAO4BzD+A45wPfj4jXJjU6XGbCipVSOYiipBSr7avIBDEf2Fq1vC1bV+s8SY9LWiNpYc72i4DbiwjQZSasSCmVgyhKSrHavsruR7kHaI+IE4EHgFurN0pqA94H3Je3s6RLJHVJ6urt7d3vk7vMhBUppXIQRUkpVttXkQliO1D9jWBBtm5YROyKiNezxdXAyTXHuAC4OyL25p0gIm6MiM6I6Gxtbd3vAF1mwoqUUjmIoqQUq+2rsJHUkmYCzwBnUUkM64GLI6K76j1tEdGTvf4o8OWIOLVq+8PAldlN6zEd6Ehql5mwIqVUDqIoKcXaiEortSHpHOBrwAzg5oj4U0lXA10RsU7SnwPLgQHgJeAPIuJn2b7twI+BhREx7rOnLrVhZrb/XIvJzMxyuRaTmZntt4afk9oTlFuRfC0U1wZu2+LboKEThCcotyL5WvBo8iJNRRs0dBeTJyi3Ivla8GjyIk1FGzR0gvAE5VYkXwseTV6kqWiDhk4QnqDciuRrwaPJizQVbdDQCcITlFuRfC14NHmRpqINGn4cRKNNUG5Ty9eCR5MXaTLawAPlzMwslwfKmZnZfnOCMDOzXE4QZmaWq6FHUptZ8VxqI11OEGZWGJfaSJu7mMysMC61kTYnCDMrjEttpM0JwswK41IbaXOCMLPCuNRG2jyS2swK5VIb9W2skdR+isnMCtXUJBa1zmFR65wkjmtvcheTmZnlcoIwM7Nc7mIqwMDAIN09ffT09dPWcigdbXOZOfPgc3FqI0eLagdL71qwNDlBTLKBgUHWbtzOVWs3DY/wXLViMSuWzD+oP46pjRwtqh0svWvB0jWh31RJn5c0VxU3SXpM0oeLDi5F3T19w38UoTJ456q1m+ju6Tuo46Y2crSodrD0rgVL10Q/yv1+ROwGPgy8DfgkcE1hUSWspy9/hOeOvsYaOVpUO1h614Kla6IJYuh76znA/4yI7qp1VqWt5dDcEZ7zWhpr5GhR7WDpXQuWrokmiEcl3U8lQdwn6XBgcJx9GlJH21xWrVg8YoTnqhWL6WhrOajjpjZytKh2sPSuBUvXhEZSS2oClgKbI+JlSW8HFkTE4wXHN2H1NJJ66OmdHX39zGtppqOtZVKfYkpl5GhR7WDpXQtWv8YaST3RBHEasCEiXpX0CeAk4OsR8dw4+y0Dvg7MAFZHxDU121cC1wLbs1XXR8TqbNsxwGpgIRDAORGxZbRz1VOCMDNLxVgJYqIf574BvCZpCfBF4OfAt8Y56QzgBuB3gROAj0k6Ieetd0bE0uzf6qr13wKujYjjgVOAnROM1czMJsFEE8RAVL5qnEvlU/4NwOHj7HMK8GxEbI6IN4A7sv3HlSWSmRHxAEBEvBIRr00wVjMzmwQTTRB7JF1J5fHWv8vuScwaZ5/5wNaq5W3ZulrnSXpc0hpJC7N17wZelvRdST+VdG32jWQESZdI6pLU1dvbO8EfZaTBwWBz7ys89PMX2dz7CoOD9VvdNqVYi5JaG6QWr1m1iY6kvhC4mMp4iB3Z/YFrJ+H89wC3R8Trkv4tcCtwZhbX6cD7geeBO4GVwE3VO0fEjcCNULkHsb8nT2lEakqxFiW1NkgtXrNaE/oGERE7gNuAFkkfAfojYsx7EFRuPC+sWl7Amzejh467KyJezxZXAydnr7dRuSm+OSIGgLVUboxPqpRGpKYUa1FSa4PU4jWrNdFSGxcAPwH+FXAB8Iik88fZbT1wnKRjJR0CXASsqzluW9XicuCpqn3fKqk1Wz4TeHIise6PlEakphRrUVJrg9TiNas10S6mPwY+EBE7AbI/3P8bWDPaDhExIOlS4D4qj7neHBHdkq4GuiJiHXCZpOXAAPASlW4kIuJXkr4EPChJwKPA/ziQH3AsQyNSq3+J63VEakqxFiW1NkgtXrNaE71J3TSUHDK7JrJvRHwvIt4dEe+MiD/N1n0lSw5ExJUR0RERSyLijIj4WdW+D0TEiRHxvohYmT0JNalSGpGaUqxFSa0NUovXrNZEB8pdC5wI3J6tuhB4PCK+XGBs++VAB8qlNCI1pViLklobpBavNZ6DHkmdHeQ84LRs8e8j4u5Jim9SeCS1mdn+GytBTHjCoIj4DvCdSYvKzMzq2pgJQtIeKnWQ9tkERETMLSQqMzMr3ZgJIiLGK6dhZmbTlOekNuPNm8kv7O7n6Ln1fzN5qJR6T18/bS2H0tE296BLqRfVBqm1rb3JCcIaXmolMQYGBlm7cfvwnN9DkzGtWDL/gJNEUW2QWtvaSJ69xRpeaiUxunv6hpMDVOK9au0munv6DviYRbVBam1rIzlBWMNLrSRGT19+vDv6Djzeotogtba1kZwgrOENlcSoVs8lMdpaDs2Nd17LgcdbVBuk1rY2khOENbzUSmJ0tM1l1YrFI+JdtWIxHW0tB3zMotogtba1kSY8krreeSS1HYzUSmIMPcW0o6+feS3NdLS1TNpTTJPdBqm1baOZlFIb9c4Jwsxs/42VINzFZGZmuZwgzMwslwfKWVI8Ktds6jhBWDI8KtdsarmLyZLhUblmU8sJwpLhUblmU8sJwpLhUblmU8sJwpLhUblmU8s3qS0ZTU1iWcc83nvZ6R6VazYFnCAsKU1NYlHrHBa1zik7FLNpz11MZmaWywnCzMxyOUGYmVku34OwwrgshlnanCCsEC6LYZY+dzFZIVwWwyx9hSYIScskPS3pWUlX5GxfKalX0obs36ertv2qav26IuO0yeeyGGbpK6yLSdIM4AbgbGAbsF7Suoh4suatd0bEpTmH+GVELC0qPivWUFmM6iThshhmaSnyG8QpwLMRsTki3gDuAM4t8HxWR1wWwyx9Rd6kng9srVreBvyLnPedJ+lDwDPAFyJiaJ9mSV3AAHBNRKyt3VHSJcAlAMccc8wkhm4Hy2UxzNJX9k3qe4D2iDgReAC4tWrbO7KJtC8GvibpnbU7R8SNEdEZEZ2tra1TE7FN2FBZjFMXHcmi1jlODmaJKTJBbAcWVi0vyNYNi4hdEfF6trgaOLlq2/bsv5uBHwLvLzBWMzOrUWSCWA8cJ+lYSYcAFwEjnkaS1Fa1uBx4Klv/NklvyV4fCZwG1N7cNjOzAhV2DyIiBiRdCtwHzABujohuSVcDXRGxDrhM0nIq9xleAlZmux8P/JWkQSpJ7Jqcp5+sAXl0ttnUUUSUHcOk6OzsjK6urrLDsAJ5dLbZ5JP0aHa/dx9l36Q2mzCPzjabWk4QlgyPzjabWk4Qloyh0dnVPDrbrDhOEJYMj842m1ou923J8Ohss6nlBGFJGRqdvah1TtmhmE177mIyM7NcThBmZpbLXUzm0clmlssJosF5dLKZjcZdTA3Oo5PNbDROEA3Oo5PNbDROEA3Oo5PNbDROEA3Oo5PNbDS+Sd3gPDrZzEbjBGEenWxmudzFZGZmuZwgzMwslxOEmZnl8j0IM7MqLj3zJicIM7OMS8+M5C4mM7OMS8+M5ARhZpZx6ZmRnCDMzDIuPTOSE4SZWcalZ0byTWozs4xLz4zkBGFmVsWlZ97kLiYzM8vlBGFmZrkKTRCSlkl6WtKzkq7I2b5SUq+kDdm/T9dsnytpm6Tri4zTzMz2Vdg9CEkzgBuAs4FtwHpJ6yLiyZq33hkRl45ymP8E/KioGM3MbHRFfoM4BXg2IjZHxBvAHcC5E91Z0snA0cD9BcVnZmZjKDJBzAe2Vi1vy9bVOk/S45LWSFoIIKkJ+K/Al8Y6gaRLJHVJ6urt7Z2suM3MjPJvUt8DtEfEicADwK3Z+s8C34uIbWPtHBE3RkRnRHS2trYWHKqZWWMpchzEdmBh1fKCbN2wiNhVtbga+Gr2+oPA6ZI+C8wBDpH0SkTsc6PbzMyKUWSCWA8cJ+lYKonhIuDi6jdIaouInmxxOfAUQER8vOo9K4FOJwczs6lVWIKIiAFJlwL3ATOAmyOiW9LVQFdErAMuk7QcGABeAlYWFY+Zme0fRUTZMUyKzs7O6OrqKjsMM7OkSHo0IjrztpV9k9rMzOqUE4SZmeVygjAzs1xOEGZmlssJwszMcjlBmJlZLicIMzPL5QRhZma5nCDMzCyXE4SZmeVygjAzs1xOEGZmlqvIct82yQYHgy27XuWF3f0cPbeZ9iNm09SkssMys2nKCSIRg4PBvd07uPyuDfTvHaR5VhPXXbCUZR3znCTMrBDuYkrEll2vDicHgP69g1x+1wa27Hq15MjMbLpygkjEC7v7h5PDkP69g+zc019SRGY23TlBJOLouc00zxr5v6t5VhNHHd5cUkRmNt05QSSi/YjZXHfB0uEkMXQPov2I2SVHZmbTlW9SJ6KpSSzrmMd7LzudnXv6OepwP8VkZsVygkhIU5NY1DqHRa1zyg7FzBqAu5jMzCyXE4SZmeVygjAzs1xOEGZmlssJwszMcikiyo5hUkjqBZ47iEMcCbw4SeEULaVYIa14U4oV0oo3pVghrXgPJtZ3RERr3oZpkyAOlqSuiOgsO46JSClWSCvelGKFtOJNKVZIK96iYnUXk5mZ5XKCMDOzXE4Qb7qx7AD2Q0qxQlrxphQrpBVvSrFCWvEWEqvvQZiZWS5/gzAzs1xOEGZmlquhE4SkhZJ+IOlJSd2SPl92TOORNEPSTyX9bdmxjEfSWyWtkfQzSU9J+mDZMY1F0hey62CTpNsl1c1sTJJulrRT0qaqdW+X9ICkf8z++7YyY6w2SrzXZtfC45LulvTWEkMclhdr1bYvSgpJR5YRW57R4pX0h1n7dkv66mScq6ETBDAAfDEiTgBOBT4n6YSSYxrP54Gnyg5igr4O3BsR7wWWUMdxS5oPXAZ0RsRiYAZwUblRjXALsKxm3RXAgxFxHPBgtlwvbmHfeB8AFkfEicAzwJVTHdQobmHfWJG0EPgw8PxUBzSOW6iJV9IZwLnAkojoAP7LZJyooRNERPRExGPZ6z1U/oDNLzeq0UlaAPxLYHXZsYxHUgvwIeAmgIh4IyJeLjWo8c0EDpU0EzgM+OeS4xkWET8CXqpZfS5wa/b6VmDFVMY0lrx4I+L+iBjIFh8GFkx5YDlGaVuAvwD+A1BXT/KMEu8fANdExOvZe3ZOxrkaOkFUk9QOvB94pORQxvI1KhfsYMlxTMSxQC/w11mX2GpJdTs/akRsp/Kp63mgB+iLiPvLjWpcR0dET/Z6B3B0mcHsp98Hvl92EKORdC6wPSI2lh3LBL0bOF3SI5L+r6QPTMZBnSAASXOA7wD/LiJ2lx1PHkkfAXZGxKNlxzJBM4GTgG9ExPuBV6mvLpARsv77c6kktl8DZkv6RLlRTVxUnlevq0+6o5H0x1S6d28rO5Y8kg4D/gj4Stmx7IeZwNupdJX/e+AuSQc9H3HDJwhJs6gkh9si4rtlxzOG04DlkrYAdwBnSvp2uSGNaRuwLSKGvpGtoZIw6tVvA/8UEb0RsRf4LvDrJcc0nhcktQFk/52UboUiSVoJfAT4eNTvIKx3UvmgsDH7fVsAPCZpXqlRjW0b8N2o+AmVXoaDvrHe0Akiy7A3AU9FxHVlxzOWiLgyIhZERDuVm6f/JyLq9hNuROwAtkp6T7bqLODJEkMaz/PAqZIOy66Ls6jjm+qZdcCnstefAv6mxFjGJWkZlS7S5RHxWtnxjCYinoiIoyKiPft92waclF3T9WotcAaApHcDhzAJlWgbOkFQ+VT+SSqfxjdk/84pO6hp5A+B2yQ9DiwF/qzccEaXfdNZAzwGPEHld6NuSi1Iuh14CHiPpG2S/g1wDXC2pH+k8g3omjJjrDZKvNcDhwMPZL9r3yw1yMwosdatUeK9GViUPfp6B/CpyfiG5lIbZmaWq9G/QZiZ2SicIMzMLJcThJmZ5XKCMDOzXE4QZmaWywnCzMxyOUFYw5H0Q0mdZZ5X0h/VbPt/E9h/S9FlpyWtlHR99vozkv511fpfK/LcVn+cIMzKMSJBRETdlfWIiG9GxLeyxZVUalRZA3GCsLogabakv5O0MZuw50JJX5G0Plu+caj4WPZJ/C8kdWUTEX1A0neziXNWZe9pzyZPuS17z5qsCFvteT8s6SFJj0n6X1nhxtFi3CLpz7NRwF2STpJ0n6SfS/pM9p7fUtVkTpKuz+oPVR/nGiplxTdIui1b90rV/j/K2uJpSd+UtM/vqaRPSPpJdoy/kjRjlJhnSLola8MnJH2hqg2/nu2/SdIpOfv+iaQvSTof6KQyKn6DpEMlXaPKRFuPS5qUuQes/jhBWL1YBvxzRCzJJuy5F7g+Ij6QLR9KpcjbkDciohP4JpUaRJ8DFgMrJR2Rvec9wH+PiOOB3cBnq0+YdddcBfx2RJwEdAGXjxPn8xGxFPh7KhO3nE+lguZ/nOgPGhFXAL+MiKUR8fGct5xCpUzJCVQKx/1eTdzHAxcCp2Wx/ArIOw5USpzMj4jFEfE+4K+rth2W7f9ZKqUaRot3DZW2+Xj2/sOAjwId2eQ/q8b6eS1dThBWL56gUlfoP0s6PSL6gDNUqW//BHAm0FH1/nVV+3Vnkz+9DmwGFmbbtkbEj7PX3wZ+o+acp1L5I/xjSRuoFLx7xzhxVp/3kYjYExG9wOuavCk0fxIRmyPiV8DtOXGfBZwMrM/iPgtYNMqxNlOp0fOXWbG86nL2t8PwBDRz9yP+PqAfuEnS7wF1W3jPDs7MsgMwA4iIZySdBJwDrJL0IJVvBZ0RsVXSnwDVc0S/nv13sOr10PLQdV1baKx2WcADEfGx/Qh1vPMOMPKD14HMaz2RuG+NiHGn7IyIX0haAvwO8BngAiqT9UzkPKMdcyDrkjqLyjeoS6kkcJtm/A3C6kL2hMxrEfFt4FrenDvixey+wPkHcNhjJH0we30x8A812x8GTpP0riyG2aqUSj4YzwEnSHpL9on8rFHet1eVuUjynCLp2Ozew4U5cT8InC/pqCzut0vK/eaTdaM1RcR3qHSnVc/JcWH2nt+gMoNe3xg/1x4qlViHJthqiYjvAV+gMt+4TUP+BmH14n3AtZIGgb1U5thdAWyiMp3m+gM45tPA5yTdTGUuim9Ub4yI3uwG8u2S3pKtvgp45kB+gOyYWyXdlcX9T8BPR3nrjcDjkh7LuQ+xnkpp7HcBPwDurjnHk5KuAu7PksheKt+2nss5z3wq074OfRis/tbRL+mnwCze/FYxmluAb0r6JfC7wN9IaqbybWa8+zaWKJf7tmlJlTnG/za7wZ0MSb8FfCkiPjLOWw/2PD/MztNV5Hksbe5iMjOzXP4GYVZD0t1U5iSu9uWIuK+MeCZK0iPAW2pWfzIinigjHkufE4SZmeVyF5OZmeVygjAzs1xOEGZmlssJwszMcv1/kf88/F0cWbQAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df, x='sample_multiple_splits', y='loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df, x='max_depth', y='loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}