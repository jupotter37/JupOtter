{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "import torch\n",
    "from glob import glob\n",
    "import shap\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig, GatedAdditiveTreeEnsembleConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.classification import (\n",
    "    multiclass_accuracy,\n",
    "    multiclass_f1_score,\n",
    "    multiclass_precision,\n",
    "    multiclass_recall,\n",
    "    multiclass_specificity,\n",
    "    multiclass_cohen_kappa,\n",
    "    multiclass_auroc\n",
    ")\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from pytorch_tabular.utils import get_balanced_sampler\n",
    "from src.plot.radar import radar_factory\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path_data = \"D:/YandexDisk/Work/bbd/immunology/002_central_vs_yakutia/classification\"\n",
    "path_configs = \"D:/Work/bbs/notebooks/immunology/002_central_vs_yakutia/pt_configs\"\n",
    "data = pd.read_excel(f\"{path_data}/data.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path_data}/feats.xlsx\", index_col=0).index.values.tolist()\n",
    "\n",
    "test_split_id = 0\n",
    "\n",
    "val_n_splits = 4\n",
    "val_random_state = 1337\n",
    "val_fold_id = 0\n",
    "\n",
    "for fold_id in range(val_n_splits):\n",
    "    data[f\"Fold_{fold_id}\"] = data[f\"Split_{test_split_id}\"]\n",
    "\n",
    "stratify_cat_parts = {\n",
    "    'Central': data.index[(data['Region'] == 'Central') & (data[f\"Split_{test_split_id}\"] == 'trn_val')].values,\n",
    "    'Yakutia': data.index[(data['Region'] == 'Yakutia') & (data[f\"Split_{test_split_id}\"] == 'trn_val')].values,\n",
    "}\n",
    "for part, ids in stratify_cat_parts.items():\n",
    "    print(f\"{part}: {len(ids)}\")\n",
    "    con = data.loc[ids, 'Age'].values\n",
    "    ptp = np.ptp(con)\n",
    "    num_bins = 5\n",
    "    bins = np.linspace(np.min(con) - 0.1 * ptp, np.max(con) + 0.1 * ptp, num_bins + 1)\n",
    "    binned = np.digitize(con, bins) - 1\n",
    "    unique, counts = np.unique(binned, return_counts=True)\n",
    "    occ = dict(zip(unique, counts))\n",
    "    k_fold = RepeatedStratifiedKFold(\n",
    "        n_splits=val_n_splits,\n",
    "        n_repeats=1,\n",
    "        random_state=val_random_state\n",
    "    )\n",
    "    splits = k_fold.split(X=ids, y=binned, groups=binned)\n",
    "    \n",
    "    for fold_id, (ids_trn, ids_val) in enumerate(splits):\n",
    "        data.loc[ids[ids_trn], f\"Fold_{fold_id}\"] = \"trn\"\n",
    "        data.loc[ids[ids_val], f\"Fold_{fold_id}\"] = \"val\"\n",
    "        \n",
    "test = data.loc[data[f\"Split_{test_split_id}\"] == \"tst\", feats + ['Region']]\n",
    "train_validation = data.loc[data[f\"Split_{test_split_id}\"] == \"trn_val\", feats + ['Region'] + [f\"Fold_{i}\" for i in range(val_n_splits)]]\n",
    "train_only = data.loc[data[f\"Fold_{val_fold_id}\"] == \"trn\", feats + ['Region']]\n",
    "validation_only = data.loc[data[f\"Fold_{val_fold_id}\"] == \"val\", feats + ['Region']]\n",
    "cv_indexes = [\n",
    "    (\n",
    "        np.where(train_validation.index.isin(train_validation.index[train_validation[f\"Fold_{i}\"] == 'trn']))[0],\n",
    "        np.where(train_validation.index.isin(train_validation.index[train_validation[f\"Fold_{i}\"] == 'val']))[0],\n",
    "    )\n",
    "    for i in range(val_n_splits)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare balanced sampler"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sampler_balanced = get_balanced_sampler(train_only['Region'].values.ravel())",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models Search Spaces"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CategoryEmbeddingModel Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__layers\": [\"256-128-64\", \"512-256-128\", \"32-16\", \"32-32-16\", \"16-8\", \"32-16-8\", \"128-64\", \"128-128\", \"16-16\"],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/CategoryEmbeddingModelConfig.yaml\", CategoryEmbeddingModelConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GANDALF Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__gflu_stages\": [5, 10, 15, 20, 25, 30, 35],\n",
    "    \"model_config__gflu_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__gflu_feature_init_sparsity\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/GANDALFConfig.yaml\", GANDALFConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TabNetModel Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__n_d\": [8, 16, 24, 32, 40, 48],\n",
    "    \"model_config__n_a\": [8, 16, 24, 32, 40, 48],\n",
    "    \"model_config__n_steps\": [3, 5, 7],\n",
    "    \"model_config__gamma\": [1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n",
    "    \"model_config__n_independent\": [1, 2, 3, 4, 5],\n",
    "    \"model_config__n_shared\": [1, 2, 3, 4, 5],\n",
    "    \"model_config__mask_type\": [\"sparsemax\", \"entmax\"],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/TabNetModelConfig.yaml\", TabNetModelConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DANet Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__n_layers\": [4, 8, 16, 20, 32],\n",
    "    \"model_config__abstlay_dim_1\": [8, 16, 32, 64],\n",
    "    \"model_config__k\": [3, 4, 5, 6, 7],\n",
    "    \"model_config__dropout_rate\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/DANetConfig.yaml\", DANetConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FTTransformer Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__num_heads\": [2, 4, 8, 16, 32],\n",
    "    \"model_config__num_attn_blocks\": [4, 6, 8, 10, 12],\n",
    "    \"model_config__attn_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__add_norm_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__ff_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/FTTransformerConfig.yaml\", FTTransformerConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grid Search and Random Search"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "strategy = 'random_search' # 'grid_search'\n",
    "seed = 1337\n",
    "n_random_trials = 250\n",
    "is_cross_validation = True\n",
    "\n",
    "if grid_size < n_random_trials and strategy == 'random_search':\n",
    "    strategy = 'grid_search'\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "data_config['continuous_feature_transform'] = 'yeo-johnson'\n",
    "data_config['normalize_continuous_features'] = True\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = None\n",
    "trainer_config['load_best'] = False\n",
    "trainer_config['auto_lr_find'] = True\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "tuner = TabularModelTuner(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    suppress_lightning_logger=True,\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    if is_cross_validation:\n",
    "        result = tuner.tune(\n",
    "            train=train_validation,\n",
    "            validation=None,\n",
    "            search_space=search_space,\n",
    "            metric=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            strategy=strategy,\n",
    "            n_trials=n_random_trials,\n",
    "            cv=cv_indexes,\n",
    "            return_best_model=True,\n",
    "            verbose=False,\n",
    "            progress_bar=False,\n",
    "            random_state=seed,\n",
    "            train_sampler=sampler_balanced\n",
    "        )\n",
    "    else: \n",
    "        result = tuner.tune(\n",
    "            train=train_only,\n",
    "            validation=validation_only,\n",
    "            search_space=search_space,\n",
    "            metric=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            strategy=strategy,\n",
    "            n_trials=n_random_trials,\n",
    "            cv=None,\n",
    "            return_best_model=True,\n",
    "            verbose=False,\n",
    "            progress_bar=False,\n",
    "            random_state=seed,\n",
    "            train_sampler=sampler_balanced\n",
    "        )\n",
    "\n",
    "result.trials_df.to_excel(f\"{trainer_config['checkpoints_path']}/trials/{model_config['_model_name']}_{strategy}_{seed}_{optimizer_config['lr_scheduler']}.xlsx\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Sweep Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate models' configs from trials files"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_top_trials = 50\n",
    "\n",
    "target_models_types = [\n",
    "    'CategoryEmbeddingModel',\n",
    "    'GANDALF',\n",
    "    'TabNetModel',\n",
    "    'DANet',\n",
    "    # 'FTTransformer'\n",
    "]\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "\n",
    "common_params = {\n",
    "    \"task\": \"classification\",\n",
    "}\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\",\n",
    "    activation='ReLU',\n",
    "    dropout=0.1,\n",
    "    use_batch_norm=False,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__\n",
    "\n",
    "model_list = []\n",
    "for model_type in target_models_types:\n",
    "    trials_files = glob(f\"{trainer_config['checkpoints_path']}/trials/{model_type}*.xlsx\")\n",
    "    for trials_file in trials_files:\n",
    "        df_trials = pd.read_excel(trials_file, index_col=0)\n",
    "        df_trials.sort_values(['accuracy'], ascending=[True], inplace=True)\n",
    "        df_trials = df_trials.head(n_top_trials)\n",
    "        for _, row in df_trials.iterrows():\n",
    "            head_config_tmp = copy.deepcopy(head_config)\n",
    "            head_config_tmp['dropout'] = float(row['model_config.head_config__dropout'])\n",
    "            if model_type == 'CategoryEmbeddingModel':\n",
    "                model_config = read_parse_config(f\"{path_configs}/models/{model_type}Config.yaml\", CategoryEmbeddingModelConfig)\n",
    "                model_config['layers'] = row['model_config__layers']\n",
    "                model_config['learning_rate'] = row['model_config__learning_rate']\n",
    "                model_config['seed'] = row['model_config__seed']\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(CategoryEmbeddingModelConfig(**model_config))\n",
    "            elif model_type == 'GANDALF':\n",
    "                model_config = read_parse_config(f\"{path_configs}/models/{model_type}Config.yaml\", GANDALFConfig)\n",
    "                model_config['gflu_stages'] = int(row['model_config__gflu_stages'])\n",
    "                model_config['gflu_feature_init_sparsity'] = float(row['model_config__gflu_feature_init_sparsity'])\n",
    "                model_config['gflu_dropout'] = float(row['model_config__gflu_dropout'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(GANDALFConfig(**model_config))\n",
    "            elif model_type == 'TabNetModel':\n",
    "                model_config = read_parse_config(f\"{path_configs}/models/{model_type}Config.yaml\", TabNetModelConfig)\n",
    "                model_config['n_steps'] = row['model_config__n_steps']\n",
    "                model_config['n_shared'] = row['model_config__n_shared']\n",
    "                model_config['n_independent'] = row['model_config__n_independent']\n",
    "                model_config['n_d'] = row['model_config__n_d']\n",
    "                model_config['n_a'] = row['model_config__n_a']\n",
    "                model_config['mask_type'] = row['model_config__mask_type']\n",
    "                model_config['gamma'] = row['model_config__gamma']\n",
    "                model_config['learning_rate'] = row['model_config__learning_rate']\n",
    "                model_config['seed'] = row['model_config__seed']\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(TabNetModelConfig(**model_config))\n",
    "            elif model_type == 'FTTransformer':\n",
    "                model_config = read_parse_config(f\"{path_configs}/models/{model_type}Config.yaml\", FTTransformerConfig)\n",
    "                model_config['num_heads'] = int(row['model_config__num_heads'])\n",
    "                model_config['num_attn_blocks'] = int(row['model_config__num_attn_blocks'])\n",
    "                model_config['attn_dropout'] = float(row['model_config__attn_dropout'])\n",
    "                model_config['add_norm_dropout'] = float(row['model_config__add_norm_dropout'])\n",
    "                model_config['ff_dropout'] = float(row['model_config__ff_dropout'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(FTTransformerConfig(**model_config))\n",
    "            elif model_type == 'DANet':\n",
    "                model_config = read_parse_config(f\"{path_configs}/models/{model_type}Config.yaml\", DANetConfig)\n",
    "                model_config['n_layers'] = int(row['model_config__n_layers'])\n",
    "                model_config['abstlay_dim_1'] = int(row['model_config__abstlay_dim_1'])\n",
    "                model_config['k'] = int(row['model_config__k'])\n",
    "                model_config['dropout_rate'] = float(row['model_config__dropout_rate'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(DANetConfig(**model_config))\n",
    "print(len(model_list))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Perform model sweep"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "for seed in [1337, 55763, 40279, 8751, 234461]:\n",
    "\n",
    "    trainer_config['seed'] = seed\n",
    "    trainer_config['checkpoints'] = 'valid_loss'\n",
    "    trainer_config['load_best'] = True\n",
    "    trainer_config['auto_lr_find'] = True\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sweep_df, best_model = model_sweep_custom(\n",
    "            task=\"classification\",\n",
    "            # train=train_validation,\n",
    "            train=train_only,\n",
    "            # validation=None,\n",
    "            validation=validation_only,\n",
    "            test=test,\n",
    "            data_config=data_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config,\n",
    "            model_list=model_list,\n",
    "            common_model_args=common_params,\n",
    "            metrics=[\n",
    "                \"accuracy\",\n",
    "                \"f1_score\",\n",
    "                \"precision\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"cohen_kappa\",\n",
    "                \"auroc\"\n",
    "            ],\n",
    "            metrics_params=[\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "                {'task': 'multiclass', 'num_classes': 2},\n",
    "                {'task': 'multiclass', 'num_classes': 2, 'average': 'macro'},\n",
    "            ],\n",
    "            metrics_prob_input=[True, True, True, True, True, True, True],\n",
    "            rank_metric=(\"accuracy\", \"higher_is_better\"),\n",
    "            return_best_model=True,\n",
    "            seed=seed,\n",
    "            progress_bar=False,\n",
    "            verbose=False,\n",
    "            suppress_lightning_logger=True,\n",
    "            train_sampler=sampler_balanced\n",
    "        )\n",
    "    fn_suffix = f\"{seed}_{best_model.config['lr_scheduler']}_{best_model.config['continuous_feature_transform']}\"\n",
    "    sweep_df.style.background_gradient(\n",
    "        subset=[\n",
    "            \"train_loss\",\n",
    "            \"validation_loss\",\n",
    "            \"test_loss\",\n",
    "            \"time_taken\",\n",
    "            \"time_taken_per_epoch\"\n",
    "        ], cmap=\"RdYlGn_r\"\n",
    "    ).to_excel(f\"{trainer_config['checkpoints_path']}/sweep_{fn_suffix}.xlsx\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save best models"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "seed = 234461\n",
    "models_ids = [196, 159]\n",
    "explain_method = \"GradientShap\"\n",
    "explain_baselines = \"b|1000\"\n",
    "\n",
    "class_names = ['Central', 'Yakutia']\n",
    "\n",
    "sweep_suffix = f\"{seed}_{optimizer_config['lr_scheduler']}_{data_config['continuous_feature_transform']}\"\n",
    "path_models = f\"{trainer_config['checkpoints_path']}/candidates/{sweep_suffix}\"\n",
    "pathlib.Path(path_models).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sweep_df = pd.read_excel(f\"{trainer_config['checkpoints_path']}/sweep_{sweep_suffix}.xlsx\", index_col=0)\n",
    "\n",
    "for model_id in models_ids:\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=ast.literal_eval(sweep_df.at[model_id, 'params']),\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=True,\n",
    "        suppress_lightning_logger=False\n",
    "    )\n",
    "    datamodule = tabular_model.prepare_dataloader(\n",
    "        train=train_only,\n",
    "        validation=validation_only,\n",
    "        seed=seed,\n",
    "    )\n",
    "    model = tabular_model.prepare_model(\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model._prepare_for_training(\n",
    "        model,\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model.load_weights(sweep_df.at[model_id, 'checkpoint'])\n",
    "    tabular_model.evaluate(test, verbose=False)\n",
    "    tabular_model.save_model(f\"{path_models}/{model_id}\")\n",
    "    \n",
    "    loaded_model = TabularModel.load_model(f\"{path_models}/{model_id}\")\n",
    "    \n",
    "    df = data.loc[:, ['Age', 'SImAge', 'Sex', 'Region']]\n",
    "    df.loc[train_only.index, 'Group'] = 'Train'\n",
    "    df.loc[validation_only.index, 'Group'] = 'Validation'\n",
    "    df.loc[test.index, 'Group'] = 'Test'\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            loaded_model.predict(data),\n",
    "            loaded_model.predict(data, ret_logits=True).loc[:, ['logits_0', 'logits_1']]\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "    df.rename(columns={'prediction': 'Prediction', 'logits_0': 'Central_logits', 'logits_1': 'Yakutia_logits'},\n",
    "              inplace=True)\n",
    "    df['Region ID'] = df['Region']\n",
    "    df['Region ID'].replace({'Central': 0, 'Yakutia': 1}, inplace=True)\n",
    "    df['Prediction ID'] = df['Prediction']\n",
    "    df['Prediction ID'].replace({'Central': 0, 'Yakutia': 1}, inplace=True)\n",
    "    df.to_excel(f\"{path_models}/{model_id}/df.xlsx\")\n",
    "    \n",
    "    colors_groups = {\n",
    "        'Train': 'chartreuse',\n",
    "        'Validation': 'dodgerblue',\n",
    "        'Test': 'crimson',\n",
    "    }\n",
    "    \n",
    "    metrics_w_avg = [\n",
    "        \"accuracy\",\n",
    "        \"f1_score\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"specificity\",\n",
    "        \"auroc\"\n",
    "    ]\n",
    "    metrics_wo_avg = [\n",
    "        \"cohen_kappa\"\n",
    "    ]\n",
    "    metrics_names = {\n",
    "        \"accuracy\": \"Accuracy\",\n",
    "        \"f1_score\": \"F-1 Score\",\n",
    "        \"precision\": \"Precision\",\n",
    "        \"recall\": \"Recall\",\n",
    "        \"specificity\": \"Specificity\",\n",
    "        \"auroc\": \"AUROC\",\n",
    "        \"cohen_kappa\": \"Cohen Kappa\"\n",
    "    }\n",
    "    \n",
    "    df_metrics = pd.DataFrame(\n",
    "        index=[f\"{m}_macro\" for m in metrics_w_avg] +\n",
    "              [f\"{m}_weighted\" for m in metrics_w_avg] +\n",
    "              metrics_wo_avg,\n",
    "        columns=list(colors_groups.keys()),\n",
    "        data=np.zeros((len(metrics_w_avg) * 2 + 1, len(colors_groups))),\n",
    "    )\n",
    "    for group in colors_groups.keys():\n",
    "        pred = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction ID'].values)\n",
    "        real = torch.from_numpy(df.loc[df['Group'] == group, 'Region ID'].values)\n",
    "        probs = torch.from_numpy(df.loc[df['Group'] == group, ['Central_probability', 'Yakutia_probability']].values)\n",
    "        for avg_type in ['macro', 'weighted']:\n",
    "            df_metrics.at[f\"accuracy_{avg_type}\", group] = multiclass_accuracy(preds=pred, target=real, num_classes=2, average=avg_type).numpy()\n",
    "            df_metrics.at[f\"f1_score_{avg_type}\", group] = multiclass_f1_score(preds=pred, target=real, num_classes=2, average=avg_type).numpy()\n",
    "            df_metrics.at[f\"precision_{avg_type}\", group] = multiclass_precision(preds=pred, target=real, num_classes=2, average=avg_type).numpy()\n",
    "            df_metrics.at[f\"recall_{avg_type}\", group] = multiclass_recall(preds=pred, target=real, num_classes=2, average=avg_type).numpy()\n",
    "            df_metrics.at[f\"specificity_{avg_type}\", group] = multiclass_specificity(preds=pred, target=real, num_classes=2, average=avg_type).numpy()\n",
    "            df_metrics.at[f\"auroc_{avg_type}\", group] = multiclass_auroc(preds=probs, target=real, num_classes=2, average=avg_type).numpy()\n",
    "        df_metrics.at[\"cohen_kappa\", group] = multiclass_cohen_kappa(preds=pred, target=real, num_classes=2).numpy()\n",
    "        \n",
    "        conf_mtx = confusion_matrix(real, pred)\n",
    "        cm_sum = np.sum(conf_mtx, axis=1, keepdims=True)\n",
    "        cm_perc = conf_mtx / cm_sum.astype(float) * 100\n",
    "        annot = np.empty_like(conf_mtx).astype(str)\n",
    "        nrows, ncols = conf_mtx.shape\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                c = conf_mtx[i, j]\n",
    "                p = cm_perc[i, j]\n",
    "                if i == j:\n",
    "                    s = cm_sum[i]\n",
    "                    annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "                elif c == 0:\n",
    "                    annot[i, j] = ''\n",
    "                else:\n",
    "                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "        conf_mtx = pd.DataFrame(conf_mtx, index=class_names, columns=class_names)\n",
    "        conf_mtx.index.name = 'Actual'\n",
    "        conf_mtx.columns.name = 'Predicted'\n",
    "        fig, ax = plt.subplots(figsize=(1.5*len(class_names), 0.8*len(class_names)))\n",
    "        heatmap = sns.heatmap(conf_mtx, annot=annot, fmt='', ax=ax)\n",
    "        heatmap.set_aspect('equal', adjustable='box')\n",
    "        fig.savefig(f\"{path_models}/{model_id}/confusion_matrix_{group}.png\", bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(f\"{path_models}/{model_id}/confusion_matrix_{group}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    df_metrics.to_excel(f\"{path_models}/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "    \n",
    "    for avg_type in ['macro', 'weighted']:\n",
    "        n_categories = len(metrics_w_avg) + len(metrics_wo_avg)\n",
    "        theta = radar_factory(n_categories, frame='polygon')\n",
    "        \n",
    "        case_data = df_metrics.loc[[f\"{m}_{avg_type}\" for m in metrics_w_avg] + metrics_wo_avg, list(colors_groups.keys())].T.values\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(projection='radar'))\n",
    "        ax.set_rgrids(list(np.linspace(0, 1, 21)))\n",
    "        for d, group in zip(case_data, colors_groups):\n",
    "            ax.plot(theta, d, color=colors_groups[group])\n",
    "            ax.fill(theta, d, facecolor=colors_groups[group], alpha=0.25, label='_nolegend_')\n",
    "        ax.set_varlabels([metrics_names[m_name] for m_name in metrics_w_avg + metrics_wo_avg])\n",
    "        labels = (list(colors_groups.keys()))\n",
    "        legend = ax.legend(labels, loc=(0.9, .95), labelspacing=0.1, fontsize='small')\n",
    "        fig.savefig(f\"{path_models}/{model_id}/metrics_{avg_type}.png\", bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(f\"{path_models}/{model_id}/metrics_{avg_type}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    try:\n",
    "        explanation = loaded_model.explain(train_only, method=explain_method, baselines=explain_baselines)\n",
    "        \n",
    "        sns.set_theme(style='whitegrid')\n",
    "        fig = shap.summary_plot(\n",
    "            shap_values=explanation.loc[:, feats].values,\n",
    "            features=train_only.loc[:, feats].values,\n",
    "            feature_names=feats,\n",
    "            max_display=len(feats),\n",
    "            plot_type=\"violin\",\n",
    "            show=False,\n",
    "        )\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_logits_beeswarm.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_logits_beeswarm.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        sns.set_theme(style='whitegrid')\n",
    "        fig = shap.summary_plot(\n",
    "            shap_values=explanation.loc[:, feats].values,\n",
    "            features=train_only.loc[:, feats].values,\n",
    "            feature_names=feats,\n",
    "            max_display=len(feats),\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "        )\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_logits_bar.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_models}/{model_id}/explain_logits_bar.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    except NotImplementedError:\n",
    "        pass\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Best model processing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load best model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "\n",
    "seed = 1337\n",
    "model_id = 197\n",
    "\n",
    "class_names = ['Central', 'Yakutia']\n",
    "\n",
    "sweep_suffix = f\"{seed}_{optimizer_config['lr_scheduler']}_{data_config['continuous_feature_transform']}\"\n",
    "path_model = f\"{trainer_config['checkpoints_path']}/candidates/{sweep_suffix}/{model_id}\"\n",
    "\n",
    "loaded_model = TabularModel.load_model(f\"{path_model}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Best model probabilistic explanation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_func(X):\n",
    "    df_tmp = pd.DataFrame(columns=feats, data=X)\n",
    "    return loaded_model.predict(df_tmp).loc[:, ['Central_probability', 'Yakutia_probability']].values\n",
    "\n",
    "X = train_only.loc[:, feats].values\n",
    "explainer = shap.SamplingExplainer(predict_func, X)\n",
    "expected_value = explainer.expected_value\n",
    "\n",
    "shap_values = explainer.shap_values(X)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with (pd.ExcelWriter(f\"{path_model}/shap_values.xlsx\", engine='xlsxwriter') as writer):\n",
    "    for class_id, class_name in enumerate(class_names):\n",
    "        df_shap_values = pd.DataFrame(data=shap_values[:, :, class_id], columns=feats, index=train_only.index.values)\n",
    "        df_shap_values.to_excel(writer, sheet_name=class_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for class_id, class_name in enumerate(class_names):\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig = shap.summary_plot(\n",
    "        shap_values=shap_values[:, :, class_id],\n",
    "        features=X,\n",
    "        feature_names=feats,\n",
    "        max_display=len(feats),\n",
    "        plot_type=\"violin\",\n",
    "        show=False,\n",
    "    )\n",
    "    plt.gca().set_xlim([-0.4, 0.4])\n",
    "    sns.despine(left=False, right=False, bottom=False, top=False)\n",
    "    plt.gcf().axes[1].tick_params(labelsize=20)\n",
    "    plt.gcf().axes[1].set_ylabel(\"Feature value\", fontsize=22)\n",
    "    plt.gca().tick_params(labelsize=20)\n",
    "    plt.gca().set_xlabel(\"SHAP value (impact on model output)\", fontsize=22)\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_beeswarm.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_beeswarm.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig = shap.summary_plot(\n",
    "        shap_values=shap_values[:, :, class_id],\n",
    "        features=X,\n",
    "        feature_names=feats,\n",
    "        max_display=len(feats),\n",
    "        plot_type=\"bar\",\n",
    "        show=False,\n",
    "    )\n",
    "    sns.despine(left=False, right=False, bottom=False, top=False)\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_bar.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_bar.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values[:, :, class_id],\n",
    "        base_values=np.array([expected_value] * X.shape[0]),\n",
    "        data=X,\n",
    "        feature_names=feats\n",
    "    )\n",
    "    shap.plots.heatmap(\n",
    "        explanation,\n",
    "        show=False,\n",
    "        max_display=len(feats),\n",
    "        instance_order=explanation.sum(1)\n",
    "    )\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_heatmap.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_model}/explain_{class_name}_probs_heatmap.pdf\", bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Additional plots for best model"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Radar chart"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors_groups = {\n",
    "    'Train': 'chartreuse',\n",
    "    'Validation': 'dodgerblue',\n",
    "    'Test': 'crimson',\n",
    "}\n",
    "\n",
    "metrics_w_avg = [\n",
    "    \"accuracy\",\n",
    "    \"f1_score\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"specificity\",\n",
    "    \"auroc\"\n",
    "]\n",
    "metrics_wo_avg = [\n",
    "    \"cohen_kappa\"\n",
    "]\n",
    "metrics_names = {\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "    \"f1_score\": \"F-1 Score\",\n",
    "    \"precision\": \"Precision\",\n",
    "    \"recall\": \"Recall\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "    \"auroc\": \"AUROC\",\n",
    "    \"cohen_kappa\": \"Cohen Kappa\"\n",
    "}\n",
    "\n",
    "df_metrics = pd.read_excel(f\"{path_model}/metrics.xlsx\", index_col=0)\n",
    "\n",
    "for avg_type in ['macro', 'weighted']:\n",
    "    n_categories = len(metrics_w_avg) + len(metrics_wo_avg)\n",
    "    theta = radar_factory(n_categories, frame='polygon')\n",
    "    \n",
    "    case_data = df_metrics.loc[[f\"{m}_{avg_type}\" for m in metrics_w_avg] + metrics_wo_avg, ['Test']].values\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5), subplot_kw=dict(projection='radar'))\n",
    "    ax.set_rgrids(list(np.linspace(0, 1, 101)))\n",
    "    ax.plot(theta, case_data, color=colors_groups['Test'])\n",
    "    ax.fill(theta, case_data, facecolor=colors_groups['Test'], alpha=0.25, label='_nolegend_')\n",
    "    ax.set_varlabels([metrics_names[m_name] for m_name in metrics_w_avg + metrics_wo_avg])\n",
    "    fig.savefig(f\"{path_model}/metrics_test_only_{avg_type}.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path_model}/metrics_test_only_{avg_type}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple TabularModel training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = True\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=f\"{path_configs}/DataConfig.yaml\",\n",
    "    model_config=f\"{path_configs}/models/CategoryEmbeddingModelConfig.yaml\",\n",
    "    optimizer_config=f\"{path_configs}/OptimizerConfig.yaml\",\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=True,\n",
    "    suppress_lightning_logger=False\n",
    ")\n",
    "\n",
    "tabular_model.fit(\n",
    "    train=train_only,\n",
    "    validation=validation_only,\n",
    "    # target_transform=[np.log, np.exp],\n",
    "    # callbacks=[DeviceStatsMonitor()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Play with trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.predict(test, progress_bar='rich')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.evaluate(test, verbose=True, ckpt_path=\"best\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.config['checkpoints_path']"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(tabular_model.trainer.checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.save_model(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.save_config(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model = TabularModel.load_model(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
