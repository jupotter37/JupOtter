{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrstract\n",
    "Artitifial Intelligenece (AI), is the intelligence demonstrated by machines opposed to that of animals including, humans. This is ability of a computer systems or robot/electronics device to do tasks that are ussually done by humans because they require human/animal intelligence and discrement, such tasks includes natural language processing, decision-making, visual perception, drug discovery, etc. \n",
    "\n",
    "## Machine Learning\n",
    "Machine Learning (ML) is an application of AI that enables systems to learn and advance based on experience without being explicitly programmed. ML focuses on development of computer systems that can learn from data given and draw experience based on data patterns.\n",
    "\n",
    "Machine Learning is application of Inferential Statistics, unlike normal Statistical models which are designed for inference about the relationships between variables, machine learning models ML is designed to make most accurate predictions possible this is possible thanks to imporved Computations and Amount of Data produced.\n",
    "\n",
    ">  **ML is to Statistics as Engineering to Physics**\n",
    "\n",
    "### Types of Machine Learning\n",
    "\n",
    "#### 1. Supervised Learning\n",
    "This is the type of Machine Learning that use labeled examples to train machine learning to train Machine Learning models that can be used classify data or predict. In this type of Machine Learning the possible outcomes are already known and that the data used to train the model is already lebled.\n",
    "\n",
    "#### 2. Unsupervised Learning\n",
    "Unlike Supervised Learning Machine Learning tasks, Unsupervised Learning finds patterns where we don't.\n",
    "Advances of this type of ML is very important to future of AI as it moves AI closer to the Artitifial general Intelligence, such advancement is Generative Adversarial Networks.\n",
    "\n",
    "#### 3. Semi-supervised Learning\n",
    "This is somethime between the above two types, this is used when AI problem required balance of Supervised Learning and unsupervised learning. This invloves creating a machine learning model from small amount of labeled examples and then uses it with unlabeled examples to predict the outputs, linking the outcome and then retrain the model.\n",
    "\n",
    "#### 4. Reinforcement Learning\n",
    "This is the type of dynamic programming that is used to train a machine learning models using systems of reward and punishment. The reiforcement agent learns by intertacting with environment, it receives reward by performing correctly and penalties when doing a task incorrectly. The reiforcement agent learns without having to be directly taught by a human.\n",
    "The agent learns to maximize the reward and minimize the penalty.\n",
    "\n",
    "Example of such agent will an AI agent that play a computer game or an autonomous robot or vehicle.\n",
    "\n",
    "## Deep Learning\n",
    "Deep Leaning is the Specialize form of machine learning. It imitates the working of human brain in processing data and creating partterns. Deep learning uses Networks of Artifical neural networks for machine learning process.\n",
    "\n",
    "This Neural networks are built to resemble the human Neurons, in Deep Learning these Neural networks are designed to process data in non linear way.\n",
    "\n",
    "A standard Machine Learning workflow starts with manually extracting selected features (Consider an Image), normally we will require to get color distribution, pixels invomations, e.t.c. A deep learning workflow differs from this as relevant features are extracted automatically.\n",
    "\n",
    "Deep learning Models are sometimes considered **Universal Functions Estimators** and therefore they outperfoms most Machine Learning algorithms\n",
    "\n",
    "In this Notebook will only limited to convolution neural networks (Focusing on Variant of called resudal networks), also will not go beyond Computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Inroduction\n",
    "\n",
    "A convolutional Neural networks are types of Deep Neural networks used in computer visions applications like (Image classifications, Object Detections).\n",
    "\n",
    "Depending on type of use cases and other factors such as accuracy, computions there are varians of CNN architectures.\n",
    "\n",
    "In this book we will implement one of theses architectures called [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "## ResNet\n",
    "RestNet has Multiple configuration which specify the number of layers and sizes of those layers. Each layer is made out of blocks, made of convolutional layers, bacth normaliztion layers and residual connections (also called skip connections or shortcut connections).\n",
    "\n",
    "ResNet uses the term layer to refer to both a set of blocks e.g \"layer 1 has two blocks\", and also the total number of layers within the entire ResNet, e.g \"ResNet18 has 18 layers\".\n",
    "\n",
    "A residual connection is simply a direct connection between the input of a block and the output of block.\n",
    "\n",
    "It is possible to add layers in residual connection.\n",
    "\n",
    "Residual Network architecture\n",
    "\n",
    "![resnet](https://d2l.ai/_images/resnet-block.svg)\n",
    "\n",
    "The different configurations of ResNet\n",
    "![resnet](https://miro.medium.com/max/1400/1*I2557MCaFdNUm4q9TfvOpw.png)\n",
    "\n",
    "From the table above, we can see that for ResNet18 and ResNet34 that the first block contains two 3x3 convolutional layers with 64 filters, and that ResNet18 has two of these blocks in the first layer, whilst Resnet34 has three. ResNet50, ResNet101 and ResNet152 blocks have a different structure than those in ResNet18 and ResNet34, and these blocks are called bottleneck blocks. Bottleneck blocks reduce the number of number of channels within the input before expanding them back out again. Below shows a standard BasicBlock (left) - used by ResNet18 and ResNet34 - and the Bottleneck block used by ResNet50, ResNet101 and ResNet152.\n",
    "\n",
    "### Why ResNet Works\n",
    "Normally training deep learning is very difficult due to the gradient descent either exploding or vanishing as it get backprogated through many layers, the residual connection allow the model to skip layers, by setting all their weighs to zero and only rely on the residual connection.\n",
    "\n",
    "In theory, if your ResNet152 model can actually learn the desired function between input and output by only using the first 52 layers the remaining 100 layers should set their weights to zero and the output of the 52nd layer will simply pass through the residual connections unhindered. This also allows for the gradient signal to also backpropagate through those 100 layers unhindered too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "In this document we will show how to prepare image datasets for image classification, training, validation, and monitoring the model training\n",
    "\n",
    "## Libraries and dependencies\n",
    "\n",
    "We will be using PyTorch as our primary Deep learning library to due it is friendly Syntax and ecosystem integration.\n",
    "\n",
    "We will use Sklearn to capture model metrics like ConfusionMatrix, and matplotlib for plotting training results\n",
    "\n",
    "To help with training and evaluting neural networks in PyTorch flexibly and transparently we will use PyTorch Ignite.\n",
    "\n",
    "We will use TensorBoard, and WandB(Weights and Bias) to monitor training process. TensorBoard provides the visualization and tooling needed for machine learning experimentation, for tracking and visualizing metrics such as loss and accuracy, Visualizing the model graph.\n",
    "\n",
    "WandB is the alternative to TensorBoard that can help you to track metrics similar to TensorBoard with addition to system metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.handlers import FastaiLRFinder\n",
    "from ignite.contrib.handlers.wandb_logger import *\n",
    "from ignite.handlers import ModelCheckpoint, global_step_from_engine\n",
    "from ignite.contrib.handlers import TensorboardLogger\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Accuracy, Loss, Precision, Recall, ConfusionMatrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ResNet import *\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducability\n",
    "\n",
    "A random seed is used to ensure that results are reproducible. In other words, using this parameter makes sure that anyone who re-runs your code will get the exact same outputs. Reproducibility is an extremely important concept in data science and other fields.\n",
    "\n",
    "Deterministic operations are often slower than nondeterministic operations, so single-run performance may decrease for your model. However, determinism may save time in development by facilitating experimentation, debugging, and regression testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_MODE=offline\n",
      "env: WANDB_SILENT=true\n"
     ]
    }
   ],
   "source": [
    "# Setting up random seed to ensure repoducibility\n",
    "SEED = 500\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "%env WANDB_MODE=offline\n",
    "%env WANDB_SILENT=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE THESE WITH YOUR OWN KAGGLE USERNAME AND KEY\n",
    "\"\"\"\n",
    "This step is only important if you want to download data from Kaggle.\n",
    "\"\"\"\n",
    "os.environ['KAGGLE_USERNAME'] = \"januarymagori\"\n",
    "os.environ['KAGGLE_KEY'] = \"bc6ce7bdd037b4b7edf3c329d842f4f3\"\n",
    "\n",
    "# !kaggle datasets download smaranjitghose/corn-or-maize-leaf-disease-dataset --unzip\n",
    "# !mkdir datasets/maize-leaf-disease-dataset/\n",
    "# !cp -R data/ datasets/maize-leaf-disease-dataset/images/\n",
    "# !rm -rf data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset organization\n",
    "We suggest all the datasets are arranged in the following form\n",
    "\n",
    "```---> datasets/\n",
    "        ---> application-name/\n",
    "                ---> images/\n",
    "                    ---> class1/\n",
    "                    ---> class2/\n",
    "                    ---> classN/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'datasets/'\n",
    "application_name = 'mango-Quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This is very important part in any machine learning problem since data is main fuel to Machine Learning models, therefore data should be prepared in best way possible.\n",
    "\n",
    "## Train-Tes Split\n",
    "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.\n",
    "\n",
    "This requires that the original dataset to be a suitable representation of the problem domain.\n",
    "\n",
    "> This procedure is not advised when the dataset is small, the reason is it will cause the model to have few examples to learn from\n",
    "\n",
    "For Insuffienct data other methods can be used like \n",
    "* K Cross Validation\n",
    "* Leave One Out cross validation\n",
    "* Stratified\n",
    "* Repeated\n",
    "* Nested\n",
    "\n",
    "Those methods are out scope in this implementation and will not be discussed\n",
    "\n",
    "This Example we will split train-test into 80% and 20% ratio (For experimenting we can try different ratios)\n",
    "\n",
    "## Data Imblance\n",
    "Imbdalanced data refers to those types of datasets where the target class has uneven distribution of observations.\n",
    "\n",
    "Due to challenges in getting data from the data for training the model, and may lead to bias in classifier.\n",
    "\n",
    "To explain data Imbalance we will use Confusion Matrix, to show how the model classifies the target classes and evaluate the model accuracy.\n",
    "\n",
    "### Dealing with Imbdalanced datasets\n",
    "1. Model Metrics\n",
    "The Accuracy\n",
    "The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of predictions.\n",
    "This is good for balanced datasets but not for imbalanced datasets.\n",
    "\n",
    "Precision and Recall\n",
    "Precision is the measure of how accurate the classifier’s prediction of a specific class and recall is the measure of the classifier’s ability to identify a class.\n",
    "\n",
    "> We don't expect much impact of balanced datasets but we will store our mode based on F1 score and Accuracy\n",
    "\n",
    "2. Resampling and Undersampling\n",
    "This technique is used to upsample or downsample the minority or majority class. When we are using an imbalanced dataset, we can oversample the minority class using replacement. This technique is called oversampling. Similarly, we can randomly delete rows from the majority class to match them with the minority class which is called undersampling.\n",
    "\n",
    "3. SMOTE\n",
    "Synthetic Minority Oversampling Technique or SMOTE is another technique to oversample the minority class. Simply adding duplicate records of minority class often don’t add any new information to the model.\n",
    "\n",
    "4. Threshold moving\n",
    "In the case of our classifiers, many times classifiers actually predict the probability of class membership. We assign those prediction’s probabilities to a certain class based on a threshold which is usually 0.5, i.e. if the probabilities < 0.5 it belongs to a certain class, and if not it belongs to the other class.\n",
    "\n",
    "For imbalanced class problems, this default threshold may not work properly. We need to change the threshold to the optimum value so that it can efficiently separate two classes. We can use ROC Curves and Precision-Recall Curves to find the optimal threshold for the classifier. We can also use a grid search method or search within a set of values to identify the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spliting train and test data in 80:20 ratio\n",
    "\n",
    "From our standard dataset organization, we have the following directory structure:\n",
    "images/ folder this should contain all our images separated by class names\n",
    "\n",
    "train/ folder this should contain all our training images\n",
    "test/ folder this should contain all our testing images\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "data_dir = os.path.join(ROOT, application_name)\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir) \n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "    \n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(test_dir)\n",
    "\n",
    "classes = os.listdir(images_dir)\n",
    "\n",
    "for c in classes:\n",
    "    \n",
    "    class_dir = os.path.join(images_dir, c)\n",
    "    \n",
    "    images = os.listdir(class_dir)\n",
    "       \n",
    "    n_train = int(len(images) * TRAIN_RATIO)\n",
    "    \n",
    "    train_images = images[:n_train]\n",
    "    test_images = images[n_train:]\n",
    "    \n",
    "    os.makedirs(os.path.join(train_dir, c), exist_ok = True)\n",
    "    os.makedirs(os.path.join(test_dir, c), exist_ok = True)\n",
    "    \n",
    "    for image in train_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(train_dir, c, image)\n",
    "        try:\n",
    "            shutil.copyfile(image_src, image_dst)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for image in test_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(test_dir, c, image) \n",
    "        try:\n",
    "            shutil.copyfile(image_src, image_dst)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "### Datasets and Dataloaders\n",
    "\n",
    "PyTorch provide are very easy way of processing data samples and maintaining them.\n",
    "\n",
    "It is good practice to decouple our datasets code from our model training code for modularity and maintainability.\n",
    "\n",
    "Pytorch Provide two primitives: <pre><code>torch.utils.data.DataLoader</code></pre> <pre><code>torch.utils.data.Dataset</code></pre> \n",
    "that allows loading pre-loaded datases or custom datasets\n",
    "\n",
    "### Image Normalization\n",
    "Image Normalization is a the process of changing the range of pixel intensity values, the reason we require this step is because during the training process we are goin to multiply weights and adding to (biases) in order to cause activation that we then propagate with gradient to train the model. This process should be repeated for each feature so our gradient remains in control.\n",
    "\n",
    "### Transformation\n",
    "In order to improve our model accuracy we need to make some transforms to our datasets, such cropping, rotation, scalling and also we need to transform the image into **Tensor** that can be used as input to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading custom data from the train and test folders,\n",
    "\n",
    "Also we calculate means and standard deviation that we'll use for Normalization\n",
    "\"\"\"\n",
    "train_data = datasets.ImageFolder(\n",
    "    root = train_dir,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "    \n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')\n",
    "\n",
    "# Calculated means: tensor([0.2399, 0.2776, 0.2590])\n",
    "# Calculated stds: tensor([0.0703, 0.0997, 0.0848])\n",
    "\n",
    "# Calculated means: tensor([0.7322, 0.6320, 0.5282])\n",
    "# Calculated stds: tensor([0.2886, 0.3069, 0.3414])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we need to apply different transformation to help our model generalize the data, and\n",
    "In this step we resize our dataset into a fixed size (32 x 32) we choose this to increase the training process\n",
    "We apply random horizontal flipping, rotation and crop\n",
    "\n",
    "After transformation we apply it loaded image\n",
    "\"\"\"\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize((32, 32)),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(32, padding = 10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize((32, 32)),\n",
    "                           transforms.CenterCrop(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])\n",
    "\n",
    "train_data = datasets.ImageFolder(root = train_dir, \n",
    "                                  transform = train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root = test_dir, \n",
    "                                 transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.1\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])\n",
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will load 32 images at a time to train our model and we will use the same during validation\n",
    "num_workers = 0 means that we will use only one core to load the data, PyTorch provide parallel training in case we use multi-core GPU/CPU\n",
    "\"\"\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                num_workers=0,\n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "num_workers=0,\n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalize Images\n",
    "\"\"\"\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize = True):\n",
    "    \"\"\"\n",
    "    It is good practice to visualize dataset before strating working with It to understand the data\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1 )\n",
    "        \n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        # plt.hist(image.cpu().numpy().ravel(), bins = 30, density = True)\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 8\n",
    "images, labels = zip(*[(image, label) for image, label in \n",
    "                           [train_data[i] for i in range(N_IMAGES)]])\n",
    "classes = test_data.classes\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_label(label):\n",
    "    label = label.split('.')[-1]\n",
    "    label = label.replace('_', ' ')\n",
    "    label = label.title()\n",
    "    label = label.replace(' ', '')\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.classes = [format_label(c) for c in test_data.classes]\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading ResNet variant model, we will strat with ResNet18, depending on the permance we can update the model with deeper version\n",
    "\"\"\"\n",
    "\n",
    "model = resnet18(num_classes=len(classes))\n",
    "\n",
    "# model = resnet101(num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Number of parameters in the model\n",
    "\"\"\"\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameters tuning\n",
    "Deep learning neural networks are trained using the stochastic gradient descent algorithm.\n",
    "Stochastic gradient descent is an optimization algorithm that estimates the error gradient for the current state of the model using examples from the training dataset, \n",
    "then updates the weights of the model using the back-propagation of errors algorithm,\n",
    "\n",
    "Learning Rate\n",
    "The amount that the weights are updated during training is referred to as the step size or the “learning rate.”\n",
    "Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, \n",
    "often in the range between 0.0 and 1.0.\n",
    "\n",
    "The learning rate controls how quickly the model is adapted to the problem. Smaller learning rates require more training epochs \n",
    "given the smaller changes made to the weights each update, \n",
    "whereas larger learning rates result in rapid changes and require fewer training epochs.\n",
    "\n",
    "The challenge of training deep learning neural networks involves carefully selecting the learning rate. \n",
    "It may be the most important hyperparameter for the model.\n",
    "\n",
    "Instead of manually tuning the learning rate, we can use the learning rate scheduler to automatically tune the learning rate.\n",
    "In our case we use FastaiLRFinder to find the best learning rate for our model. \n",
    "FastaiLRFinder is based on this paper Cyclical Learning Rates for Training Neural Networks - https://arxiv.org/abs/1506.01186\n",
    "\"\"\"\n",
    "\n",
    "START_LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-2\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=START_LR, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = optim.SGD(model.parameters(), lr=START_LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "\n",
    "lr_finder = FastaiLRFinder()\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer}\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    model, optimizer, criterion, device=device\n",
    ")\n",
    "ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
    "with lr_finder.attach(trainer, to_save=to_save, end_lr=100, num_iter=100) as trainer_with_lr_finder:\n",
    "    trainer_with_lr_finder.run(train_iterator)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "ax = lr_finder.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.apply_suggested_lr(optimizer)\n",
    "print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training Process, we will use egnite to assist training and reporting the learning process.\n",
    "\n",
    "Validation Metrics\n",
    "The F1-score combines the precision and recall of a classifier into a single metric by taking their harmonic mean. \n",
    "It is primarily used to compare the performance of two classifiers. Suppose that classifier A has a higher recall, and classifier B has higher precision.\n",
    "\n",
    "Mathematically, the F1-score is defined as: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "Accuracy\n",
    "Accuracy is defined as the number of classifications a model correctly predicts divided by the total number of predictions made. \n",
    "It's a way of assessing the performance of a model, but certainly not the only way\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "desc = \"ITERATION - loss: {:.2f}\"\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(\n",
    "    initial=0, leave=False, total=len(train_iterator), \n",
    "    desc=desc.format(0)\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "precision = Precision(average=False)\n",
    "recall = Recall(average=False)\n",
    "F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"loss\": Loss(criterion),\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": F1,\n",
    "    \"confusion_matrix\": ConfusionMatrix(num_classes=len(classes))\n",
    "}\n",
    "\n",
    "# create a confusion Matrix\n",
    "def transform_confusion_matrix(matrix):\n",
    "    return matrix.cpu().numpy().astype(int).astype(str)\n",
    "\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "log_interval = 30\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "def log_training_loss(engine):\n",
    "    \"\"\"\n",
    "     Log training loss at log_interval\n",
    "     \"\"\"\n",
    "    progress_bar.desc = desc.format(engine.state.output)\n",
    "    progress_bar.update(log_interval)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    \"\"\"\n",
    "    Lofts training results at the end of each epoch\n",
    "    \"\"\"\n",
    "    progress_bar.refresh()\n",
    "    evaluator.run(train_iterator)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics[\"accuracy\"]\n",
    "    avg_loss = metrics[\"loss\"]\n",
    "    \n",
    "    tqdm.write(\n",
    "        \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "        .format(engine.state.epoch, avg_accuracy, avg_loss)\n",
    "    )\n",
    "\n",
    "def score_function(engine):\n",
    "    return engine.state.metrics['f1']\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(valid_iterator)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics[\"accuracy\"]\n",
    "    avg_loss = metrics[\"loss\"]\n",
    "\n",
    "    tqdm.write(\n",
    "        \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "        .format(engine.state.epoch, avg_accuracy, avg_loss)\n",
    "    )\n",
    "   \n",
    "model_checkpoint = ModelCheckpoint(\n",
    "        dirname=\"{}/models/f1\".format(application_name),\n",
    "        n_saved=2,\n",
    "        require_empty=False,\n",
    "        filename_prefix=\"best_{}\".format(application_name),\n",
    "        create_dir=True,\n",
    "        score_function=score_function,\n",
    "        score_name=\"f1\", # accuracy\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "# Use this if you want to get the model based on accuracy\n",
    "\n",
    "_model_checkpoint = ModelCheckpoint(\n",
    "        dirname=\"{}/models/accuracy\".format(application_name),\n",
    "        n_saved=2,\n",
    "        require_empty=False,\n",
    "        filename_prefix=\"best_{}\".format(application_name),\n",
    "        create_dir=True,\n",
    "        score_function=score_function,\n",
    "        score_name=\"accuracy\", # accuracy\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\n",
    "    \"model\": model,\n",
    "})\n",
    "\n",
    "evaluator.add_event_handler(Events.COMPLETED, _model_checkpoint, {\n",
    "    \"model\": model,\n",
    "})\n",
    "\n",
    "\"\"\"\n",
    "Logging and monitoring\n",
    "\"\"\"\n",
    "# wandb_logger = WandBLogger(\n",
    "#     project=application_name,\n",
    "#     anonymous=\"allow\",\n",
    "#     name=application_name,\n",
    "#     config={\"max_epochs\": EPOCHS, \"batch_size\": BATCH_SIZE},\n",
    "# )\n",
    "\n",
    "# wandb_logger.attach_output_handler(\n",
    "#     trainer, Events.ITERATION_COMPLETED,\n",
    "#     tag='training',\n",
    "#     output_transform=lambda loss: {'loss': loss},\n",
    "# )\n",
    "# wandb_logger.attach_output_handler(\n",
    "#     evaluator, Events.EPOCH_COMPLETED,\n",
    "#     tag='training',\n",
    "#     metric_names='all',\n",
    "#     global_step_transform=lambda *_: trainer.state.iteration,\n",
    "# )\n",
    "# wandb_logger.attach_opt_params_handler(\n",
    "#     trainer, Events.ITERATION_STARTED,\n",
    "#     optimizer=optimizer,\n",
    "#     param_name='lr',\n",
    "# )\n",
    "\n",
    "tensorboard_logger = TensorboardLogger(\n",
    "    log_dir=\"logs-{}\".format(application_name),\n",
    ")\n",
    "tensorboard_logger.attach_output_handler(\n",
    "    trainer, Events.ITERATION_COMPLETED,\n",
    "    tag='training',\n",
    "    output_transform=lambda loss: {'training loss': loss},\n",
    ")\n",
    "tensorboard_logger.attach_output_handler(\n",
    "    evaluator, Events.EPOCH_COMPLETED,\n",
    "    tag='validation',\n",
    "    metric_names='all',\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "class ImageDenomalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def predictions_get_images_handler(engine, logger, *args, **kwargs):\n",
    "    x, _ = engine.state.batch\n",
    "    y_pred, y = engine.state.output\n",
    "    num_x = num_y = len(classes)\n",
    "    le = num_x * num_y\n",
    "    probs, preds = torch.max(torch.exp(y_pred[:le]), dim=1)\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    for idx in range(le):\n",
    "        ax = fig.add_subplot(num_x, num_y, idx + 1, xticks=[], yticks=[])\n",
    "        \n",
    "        try:\n",
    "            # image = x[idx].numpy().transpose((1, 2, 0))\n",
    "            # image = x[idx].permute(1, 2, 0) \n",
    "            image = x[idx]\n",
    "\n",
    "            unormalized_image = ImageDenomalize(\n",
    "                mean=means, std=stds\n",
    "            )\n",
    "            image = unormalized_image(image)\n",
    "            image = transforms.ToPILImage(mode='RGB')(image)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        ax.imshow(\n",
    "            image, cmap=\"Greys\"\n",
    "        )\n",
    "        ax.set_title(\"Preds: {0} {1:.1f}%, Actual: (label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx],\n",
    "            classes[y[idx]]\n",
    "        ), color=(\"green\" if preds[idx] == y[idx] else \"red\"))\n",
    "    logger.writer.add_figure(\n",
    "        \"Predictions vs actuals\", figure=fig, global_step=trainer.state.epoch\n",
    "    )\n",
    "\n",
    "def plot_confusion_matrix(engine, logger, *args, **kwargs):\n",
    "    confusion_matrix_data = engine.state.metrics['confusion_matrix'].numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    _confusion_matrix = ConfusionMatrixDisplay(confusion_matrix_data, display_labels=classes)\n",
    "    _confusion_matrix.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Predicted Label', fontsize = 50)\n",
    "    plt.ylabel('True Label', fontsize = 50)\n",
    "    logger.writer.add_figure(\n",
    "        \"Confusion Matrix\", figure=fig, global_step=trainer.state.epoch\n",
    "    )\n",
    "\n",
    "tensorboard_logger.attach(\n",
    "    evaluator,\n",
    "    event_name=Events.ITERATION_COMPLETED(once=1),\n",
    "    log_handler=predictions_get_images_handler,\n",
    ")\n",
    "tensorboard_logger.attach(\n",
    "    evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    log_handler=plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "# wandb_logger.watch(model, log=\"all\")\n",
    "trainer.run(train_iterator, max_epochs=EPOCHS)\n",
    "\n",
    "progress_bar.close()\n",
    "tensorboard_logger.close()\n",
    "\n",
    "\n",
    "# and attach it to evaluator\n",
    "\n",
    "# wandb_logger._wandb.finish()\n",
    "\n",
    "# f102268ac0afc1f2162c032ef8401883971ada66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_idx = test_data.class_to_idx\n",
    "classes_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboardX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading trained model, and testing \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model_path = \"{}/models/f1/best_mango-Quality_model_1_f1=0.4682.pt\".format(application_name)\n",
    "trained_model = resnet18(\n",
    "    num_classes=len(classes_idx),\n",
    ")\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "trained_model.eval()\n",
    "# ml-classfication/dl-classification/datasets/mangoes-leaves/test/diseased/0012_0002.JPG\n",
    "image = Image.open(\"datasets/mango-Quality/images/mbovu/20220309_123154.jpg\")\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = means, std = stds)\n",
    "])\n",
    "input_tensor = trans(image).unsqueeze(0)\n",
    "input_tensor = input_tensor.to('cpu')\n",
    "\n",
    "output = trained_model(input_tensor)\n",
    "\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "prob = nnf.softmax(output, dim=1)\n",
    "print(prob)\n",
    "\n",
    "top_p, top_class = prob.topk(1, dim = 1)\n",
    "prob.tolist()[0]\n",
    "confidence, label = top_p.tolist()[0][0], top_class.tolist()[0][0]\n",
    "confidence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b253ee4cad54dfd819810efba587669ce1fc7f5a849babd38cbd1de9bd5dc852"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
