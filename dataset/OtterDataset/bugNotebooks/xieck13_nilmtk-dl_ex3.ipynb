{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T06:19:50.092771Z",
     "start_time": "2020-03-30T06:19:50.081805Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from api import API\n",
    "from disaggregate import ADAE, DAE, Seq2Point, Seq2Seq, WindowGRU, RNN\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = 'D:/workspace/nilm/data/redd_data.h5'\n",
    "# path = 'D:/workspace/nilm/code/databank/redd_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T06:19:52.511075Z",
     "start_time": "2020-03-30T06:19:52.487071Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "TEST = False\n",
    "\n",
    "def generate_method(debug, test):\n",
    "    if debug:\n",
    "        method = {\n",
    "            'DAE': DAE({'save-model-path': 'DAE', 'pretrained-model-path': None, 'n_epochs': 1, 'batch_size': 256}),\n",
    "            # 'RNN': RNN({'save-model-path': 'RNN', 'pretrained-model-path': None, 'n_epochs': 1, 'batch_size': 256}),\n",
    "            # 'Seq2Point': Seq2Point({'save-model-path': 'Seq2Point', 'pretrained-model-path': None, 'n_epochs': 1, 'batch_size': 256}),\n",
    "            # 'Seq2Seq': Seq2Seq({'save-model-path': 'Seq2Seq', 'pretrained-model-path': None, 'n_epochs': 1, 'batch_size': 256}),\n",
    "            # 'GRU': WindowGRU({'save-model-path': 'GRU', 'pretrained-model-path': None, 'n_epochs': 1, 'batch_size': 256}),\n",
    "        }\n",
    "    else:\n",
    "        method = {\n",
    "            'DAE': DAE({'save-model-path': 'DAE', 'pretrained-model-path': None}),\n",
    "            'RNN': RNN({'save-model-path': 'RNN', 'pretrained-model-path': None}),\n",
    "            'Seq2Point': Seq2Point({'save-model-path': 'Seq2Point', 'pretrained-model-path': None}),\n",
    "            'Seq2Seq': Seq2Seq({'save-model-path': 'Seq2Seq', 'pretrained-model-path': None}),\n",
    "            'GRU': WindowGRU({'save-model-path': 'GRU', 'pretrained-model-path': None}),\n",
    "        }\n",
    "    if test:\n",
    "        method = {\n",
    "            'DAE': DAE({'save-model-path': 'DAE', 'pretrained-model-path': 'DAE'}),\n",
    "            'RNN': RNN({'save-model-path': 'RNN', 'pretrained-model-path': 'RNN'}),\n",
    "            'Seq2Point': Seq2Point({'save-model-path': 'Seq2Point', 'pretrained-model-path': 'Seq2Point'}),\n",
    "            'Seq2Seq': Seq2Seq({'save-model-path': 'Seq2Seq', 'pretrained-model-path': 'Seq2Seq'}),\n",
    "            'GRU': WindowGRU({'save-model-path': 'GRU', 'pretrained-model-path': 'GRU'}),\n",
    "        }\n",
    "    return method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_dish_washer = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['dish washer'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    }, \n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    4: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-06-03'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    4: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-06-03'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "API(ex_train_dish_washer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T12:09:02.500319Z",
     "start_time": "2020-03-18T12:09:02.488624Z"
    },
    "code_folding": [
     1
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_fridge = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['fridge'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-04-27'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-23'\n",
    "                    },\n",
    "\n",
    "                    6: {\n",
    "                        'start_time': '2011-05-21',\n",
    "                        'end_time': '2011-06-09'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    6: {\n",
    "                        'start_time': '2011-06-09',\n",
    "                        'end_time': '2011-06-13'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "API(ex_train_fridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1,
     14
    ],
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_microwave = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['microwave'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-04-27'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-23'\n",
    "                    }\n",
    "                }\n",
    "\n",
    "\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "API(ex_train_microwave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:55:22.593810Z",
     "start_time": "2020-03-30T06:19:59.227401Z"
    },
    "code_folding": [
     1,
     72,
     145
    ],
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for  DAE\n",
      "Joint training for  DAE\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  redd  dataset\n",
      "Loading building ...  1\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  2\n",
      "Loading data for meter ElecMeterID(instance=2, building=2, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  3\n",
      "Loading data for meter ElecMeterID(instance=2, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  4\n",
      "Loading data for meter ElecMeterID(instance=2, building=4, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Doing Preprocessing\n",
      "[[-0.0018285  -0.00182979 -0.00182951 ... -0.00183251 -0.00183083\n",
      "  -0.00183173]\n",
      " [-0.00182979 -0.00182951 -0.00182284 ... -0.00183083 -0.00183173\n",
      "  -0.0018314 ]\n",
      " [-0.00182951 -0.00182284 -0.00182591 ... -0.00183173 -0.0018314\n",
      "  -0.0018315 ]\n",
      " ...\n",
      " [-0.00207967 -0.0020796  -0.00208002 ... -0.00277778 -0.00277778\n",
      "  -0.00277778]\n",
      " [-0.0020796  -0.00208002 -0.00208065 ... -0.00277778 -0.00277778\n",
      "  -0.00277778]\n",
      " [-0.00208002 -0.00208065 -0.00277778 ... -0.00277778 -0.00277778\n",
      "  -0.00277778]]\n",
      "First model training for  dish washer\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 99, 8)             40        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 792)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 792)               628056    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               101504    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 792)               102168    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 99, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 99, 1)             33        \n",
      "=================================================================\n",
      "Total params: 831,801\n",
      "Trainable params: 831,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Started Retraining model for  dish washer\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 812267 samples, validate on 143342 samples\n",
      "Epoch 1/50\n",
      "812267/812267 [==============================] - 10s 12us/step - loss: 0.7916 - val_loss: 0.6981\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69806, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 2/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.6423 - val_loss: 0.6234\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69806 to 0.62341, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 3/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.5976 - val_loss: 0.6361\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.62341\n",
      "Epoch 4/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.5743 - val_loss: 0.5569\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62341 to 0.55686, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 5/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.5456 - val_loss: 0.5407\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55686 to 0.54068, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 6/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.5115 - val_loss: 0.5292\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54068 to 0.52922, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 7/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.4818 - val_loss: 0.4684\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52922 to 0.46841, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 8/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.4547 - val_loss: 0.4252\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46841 to 0.42517, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 9/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.4209 - val_loss: 0.4126\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.42517 to 0.41257, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 10/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.4037 - val_loss: 0.3912\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.41257 to 0.39124, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 11/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3752 - val_loss: 0.3741\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.39124 to 0.37407, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 12/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3580 - val_loss: 0.3466\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37407 to 0.34655, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 13/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3448 - val_loss: 0.3267\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34655 to 0.32672, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 14/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3263 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.32672 to 0.31801, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 15/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3184 - val_loss: 0.3160\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31801 to 0.31597, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 16/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.3070 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.31597 to 0.30654, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 17/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2965 - val_loss: 0.3028\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.30654 to 0.30279, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 18/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2881 - val_loss: 0.2795\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.30279 to 0.27954, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 19/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2809 - val_loss: 0.2774\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.27954 to 0.27738, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 20/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2696 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.27738 to 0.26253, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 21/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2560 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26253\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2510 - val_loss: 0.2597\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.26253 to 0.25975, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 23/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2453 - val_loss: 0.2637\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25975\n",
      "Epoch 24/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2336 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.25975\n",
      "Epoch 25/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2331 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.25975\n",
      "Epoch 26/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2262 - val_loss: 0.2256\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.25975 to 0.22563, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 27/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2150 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22563\n",
      "Epoch 28/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2170 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.22563\n",
      "Epoch 29/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2077 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22563\n",
      "Epoch 30/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2100 - val_loss: 0.2044\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22563 to 0.20442, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 31/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1979 - val_loss: 0.1990\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20442 to 0.19899, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 32/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.2039 - val_loss: 0.2054\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19899\n",
      "Epoch 33/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1983 - val_loss: 0.2044\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.19899\n",
      "Epoch 34/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1920 - val_loss: 0.1900\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19899 to 0.18998, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 35/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1927 - val_loss: 0.2170\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18998\n",
      "Epoch 36/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1870 - val_loss: 0.1893\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18998 to 0.18934, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 37/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1782 - val_loss: 0.1978\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.18934\n",
      "Epoch 38/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1824 - val_loss: 0.1943\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.18934\n",
      "Epoch 39/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1753 - val_loss: 0.1798\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18934 to 0.17982, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 40/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1767 - val_loss: 0.1960\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.17982\n",
      "Epoch 41/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1695 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.17982 to 0.17019, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 42/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1739 - val_loss: 0.1897\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17019\n",
      "Epoch 43/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1728 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17019\n",
      "Epoch 44/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1641 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17019\n",
      "Epoch 45/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1666 - val_loss: 0.1835\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17019\n",
      "Epoch 46/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1602 - val_loss: 0.1603\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17019 to 0.16028, saving model to dae-temp-weights-74894.h5\n",
      "Epoch 47/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1682 - val_loss: 0.1633\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16028\n",
      "Epoch 48/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1583 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16028\n",
      "Epoch 49/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1589 - val_loss: 0.1614\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16028\n",
      "Epoch 50/50\n",
      "812267/812267 [==============================] - 6s 8us/step - loss: 0.1586 - val_loss: 0.2030\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16028\n",
      "Saving model for  dish washer\n",
      "Finished training for  DAE\n",
      "Started training for  RNN\n",
      "Joint training for  RNN\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  redd  dataset\n",
      "Loading building ...  1\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  2\n",
      "Loading data for meter ElecMeterID(instance=2, building=2, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  3\n",
      "Loading data for meter ElecMeterID(instance=2, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  4\n",
      "Loading data for meter ElecMeterID(instance=2, building=4, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "{'dish washer': {'mean': 11.789397, 'std': 105.67333}}\n",
      "...............RNN partial_fit running...............\n",
      "First model training for  dish washer\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 814657 samples, validate on 143764 samples\n",
      "Epoch 1/50\n",
      "814657/814657 [==============================] - 653s 801us/step - loss: 0.6720 - mean_squared_error: 0.6720 - val_loss: 0.6173 - val_mean_squared_error: 0.6173\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61734, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 2/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.5345 - mean_squared_error: 0.5345 - val_loss: 0.4634 - val_mean_squared_error: 0.4634\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61734 to 0.46339, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 3/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.5771 - mean_squared_error: 0.5771 - val_loss: 0.5785 - val_mean_squared_error: 0.5785\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.46339\n",
      "Epoch 4/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.5587 - mean_squared_error: 0.5587 - val_loss: 0.5466 - val_mean_squared_error: 0.5466\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46339\n",
      "Epoch 5/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.4787 - mean_squared_error: 0.4787 - val_loss: 0.3952 - val_mean_squared_error: 0.3952\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46339 to 0.39522, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 6/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.3691 - mean_squared_error: 0.3691 - val_loss: 0.3076 - val_mean_squared_error: 0.3076\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39522 to 0.30763, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 7/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.2884 - mean_squared_error: 0.2884 - val_loss: 0.2373 - val_mean_squared_error: 0.2373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss improved from 0.30763 to 0.23725, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 8/50\n",
      "814657/814657 [==============================] - 650s 797us/step - loss: 0.3365 - mean_squared_error: 0.3365 - val_loss: 0.2854 - val_mean_squared_error: 0.2854\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23725\n",
      "Epoch 9/50\n",
      "814657/814657 [==============================] - 648s 796us/step - loss: 0.2542 - mean_squared_error: 0.2542 - val_loss: 0.2072 - val_mean_squared_error: 0.2072\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23725 to 0.20720, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 10/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.2181 - mean_squared_error: 0.2181 - val_loss: 0.1899 - val_mean_squared_error: 0.1899\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20720 to 0.18990, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 11/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1801 - mean_squared_error: 0.1801 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18990 to 0.15053, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 12/50\n",
      "814657/814657 [==============================] - 651s 799us/step - loss: 0.2093 - mean_squared_error: 0.2093 - val_loss: 0.1895 - val_mean_squared_error: 0.1895\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.15053\n",
      "Epoch 13/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1709 - mean_squared_error: 0.1709 - val_loss: 0.1456 - val_mean_squared_error: 0.1456\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.15053 to 0.14559, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 14/50\n",
      "814657/814657 [==============================] - 651s 799us/step - loss: 0.1638 - mean_squared_error: 0.1638 - val_loss: 0.1299 - val_mean_squared_error: 0.1299\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.14559 to 0.12993, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 15/50\n",
      "814657/814657 [==============================] - 652s 800us/step - loss: 0.1322 - mean_squared_error: 0.1322 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.12993 to 0.09761, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 16/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1282 - mean_squared_error: 0.1282 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09761\n",
      "Epoch 17/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1231 - mean_squared_error: 0.1231 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09761\n",
      "Epoch 18/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1298 - mean_squared_error: 0.1298 - val_loss: 0.1269 - val_mean_squared_error: 0.1269\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09761\n",
      "Epoch 19/50\n",
      "814657/814657 [==============================] - 651s 799us/step - loss: 0.1086 - mean_squared_error: 0.1086 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09761 to 0.08912, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 20/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1104 - mean_squared_error: 0.1104 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08912\n",
      "Epoch 21/50\n",
      "814657/814657 [==============================] - 650s 797us/step - loss: 0.1034 - mean_squared_error: 0.1034 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08912\n",
      "Epoch 22/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.1345 - mean_squared_error: 0.1345 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08912\n",
      "Epoch 23/50\n",
      "814657/814657 [==============================] - 649s 796us/step - loss: 0.0829 - mean_squared_error: 0.0829 - val_loss: 0.0680 - val_mean_squared_error: 0.0680\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.08912 to 0.06800, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 24/50\n",
      "814657/814657 [==============================] - 648s 795us/step - loss: 0.1201 - mean_squared_error: 0.1201 - val_loss: 0.0906 - val_mean_squared_error: 0.0906\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06800\n",
      "Epoch 25/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0848 - mean_squared_error: 0.0848 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06800\n",
      "Epoch 26/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0712 - mean_squared_error: 0.0712 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06800\n",
      "Epoch 27/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0762 - mean_squared_error: 0.0762 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06800\n",
      "Epoch 28/50\n",
      "814657/814657 [==============================] - 648s 796us/step - loss: 0.0747 - mean_squared_error: 0.0747 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06800\n",
      "Epoch 29/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0752 - mean_squared_error: 0.0752 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06800\n",
      "Epoch 30/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.1342 - val_mean_squared_error: 0.1342\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06800\n",
      "Epoch 31/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06800 to 0.06568, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 32/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0684 - mean_squared_error: 0.0684 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06568\n",
      "Epoch 33/50\n",
      "814657/814657 [==============================] - 648s 796us/step - loss: 0.0883 - mean_squared_error: 0.0883 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06568\n",
      "Epoch 34/50\n",
      "814657/814657 [==============================] - 649s 796us/step - loss: 0.1070 - mean_squared_error: 0.1070 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06568\n",
      "Epoch 35/50\n",
      "814657/814657 [==============================] - 649s 796us/step - loss: 0.0954 - mean_squared_error: 0.0954 - val_loss: 0.4007 - val_mean_squared_error: 0.4007\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06568\n",
      "Epoch 36/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.1193 - mean_squared_error: 0.1193 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06568\n",
      "Epoch 37/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0967 - mean_squared_error: 0.0967 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06568\n",
      "Epoch 38/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0981 - mean_squared_error: 0.0981 - val_loss: 0.1129 - val_mean_squared_error: 0.1129\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06568\n",
      "Epoch 39/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0839 - mean_squared_error: 0.0839 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06568\n",
      "Epoch 40/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.0876 - mean_squared_error: 0.0876 - val_loss: 0.0834 - val_mean_squared_error: 0.0834\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06568\n",
      "Epoch 41/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.0620 - mean_squared_error: 0.0620 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.06568 to 0.06360, saving model to RNN-temp-weights-4270.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0607 - mean_squared_error: 0.0607 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06360\n",
      "Epoch 43/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06360\n",
      "Epoch 44/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0778 - mean_squared_error: 0.0778 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.06360 to 0.05996, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 45/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.0568 - mean_squared_error: 0.0568 - val_loss: 0.1192 - val_mean_squared_error: 0.1192\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05996\n",
      "Epoch 46/50\n",
      "814657/814657 [==============================] - 651s 799us/step - loss: 0.0931 - mean_squared_error: 0.0931 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05996\n",
      "Epoch 47/50\n",
      "814657/814657 [==============================] - 650s 798us/step - loss: 0.0550 - mean_squared_error: 0.0550 - val_loss: 0.0563 - val_mean_squared_error: 0.0563\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05996 to 0.05626, saving model to RNN-temp-weights-4270.h5\n",
      "Epoch 48/50\n",
      "814657/814657 [==============================] - 650s 797us/step - loss: 0.0516 - mean_squared_error: 0.0516 - val_loss: 0.0624 - val_mean_squared_error: 0.0624\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05626\n",
      "Epoch 49/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0748 - val_mean_squared_error: 0.0748\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05626\n",
      "Epoch 50/50\n",
      "814657/814657 [==============================] - 649s 797us/step - loss: 0.0560 - mean_squared_error: 0.0560 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05626\n",
      "Saving model for  dish washer\n",
      "Finished training for  RNN\n",
      "Started training for  Seq2Point\n",
      "Joint training for  Seq2Point\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  redd  dataset\n",
      "Loading building ...  1\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  2\n",
      "Loading data for meter ElecMeterID(instance=2, building=2, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  3\n",
      "Loading data for meter ElecMeterID(instance=2, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  4\n",
      "Loading data for meter ElecMeterID(instance=2, building=4, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "{'dish washer': {'mean': 11.789397, 'std': 105.67333}}\n",
      "...............Seq2Point partial_fit running...............\n",
      "First model training for  dish washer\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\nilmtk-contrib\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 814657 samples, validate on 143764 samples\n",
      "Epoch 1/50\n",
      "814657/814657 [==============================] - 20s 25us/step - loss: 0.5656 - val_loss: 0.4100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41002, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 2/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.3735 - val_loss: 0.3388\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41002 to 0.33884, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 3/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.2986 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33884 to 0.24062, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 4/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.2487 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24062\n",
      "Epoch 5/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.2240 - val_loss: 0.2059\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.24062 to 0.20593, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 6/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.2076 - val_loss: 0.2093\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20593\n",
      "Epoch 7/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1943 - val_loss: 0.1598\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20593 to 0.15980, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 8/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1807 - val_loss: 0.1655\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15980\n",
      "Epoch 9/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1626 - val_loss: 0.1441\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.15980 to 0.14411, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 10/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1549 - val_loss: 0.1426\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14411 to 0.14262, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 11/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1443 - val_loss: 0.1215\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.14262 to 0.12155, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 12/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1435 - val_loss: 0.1364\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12155\n",
      "Epoch 13/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1294 - val_loss: 0.1167\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12155 to 0.11670, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 14/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1244 - val_loss: 0.1445\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11670\n",
      "Epoch 15/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1239 - val_loss: 0.0999\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.11670 to 0.09988, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 16/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1238 - val_loss: 0.1486\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09988\n",
      "Epoch 17/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1186 - val_loss: 0.0960\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09988 to 0.09598, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 18/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1099 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09598 to 0.09291, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 19/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1039 - val_loss: 0.1304\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09291\n",
      "Epoch 20/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1098 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09291 to 0.08551, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 21/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.1038 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08551\n",
      "Epoch 22/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0890 - val_loss: 0.0812\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.08551 to 0.08116, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 23/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.1119 - val_loss: 0.0835\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08116\n",
      "Epoch 24/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0883 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08116\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0924 - val_loss: 0.0720\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08116 to 0.07196, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 26/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0889 - val_loss: 0.0787\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07196\n",
      "Epoch 27/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0856 - val_loss: 0.0816\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07196\n",
      "Epoch 28/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0797 - val_loss: 0.0635\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.07196 to 0.06354, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 29/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0784 - val_loss: 0.0796\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06354\n",
      "Epoch 30/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0832 - val_loss: 0.1073\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06354\n",
      "Epoch 31/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0794 - val_loss: 0.0633\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06354 to 0.06332, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 32/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0714 - val_loss: 0.0652\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06332\n",
      "Epoch 33/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0788 - val_loss: 0.0624\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.06332 to 0.06242, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 34/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0711 - val_loss: 0.0670\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06242\n",
      "Epoch 35/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0805 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06242\n",
      "Epoch 36/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0698 - val_loss: 0.0640\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06242\n",
      "Epoch 37/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0684 - val_loss: 0.0737\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06242\n",
      "Epoch 38/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0642 - val_loss: 0.0568\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.06242 to 0.05680, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 39/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0696 - val_loss: 0.0693\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05680\n",
      "Epoch 40/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0696 - val_loss: 0.0581\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05680\n",
      "Epoch 41/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0720 - val_loss: 0.0665\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05680\n",
      "Epoch 42/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0643 - val_loss: 0.0570\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05680\n",
      "Epoch 43/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0655 - val_loss: 0.0548\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.05680 to 0.05483, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 44/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0612 - val_loss: 0.0563\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05483\n",
      "Epoch 45/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0785 - val_loss: 0.0571\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05483\n",
      "Epoch 46/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0635 - val_loss: 0.0725\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05483\n",
      "Epoch 47/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0583 - val_loss: 0.0512\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05483 to 0.05123, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 48/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0595 - val_loss: 0.0479\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.05123 to 0.04787, saving model to seq2point-temp-weights-56215.h5\n",
      "Epoch 49/50\n",
      "814657/814657 [==============================] - 16s 20us/step - loss: 0.0601 - val_loss: 0.0645\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04787\n",
      "Epoch 50/50\n",
      "814657/814657 [==============================] - 17s 20us/step - loss: 0.0563 - val_loss: 0.1083\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04787\n",
      "Saving model for  dish washer\n",
      "Finished training for  Seq2Point\n",
      "Started training for  Seq2Seq\n",
      "Joint training for  Seq2Seq\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  redd  dataset\n",
      "Loading building ...  1\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  2\n",
      "Loading data for meter ElecMeterID(instance=2, building=2, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  3\n",
      "Loading data for meter ElecMeterID(instance=2, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  4\n",
      "Loading data for meter ElecMeterID(instance=2, building=4, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "...............Seq2Seq partial_fit running...............\n",
      "61\n",
      "First model training for  dish washer\n",
      "Train on 814657 samples, validate on 143764 samples\n",
      "Epoch 1/50\n",
      "814657/814657 [==============================] - 9s 11us/step - loss: 0.5600 - val_loss: 0.4351\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43507, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 2/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.3822 - val_loss: 0.3278\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43507 to 0.32780, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 3/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.3179 - val_loss: 0.2680\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32780 to 0.26800, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 4/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.2748 - val_loss: 0.2334\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26800 to 0.23343, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 5/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.2501 - val_loss: 0.2330\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23343 to 0.23299, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 6/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.2270 - val_loss: 0.1817\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23299 to 0.18172, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 7/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.2053 - val_loss: 0.1997\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18172\n",
      "Epoch 8/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1981 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18172 to 0.17422, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 9/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.1844 - val_loss: 0.1615\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.17422 to 0.16146, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 10/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.1784 - val_loss: 0.1625\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16146\n",
      "Epoch 11/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.1672 - val_loss: 0.1459\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.16146 to 0.14593, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 12/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1636 - val_loss: 0.1315\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.14593 to 0.13147, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1510 - val_loss: 0.1401\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13147\n",
      "Epoch 14/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1562 - val_loss: 0.1287\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.13147 to 0.12867, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 15/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1460 - val_loss: 0.1194\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.12867 to 0.11939, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 16/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1378 - val_loss: 0.1170\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.11939 to 0.11702, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 17/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1410 - val_loss: 0.1383\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11702\n",
      "Epoch 18/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1296 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.11702 to 0.09379, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 19/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.1202 - val_loss: 0.1149\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09379\n",
      "Epoch 20/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1234 - val_loss: 0.1003\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09379\n",
      "Epoch 21/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1209 - val_loss: 0.1253\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.09379\n",
      "Epoch 22/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1183 - val_loss: 0.0957\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.09379\n",
      "Epoch 23/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1121 - val_loss: 0.0926\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.09379 to 0.09264, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 24/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1062 - val_loss: 0.1206\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.09264\n",
      "Epoch 25/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1107 - val_loss: 0.0975\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.09264\n",
      "Epoch 26/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1093 - val_loss: 0.0911\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.09264 to 0.09114, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 27/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1048 - val_loss: 0.0994\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09114\n",
      "Epoch 28/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1039 - val_loss: 0.0926\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09114\n",
      "Epoch 29/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.1041 - val_loss: 0.0757\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.09114 to 0.07571, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 30/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1021 - val_loss: 0.1104\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07571\n",
      "Epoch 31/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0971 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07571\n",
      "Epoch 32/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1044 - val_loss: 0.0831\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07571\n",
      "Epoch 33/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0973 - val_loss: 0.0902\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07571\n",
      "Epoch 34/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.1010 - val_loss: 0.0818\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07571\n",
      "Epoch 35/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0934 - val_loss: 0.1063\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07571\n",
      "Epoch 36/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0944 - val_loss: 0.0753\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07571 to 0.07526, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 37/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0932 - val_loss: 0.0898\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07526\n",
      "Epoch 38/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0899 - val_loss: 0.1121\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07526\n",
      "Epoch 39/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0856 - val_loss: 0.0660\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.07526 to 0.06599, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 40/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0874 - val_loss: 0.0833\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06599\n",
      "Epoch 41/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0972 - val_loss: 0.0806\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06599\n",
      "Epoch 42/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0860 - val_loss: 0.0662\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06599\n",
      "Epoch 43/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0848 - val_loss: 0.0648\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.06599 to 0.06483, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 44/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0861 - val_loss: 0.1062\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06483\n",
      "Epoch 45/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0864 - val_loss: 0.0655\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06483\n",
      "Epoch 46/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0799 - val_loss: 0.0680\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06483\n",
      "Epoch 47/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0771 - val_loss: 0.0621\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.06483 to 0.06205, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 48/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0929 - val_loss: 0.0638\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06205\n",
      "Epoch 49/50\n",
      "814657/814657 [==============================] - 7s 9us/step - loss: 0.0741 - val_loss: 0.0581\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06205 to 0.05807, saving model to seq2seq-temp-weights-63250.h5\n",
      "Epoch 50/50\n",
      "814657/814657 [==============================] - 8s 9us/step - loss: 0.0766 - val_loss: 0.0607\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05807\n",
      "Saving model for  dish washer\n",
      "Finished training for  Seq2Seq\n",
      "Started training for  WindowGRU\n",
      "Joint training for  WindowGRU\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  redd  dataset\n",
      "Loading building ...  1\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  2\n",
      "Loading data for meter ElecMeterID(instance=2, building=2, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  3\n",
      "Loading data for meter ElecMeterID(instance=2, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "Loading building ...  4\n",
      "Loading data for meter ElecMeterID(instance=2, building=4, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "{'dish washer': {'mean': 11.789397, 'std': 105.67333}}\n",
      "...............GRU partial_fit running...............\n",
      "First model training for  dish washer\n",
      "Train on 814657 samples, validate on 143764 samples\n",
      "Epoch 1/30\n",
      "814657/814657 [==============================] - 495s 608us/step - loss: 0.6199 - val_loss: 0.4677\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46772, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 2/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.4667 - val_loss: 0.5105\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46772\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.3852 - val_loss: 0.3186\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46772 to 0.31862, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 4/30\n",
      "814657/814657 [==============================] - 491s 603us/step - loss: 0.3128 - val_loss: 0.2509\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31862 to 0.25095, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 5/30\n",
      "814657/814657 [==============================] - 491s 603us/step - loss: 0.2904 - val_loss: 0.2416\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25095 to 0.24156, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 6/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2967 - val_loss: 0.2581\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24156\n",
      "Epoch 7/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2881 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24156 to 0.22623, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 8/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2592 - val_loss: 0.2062\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.22623 to 0.20623, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 9/30\n",
      "814657/814657 [==============================] - 491s 603us/step - loss: 0.2598 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20623\n",
      "Epoch 10/30\n",
      "814657/814657 [==============================] - 491s 603us/step - loss: 0.2438 - val_loss: 0.2031\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20623 to 0.20308, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 11/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2537 - val_loss: 0.2914\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20308\n",
      "Epoch 12/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2500 - val_loss: 0.1836\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20308 to 0.18362, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 13/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2324 - val_loss: 0.1953\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18362\n",
      "Epoch 14/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2518 - val_loss: 0.1870\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18362\n",
      "Epoch 15/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2208 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.18362 to 0.17314, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 16/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2158 - val_loss: 0.1565\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17314 to 0.15647, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 17/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.2096 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15647\n",
      "Epoch 18/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.1891 - val_loss: 0.2028\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15647\n",
      "Epoch 19/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.1973 - val_loss: 0.1491\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15647 to 0.14914, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 20/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.1995 - val_loss: 0.1978\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.14914\n",
      "Epoch 21/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.1887 - val_loss: 0.1464\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.14914 to 0.14637, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 22/30\n",
      "814657/814657 [==============================] - 492s 604us/step - loss: 0.1837 - val_loss: 0.1889\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14637\n",
      "Epoch 23/30\n",
      "814657/814657 [==============================] - 493s 605us/step - loss: 0.1825 - val_loss: 0.1417\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.14637 to 0.14174, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 24/30\n",
      "814657/814657 [==============================] - 493s 605us/step - loss: 0.1800 - val_loss: 0.1458\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14174\n",
      "Epoch 25/30\n",
      "814657/814657 [==============================] - 493s 605us/step - loss: 0.1739 - val_loss: 0.1428\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14174\n",
      "Epoch 26/30\n",
      "814657/814657 [==============================] - 494s 606us/step - loss: 0.1717 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14174\n",
      "Epoch 27/30\n",
      "814657/814657 [==============================] - 494s 606us/step - loss: 0.1640 - val_loss: 0.1265\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14174 to 0.12649, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 28/30\n",
      "814657/814657 [==============================] - 493s 605us/step - loss: 0.1527 - val_loss: 0.1172\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12649 to 0.11722, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 29/30\n",
      "814657/814657 [==============================] - 494s 606us/step - loss: 0.1435 - val_loss: 0.1063\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11722 to 0.10628, saving model to GRU-temp-weights-75771.h5\n",
      "Epoch 30/30\n",
      "814657/814657 [==============================] - 493s 605us/step - loss: 0.1970 - val_loss: 0.1268\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10628\n",
      "Saving model for  dish washer\n",
      "Finished training for  WindowGRU\n",
      "Joint Testing for all algorithms\n",
      "Loading data for  redd  dataset\n",
      "Loading data for meter ElecMeterID(instance=2, building=1, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "Dropping missing values\n",
      "Test Jointly\n",
      "Generating predictions for : DAE\n",
      "Generating predictions for : RNN\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float32'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3f9616313430>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m }\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex_train_dish_washer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misState\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'isState'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\api.py\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Joint Testing for all algorithms\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_jointly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\api.py\u001b[0m in \u001b[0;36mtest_jointly\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoring_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuilding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\api.py\u001b[0m in \u001b[0;36mcall_predict\u001b[1;34m(self, classifiers)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mgt_overall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mgt_overall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_overall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_mains\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_submeters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Europe/London'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt_overall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgt_overall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\api.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, clf, test_elec, test_submeters, sample_period, timezone)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mpred_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisaggregate_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_elec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\nilm\\nilmtk-contrib-master\\experiment\\nilmtk-dl\\disaggregate\\rnn.py\u001b[0m in \u001b[0;36mdisaggregate_chunk\u001b[1;34m(self, test_main_list, model, do_preprocessing)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mappliance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mappliance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_main\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappliance_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mappliance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappliance_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mappliance\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                 \u001b[0mvalid_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[0mvalid_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_predictions\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float32'"
     ]
    }
   ],
   "source": [
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_dish_washer = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['dish washer'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    }, \n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    4: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-06-03'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    4: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-06-03'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "API(ex_train_dish_washer)\n",
    "\n",
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_fridge = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['fridge'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-04-27'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-23'\n",
    "                    },\n",
    "\n",
    "                    6: {\n",
    "                        'start_time': '2011-05-21',\n",
    "                        'end_time': '2011-06-09'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    },\n",
    "\n",
    "                    6: {\n",
    "                        'start_time': '2011-06-09',\n",
    "                        'end_time': '2011-06-13'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "API(ex_train_fridge)\n",
    "\n",
    "method = generate_method(debug=DEBUG, test=TEST)\n",
    "ex_train_microwave = {\n",
    "\n",
    "    'power': {\n",
    "        'mains': ['apparent', 'active'],\n",
    "        'appliance': ['apparent', 'active']\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "\n",
    "\n",
    "    'appliances': ['microwave'],\n",
    "    'methods': method,\n",
    "    'isState': False,\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-04-18',\n",
    "                        'end_time': '2011-05-08'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-17',\n",
    "                        'end_time': '2011-04-27'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-04-16',\n",
    "                        'end_time': '2011-05-23'\n",
    "                    }\n",
    "                }\n",
    "\n",
    "\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': path,\n",
    "                'buildings': {\n",
    "                    1: {\n",
    "                        'start_time': '2011-05-11',\n",
    "                        'end_time': '2011-05-24'\n",
    "                    },\n",
    "                    2: {\n",
    "                        'start_time': '2011-04-27',\n",
    "                        'end_time': '2011-05-22'\n",
    "                    },\n",
    "                    3: {\n",
    "                        'start_time': '2011-05-23',\n",
    "                        'end_time': '2011-05-30'\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "API(ex_train_microwave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
