{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cPickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "import tflib\n",
    "import tflib.cifar10\n",
    "import tflib.mnist\n",
    "import tflib.plot\n",
    "import tflib.save_images\n",
    "from datasets.utils import get_generators\n",
    "from models.base_model import AbstractModel\n",
    "from models.dataset_models import celeba_discriminator, celeba_generator\n",
    "from utils.misc import ensure_dir\n",
    "from utils.visualize import save_images_files\n",
    "from utils.config import load_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DefenseGANBase(AbstractModel):\n",
    "    def __init__(self, cfg=None, test_mode=False, verbose=True, **args):\n",
    "        default_attributes = ['dataset_name', 'batch_size', 'use_bn',\n",
    "                              'test_batch_size',\n",
    "                              'mode', 'gradient_penalty_lambda', 'train_iters',\n",
    "                              'critic_iters', 'latent_dim', 'net_dim',\n",
    "                              'input_transform_type',\n",
    "                              'debug', 'rec_iters', 'image_dim', 'rec_rr',\n",
    "                              'rec_lr', 'test_again', 'loss_type',\n",
    "                              'attribute']\n",
    "\n",
    "        self.dataset_name = None  # Name of the datsaet.\n",
    "        self.batch_size = 32  # Batch size for training the GAN.\n",
    "        self.use_bn = True  # Use batchnorm in the discriminator and generator.\n",
    "        self.test_batch_size = 20  # Batch size for test time.\n",
    "        self.mode = 'gp-wgan'  # The mode of training the GAN (default: gp-wgan).\n",
    "        self.gradient_penalty_lambda = 10.0  # Gradient penalty scale.\n",
    "        self.train_iters = 30000  # Number of training iterations.\n",
    "        self.critic_iters = 5  # Critic iterations per training step.\n",
    "        self.latent_dim = None  # The dimension of the latent vectors.\n",
    "        self.net_dim = None  # The complexity of network per layer.\n",
    "        self.input_transform_type = 0  # The normalization used for the inputs.\n",
    "        self.debug = False  # Debug info will be printed.\n",
    "        self.rec_iters = 200  # Number of reconstruction iterations.\n",
    "        self.image_dim = [None, None, None]  # [height, width, number of channels] of the output image.\n",
    "        self.rec_rr = 10  # Number of random restarts for the reconstruction\n",
    "\n",
    "        self.rec_lr = 10.0  # The reconstruction learning rate.\n",
    "        self.test_again = False  # If true, do not use the cached info for test phase.\n",
    "        self.attribute = 'gender'\n",
    "\n",
    "        # Should be implemented in the child classes.\n",
    "        self.discriminator_fn = None\n",
    "        self.generator_fn = None\n",
    "        self.train_data_gen = None\n",
    "\n",
    "        self.model_save_name = 'GAN.model'\n",
    "\n",
    "        super(DefenseGANBase, self).__init__(default_attributes,\n",
    "                                             test_mode=test_mode,\n",
    "                                             verbose=verbose, cfg=cfg, **args)\n",
    "        self.save_var_prefixes = ['Generator', 'Discriminator']\n",
    "        if self.mode == 'enc':\n",
    "            saver = tf.train.Saver(\n",
    "                var_list=self.generator_vars + self.enc_params)\n",
    "        else:\n",
    "            saver = tf.train.Saver(var_list=self.generator_vars)\n",
    "        self.load_generator = lambda ckpt_path=None: self.load(\n",
    "            checkpoint_dir=ckpt_path, saver=saver)\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _build_generator_discriminator(self):\n",
    "        \"\"\"Creates the generator and discriminator graph per dataset.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        \"\"\"Loads the dataset.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _build(self):\n",
    "        \"\"\"Builds the computation graph.\"\"\"\n",
    "\n",
    "        assert (self.batch_size % self.rec_rr) == 0, 'Batch size ' \\\n",
    "                                                     'should be ' \\\n",
    "                                                     'divisable by ' \\\n",
    "                                                     'random restart'\n",
    "        self.test_batch_size = self.batch_size\n",
    "\n",
    "        # Defining batch_size in input placeholders is inevitable at least\n",
    "        # for now, because the z vectors are Tensorflow variables.\n",
    "        self.real_data_pl = tf.placeholder(\n",
    "            tf.float32, shape=[self.batch_size] + self.image_dim,\n",
    "        )\n",
    "        self.real_data_test_pl = tf.placeholder(\n",
    "            tf.float32, shape=[self.test_batch_size] + self.image_dim,\n",
    "        )\n",
    "\n",
    "        self.input_pl_transform()\n",
    "        self._build_generator_discriminator()\n",
    "\n",
    "        self.fake_data = self.generator_fn()\n",
    "\n",
    "        self.disc_real = self.discriminator_fn(self.real_data)\n",
    "\n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "            sc = tf.get_variable_scope()\n",
    "            sc.reuse_variables()\n",
    "            self.disc_fake = self.discriminator_fn(self.fake_data)\n",
    "\n",
    "            self.generator_vars = slim.get_variables('Generator')\n",
    "            self.discriminator_vars = slim.get_variables('Discriminator')\n",
    "\n",
    "            self.fixed_noise = tf.constant(\n",
    "                np.random.normal(size=(128, self.latent_dim)).astype(\n",
    "                    'float32'))\n",
    "            self.fixed_noise_samples = self.generator_fn(self.fixed_noise,\n",
    "                                                         is_training=False)\n",
    "\n",
    "    def _loss(self):\n",
    "        \"\"\"Builds the loss part of the graph..\"\"\"\n",
    "        self.discriminator_cost = 0\n",
    "        self.generator_cost = 0\n",
    "\n",
    "        if self.mode == 'wgan':\n",
    "            self.generator_cost = -tf.reduce_mean(self.disc_fake)\n",
    "            self.discriminator_cost = tf.reduce_mean(\n",
    "                self.disc_fake) - tf.reduce_mean(\n",
    "                self.disc_real)\n",
    "\n",
    "            self.gen_train_op = tf.train.RMSPropOptimizer(\n",
    "                learning_rate=5e-5\n",
    "            ).minimize(self.generator_cost, var_list=self.generator_vars)\n",
    "            self.disc_train_op = tf.train.RMSPropOptimizer(\n",
    "                learning_rate=5e-5\n",
    "            ).minimize(self.discriminator_cost,\n",
    "                       var_list=self.discriminator_vars)\n",
    "\n",
    "            clip_ops = []\n",
    "            for var in tflib.params_with_name('Discriminator'):\n",
    "                clip_bounds = [-.01, .01]\n",
    "                clip_ops.append(\n",
    "                    tf.assign(\n",
    "                        var,\n",
    "                        tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])\n",
    "                    )\n",
    "                )\n",
    "            self.clip_disc_weights = tf.group(*clip_ops)\n",
    "\n",
    "        elif self.mode == 'wgan-gp':\n",
    "            self.generator_cost = -tf.reduce_mean(self.disc_fake)\n",
    "            disc_cost = tf.reduce_mean(self.disc_fake) - tf.reduce_mean(\n",
    "                self.disc_real)\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[self.batch_size, 1, 1, 1],\n",
    "                minval=0.,\n",
    "                maxval=1.\n",
    "            )\n",
    "            differences = self.fake_data - self.real_data\n",
    "            interpolates = self.real_data + (alpha * differences)\n",
    "            gradients = \\\n",
    "                tf.gradients(self.discriminator_fn(interpolates),\n",
    "                             [interpolates])[0]\n",
    "            slopes = tf.sqrt(\n",
    "                tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n",
    "            self.discriminator_cost = disc_cost + \\\n",
    "                                      self.gradient_penalty_lambda * \\\n",
    "                                      gradient_penalty\n",
    "\n",
    "            self.gen_train_op = tf.train.AdamOptimizer(\n",
    "                learning_rate=1e-4,\n",
    "                beta1=0.5,\n",
    "                beta2=0.9\n",
    "            ).minimize(self.generator_cost, var_list=self.generator_vars)\n",
    "            self.disc_train_op = tf.train.AdamOptimizer(\n",
    "                learning_rate=1e-4,\n",
    "                beta1=0.5,\n",
    "                beta2=0.9\n",
    "            ).minimize(self.discriminator_cost,\n",
    "                       var_list=self.discriminator_vars)\n",
    "\n",
    "            self.clip_disc_weights = None\n",
    "\n",
    "        elif self.mode == 'dcgan':\n",
    "            self.generator_cost = tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    self.disc_fake,\n",
    "                    tf.ones_like(self.disc_fake)\n",
    "                ))\n",
    "\n",
    "            disc_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                self.disc_fake,\n",
    "                tf.zeros_like(self.disc_fake)\n",
    "            ))\n",
    "            disc_cost += tf.reduce_mean(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    self.disc_real,\n",
    "                    tf.ones_like(self.disc_real)\n",
    "                ))\n",
    "            self.discriminator_cost = disc_cost / 2.\n",
    "\n",
    "            self.gen_train_op = tf.train.AdamOptimizer(\n",
    "                learning_rate=2e-4,\n",
    "                beta1=0.5\n",
    "            ).minimize(self.generator_cost, var_list=self.generator_vars)\n",
    "            self.disc_train_op = tf.train.AdamOptimizer(\n",
    "                learning_rate=2e-4,\n",
    "                beta1=0.5\n",
    "            ).minimize(disc_cost, var_list=self.discriminator_vars)\n",
    "\n",
    "            self.clip_disc_weights = None\n",
    "\n",
    "    def _generate_image(self, training_iter):\n",
    "        \"\"\"Generates a set of sample images from fixed noise and log them in\n",
    "            the `debug` directory.\n",
    "\n",
    "        Args:\n",
    "            training_iter: The training iteration to include as part of the\n",
    "                filename.\n",
    "        \"\"\"\n",
    "        samples = self.sess.run(self.fixed_noise_samples)\n",
    "        tflib.save_images.save_images(\n",
    "            samples.reshape((128, 28, 28)),\n",
    "            os.path.join(self.checkpoint_dir.replace('output', 'debug'),\n",
    "                         'samples_{}.png'.format(training_iter))\n",
    "        )\n",
    "\n",
    "    def _inf_train_gen(self):\n",
    "        \"\"\"A generator function for input training data.\"\"\"\n",
    "        while True:\n",
    "            for images, targets in self.train_data_gen():\n",
    "                yield images\n",
    "\n",
    "    def train(self, phase=None):\n",
    "        \"\"\"Trains the GAN model.\"\"\"\n",
    "\n",
    "        sess = self.sess\n",
    "        self.initialize_uninitialized()\n",
    "\n",
    "        gen = self._inf_train_gen()\n",
    "        could_load = self.load(checkpoint_dir=self.checkpoint_dir,\n",
    "                               prefixes=self.save_var_prefixes)\n",
    "        if could_load:\n",
    "            print('[*] Model loaded.')\n",
    "        else:\n",
    "            print('[#] No model found')\n",
    "\n",
    "        cur_iter = self.sess.run(self.global_step)\n",
    "        max_train_iters = self.train_iters\n",
    "        step_inc = self.global_step_inc\n",
    "        global_step = self.global_step\n",
    "        ckpt_dir = self.checkpoint_dir\n",
    "\n",
    "        for iteration in xrange(cur_iter, max_train_iters):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if iteration > 0 and 'gan' in self.mode and phase is None:\n",
    "                _ = sess.run(self.gen_train_op,\n",
    "                             feed_dict={self.is_training: 1})\n",
    "\n",
    "            if self.mode == 'dcgan':\n",
    "                disc_iters = 1\n",
    "            else:\n",
    "                disc_iters = self.critic_iters\n",
    "\n",
    "            for i in xrange(disc_iters):\n",
    "                _data = gen.next()\n",
    "                _disc_cost, _ = sess.run(\n",
    "                    [self.discriminator_cost, self.disc_train_op],\n",
    "                    feed_dict={self.real_data_pl: _data,\n",
    "                               self.is_training: 1}\n",
    "                )\n",
    "                if self.clip_disc_weights is not None:\n",
    "                    _ = sess.run(self.clip_disc_weights)\n",
    "\n",
    "            tflib.plot.plot('{}/train disc cost'.format(self.debug_dir),\n",
    "                            _disc_cost)\n",
    "            tflib.plot.plot('{}/time'.format(self.debug_dir),\n",
    "                            time.time() - start_time)\n",
    "\n",
    "            # Calculate dev loss and generate samples every 100 iters.\n",
    "            if iteration % 100 == 5:\n",
    "                dev_disc_costs = []\n",
    "                dev_ctr = 0\n",
    "                for images, _ in self.dev_gen():\n",
    "                    dev_ctr += 1\n",
    "                    if dev_ctr > 20:\n",
    "                        break\n",
    "                    _dev_disc_cost = sess.run(\n",
    "                        self.discriminator_cost,\n",
    "                        feed_dict={self.real_data_pl: images,\n",
    "                                   self.is_training: 0}\n",
    "                    )\n",
    "                    dev_disc_costs.append(_dev_disc_cost)\n",
    "                tflib.plot.plot('{}/dev disc cost'.format(self.debug_dir),\n",
    "                                np.mean(dev_disc_costs))\n",
    "                self.generate_image(iteration)\n",
    "\n",
    "            # Write logs every 100 iters\n",
    "\n",
    "            if (iteration < 5) or (iteration % 100 == 99):\n",
    "                tflib.plot.flush()\n",
    "\n",
    "            self.sess.run(step_inc)\n",
    "            if iteration % 500 == 499:\n",
    "                self.save(checkpoint_dir=ckpt_dir, global_step=global_step)\n",
    "\n",
    "            tflib.plot.tick()\n",
    "\n",
    "        self.save(checkpoint_dir=ckpt_dir, global_step=global_step)\n",
    "\n",
    "        self.close_session()\n",
    "\n",
    "    def reconstruct(\n",
    "        self, images, batch_size=None, back_prop=True,\n",
    "        reconstructor_id=0, z_init_val=None):\n",
    "        \"\"\"Creates the reconstruction op for Defense-GAN.\n",
    "\n",
    "        Args:\n",
    "            X: Input tensor\n",
    "\n",
    "        Returns:\n",
    "            The `tf.Tensor` of the reconstructed input.\n",
    "        \"\"\"\n",
    "\n",
    "        # Batch size is needed because the latent codes are `tf.Variable`s and\n",
    "        # need to be built into TF's static graph beforehand.\n",
    "\n",
    "        batch_size = batch_size if batch_size else self.test_batch_size\n",
    "\n",
    "        x_shape = images.get_shape().as_list()\n",
    "        x_shape[0] = batch_size\n",
    "\n",
    "        # Repeat images self.rec_rr times to handle random restarts in\n",
    "        # parallel.\n",
    "        images_tiled_rr = tf.reshape(\n",
    "            images, [x_shape[0], np.prod(x_shape[1:])])\n",
    "        images_tiled_rr = tf.tile(images_tiled_rr, [1, self.rec_rr])\n",
    "        images_tiled_rr = tf.reshape(\n",
    "            images_tiled_rr, [x_shape[0] * self.rec_rr] + x_shape[1:])\n",
    "\n",
    "        # Number of reconstruction iterations.\n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "            rec_iter_const = tf.get_variable(\n",
    "                'rec_iter_{}'.format(reconstructor_id),\n",
    "                initializer=tf.constant(0),\n",
    "                trainable=False, dtype=tf.int32,\n",
    "                collections=[tf.GraphKeys.LOCAL_VARIABLES],\n",
    "            )\n",
    "            # The latent variables.\n",
    "            z_hat = tf.get_variable(\n",
    "                'z_hat_rec_{}'.format(reconstructor_id),\n",
    "                shape=[batch_size * self.rec_rr, self.latent_dim],\n",
    "                dtype=tf.float32,\n",
    "                initializer=tf.random_normal_initializer(\n",
    "                    stddev=np.sqrt(1.0 / self.latent_dim)),\n",
    "                collections=[tf.GraphKeys.LOCAL_VARIABLES]\n",
    "            )\n",
    "\n",
    "        # Learning rate for reconstruction.\n",
    "        rec_lr_op_from_const = self.get_learning_rate(init_lr=self.rec_lr,\n",
    "                                                      global_step=rec_iter_const,\n",
    "                                                      decay_mult=0.1,\n",
    "                                                      decay_iter=np.ceil(\n",
    "                                                          self.rec_iters *\n",
    "                                                          0.8).astype(\n",
    "                                                          np.int32))\n",
    "\n",
    "        # The optimizer.\n",
    "        rec_online_optimizer = tf.train.MomentumOptimizer(\n",
    "            learning_rate=rec_lr_op_from_const, momentum=0.7,\n",
    "            name='rec_optimizer')\n",
    "\n",
    "\n",
    "\n",
    "        init_z = tf.no_op()\n",
    "        if z_init_val is not None:\n",
    "            init_z = tf.assign(z_hat, z_init_val)\n",
    "\n",
    "        z_hats_recs = self.generator_fn(z_hat, is_training=False)\n",
    "        num_dim = len(z_hats_recs.get_shape())\n",
    "        axes = range(1, num_dim)\n",
    "\n",
    "        image_rec_loss = tf.reduce_mean(\n",
    "            tf.square(z_hats_recs - images_tiled_rr),\n",
    "            axis=axes)\n",
    "        rec_loss = tf.reduce_sum(image_rec_loss)\n",
    "        rec_online_optimizer.minimize(rec_loss, var_list=[z_hat])\n",
    "\n",
    "\n",
    "        def rec_body(i, *args):\n",
    "            z_hats_recs = self.generator_fn(z_hat, is_training=False)\n",
    "            image_rec_loss = tf.reduce_mean(\n",
    "                tf.square(z_hats_recs - images_tiled_rr),\n",
    "                axis=axes)\n",
    "            rec_loss = tf.reduce_sum(image_rec_loss)\n",
    "\n",
    "            train_op = rec_online_optimizer.minimize(rec_loss,\n",
    "                                                     var_list=[z_hat])\n",
    "\n",
    "            return tf.tuple(\n",
    "                [tf.add(i, 1), rec_loss, image_rec_loss, z_hats_recs],\n",
    "                control_inputs=[train_op])\n",
    "\n",
    "        rec_iter_condition = lambda i, *args: tf.less(i, self.rec_iters)\n",
    "        for opt_var in rec_online_optimizer.variables():\n",
    "            tf.add_to_collection(\n",
    "                tf.GraphKeys.LOCAL_VARIABLES,\n",
    "                opt_var,\n",
    "            )\n",
    "\n",
    "        with tf.control_dependencies([init_z]):\n",
    "            online_rec_iter, online_rec_loss, online_image_rec_loss, \\\n",
    "            all_z_recs = tf.while_loop(\n",
    "                rec_iter_condition,\n",
    "                rec_body,\n",
    "                [rec_iter_const, rec_loss, image_rec_loss, z_hats_recs]\n",
    "                , parallel_iterations=1, back_prop=back_prop,\n",
    "                swap_memory=False)\n",
    "            final_recs = []\n",
    "            for i in range(batch_size):\n",
    "                ind = i * self.rec_rr + tf.argmin(\n",
    "                    online_image_rec_loss[\n",
    "                    i * self.rec_rr:(i + 1) * self.rec_rr\n",
    "                    ],\n",
    "                    axis=0)\n",
    "                final_recs.append(all_z_recs[tf.cast(ind, tf.int32)])\n",
    "\n",
    "            online_rec = tf.stack(final_recs)\n",
    "\n",
    "            return tf.reshape(online_rec, x_shape)\n",
    "\n",
    "    def reconstruct_dataset(self, ckpt_path=None, max_num=-1, max_num_load=-1):\n",
    "        \"\"\"Reconstructs the images of the config's dataset with the generator.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.initialized:\n",
    "            self.load_generator(ckpt_path=ckpt_path)\n",
    "\n",
    "        splits = ['train', 'dev', 'test']\n",
    "\n",
    "        rec = self.reconstruct(self.real_data_test)\n",
    "\n",
    "        self.sess.run(tf.local_variables_initializer())\n",
    "        rets = {}\n",
    "\n",
    "        for split in splits:\n",
    "            if max_num > 0:\n",
    "                output_dir = os.path.join(self.checkpoint_dir,\n",
    "                                          'recs_rr{:d}_lr{:.5f}_'\n",
    "                                          'iters{:d}_num{:d}'.format(\n",
    "                                              self.rec_rr, self.rec_lr,\n",
    "                                              self.rec_iters, max_num),\n",
    "                                          split)\n",
    "            else:\n",
    "                output_dir = os.path.join(self.checkpoint_dir,\n",
    "                                          'recs_rr{:d}_lr{:.5f}_'\n",
    "                                          'iters{:d}'.format(\n",
    "                                              self.rec_rr, self.rec_lr,\n",
    "                                              self.rec_iters), split)\n",
    "\n",
    "            if self.debug:\n",
    "                output_dir += '_debug'\n",
    "\n",
    "            ensure_dir(output_dir)\n",
    "            feats_path = os.path.join(output_dir, 'feats.pkl'.format(split))\n",
    "            could_load = False\n",
    "            try:\n",
    "                if os.path.exists(feats_path) and not self.test_again:\n",
    "                    with open(feats_path) as f:\n",
    "                        all_recs = cPickle.load(f)\n",
    "                        could_load = True\n",
    "                        print('[#] Successfully loaded features.')\n",
    "                else:\n",
    "                    all_recs = []\n",
    "            except Exception as e:\n",
    "                all_recs = []\n",
    "                print('[#] Exception loading features {}'.format(str(e)))\n",
    "\n",
    "            gen_func = getattr(self, '{}_gen_test'.format(split))\n",
    "            all_targets = []\n",
    "            orig_imgs = []\n",
    "            ctr = 0\n",
    "            sti = time.time()\n",
    "\n",
    "            # Pickle files per reconstructed image.\n",
    "            pickle_out_dir = os.path.join(output_dir, 'pickles')\n",
    "            ensure_dir(pickle_out_dir)\n",
    "            single_feat_path_template = os.path.join(pickle_out_dir,\n",
    "                                                     'rec_{:07d}_l{}.pkl')\n",
    "\n",
    "            for images, targets in gen_func():\n",
    "                batch_size = len(images)\n",
    "                im_paths = [\n",
    "                    single_feat_path_template.format(ctr * batch_size + i,\n",
    "                                                     targets[i]) for i in\n",
    "                    range(batch_size)]\n",
    "\n",
    "                mn = max(max_num, max_num_load)\n",
    "\n",
    "                if (mn > -1 and ctr * (len(images)) > mn) or (\n",
    "                    self.debug and ctr > 2):\n",
    "                    break\n",
    "\n",
    "                batch_could_load = not self.test_again\n",
    "                batch_rec_list = []\n",
    "\n",
    "                for imp in im_paths: # Load per image cached files.\n",
    "                    try:\n",
    "                        with open(imp) as f:\n",
    "                            loaded_rec = cPickle.load(f)\n",
    "                            batch_rec_list.append(loaded_rec)\n",
    "                            # print('[-] Loaded batch {}'.format(ctr))\n",
    "                    except:\n",
    "                        batch_could_load = False\n",
    "                        break\n",
    "\n",
    "                if batch_could_load and not could_load:\n",
    "                    recs = np.stack(batch_rec_list)\n",
    "                    all_recs.append(recs)\n",
    "\n",
    "                if not (could_load or batch_could_load):\n",
    "                    self.sess.run(tf.local_variables_initializer())\n",
    "                    recs = self.sess.run(\n",
    "                        rec, feed_dict={self.real_data_test_pl: images},\n",
    "                    )\n",
    "                    print('[#] t:{:.2f} batch: {:d} '.format(time.time() - sti,\n",
    "                                                             ctr))\n",
    "                    all_recs.append(recs)\n",
    "                else:\n",
    "                    print('[*] could load batch: {:d}'.format(ctr))\n",
    "\n",
    "                if not batch_could_load and not could_load:\n",
    "                    for i in range(len(recs)):\n",
    "                        pkl_path = im_paths[i]\n",
    "                        with open(pkl_path, 'w') as f:\n",
    "                            cPickle.dump(recs[i], f,\n",
    "                                         protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "                            #print('[*] Saved reconstruction for {}'.format(pkl_path))\n",
    "\n",
    "                all_targets.append(targets)\n",
    "\n",
    "                orig_transformed = self.sess.run(self.real_data_test,\n",
    "                                                 feed_dict={\n",
    "                                                     self.real_data_test_pl:\n",
    "                                                         images})\n",
    "\n",
    "                orig_imgs.append(orig_transformed)\n",
    "                ctr += 1\n",
    "            if not could_load:\n",
    "                all_recs = np.concatenate(all_recs)\n",
    "                all_recs = all_recs.reshape([-1] + self.image_dim)\n",
    "\n",
    "            orig_imgs = np.concatenate(orig_imgs).reshape(\n",
    "                [-1] + self.image_dim)\n",
    "            all_targets = np.concatenate(all_targets)\n",
    "\n",
    "            if self.debug:\n",
    "                save_images_files(all_recs,\n",
    "                                  output_dir=output_dir, labels=all_targets)\n",
    "                save_images_files(\n",
    "                    (orig_imgs + min(0, orig_imgs.min()) / (\n",
    "                        orig_imgs.max() - min(0, orig_imgs.min()))),\n",
    "                    output_dir=output_dir,\n",
    "                    labels=all_targets, postfix='_orig')\n",
    "\n",
    "            rets[split] = [all_recs, all_targets, orig_imgs]\n",
    "\n",
    "        return rets\n",
    "\n",
    "    def generate_image(self, iteration=None):\n",
    "        \"\"\"Generates a fixed noise for visualization of generation output.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def test_batch(self):\n",
    "        \"\"\"Tests the image batch generator.\"\"\"\n",
    "        output_dir = os.path.join(self.debug_dir, 'test_batch')\n",
    "        ensure_dir(output_dir)\n",
    "\n",
    "        img, target = self.train_data_gen().next()\n",
    "        img = img.reshape([self.batch_size] + self.image_dim)\n",
    "        save_images_files(img / 255.0, output_dir=output_dir,\n",
    "                          labels=target)\n",
    "\n",
    "    def save_ds(self):\n",
    "        \"\"\"Reconstructs the images of the config's dataset with the\n",
    "        generator.\"\"\"\n",
    "        if self.dataset_name == 'cifar':\n",
    "            splits = ['train', 'dev']\n",
    "        else:\n",
    "            splits = ['train', 'dev', 'test']\n",
    "        for split in splits:\n",
    "            output_dir = os.path.join('data', 'cache',\n",
    "                                      '{}_pkl'.format(self.dataset_name),\n",
    "                                      split)\n",
    "            if self.debug:\n",
    "                output_dir += '_debug'\n",
    "\n",
    "            ensure_dir(output_dir)\n",
    "            orig_imgs_pkl_path = os.path.join(output_dir,\n",
    "                                              'feats.pkl'.format(split))\n",
    "\n",
    "            if os.path.exists(orig_imgs_pkl_path) and not self.test_again:\n",
    "                with open(orig_imgs_pkl_path) as f:\n",
    "                    all_recs = cPickle.load(f)\n",
    "                    could_load = True\n",
    "                    print('[#] Dataset is already saved.')\n",
    "                    return\n",
    "\n",
    "            gen_func = getattr(self, '{}_gen_test'.format(split))\n",
    "            all_targets = []\n",
    "            orig_imgs = []\n",
    "            ctr = 0\n",
    "            for images, targets in gen_func():\n",
    "                ctr += 1\n",
    "                transformed_images = self.sess.run(self.real_data_test,\n",
    "                                                   feed_dict={\n",
    "                                                       self.real_data_test_pl:\n",
    "                                                           images})\n",
    "                orig_imgs.append(transformed_images)\n",
    "                all_targets.append(targets)\n",
    "            orig_imgs = np.concatenate(orig_imgs).reshape(\n",
    "                [-1] + self.image_dim)\n",
    "            all_targets = np.concatenate(all_targets)\n",
    "            with open(orig_imgs_pkl_path, 'w') as f:\n",
    "                cPickle.dump(orig_imgs, f, cPickle.HIGHEST_PROTOCOL)\n",
    "                cPickle.dump(all_targets, f, cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "class CelebADefenseGAN(DefenseGANBase):\n",
    "    def _build_generator_discriminator(self):\n",
    "        self.discriminator_fn = lambda x: celeba_discriminator(\n",
    "            x,\n",
    "            use_bn=self.use_bn,\n",
    "            net_dim=self.net_dim,\n",
    "            is_training=self.is_training,\n",
    "            stats_iter=self.global_step,\n",
    "            data_format='NHWC')\n",
    "        self.generator_fn = lambda z=None, is_training=self.is_training: \\\n",
    "            celeba_generator(\n",
    "                self.batch_size,\n",
    "                use_bn=self.use_bn,\n",
    "                net_dim=self.net_dim,\n",
    "                is_training=is_training,\n",
    "                latent_dim=self.latent_dim,\n",
    "                output_dim=self.image_dim,\n",
    "                noise=z,\n",
    "                stats_iter=self.global_step)\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        self.train_data_gen, self.dev_gen, self.test_gen = get_generators(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            attribute=self.attribute)\n",
    "        self.train_gen_test, self.dev_gen_test, self.test_gen_test = \\\n",
    "            get_generators(\n",
    "                self.dataset_name,\n",
    "                self.test_batch_size,\n",
    "                randomize=False,\n",
    "                attribute=self.attribute)\n",
    "        self.test_decoder_images, _ = self.dev_gen().next()\n",
    "\n",
    "    def generate_image(self, training_iter):\n",
    "        samples = self.sess.run(self.fixed_noise_samples)\n",
    "        debug_dir = self.checkpoint_dir.replace('output', 'debug')\n",
    "        ensure_dir(debug_dir)\n",
    "        tflib.save_images.save_images(\n",
    "            (samples.reshape((len(samples), 64, 64, 3)) + 1) / (2.0),\n",
    "            os.path.join(debug_dir, 'samples_{}.png'.format(training_iter))\n",
    "        )\n",
    "\n",
    "    def imsave_transform(self, imgs): # to re transform the images form [-1,1] to [0,1]\n",
    "        imgs = (imgs + 1.0) / 2\n",
    "        imgs[imgs < 0] = 0.0\n",
    "        imgs[imgs > 1] = 1.0\n",
    "        return imgs\n",
    "\n",
    "    def input_transform(self, images): #transform the images form [0,255] to [-1,1]\n",
    "        return 2 * ((tf.cast(images, tf.float32) / 255.) - .5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = CelebADefenseGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config('experiments/cfgs/gans/celeba.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] CelebADefenseGAN.dataset_name is set to celeba.\n",
      "[#] CelebADefenseGAN.batch_size is set to 50.\n",
      "[#] CelebADefenseGAN.use_bn is set to False.\n",
      "[#] CelebADefenseGAN.test_batch_size is set to 20.\n",
      "[#] CelebADefenseGAN.mode is set to wgan-gp.\n",
      "[#] CelebADefenseGAN.gradient_penalty_lambda is set to 10.0.\n",
      "[#] CelebADefenseGAN.train_iters is set to 200000.\n",
      "[#] CelebADefenseGAN.critic_iters is set to 5.\n",
      "[#] CelebADefenseGAN.latent_dim is set to 128.\n",
      "[#] CelebADefenseGAN.net_dim is set to 64.\n",
      "[#] CelebADefenseGAN.input_transform_type is set to 0.\n",
      "[-] CelebADefenseGAN.debug is not set.\n",
      "[#] CelebADefenseGAN.debug is set to None.\n",
      "[#] CelebADefenseGAN.rec_iters is set to 200.\n",
      "[#] CelebADefenseGAN.image_dim is set to [64, 64, 3].\n",
      "[#] CelebADefenseGAN.rec_rr is set to 2.\n",
      "[#] CelebADefenseGAN.rec_lr is set to 10.0.\n",
      "[-] CelebADefenseGAN.test_again is not set.\n",
      "[#] CelebADefenseGAN.test_again is set to None.\n",
      "[-] CelebADefenseGAN.loss_type is not set.\n",
      "[#] CelebADefenseGAN.loss_type is set to None.\n",
      "[#] CelebADefenseGAN.attribute is set to gender.\n",
      "[-] CelebADefenseGAN.tensorboard_log is not set.\n",
      "[#] CelebADefenseGAN.tensorboard_log is set to None.\n",
      "[#] CelebADefenseGAN.output_dir is set to output.\n",
      "[#] CelebADefenseGAN.num_gpus is set to 1.\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(cfg=cfg, test_mode=not True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] not init: global_step:0\n",
      "[!] not init: Generator.Input/Generator.Input.W:0\n",
      "[!] not init: Generator.Input/Generator.Input.b:0\n",
      "[!] not init: Generator.2/Generator.2.Filters:0\n",
      "[!] not init: Generator.2/Generator.2.Biases:0\n",
      "[!] not init: Generator.3/Generator.3.Filters:0\n",
      "[!] not init: Generator.3/Generator.3.Biases:0\n",
      "[!] not init: Generator.5/Generator.5.Filters:0\n",
      "[!] not init: Generator.5/Generator.5.Biases:0\n",
      "[!] not init: Generator.6/Generator.6.Filters:0\n",
      "[!] not init: Generator.6/Generator.6.Biases:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Filters:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Biases:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Filters:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Biases:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Filters:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Biases:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.W:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.b:0\n",
      "[!] not init: beta1_power:0\n",
      "[!] not init: beta2_power:0\n",
      "[!] not init: Generator.Input/Generator.Input.W/Adam:0\n",
      "[!] not init: Generator.Input/Generator.Input.W/Adam_1:0\n",
      "[!] not init: Generator.Input/Generator.Input.b/Adam:0\n",
      "[!] not init: Generator.Input/Generator.Input.b/Adam_1:0\n",
      "[!] not init: Generator.2/Generator.2.Filters/Adam:0\n",
      "[!] not init: Generator.2/Generator.2.Filters/Adam_1:0\n",
      "[!] not init: Generator.2/Generator.2.Biases/Adam:0\n",
      "[!] not init: Generator.2/Generator.2.Biases/Adam_1:0\n",
      "[!] not init: Generator.3/Generator.3.Filters/Adam:0\n",
      "[!] not init: Generator.3/Generator.3.Filters/Adam_1:0\n",
      "[!] not init: Generator.3/Generator.3.Biases/Adam:0\n",
      "[!] not init: Generator.3/Generator.3.Biases/Adam_1:0\n",
      "[!] not init: Generator.5/Generator.5.Filters/Adam:0\n",
      "[!] not init: Generator.5/Generator.5.Filters/Adam_1:0\n",
      "[!] not init: Generator.5/Generator.5.Biases/Adam:0\n",
      "[!] not init: Generator.5/Generator.5.Biases/Adam_1:0\n",
      "[!] not init: Generator.6/Generator.6.Filters/Adam:0\n",
      "[!] not init: Generator.6/Generator.6.Filters/Adam_1:0\n",
      "[!] not init: Generator.6/Generator.6.Biases/Adam:0\n",
      "[!] not init: Generator.6/Generator.6.Biases/Adam_1:0\n",
      "[!] not init: beta1_power_1:0\n",
      "[!] not init: beta2_power_1:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Filters/Adam:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Filters/Adam_1:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Biases/Adam:0\n",
      "[!] not init: Discriminator.1/Discriminator.1.Biases/Adam_1:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Filters/Adam:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Filters/Adam_1:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Biases/Adam:0\n",
      "[!] not init: Discriminator.2/Discriminator.2.Biases/Adam_1:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Filters/Adam:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Filters/Adam_1:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Biases/Adam:0\n",
      "[!] not init: Discriminator.3/Discriminator.3.Biases/Adam_1:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.W/Adam:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.W/Adam_1:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.b/Adam:0\n",
      "[!] not init: Discriminator.Output/Discriminator.Output.b/Adam_1:0\n",
      "[!] Saver is not initialized\n",
      "[#] Initializing it with variable prefixes: Generator Discriminator \n",
      " [-] Reading checkpoints... output/gans/celeba \n",
      "INFO:tensorflow:Restoring parameters from output/gans/celeba/GAN.model-144000\n",
      " [*] Checkpoint is read successfully from output/gans/celeba\n",
      "[*] Model loaded.\n",
      "iter 0\tdebug/gans/celeba/train disc cost\t-1.1496155262\tdebug/gans/celeba/time\t28.5495729446\n",
      "iter 1\tdebug/gans/celeba/train disc cost\t0.736635088921\tdebug/gans/celeba/time\t9.72410082817\n",
      "iter 2\tdebug/gans/celeba/train disc cost\t-6.96059036255\tdebug/gans/celeba/time\t7.67227983475\n",
      "iter 3\tdebug/gans/celeba/train disc cost\t-4.7713804245\tdebug/gans/celeba/time\t8.19394803047\n",
      "iter 4\tdebug/gans/celeba/train disc cost\t-11.7092056274\tdebug/gans/celeba/time\t7.49966597557\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8827ae40166e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c8ef975ceb3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, phase)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 _disc_cost, _ = sess.run(\n\u001b[1;32m    245\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_train_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c8ef975ceb3c>\u001b[0m in \u001b[0;36m_inf_train_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"A generator function for input training data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bibinbins/defensegan/datasets/utils.pyc\u001b[0m in \u001b[0;36mget_gen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             image_batch, label_batch = ds.images[\n\u001b[0;32m---> 57\u001b[0;31m                                        i:i + batch_size], \\\n\u001b[0m\u001b[1;32m     58\u001b[0m                                        \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bibinbins/defensegan/datasets/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             return np.array(\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             )\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bibinbins/defensegan/datasets/dataset.pyc\u001b[0m in \u001b[0;36m_get_image\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Read image at image_path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Return transformed image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/numpy/lib/utils.pyc\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
