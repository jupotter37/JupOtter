{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXC RB simulation\n",
    "\n",
    "Luca Mechelli, Tim Keil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~\n",
    "# This file is part of the paper:\n",
    "#\n",
    "#  \"A NON-CONFORMING DUAL APPROACH FOR ADAPTIVE TRUST-REGION REDUCED BASIS\n",
    "#           APPROXIMATION OF PDE-CONSTRAINED OPTIMIZATION\"\n",
    "#\n",
    "#   https://github.com/TiKeil/NCD-corrected-TR-RB-approach-for-pde-opt\n",
    "#\n",
    "# Copyright 2019-2020 all developers. All rights reserved.\n",
    "# License: Licensed as BSD 2-Clause License (http://opensource.org/licenses/BSD-2-Clause)\n",
    "# ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '../../'\n",
    "sys.path.append(path)\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pymor.basic import *\n",
    "set_log_levels({'pymor': 'WARN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymor.core.logger import set_log_levels, getLogger\n",
    "set_log_levels({'pymor': 'ERROR',\n",
    "                'distributed_adaptive_discretizations': 'DEBUG',\n",
    "                'notebook': 'INFO'})\n",
    "logger = getLogger('notebook.notebook')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "data_path = '../../../EXC_data'\n",
    "# domain of interest\n",
    "bounding_box = [[0,0],[2,1]]\n",
    "domain_of_interest = BitmapFunction('{}/Domain_of_interest.png'.format(data_path), range=[1,0], bounding_box=bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Check whether you have not used coefficient_expressions for the later experiment\n",
      "desired_parameter:  None\n",
      "I am using the corrected functional!!\n",
      "I am using the corrected gradient!!\n",
      "{heaters: [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], walls: [0.049999999999999996, 0.049999999999999996, 0.049999999999999996]}\n",
      "my product is fixed_energy\n"
     ]
    }
   ],
   "source": [
    "from pdeopt.problems import EXC_problem, set_input_dict\n",
    "from pdeopt.discretizer import discretize_quadratic_pdeopt_stationary_cg\n",
    "\n",
    "parametric_quantities = {'walls': [1,4,9], 'windows': [], 'doors': [], 'heaters': [1,3,5,6,7,8,9]}\n",
    "inactive_quantities = {'removed_walls': [], 'open_windows': [], 'open_doors': [1,2,3,4,5,6,7,10], 'active_heaters': []}\n",
    "summed_quantities = {'walls': [[1,2,3,8],[4,5,6,7]], 'windows': [], 'doors': [], 'heaters': [[1,2],[3,4],[9,10,11,12]]}\n",
    "\n",
    "coefficient_expressions = None\n",
    "\n",
    "parameters_in_q = True\n",
    "input_dict = set_input_dict(parametric_quantities, inactive_quantities, coefficient_expressions, summed_quantities, parameters_in_q,\n",
    "                            ac=0.5, owc=[0.025,0.1], iwc= [0.025,0.1], idc=[0.005], wc=[0.0005], ht=[0,100],\n",
    "                                    owc_c=0.001,  iwc_c= 0.025,     idc_c=0.01,  wc_c=0.025,  ht_c=80)\n",
    "\n",
    "\n",
    "parameter_scaling = False\n",
    "u_out = 5\n",
    "\n",
    "problem, parameter_scales = EXC_problem(input_dict, summed_quantities, outside_temperature=u_out, #, q_inverse=0.0001\n",
    "                                        data_path = data_path,parameters_in_q=parameters_in_q, \n",
    "                                        parameter_scaling=parameter_scaling,\n",
    "                                        coefficient_expressions=coefficient_expressions)\n",
    "\n",
    "u_d = 18  \n",
    "mu_d = None \n",
    "print('desired_parameter: ', mu_d)\n",
    "\n",
    "sigma_d = 100\n",
    "weights = {'walls': [0.5,0.25,0.05], 'doors': 1, 'heaters': [0.002,0.002,0.001,0.001,0.001,0.001,0.004], 'windows': 1, 'state': sigma_d}\n",
    "\n",
    "diameter = np.sqrt(2)/200.\n",
    "opt_fom, data, mu_bar = discretize_quadratic_pdeopt_stationary_cg(problem, diameter, weights, parameter_scales, \n",
    "                                                          domain_of_interest, desired_temperature=u_d, \n",
    "                                                          mu_for_u_d=mu_d, mu_for_tikhonov=mu_d,\n",
    "                                                          parameters_in_q=parameters_in_q, product='fixed_energy',\n",
    "                                                          use_corrected_gradient= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information on the grid:\n",
      "Rect-Grid on domain [0,2] x [0,1]\n",
      "x0-intervals: 400, x1-intervals: 200\n",
      "faces: 80000, edges: 160600, vertices: 80601\n"
     ]
    }
   ],
   "source": [
    "print('information on the grid:')\n",
    "print(data['grid'])\n",
    "\n",
    "N = 32\n",
    "validation_set_size = 100\n",
    "tau_global_RB_J = 5e-4\n",
    "tau_global_RB_DJ = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Model Order Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS-Greedy for non-corrected functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a simple RB basis for primal, dual and all sensitivities. For this, we start with an empty basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 0 and 0\n"
     ]
    }
   ],
   "source": [
    "params = []\n",
    "from pdeopt.model import build_initial_basis\n",
    "RBbasis, dual_RBbasis = build_initial_basis(opt_fom, params, build_sensitivities=False)\n",
    "\n",
    "from pdeopt.reductor import QuadraticPdeoptStationaryCoerciveReductor\n",
    "\n",
    "from pymor.parameters.functionals import MinThetaParameterFunctional\n",
    "\n",
    "ce = MinThetaParameterFunctional(opt_fom.primal_model.operator.coefficients, mu_bar)\n",
    "\n",
    "opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "\n",
    "pdeopt_reductor = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                                RBbasis, dual_RBbasis, \n",
    "                                                                opt_product=opt_fom.opt_product,\n",
    "                                                                coercivity_estimator=ce, \n",
    "                                                                prepare_for_gradient_estimate=True,\n",
    "                                                                mu_bar=mu_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start a greedy for the whole domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Greedy for J target\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 1, 1, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 2, 2, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 3, 3, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 4, 4, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 5, 5, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 6, 6, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 7, 7, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 8, 8, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 9, 9, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 10, 10, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 11, 11, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 12, 12, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 13, 13, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 14, 14, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 15, 15, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 16, 16, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 17, 17, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 18, 18, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 19, 19, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 20, 20, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 21, 21, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 22, 22, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 23, 23, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 24, 24, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 25, 25, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      " ... finished after 25 extensions\n",
      "Continuing with DJ target\n",
      "Enrichment completed... length of Bases are 26, 26, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 27, 27, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 28, 28, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 29, 29, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 30, 30, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 31, 31, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Enrichment completed... length of Bases are 32, 32, [] and []\n",
      "GRAD J ESTIMATOR: non corrected estimator\n",
      "Greedy took 4689.03039264679\n"
     ]
    }
   ],
   "source": [
    "set_log_levels({'pymor': 'WARN'})  # <-- set this to 'INFO' if you want to have further details \n",
    "from pdeopt.greedy import pdeopt_adaptive_greedy\n",
    "\n",
    "result_J, result_DJ = pdeopt_adaptive_greedy(opt_fom, pdeopt_reductor, opt_fom.parameter_space, validation_mus=-100, \n",
    "                                max_extensions=N, J_atol=tau_global_RB_J, DJ_atol=tau_global_RB_DJ)\n",
    "opt_rom = result_DJ['rom']\n",
    "tictoc = result_DJ['time'] + result_J['time']\n",
    "print('Greedy took {}'.format(tictoc))\n",
    "picked_mus = result_J['max_err_mus'][:-1]\n",
    "picked_mus.extend(result_DJ['max_err_mus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set sizes:  [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024] [1024, 1024, 1024, 1024, 1024, 1024, 59049]\n"
     ]
    }
   ],
   "source": [
    "print('training set sizes: ', result_J['training_set_sizes'], result_DJ['training_set_sizes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the 25th extension of J goal, the max error was 0.0006037571522573492\n",
      "Before the 7th extension of DJ goal, the max error was 4950.941163916121\n"
     ]
    }
   ],
   "source": [
    "print('Before the {}th extension of J goal, the max error was {}'.format(result_J['extensions'],result_J['max_errs'][-2]))\n",
    "print('Before the {}th extension of DJ goal, the max error was {}'.format(result_DJ['extensions'],result_DJ['max_errs'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = picked_mus\n",
    "RBbasis, dual_RBbasis, RBPrimalSens, RBDualSens = build_initial_basis(opt_fom, params, build_sensitivities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "GRAD J ESTIMATOR: non corrected estimator\n"
     ]
    }
   ],
   "source": [
    "ce = MinThetaParameterFunctional(opt_fom.primal_model.operator.coefficients, mu_bar)\n",
    "\n",
    "opt_fom = opt_fom.with_(use_corrected_functional=False)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "\n",
    "pdeopt_reductor = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                                RBbasis.copy(), dual_RBbasis.copy(), \n",
    "                                                                opt_product=opt_fom.opt_product,\n",
    "                                                                coercivity_estimator=ce, \n",
    "                                                                prepare_for_gradient_estimate=True,\n",
    "                                                                mu_bar=mu_bar)\n",
    "\n",
    "opt_rom_1a = pdeopt_reductor.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "GRAD J ESTIMATOR: non corrected estimator\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=True)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "\n",
    "pdeopt_reductor_2a = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                            RBbasis.copy(), dual_RBbasis.copy(), \n",
    "                                                            opt_product=opt_fom.opt_product,\n",
    "                                                            coercivity_estimator=ce, mu_bar=mu_bar,\n",
    "                                                            prepare_for_gradient_estimate=True,\n",
    "                                                            true_lagrange=True)\n",
    "\n",
    "opt_rom_2a = pdeopt_reductor_2a.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "GRAD J ESTIMATOR: adjoint approach - adjoint estimate (no sensitivities)\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=True)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=True)\n",
    "\n",
    "pdeopt_reductor_3a = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                            RBbasis.copy(), dual_RBbasis.copy(), \n",
    "                                                            opt_product=opt_fom.opt_product,\n",
    "                                                            coercivity_estimator=ce, mu_bar=mu_bar,\n",
    "                                                            adjoint_estimate=True,\n",
    "                                                            prepare_for_gradient_estimate=True,\n",
    "                                                            true_lagrange=True)\n",
    "\n",
    "opt_rom_3a = pdeopt_reductor_3a.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with two bases. Primal and dual have length 32 and 32\n",
      "building a SINGLE sensitivtiy model for any direction...\n",
      "GRAD J ESTIMATOR: adjoint approach - sensitivity estimate (d_mu) - Also valid for unique\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=True)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=False)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=True)\n",
    "\n",
    "pdeopt_reductor_4a = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                            RBbasis.copy(), dual_RBbasis.copy(), \n",
    "                                                            opt_product=opt_fom.opt_product,\n",
    "                                                            coercivity_estimator=ce, mu_bar=mu_bar,\n",
    "                                                            prepare_for_gradient_estimate=True,\n",
    "                                                            prepare_for_sensitivity_estimate=True,\n",
    "                                                            true_lagrange=True)\n",
    "\n",
    "opt_rom_4a = pdeopt_reductor_4a.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with separated sensitivity bases. Primal and dual have length 32 and 32\n",
      "building MULTIPLE sensitivity models for 10 directions...\n",
      "GRAD J ESTIMATOR: standard (d_mu-tilde sensitivity correction optional)\n"
     ]
    }
   ],
   "source": [
    "opt_fom = opt_fom.with_(use_corrected_functional=True)\n",
    "opt_fom = opt_fom.with_(use_corrected_gradient=True)\n",
    "opt_fom = opt_fom.with_(adjoint_approach=False)\n",
    "\n",
    "pdeopt_reductor_5a = QuadraticPdeoptStationaryCoerciveReductor(opt_fom, \n",
    "                                                            RBbasis.copy(), dual_RBbasis.copy(), \n",
    "                                                            RBPrimalSens.copy(), RBDualSens.copy(),\n",
    "                                                            opt_product=opt_fom.opt_product,\n",
    "                                                            coercivity_estimator=ce, mu_bar=mu_bar,\n",
    "                                                            prepare_for_gradient_estimate=True,\n",
    "                                                            prepare_for_sensitivity_estimate=True,\n",
    "                                                            true_lagrange=True)\n",
    "\n",
    "opt_rom_5a = pdeopt_reductor_5a.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute true errors and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = opt_fom.parameter_space.sample_randomly(validation_set_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "from pdeopt.tools import compute_all_errors_and_estimators_for_all_ROMS\n",
    "\n",
    "J_errors_1a, DJ_errors_1a, rel_J_errors_1a, rel_DJ_errors_1a, J_estimators_1a, DJ_estimators_1a, effectivities_J_1a, effectivities_DJ_1a, \\\n",
    "J_errors_2a, DJ_errors_2a, rel_J_errors_2a, rel_DJ_errors_2a, J_estimators_2a, DJ_estimators_2a, effectivities_J_2a, effectivities_DJ_2a, \\\n",
    "J_errors_3a, DJ_errors_3a, rel_J_errors_3a, rel_DJ_errors_3a, J_estimators_3a, DJ_estimators_3a, effectivities_J_3a, effectivities_DJ_3a, \\\n",
    "J_errors_4a, DJ_errors_4a, rel_J_errors_4a, rel_DJ_errors_4a, J_estimators_4a, DJ_estimators_4a, effectivities_J_4a, effectivities_DJ_4a, \\\n",
    "J_errors_5a, DJ_errors_5a, rel_J_errors_5a, rel_DJ_errors_5a, J_estimators_5a, DJ_estimators_5a, effectivities_J_5a, effectivities_DJ_5a, \\\n",
    "                                    J, DJ, \\\n",
    "u_mu_errors_4a, rel_u_mu_errors_4a, u_mu_estimators_4a, effectivities_u_mu_4a, \\\n",
    "u_mu_errors_5a, rel_u_mu_errors_5a, u_mu_estimators_5a, effectivities_u_mu_5a, \\\n",
    "p_mu_errors_4a, rel_p_mu_errors_4a, p_mu_estimators_4a, effectivities_p_mu_4a, \\\n",
    "p_mu_errors_5a, rel_p_mu_errors_5a, p_mu_estimators_5a, effectivities_p_mu_5a \\\n",
    "        = compute_all_errors_and_estimators_for_all_ROMS(\n",
    "            validation_set, opt_fom, opt_rom_1a, opt_rom_2a, opt_rom_3a, opt_rom_4a, opt_rom_5a, \n",
    "            pdeopt_reductor_4a, pdeopt_reductor_5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J\n",
    "max_J_error_1a = max(J_errors_1a)\n",
    "min_J_error_1a = min(J_errors_1a)\n",
    "\n",
    "max_J_error_2a = max(J_errors_2a)\n",
    "min_J_error_2a = min(J_errors_2a)\n",
    "\n",
    "max_J_error_3a = max(J_errors_3a)\n",
    "min_J_error_3a = min(J_errors_3a)\n",
    "\n",
    "max_J_error_4a = max(J_errors_4a)\n",
    "min_J_error_4a = min(J_errors_4a)\n",
    "\n",
    "max_J_error_5a = max(J_errors_5a)\n",
    "min_J_error_5a = min(J_errors_5a)\n",
    "\n",
    "#DJ\n",
    "max_DJ_error_1a = max(DJ_errors_1a)\n",
    "min_DJ_error_1a = min(DJ_errors_1a)\n",
    "\n",
    "max_DJ_error_2a = max(DJ_errors_2a)\n",
    "min_DJ_error_2a = min(DJ_errors_2a)\n",
    "\n",
    "max_DJ_error_3a = max(DJ_errors_3a)\n",
    "min_DJ_error_3a = min(DJ_errors_3a)\n",
    "\n",
    "max_DJ_error_4a = max(DJ_errors_4a)\n",
    "min_DJ_error_4a = min(DJ_errors_4a)\n",
    "\n",
    "max_DJ_error_5a = max(DJ_errors_5a)\n",
    "min_DJ_error_5a = min(DJ_errors_5a)\n",
    "\n",
    "#J estimator\n",
    "max_J_estimators_1a = max(J_estimators_1a)\n",
    "min_J_estimators_1a = min(J_estimators_1a)\n",
    "\n",
    "max_J_estimators_2a = max(J_estimators_2a)\n",
    "min_J_estimators_2a = min(J_estimators_2a)\n",
    "\n",
    "max_J_estimators_3a = max(J_estimators_3a)\n",
    "min_J_estimators_3a = min(J_estimators_3a)\n",
    "\n",
    "max_J_estimators_4a = max(J_estimators_4a)\n",
    "min_J_estimators_4a = min(J_estimators_4a)\n",
    "\n",
    "max_J_estimators_5a = max(J_estimators_5a)\n",
    "min_J_estimators_5a = min(J_estimators_5a)\n",
    "\n",
    "#DJ estimator\n",
    "max_DJ_estimators_1a = max(DJ_estimators_1a)\n",
    "min_DJ_estimators_1a = min(DJ_estimators_1a)\n",
    "\n",
    "max_DJ_estimators_2a = max(DJ_estimators_2a)\n",
    "min_DJ_estimators_2a = min(DJ_estimators_2a)\n",
    "\n",
    "max_DJ_estimators_3a = max(DJ_estimators_3a)\n",
    "min_DJ_estimators_3a = min(DJ_estimators_3a)\n",
    "\n",
    "max_DJ_estimators_4a = max(DJ_estimators_4a)\n",
    "min_DJ_estimators_4a = min(DJ_estimators_4a)\n",
    "\n",
    "max_DJ_estimators_5a = max(DJ_estimators_5a)\n",
    "min_DJ_estimators_5a = min(DJ_estimators_5a)\n",
    "\n",
    "\n",
    "median_effectivities_J_1a = np.sum(effectivities_J_1a)/len(effectivities_J_1a)\n",
    "median_effectivities_J_2a = np.sum(effectivities_J_2a)/len(effectivities_J_1a)\n",
    "median_effectivities_J_3a = np.sum(effectivities_J_3a)/len(effectivities_J_1a)\n",
    "median_effectivities_J_4a = np.sum(effectivities_J_4a)/len(effectivities_J_1a)\n",
    "median_effectivities_J_5a = np.sum(effectivities_J_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_effectivities_DJ_1a = np.sum(effectivities_DJ_1a)/len(effectivities_J_1a)\n",
    "median_effectivities_DJ_2a = np.sum(effectivities_DJ_2a)/len(effectivities_J_1a)\n",
    "median_effectivities_DJ_3a = np.sum(effectivities_DJ_3a)/len(effectivities_J_1a)\n",
    "median_effectivities_DJ_4a = np.sum(effectivities_DJ_4a)/len(effectivities_J_1a)\n",
    "median_effectivities_DJ_5a = np.sum(effectivities_DJ_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_errors_J_1a = np.sum(J_errors_1a)/len(effectivities_J_1a)\n",
    "median_errors_J_2a = np.sum(J_errors_2a)/len(effectivities_J_1a)\n",
    "median_errors_J_3a = np.sum(J_errors_3a)/len(effectivities_J_1a)\n",
    "median_errors_J_4a = np.sum(J_errors_4a)/len(effectivities_J_1a)\n",
    "median_errors_J_5a = np.sum(J_errors_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_estimators_J_1a = np.sum(J_estimators_1a)/len(effectivities_J_1a)\n",
    "median_estimators_J_2a = np.sum(J_estimators_2a)/len(effectivities_J_1a)\n",
    "median_estimators_J_3a = np.sum(J_estimators_3a)/len(effectivities_J_1a)\n",
    "median_estimators_J_4a = np.sum(J_estimators_4a)/len(effectivities_J_1a)\n",
    "median_estimators_J_5a = np.sum(J_estimators_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_errors_DJ_1a = np.sum(DJ_errors_1a)/len(effectivities_J_1a)\n",
    "median_errors_DJ_2a = np.sum(DJ_errors_2a)/len(effectivities_J_1a)\n",
    "median_errors_DJ_3a = np.sum(DJ_errors_3a)/len(effectivities_J_1a)\n",
    "median_errors_DJ_4a = np.sum(DJ_errors_4a)/len(effectivities_J_1a)\n",
    "median_errors_DJ_5a = np.sum(DJ_errors_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_estimators_DJ_1a = np.sum(DJ_estimators_1a)/len(effectivities_J_1a)\n",
    "median_estimators_DJ_2a = np.sum(DJ_estimators_2a)/len(effectivities_J_1a)\n",
    "median_estimators_DJ_3a = np.sum(DJ_estimators_3a)/len(effectivities_J_1a)\n",
    "median_estimators_DJ_4a = np.sum(DJ_estimators_4a)/len(effectivities_J_1a)\n",
    "median_estimators_DJ_5a = np.sum(DJ_estimators_5a)/len(effectivities_J_1a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J estimator comparison\n",
      "\n",
      "| Method       |   max J error |   min J error |   max J estimate |   min J estimate |   average effectivity |\n",
      "|--------------|---------------|---------------|------------------|------------------|-----------------------|\n",
      "| 1a not-corr  |     0.0766135 |     0.0001558 |        0.1245623 |        0.0005691 |             4.5721838 |\n",
      "| 2a semi-corr |     0.0060158 |     0.0000049 |        0.0782738 |        0.0003259 |            92.6643106 |\n",
      "| 3a AA A-Est  |     0.0060158 |     0.0000049 |        0.0782738 |        0.0003259 |            92.6643106 |\n",
      "| 4a AA S-Est  |     0.0060158 |     0.0000049 |        0.0782738 |        0.0003259 |            92.6643106 |\n",
      "| 5a Corr SA   |     0.0060158 |     0.0000049 |        0.0782738 |        0.0003259 |            92.6643106 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# tabulate for the output functional\n",
    "print('J estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'max J error', 'min J error', 'max J estimate', 'min J estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['1a not-corr ', max_J_error_1a, min_J_error_1a, max_J_estimators_1a, min_J_estimators_1a, median_effectivities_J_1a],\n",
    "    ['2a semi-corr', max_J_error_2a, min_J_error_2a, max_J_estimators_2a, min_J_estimators_2a, median_effectivities_J_2a],\n",
    "    ['3a AA A-Est ', max_J_error_3a, min_J_error_3a, max_J_estimators_3a, min_J_estimators_3a, median_effectivities_J_3a],\n",
    "    ['4a AA S-Est ', max_J_error_4a, min_J_error_4a, max_J_estimators_4a, min_J_estimators_4a, median_effectivities_J_4a],\n",
    "    ['5a Corr SA  ', max_J_error_5a, min_J_error_5a, max_J_estimators_5a, min_J_estimators_5a, median_effectivities_J_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DJ estimator comparison\n",
      "\n",
      "| Method       |   max DJ error |   min DJ error |   max DJ estimate |   min DJ estimate |   average effectivity |\n",
      "|--------------|----------------|----------------|-------------------|-------------------|-----------------------|\n",
      "| 1a not-corr  |      6.4303011 |      0.0203068 |      4503.6642106 |        75.8235663 |          2314.4869914 |\n",
      "| 2a semi-corr |      6.4303011 |      0.0203068 |      4503.6642106 |        75.8235663 |          2314.4869914 |\n",
      "| 3a AA A-Est  |      0.3138649 |      0.0014529 |      9997.2867375 |       183.6478632 |        135127.3720588 |\n",
      "| 4a AA S-Est  |      0.3138649 |      0.0014529 |        10.5050809 |         0.0933301 |            84.4277547 |\n",
      "| 5a Corr SA   |      0.0900121 |      0.0000390 |         8.8771813 |         0.0205983 |           323.5192181 |\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "# tabulate for the gradient of the output functional\n",
    "print('DJ estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'max DJ error', 'min DJ error', 'max DJ estimate', 'min DJ estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['1a not-corr ', max_DJ_error_1a, min_DJ_error_1a, max_DJ_estimators_1a, min_DJ_estimators_1a, median_effectivities_DJ_1a],\n",
    "    ['2a semi-corr', max_DJ_error_2a, min_DJ_error_2a, max_DJ_estimators_2a, min_DJ_estimators_2a, median_effectivities_DJ_2a],\n",
    "    ['3a AA A-Est ', max_DJ_error_3a, min_DJ_error_3a, max_DJ_estimators_3a, min_DJ_estimators_3a, median_effectivities_DJ_3a],\n",
    "    ['4a AA S-Est ', max_DJ_error_4a, min_DJ_error_4a, max_DJ_estimators_4a, min_DJ_estimators_4a, median_effectivities_DJ_4a],\n",
    "    ['5a Corr SA  ', max_DJ_error_5a, min_DJ_error_5a, max_DJ_estimators_5a, min_DJ_estimators_5a, median_effectivities_DJ_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J estimator comparison\n",
      "\n",
      "| Method       |   median J error |   median J estimate |   average effectivity |\n",
      "|--------------|------------------|---------------------|-----------------------|\n",
      "| 1a not-corr  |        0.0182426 |           0.0340405 |             4.5721838 |\n",
      "| 2a semi-corr |        0.0009864 |           0.0155649 |            92.6643106 |\n",
      "| 3a AA A-Est  |        0.0009864 |           0.0155649 |            92.6643106 |\n",
      "| 4a AA S-Est  |        0.0009864 |           0.0155649 |            92.6643106 |\n",
      "| 5a Corr SA   |        0.0009864 |           0.0155649 |            92.6643106 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# tabulate for the output functional\n",
    "print('J estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'median J error', 'median J estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['1a not-corr ', median_errors_J_1a, median_estimators_J_1a, median_effectivities_J_1a],\n",
    "    ['2a semi-corr', median_errors_J_2a, median_estimators_J_2a, median_effectivities_J_2a],\n",
    "    ['3a AA A-Est ', median_errors_J_3a, median_estimators_J_3a, median_effectivities_J_3a],\n",
    "    ['4a AA S-Est ', median_errors_J_4a, median_estimators_J_4a, median_effectivities_J_4a],\n",
    "    ['5a Corr SA  ', median_errors_J_5a, median_estimators_J_5a, median_effectivities_J_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DJ estimator comparison\n",
      "\n",
      "| Method       |   median DJ error |   median DJ estimate |   average effectivity |\n",
      "|--------------|-------------------|----------------------|-----------------------|\n",
      "| 1a not-corr  |         1.2818809 |         1501.9496953 |          2314.4869914 |\n",
      "| 2a semi-corr |         1.2818809 |         1501.9496953 |          2314.4869914 |\n",
      "| 3a AA A-Est  |         0.0494179 |         3320.4244504 |        135127.3720588 |\n",
      "| 4a AA S-Est  |         0.0494179 |            2.3587725 |            84.4277547 |\n",
      "| 5a Corr SA   |         0.0146849 |            1.3429669 |           323.5192181 |\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "# tabulate for the gradient of the output functional\n",
    "print('DJ estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'median DJ error', 'median DJ estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['1a not-corr ', median_errors_DJ_1a, median_estimators_DJ_1a, median_effectivities_DJ_1a],\n",
    "    ['2a semi-corr', median_errors_DJ_2a, median_estimators_DJ_2a, median_effectivities_DJ_2a],\n",
    "    ['3a AA A-Est ', median_errors_DJ_3a, median_estimators_DJ_3a, median_effectivities_DJ_3a],\n",
    "    ['4a AA S-Est ', median_errors_DJ_4a, median_estimators_DJ_4a, median_effectivities_DJ_4a],\n",
    "    ['5a Corr SA  ', median_errors_DJ_5a, median_estimators_DJ_5a, median_effectivities_DJ_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primal sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_u_error_4a = max(u_mu_errors_4a)\n",
    "min_u_error_4a = min(u_mu_errors_4a)\n",
    "\n",
    "max_u_error_5a = max(u_mu_errors_5a)\n",
    "min_u_error_5a = min(u_mu_errors_5a)\n",
    "\n",
    "max_u_estimators_4a = max(u_mu_estimators_4a)\n",
    "min_u_estimators_4a = min(u_mu_estimators_4a)\n",
    "\n",
    "max_u_estimators_5a = max(u_mu_estimators_5a)\n",
    "min_u_estimators_5a = min(u_mu_estimators_5a)\n",
    "\n",
    "median_effectivities_u_4a = np.sum(effectivities_u_mu_4a)/len(effectivities_J_1a)\n",
    "median_effectivities_u_5a = np.sum(effectivities_u_mu_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_errors_u_4a = np.sum(u_mu_errors_4a)/len(effectivities_J_1a)\n",
    "median_errors_u_5a = np.sum(u_mu_errors_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_estimators_u_4a = np.sum(u_mu_estimators_4a)/len(effectivities_J_1a)\n",
    "median_estimators_u_5a = np.sum(u_mu_estimators_5a)/len(effectivities_J_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u estimator comparison\n",
      "\n",
      "| Method      |   max error |   min error |   max estimator |   min estimator |\n",
      "|-------------|-------------|-------------|-----------------|-----------------|\n",
      "| 4a AA S-Est |   0.8533939 |   0.0272763 |       1.2687267 |       0.1029352 |\n",
      "| 5a Corr SA  |   0.1127435 |   0.0041662 |       0.7053271 |       0.0276643 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('u estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'max error', 'min error', 'max estimator', 'min estimator']\n",
    "table = [\n",
    "    ['4a AA S-Est ', max_u_error_4a, min_u_error_4a, max_u_estimators_4a, min_u_estimators_4a],\n",
    "    ['5a Corr SA  ', max_u_error_5a, min_u_error_5a, max_u_estimators_5a, min_u_estimators_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Method      |   average error |   average estimate |   average effectivity |\n",
      "|-------------|-----------------|--------------------|-----------------------|\n",
      "| 4a AA S-Est |       0.1316809 |          0.3520109 |            35.0218823 |\n",
      "| 5a Corr SA  |       0.0397695 |          0.2060156 |           146.5005875 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = ['Method', 'average error', 'average estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['4a AA S-Est ', median_errors_u_4a, median_estimators_u_4a, median_effectivities_u_4a],\n",
    "    ['5a Corr SA  ', median_errors_u_5a, median_estimators_u_5a, median_effectivities_u_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dual sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_p_error_4a = max(p_mu_errors_4a)\n",
    "min_p_error_4a = min(p_mu_errors_4a)\n",
    "\n",
    "max_p_error_5a = max(p_mu_errors_5a)\n",
    "min_p_error_5a = min(p_mu_errors_5a)\n",
    "\n",
    "#J estimator\n",
    "max_p_estimators_4a = max(p_mu_estimators_4a)\n",
    "min_p_estimators_4a = min(p_mu_estimators_4a)\n",
    "\n",
    "max_p_estimators_5a = max(p_mu_estimators_5a)\n",
    "min_p_estimators_5a = min(p_mu_estimators_5a)\n",
    "\n",
    "median_effectivities_p_4a = np.sum(effectivities_p_mu_4a)/len(effectivities_J_1a)\n",
    "median_effectivities_p_5a = np.sum(effectivities_p_mu_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_errors_p_4a = np.sum(p_mu_errors_4a)/len(effectivities_J_1a)\n",
    "median_errors_p_5a = np.sum(p_mu_errors_5a)/len(effectivities_J_1a)\n",
    "\n",
    "median_estimators_p_4a = np.sum(p_mu_estimators_4a)/len(effectivities_J_1a)\n",
    "median_estimators_p_5a = np.sum(p_mu_estimators_5a)/len(effectivities_J_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p estimator comparison\n",
      "\n",
      "| Method      |   max error |   min error |   max estimator |   min estimator |\n",
      "|-------------|-------------|-------------|-----------------|-----------------|\n",
      "| 4a AA S-Est | 398.5507306 |  13.6129654 |    1032.0519773 |      55.0314370 |\n",
      "| 5a Corr SA  |  74.6967860 |   0.8531035 |     783.3274162 |      18.7082574 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tabulate for the output functional\n",
    "print('p estimator comparison')\n",
    "print()\n",
    "headers = ['Method', 'max error', 'min error', 'max estimator', 'min estimator']\n",
    "table = [\n",
    "    ['4a AA S-Est ', max_p_error_4a, min_p_error_4a, max_p_estimators_4a, min_p_estimators_4a],\n",
    "    ['5a Corr SA  ', max_p_error_5a, min_p_error_5a, max_p_estimators_5a, min_p_estimators_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Method      |   average error |   average estimate |   average effectivity |\n",
      "|-------------|-----------------|--------------------|-----------------------|\n",
      "| 4a AA S-Est |      81.2893418 |        347.3331801 |            51.6269574 |\n",
      "| 5a Corr SA  |      24.8254691 |        218.2519683 |           232.1951634 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = ['Method', 'average error', 'average estimate', 'average effectivity']\n",
    "table = [\n",
    "    ['4a AA S-Est ', median_errors_p_4a, median_estimators_p_4a, median_effectivities_p_4a],\n",
    "    ['5a Corr SA  ', median_errors_p_5a, median_estimators_p_5a, median_effectivities_p_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eff_J_1a = max(effectivities_J_1a)\n",
    "max_eff_J_2a = max(effectivities_J_2a)\n",
    "max_eff_J_3a = max(effectivities_J_3a)\n",
    "max_eff_J_4a = max(effectivities_J_4a)\n",
    "max_eff_J_5a = max(effectivities_J_5a)\n",
    "\n",
    "max_eff_DJ_1a = max(effectivities_DJ_1a)\n",
    "max_eff_DJ_2a = max(effectivities_DJ_2a)\n",
    "max_eff_DJ_3a = max(effectivities_DJ_3a)\n",
    "max_eff_DJ_4a = max(effectivities_DJ_4a)\n",
    "max_eff_DJ_5a = max(effectivities_DJ_5a)\n",
    "\n",
    "max_eff_u_4a = max(effectivities_u_mu_4a)\n",
    "max_eff_u_5a = max(effectivities_u_mu_5a)\n",
    "\n",
    "max_eff_p_4a = max(effectivities_p_mu_4a)\n",
    "max_eff_p_5a = max(effectivities_p_mu_5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max effectivities\n",
      "| Method       |   max eff for J |   max eff for DJ | max eff for u_mu   | max eff for p_mu   |\n",
      "|--------------|-----------------|------------------|--------------------|--------------------|\n",
      "| 1a not-corr  |      60.4071149 |    15603.3009341 | -                  | -                  |\n",
      "| 2a semi-corr |    3188.1462625 |    15603.3009342 | -                  | -                  |\n",
      "| 3a AA A-Est  |    3188.1462625 |  1365892.9197413 | -                  | -                  |\n",
      "| 4a AA S-Est  |    3188.1462625 |      653.1983662 | 212.17633160323192 | 439.0174676769815  |\n",
      "| 5a Corr SA   |    3188.1462625 |     5326.0440363 | 517.8677462474733  | 1314.1632679305967 |\n"
     ]
    }
   ],
   "source": [
    "print('max effectivities')\n",
    "\n",
    "headers = ['Method', 'max eff for J', 'max eff for DJ', 'max eff for u_mu', 'max eff for p_mu']\n",
    "table = [\n",
    "    ['1a not-corr ', max_eff_J_1a, max_eff_DJ_1a, '-', '-'],\n",
    "    ['2a semi-corr', max_eff_J_2a, max_eff_DJ_2a, '-', '-'],\n",
    "    ['3a AA A-Est ', max_eff_J_3a, max_eff_DJ_3a, '-', '-'],\n",
    "    ['4a AA S-Est ', max_eff_J_4a, max_eff_DJ_4a, max_eff_u_4a, max_eff_p_4a],\n",
    "    ['5a Corr SA  ', max_eff_J_5a, max_eff_DJ_5a, max_eff_u_5a, max_eff_p_5a]]\n",
    "\n",
    "print(tabulate(table, headers=headers, tablefmt='github', floatfmt='.7f')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
