{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarCraft II - Project Plan for MoveToBeacon minigame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "Specific tasks that I must be able to solve in order to be able to solve the full MoveToBeacon minigame challange.\n",
    "\n",
    "1. **Setup the game environment** <br>\n",
    "    i. Install StarCraft II Learning Environment (SC2LE / pysc2) <br>\n",
    "    ii. Parameters of the game (map, resolution, replays) <br>\n",
    "    \n",
    "    \n",
    "2. **How to interact with the game** <br>\n",
    "    i. How to use reset and step methods <br>\n",
    "    ii. What are the observables <br>\n",
    "    iii. What are the actions \n",
    "    \n",
    "    \n",
    "3. **How to build an agent** <br>\n",
    "    i. How to use method step <br>\n",
    "    ii. How to choose a valid action id <br>\n",
    "    iii. How to know what kind of additional parameters are needed (spatial or not, parameter space in general)\n",
    "    \n",
    "    \n",
    "4. **How to preprocess the spatial observation** <br>\n",
    "    i. How to get the number of possible values that each variable can assume (variable = feature layer in the case of the feature_screen and feature_minimap) -> **manual inspection and custom preprocessing** <br>\n",
    "    ii. How to embed each layer independently (since they have different vocabularies and semantic meanings) - used ohe when needed, log2 for numerical variables with high range and casting to float for those that were numerical but with values limited in a small range<br>\n",
    "    iii. How to deal with screen and minimap different resolutions [see specific thread] - assume same resolution<br>\n",
    "    iv. How many feature layers to use (all info or just the useful one for MoveToBeacon?) [see specific thread] - custom number of them\n",
    "    \n",
    "    \n",
    "5. **How to preprocess player information** <br>\n",
    "    i. Categorical (e.g. player id) vs pure integer (e.g. minerals and gas) distinction - done<br>\n",
    "    ii. What should be the output of the preprocessing - multi-channel image\n",
    "    \n",
    "\n",
    "6. **Which architecture to use for learning state representation** <br>\n",
    "    i. When actor and critic architectures depart from each other? - last layer <br>\n",
    "    ii. Which kind of representation should we produce? <br>\n",
    "    iii. Spatial and non-spatial outputs - done <br>\n",
    "    iv. Possible architectures [see specific thread] \n",
    "    \n",
    "    \n",
    "7. **Actor final layers** <br>\n",
    "    i. How to choose actions id - masked softmax all in one <br>\n",
    "    ii. How to encode the information about the chosen action when we need to get the additional parameters - at the moment with the embedding layer, but we could use the FiLM layer <br>\n",
    "    iii. How to know if parameters are spatial or not - access to parameter specifics and look for the size\n",
    "    iv. How to sample non-spatial additional params - which layers and which input to use? Fully-connected with one hidden layer of 256 neurons and ReLU activation (we could skip this hidden layer maybe)\n",
    "    v. How to sample spatial additional params - which layers and which input to use? (conv2d 1x1 or 3x3 with 1 of padding directly after the spatial features -> no activation functions specific to the FullyConvNonSpatial net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestones / Tests\n",
    "What intermediary objective I plan to achive in the meanwhile.\n",
    "\n",
    "### Components to test\n",
    "1. Input preprocessing\n",
    "2. Shared architecture\n",
    "3. Critic architecture\n",
    "4. Actor architecture - action id \n",
    "5. Actor architecture - actions parameters\n",
    "6. Critic update\n",
    "7. Actor update\n",
    "8. Training cycle\n",
    "9. Relational architecture\n",
    "\n",
    "### Milestones\n",
    "**Agent 1:** \n",
    "    - Actor and Critic provided only with useful info for MoveToBeacon (x,y of agent and beacon center, flags  exists_beacon and is_selected)\n",
    "    - Simplest FF net that chooses onyl the function id (so action space = 3)\n",
    "    - Scripted (optimal) choice of additional parameters\n",
    "    \n",
    "Tests the actor architecture for choosing the action id (4), actor-critic update (7) and the training cycle (8). <br>\n",
    "\n",
    "**Agent 2:** \n",
    "    - Actor-Critic provided only with one-hot-encoded version of the most important layers (player relative and selected)\n",
    "    - AtariNet-like agent to select action id (so action space = 3)\n",
    "    - Scripted (optimal) choice of additional parameters\n",
    "    \n",
    "Tests the input preprocessing (1) and a bit of the shared architecture (2).\n",
    "\n",
    "**Agent 3:** \n",
    "    - Actor-Critic provided only with one-hot-encoded version of the most important layers (player relative and selected)\n",
    "    - AtariNet-like agent to select action id and additional parameters\n",
    "    \n",
    "Tests actor and critic architecture (3, 4, 5).\n",
    "\n",
    "**Agent 4:** \n",
    "    - Actor-Critic provided only with one-hot-encoded version of the most important layers (player relative and selected)\n",
    "    - FullyConvNet-like agent to select action id and additional parameters\n",
    "    \n",
    "Tests actor and critic architecture (3, 4, 5).\n",
    "\n",
    "**Agent 5:** \n",
    "    - Relational architecture from Relational Deep RL paper\n",
    "    - Actor-Critic provided only with one-hot-encoded version of the most important layers (player relative and selected)\n",
    "    - Only action id selection\n",
    "    - Scripted (optimal) choice of additional parameters\n",
    "    \n",
    "Test relational architecture (9).\n",
    "\n",
    "**Agent 6:** \n",
    "    - Relational architecture from Relational Deep RL paper\n",
    "    - Actor-Critic provided only with one-hot-encoded version of the most important layers (player relative and selected) + non-spatial info (no minimap)\n",
    "    - Full action selection\n",
    "    \n",
    "Agent almost complete. \n",
    "\n",
    "All input info retained is actually not useful, so it doesn't make sense to include it except for generalization purposes that will be addressed when we take on the whole minigame challenge.\n",
    "\n",
    "**Update:** all agents up to 4 done successfully, agent 5 not planned, agent 6 still to try. Problems with the GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues / Threads\n",
    "Conceptual choices that I have to make.\n",
    "\n",
    "1. Trade-off between generalization and complexity (How many features do we actually need? Is it okay to manually filter them before feeding them to the agent?)\n",
    "2. How to deal with screen and minimap resolutions: ideally they should be 84x84 and 64x64 respectively, but in the original paper they assume them to have the same resolution. Actually for the moment I will actually skip the whole minimap observation, but in the other minigames could be important.\n",
    "3. Possible architectures: Atari-like, FullConv, Relational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful material\n",
    "Most useful guides, repositories and papers.\n",
    "\n",
    "StarCraft II Learning Environment from DeepMind: \n",
    "- Library repository: https://github.com/deepmind/pysc2 \n",
    "- Original paper: https://arxiv.org/abs/1708.04782\n",
    "- Relational paper: https://arxiv.org/abs/1806.01830\n",
    "\n",
    "Full-game mostly scripted bots: <br>\n",
    "https://github.com/skjb/pysc2-tutorial \n",
    "\n",
    "TensorFlow solutions for A2C and PPO agents for the minigames: <br>\n",
    "https://github.com/inoryy/reaver <br>\n",
    "https://github.com/chris-chris/pysc2-examples\n",
    "\n",
    "Some simple Q-table solutions of MoveToBeacon minigame: <br>\n",
    "https://github.com/yvan/nbsblogs/tree/master/pysc2_tut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
