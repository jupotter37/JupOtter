{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucy-Moctezuma/ML-Tutorial-for-Antibiotic-Resistance-Predictions-for-E.-Coli/blob/main/6)_Making_Final_Metrics_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(**Note:**\n",
        "Click on the button that reads *“Open in Colab”* to open this code in Google Colab. Once open in Google Colab, you can make a copy of the notebook in your personal drive and run the code by clicking a little triangle/arrow to the left of each code block.)"
      ],
      "metadata": {
        "id": "rEnnmSg_xlhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Graphs for Accuracies, Recall and Precision Scores**\n",
        "\n",
        "In this Notebook we will create a graph that will let us show the Accuracy,  Recall and Precision Scores for both Resistant (R) and Susceptibility (S). The figures we will create are inspired by the paper where our dataset comes from:\n",
        "\n",
        "**Moradigaravand D, Palm M, Farewell A, Mustonen V, Warringer J, Parts L (2018) Prediction of antibiotic resistance in Escherichia coli from large-scale pan-genome data. PLoS Comput Biol 14(12): e1006258. https://doi.org/10.1371/journal.pcbi.1006258**\n",
        "\n",
        "Below is the figure the author of the paper created:\n",
        "\n",
        "![Moradigaravand graph](https://drive.google.com/uc?export=view&id=11aByLgM7pVPfBfhVU2LNBW2ZbZGbSgJH)\n",
        "\n",
        "We will be creating a similar ones except instead of F1-scores we will focus on the **Recall** and **Precision** scores for each (Resistance and Susceptibility). In addition, our dataset includes an antibiotic drug that was not included in their original publication (\"TZP\") and we will not be using population structure as a train feature.\n"
      ],
      "metadata": {
        "id": "mZzQPqYib3RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0G4Z0d2qFFXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Importing packages needed for visualization**\n",
        "\n",
        "Below we will only be importing libraries needed for visualization of the results from all our models."
      ],
      "metadata": {
        "id": "eyEsWoENgE1F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI6qtXkG3ruy"
      },
      "outputs": [],
      "source": [
        "# Data Wrangling Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# File Manipulation Imports\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Loading each models scores and join them into a single dictionary**\n",
        "\n",
        "Below we will import the 4 csv files created from Notebooks 2 to 5, where the metrics (Accuracy, Resistant Recall, Susceptibility Recall, Resistant Precision and Susceptibility Precision) from every combination of features (Y, G and GY) were stored. Then we will store it in a dictionary to access later on."
      ],
      "metadata": {
        "id": "s31dSpjkgSZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading all models metrics and joint them in a dictionary:\n",
        "filepath = \"/content/drive/MyDrive/EColi_ML_CSV_files/\"\n",
        "Model_Scores = {}\n",
        "\n",
        "# Loading all data frames\n",
        "LG_metrics = pd.read_csv(filepath+\"LG_metrics_df.csv\")\n",
        "RF_metrics = pd.read_csv(filepath+\"RF_metrics_df.csv\")\n",
        "GB_metrics = pd.read_csv(filepath+\"GB_metrics_df.csv\")\n",
        "DL_metrics = pd.read_csv(filepath+\"NN_metrics_df.csv\")\n",
        "\n",
        "# Adding all dataframes to dictionary\n",
        "Model_Scores[\"Logistic_Regression\"] = LG_metrics\n",
        "Model_Scores[\"Random_Forest\"] = RF_metrics\n",
        "Model_Scores[\"Gradient_Boosted_Trees\"] = GB_metrics\n",
        "Model_Scores[\"Neural_Network\"] = DL_metrics"
      ],
      "metadata": {
        "id": "7a7nIbEvcVMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is an example of how we can access a particular dataframe within our Python dictionary:"
      ],
      "metadata": {
        "id": "3pENTKgpY9ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# showing example of how a single dataframe can be accessed\n",
        "Model_Scores['Gradient_Boosted_Trees'].head()"
      ],
      "metadata": {
        "id": "CI8_NBUpfb8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) Select only the best scores for each drug from each model**\n",
        "\n",
        "Below we will be creating a function that helps us extract the best metrics, we can choose to extract either Recall or Precision. By default we will work with Recall first as part of an example."
      ],
      "metadata": {
        "id": "nHnUBCl-f4eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting list of combos from dictionary created\n",
        "combo_list = list(Model_Scores['Gradient_Boosted_Trees'][\"Drug_combo\"].str.split(\"_\", expand= True)[1].unique())\n",
        "combo_list"
      ],
      "metadata": {
        "id": "A8ZPxpuQPuJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting list of drugs from dictionary created\n",
        "drug_list = list(Model_Scores['Gradient_Boosted_Trees'][\"Drug_combo\"].str[:3].unique())\n",
        "drug_list"
      ],
      "metadata": {
        "id": "bQVnCVGXgBZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating function that will take the best scores from each model\n",
        "def Best_metrics(model,df):\n",
        "  print(\"Selecting Best Scores for model: \",model)\n",
        "  bestcores_dic = {}\n",
        "  for drug in drug_list:\n",
        "    data = df.loc[df[\"Drug_combo\"].str.startswith(drug)]\n",
        "    max_acc = max(data[\"Accuracy\"])\n",
        "    drug_combo = data[\"Drug_combo\"][data[\"Accuracy\"] == max_acc].unique()[0]\n",
        "    R_rec = float(data[data[\"Drug_combo\"] == drug_combo].iloc[:,2].iloc[0])\n",
        "    S_rec = float(data[data[\"Drug_combo\"] == drug_combo].iloc[:,3].iloc[0])\n",
        "    R_prec = float(data[data[\"Drug_combo\"] == drug_combo].iloc[:,4].iloc[0])\n",
        "    S_prec = float(data[data[\"Drug_combo\"] == drug_combo].iloc[:,5].iloc[0])\n",
        "    bestcores_dic[drug_combo] = [max_acc, R_rec, S_rec, R_prec, S_prec]\n",
        "    bestscores_df = pd.DataFrame.from_dict(bestcores_dic, orient ='index',columns=[\"Accuracy\", \"R_recall\", \"S_recall\", \"R_precision\", \"S_precision\"]).reset_index()\n",
        "    bestscores_df = bestscores_df.rename(columns = {'index':'Drug_combo'})\n",
        "  return bestscores_df"
      ],
      "metadata": {
        "id": "5nca1_fT4_mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will implement this function to extract the best Accuracy and other metrics from our Logistic Regression Results."
      ],
      "metadata": {
        "id": "1HQVMCfvdz_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of function Best_metrics() example with Logistic Regression scores\n",
        "LG_best_metrics = Best_metrics(\"Logistic_Regression\", Model_Scores[\"Logistic_Regression\"])\n",
        "LG_best_metrics"
      ],
      "metadata": {
        "id": "8xa0BRcSNW4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) Converting combo strings into separate columns of G, Y and S**\n",
        "\n",
        "The function below will help us code what feature datasets were used. This information will now appear as 2 columns, one per dataset feature (G and Y). These columns will help us create the black and white checkered grids we see at the bottom of the example figure from Moradigaravand's paper.\n"
      ],
      "metadata": {
        "id": "wfVa_Cb68iKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function that takes the combo strings from Drug_combo column and turns them into separate columns\n",
        "def make_GY(bestscores_df):\n",
        "  # Create 2 new columns one for each type of features (Gene presence, Year and Population structure)\n",
        "  bestscores_df[\"G\"] = \" \"\n",
        "  bestscores_df[\"Y\"] = \" \"\n",
        "\n",
        "  # Read the combo part of Drug_combo\n",
        "  split_c = bestscores_df[\"Drug_combo\"].str.split(\"_\", expand=True)\n",
        "  i=0\n",
        "  while i < len(split_c[1]):\n",
        "    split_each_c = [x for x in split_c[1][i]]\n",
        "    for g in split_each_c:\n",
        "      if \"G\" in split_each_c:\n",
        "        bestscores_df.at[i,\"G\"] = 1\n",
        "      else:\n",
        "        bestscores_df.at[i,\"G\"] = 0\n",
        "    for y in split_each_c:\n",
        "      if \"Y\" in split_each_c:\n",
        "        bestscores_df.at[i,\"Y\"] = 1\n",
        "      else:\n",
        "        bestscores_df.at[i,\"Y\"] = 0\n",
        "    i += 1\n",
        "  bestscores_df[\"Drug_combo\"] = bestscores_df[\"Drug_combo\"].map(lambda x: x.rstrip('_GY'))\n",
        "  bestscores_df.rename(columns={\"Drug_combo\": \"Drug\"}, inplace = True)\n",
        "\n",
        "  return bestscores_df"
      ],
      "metadata": {
        "id": "lwkHfYt6l4Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below in the implementation we can see our three columns appear, one for each type of feature. 1 indicates that a feature was used and 0 that it wasn't used. Below we see an example of these columns for our Logistic Regression model results."
      ],
      "metadata": {
        "id": "XauEO0SqoU1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing function make_GY()\n",
        "GY_LG_best_metrics = make_GY(LG_best_metrics)\n",
        "GY_LG_best_metrics"
      ],
      "metadata": {
        "id": "IlWaoH1vT8ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) Extracting best metrics and coding GYS into columns for all models**\n",
        "\n",
        "Below we will be implementing the two functions we have created before: **Best_metrics()** and **make_GYS()** for all the results from each of the models."
      ],
      "metadata": {
        "id": "GmFOU3Mfw6Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the best metrics for all the models\n",
        "Best_metrics_models = {}\n",
        "for model, df in Model_Scores.items():\n",
        "  # select the best scores obtained from each model\n",
        "  Model_best_metrics = Best_metrics(model, df)\n",
        "\n",
        "  # Code GYS data in 0 \"for absence\" and 1 \"for presence\" into 3 columns\n",
        "  GY_coded_best = make_GY(Model_best_metrics)\n",
        "  print(GY_coded_best)\n",
        "\n",
        "  # Save new dataframe in a dictionary with best metrics selected\n",
        "  Best_metrics_models[model] = GY_coded_best"
      ],
      "metadata": {
        "id": "DfmpOZNPryWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6) Creating a function to plot bar charts for each metric**\n",
        "\n",
        "The function below will help us plot barplots comparing the metrics we choose for all the models created."
      ],
      "metadata": {
        "id": "DHN5qX9420VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def barplot(metric_col, subplot_axis, label_show = True):\n",
        "  for model, df in Best_metrics_models.items():\n",
        "    X_axis = np.arange(len(drug_list))\n",
        "    X_labels = drug_list\n",
        "\n",
        "    Y_axis = np.arange(0,1.2,0.2)\n",
        "\n",
        "    subplot_axis.set_ylabel(metric_col, fontsize = 14)\n",
        "    subplot_axis.set_ylim(bottom=0, top=1)\n",
        "\n",
        "    subplot_axis.xaxis.set_ticklabels(X_labels, fontsize = 15)\n",
        "    subplot_axis.xaxis.set_ticks(X_axis)\n",
        "    subplot_axis.margins(x=0)\n",
        "\n",
        "    if label_show == False:\n",
        "      subplot_axis.tick_params(left = True, right = False , labelleft = True , labelbottom = False, bottom = True)\n",
        "\n",
        "    if model == \"Logistic_Regression\":\n",
        "      X_axis = X_axis - 0.3\n",
        "      color = \"plum\"\n",
        "      label = \"LG\"\n",
        "      subplot_axis.bar(X_axis, list(df[metric_col]), width =.2, align = 'center', color = color, label = label, edgecolor=\"gray\")\n",
        "    elif model == \"Random_Forest\":\n",
        "      X_axis = X_axis - 0.1\n",
        "      color = \"cadetblue\"\n",
        "      label = \"RF\"\n",
        "      subplot_axis.bar(X_axis, list(df[metric_col]), width =.2, align = 'center', color = color, label = label, edgecolor=\"gray\")\n",
        "    elif model == \"Gradient_Boosted_Trees\":\n",
        "      X_axis = X_axis + 0.1\n",
        "      color = \"goldenrod\"\n",
        "      label = \"GB\"\n",
        "      subplot_axis.bar(X_axis, list(df[metric_col]), width =.2, align = 'center', color = color, label = label, edgecolor=\"gray\")\n",
        "    elif model == \"Neural_Network\":\n",
        "      X_axis = X_axis + 0.3\n",
        "      color = \"steelblue\"\n",
        "      label = \"GB\"\n",
        "      subplot_axis.bar(X_axis, list(df[metric_col]), width =.2, align = 'center', color = color, label = label, edgecolor=\"gray\")\n",
        "  return"
      ],
      "metadata": {
        "id": "PI7lzr7c4WMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we have the implementation of this function on the **Accuracy** metric. However we can choose other ones available as well. In this case we could choose **R_recall**, **S_precision**, etc."
      ],
      "metadata": {
        "id": "rtBYRMSFf8Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing function barplot() for one metric \"Accuracy\"\n",
        "figure, subs = plt.subplots(1, 1,figsize = (18,8))\n",
        "acc_plot = barplot(\"Accuracy\",subs,label_show=True)"
      ],
      "metadata": {
        "id": "m_KHDt9HLpWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) Creating a function to plot GYS grids for each drug**\n",
        "\n",
        "The function below will create a small graphic that will indicate what dataset was used (G, Y, and/or S) when training the model. This is made using the columns created before when we implemented the **make_GYS()** function."
      ],
      "metadata": {
        "id": "2u7tQmwslrC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that creates a graph for each of the drugs\n",
        "def GY_gridplot(drug,subplot_axis, label_show = True, title_pos = -0.2):\n",
        "  # Create 2 new lists one for each type of features (Year and Gene presence)\n",
        "  Y_list = [] # storing whether it used or not year data\n",
        "  G_list = [] # storing whether it used or not accessory gene data\n",
        "\n",
        "  # Fill up corresponding lists from drug results from each model\n",
        "  for model, df in Best_metrics_models.items():\n",
        "    for drug_name in df[\"Drug\"]:\n",
        "      if drug_name == drug:\n",
        "        Y_list.append(int(df[\"Y\"][df[\"Drug\"]==drug].iloc[0]))\n",
        "        G_list.append(int(df[\"G\"][df[\"Drug\"]==drug].iloc[0]))\n",
        "\n",
        "  Drug_GY_list = [Y_list, G_list]\n",
        "\n",
        "  plt.yticks(np.arange(2), [\"Year\", \"Accessory Genes\"])\n",
        "  if label_show == False:\n",
        "      subplot_axis.tick_params(left = False, labelleft = False)\n",
        "\n",
        "  orig_map = plt.colormaps['gray']\n",
        "  reversed_map = orig_map.reversed()\n",
        "  subplot_axis.imshow(Drug_GY_list, cmap = reversed_map)\n",
        "\n",
        "  subplot_axis.axvline(x=0.5)\n",
        "  subplot_axis.axvline(x=1.5)\n",
        "  subplot_axis.axvline(x=2.5)\n",
        "  subplot_axis.axhline(y=0.5)\n",
        "  subplot_axis.axhline(y=1.5)\n",
        "  subplot_axis.set_title(drug, fontsize= 15, y=title_pos)\n",
        "  subplot_axis.tick_params(\n",
        "    axis = 'x',\n",
        "    which = 'both',\n",
        "    bottom = False,\n",
        "    top = False,\n",
        "    labelbottom = False)\n",
        "  return [Y_list, G_list]"
      ],
      "metadata": {
        "id": "I3HdYBHIqxcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The way we read this gridplot is that if the square is black, then it means that the dataset feature was used. If it is white, then it was not used. In the example implementation below, we are choosing the antibiotic CTZ and have extracted their best metrics from each of the models.\n",
        "\n",
        "In the first column of the graph we see year and Genes (Gene Presence and Absence data features) in black, meaning this was the combination that yielded the best results for one particular model. Each column represents one model."
      ],
      "metadata": {
        "id": "RZMhVQ1AmZlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing function GY_gridplot() for one drug \"CTZ\"\n",
        "figure, subs = plt.subplots()\n",
        "CTZ_gridplot = GY_gridplot(\"CTZ\",subs, label_show=True)"
      ],
      "metadata": {
        "id": "b8X4Vg7Dl8eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8) Create the final composite graph (Bargraphs + GY gridplots)**\n",
        "\n",
        "Below we finally create our Visualization graphs for the best metrics from all the models."
      ],
      "metadata": {
        "id": "8y8GnAPHpac1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to create bargraphs\n",
        "fig = plt.figure(figsize = (24,15), constrained_layout=False)\n",
        "\n",
        "gs1 = fig.add_gridspec(nrows=6, ncols=12, left=0.05, right=0.6, wspace=0.07)\n",
        "# Accuracy barcharts for all models\n",
        "acc_axis = fig.add_subplot(gs1[0, :])\n",
        "acc_axis.set_title('Prediction of Antibiotic Resistance From Pan-Genome Data', fontsize = 20)\n",
        "acc_plot = barplot(\"Accuracy\",acc_axis, label_show = False)\n",
        "\n",
        "# R_recall_score barcharts for all models\n",
        "R_metric_axis = fig.add_subplot(gs1[1, :])\n",
        "R_metric_plot = barplot('R_recall',R_metric_axis, label_show = False)\n",
        "\n",
        "# S_recall barcharts for all models\n",
        "S_metric_axis = fig.add_subplot(gs1[2, :])\n",
        "S_metric_plot = barplot('S_recall',S_metric_axis, label_show = False)\n",
        "\n",
        "# R_precision barcharts for all models\n",
        "R_metric_axis = fig.add_subplot(gs1[3, :])\n",
        "R_metric_plot = barplot('R_precision',R_metric_axis, label_show = False)\n",
        "\n",
        "# S_precision barcharts for all models\n",
        "S_metric_axis = fig.add_subplot(gs1[4, :])\n",
        "S_metric_plot = barplot('S_precision',S_metric_axis, label_show = False)\n",
        "\n",
        "# GY gridplot charts for each drug\n",
        "gs2 = fig.add_gridspec(nrows=1, ncols=12, top=0.44,bottom=0,left=0.05, right=0.6, wspace=0.2)\n",
        "i=0\n",
        "while (i< len(drug_list)):\n",
        "  for drug in drug_list:\n",
        "    if i == 0:\n",
        "      Drug_grid = fig.add_subplot(gs2[-1, i])\n",
        "      drug_GY = GY_gridplot(drug, Drug_grid, label_show=True, title_pos=-0.6)\n",
        "      i+=1\n",
        "    else:\n",
        "      Drug_grid = fig.add_subplot(gs2[-1, i])\n",
        "      drug_GY = GY_gridplot(drug, Drug_grid, label_show=False, title_pos=-0.6)\n",
        "      i+=1\n",
        "\n",
        "legend_elements = [Patch(facecolor='plum', edgecolor='plum', label='Logistic Regression'),\n",
        "                   Patch(facecolor='cadetblue', edgecolor='cadetblue', label='Random Forest'),\n",
        "                   Patch(facecolor='goldenrod', edgecolor='goldenrod', label='Extreme Gradient Boosted Tree'),\n",
        "                   Patch(facecolor='steelblue', edgecolor='steelblue', label='Neural Network'),\n",
        "                   Patch(facecolor='black', edgecolor=\"black\", label='Used'),\n",
        "                   Patch(facecolor='white', edgecolor=\"black\",label='Not Used')]\n",
        "\n",
        "plt.legend(handles=legend_elements,loc = 'lower center', bbox_to_anchor=(-6.1, -1), prop ={'size': 15}, borderaxespad=-3, ncol = 3)\n",
        "\n",
        "# saving plot as a jpg image (Make sure to change names if you plan to create more than one!)\n",
        "plt.savefig('/content/drive/MyDrive/EColi_ML_Plots/Final_Metrics_Plot.jpg',dpi=400, bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "phhRs6WNd77S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that, over all, the extreme gradient-boosted tree model does very well, and has the highest accuracy and recall for many of the drugs. We also see that gene presence-absence data are most likely to be included in the best-scoring models, whereas year of isolation is least likely to be included. Finally, we notice big differences between drugs and between resistance and susceptibility. This may be explained by the fact that for some of the drugs, the number of resistant strains is low, which makes it hard for the models to “learn” to recognize them.\n",
        "\n",
        "It is also important to acknowledge that the graph only shows the best results using only regular K-fold validation, therefore it is left as a future exercise to recreate this graph using instead Blocked crossvalidation or another method where population structure is taken into account.\n",
        "\n",
        "***Open Question:***\n",
        "\n",
        "What differences do you expect to see in the final graph between random k-fold crossvalidation and Stratified blocked crossvalidation?\n"
      ],
      "metadata": {
        "id": "5Cb8we75toTh"
      }
    }
  ]
}