{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNNt5B0PlNGt"
      },
      "source": [
        "\n",
        "# Get started with your own first training loop\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqpkEuelNGv"
      },
      "source": [
        "Time to wrap up everything we've learned so far in this Getting Started\n",
        "series!\n",
        "\n",
        "In this tutorial, we will be writing the most basic training loop there is\n",
        "using only components we have presented in the previous lessons.\n",
        "\n",
        "We'll be using DQN with a CartPole environment as a prototypical example.\n",
        "\n",
        "We will be voluntarily keeping the verbosity to its minimum, only linking\n",
        "each section to the related tutorial.\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "We'll be using a gym environment with a :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform. If you need a refresher, check our these features are presented in\n",
        "`the environment tutorial <gs_env_ted>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "dUjqG3vlOLPo",
        "outputId": "caa1c122-ce14-413d-b1d7-f38288e65f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensordict\n",
            "  Downloading tensordict-0.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->tensordict)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->tensordict) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->tensordict)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->tensordict) (1.3.0)\n",
            "Downloading tensordict-0.4.0-cp310-cp310-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensordict\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 tensordict-0.4.0\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Requirement already satisfied: tensordict>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchrl) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchrl) (1.3.0)\n",
            "Downloading torchrl-0.4.0-cp310-cp310-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchrl\n",
            "Successfully installed torchrl-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQwYojO2lNGx",
        "outputId": "d2759667-b8b0-4f34-9e69-0b95b3a10400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py:2989: DeprecationWarning: Your wrapper was not given a device. Currently, this value will default to 'cpu'. From v0.5 it will default to `None`. With a device of None, no device casting is performed and the resulting tensordicts are deviceless. Please set your device accordingly.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import time\n",
        "\n",
        "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
        "\n",
        "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
        "env.set_seed(0)\n",
        "\n",
        "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOr5KVyflNGy"
      },
      "source": [
        "## Designing a policy\n",
        "\n",
        "The next step is to build our policy.\n",
        "We'll be making a regular, deterministic\n",
        "version of the actor to be used within the\n",
        "`loss module <gs_optim>` and during\n",
        "`evaluation <gs_logging>`.\n",
        "Next, we will augment it with an exploration module\n",
        "for `inference <gs_storage>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRd7OOvylNGy",
        "outputId": "93863207-de3c-4dd0-f8c5-cb839658c2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
        "\n",
        "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
        "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
        "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
        "exploration_module = EGreedyModule(\n",
        "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
        ")\n",
        "policy_explore = Seq(policy, exploration_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4l6SiplNGz"
      },
      "source": [
        "## Data Collector and replay buffer\n",
        "\n",
        "Here comes the data part: we need a\n",
        "`data collector <gs_storage_collector>` to easily get batches of data\n",
        "and a `replay buffer <gs_storage_rb>` to store that data for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDIZxZSVlNGz"
      },
      "outputs": [],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
        "\n",
        "init_rand_steps = 5000\n",
        "frames_per_batch = 100\n",
        "optim_steps = 10\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=-1,\n",
        "    init_random_frames=init_rand_steps,\n",
        ")\n",
        "# rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n",
        "\n",
        "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage, ReplayBuffer, PrioritizedReplayBuffer, TensorDictReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import PrioritizedSampler, SamplerWithoutReplacement, RandomSampler\n",
        "tamanho_buffer = 100000       # Define o tamanho do buffer de replay.\n",
        "alfa = 0.6                    # Parâmetro de correção de viés de importância. Valores maiores de beta aumentam a correção.\n",
        "b = 1.0\n",
        "# rb = PrioritizedReplayBuffer(alpha = alfa, beta = b, storage = LazyTensorStorage(tamanho_buffer))\n",
        "rb = ReplayBuffer(\n",
        "    storage = LazyTensorStorage(tamanho_buffer),\n",
        "    sampler = PrioritizedSampler(\n",
        "        max_capacity = tamanho_buffer,            # A capacidade máxima do amostrador, que deve ser consistente com o tamanho do buffer de replay.\n",
        "        alpha = alfa,                             # Controla quão fortemente a prioridade afeta a amostragem. Valores maiores de @: amostragem dependa mais das prioridades.\n",
        "        beta = b)                                 # O parâmetro de correção de viés de importância. Valores maiores de beta aumentam a correção.\n",
        "    )\n",
        "\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w14rVv-dlNG0"
      },
      "source": [
        "## Loss module and optimizer\n",
        "\n",
        "We build our loss as indicated in the `dedicated tutorial <gs_optim>`, with\n",
        "its optimizer and target parameter updater:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL_w2qOllNG0"
      },
      "outputs": [],
      "source": [
        "from torchrl.objectives import DQNLoss, SoftUpdate\n",
        "\n",
        "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
        "optim = Adam(loss.parameters(), lr=0.02)\n",
        "updater = SoftUpdate(loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDh3vSc6lNG0"
      },
      "source": [
        "## Logger\n",
        "\n",
        "We'll be using a CSV logger to log our results, and save rendered videos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsOCp1a6lNG1",
        "outputId": "64a88b57-ba03-4a7f-ef41-417aa6803d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py:2989: DeprecationWarning: Your wrapper was not given a device. Currently, this value will default to 'cpu'. From v0.5 it will default to `None`. With a device of None, no device casting is performed and the resulting tensordicts are deviceless. Please set your device accordingly.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torchrl._utils import logger as torchrl_logger\n",
        "from torchrl.record import CSVLogger, VideoRecorder\n",
        "\n",
        "path = \"./training_loop\"\n",
        "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
        "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
        "record_env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqkxjGE_lNG1"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Instead of fixing a specific number of iterations to run, we will keep on\n",
        "training the network until it reaches a certain performance (arbitrarily\n",
        "defined as 200 steps in the environment -- with CartPole, success is defined\n",
        "as having longer trajectories).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6z5oUu6lNG2",
        "outputId": "6a12f8da-f500-44ed-b1eb-872ae9318585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-07-28 21:55:04,599 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,618 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,635 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,657 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,673 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,690 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,706 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,721 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,736 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,750 [torchrl][INFO] Max num steps: 98, rb length 5200\n",
            "2024-07-28 21:55:04,900 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:04,916 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:04,933 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:04,949 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:04,967 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:04,985 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:05,001 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:05,016 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:05,032 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:05,049 [torchrl][INFO] Max num steps: 115, rb length 5300\n",
            "2024-07-28 21:55:05,206 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,224 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,240 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,255 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,272 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,292 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,309 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,326 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,344 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,361 [torchrl][INFO] Max num steps: 215, rb length 5400\n",
            "2024-07-28 21:55:05,367 [torchrl][INFO] solved after 4000 steps, 80 episodes and in 4.719292879104614s.\n"
          ]
        }
      ],
      "source": [
        "total_count = 0\n",
        "total_episodes = 0\n",
        "t0 = time.time()\n",
        "for i, data in enumerate(collector):\n",
        "    # Write data in replay buffer\n",
        "    rb.extend(data)\n",
        "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
        "    if len(rb) > init_rand_steps:\n",
        "        # Optim loop (we do several optim steps\n",
        "        # per batch collected for efficiency)\n",
        "        for _ in range(optim_steps):\n",
        "            sample = rb.sample(128)\n",
        "            loss_vals = loss(sample)\n",
        "            loss_vals[\"loss\"].backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            # Update exploration factor\n",
        "            exploration_module.step(data.numel())\n",
        "            # Update target params\n",
        "            updater.step()\n",
        "            if i % 10:\n",
        "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
        "            total_count += data.numel()\n",
        "            total_episodes += data[\"next\", \"done\"].sum()\n",
        "    if max_length > 200:\n",
        "        break\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "torchrl_logger.info(\n",
        "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbwOn5mwlNG2"
      },
      "source": [
        "## Rendering\n",
        "\n",
        "Finally, we run the environment for as many steps as we can and save the\n",
        "video locally (notice that we are not exploring).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI3_TtMtlNG2"
      },
      "outputs": [],
      "source": [
        "# record_env.rollout(max_steps=1000, policy=policy)\n",
        "# video_recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFQxv_FGlNG3"
      },
      "source": [
        "This is what your rendered CartPole video will look like after a full\n",
        "training loop:\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "\n",
        "This concludes our series of \"Getting started with TorchRL\" tutorials!\n",
        "Feel free to share feedback about it on GitHub.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
