{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"06-language-as-sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as md:\n",
    "        content = md.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Мова як послідовність\n",
       "\n",
       "## Run-on Sentences\n",
       "\n",
       "### 1. Домен\n",
       "\n",
       "Цього тижня ви працюватимете над задачею виправлення помилок.\n",
       "\n",
       "Run-on речення - це речення, склеєне з двох чи більше речень без належної пунктуації. Таку помилку часто допускають механічно, коли швидко друкують текст, проте така помилка виникає і від незнання мови. Особливо часто ця помилка зустрічається в інтернет-спілкуванні.\n",
       "\n",
       "Наприклад:\n",
       "```\n",
       "Thanks for talking to me let's meet again tomorrow Bye.\n",
       "```\n",
       "\n",
       "У цьому реченні насправді три склеєні речення. Правильний варіант:\n",
       "```\n",
       "Thanks for talking to me. Let's meet again tomorrow. Bye.\n",
       "```\n",
       "\n",
       "Run-on речення важливо визначати не лише для виправлення помилок. Ця помилка впливає на якість визначення сутностей, машинного перекладу, об'єкта сентименту тощо.\n",
       "\n",
       "Більше інформації та прикладів можна знайти за посиланнями:\n",
       "- <http://www.bristol.ac.uk/arts/exercises/grammar/grammar_tutorial/page_37.htm>\n",
       "- <https://www.english-grammar-revolution.com/run-on-sentence.html>\n",
       "- <https://www.quickanddirtytips.com/education/grammar/what-are-run-on-sentences>\n",
       "\n",
       "### 2. Класифікатор\n",
       "\n",
       "Дані:\n",
       "- Згенеруйте тренувальні дані для моделі на основі відкритих корпусів. Тренувальними даними буде набір склеєних речень. Візьміть до уваги, що склеєних речень може бути кілька (зазвичай 2, але буває і 3-4), а перше слово наступного речення може писатися з великої чи малої літери.\n",
       "- Знайдіть у відкритому доступі чи зберіть самостійно базу енграмів на рівні слів чи частин мови. Завважте, що відкриті бази енграмів зазвичай містять статистику, зібрану на реченнях, а отже вони можуть не містити енграми на межі речень.\n",
       "\n",
       "Тестування:\n",
       "- Напишіть базове рішення та метрику для тестування якості.\n",
       "- Для тестування використайте корпус [run-on-test.json](run-on-test.json). Формат корпусу:\n",
       "```\n",
       "[\n",
       "  [\n",
       "    [\"Thanks\", false],\n",
       "    [\"for\", false],\n",
       "    [\"talking\", false],\n",
       "    [\"to\", false],\n",
       "    [\"me\", true],\n",
       "    [\"let\", false],\n",
       "    [\"'s\", false],\n",
       "    [\"meet\", false],\n",
       "    [\"again\", false],\n",
       "    [\"tomorrow\", true],\n",
       "    [\"Bye\", false],\n",
       "    [\".\", false]\n",
       "  ],\n",
       "...\n",
       "]\n",
       "```\n",
       "\n",
       "`true` позначає слово, після якого треба додати крапку. Тестовий корпус містить 200 токенізованих речень (~ 4700 токенів). 3% токенів мають клас `true`, а решта - `false`. Зверніть увагу, що корпус вже токенізований.\n",
       "\n",
       "Класифікатор:\n",
       "- Виділіть ознаки, які впливають на те, чи є слово на межі речень. Наприклад:\n",
       "  - правий/лівий контекст;\n",
       "  - написання слова;\n",
       "  - граматичні ознаки (чи може речення закінчитись на сполучник?);\n",
       "  - енграми (чи часто це слово і наступне йдуть поруч? чи ймовірні ці дві частини мови поруч?);\n",
       "  - глибина синтаксичного дерева чи найближчий спільний предок;\n",
       "  - ваші варіанти.\n",
       "- Побудуйте класифікатор на основі логістичної регресії чи умовних випадкових полів (CRF), який анотує послідовно слова у реченні на предмет закінчення речення.\n",
       "- Спробуйте покращити якість роботи класифікатора, змінюючи набір чи комбінацію ознак.\n",
       "- **Важливо:** під час покращення класифікатора перевіряйте його якість на своїх даних (train/test або кросвалідація).\n",
       "- Визначте фінальну якість класифікатора на тестовій вибірці.\n",
       "\n",
       "Запишіть ваші спостереження та результати в окремий файл.\n",
       "\n",
       "### Корисні посилання\n",
       "\n",
       "- [CRF tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)\n",
       "- [Google ngrams](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) (and [how to download](https://pypi.org/project/google-ngram-downloader/))\n",
       "- [Google syntactic ngrams](http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html)\n",
       "- [1 mln of 2/3/4/5-ngrams from COCA](https://www.ngrams.info/download_coca.asp)\n",
       "\n",
       "### Оцінювання\n",
       "\n",
       "100% за завдання.\n",
       "\n",
       "### Крайній термін\n",
       "\n",
       "18.04.2020\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(os.path.join(TASK_PATH, \"06-language-as-sequence.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki:\n",
    "https://dumps.wikimedia.org/simplewiki/latest/  \n",
    "Brown:\n",
    "https://www.kaggle.com/nltkdata/brown-corpus  \n",
    "Some corpus:\n",
    "https://www.kaggle.com/espn56/english-corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python WikiExtractor.py simplewiki-latest-pages-articles-multistream.xml -o wiki_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for folder in os.listdir('wiki_articles'):\n",
    "#     for fn in tqdm(os.listdir(f\"wiki_articles/{folder}\")):\n",
    "#         with open(f'wiki_articles/{folder}/{fn}') as file_:\n",
    "#             res = file_.readlines()\n",
    "#             res = \"\".join(res)\n",
    "#             res = BeautifulSoup(res, 'lxml')\n",
    "#             res = list(filter(lambda x: len(x.split()) > 10, res.get_text().split(\"\\n\")))\n",
    "#             lst.extend(res)\n",
    "\n",
    "# df = pd.DataFrame(lst, columns=['text'])\n",
    "# df.to_csv(\"simple_wiki.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428708, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki = pd.read_csv(\"simple_wiki.txt\")\n",
    "df_wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jean Bercher (known as Dauberval or D'Auberval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cri-Cri is a fictional talking cricket. The ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The character was created by Gabilondo Soler w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was made into a movie that was released on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baldwin I († 879), also known as \"Baldwin Iron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Jean Bercher (known as Dauberval or D'Auberval...\n",
       "1  Cri-Cri is a fictional talking cricket. The ch...\n",
       "2  The character was created by Gabilondo Soler w...\n",
       "3  It was made into a movie that was released on ...\n",
       "4  Baldwin I († 879), also known as \"Baldwin Iron..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_brown = pd.read_csv(\"brown.csv\")[['tokenized_text']]\n",
    "# df_brown.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_brown.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some unknown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"corpus.txt\") as file_:\n",
    "#     res = file_.readlines()\n",
    "    \n",
    "# lst = []\n",
    "# tmp = ''\n",
    "\n",
    "# for item in res:\n",
    "#     if not item.strip().endswith(\".\"):\n",
    "#         lst.append(tmp)\n",
    "#         tmp = ''\n",
    "#     else:\n",
    "#         tmp += \" \" + item.strip()\n",
    "\n",
    "# df_small = pd.DataFrame(lst, columns=['text'])\n",
    "# df_small['text'] = df_small['text'].map(lambda x: x.strip())\n",
    "# df_small = df_small.loc[df_small.text.str.len() > 0]\n",
    "\n",
    "# df_small.to_csv(\"small_corpus.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.read_csv(\"small_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When the shouting ended , the bill passed , 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-- A Houston teacher , now serving in the Legi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-- Principals of the 13 schools in the Denton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The monthly cost of ADC to more than 100,000 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Several defendants in the Summerdale police bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  When the shouting ended , the bill passed , 11...\n",
       "1  -- A Houston teacher , now serving in the Legi...\n",
       "2  -- Principals of the 13 schools in the Denton ...\n",
       "3  The monthly cost of ADC to more than 100,000 r...\n",
       "4  Several defendants in the Summerdale police bu..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.sample().values[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TASK_PATH ,'run-on-test.json')) as file_:\n",
    "    test_js = json.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \" \".join([item[0] for item in test_js[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of sentence splits in one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    145\n",
       "0     50\n",
       "2      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([sum([int(item[1] == True) for item in sample]) for sample in test_js]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4542\n",
       "1     155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for sample in test_js:\n",
    "    lst.extend([int(item[1]) for item in sample])\n",
    "pd.Series(lst).value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 80\n"
     ]
    }
   ],
   "source": [
    "up_count = 0\n",
    "low_count = 0\n",
    "\n",
    "for sample in test_js:\n",
    "    for index, item in enumerate(sample):\n",
    "        if item[1] == True:\n",
    "            if sample[index+1][0][0].isupper():\n",
    "                up_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "print(up_count, low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 79.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "\n",
    "for sample in tqdm(test_js):\n",
    "    try:\n",
    "        tokens, labels = [item[0] for item in sample], [item[1] for item in sample]\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        test_df = test_df.append(tmp_df)\n",
    "    except:\n",
    "        print(sample)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's hard I'm so proud of how we 've managed to balance and sacrifice .\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(tokens).replace(\" 'm \", \"'m \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('doublecheck')[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_token_pos</th>\n",
       "      <th>prev_token_lemma_</th>\n",
       "      <th>prev_token_ent_iob</th>\n",
       "      <th>prev_token_is_alpha</th>\n",
       "      <th>prev_token_is_digit</th>\n",
       "      <th>prev_token_is_lower</th>\n",
       "      <th>prev_token_is_upper</th>\n",
       "      <th>prev_token_is_title</th>\n",
       "      <th>prev_token_is_punct</th>\n",
       "      <th>prev_token_dep_</th>\n",
       "      <th>...</th>\n",
       "      <th>next_token_ent_iob</th>\n",
       "      <th>next_token_is_alpha</th>\n",
       "      <th>next_token_is_digit</th>\n",
       "      <th>next_token_is_lower</th>\n",
       "      <th>next_token_is_upper</th>\n",
       "      <th>next_token_is_title</th>\n",
       "      <th>next_token_is_punct</th>\n",
       "      <th>next_token_dep_</th>\n",
       "      <th>next_token_end_sen</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>start_sent</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRON</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUX</td>\n",
       "      <td>be</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERB</td>\n",
       "      <td>know</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP</td>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>monk</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>an</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>episcopalian</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333485 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prev_token_pos prev_token_lemma_  prev_token_ent_iob  prev_token_is_alpha  \\\n",
       "0           PROPN        start_sent                   2                False   \n",
       "1            PRON            -PRON-                   2                 True   \n",
       "2             AUX                be                   2                 True   \n",
       "3            VERB              know                   2                 True   \n",
       "4             ADP               for                   2                 True   \n",
       "..            ...               ...                 ...                  ...   \n",
       "27           NOUN              monk                   2                 True   \n",
       "28          PUNCT                 ,                   2                False   \n",
       "29          CCONJ               and                   2                 True   \n",
       "30            DET                an                   2                 True   \n",
       "31           NOUN      episcopalian                   3                 True   \n",
       "\n",
       "    prev_token_is_digit  prev_token_is_lower  prev_token_is_upper  \\\n",
       "0                 False                 True                False   \n",
       "1                 False                False                False   \n",
       "2                 False                 True                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "..                  ...                  ...                  ...   \n",
       "27                False                 True                False   \n",
       "28                False                False                False   \n",
       "29                False                 True                False   \n",
       "30                False                 True                False   \n",
       "31                False                 True                False   \n",
       "\n",
       "    prev_token_is_title  prev_token_is_punct  prev_token_dep_  ...  \\\n",
       "0                 False                False            False  ...   \n",
       "1                  True                False            False  ...   \n",
       "2                 False                False            False  ...   \n",
       "3                 False                False            False  ...   \n",
       "4                 False                False            False  ...   \n",
       "..                  ...                  ...              ...  ...   \n",
       "27                False                False            False  ...   \n",
       "28                False                 True             True  ...   \n",
       "29                False                False            False  ...   \n",
       "30                False                False            False  ...   \n",
       "31                False                False            False  ...   \n",
       "\n",
       "    next_token_ent_iob next_token_is_alpha next_token_is_digit  \\\n",
       "0                    2                True               False   \n",
       "1                    2                True               False   \n",
       "2                    2                True               False   \n",
       "3                    2                True               False   \n",
       "4                    3                True               False   \n",
       "..                 ...                 ...                 ...   \n",
       "27                   2                True               False   \n",
       "28                   2                True               False   \n",
       "29                   3                True               False   \n",
       "30                   2               False               False   \n",
       "31                   2               False               False   \n",
       "\n",
       "    next_token_is_lower  next_token_is_upper  next_token_is_title  \\\n",
       "0                  True                False                False   \n",
       "1                  True                False                False   \n",
       "2                  True                False                False   \n",
       "3                  True                False                False   \n",
       "4                 False                False                 True   \n",
       "..                  ...                  ...                  ...   \n",
       "27                 True                False                False   \n",
       "28                 True                False                False   \n",
       "29                 True                False                False   \n",
       "30                False                False                False   \n",
       "31                 True                False                False   \n",
       "\n",
       "    next_token_is_punct  next_token_dep_  next_token_end_sen  target  \n",
       "0                 False            False                   0   False  \n",
       "1                 False            False                   0   False  \n",
       "2                 False            False                   0   False  \n",
       "3                 False            False                   0   False  \n",
       "4                 False            False                   0   False  \n",
       "..                  ...              ...                 ...     ...  \n",
       "27                False            False                   0   False  \n",
       "28                False            False                   0   False  \n",
       "29                False            False                   0   False  \n",
       "30                 True             True                   0   False  \n",
       "31                False            False                   1   False  \n",
       "\n",
       "[333485 rows x 33 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur_token_lemma_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>manage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sacrifice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cur_token_lemma_\n",
       "0            -PRON-\n",
       "1                be\n",
       "2              hard\n",
       "3            -PRON-\n",
       "4                be\n",
       "5                so\n",
       "6             proud\n",
       "7                of\n",
       "8               how\n",
       "9            -PRON-\n",
       "10                '\n",
       "11               ve\n",
       "12           manage\n",
       "13               to\n",
       "14          balance\n",
       "15              and\n",
       "16        sacrifice\n",
       "17                ."
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(make_features(tokens))[['cur_token_lemma_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [10:45<00:00, 15.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.DataFrame()\n",
    "# failed_sentences = []\n",
    "\n",
    "# for text in tqdm(df.text.values):\n",
    "#     try:\n",
    "#         tokens, labels = prepare_train(text)\n",
    "#         tmp_df = pd.DataFrame(make_features(tokens))\n",
    "#         tmp_df['target'] = labels\n",
    "#         train_df = train_df.append(tmp_df)\n",
    "#     except:\n",
    "#         failed_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now , they say they believe that will likely happen during the current April-to-June period .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_token_pos</th>\n",
       "      <th>prev_token_lemma_</th>\n",
       "      <th>prev_token_ent_iob</th>\n",
       "      <th>prev_token_is_alpha</th>\n",
       "      <th>prev_token_is_digit</th>\n",
       "      <th>prev_token_is_lower</th>\n",
       "      <th>prev_token_is_upper</th>\n",
       "      <th>prev_token_is_title</th>\n",
       "      <th>prev_token_is_punct</th>\n",
       "      <th>prev_token_dep_</th>\n",
       "      <th>...</th>\n",
       "      <th>next_token_lemma_</th>\n",
       "      <th>next_token_ent_iob</th>\n",
       "      <th>next_token_is_alpha</th>\n",
       "      <th>next_token_is_digit</th>\n",
       "      <th>next_token_is_lower</th>\n",
       "      <th>next_token_is_upper</th>\n",
       "      <th>next_token_is_title</th>\n",
       "      <th>next_token_is_punct</th>\n",
       "      <th>next_token_dep_</th>\n",
       "      <th>next_token_end_sen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>start_sent</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADV</td>\n",
       "      <td>now</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>say</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRON</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>believe</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRON</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VERB</td>\n",
       "      <td>believe</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>will</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DET</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>likely</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VERB</td>\n",
       "      <td>will</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>happen</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADV</td>\n",
       "      <td>likely</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>during</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VERB</td>\n",
       "      <td>happen</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADP</td>\n",
       "      <td>during</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>current</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DET</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>April</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>current</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>April</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ADP</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>June</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>period</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>June</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>period</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>end_sent</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prev_token_pos prev_token_lemma_  prev_token_ent_iob  prev_token_is_alpha  \\\n",
       "0           PROPN        start_sent                   2                False   \n",
       "1             ADV               now                   2                 True   \n",
       "2           PUNCT                 ,                   2                False   \n",
       "3            PRON            -PRON-                   2                 True   \n",
       "4            VERB               say                   2                 True   \n",
       "5            PRON            -PRON-                   2                 True   \n",
       "6            VERB           believe                   2                 True   \n",
       "7             DET              that                   2                 True   \n",
       "8            VERB              will                   2                 True   \n",
       "9             ADV            likely                   2                 True   \n",
       "10           VERB            happen                   2                 True   \n",
       "11            ADP            during                   2                 True   \n",
       "12            DET               the                   2                 True   \n",
       "13            ADJ           current                   2                 True   \n",
       "14          PROPN             April                   3                 True   \n",
       "15          PUNCT                 -                   1                False   \n",
       "16            ADP                to                   1                 True   \n",
       "17          PUNCT                 -                   1                False   \n",
       "18          PROPN              June                   1                 True   \n",
       "19           NOUN            period                   2                 True   \n",
       "\n",
       "    prev_token_is_digit  prev_token_is_lower  prev_token_is_upper  \\\n",
       "0                 False                 True                False   \n",
       "1                 False                False                False   \n",
       "2                 False                False                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "5                 False                 True                False   \n",
       "6                 False                 True                False   \n",
       "7                 False                 True                False   \n",
       "8                 False                 True                False   \n",
       "9                 False                 True                False   \n",
       "10                False                 True                False   \n",
       "11                False                 True                False   \n",
       "12                False                 True                False   \n",
       "13                False                 True                False   \n",
       "14                False                False                False   \n",
       "15                False                False                False   \n",
       "16                False                 True                False   \n",
       "17                False                False                False   \n",
       "18                False                False                False   \n",
       "19                False                 True                False   \n",
       "\n",
       "    prev_token_is_title  prev_token_is_punct  prev_token_dep_  ...  \\\n",
       "0                 False                False            False  ...   \n",
       "1                  True                False            False  ...   \n",
       "2                 False                 True             True  ...   \n",
       "3                 False                False            False  ...   \n",
       "4                 False                False            False  ...   \n",
       "5                 False                False            False  ...   \n",
       "6                 False                False            False  ...   \n",
       "7                 False                False            False  ...   \n",
       "8                 False                False            False  ...   \n",
       "9                 False                False            False  ...   \n",
       "10                False                False            False  ...   \n",
       "11                False                False            False  ...   \n",
       "12                False                False            False  ...   \n",
       "13                False                False            False  ...   \n",
       "14                 True                False            False  ...   \n",
       "15                False                 True             True  ...   \n",
       "16                False                False            False  ...   \n",
       "17                False                 True             True  ...   \n",
       "18                 True                False            False  ...   \n",
       "19                False                False            False  ...   \n",
       "\n",
       "    next_token_lemma_ next_token_ent_iob next_token_is_alpha  \\\n",
       "0                   ,                  2               False   \n",
       "1              -PRON-                  2                True   \n",
       "2                 say                  2                True   \n",
       "3              -PRON-                  2                True   \n",
       "4             believe                  2                True   \n",
       "5                that                  2                True   \n",
       "6                will                  2                True   \n",
       "7              likely                  2                True   \n",
       "8              happen                  2                True   \n",
       "9              during                  2                True   \n",
       "10                the                  2                True   \n",
       "11            current                  2                True   \n",
       "12              April                  3                True   \n",
       "13                  -                  1               False   \n",
       "14                 to                  1                True   \n",
       "15                  -                  1               False   \n",
       "16               June                  1                True   \n",
       "17             period                  2                True   \n",
       "18                  .                  2               False   \n",
       "19           end_sent                  2               False   \n",
       "\n",
       "    next_token_is_digit  next_token_is_lower  next_token_is_upper  \\\n",
       "0                 False                False                False   \n",
       "1                 False                 True                False   \n",
       "2                 False                 True                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "5                 False                 True                False   \n",
       "6                 False                 True                False   \n",
       "7                 False                 True                False   \n",
       "8                 False                 True                False   \n",
       "9                 False                 True                False   \n",
       "10                False                 True                False   \n",
       "11                False                 True                False   \n",
       "12                False                False                False   \n",
       "13                False                False                False   \n",
       "14                False                 True                False   \n",
       "15                False                False                False   \n",
       "16                False                False                False   \n",
       "17                False                 True                False   \n",
       "18                False                False                False   \n",
       "19                False                 True                False   \n",
       "\n",
       "    next_token_is_title  next_token_is_punct  next_token_dep_  \\\n",
       "0                 False                 True             True   \n",
       "1                 False                False            False   \n",
       "2                 False                False            False   \n",
       "3                 False                False            False   \n",
       "4                 False                False            False   \n",
       "5                 False                False            False   \n",
       "6                 False                False            False   \n",
       "7                 False                False            False   \n",
       "8                 False                False            False   \n",
       "9                 False                False            False   \n",
       "10                False                False            False   \n",
       "11                False                False            False   \n",
       "12                 True                False            False   \n",
       "13                False                 True             True   \n",
       "14                False                False            False   \n",
       "15                False                 True             True   \n",
       "16                 True                False            False   \n",
       "17                False                False            False   \n",
       "18                False                 True             True   \n",
       "19                False                False            False   \n",
       "\n",
       "    next_token_end_sen  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  \n",
       "15                   0  \n",
       "16                   0  \n",
       "17                   0  \n",
       "18                   0  \n",
       "19                   1  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(make_features(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428708/428708 [59:04<00:00, 120.94it/s] \n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "\n",
    "for x in tqdm(df_wiki['text'].values):\n",
    "    lst.append([sen for sen in nlp(x).sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki['sentences'] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki['sen_num'] = df_wiki.sentences.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cri-Cri is a fictional talking cricket. The character was created by Francisco Gabilondo Soler and introduced in 1934 on his own musical radio show in Mexico. Cri-Cri is known as \"el grillito cantor\", which is Spanish for \"the singing cricket\".'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.loc[df_wiki.sen_num > 1].text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wiki.sen_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_wiki.loc[df_wiki.sen_num < 4].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_wiki.loc[df_wiki.sen_num < 4].sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: re.sub(r'\\s+', \" \", re.sub(r\"(\\(.+?\\))\", \" \", x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df.text.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul O'Neill was an American music composer, lyricist, producer, and songwriter.\""
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(text, zipped=False):\n",
    "    doc = nlp(text)\n",
    "    sents = list(doc.sents)\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for index, sen in enumerate(sents):\n",
    "        tkns = [token.text for token in sen]\n",
    "        if index > 0 and np.random.rand() > 0.5:\n",
    "            tkns[0] = tkns[0].lower()\n",
    "        if index != len(sents)-1:\n",
    "            tkns = tkns[:-1]\n",
    "        tokens.extend(tkns)\n",
    "        lbls = [False for i in range(len(tkns)-1)] + [True]\n",
    "        labels.extend(lbls)\n",
    "    labels[-1] = False\n",
    "    if sum(labels) != len(sents) - 1:\n",
    "        raise ValueError(f\"there is a problem with sentence=*{text}*\")\n",
    "    if zipped:\n",
    "        return list(zip(tokens, labels))\n",
    "    else:\n",
    "        return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(tokens):\n",
    "    text = \" \".join(tokens).replace(\"-\", \"\")\n",
    "    text = re.sub(r\".*(\\\")\\w\", \"\", text)\n",
    "#     for item in [\"-\", \",\", \".\"]:\n",
    "#         text = text.replace(\" {item} \", \"{item}\")\n",
    "    for k, v in [(\"'m\", \"am\"), (\"'s\", \"is\"), (\"'re\", \"are\"), (\"'ve\", \"have\")]:\n",
    "        text = text.replace(k, v)\n",
    "#     print(text)\n",
    "\n",
    "    text = \"start_sent \" + text + \" end_sent\"\n",
    "    doc = nlp(text)\n",
    "    doc_range = len(doc)\n",
    "    lst = []\n",
    "    for i in range(1, doc_range - 1):\n",
    "        prev_token = doc[i-1]\n",
    "        cur_token = doc[i]\n",
    "        next_token = doc[i+1]\n",
    "        \n",
    "        features = {\n",
    "            \"prev_token_pos\": prev_token.pos_,\n",
    "            \"prev_token_lemma_\": prev_token.lemma_,\n",
    "            \"prev_token_ent_iob\": prev_token.ent_iob,\n",
    "            \"prev_token_is_alpha\": prev_token.is_alpha,\n",
    "            \"prev_token_is_digit\": prev_token.is_digit,\n",
    "            \"prev_token_is_lower\": prev_token.is_lower,\n",
    "            \"prev_token_is_upper\": prev_token.is_upper,\n",
    "            \"prev_token_is_title\": prev_token.is_title,\n",
    "            \"prev_token_is_punct\": prev_token.is_punct,\n",
    "            \"prev_token_dep_\": prev_token.is_punct,\n",
    "            \"prev_token_start_sen\": int(prev_token.text == 'start_sent'),\n",
    "            \n",
    "            \"cur_token_pos\": cur_token.pos_,\n",
    "            \"cur_token_lemma_\": cur_token.lemma_,\n",
    "            \"cur_token_ent_iob\": cur_token.ent_iob,\n",
    "            \"cur_token_is_alpha\": cur_token.is_alpha,\n",
    "            \"cur_token_is_digit\": cur_token.is_digit,\n",
    "            \"cur_token_is_lower\": cur_token.is_lower,\n",
    "            \"cur_token_is_upper\": cur_token.is_upper,\n",
    "            \"cur_token_is_title\": cur_token.is_title,\n",
    "            \"cur_token_is_punct\": cur_token.is_punct,\n",
    "            \"cur_token_dep_\": cur_token.is_punct,\n",
    "            \n",
    "            \"next_token_pos\": next_token.pos_,\n",
    "            \"next_token_lemma_\": next_token.lemma_,\n",
    "            \"next_token_ent_iob\": next_token.ent_iob,\n",
    "            \"next_token_is_alpha\": next_token.is_alpha,\n",
    "            \"next_token_is_digit\": next_token.is_digit,\n",
    "            \"next_token_is_lower\": next_token.is_lower,\n",
    "            \"next_token_is_upper\": next_token.is_upper,\n",
    "            \"next_token_is_title\": next_token.is_title,\n",
    "            \"next_token_is_punct\": next_token.is_punct,\n",
    "            \"next_token_dep_\": next_token.is_punct,\n",
    "            \"next_token_end_sen\": int(next_token.text == 'end_sent')\n",
    "        }\n",
    "        lst.append(features)\n",
    "    return lst\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:16<00:00, 25.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "failed_sentences = []\n",
    "\n",
    "for text in tqdm(df.text.values):\n",
    "    try:\n",
    "        tokens, labels = prepare_train(text)\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        train_df = train_df.append(tmp_df)\n",
    "    except:\n",
    "        failed_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"\"\"Originally Elgar wanted to write three oratorios which would belong together. \"The Apostles\" is the first one, the second one became \"The Kingdom\" but the third one, which would have been about the Last Judgement, was never written.\"\"\"\n",
    "var1 = \"\"\"Ellery Cory Stowell was a professor of international law at Columbia University and then American University in Washington, D.C. He represented the United States at The Hague Convention of 1907 and the London Naval Conference of 1909.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    161533\n",
       "True       4729\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(clf):\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    print(\"f1 macro:\", f1_score(y_test, y_pred, average='macro'))\n",
    "#     print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(train_df.drop('target', 1), train_df['target'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=train_df['target'])\n",
    "X_test, y_test = test_df.drop('target', 1), test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 1.0292742946465883, True: 35.159661644197726}"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 / y_train.value_counts(normalize=True)).to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train.to_dict('records'))\n",
    "X_dev_vec = vectorizer.transform(X_dev.to_dict('records'))\n",
    "X_test_vec = vectorizer.transform(X_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.7599012530795769\n",
      "0.5\n",
      "f1 macro: 0.7693961849150968\n",
      "1\n",
      "f1 macro: 0.7774686971235194\n",
      "5\n",
      "f1 macro: 0.7825159602608847\n",
      "10\n",
      "f1 macro: 0.8138202994141503\n",
      "100\n",
      "f1 macro: 0.7915501708605157\n"
     ]
    }
   ],
   "source": [
    "reg_interval = [0.1, 0.5, 1, 5, 10, 100]\n",
    "\n",
    "for index, interval in enumerate(reg_interval):\n",
    "    print(reg_interval[index])\n",
    "    train_eval(LinearSVC(C=interval, class_weight=class_weights, max_iter=1000))\n",
    "#     train_eval(LogisticRegression(C=i, class_weight=class_weights, max_iter=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# model = LinearSVC(C=10, class_weight=class_weights)\n",
    "model = LogisticRegression(C=10, class_weight=class_weights)\n",
    "\n",
    "model.fit(X_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98     32307\n",
      "        True       0.46      0.75      0.57       946\n",
      "\n",
      "    accuracy                           0.97     33253\n",
      "   macro avg       0.73      0.86      0.78     33253\n",
      "weighted avg       0.98      0.97      0.97     33253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.98      4542\n",
      "        True       0.41      0.79      0.54       155\n",
      "\n",
      "    accuracy                           0.96      4697\n",
      "   macro avg       0.70      0.88      0.76      4697\n",
      "weighted avg       0.97      0.96      0.96      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fscore(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    res = f1_score(y_true, y_pred, average='macro')\n",
    "    return 'macro_f1', res, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.600525624178715"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_rounds': 5000,\n",
    "    'max_depth': -1, #  8\n",
    "    'learning_rate': 0.01,  #  0.007\n",
    "    'num_leaves': 16, # was 127\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'lambda_l2': 0.9,\n",
    "    'feature_fraction': 1, #  0.8\n",
    "    'metric': 'custom',\n",
    "    'imbalance': True\n",
    "}\n",
    "\n",
    "\n",
    "lgb_clf = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.795061\n",
      "[200]\tvalid_0's macro_f1: 0.848706\n",
      "[300]\tvalid_0's macro_f1: 0.872714\n",
      "[400]\tvalid_0's macro_f1: 0.877121\n",
      "[500]\tvalid_0's macro_f1: 0.878378\n",
      "[600]\tvalid_0's macro_f1: 0.879151\n",
      "[700]\tvalid_0's macro_f1: 0.881881\n",
      "[800]\tvalid_0's macro_f1: 0.883404\n",
      "[900]\tvalid_0's macro_f1: 0.884541\n",
      "[1000]\tvalid_0's macro_f1: 0.885218\n",
      "[1100]\tvalid_0's macro_f1: 0.886827\n",
      "[1200]\tvalid_0's macro_f1: 0.887202\n",
      "[1300]\tvalid_0's macro_f1: 0.887818\n",
      "[1400]\tvalid_0's macro_f1: 0.888192\n",
      "Early stopping, best iteration is:\n",
      "[1244]\tvalid_0's macro_f1: 0.888192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               early_stopping_rounds=200, feature_fraction=1, imbalance=True,\n",
       "               importance_type='split', lambda_l2=0.9, learning_rate=0.01,\n",
       "               max_depth=-1, metric='custom', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=16, num_rounds=5000,\n",
       "               objective='binary', random_state=None, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, verbose=100)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.fit(\n",
    "    X=X_train_vec,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_dev_vec, y_dev)],\n",
    "#        early_stopping_rounds=params['early_stopping_rounds'],\n",
    "    verbose=params['verbose'],\n",
    "    eval_metric=lgb_fscore,\n",
    "#     sample_weight=y_train.map(class_weights).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99     32307\n",
      "        True       0.91      0.69      0.78       946\n",
      "\n",
      "    accuracy                           0.99     33253\n",
      "   macro avg       0.95      0.84      0.89     33253\n",
      "weighted avg       0.99      0.99      0.99     33253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      4542\n",
      "        True       0.81      0.72      0.76       155\n",
      "\n",
      "    accuracy                           0.99      4697\n",
      "   macro avg       0.90      0.86      0.88      4697\n",
      "weighted avg       0.98      0.99      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [item[0] for item in prepare_train(sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near Phoenix, rainfall from the storm caused the Narrows Dam, a small earthen dam, to fail. In other locations in Arizona, California, Nevada, and Utah, more than occurred in a few localized areas, sometimes with precipitation comparable to the entire local yearly average rainfall. Flooding was also reported in Somerton, San Diego, El Centro, Palm Springs and Indio, while 12,000 people lost power in Yuma, as well as Los Angeles and southwestern Utah.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Near', False),\n",
       " ('Phoenix', False),\n",
       " (',', False),\n",
       " ('rainfall', False),\n",
       " ('from', False),\n",
       " ('the', False),\n",
       " ('storm', False),\n",
       " ('caused', False),\n",
       " ('the', False),\n",
       " ('Narrows', False),\n",
       " ('Dam', False),\n",
       " (',', False),\n",
       " ('a', False),\n",
       " ('small', False),\n",
       " ('earthen', False),\n",
       " ('dam', False),\n",
       " (',', False),\n",
       " ('to', False),\n",
       " ('fail', True),\n",
       " ('In', False),\n",
       " ('other', False),\n",
       " ('locations', False),\n",
       " ('in', False),\n",
       " ('Arizona', False),\n",
       " (',', False),\n",
       " ('California', False),\n",
       " (',', False),\n",
       " ('Nevada', False),\n",
       " (',', False),\n",
       " ('and', False),\n",
       " ('Utah', False),\n",
       " (',', False),\n",
       " ('more', False),\n",
       " ('than', False),\n",
       " ('occurred', False),\n",
       " ('in', False),\n",
       " ('a', False),\n",
       " ('few', False),\n",
       " ('localized', False),\n",
       " ('areas', False),\n",
       " (',', False),\n",
       " ('sometimes', False),\n",
       " ('with', False),\n",
       " ('precipitation', False),\n",
       " ('comparable', False),\n",
       " ('to', False),\n",
       " ('the', False),\n",
       " ('entire', False),\n",
       " ('local', False),\n",
       " ('yearly', False),\n",
       " ('average', False),\n",
       " ('rainfall', True),\n",
       " ('flooding', False),\n",
       " ('was', False),\n",
       " ('also', False),\n",
       " ('reported', False),\n",
       " ('in', False),\n",
       " ('Somerton', False),\n",
       " (',', False),\n",
       " ('San', False),\n",
       " ('Diego', False),\n",
       " (',', False),\n",
       " ('El', False),\n",
       " ('Centro', False),\n",
       " (',', False),\n",
       " ('Palm', False),\n",
       " ('Springs', False),\n",
       " ('and', False),\n",
       " ('Indio', False),\n",
       " (',', False),\n",
       " ('while', False),\n",
       " ('12,000', False),\n",
       " ('people', False),\n",
       " ('lost', False),\n",
       " ('power', False),\n",
       " ('in', False),\n",
       " ('Yuma', False),\n",
       " (',', False),\n",
       " ('as', False),\n",
       " ('well', False),\n",
       " ('as', False),\n",
       " ('Los', False),\n",
       " ('Angeles', False),\n",
       " ('and', False),\n",
       " ('southwestern', False),\n",
       " ('Utah', False),\n",
       " ('.', False)]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sample)\n",
    "prepare_train(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for sen in doc.sents:\n",
    "# #     lst = []\n",
    "# #     for index, token in enumerate(sen):\n",
    "# #         lst.append((token.text, token.pos_, False))\n",
    "    \n",
    "#     print([(token.text, token.pos_) for token in sen])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503172740143496"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_wiki.sample().text.values[0]\n",
    "# tmp = df_small.text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bryozoa have a lophophore.\n",
      "\n",
      "All all DET\n",
      "bryozoa bryozoa PROPN\n",
      "have have AUX\n",
      "a a DET\n",
      "lophophore lophophore NOUN\n",
      ". . PUNCT\n",
      "This is a ring of ten tentacles surrounding the mouth, each tentacle covered with cilia.\n",
      "\n",
      "This this DET\n",
      "is be AUX\n",
      "a a DET\n",
      "ring ring NOUN\n",
      "of of ADP\n",
      "ten ten NUM\n",
      "tentacles tentacle NOUN\n",
      "surrounding surround VERB\n",
      "the the DET\n",
      "mouth mouth NOUN\n",
      ", , PUNCT\n",
      "each each DET\n",
      "tentacle tentacle NOUN\n",
      "covered cover VERB\n",
      "with with ADP\n",
      "cilia cilia NOUN\n",
      ". . PUNCT\n",
      "When feeding, the zooid extends the lophophore outwards; when resting it is withdrawn into the mouth to protect it from predators.\n",
      "\n",
      "When when ADV\n",
      "feeding feed VERB\n",
      ", , PUNCT\n",
      "the the DET\n",
      "zooid zooid PROPN\n",
      "extends extend VERB\n",
      "the the DET\n",
      "lophophore lophophore NOUN\n",
      "outwards outward VERB\n",
      "; ; PUNCT\n",
      "when when ADV\n",
      "resting rest VERB\n",
      "it -PRON- PRON\n",
      "is be AUX\n",
      "withdrawn withdraw VERB\n",
      "into into ADP\n",
      "the the DET\n",
      "mouth mouth NOUN\n",
      "to to PART\n",
      "protect protect VERB\n",
      "it -PRON- PRON\n",
      "from from ADP\n",
      "predators predator NOUN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sen in doc.sents:\n",
    "    print(sen)\n",
    "    print()\n",
    "    for token in sen:\n",
    "        print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opel and Vauxhall make the same vehicle but with different names, The names are: Opel Vivaro and Vauxhall Vivaro.\n",
      "\n",
      "Opel Opel PROPN\n",
      "and and CCONJ\n",
      "Vauxhall Vauxhall PROPN\n",
      "make make VERB\n",
      "the the DET\n",
      "same same ADJ\n",
      "vehicle vehicle NOUN\n",
      "but but CCONJ\n",
      "with with ADP\n",
      "different different ADJ\n",
      "names name NOUN\n",
      ", , PUNCT\n",
      "The the DET\n",
      "names name NOUN\n",
      "are be AUX\n",
      ": : PUNCT\n",
      "Opel Opel PROPN\n",
      "Vivaro Vivaro PROPN\n",
      "and and CCONJ\n",
      "Vauxhall Vauxhall PROPN\n",
      "Vivaro Vivaro PROPN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sen in doc.sents:\n",
    "    print(sen)\n",
    "    print()\n",
    "    for token in sen:\n",
    "        print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36] *",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
