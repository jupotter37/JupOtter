{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerチュートリアル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder-Decoderモデルへの前準備としてのChainerイントロダクション。\n",
    "\n",
    "公式のIntroduction to Chainerに目を通した方を対象にしています。（Chainer ver2）  \n",
    "https://docs.chainer.org/en/stable/tutorial/basic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainerの特徴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChainerはDefine by Runという思想の深層学習フレームワークです。  \n",
    "Define and Runなフレームワークと異なり、可変長系列の処理などが、より直感的書ける、またよりpythonicに書けるという利点があります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerは計算過程を保持しつつnumpy.arrayのように扱えるデータ型`Variable`をサポートしており、保持された計算過程を通して、自動的にbackpropagationが行われるようになっています。  \n",
    "そのあたりは公式のIntroductionが詳しいので、そちらを参照してください。  \n",
    "https://docs.chainer.org/en/stable/tutorial/basic.html  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerにおいては、クラスを用いてモデル記述を行います。  \n",
    "属性にニューラルネットワークのレイヤー、メソッドにそれらをいかに組み合わせて計算するかを記述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self): # 属性にどのようなレイヤーを用いるかを記述\n",
    "        self.layer1 = ...\n",
    "        self.layer2 = ...\n",
    "        \n",
    "    def __call__(self, x): # __call__メソッドにどのようにレイヤーを用いるかを記述\n",
    "        h1 = self.layer1(x)\n",
    "        h2 = self.layer2(h1)\n",
    "        ...\n",
    "        ...\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainというスーパークラスを継承することで、モデルを保存したり、CPUとGPUの切り替わりにうまく対応したりすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Chain):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__() # Chainを継承\n",
    "        with self.init_scope():\n",
    "            self.layer1 = ...\n",
    "            self.layer2 = ...\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h1 = self.layer1(x)\n",
    "        h2 = self.layer2(h1)\n",
    "        ...\n",
    "        ...\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これがChainerでモデルを記述する際の基本骨子となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainerのレイヤー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerでは様々なニューラルネットワークアーキテクチャが予め用意されています。  \n",
    "公式のReferenceを見ると、代表的なものはほぼ網羅されているのがわかります。  \n",
    "https://docs.chainer.org/en/stable/reference/links.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では、Encoder-Decoderモデルを記述する上で必要なレイヤーについて解説していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その前にまずはライブラリをインポートしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式のチュートリアルにあるものの丸写しです。  \n",
    "使わないものもあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chainer.links.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シンプルな線形変換の関数です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h = Wx + b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よく見るこれです。  \n",
    "入力次元と出力次元を指定して使います。\n",
    "\n",
    "試しに使ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力；50次元 -> 出力；10次元\n",
    "linear = L.Linear(in_size=50, out_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20個の50次元の疑似データ\n",
    "x = np.random.normal(size=(20, 50)).astype('f')\n",
    "# dtypeをfloat32にするのを忘れないように。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、Linearの場合、in_sizeを指定しなくてもかまいません。  \n",
    "in_sizeを指定しないときは、入力ベクトルの次元に自動的に合わせてくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = L.Linear(10)\n",
    "linear(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にこの関数と、好きな活性化関数を用いれば、多層パーセプトロンを書くことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    # 二つの中間層(100 -> 50)を持つ4クラス分類の多層パーセプトロン\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(100)\n",
    "            self.l2 = L.Linear(50)\n",
    "            self.l3 = L.Linear(4)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # 活性化関数はtanh\n",
    "        h1 = F.tanh(self.l1(x))\n",
    "        h2 = F.tanh(self.l2(h1))\n",
    "        \n",
    "        # 出力。これをsoftmaxなどにかければよい。\n",
    "        y = self.l3(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chainer.links.EmbedID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語id(int)の系列を、idに対応するembeddingの系列に変換してくれるレイヤーです。  \n",
    "もちろん、単語でなくとも構いません。  \n",
    "自然言語処理ではよく使います。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これもin_sizeとout_sizeを指定して使います。  \n",
    "in_sizeはボキャブラリー数、out_sizeはembeddingの次元数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000ボキャブラリーで50次元のembedding\n",
    "embed_id = L.EmbedID(in_size=1000, out_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20個で、長さ40の系列の疑似データ\n",
    "xs = np.random.randint(0, 1000, (20, 40)).astype('i')\n",
    "# dtypeをint32にするのを忘れないように。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_id(xs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このshapeは(バッチサイズ * 系列の長さ * emmbedingの次元)となっています。  \n",
    "これが、LSTMなどのRNNの入力となっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、initialWという項を指定することで、word2vecなどで獲得したembeddingを初期値することが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chainer.links.NStepLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可変長系列に対応したLSTMです。  \n",
    "n_layers(レイヤー数)、in_size(入力ベクトル次元)、out_size(隠れ状態次元)、dropout(ドロップアウト率)を指定して使います。  \n",
    "dropoutは縦方向にかかります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴的なのは、arrayではなく、arrayのlistが入力となるところです。  \n",
    "arrayのlistを受け取ることができるので、可変長の系列を扱うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_lstm = L.NStepLSTM(n_layers=2, in_size=50, out_size=100, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~999ボキャブラリーのidを１〜１５系列までランダムに並べた２０サンプルの疑似データ\n",
    "xs = [np.random.randint(0, 1000, size=np.random.randint(1, 15, 1)).astype('i')\n",
    "      for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([722, 457, 925, 479, 393,  86, 890, 826, 588,  80, 169, 295], dtype=int32),\n",
       " array([777, 633, 693, 165, 121, 219, 424, 957], dtype=int32),\n",
       " array([356, 583, 715, 923, 633, 668, 647, 877, 352], dtype=int32),\n",
       " array([682, 566, 787, 310, 394,  19], dtype=int32),\n",
       " array([908, 614, 555, 392, 640, 424, 856, 306, 792, 762, 693], dtype=int32),\n",
       " array([147, 694, 925, 560, 430, 144, 699, 362, 806, 524, 543], dtype=int32),\n",
       " array([111, 169, 145, 304], dtype=int32),\n",
       " array([778, 962, 949, 319, 867, 475, 518, 915,  87], dtype=int32),\n",
       " array([773, 788, 557, 605, 805, 307, 748, 210, 185, 225, 647], dtype=int32),\n",
       " array([662,   9, 252, 401], dtype=int32),\n",
       " array([377, 173, 318, 181, 627, 344, 831, 530,   0, 474, 519], dtype=int32),\n",
       " array([689, 898, 697, 601, 711, 806, 299, 571, 166, 523], dtype=int32),\n",
       " array([513, 989, 893, 759], dtype=int32),\n",
       " array([545, 596], dtype=int32),\n",
       " array([ 72, 856, 617, 601, 536, 344], dtype=int32),\n",
       " array([714, 903, 370, 274, 298, 303,  73, 749], dtype=int32),\n",
       " array([566, 335, 901, 471, 575, 131, 238,  14, 514, 405,  86, 302,   2], dtype=int32),\n",
       " array([143, 635, 553, 105, 164, 389, 322, 348, 947, 785, 493, 889, 688, 765], dtype=int32),\n",
       " array([623, 181, 258, 682, 843, 155], dtype=int32),\n",
       " array([791, 647, 332, 469, 909, 727,  71, 414, 569, 363, 421], dtype=int32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 50)\n",
      "(8, 50)\n",
      "(9, 50)\n",
      "(6, 50)\n",
      "(11, 50)\n",
      "(11, 50)\n",
      "(4, 50)\n",
      "(9, 50)\n",
      "(11, 50)\n",
      "(4, 50)\n",
      "(11, 50)\n",
      "(10, 50)\n",
      "(4, 50)\n",
      "(2, 50)\n",
      "(6, 50)\n",
      "(8, 50)\n",
      "(13, 50)\n",
      "(14, 50)\n",
      "(6, 50)\n",
      "(11, 50)\n"
     ]
    }
   ],
   "source": [
    "embed = [embed_id(x) for x in xs]\n",
    "for i in embed:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callする際の引数は、hx, cx, xsの３つです。それぞれ、\n",
    "\n",
    "- hx: 最初の隠れ状態\n",
    "- cy: 最初のcellの状態\n",
    "- xs: 入力（embedding）の系列\n",
    "\n",
    "となります。\n",
    "hx, cyは`None`を指定すると、自動的にzeroベクトルで埋めてくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy, cy, ys = ns_lstm(hx=None, cx=None, xs=embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyは最後のタイムステップの隠れ状態。  \n",
    "cyは最後のタイムステップのcellの状態。  \n",
    "ysは各タイムステップの隠れ状態です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyは(n_layers, batch_size, outsize)のshapeになっています。  \n",
    "今回は二層のlstmなので、hy[1]には二層目の(batch_size, outsize)のベクトルが入っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cyも同様です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ysはbatch_sizeの長さを持つリストです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各要素は(n_time_step, outsize)のshapeのVariableで、各time_stepのhidden vectorが入っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらのレイヤーを利用して、Encoder-Decoderモデルを実装することが可能です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
