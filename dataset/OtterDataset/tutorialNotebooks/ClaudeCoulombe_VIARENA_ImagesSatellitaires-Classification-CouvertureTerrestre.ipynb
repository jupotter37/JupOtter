{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAfdD6fL6jrY"
      },
      "source": [
        "<a style=\"float:left;\" href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Couverture_Terrestre/ImagesSatellitaires-Classification-CouvertureTerrestre.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<br/>\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter);\n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables;\n",
        "* Pour obtenir de l'information sur une fonction, utilisez la commande Python `help(`\"nom de la fonction\"`)`\n",
        "\n",
        "* **SVP**, déployez toutes les cellules en sélectionnant l'item « Développer les rubriques » de l'onglet « Affichage »."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPGs4XnJ70g3"
      },
      "source": [
        "# Images satellitaires - Classification de la couverture terrestre\n",
        "\n",
        "## Utilisation d'un réseau convolutif"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspiration et droits d'auteur\n",
        "\n",
        "Ce laboratoire s'inspire de plusieurs oeuvres en logiciels libres qui ont été transformées.\n",
        "\n",
        "Plus précisément, ce carnet IPython pour Google Colab est une traduction et une adaptation du tutoriel « <a href=\"https://github.com/patrickcgray/open-geo-tutorial/blob/master/notebooks/chapter_6_neural_networks.ipynb\" target='_blank'>Chapter 6: Using Neural Networks for Classification and Land Cover Mapping</a> » de <a href=\"https://github.com/patrickcgray\" target='_blank'><b>Patrick Gray</b></a> par <a href=\"https:/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Couverture_Terrestre/ImagesSatellitaires-AnalyseCouvertureTerrestre.ipynb\" target='_blank'>Claude Coulombe</a>.\n",
        "\n",
        "##### Copyright (c) 2019-2022, Patrick Gray\n",
        "##### Copyright (c) 2022-2024, Claude Coulombe"
      ],
      "metadata": {
        "id": "IufOjPPR8qnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "L'apprentissage profond est à la fois surexposé sur le plan médiatique et sous-utilisé en pratique (https://doi.org/10.1038/nature14539). Peu importe,  l'apprentissage profond constitue un puissant coffre à outils pour analyser d'énormes quantités de données. De nouvelles applications passionnantes se développent rapidement en <a href=\"https://doi.org/10.1109/MGRS.2017.2762307\" target='_blank'>télédétection</a> dans des domaines tels que la <a href=\"https://doi.org/10.1109/TGRS.2018.2872509\" target='_blank'>détection d'anomalies</a>, la <a href=\"https://doi.org/10.1109/TGRS.2016.2612821\" target='_blank'>classification des images</a> et la <a href=\"https://doi.org/10.3390/rs11070768\" target='_blank'>régression des variables biophysiques</a>.\n",
        "\n",
        "Vous expérimenterez ici un exemple simple de classification de la couverture terrestre à partir d'images satellitaires de <i>Landsat 8</i> du <i>National Landcover Dataset</i> américain comme données d'entraînement et d'un réseau convolutif profond.\n",
        "\n",
        "Lancé par la <i>NASA</i> au début des années 1970, <i>Landsat</i> est un programme d’observation de la terre basé sur une constellation de 8 satellites.  <i>Landsat</i> est destiné à des applications civiles (agriculture, utilisation des sols, foresterie, urbanisme, etc.)\n",
        "\n",
        "## Plan\n",
        "\n",
        "*   Installation de bibiothèques Python requises;\n",
        "*   Téléchargement des données depuis GitHub;\n",
        "*   Création de fonctions utilitaires;\n",
        "*   Exploration des données;\n",
        "*   Création d'une base de référence\n",
        "    * l'algorithme de la forêt aléatoire (<i>random forest</i>);\n",
        "*   Création et entraînement d'un réseau convolutif;\n",
        "*   Évaluation et comparaison du modèle."
      ],
      "metadata": {
        "id": "oD3bchy_-Bib"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrZCENKK6jrg"
      },
      "source": [
        "## Installation de bibliothèques Python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export GTIFF_SRS_SOURCE=EPSG\n",
        "!export TF_XLA_FLAGS=\"--tf_xla_enable_xla_devices=false\"\n",
        "import os\n",
        "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'"
      ],
      "metadata": {
        "id": "MsUJpI9vHlJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ClI2eJVDPx"
      },
      "outputs": [],
      "source": [
        "# Installation de bibliothèques Python\n",
        "! pip3 install geopandas rasterio matplotlib descartes scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO2Qj6Rg6jrj"
      },
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "La mise au point de réseaux de neurones implique certains processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous fixez temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YJSxwit6jrk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 42\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(GERME_ALEATOIRE)\n",
        "\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "# os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELRhbQjO6jrl"
      },
      "source": [
        "## Téléchargement des données depuis GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAnp75RiapFx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "!wget https://github.com/ClaudeCoulombe/open-geo-tutorial/blob/master/data.zip?raw=True -O data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AILE3wOX6jrn"
      },
      "source": [
        "### Décompression des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcRzCGQjmvkX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "fichier_archive = zipfile.ZipFile('data.zip','r')\n",
        "fichier_archive.extractall('.')\n",
        "fichier_archive.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7CxQbgjwHnw"
      },
      "outputs": [],
      "source": [
        "!ls -all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSKYjxRW6jrq"
      },
      "source": [
        "### Les différentes classes de couverture du sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ng4KwzvDsmq"
      },
      "outputs": [],
      "source": [
        "# Dictionnaire de toutes les classes et de leur identifiant\n",
        "classes_couverture = dict((\n",
        "    (0,  \"arrière-plan\"), # (0,  'Background'),\n",
        "    (1,  \"non-classé\"), # (1, 'Unclassified'),\n",
        "    # anthropoformé ou aménagé ?\n",
        "    (2,  \"fortement aménagé\"), # (2, 'High Intensity Developed'),\n",
        "    (3,  \"moyennement aménagé\"), # (3, 'Medium Intensity Developed'),\n",
        "    (4,  \"faiblement aménagé\"), # (4, 'Low Intensity Developed'),\n",
        "    (5,  \"espace ouvert aménagé\"),# (5, 'Open Space Developed'),\n",
        "    (6,  \"terre cultivée\"), # (6, 'Cultivated Land'),\n",
        "    (7,  \"pâturage/foin\"), # (7, 'Pasture/Hay')\n",
        "    (8,  \"prairie\"), # (8, 'Grassland'),\n",
        "    (9,  \"forêt de feuillus\"), # (9, 'Deciduous Forest'),\n",
        "    (10, \"forêt de conifères\"), # (10, 'Evergreen Forest'),\n",
        "    (11, \"forêt mixte\"), # (11, 'Mixed Forest'),\n",
        "    (12, \"arbuste/broussaille\"), # (12, 'Scrub/Shrub'),\n",
        "    (13, \"milieu humide boisé palustre\"), # (13, 'Palustrine Forested Wetland'),\n",
        "    (14, \"milieu humide arbustif/broussailleux palustre\"), # (14, 'Palustrine Scrub/Shrub Wetland'),\n",
        "    (15, \"milieu humide émergent palustre\"), # (15, 'Palustrine Emergent Wetland'),\n",
        "    (16, \"milieu humide boisé estuarien\"), # (16, 'Estuarine Forested Wetland'),\n",
        "    (17, \"milieu humide arbustif/broussailleux estuarien\"), # (17, 'Estuarine Scrub/Shrub Wetland')\n",
        "    (18, \"milieu humide émergent estuarien\"), # (18, 'Estuarine Emergent Wetland'),\n",
        "    (19, \"rivage meuble/non consolidé\"), # (19, 'Unconsolidated Shore'),\n",
        "    (20, \"terre nue\"), # (20, 'Bare Land'),\n",
        "    (21, \"eau\"), # (21, 'Water'),\n",
        "    (22, \"lit de cours d'eau palustre\"), # (22, 'Palustrine Aquatic Bed'),\n",
        "    (23, \"lit de cours d'eau estuarien\"), # (23, 'Estuarine Aquatic Bed'),\n",
        "    (24, 'toundra'), # (24, 'Tundra'),\n",
        "    (25, 'neige/glace') # (25, 'Snow/Ice')\n",
        "))\n",
        "\n",
        "print('Code exécuté!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ8PL4am6jrr"
      },
      "source": [
        "## Création de fonctions utilitaires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMUOPBUt6jrs"
      },
      "source": [
        "### Un échantillonneur d'images\n",
        "\n",
        "Échantillonneur aléatoire d'images d'entraînement définis par leurs positions x, y dans une image. L'échantillonneur tient compte des tailles différentes des classes-cibles et fournit un jeu de données d'entraînement équilibré.\n",
        "\n",
        "Cette fonction extrait un nombre nbre_donnees_entrainement + nbre_donnees_validation aléatoire d'images d'une liste de jeux de données matricielles (<i>raster</i>) fournie en entrée. Elle retourne une liste de positions d'images d'entraînement associée à une image (index_image) et une liste de positions d'images de validation également avec un index d'image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCZmrN3I6jrs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "from rasterio.plot import adjust_band\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import show\n",
        "from rasterio.windows import Window\n",
        "import rasterio.features\n",
        "import rasterio.warp\n",
        "import rasterio.mask\n",
        "\n",
        "from pyproj import Proj, transform\n",
        "from tqdm import tqdm\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "def echantillonner_images(liste_jeux_donnees_landsat,\n",
        "                  jeu_donnees_etiquettes,\n",
        "                  etiquettes_couverture,\n",
        "                  classes_couverture,\n",
        "                  nombre_donnees_d_entrainement,\n",
        "                  fusionner=False):\n",
        "\n",
        "   # Rappel: système de référence géodésique / cartographique, en anglais \"Coordinate Reference System\" (CRS)\n",
        "   # Obtenir le système de projection cartographique des étiquettes de classe-cible\n",
        "   projection_cartographique_etiquettes = Proj(jeu_donnees_etiquettes.crs)\n",
        "   # initialiser le jeu de pixel d'entraînement\n",
        "   pixels_entrainement = []\n",
        "   nbr_donnees_entrainement_par_jeu = math.ceil(nombre_donnees_d_entrainement / len(liste_jeux_donnees_landsat))\n",
        "   print(\"Nombre de donnees d'entraînement par jeu de données:\",nbr_donnees_entrainement_par_jeu)\n",
        "   print(\"Nombre d'images dans le jeu de données:\",len(liste_jeux_donnees_landsat))\n",
        "   for index, jeu_donnees_images in enumerate(liste_jeux_donnees_landsat):\n",
        "       # Combien de points de données pour chaque classe-cible?\n",
        "       points_par_classe = nbr_donnees_entrainement_par_jeu // len(np.unique(fusionner_classes(etiquettes_couverture,classes_couverture)[0]))\n",
        "       print(\"Nombre de points de données par classe-cible:\",points_par_classe)\n",
        "       # obtenir les limites (4 coins) de l'image Landsat\n",
        "       # créer un masque approximatif pour le jeu de données dans les coordonnées cartographiques\n",
        "       # cette fonction transforme les positions des pixels dans les coordonnées (rangée, colonne) en des positions spatiales (x, y)\n",
        "       points_format_matriciel = jeu_donnees_images.transform * (0, 0),\\\n",
        "                       jeu_donnees_images.transform * (jeu_donnees_images.width, 0),\\\n",
        "                       jeu_donnees_images.transform * (jeu_donnees_images.width, jeu_donnees_images.height),\\\n",
        "                       jeu_donnees_images.transform * (0, jeu_donnees_images.height)\n",
        "       print(\"points_format_matriciel:\",points_format_matriciel)\n",
        "       # Obtenir le système de projection cartographique des images\n",
        "       projection_cartographique_landsat = Proj(jeu_donnees_images.crs)\n",
        "       neo_points_format_matriciel = []\n",
        "       # convertir les limites en format matriciel d'images Landsat en coordonnées cartographique des étiquettes\n",
        "       for x,y in points_format_matriciel:\n",
        "           x,y = transform(projection_cartographique_landsat,projection_cartographique_etiquettes,x,y)\n",
        "           # convertir les coordonnées cartographiques x, y en rangées et colonnes du format de l'étiquette\n",
        "           rangee, colonne = jeu_donnees_etiquettes.index(x, y)\n",
        "           # puisque rangee, colonne est en fait y, x, donc il faut inverser leur ordre\n",
        "           neo_points_format_matriciel.append((colonne, rangee))\n",
        "       # transformer ces nouvelles coordonnées en un polygone\n",
        "       polygone_matriciel = Polygon(neo_points_format_matriciel)\n",
        "       # construire une fenêtre à partir de tuples / listes d'index de début et de fin.\n",
        "       # Window.from_slices((rangee_debut, rangee_fin), (colonne_debut, colonne_fin))\n",
        "       masque_image_etiquette = jeu_donnees_etiquettes.read(window=Window.from_slices((int(polygone_matriciel.bounds[1]),\n",
        "                                                                                   int(polygone_matriciel.bounds[3])),\n",
        "                                                                                  (int(polygone_matriciel.bounds[0]),\n",
        "                                                                                   int(polygone_matriciel.bounds[2]))))\n",
        "       if fusionner:\n",
        "           masque_image_etiquette = fusionner_classes(masque_image_etiquette,classes_couverture)[0]\n",
        "       # Boucler sur toutes les classes\n",
        "       tous_les_points_d_une_image = []\n",
        "       bar_progression = tqdm(np.unique(fusionner_classes(etiquettes_couverture,classes_couverture)[0]))\n",
        "       for classe_id in (bar_progression):\n",
        "           bar_progression.set_description(\"Traitement de la classe-cible « %s »\" % str(classes_couverture[int(classe_id)]))\n",
        "           classe_id = int(classe_id)\n",
        "           # masquer l'image du sous-ensemble d'étiquettes associée à chaque classe\n",
        "           # extraire les positions où le masque est vrai\n",
        "           rangees,colonnes = np.where(masque_image_etiquette[0] == classe_id)\n",
        "           toutes_les_positions = list(zip(rangees,colonnes))\n",
        "           # mélanger au hasard toutes les positions\n",
        "           random.shuffle(toutes_les_positions)\n",
        "           # convertir dans le système de référence géodésique / cartographique (CRS, Coordinate Reference System)\n",
        "           # des images satellitaires Landsat\n",
        "           points_coordonnees_cartographiques_landsat = []\n",
        "           if len(toutes_les_positions)!=0:\n",
        "               for r,c in toutes_les_positions[:points_par_classe]:\n",
        "               # convertir la ligne et la colonne de l'étiquette en coordonnées cartographique de l'étiquette\n",
        "                   x,y = jeu_donnees_etiquettes.xy(r+polygone_matriciel.bounds[1],c+polygone_matriciel.bounds[0])\n",
        "               # convertir de la projection cartographique des étiquettes à la projection cartographique Landsat\n",
        "                   x,y = transform(projection_cartographique_etiquettes,projection_cartographique_landsat,x,y)\n",
        "               # convertir de l'espace cartographique Landsat en rangées et colonnes\n",
        "                   r,c = jeu_donnees_images.index(x,y)\n",
        "                   points_coordonnees_cartographiques_landsat.append((r,c))\n",
        "               tous_les_points_d_une_image += points_coordonnees_cartographiques_landsat\n",
        "       liste_index_jeu_de_données = [index] * len(tous_les_points_d_une_image)\n",
        "       pixels_jeu_de_donnees = list(zip(tous_les_points_d_une_image, liste_index_jeu_de_données))\n",
        "       pixels_entrainement += pixels_jeu_de_donnees\n",
        "   random.shuffle(pixels_entrainement)\n",
        "   return (pixels_entrainement)\n",
        "\n",
        "print('Code echantillonner_images prêt!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOdUd868Sdm"
      },
      "source": [
        "### Un générateur de tuiles de pixels\n",
        "\n",
        "Puisque les images satellites sont très grandes, nous devons les diviser en tuiles plus petites.\n",
        "\n",
        "Le générateur de tuiles prend des positions de pixels et construit des tuiles de pixels au bon format.\n",
        "\n",
        "Ce générateur est fourni directement au modèle « keras » et alimente en continu les données du modèle pendant l'entraînement et la validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY7L3cXJDRQz"
      },
      "outputs": [],
      "source": [
        "# Générateur de données compatible avec Keras qui génère des tuiles et\n",
        "# des étiquettes à la volée à partir d'un ensemble de positions de pixels,\n",
        "# d'un jeu de données d'images satellitaires Landsat à 8 canaux d'images\n",
        "# et d'un jeu de données d'étiquettes décrivant la couverture terrestre\n",
        "def generer_tuiles(liste_jeux_donnees_landsat,\n",
        "                   jeu_donnees_etiquettes,\n",
        "                   classes_couverture,\n",
        "                   hauteur_tuile, largeur_tuile,\n",
        "                   positions_pixel,\n",
        "                   taille_lot,\n",
        "                   fusionner=False):\n",
        "\n",
        "    rangee_pixel = 0\n",
        "    colonne_pixel = 0\n",
        "    index_pixel = 0\n",
        "\n",
        "    # Proj effectue des transformations cartographiques,\n",
        "    # convertit la longitude, la latitude en coordonnées\n",
        "    # natives x,y de la projection cartographique et vice versa\n",
        "    projection_cartographique_etiquettes = Proj(jeu_donnees_etiquettes.crs)\n",
        "\n",
        "    # On suppose que toutes les images ont le même nombre de bandes spectrales ou canaux\n",
        "    nombre_canaux = liste_jeux_donnees_landsat[0].count\n",
        "    compteur_classes = len(classes_couverture)\n",
        "    tampon = math.ceil(hauteur_tuile / 2)\n",
        "\n",
        "    while True:\n",
        "        # nombre_canaux - 1, on enleve un canal (ou bande) parce que nous n'utilisons pas le canal QA\n",
        "        # qui est la canal de contrôle de la qualité (Quality Assessment) de l'image Landsat\n",
        "        lot_images = np.zeros((taille_lot, hauteur_tuile, largeur_tuile, nombre_canaux - 1))\n",
        "        lot_etiquettes = np.zeros((taille_lot,compteur_classes))\n",
        "        b = 0\n",
        "        while b < taille_lot:\n",
        "            # si nous sommes arrivés à la fin des données, il suffit de recommencer\n",
        "            if index_pixel >= len(positions_pixel):\n",
        "                index_pixel = 0\n",
        "            rangee_pixel, colonne_pixel = positions_pixel[index_pixel][0]\n",
        "            index_jeu_donnees = positions_pixel[index_pixel][1]\n",
        "            index_pixel += 1\n",
        "            tuile = liste_jeux_donnees_landsat[index_jeu_donnees].read(list(np.arange(1, nombre_canaux+1)),\n",
        "                                                                       window=Window(colonne_pixel - tampon,\n",
        "                                                                                     rangee_pixel - tampon,\n",
        "                                                                                     largeur_tuile,\n",
        "                                                                                     hauteur_tuile))\n",
        "            if tuile.size == 0:\n",
        "                pass\n",
        "            elif np.amax(tuile) == 0: # don't include if it is part of the image with no pixels\n",
        "                pass\n",
        "            elif np.isnan(tuile).any() == True or -9999 in tuile:\n",
        "                # nous ne voulons pas de tuiles contenant nan ou -999 qui viennent des bordures\n",
        "                # cela gaspille du temps et est inefficace\n",
        "                pass\n",
        "            elif tuile.shape != (nombre_canaux, largeur_tuile, hauteur_tuile):\n",
        "                # print('mauvaise dimension')\n",
        "                # print(tuile.shape)\n",
        "                # tuile aux mauvaises dimensions\n",
        "                pass\n",
        "            elif np.isin(tuile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
        "                # le pixel ne doit pas être un nuage\n",
        "                # cela semble assez inefficace\n",
        "                # lire: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
        "                # print(\"J'ai trouvé un nuage!\")\n",
        "                # print(tuile[7,:,:])\n",
        "                pass\n",
        "            else:\n",
        "                # retrait de la bande de contrôle de qualité (QA pour Quality Assessment) qui n'est pas utilisée\n",
        "                tuile = tuile[0:7]\n",
        "                # reformater du format matriciel (raster) au format d'image normalisé\n",
        "                tuile_reformatee = (reshape_as_image(tuile)  - 982.5) / 1076.5\n",
        "\n",
        "                # obtenir l'étiquette de la classe-cible\n",
        "                # obtenir la géolocalisation du pixel dans l'image\n",
        "                (x, y) = liste_jeux_donnees_landsat[index_jeu_donnees].xy(rangee_pixel, colonne_pixel)\n",
        "\n",
        "                # si la projection cartographique des étiquettes est différente\n",
        "                # convertir la localisation du point à partir duquel nous échantillonnons en la même projection que\n",
        "                # l'ensemble de données d'étiquettes si nécessaire\n",
        "                # Rappel: système de référence géodésique / cartographique - Coordinate Reference System (CRS)\n",
        "                projection_cartographique_landsat = Proj(liste_jeux_donnees_landsat[0].crs)\n",
        "                # projection_cartographique_images = Proj(jeu_donnees_images.crs)\n",
        "                if projection_cartographique_landsat != projection_cartographique_etiquettes:\n",
        "                    x,y = transform(projection_cartographique_landsat,projection_cartographique_etiquettes,x,y)\n",
        "                # coordonnées de référence de l'étiquette\n",
        "                rangee, colonne = jeu_donnees_etiquettes.index(x,y)\n",
        "                # trouver l'étiquette\n",
        "                # l'image de l'étiquette pourrait être énorme, nous en avons donc besoin pour obtenir une seule position\n",
        "                fenetre = ((rangee, rangee+1), (colonne, colonne+1))\n",
        "                donnees, classes_couverture = fusionner_classes(jeu_donnees_etiquettes.read(1,\n",
        "                                                                                window=fenetre,\n",
        "                                                                                masked=False,\n",
        "                                                                                boundless=True),\n",
        "                                                            classes_couverture)\n",
        "                etiquette = donnees[0,0]\n",
        "                # si cette étiquette fait partie d'une couverture non classée alors ignorez la\n",
        "                if etiquette == 0 or np.isnan(etiquette).any() == True:\n",
        "                    pass\n",
        "                else:\n",
        "                    # ajouter l'étiquette au lot avec un encodage à un bit discriminant (hot encoding)\n",
        "                    lot_etiquettes[b][etiquette] = 1\n",
        "                    lot_images[b] = tuile_reformatee\n",
        "                    b += 1\n",
        "        yield (lot_images, lot_etiquettes)\n",
        "\n",
        "print('Code generer_tuiles prêt!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUEqYMQZ8qqC"
      },
      "source": [
        "### Une fonction pour fusionner les classes en un sous-ensemble plus petit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi3Wr-e1D9xT"
      },
      "outputs": [],
      "source": [
        "def fusionner_classes(y,classes_couverture):\n",
        "\n",
        "    # reclasser 255 (pixel blanc intense) à 0 (arrière-plan)\n",
        "    y[y == 255] = 0\n",
        "\n",
        "    # regrouper \"moyennement aménagé\" 3 et \"faiblement aménagé\" 4\n",
        "    # dans \"milieu aménagé\" 2\n",
        "    y[y == 3] = 2\n",
        "    y[y == 4] = 2\n",
        "    classes_couverture[2] = \"milieu aménagé\"\n",
        "\n",
        "    # regrouper \"espace ouvert aménagé\" 5 et \"pâturage/foin\" 7\n",
        "    # dans \"terre cultivée\" 6\n",
        "    y[y == 5] = 6\n",
        "    y[y == 7] = 6\n",
        "    classes_couverture[6] = \"terre cultivée\"\n",
        "\n",
        "    # regrouper \"forêt de feuillus\" 9 et \"forêt de conifères\" 10,\n",
        "    # \"arbuste/broussaille\" 12, et \"milieu humide boisé palustre\" 13\n",
        "    # dans \"milieu forestier\" 11\n",
        "    y[y == 9] = 11\n",
        "    y[y == 10] = 11\n",
        "    y[y == 12] = 11\n",
        "    y[y == 13] = 11\n",
        "    classes_couverture[11] = \"milieu forestier\"\n",
        "\n",
        "    # regrouper \"milieu humide arbustif/broussailleux palustre\" 14\n",
        "    # \"milieu humide émergent palustre\" 15, \"milieu humide boisé estuarien\") 16\n",
        "    # et \"milieu humide arbustif/broussailleux estuarien\" 17,\n",
        "    # dans \"milieu humide\" 18\n",
        "    y[y == 14] = 18\n",
        "    y[y == 15] = 18\n",
        "    y[y == 16] = 18\n",
        "    y[y == 17] = 18\n",
        "    classes_couverture[18] = \"milieu humide\"\n",
        "\n",
        "    # regrouper \"rivage meuble/non consolidé\" 19 et \"lit de cours d'eau palustre\" 22\n",
        "    # dans \"milieu aquatique\" 21\n",
        "    y[y == 22] = 21\n",
        "    y[y == 19] = 21\n",
        "    classes_couverture[21] = \"milieu aquatique\"\n",
        "\n",
        "    return(y,classes_couverture)\n",
        "\n",
        "print('Code fusionner_classes prêt!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4EFCx718ite"
      },
      "source": [
        "### Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnqxxgogQCQj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def afficher_matrice_confusion(vraies_etiquettes, etiquettes_predites, classes, dictionnaire_classes,\n",
        "                               normaliser=False,\n",
        "                               titre=None,\n",
        "                               cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    Cette fonction affiche la matrice de confusion.\n",
        "    Une normalisation peut être appliquée au besoin\n",
        "    \"\"\"\n",
        "    if not titre:\n",
        "        if normaliser:\n",
        "            titre = 'Matrice de confusion normalisée'\n",
        "        else:\n",
        "            titre = 'Matrice de confusion sans normalisation'\n",
        "\n",
        "    # Construction de la matrice de confusion\n",
        "    cm = confusion_matrix(vraies_etiquettes, etiquettes_predites)\n",
        "    # Utilisez une seule fois les étiquettes qui apparaissent dans les données\n",
        "    classes = classes[unique_labels(vraies_etiquettes, etiquettes_predites)]\n",
        "    # convertir l'identifiant de classe en nom de classe en utilisant un dictionnaire\n",
        "    nom_classes_pour_affichage = []\n",
        "    for nom_classe_affichage in classes:\n",
        "        nom_classes_pour_affichage.append(dictionnaire_classes[nom_classe_affichage])\n",
        "    if normaliser:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    fig, axe = plt.subplots(figsize=(10,10))\n",
        "    image = axe.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    axe.figure.colorbar(image, ax=axe)\n",
        "    # montrer touts les graduations (ticks)\n",
        "    axe.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # étiqueter les graduations avec les noms de classes appropriés\n",
        "           xticklabels=nom_classes_pour_affichage, yticklabels=nom_classes_pour_affichage,\n",
        "           title=titre,\n",
        "           ylabel='Étiquette vraie',\n",
        "           xlabel='Étiquette prédite')\n",
        "\n",
        "    # faire pivoter les étiquettes et définir leur alignement.\n",
        "    plt.setp(axe.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # boucler sur les composants de la matrice de confusion et ajouter des annotations\n",
        "    fmt = '.2f' if normaliser else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            axe.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return axe\n",
        "\n",
        "print('Code afficher_matrice_confusion prêt!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfbbU4aX90T1"
      },
      "source": [
        "## Exploration des données du satellite Landsat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6gpmy-Z6jr0"
      },
      "source": [
        "### Lecture des métadonnées sur les images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt_q6_SQ48wZ"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "from pyproj import CRS\n",
        "from osgeo import gdal\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Nous allons modifier l'encodage CRS (Coordinate Reference System) de nos images pour EPSG 4326\n",
        "rasterio.Env(GTIFF_SRS_SOURCE=\"EPSG\")\n",
        "gdal.SetConfigOption(\"GTIFF_SRS_SOURCE\", \"EPSG\")\n",
        "\n",
        "donnees_landsat = gdal.Open(\"data/landsat_image.tif\")\n",
        "\n",
        "print(\"Pilote: {}/{}\".format(donnees_landsat.GetDriver().ShortName,\n",
        "                           donnees_landsat.GetDriver().LongName))\n",
        "print()\n",
        "print(\"Taille: {} x {} x {}\".format(donnees_landsat.RasterXSize,\n",
        "                                   donnees_landsat.RasterYSize,\n",
        "                                   donnees_landsat.RasterCount))\n",
        "print()\n",
        "print(\"Projection: {}\".format(donnees_landsat.GetProjection()))\n",
        "\n",
        "# PROJCS[\"WGS_1984_Albers\",\n",
        "#        GEOGCS[\"WGS 84\",\n",
        "#               DATUM[\"WGS_1984\",\n",
        "#                     SPHEROID[\"WGS 84\",\n",
        "#                              6378140,298.256999999996,\n",
        "#                              AUTHORITY[\"EPSG\",\"7030\"]],\n",
        "#                     AUTHORITY[\"EPSG\",\"6326\"]],\n",
        "#               PRIMEM[\"Greenwich\",0],\n",
        "#               UNIT[\"degree\",0.0174532925199433,\n",
        "#                    AUTHORITY[\"EPSG\",\"9122\"]],\n",
        "#               AUTHORITY[\"EPSG\",\"4326\"]],\n",
        "#        PROJECTION[\"Albers_Conic_Equal_Area\"],\n",
        "#        PARAMETER[\"latitude_of_center\",23],\n",
        "#        PARAMETER[\"longitude_of_center\",-96],\n",
        "#        PARAMETER[\"standard_parallel_1\",29.5],\n",
        "#        PARAMETER[\"standard_parallel_2\",45.5],\n",
        "#        PARAMETER[\"false_easting\",0],\n",
        "#        PARAMETER[\"false_northing\",0],\n",
        "#        UNIT[\"metre\",1,\n",
        "#             AUTHORITY[\"EPSG\",\"9001\"]],\n",
        "#        AXIS[\"Easting\",\n",
        "#             EAST],\n",
        "#        AXIS[\"Northing\",NORTH]\n",
        "#        ]\n",
        "\n",
        "geotransform = donnees_landsat.GetGeoTransform()\n",
        "if geotransform:\n",
        "   print()\n",
        "   print(\"Origine: ({}, {})\".format(geotransform[0], geotransform[3]))\n",
        "   print()\n",
        "   print(\"Taille du pixel: ({}, {})\".format(geotransform[1], geotransform[5]))\n",
        "\n",
        "# Lecture des métadonnées du fichier de données matricielles (raster) Landsat\n",
        "meta_donnees_images_landsat = rasterio.open(\"data/landsat_image.tif\")\n",
        "\n",
        "# Vérification du nombre de canaux / bandes spectrales par image\n",
        "nombre_canaux = meta_donnees_images_landsat.count\n",
        "print()\n",
        "print(\"Nombre de canaux par image: {nc}\\n\".format(nc=nombre_canaux))\n",
        "\n",
        "# Combien de rangées et de colonnes dans les données?\n",
        "rangees, colonnes = meta_donnees_images_landsat.shape\n",
        "print()\n",
        "print(\"Le format des images est: {l} rangees x {c} colonnes\\n\".format(l=rangees, c=colonnes))\n",
        "\n",
        "# Quelle est la version de la bibliothèque Rasterio:\n",
        "print()\n",
        "print(\"Version de Rasterio: {v}\\n\".format(v=rasterio.__version__))\n",
        "\n",
        "# Quel pilote (driver) a été utilisé pour lire les données matricielles (raster)?\n",
        "pilote = meta_donnees_images_landsat.driver\n",
        "print()\n",
        "print(\"Pilote données matricielles utilisé: {p}\\n\".format(p=pilote))\n",
        "\n",
        "# Quelle est la projection cartographique des données?\n",
        "projection_cartographique = meta_donnees_images_landsat.crs\n",
        "print()\n",
        "print(\"Projection cartographique utilisée:\\n\",projection_cartographique)\n",
        "\n",
        "# Pour éviter un grand nombre d'avertissements (warning) comme ci-dessous\n",
        "\n",
        "# WARNING:rasterio._env:CPLE_AppDefined in The definition of geographic CRS EPSG:4326 got from GeoTIFF keys\n",
        "# is not the same as the one from the EPSG registry, which may cause issues during reprojection operations.\n",
        "# Set GTIFF_SRS_SOURCE configuration option to EPSG to use official parameters (overriding the ones from GeoTIFF keys),\n",
        "# or to GEOKEYS to use custom values from GeoTIFF keys and drop the EPSG code.\n",
        "\n",
        "print()\n",
        "print(\"\\nModification de l'encodage CRS de nos métadonnées de nos images...\")\n",
        "with rasterio.open(\"data/landsat_image.tif\", \"r+\") as meta_donnees_images_landsat:\n",
        "   # Créer un nouvel objet CRS avec l'encodage EPSG\n",
        "   nouveau_crs = rasterio.crs.CRS.from_epsg(4326)\n",
        "   # Mettre à jour l'encodage CRS des données\n",
        "   meta_donnees_images_landsat.crs = nouveau_crs\n",
        "   # Lire et réécrire chaque bande pour mettre à jour les métadonnées en place\n",
        "   for i in range(1, meta_donnees_images_landsat.count + 1):\n",
        "     metadonnees_de_bande = meta_donnees_images_landsat.read(i)\n",
        "     meta_donnees_images_landsat.write(metadonnees_de_bande, i)\n",
        "\n",
        "# Relire le fichier de données\n",
        "meta_donnees_images_landsat = rasterio.open(\"data/landsat_image.tif\", \"r+\",GTIFF_SRS_SOURCE=\"EPSG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQOn2wwF96-5"
      },
      "source": [
        "###  Lecture et chargement en mémoire des images\n",
        "ou données matricielles (raster), images satellitaires Landsat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBgu28Kj7WHw"
      },
      "outputs": [],
      "source": [
        "images_landsat = meta_donnees_images_landsat.read()\n",
        "images_landsat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip67xgqm6jr1"
      },
      "source": [
        "### Calcul de l'indice de végétation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsFccm-9-ACt"
      },
      "source": [
        "Maintenant calculons l'indice de végétation<sup>1</sup>, un indicateur utilisé en télédétection pour évaluer si la cible observée contient de la végétation. L'indice de végétation se calcule à partir des réflectances mesurées dans les bandes visible rouge et le proche infrarouge.\n",
        "<hr/>\n",
        "<span style=\"font-size:80%\"><sup>1</sup><b>Note - terminologie:</b> En français,  « indice de végétation par différence normalisée (IVDN) » ou « indice différentiel normalisé de végétation » ou plus simplement « indice de végétation ». En anglais, « <i>Normalized Difference Vegetation Index</i> (<i>NDVI</i>) ».</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE4HiOkb7Py4"
      },
      "outputs": [],
      "source": [
        "bande_proche_infrarouge = images_landsat[4, :, :]\n",
        "bande_rouge = images_landsat[3, :, :]\n",
        "\n",
        "indice_vegetation = np.clip((bande_proche_infrarouge.astype(float) - bande_rouge.astype(float)) / (bande_proche_infrarouge.astype(float) + bande_rouge.astype(float)), -1,1)\n",
        "\n",
        "print('Code exécuté!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dyg1pGY7Sjx"
      },
      "outputs": [],
      "source": [
        "print('\\nIndice de végétation maximum: {m:.2f}'.format(m=indice_vegetation.max()))\n",
        "print('Indice de végétation moyen: {m:.2f}'.format(m=indice_vegetation.mean()))\n",
        "print('Indice de végétation médian: {m:.2f}'.format(m=np.median(indice_vegetation)))\n",
        "print('Indice de végétation minimum: {m:.2f}'.format(m=indice_vegetation.min()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB81HwU36jr2"
      },
      "source": [
        "Examinons la répartition statistique de l'indice de végétation avec un histogramme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhjFb8M_8HJ4"
      },
      "outputs": [],
      "source": [
        "figure, axes = plt.subplots(figsize=(1.62*6,6))\n",
        "# Nous pouvons définir le nombre de colonnes de l'histogramme avec l'argument `bins`\n",
        "axes.hist(indice_vegetation.flatten(), bins=50)\n",
        "plt.title(\"Histogramme de l'indice de végétation\")\n",
        "plt.xlabel(\"Indice de végétation\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJIgZNds-PP2"
      },
      "source": [
        "### Histogramme multicanal de l'image\n",
        "L'indice de végétation semble normal, regardons maintenant l'histogramme de l'image dans son intégralité.\n",
        "\n",
        "Qu'est-ce que la valeur numérique (Digital Number, DN)? Dans les systèmes de télédétection, la la valeur numérique est une valeur attribuée à un pixel, généralement sous la forme d'un entier compris entre 0 et 255 (c'est-à-dire un octet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-nqFDHh6OtK",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "figure, axes = plt.subplots(figsize=(1.62*6,6))\n",
        "\n",
        "rasterio.plot.show_hist(meta_donnees_images_landsat.read([1,2,3,4,5,6,7]),\n",
        "                        bins=100,\n",
        "                        histtype='stepfilled',\n",
        "                        lw=0.0,\n",
        "                        stacked=False,\n",
        "                        alpha=0.3,\n",
        "                        ax = axes,\n",
        "                       title=\"Histogramme multicanal de l'image\",\n",
        "                       label=[1,2,3,4,5,6,7]\n",
        "                       )\n",
        "axes.set_xlabel('Valeur numérique des pixels')\n",
        "_ = axes.set_ylabel('Fréquence')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOTMZxNz7Vx3"
      },
      "source": [
        "###  Lecture et chargement en mémoire des étiquettes ou annotation de couverture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVou6etFAgr8"
      },
      "outputs": [],
      "source": [
        "# Pour éviter un grand nombre d'avertissements (warning) comme ci-dessous\n",
        "\n",
        "# WARNING:rasterio._env:CPLE_AppDefined in The definition of geographic CRS EPSG:4326 got from GeoTIFF keys\n",
        "# is not the same as the one from the EPSG registry, which may cause issues during reprojection operations.\n",
        "# Set GTIFF_SRS_SOURCE configuration option to EPSG to use official parameters (overriding the ones from GeoTIFF keys),\n",
        "# or to GEOKEYS to use custom values from GeoTIFF keys and drop the EPSG code.\n",
        "\n",
        "# Nous allons modifier l'encodage CRS (Coordinate Reference System) de nos métadonnées d'étiquettes pour EPSG 4326\n",
        "import rasterio\n",
        "rasterio.env.GTIFF_SRS_SOURCE = 'EPSG'\n",
        "from osgeo import gdal\n",
        "gdal.SetConfigOption(\"GTIFF_SRS_SOURCE\", \"EPSG\")\n",
        "\n",
        "print()\n",
        "print(\"Modification de l'encodage CRS de nos métadonnées d'étiquettes...\")\n",
        "# Ouvrir en mode lecture & écriture\n",
        "with rasterio.open(\"data/labels_image.tif\", \"r+\") as meta_donnees_etiquettes_couverture:\n",
        "    # Créer un nouvel objet CRS avec un encodage EPSG\n",
        "    nouveau_crs = rasterio.crs.CRS.from_epsg(4326)\n",
        "    # Mettre à jour l'encodage CRS des données\n",
        "    meta_donnees_etiquettes_couverture.crs = nouveau_crs\n",
        "    # Lire et réécrire chaque bande pour mettre à jour les métadonnées en place\n",
        "    for i in range(1, meta_donnees_etiquettes_couverture.count + 1):\n",
        "      donnees_de_bande = meta_donnees_etiquettes_couverture.read(i)\n",
        "      meta_donnees_etiquettes_couverture.write(donnees_de_bande, i)\n",
        "\n",
        "# Relire le fichier de métadonnées\n",
        "meta_donnees_etiquettes_couverture = rasterio.open('data/labels_image.tif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfP3lfCS6jr3"
      },
      "outputs": [],
      "source": [
        "# Nous fusionnons des classes pour limiter le nombre de classes avec lesquelles nous travaillons\n",
        "etiquettes_couverture, classes_couverture = fusionner_classes(meta_donnees_etiquettes_couverture.read(),classes_couverture)\n",
        "etiquettes_couverture.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGuIMHzz6jr3"
      },
      "source": [
        "### Visualisation - Image Landsat, couverture terrestre et indice de végétation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2gE319v-EVj"
      },
      "source": [
        "Maintenant, nous allons visualiser l'image Landsat, une carte en fausses couleurs des de la couverture terrestre et l'indice de végétation (NDVI) côte à côte :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odb65Zhy5FRB"
      },
      "outputs": [],
      "source": [
        "from rasterio.plot import adjust_band\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import show\n",
        "\n",
        "# extraire les bandes à visualiser\n",
        "index = np.array([3, 2, 1])\n",
        "couleurs = images_landsat[index, :, :].astype(np.float64)\n",
        "\n",
        "# formater l'image Landsat en fonction de l'histogramme ci-dessus\n",
        "max_val = 2500\n",
        "min_val = 0\n",
        "\n",
        "# borner les valeurs maximales et minimales\n",
        "couleurs[couleurs[:, :, :] > max_val] = max_val\n",
        "couleurs[couleurs[:, :, :] < min_val] = min_val\n",
        "\n",
        "for b in range(couleurs.shape[0]):\n",
        "    couleurs[b, :, :] = couleurs[b, :, :] * 1 / (max_val - min_val)\n",
        "\n",
        "# Les images matricielles sont dans le format [canaux, rangees, colonnes]\n",
        "# alors qu'en général les images sont typiqueent en format [rangees, colonnes, canaux]\n",
        "# et donc notre tableau doit être reformaté\n",
        "print(couleurs.shape)\n",
        "couleurs_reformatees = reshape_as_image(couleurs)\n",
        "print(couleurs_reformatees.shape)\n",
        "\n",
        "# Configuration d'une palette de couleurs pour les cartes de terrain\n",
        "fausses_couleurs = dict((\n",
        "    (0, (245,245,245, 255)), # arrière-plan # Background\n",
        "    (1, (0,0,0)), # non-classé # Unclassified (Cloud, Shadow, etc)\n",
        "    (2, (255,0,0)), # fortement aménagé # High Intensity Developed\n",
        "    (3, (255, 110, 51)), # moyennement aménagé # Medium Intensity Developed\n",
        "    (4, (255, 162, 51)), # faiblement aménagé # Low Intensity Developed\n",
        "    (5, (255, 162, 51)), # espace ouvert aménagé # Open Space Developed\n",
        "    (6, (162, 89, 0)), # terre cultivée # Cultivated Land\n",
        "    (7, (229, 221, 50)), # pâturage/foin # Pasture/Hay\n",
        "    (8, (185, 251, 96)), # prairie # Grassland\n",
        "    (9, (83, 144, 0)), # forêt de feuillus # Deciduous Forest\n",
        "    (10, (13, 118, 0  )), # forêt de conifères # Evergreen Forest\n",
        "    (11, (62, 178, 49)), # forêt mixte / Mixed Forest\n",
        "    (12, (100, 241, 125)), # arbuste/broussaille # Scrub/Shrub\n",
        "    (13, (68, 160, 85)), # milieu humide boisé palustre # Palustrine Forested Wetland\n",
        "    (14, (118, 192, 131)), # milieu humide arbustif/broussailleux palustre # Palustrine Scrub/Shrub Wetland\n",
        "    (15, (188, 0, 211)), # milieu humide émergent palustre # Palustrine Emergent Wetland\n",
        "    (16, (188, 0, 211)), # milieu humide boisé estuarien # Estuarine Forested Wetland\n",
        "    (17, (0, 0, 0)), # milieu humide arbustif/broussailleux estuarien # Estuarine Scrub/Shrub Wetland\n",
        "    (18, (172, 0, 191)), # milieu humide émergent estuarien # Estuarine Emergent Wetland\n",
        "    (19, (159, 251, 255)), # rivage meuble/non consolidé # Unconsolidated Shore\n",
        "    (20, (172, 177, 68)), # terre nue # Bare Land\n",
        "    (21, (29, 0, 189)), # eau # Water\n",
        "    (22, (40, 40, 40)), # lit de cours d'eau palustre # Pal Bed\n",
        "))\n",
        "\n",
        "n = int(np.max(etiquettes_couverture)) + 1\n",
        "\n",
        "# Normalisation, 0 à 255 devient 0 à 1\n",
        "for index_fausse_couleur in fausses_couleurs:\n",
        "    code_fausse_couleur = fausses_couleurs[index_fausse_couleur]\n",
        "    code_fausse_couleur_normalise = [element_code / 255.0 for element_code in code_fausse_couleur]\n",
        "    fausses_couleurs[index_fausse_couleur] = code_fausse_couleur_normalise\n",
        "\n",
        "index_fausses_couleurs = [fausses_couleurs[index] for index in range(0, n)]\n",
        "\n",
        "cmap_fausses_couleurs = plt.matplotlib.colors.ListedColormap(index_fausses_couleurs,\n",
        "                                                             'Classification',\n",
        "                                                             n)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(1.62*17, 17))\n",
        "\n",
        "# Afficher l'image en couleur\n",
        "axes[0].imshow(couleurs_reformatees)\n",
        "axes[0].set_title('Image Landsat couleur')\n",
        "\n",
        "# Afficher les classes de couverture en fausses couleurs\n",
        "axes[1].imshow(etiquettes_couverture[0,:, :],\n",
        "               cmap=cmap_fausses_couleurs,\n",
        "               interpolation='none')\n",
        "import matplotlib.patches as mpatches\n",
        "items_legende =[mpatches.Patch(color=cmap_fausses_couleurs.colors[classe_id],label=classes_couverture[classe_id])\\\n",
        "                for classe_id in range(len(cmap_fausses_couleurs.colors))]\n",
        "axes[1].set_title('Classes\\nde couverture')\n",
        "axes[1].legend(handles=items_legende, loc=(1.01,0), borderaxespad=0.)\n",
        "\n",
        "# Afficher l'indice de végétation\n",
        "axes[2].imshow(indice_vegetation,\n",
        "              cmap='RdYlGn')\n",
        "axes[2].set_title('Indice de végégation')\n",
        "\n",
        "# Afficher les images\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>Attention!</b>\n",
        "\n",
        "La carte de l'indice de végétation à droite, peut être très utile aux agriculteurs pour la surveillance de leurs champs. En effet, cette carte permet d'identifier du haut des airs les parcelles où la végétation a du mal à pousser en raison du manque d'eau, du manque d'engrais ou de l'action de ravageurs."
      ],
      "metadata": {
        "id": "NUi0KCmnKNlm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-bM05N-m66"
      },
      "source": [
        "Combien y a-t-il de pixels dans chaque classe ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2unJDbI-BKyd"
      },
      "outputs": [],
      "source": [
        "unique, frequences = np.unique(etiquettes_couverture, return_counts=True)\n",
        "donnees_histogramme = [(classes_couverture[classe_id],frequences) for classe_id,frequences in list(zip(unique, frequences))]\n",
        "donnees_histogramme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_lMDjTa6jr4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(1.62*6, 6))\n",
        "plt.yscale('log')\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Type de couverture\")\n",
        "plt.ylabel(\"Log(Fréquence)\")\n",
        "plt.title(\"Répartition des types de couverture terrestre - échelle logarithmique\")\n",
        "_ = plt.bar([classe[0] for classe in donnees_histogramme], [classe[1] for classe in donnees_histogramme])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMJ3aAOQ6jr4"
      },
      "source": [
        "### Génération des données d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "dNw66ioa6jr5"
      },
      "outputs": [],
      "source": [
        "echantillon_images = echantillonner_images([meta_donnees_images_landsat],\n",
        "                                            meta_donnees_etiquettes_couverture,\n",
        "                                            etiquettes_couverture,\n",
        "                                            classes_couverture,\n",
        "                                            3000,\n",
        "                                            True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9krQTTu-tkwU"
      },
      "source": [
        "### Test du générateur de tuiles\n",
        "\n",
        "Afficher des lots d'images et d'étiquettes et vérifier leurs dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCXTnWK8J8LE",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "lot_images = None\n",
        "frequence = 0\n",
        "\n",
        "def normalize(image):\n",
        "   return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "\n",
        "for (images,etiquettes) in generer_tuiles([meta_donnees_images_landsat],\n",
        "                                          meta_donnees_etiquettes_couverture,\n",
        "                                          classes_couverture,\n",
        "                                          128, 128,\n",
        "                                          echantillon_images,\n",
        "                                          10):\n",
        "   # Arrêter après 3 lots d'images\n",
        "   if frequence > 2:\n",
        "       break\n",
        "   print(\"Format du lot d'images\")\n",
        "   print(images.shape)\n",
        "   print(\"Format du lot d'étiquettes\")\n",
        "   print(etiquettes.shape)\n",
        "   fig, axes = plt.subplots(10, 7, figsize=(1.62*10, 10))\n",
        "   for index_lot in range(10):\n",
        "       for canal in range(7):\n",
        "           image = images[index_lot,:,:,canal]\n",
        "           # plt.imshow(normalize(image))\n",
        "           axes[index_lot,canal].imshow(normalize(image))\n",
        "   plt.show()\n",
        "   print('----')\n",
        "   frequence += 1\n",
        "   lot_images =  images\n",
        "   lot_etiquettes = etiquettes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzDOqswL6jr5"
      },
      "source": [
        "### Visualisation de tuiles\n",
        "\n",
        "Maintenant, visualisons des tuiles réelles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Nzeov9QKNGx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(image):\n",
        "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(1.62*10, 10))\n",
        "axes[0,0].imshow(normalize(lot_images[0,:,:,3:6]))\n",
        "axes[0,0].set_title(classes_couverture[np.argmax(lot_etiquettes[0])])\n",
        "axes[0,1].imshow(normalize(lot_images[1,:,:,3:6]))\n",
        "axes[0,1].set_title(classes_couverture[np.argmax(lot_etiquettes[1])])\n",
        "axes[0,2].imshow(normalize(lot_images[2,:,:,3:6]))\n",
        "axes[0,2].set_title(classes_couverture[np.argmax(lot_etiquettes[2])])\n",
        "axes[1,0].imshow(normalize(lot_images[3,:,:,3:6]))\n",
        "axes[1,0].set_title(classes_couverture[np.argmax(lot_etiquettes[3])])\n",
        "axes[1,1].imshow(normalize(lot_images[4,:,:,3:6]))\n",
        "axes[1,1].set_title(classes_couverture[np.argmax(lot_etiquettes[4])])\n",
        "axes[1,2].imshow(normalize(lot_images[5,:,:,3:6]))\n",
        "axes[1,2].set_title(classes_couverture[np.argmax(lot_etiquettes[5])])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VMWZ9hMuIBO"
      },
      "source": [
        "### Générer un jeu de données d'entraînement de tuiles 1x1 pour scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVPxQPW6yks"
      },
      "outputs": [],
      "source": [
        "lot_images = None\n",
        "lot_etiquettes = None\n",
        "taille_echantillon = 500\n",
        "\n",
        "frequence = 0\n",
        "\n",
        "for (images, etiquettes) in generer_tuiles([meta_donnees_images_landsat],\n",
        "                                         meta_donnees_etiquettes_couverture,\n",
        "                                         classes_couverture,\n",
        "                                         1, 1,\n",
        "                                         echantillon_images,\n",
        "                                         taille_echantillon):\n",
        "    if frequence > 0:\n",
        "        break\n",
        "    print(\"Format du lot d'images\")\n",
        "    print(images.shape)\n",
        "    print(\"Format du lot d'étiquettes\")\n",
        "    print(etiquettes.shape)\n",
        "    print('----')\n",
        "    frequence += 1\n",
        "    lot_images =  images\n",
        "    lot_etiquettes = etiquettes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZJKYR_DTcCU"
      },
      "source": [
        "#### Reformater les données\n",
        "Reformater les données pour scikit-learn qui a besoin de données au format `(echantillons, bandes)` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZqFVntt7k2y"
      },
      "outputs": [],
      "source": [
        "lot_images[0,:,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUhfVaq28Xfi"
      },
      "outputs": [],
      "source": [
        "lot_images_reformatees = lot_images.reshape(taille_echantillon,7)\n",
        "lot_images_reformatees[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNs6MwKz-myd"
      },
      "source": [
        "### Visualiser les signatures spectrales\n",
        "\n",
        "Examinons le spectre des intensités pour les différentes bandes ou canaux. Rappelons que la réflectance est le rapport de l'intensité d'une onde réfléchie sur l'intensité de l'onde incidente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgYCvsiA8NFd"
      },
      "outputs": [],
      "source": [
        "fig, axe = plt.subplots(1,1, figsize=[1.62*8,8])\n",
        "\n",
        "liste_couleurs = ['red', # 'milieu aménagé' 2\n",
        "                  'gold', # 'terre cultivée' 6\n",
        "                  'orange', # 'prairie' 8\n",
        "                  'forestgreen', # 'milieu forestier' 11\n",
        "                  'skyblue', # 'milieu humide' 18\n",
        "                  'brown', # 'terre nue' 20\n",
        "                  'blue'] # eau 21\n",
        "\n",
        "# numbers 1-8\n",
        "nombre_canaux = np.arange(1,8)\n",
        "\n",
        "etiquettes = np.argmax(lot_etiquettes, axis=1)\n",
        "images = lot_images_reformatees\n",
        "\n",
        "classes = np.unique(etiquettes)\n",
        "for index_couleur,id_classe in enumerate(classes):\n",
        "    intensite_canal = np.mean(images[etiquettes==id_classe, :], axis=0)\n",
        "    # afficher sous forme de lignes tracées dans un graphique\n",
        "    axe.plot(nombre_canaux,\n",
        "             intensite_canal,\n",
        "             color=liste_couleurs[index_couleur],\n",
        "             label=classes_couverture[id_classe])\n",
        "\n",
        "# ajouter le nom des axes du graphique\n",
        "axe.set_xlabel('Bande #')\n",
        "axe.set_ylabel('Valeur de réflectance')\n",
        "\n",
        "# ajouter un titre au graphique\n",
        "axe.set_title(\"Spectre d'intensité des différentes bandes\")\n",
        "_ = axe.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqnFJA4o6jr7"
      },
      "source": [
        "## Création d'une base de référence pour la classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFyPPa6K_VmH"
      },
      "source": [
        "### Générer un ensemble de données d'entraînement de tuiles 1x1 pour scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNfWrnY9_DXe"
      },
      "outputs": [],
      "source": [
        "lot_images = None\n",
        "lot_etiquettes = None\n",
        "\n",
        "taille_echantillon = 800\n",
        "nombre_donnees_d_entrainement = 600\n",
        "\n",
        "frequence = 0\n",
        "\n",
        "for (images,etiquettes) in generer_tuiles([meta_donnees_images_landsat],\n",
        "                                          meta_donnees_etiquettes_couverture,\n",
        "                                          classes_couverture,1, 1,\n",
        "                                          echantillon_images,\n",
        "                                          taille_echantillon):\n",
        "    if frequence > 0:\n",
        "        break\n",
        "    print(\"Format du lot d'images\")\n",
        "    print(images.shape)\n",
        "    print(\"Format du lot d'étiquettes\")\n",
        "    print(etiquettes.shape)\n",
        "    print('----')\n",
        "    frequence += 1\n",
        "    lot_images =  images\n",
        "    lot_etiquettes = etiquettes\n",
        "\n",
        "lot_images_reformatees = lot_images.reshape(taille_echantillon,7)\n",
        "\n",
        "images_entrainement = lot_images_reformatees[:nombre_donnees_d_entrainement]\n",
        "images_validation = lot_images_reformatees[nombre_donnees_d_entrainement:]\n",
        "etiquettes_entrainemnet = np.argmax(lot_etiquettes, axis=1)[:nombre_donnees_d_entrainement]\n",
        "etiquettes_validation = np.argmax(lot_etiquettes, axis=1)[nombre_donnees_d_entrainement:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4cckuf_ihh"
      },
      "source": [
        "### Algorithme de la forêt aléatoire (<i>random forest</i>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CBzgR_L_8nV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialiser notre modèle avec 500 arbres\n",
        "foret_aleatoire = RandomForestClassifier(n_estimators=500,\n",
        "                                         oob_score=True)\n",
        "\n",
        "# Entraîner le modèle sur les données d'entraînement\n",
        "foret_aleatoire = foret_aleatoire.fit(images_entrainement, etiquettes_entrainemnet)\n",
        "\n",
        "print('Exactitude de: {accuracy:.2f}%'.format(accuracy = foret_aleatoire.score(images_validation, etiquettes_validation)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwXYA-f-A1cc"
      },
      "outputs": [],
      "source": [
        "pred_index = foret_aleatoire.predict(images_validation)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(etiquettes_validation,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               dictionnaire_classes=classes_couverture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o50pTRgkvvMU"
      },
      "outputs": [],
      "source": [
        "# Plot normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(etiquettes_validation,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               dictionnaire_classes=classes_couverture,\n",
        "                               normaliser=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pySXw7Ox6jr8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "print(\"Exactitude: {exactitude:.2f}%\".format(exactitude = accuracy_score(etiquettes_validation, pred_index)*100))\n",
        "print(\"Précision: {precision:.2f}%\".format(precision = precision_score(etiquettes_validation, pred_index, average='weighted')*100))\n",
        "print(\"Rappel: {rappel:.2f}%\".format(rappel = recall_score(etiquettes_validation, pred_index, average='weighted')*100))\n",
        "print(\"Métrique F1: {f1:.2f}%\".format(f1 = f1_score(etiquettes_validation, pred_index, average='weighted')*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjcVCo0VDZu"
      },
      "source": [
        "Ce modèle n'est pas terrible, car il classe mal une bonne partie des prairies, des terres cultivées et des terres aménagées. Voyons si nous pouvons améliorer ls résultats avec un réseau convolutif profond..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdRkZ7QDtrTF"
      },
      "source": [
        "## Création et entraînement d'un réseau convolutif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gd2CsIh6jr9"
      },
      "source": [
        "### Importer les bibliothèques `keras` nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgPrE7nfKgBK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "print(\"TensorFlow version:\",tf.__version__)\n",
        "print(\"Keras version:\",keras.__version__)\n",
        "print(\"Bibliothèques Tensorflow et Keras importées!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CSQtcDutv5R"
      },
      "source": [
        "### Définir les hyperparamètres du réseau convolutif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so-MzsE6K9wY"
      },
      "outputs": [],
      "source": [
        "taille_lot = 25\n",
        "nombre_iterations = 50\n",
        "nombre_classes = len(classes_couverture)\n",
        "\n",
        "# input image dimensions\n",
        "taille_tuile = 32\n",
        "nombre_rangees_image, nombre_colonnes_image = taille_tuile, taille_tuile\n",
        "nombre_canaux = meta_donnees_images_landsat.count- 1\n",
        "\n",
        "format_donnees_entree = (nombre_rangees_image, nombre_colonnes_image, nombre_canaux)\n",
        "print(format_donnees_entree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otFus3i5txy6"
      },
      "source": [
        "### Créer l'architecture du réseau convolutif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku9yk42NKq4g"
      },
      "outputs": [],
      "source": [
        "modele = Sequential()\n",
        "\n",
        "modele.add(Conv2D(32, (3, 3), padding='same', input_shape=format_donnees_entree))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "# modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modele.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(64, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "\n",
        "modele.add(Conv2D(64, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "# modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modele.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(128, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "# modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modele.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modele.add(Conv2D(256, (3, 3), padding='same'))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "# modele.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modele.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Flatten())\n",
        "modele.add(Dense(128))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Dense(128))\n",
        "modele.add(BatchNormalization())\n",
        "modele.add(Activation('relu'))\n",
        "modele.add(Dropout(0.25))\n",
        "\n",
        "modele.add(Dense(nombre_classes))\n",
        "modele.add(Activation('softmax'))\n",
        "\n",
        "modele.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkvcOnqLt2cz"
      },
      "source": [
        "### Choisir la fonction d'optimisation et compiler le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLAmHQJXLXBo"
      },
      "outputs": [],
      "source": [
        "planificateur_taux_apprentissage = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "optimiseur = tf.keras.optimizers.Adam(learning_rate=planificateur_taux_apprentissage)\n",
        "metrics=['accuracy']\n",
        "\n",
        "modele.compile(optimizer=optimiseur,\n",
        "               loss='categorical_crossentropy',\n",
        "               jit_compile=False,\n",
        "               metrics=metrics)\n",
        "\n",
        "print(\"Modèle compilé\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7MkRMH9t0Em"
      },
      "source": [
        "### Diviser les données entre donnés d'entraînement et données de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSvnToUNLQj4"
      },
      "outputs": [],
      "source": [
        "ratio_entrainement_vs_validation = 0.8\n",
        "pixels_validation = echantillon_images[int(len(echantillon_images)*ratio_entrainement_vs_validation):]\n",
        "echantillon_images = echantillon_images[:int(len(echantillon_images)*ratio_entrainement_vs_validation)]\n",
        "print(\"Nombre d'exemples d'entraînement: {n_entrainement} \\nNombre d'exemples de validation: {n_validation}\".\n",
        "      format(n_entrainement=len(echantillon_images),n_validation=len(pixels_validation)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faJAqfMFt-To"
      },
      "source": [
        "### Entraîner le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU8eVd2rLciQ"
      },
      "outputs": [],
      "source": [
        "traces = modele.fit(generer_tuiles([meta_donnees_images_landsat],\n",
        "                                   meta_donnees_etiquettes_couverture,\n",
        "                                   classes_couverture,\n",
        "                                   taille_tuile, taille_tuile,\n",
        "                                   echantillon_images,\n",
        "                                   taille_lot,\n",
        "                                   fusionner=True),\n",
        "                    steps_per_epoch=len(echantillon_images) // taille_lot,\n",
        "                    epochs=nombre_iterations,\n",
        "                    verbose=1,\n",
        "                    validation_data=generer_tuiles([meta_donnees_images_landsat],\n",
        "                                                   meta_donnees_etiquettes_couverture,\n",
        "                                                   classes_couverture,\n",
        "                                                   taille_tuile, taille_tuile,\n",
        "                                                   pixels_validation,\n",
        "                                                   taille_lot,\n",
        "                                                   fusionner=True),\n",
        "                    validation_steps=len(pixels_validation) // taille_lot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqyixAbf6jr_"
      },
      "source": [
        "### Affichage des courbes d'entraînement et de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z9XUkWy6jr_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(1.62*6,6))\n",
        "plt.plot(traces.history['accuracy'])\n",
        "plt.plot(traces.history['val_accuracy'])\n",
        "plt.title(\"Courbes d'exactitude du modèle\")\n",
        "plt.ylabel(\"Exactitude (%)\")\n",
        "plt.xlabel(\"Nombre d'itérations / époques\")\n",
        "_ = plt.legend(['Entraînement', 'Validation'], loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNAQYYSu6jr_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(1.62*6,6))\n",
        "plt.plot(traces.history['loss'])\n",
        "plt.plot(traces.history['val_loss'])\n",
        "plt.title(\"Courbes d'erreur d'entropie du modèle\")\n",
        "plt.ylabel(\"Erreur\")\n",
        "plt.xlabel(\"Nombre d'itérations / époques\")\n",
        "_ = plt.legend(['Entraînement', 'Validation'], loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwzGxqwR6jr_"
      },
      "source": [
        "### Génération de données test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFOgWRue6jr_"
      },
      "outputs": [],
      "source": [
        "predictions = modele.predict(generer_tuiles([meta_donnees_images_landsat],\n",
        "                                            meta_donnees_etiquettes_couverture,\n",
        "                                            classes_couverture,\n",
        "                                            taille_tuile, taille_tuile,\n",
        "                                            pixels_validation,\n",
        "                                            taille_lot,\n",
        "                                            fusionner=True),\n",
        "                             steps=len(pixels_validation) // taille_lot,\n",
        "                             verbose=1)\n",
        "\n",
        "eval_generator = generer_tuiles([meta_donnees_images_landsat],\n",
        "                                meta_donnees_etiquettes_couverture,\n",
        "                                classes_couverture,\n",
        "                                taille_tuile, taille_tuile,\n",
        "                                pixels_validation,\n",
        "                                1,\n",
        "                                fusionner=True)\n",
        "\n",
        "labels = np.empty(predictions.shape)\n",
        "frequence = 0\n",
        "while frequence < len(labels):\n",
        "    image_b, label_b = next(eval_generator)\n",
        "    labels[frequence] = label_b\n",
        "    frequence += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRTAYA-nuCE4"
      },
      "source": [
        "###  Affichage d'une matrice de confusion :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkS4y2m-6jsA"
      },
      "outputs": [],
      "source": [
        "label_index = np.argmax(labels, axis=1)\n",
        "pred_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR9xuMWgYTO7"
      },
      "outputs": [],
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(label_index,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               dictionnaire_classes=classes_couverture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB7hQr-SwLf9"
      },
      "outputs": [],
      "source": [
        "# Plot normalized confusion matrix\n",
        "_ = afficher_matrice_confusion(label_index,\n",
        "                               pred_index,\n",
        "                               classes=np.array(list(classes_couverture)),\n",
        "                               dictionnaire_classes=classes_couverture,\n",
        "                               normaliser=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM3d-X366jsA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "print(\"Exactitude: {exactitude:.2f}%\".format(exactitude = accuracy_score(label_index, pred_index)*100))\n",
        "print(\"Précision: {precision:.2f}%\".format(precision = precision_score(label_index, pred_index, average='weighted')*100))\n",
        "print(\"Rappel: {rappel:.2f}%\".format(rappel = recall_score(label_index, pred_index, average='weighted')*100))\n",
        "print(\"Métrique F1: {f1:.2f}%\".format(f1 = f1_score(label_index, pred_index, average='weighted')*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npYrIDLB6jsA"
      },
      "source": [
        "Pas mal! Environ 5 % d'amélioration pour un réseau convolutif par rapport à un algorithme d'apprentissage automatique classique comme la forêt aléatoire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB5tbfy0umpM"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Vous avez expérimenté avec un certain nombre de techniques d'exploration de données satellitaires et vu comment utiliser Keras pour construire un réseau convolutif profond pour une classification efficace de la couverture terrestre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8or116_iuohq"
      },
      "outputs": [],
      "source": [
        "print(\"Exécution du carnet web IPython terminée\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ImagesSatellitaires-Classification-CouvertureTerrestre.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}