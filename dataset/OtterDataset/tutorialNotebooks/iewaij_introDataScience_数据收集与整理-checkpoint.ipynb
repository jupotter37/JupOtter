{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据科学导论：数据收集与整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据收集\n",
    "尽管互联网上已经有很多数据集，但有时候我们需要的数据不是现成的，需要收集数据。收集这些数据通常有两种方法：爬虫和 API。\n",
    "\n",
    "爬虫就是写程序把网页上的内容抓取下来，理论上，任何你能在网上看到的数据都是可以用爬虫抓取的，但要遵守法律、网站条款和隐私权，控制爬虫的抓取速度，不要把别人服务器搞垮了。\n",
    "\n",
    "API 可以理解为网站给程序用的接口，API 给出的数据更友好，但每个网站的 API 格式都不同，需要查阅文档。有些网站不提供 API 接口，不妨去 GitHub 搜一搜，通常能找到开源的非官方 API，这些 API 其实就是打包好的爬虫，你只要调用命令就能获得数据了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬虫\n",
    "爬虫首先需要发送请求给服务器，然后服务器会发回网页内容。这个过程有多个库可以使用，例如 [requests](http://docs.python-requests.org/en/master/)。\n",
    "\n",
    "```Python\n",
    "import requests\n",
    "r = requests.get('http://httpbin.org'))\n",
    "content = r.text\n",
    "```\n",
    "\n",
    "发回网页内容后，你就能得到 HTML 代码，HTML 代码构成的就是网页的内容，它们通常长这样：\n",
    "\n",
    "```HTML\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>This is a title</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h2> Test </h2>\n",
    "    <p>Hello world!</p>\n",
    "  </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "HTML 代码的特点有：\n",
    "1. 标签通常成对出现\n",
    "2. 标题 `<h1></h1> ... <h6></h6>`\n",
    "3. 段落 `<p></p>`\n",
    "4. 换行 `<br>`\n",
    "5. href 内容是链接 `<a href=\"http://www.example.com/\">An example link</a>`\n",
    "\n",
    "在 Chrome 或者 Safari 浏览器里，你只要右键网页-检查就能找到你需要的数据对应的 HTML 代码。\n",
    "\n",
    "![](%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E4%B8%8E%E6%95%B4%E7%90%86/Screen%20Shot%202017-08-08%20at%201.03.23%20PM.png)\n",
    "\n",
    "你可以硬着头皮用正则表达式筛选出你要的数据，更好的方法是用现成的分析 HTML 的工具，例如 BeautifulSoup、[Selenium](http://selenium-python.readthedocs.org/en/latest/index.html)。\n",
    "\n",
    "```Python\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 把 Requsests 得到的内容传给 BeautifulSoup，得到 bs4 对象\n",
    "soup = BeautifulSoup(source)\n",
    "\n",
    "# 查找所有的 <a>...</a> 标签\n",
    "aTag = soup.findAll('a')\n",
    "\n",
    "# 得到链接\n",
    "atag.get('href')\n",
    "\n",
    "# 得到链接并生成列表\n",
    "link_list = [l.get('href') for l in aTag]\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "```\n",
    "\n",
    "爬取的数据可以用词典保存，Python 还有个很重要的模块叫 [collections](https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431953239820157155d21c494e5786fce303f3018c86000)，为数据科学家提供了很多工具，例如加强型词典 defaultdict 和频率计算 Counter。\n",
    "\n",
    "限于篇幅，爬虫部分就在这里结束。如果你想深入了解，这里有一些爬虫实例：\n",
    "\n",
    "[使用 urllib2 和 BeautifulSoup 爬取数据科学家所需技能](https://jessesw.com/Data-Science-Skills/)  \n",
    "[使用 LXML 和 Selenium 爬取洛杉矶 Happy Hour (PyCon 2014 Tutorial)](https://www.youtube.com/watch?v=p1iX0uxM1w8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "网站为了防止 API 被滥用，通常会要求你注册账号，访问 API 的时候要加上你的账号密钥。有些 API 能控制你的账户行为，例如用 Twitter API 可以发推，所以不要让你的密钥出现在你的代码里，而是让代码访问密钥文件得到密钥。\n",
    "\n",
    "这里有一些有意思的 API：\n",
    "\n",
    "[Twitter](https://dev.twitter.com/rest/public)  \n",
    "[烂番茄电影评分](http://developer.rottentomatoes.com/member/register)  \n",
    "\n",
    "#### JSON\n",
    "有时候 API 发回的是 JSON 格式的数据，JSON 的全称是 JavaScript Object Notation，格式和 Python 中的词典很像，但不好直接处理，需要转换成词典。\n",
    "\n",
    "```Python\n",
    "import json\n",
    "dataDict = json.loads(data)\n",
    "```\n",
    "\n",
    "#### 第三方库\n",
    "有些 API 非常复杂，例如 [Twitter](https://dev.twitter.com/rest/public)，用第三方库会省力很多，例如 [tweepy](http://tweepy.readthedocs.io/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据整理\n",
    "收集数据后，我们先要探索数据 (data discovery， data unboxing)，以对数据有基本的认识。数据可能是「脏」的，或者对我们的工作是无用的，所以还需要整理数据 (data wrangling, data prep, data munging, data transformation)，让数据更好地为分析师服务。\n",
    "\n",
    "[Kandel et al.](http://db.cs.berkeley.edu/papers/vast12-interview.pdf) (2012) 采访了35位分析师后发现，许多分析师都把大部分时间花在整理数据上，而整理数据的过程，让分析师更了解数据并能提出好的猜想。\n",
    "\n",
    "> I spend more than half of my time integrating, cleansing and transforming data without doing any actual analysis. Most of time I’m lucky if I get to do any ‘analysis’ at all…  \n",
    ">   \n",
    "> … Most of the time once you transform the data ... the insights can be scarily obvious.  \n",
    "\n",
    "普林斯顿大学统计学教授 John Tukey 在 1965 年就提出了[类似的见解](https://books.google.com.hk/books?id=C1guHWTlVVoC&lpg=PA554&ots=Gyad7RQzzG&dq=tukey%201965%20the%20flexibility%20of%20the%20informed%20human%20mind&hl=zh-CN&pg=PA554#v=onepage&q=tukey%201965%20the%20flexibility%20of%20the%20informed%20human%20mind&f=false)。Tukey 指出，统计学家要想灵活地分析数据，就必须让数据对使用者更友好，这个过程如此重要，以致于是数学、统计模型、计算机不能比拟的。 \n",
    "\n",
    "> at all stages of data analysis, the nature and detail of output, both actual and potential, need to be matched to the capabilities of the people who use it and want it … Nothing - not the careful logic of mathematics, not statistical models and theories, not the awesome arithmetic power of modern computers - nothing can substitute here for **the flexibility of the informed human mind**.  \n",
    "\n",
    "Hoaglin(2003) 有一篇[论文](https://projecteuclid.org/euclid.ss/1076102418)讨论了 John Tukey 的事迹和他对统计学的贡献。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理要点\n",
    "这里提供一个通用的整理要点，但是整理数据是个主观过程。没有一成不变的规则\n",
    "\n",
    "#### 结构 (Structure)：数据的形状\n",
    "* 数据是矩形结构（Rectangular Data）吗？\n",
    "矩形结构包含表格（用关系代数处理）和矩阵（用线性代数处理）。如果不是这两者，例如 JSON、XML，需要转换成矩形结构（Rectangular Data）。\n",
    "* 有没有超出定义的数据？例如在日期里出现了 ￥120。\n",
    "* 数据内有嵌套吗？例如在支出里出现了￥180（住宿）。\n",
    "* 数据是什么类型？定类数据（nominal）、定序数据（ordinal）还是定量数据（quantitative）？\n",
    "* 相同类型的数据格式一样吗？例如日期里出现了 4th May 和 04-05-2017\n",
    "\n",
    "#### 粒度 (Granularity): 主键的精细程度\n",
    "主键（primary key）指赋予每条数据独特性的指标，例如 `user_id`、`transaction_id`、`(City, State)`。主键的值最多出现一次，主键决定了数据的粒度。根据主键，可以把不同的数据拼合起来。\n",
    "\n",
    "#### 可信度 (Faithfulness): 数据的真实程度\n",
    "可信度只能在上下文（context）中检验，如果出现了偏离数据分布太多的异常值（outlier），有三者方法处理：  \n",
    "1. 删掉\n",
    "2. 改为最接近的非异常值（non-outlier）\n",
    "3. 保持数据原样，并添加一栏注明是否为异常值，添加一栏注明修改后的结果。\n",
    "\n",
    "#### 完整性 (Scope): 数据的完整程度\n",
    "是否有缺失的数据或者条目？可以利用数字排序推测，比如数据中房间号有101、103、104，那么我们可以认为 102 缺失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIX 命令行\n",
    "`man something` 手册（manual）的缩写，可以查看任何 UNIX 命令的指引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 `movieLens/` 文件夹下的文件目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6136\r\n",
      "-rw-r--r--@ 1 Jiawei  staff   8.2K Oct 17  2016 README.txt\r\n",
      "-rw-r--r--@ 1 Jiawei  staff   179K Oct 17  2016 links.csv\r\n",
      "-rw-r--r--@ 1 Jiawei  staff   448K Oct 17  2016 movies.csv\r\n",
      "-rw-r--r--@ 1 Jiawei  staff   2.3M Oct 17  2016 ratings.csv\r\n",
      "-rw-r--r--@ 1 Jiawei  staff    41K Oct 17  2016 tags.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh movieLens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 `README.txt` 文件全文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat movieLens/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wc 是 word count 的缩写，查看 `movieLens/movies.csv`、 `movieLens/ratings.csv` 、`movieLens/tags.csv` 文件的行数、词数、字节数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9126   39127  458390 movieLens/movies.csv\r\n",
      "  100005  100005 2438266 movieLens/ratings.csv\r\n",
      "    1297    1887   41902 movieLens/tags.csv\r\n",
      "  110428  141019 2938558 total\r\n"
     ]
    }
   ],
   "source": [
    "!wc movieLens/movies.csv movieLens/ratings.csv movieLens/tags.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 `movieLens/movies.csv`、 `movieLens/ratings.csv` 、`movieLens/tags.csv` 文件的前5行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> movieLens/movies.csv <==\r\n",
      "movieId,title,genres\r",
      "\r\n",
      "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\r",
      "\r\n",
      "2,Jumanji (1995),Adventure|Children|Fantasy\r",
      "\r\n",
      "3,Grumpier Old Men (1995),Comedy|Romance\r",
      "\r\n",
      "4,Waiting to Exhale (1995),Comedy|Drama|Romance\r",
      "\r\n",
      "\r\n",
      "==> movieLens/ratings.csv <==\r\n",
      "userId,movieId,rating,timestamp\r",
      "\r\n",
      "1,31,2.5,1260759144\r",
      "\r\n",
      "1,1029,3.0,1260759179\r",
      "\r\n",
      "1,1061,3.0,1260759182\r",
      "\r\n",
      "1,1129,2.0,1260759185\r",
      "\r\n",
      "\r\n",
      "==> movieLens/tags.csv <==\r\n",
      "userId,movieId,tag,timestamp\r",
      "\r\n",
      "15,339,sandra 'boring' bullock,1138537770\r",
      "\r\n",
      "15,1955,dentist,1193435061\r",
      "\r\n",
      "15,7478,Cambodia,1170560997\r",
      "\r\n",
      "15,32892,Russian,1170626366\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 movieLens/movies.csv movieLens/ratings.csv movieLens/tags.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "我们可以用 Pandas 做一些简单的数据操作来整理数据，在后续的章节里我们会更深入地了解 Pandas。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始前我们先设置 Jupyter Notebook 的配置文件 ast_note_interactivity，使得 Jupyter 对独占一行的所有变量或者语句都自动显示，不需要 `print`。这个技巧来源于 [Josh Devlin](https://www.zybuluo.com/hanxiaoyang/note/534296)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入 pandas 模块，缩写为 pd。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movieLens/movies.csv') # 导入 csv 文件\n",
    "ratings = pd.read_csv('movieLens/ratings.csv')\n",
    "tags = pd.read_csv('movieLens/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31123.291836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40782.633604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>164979.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movieId\n",
       "count    9125.000000\n",
       "mean    31123.291836\n",
       "std     40782.633604\n",
       "min         1.000000\n",
       "25%      2850.000000\n",
       "50%      6290.000000\n",
       "75%     56274.000000\n",
       "max    164979.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId     int64\n",
       "title      object\n",
       "genres     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies.shape\n",
    "movies.columns\n",
    "movies.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/groupby.html)过程会频繁出现在你的数据科学项目里，简而言之，该过程包括3个步骤:\n",
    "\n",
    "1. 把数据分组\n",
    "2. 对每个组应用函数\n",
    "3. 整合结果\n",
    "\n",
    "如下图所示，我们把数据分成3组，然后对每个组求均值，最后整合在一块就是一次 split-apply-combine 过程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
