{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Multinomial Naive Bayes Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Problem Set: Spam Filtering with Multinomial Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## What to expect\n",
    "\n",
    "1. Representing text as numerical or count data\n",
    "2. Reading a text corpus into a pandas DataFrame\n",
    "3. Vectorizing the dataset with CountVectorizer\n",
    "4. Building and evaluating a Spam Classifier\n",
    "5. Examining a model for further insight\n",
    "6. Tuning the vectorizer\n",
    "7. Tuning the Laplacian Correction factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['hello how are you', 'Hello are you there', 'why hello there']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use the [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert a text corpus into a sparse matrix of word or token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "# Use the fit() method of the CountVectorizer on simple_train\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'hello', 'how', 'there', 'why', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# using the transform() method, transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also convert a sparse matrix to a dense matrix\n",
    "# using the toarray() method\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>there</th>\n",
       "      <th>why</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  hello  how  there  why  you\n",
       "0    1      1    1      0    0    1\n",
       "1    1      1    0      1    0    1\n",
       "2    0      1    0      1    1    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"hello world apples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>there</th>\n",
       "      <th>why</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  hello  how  there  why  you\n",
       "0    0      1    0      0    0    0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into a pandas DataFrame\n",
    "# use names=['label', 'location','message'] as a parameter in the read_csv() method \n",
    "# finally, drop the irrelevant location columns and also rows with nan values\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = pd.read_csv(path, names=['label', 'location','message'], skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31161, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/005</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/006</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/008</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/009</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/010</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/011</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      location                                            message\n",
       "0  spam  data/000/001  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  data/000/002  Academic Qualifications available from prestig...\n",
       "2   ham  data/000/003  Greetings all. This is to verify your subscrip...\n",
       "3  spam  data/000/004  try chauncey may conferred the luscious not co...\n",
       "4   ham  data/000/005  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  data/000/006  It's working here. I have departed almost tota...\n",
       "6  spam  data/000/008  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  data/000/009  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  data/000/010  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  data/000/011  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19362\n",
       "ham     11799\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "# using the map() function or Scikit-Learn's LabelEncoder\n",
    "# spam_ham['label'].map(lambda x: 1 if x == 'spam' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "spam_ham['label'] = LabelEncoder().fit_transform(spam_ham['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>data/000/005</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      location                                            message\n",
       "0      1  data/000/001  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1      1  data/000/002  Academic Qualifications available from prestig...\n",
       "2      0  data/000/003  Greetings all. This is to verify your subscrip...\n",
       "3      1  data/000/004  try chauncey may conferred the luscious not co...\n",
       "4      0  data/000/005  It's quiet. Too quiet. Well, how about a straw..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked using the head() method\n",
    "spam_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31161,)\n",
      "(31161,)\n"
     ]
    }
   ],
   "source": [
    "# This is to define the features and labels for the CountVectorizer\n",
    "X = spam_ham['message'].fillna('')\n",
    "y = spam_ham['label']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23370,)\n",
      "(7791,)\n",
      "(23370,)\n",
      "(7791,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "# using the train_test_split() function\n",
    "# Don't forget to stratify by y and set a random_state value\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate a new count vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "# using the fit_transform() method\n",
    "# assign X_train_dtm to the output\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '0000000000status',\n",
       " '00000000message']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23370x155840 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2303897 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x155840 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix\n",
    "# using the transform() method\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a Spam Classifier\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for X_test_dtm\n",
    "preds = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849416880529657"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate balanced accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.balanced_accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate the predicted probabilities for X_test_dtm\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([5.4042997e-106, 1.0000000e-001, 2.0000000e-001, 3.0000000e-001,\n",
       "        4.0000000e-001, 5.0000000e-001, 6.0000000e-001, 7.0000000e-001,\n",
       "        8.0000000e-001, 9.0000000e-001, 1.0000000e+000]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the histogram of probabilities..\n",
    "# What does this mean? Explain.\n",
    "hist(y_pred_prob[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([9.79446291e-04, 1.00783557e-01, 2.00587668e-01, 3.00391779e-01,\n",
       "        4.00195889e-01, 5.00000000e-01, 5.99804111e-01, 6.99608221e-01,\n",
       "        7.99412332e-01, 8.99216443e-01, 9.99020554e-01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(y_pred_prob[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining the vectorized dataset and spam classifier\n",
    "\n",
    "We will examine the **count vectorizer** and **trained spam classifier** to calculate and approximate **spam ratio of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155840"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train with get_feature_names of the vect() object\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000', '0000000', '00000000', '000000000', '00000000000000', '0000000000status', '00000000message', '00000000x', '00000001', '00000001content', '00000001irdecode', '00000004', '00000010', '00000010pwm', '00000011', '0000001196', '00000049']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 20 tokens\n",
    "print(X_train_tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ｍ子様セーリングクルーザーをお持ちで', 'ｍ字開脚オナニーを机の下から盗撮', 'ｍａｉｌでのサポートは２４時間対応です', 'ｎ藤', 'ｏｌ', 'ｐｃ', 'ｐｃから簡単プロフィール作成', 'ｓクラス専門店', 'ｓ子様秘密が条件で', 'ｓｅｘを求めている', 'ｓｅｘを求めているのです', 'ｓｍ', 'ｔ165', 'ｔバックは', 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね', 'ｔバックを購入しました', 'ｔ島', 'ｔ谷', 'ｗ６２', 'ｙ里様お互いがくつろげるような']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 20 tokens\n",
    "print(X_train_tokens[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.873e+03, 4.070e+02, 3.560e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.570e+03, 5.395e+03, 2.000e+00, ..., 1.000e+00, 4.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the feature_count_ attribute,\n",
    "# MultinomialNB counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1873.,  407.,  356., ...,    0.,    0.,    0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.570e+03, 5.395e+03, 2.000e+00, ..., 1.000e+00, 4.000e+00,\n",
       "       1.000e+00])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>3570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  ham_count  spam_count\n",
       "0       00     1873.0      3570.0\n",
       "1      000      407.0      5395.0\n",
       "2     0000      356.0         2.0\n",
       "3   000000       44.0        60.0\n",
       "4  0000000        1.0         0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame()\n",
    "tokens['token'] = X_train_tokens\n",
    "tokens['ham_count'] = ham_token_count\n",
    "tokens['spam_count'] = spam_token_count\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150009</th>\n",
       "      <td>youall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154962</th>\n",
       "      <td>男性様にご理解を頂く為</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62813</th>\n",
       "      <td>fulfill</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90340</th>\n",
       "      <td>mieke</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>6003another</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  ham_count  spam_count\n",
       "150009       youall        2.0         3.0\n",
       "154962  男性様にご理解を頂く為        0.0         1.0\n",
       "62813       fulfill        5.0        49.0\n",
       "90340         mieke        2.0         0.0\n",
       "13312   6003another        1.0         0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "# using the sample() method\n",
    "tokens.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8849., 14521.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "# with the class_count_ attribute\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "# so that we can calculate the spam ratio of each token\n",
    "tokens['ham_ratio'] = (tokens['ham_count'] + 1) / tokens['ham_count'].sum()\n",
    "tokens['spam_ratio'] = (tokens['spam_count'] + 1)/ tokens['spam_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_ratio</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>7.519648e-04</td>\n",
       "      <td>1.670082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>1.637149e-04</td>\n",
       "      <td>2.523596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.432505e-04</td>\n",
       "      <td>1.403037e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.805678e-05</td>\n",
       "      <td>2.852842e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.025238e-07</td>\n",
       "      <td>4.676789e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  ham_count  spam_count     ham_ratio    spam_ratio\n",
       "0       00     1873.0      3570.0  7.519648e-04  1.670082e-03\n",
       "1      000      407.0      5395.0  1.637149e-04  2.523596e-03\n",
       "2     0000      356.0         2.0  1.432505e-04  1.403037e-06\n",
       "3   000000       44.0        60.0  1.805678e-05  2.852842e-05\n",
       "4  0000000        1.0         0.0  8.025238e-07  4.676789e-07"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into ratios\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_to_ham_ratio'] = tokens['spam_ratio'] / tokens['ham_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_ratio</th>\n",
       "      <th>spam_ratio</th>\n",
       "      <th>spam_to_ham_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68276</th>\n",
       "      <td>hb</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.010045e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95940</th>\n",
       "      <td>node</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.055042e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38625</th>\n",
       "      <td>cert</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.950714e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67431</th>\n",
       "      <td>handy</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.721995e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95979</th>\n",
       "      <td>nodes</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.633717e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106695</th>\n",
       "      <td>port</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.674701e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95666</th>\n",
       "      <td>nil</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.312528e-03</td>\n",
       "      <td>1.403037e-06</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101658</th>\n",
       "      <td>output</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.293502e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125685</th>\n",
       "      <td>starship</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.237326e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115100</th>\n",
       "      <td>ribbon</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.149048e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115670</th>\n",
       "      <td>robot</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.996568e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83760</th>\n",
       "      <td>libimlib</td>\n",
       "      <td>864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.470915e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84599</th>\n",
       "      <td>linux</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.362575e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135209</th>\n",
       "      <td>thu</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.258247e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92270</th>\n",
       "      <td>motors</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.254234e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119812</th>\n",
       "      <td>sep</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069653e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119727</th>\n",
       "      <td>sensor</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.844947e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76394</th>\n",
       "      <td>ir</td>\n",
       "      <td>656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.636291e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123867</th>\n",
       "      <td>sonar</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.596164e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120146</th>\n",
       "      <td>servo</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.483811e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>analog</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.343369e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.001996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62084</th>\n",
       "      <td>fred</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279168e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104733</th>\n",
       "      <td>pgp</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.235029e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33732</th>\n",
       "      <td>bmp</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.182865e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42617</th>\n",
       "      <td>computing</td>\n",
       "      <td>530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130701e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127763</th>\n",
       "      <td>sunbird</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.118663e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82647</th>\n",
       "      <td>lcd</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110638e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74739</th>\n",
       "      <td>input</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.181149e-04</td>\n",
       "      <td>9.353579e-07</td>\n",
       "      <td>0.002237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144069</th>\n",
       "      <td>voltage</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.074524e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135457</th>\n",
       "      <td>timedx</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.030385e-04</td>\n",
       "      <td>4.676789e-07</td>\n",
       "      <td>0.002303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117823</th>\n",
       "      <td>satisfactionmore</td>\n",
       "      <td>0.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>3.792876e-04</td>\n",
       "      <td>945.237096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48148</th>\n",
       "      <td>deliverycomplete</td>\n",
       "      <td>0.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>3.792876e-04</td>\n",
       "      <td>945.237096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32974</th>\n",
       "      <td>bilbo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>3.853674e-04</td>\n",
       "      <td>960.388862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115891</th>\n",
       "      <td>rolex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>3.895766e-04</td>\n",
       "      <td>970.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50273</th>\n",
       "      <td>discreet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>3.984625e-04</td>\n",
       "      <td>993.023435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59358</th>\n",
       "      <td>fff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>8.025238e-07</td>\n",
       "      <td>8.277917e-04</td>\n",
       "      <td>1031.485610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>5adobe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42150</th>\n",
       "      <td>compacted_image</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108211</th>\n",
       "      <td>proadobe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42151</th>\n",
       "      <td>compacted_price</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124216</th>\n",
       "      <td>sp_cont</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66231</th>\n",
       "      <td>greylink</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41273</th>\n",
       "      <td>collectionadobe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>00c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.429753e-04</td>\n",
       "      <td>1353.169258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32482</th>\n",
       "      <td>bestsellers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.504581e-04</td>\n",
       "      <td>1371.817586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145777</th>\n",
       "      <td>weightzipping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>5.579410e-04</td>\n",
       "      <td>1390.465913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>13px</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>8.025238e-07</td>\n",
       "      <td>1.364687e-03</td>\n",
       "      <td>1700.494356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154811</th>\n",
       "      <td>無料</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>6.898264e-04</td>\n",
       "      <td>1719.142684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>cantex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>7.061952e-04</td>\n",
       "      <td>1759.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45668</th>\n",
       "      <td>cs2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>7.202256e-04</td>\n",
       "      <td>1794.901514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70233</th>\n",
       "      <td>hoodia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>7.328529e-04</td>\n",
       "      <td>1826.370566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42149</th>\n",
       "      <td>compacted_description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.142290e-04</td>\n",
       "      <td>2029.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>00you</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.142290e-04</td>\n",
       "      <td>2029.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17258</th>\n",
       "      <td>95more</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.142290e-04</td>\n",
       "      <td>2029.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114855</th>\n",
       "      <td>reviewsretail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.142290e-04</td>\n",
       "      <td>2029.171127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36391</th>\n",
       "      <td>bz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.287271e-04</td>\n",
       "      <td>2065.302261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69048</th>\n",
       "      <td>hereopt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>8.633353e-04</td>\n",
       "      <td>2151.550776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108556</th>\n",
       "      <td>professionaladobe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>1.085483e-03</td>\n",
       "      <td>2705.172996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108965</th>\n",
       "      <td>proms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>1.085483e-03</td>\n",
       "      <td>2705.172996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108494</th>\n",
       "      <td>product_table</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9266.0</td>\n",
       "      <td>4.012619e-07</td>\n",
       "      <td>4.333981e-03</td>\n",
       "      <td>10800.878135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        token  ham_count  spam_count     ham_ratio  \\\n",
       "68276                      hb     1746.0         0.0  7.010045e-04   \n",
       "95940                    node     1508.0         0.0  6.055042e-04   \n",
       "38625                    cert     1482.0         0.0  5.950714e-04   \n",
       "67431                   handy     1425.0         0.0  5.721995e-04   \n",
       "95979                   nodes     1403.0         0.0  5.633717e-04   \n",
       "106695                   port     1164.0         0.0  4.674701e-04   \n",
       "95666                     nil     3270.0         2.0  1.312528e-03   \n",
       "101658                 output     1069.0         0.0  4.293502e-04   \n",
       "125685               starship     1055.0         0.0  4.237326e-04   \n",
       "115100                 ribbon     1033.0         0.0  4.149048e-04   \n",
       "115670                  robot      995.0         0.0  3.996568e-04   \n",
       "83760                libimlib      864.0         0.0  3.470915e-04   \n",
       "84599                   linux      837.0         0.0  3.362575e-04   \n",
       "135209                    thu      811.0         0.0  3.258247e-04   \n",
       "92270                  motors      810.0         0.0  3.254234e-04   \n",
       "119812                    sep      764.0         0.0  3.069653e-04   \n",
       "119727                 sensor      708.0         0.0  2.844947e-04   \n",
       "76394                      ir      656.0         0.0  2.636291e-04   \n",
       "123867                  sonar      646.0         0.0  2.596164e-04   \n",
       "120146                  servo      618.0         0.0  2.483811e-04   \n",
       "23486                  analog      583.0         0.0  2.343369e-04   \n",
       "62084                    fred      567.0         0.0  2.279168e-04   \n",
       "104733                    pgp      556.0         0.0  2.235029e-04   \n",
       "33732                     bmp      543.0         0.0  2.182865e-04   \n",
       "42617               computing      530.0         0.0  2.130701e-04   \n",
       "127763                sunbird      527.0         0.0  2.118663e-04   \n",
       "82647                     lcd      525.0         0.0  2.110638e-04   \n",
       "74739                   input     1041.0         1.0  4.181149e-04   \n",
       "144069                voltage      516.0         0.0  2.074524e-04   \n",
       "135457                 timedx      505.0         0.0  2.030385e-04   \n",
       "...                       ...        ...         ...           ...   \n",
       "117823       satisfactionmore        0.0       810.0  4.012619e-07   \n",
       "48148        deliverycomplete        0.0       810.0  4.012619e-07   \n",
       "32974                   bilbo        0.0       823.0  4.012619e-07   \n",
       "115891                  rolex        0.0       832.0  4.012619e-07   \n",
       "50273                discreet        0.0       851.0  4.012619e-07   \n",
       "59358                     fff        1.0      1769.0  8.025238e-07   \n",
       "13066                  5adobe        0.0      1160.0  4.012619e-07   \n",
       "42150         compacted_image        0.0      1160.0  4.012619e-07   \n",
       "108211               proadobe        0.0      1160.0  4.012619e-07   \n",
       "42151         compacted_price        0.0      1160.0  4.012619e-07   \n",
       "124216                sp_cont        0.0      1160.0  4.012619e-07   \n",
       "66231                greylink        0.0      1160.0  4.012619e-07   \n",
       "41273         collectionadobe        0.0      1160.0  4.012619e-07   \n",
       "936                       00c        0.0      1160.0  4.012619e-07   \n",
       "32482             bestsellers        0.0      1176.0  4.012619e-07   \n",
       "145777          weightzipping        0.0      1192.0  4.012619e-07   \n",
       "4192                     13px        1.0      2917.0  8.025238e-07   \n",
       "154811                     無料        0.0      1474.0  4.012619e-07   \n",
       "37340                  cantex        0.0      1509.0  4.012619e-07   \n",
       "45668                     cs2        0.0      1539.0  4.012619e-07   \n",
       "70233                  hoodia        0.0      1566.0  4.012619e-07   \n",
       "42149   compacted_description        0.0      1740.0  4.012619e-07   \n",
       "987                     00you        0.0      1740.0  4.012619e-07   \n",
       "17258                  95more        0.0      1740.0  4.012619e-07   \n",
       "114855          reviewsretail        0.0      1740.0  4.012619e-07   \n",
       "36391                      bz        0.0      1771.0  4.012619e-07   \n",
       "69048                 hereopt        0.0      1845.0  4.012619e-07   \n",
       "108556      professionaladobe        0.0      2320.0  4.012619e-07   \n",
       "108965                  proms        0.0      2320.0  4.012619e-07   \n",
       "108494          product_table        0.0      9266.0  4.012619e-07   \n",
       "\n",
       "          spam_ratio  spam_to_ham_ratio  \n",
       "68276   4.676789e-07           0.000667  \n",
       "95940   4.676789e-07           0.000772  \n",
       "38625   4.676789e-07           0.000786  \n",
       "67431   4.676789e-07           0.000817  \n",
       "95979   4.676789e-07           0.000830  \n",
       "106695  4.676789e-07           0.001000  \n",
       "95666   1.403037e-06           0.001069  \n",
       "101658  4.676789e-07           0.001089  \n",
       "125685  4.676789e-07           0.001104  \n",
       "115100  4.676789e-07           0.001127  \n",
       "115670  4.676789e-07           0.001170  \n",
       "83760   4.676789e-07           0.001347  \n",
       "84599   4.676789e-07           0.001391  \n",
       "135209  4.676789e-07           0.001435  \n",
       "92270   4.676789e-07           0.001437  \n",
       "119812  4.676789e-07           0.001524  \n",
       "119727  4.676789e-07           0.001644  \n",
       "76394   4.676789e-07           0.001774  \n",
       "123867  4.676789e-07           0.001801  \n",
       "120146  4.676789e-07           0.001883  \n",
       "23486   4.676789e-07           0.001996  \n",
       "62084   4.676789e-07           0.002052  \n",
       "104733  4.676789e-07           0.002092  \n",
       "33732   4.676789e-07           0.002143  \n",
       "42617   4.676789e-07           0.002195  \n",
       "127763  4.676789e-07           0.002207  \n",
       "82647   4.676789e-07           0.002216  \n",
       "74739   9.353579e-07           0.002237  \n",
       "144069  4.676789e-07           0.002254  \n",
       "135457  4.676789e-07           0.002303  \n",
       "...              ...                ...  \n",
       "117823  3.792876e-04         945.237096  \n",
       "48148   3.792876e-04         945.237096  \n",
       "32974   3.853674e-04         960.388862  \n",
       "115891  3.895766e-04         970.878546  \n",
       "50273   3.984625e-04         993.023435  \n",
       "59358   8.277917e-04        1031.485610  \n",
       "13066   5.429753e-04        1353.169258  \n",
       "42150   5.429753e-04        1353.169258  \n",
       "108211  5.429753e-04        1353.169258  \n",
       "42151   5.429753e-04        1353.169258  \n",
       "124216  5.429753e-04        1353.169258  \n",
       "66231   5.429753e-04        1353.169258  \n",
       "41273   5.429753e-04        1353.169258  \n",
       "936     5.429753e-04        1353.169258  \n",
       "32482   5.504581e-04        1371.817586  \n",
       "145777  5.579410e-04        1390.465913  \n",
       "4192    1.364687e-03        1700.494356  \n",
       "154811  6.898264e-04        1719.142684  \n",
       "37340   7.061952e-04        1759.935900  \n",
       "45668   7.202256e-04        1794.901514  \n",
       "70233   7.328529e-04        1826.370566  \n",
       "42149   8.142290e-04        2029.171127  \n",
       "987     8.142290e-04        2029.171127  \n",
       "17258   8.142290e-04        2029.171127  \n",
       "114855  8.142290e-04        2029.171127  \n",
       "36391   8.287271e-04        2065.302261  \n",
       "69048   8.633353e-04        2151.550776  \n",
       "108556  1.085483e-03        2705.172996  \n",
       "108965  1.085483e-03        2705.172996  \n",
       "108494  4.333981e-03       10800.878135  \n",
       "\n",
       "[155840 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_to_ham_ratio\n",
    "tokens.sort_values('spam_to_ham_ratio', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "# Note that the specified token, adobe, can change due to the nature of randomness\n",
    "tokens.loc['adobe', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer\n",
    "\n",
    "Currently, we've been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"I love apples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [\"I\", \"love\", \"apples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [\"I love\", \"love apples\"]\n",
    "\n",
    "\"I love new york\", \"I love new stuff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Some parameters that we can tune in the CountVectorizer:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning the CountVectorizer:**\n",
    "\n",
    "Tasks:\n",
    "1. From the spam ratios that you've obtained from before, **experiment** by adding more stop words!\n",
    "2. Play with the df and n-gram parameters.\n",
    "    * Try using GridSearch on the CountVectorizer!\n",
    "3. Try to reduce or increase the features and get a better score on the previous model. \n",
    "    * Score above a 99.5%? Tell us! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 10: Tuning the Laplacian Correction Factor\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> class sklearn.naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "> Parameters:\t\n",
    "alpha : float, optional (default=1.0)\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "One of the parameters that we can tune in training a Multinomial Naive Bayes Classifier is the Laplacian Correction Factor.\n",
    "\n",
    "Tasks:\n",
    "1. Tweak the correction factor from 0-3 in increments of 0.1, 5, and 10, thus training multiple classifiers.\n",
    "2. Plot the precision-recall curves for these classifiers to compare and contrast.\n",
    "3. Explain why the Laplacian Correction Factor is significant. What happens if it's 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Compare and Contrast the Difference of Using CountVectorizer vs TF-IDF Vectorizer\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Train two models of Naive Bayes Classifiers that have the same train and test sets with CountVectorizer and TF-IDF.\n",
    "2. Explain how TF-IDF works.\n",
    "2. Which vectorizer works better? Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "This practicals notebook is largely based from the Sci-kit Learn Documentation and PyCon 2016.\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "2. http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "3. https://www.youtube.com/watch?v=WHocRqT-KkU"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
