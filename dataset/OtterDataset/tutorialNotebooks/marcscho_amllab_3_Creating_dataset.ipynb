{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Creating a dataset in Azure ML\n",
    "\n",
    "In this prelude to the first \"real\" lab using the Azure ML python SDK, we're going to upload a dataset to Azure ML for future use. This is a great piece of functionality we like to ensure that a dataset is accessible for training not only by a user but later also by a pipeline for automated, unattended re-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the workspace\n",
    "\n",
    "As a first step, we must establish a connection to the workspace in which we are going to log our model measures etc. \n",
    "\n",
    "Note that in the following code cell we create this connection by refering to a configuration file that is available within the Compute Instance we're working with. To use this method outside of the Compute Instance, you will first need to download the config file from the Azure ML Studio.\n",
    "\n",
    "**When you run this cell for the first time, you will need to copy the code provided and navigate to the page linked to complete authentication.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading CSV to datastore\n",
    "\n",
    "In this case we are uploading our CSV files to Azure ML's default blob storage. Please note that this is not recommended practice outside of this tutorial. Typicially, your organization will register separate datastore first that hosts your organization's training data, e.g. data sitting in an Azure Data Lake or a relational database.\n",
    "\n",
    "Please note that in a production environment you will rarely be uploading individual files but will want to rely on a clear process to ingest data into Azure ML. Have a look at the data ingestion options outline in [this article](https://docs.microsoft.com/en-us/azure/machine-learning/concept-data-ingestion). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "datastore.upload_files(files = ['data/german_credit_dataset.csv'], overwrite = True, show_progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset\n",
    "\n",
    "Next, we will create a dataset object of type *Tabular* and point to the CSV file we have previously uploaded to our datastore. Note that the Dataset class also supports file datasets which may be used for example when handling image data or other file types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'german_credit_dataset.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we are now going to register this dataset in our Azure ML workspace and give it some meta data tags for easier identification in the future when the list of datasets may have grown rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.register(ws, name = 'german_credit_dataset', tags = {'purpose': 'demo'}, create_new_version = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the command above has completed, navigate to your [Azure ML workspace](https://ml.azure.com) and open the datasets section to verify that your dataset has been successfully created.\n",
    "\n",
    "You may now close this notebook and proceed to the next one. \n",
    "\n",
    "# Further information\n",
    "\n",
    "- [Example notebooks for working with datasets and datastores in Azure ML](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/work-with-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
