{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10: Build and register ML Models with Reason Codes and Filtered Columns\n",
    "\n",
    "In this tutorial, we will demonstrate how to build and register ML: 1) with reason codes and 2) remove any additional columns that could be in the input dataframe.\n",
    "More info on mlflow [here](https://mlflow.org/docs/latest/index.html)\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Create an experiment using mlflow client\n",
    "- Create a pandas dataframe using _credit_card_train.csv_ file\n",
    "- Use imbalanced-learn library for random undersampling\n",
    "- Create a pipeline using sklearn pipeline module to include StandardScaler as a pre-processing step\n",
    "- Build and register multiple models, parameters, and metrics using mlflow Python APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MLFlow libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from  mlflow.tracking import MlflowClient\n",
    "from IPython.display import Markdown, display\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Numpy, Matplotlib, Sklearn libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Column Filter Transformer using Sklearn BaseEstimator and TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnFilterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns=\"V0,V1,V2\"):\n",
    "        self.columns = columns.split(\",\")\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Time Difference Transformer using Sklearn BaseEstimator and TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDifferenceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,unit='second',time_pre_column='time_pre',time_post_column='time_post',missing_value=-999999,output_column='time_diff'):\n",
    "        self.unit = unit\n",
    "        self.time_pre_column = time_pre_column\n",
    "        self.time_post_column = time_post_column\n",
    "        self.missing_value = missing_value\n",
    "        self.output_column = output_column\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        from dateutil import parser\n",
    "        time_diff_list = list()\n",
    "        is_NaN = X[[self.time_pre_column,self.time_post_column]].isnull()\n",
    "        row_has_NaN = is_NaN.any(axis=1)\n",
    "        rows_with_NaN = list(X[row_has_NaN].index)\n",
    "        for index, row in tqdm(X.iterrows()):\n",
    "            time_pre = row[self.time_pre_column]\n",
    "            time_post = row[self.time_post_column]\n",
    "            if index in rows_with_NaN:\n",
    "                time_diff = self.missing_value\n",
    "            else:\n",
    "                time_pre  = parser.parse(time_pre)\n",
    "                time_post = parser.parse(time_post)\n",
    "                time_delta = time_post - time_pre\n",
    "                time_diff = time_delta.seconds\n",
    "                if self.unit == 'day':\n",
    "                    time_diff = time_delta.days\n",
    "                if self.unit == 'minute':\n",
    "                    time_diff = (time_delta.seconds//60)%60\n",
    "                if self.unit == 'hour':\n",
    "                    time_diff = (time_delta.seconds//3600)                \n",
    "            time_diff_list.append(time_diff)\n",
    "        X[self.output_column] = time_diff_list\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IP2Block Transformer using Sklearn BaseEstimator and TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IP2BlockTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,ip_address_column='ip_address',missing_value=-999999,output_column='ip2block'):\n",
    "        self.missing_value = missing_value\n",
    "        self.ip_address_column = ip_address_column\n",
    "        self.output_column = output_column\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        ip2block_list = list()\n",
    "        is_NaN = X[[self.ip_address_column]].isnull()\n",
    "        row_has_NaN = is_NaN.any(axis=1)\n",
    "        rows_with_NaN = list(X[row_has_NaN].index)\n",
    "        for index, row in tqdm(X.iterrows()):\n",
    "            ip_address = row[self.ip_address_column]\n",
    "            if index in rows_with_NaN:\n",
    "                ip2block = self.missing_value\n",
    "            else:\n",
    "                ip2block = '.'.join(ip_address.strip().split('.')[:2])\n",
    "            ip2block_list.append(ip2block)\n",
    "        X[self.output_column] = ip2block_list\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = 'credit_card_train_new_columns.csv'\n",
    "X = pd.read_csv(full_path)\n",
    "y = X[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"V\"+str(i) for i in range(30)]\n",
    "column_names = column_names + ['time_pre','time_post','cc_exp', 'lat1', 'long1', 'lat2', 'long2', 'lat3', 'long3', 'ip_address']\n",
    "feature_column_names = [\"V\"+str(i) for i in range(30)] + ['time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('cf1',ColumnFilterTransformer(\",\".join(column_names))),\n",
    "         ('tdiff',TimeDifferenceTransformer()),('ip2block',IP2BlockTransformer()), \n",
    "         ('cf2',ColumnFilterTransformer(\",\".join(feature_column_names))),\n",
    "         ('m',LGBMClassifier(n_estimators=100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "788it [00:00, 3624.52it/s]\n",
      "788it [00:00, 15617.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cf1',\n",
       "                 ColumnFilterTransformer(columns=['V0', 'V1', 'V2', 'V3', 'V4',\n",
       "                                                  'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "                                                  'V10', 'V11', 'V12', 'V13',\n",
       "                                                  'V14', 'V15', 'V16', 'V17',\n",
       "                                                  'V18', 'V19', 'V20', 'V21',\n",
       "                                                  'V22', 'V23', 'V24', 'V25',\n",
       "                                                  'V26', 'V27', 'V28', 'V29', ...])),\n",
       "                ('tdiff', TimeDifferenceTransformer()),\n",
       "                ('ip2block', IP2BlockTransformer()),\n",
       "                ('cf2',\n",
       "                 ColumnFilterTransformer(columns=['V0', 'V1', 'V2', 'V3', 'V4',\n",
       "                                                  'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "                                                  'V10', 'V11', 'V12', 'V13',\n",
       "                                                  'V14', 'V15', 'V16', 'V17',\n",
       "                                                  'V18', 'V19', 'V20', 'V21',\n",
       "                                                  'V22', 'V23', 'V24', 'V25',\n",
       "                                                  'V26', 'V27', 'V28', 'V29', ...])),\n",
       "                ('m', LGBMClassifier())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate precision-recall area under curve\n",
    "def pr_auc(y_true, probas_pred):\n",
    "    # calculate precision-recall curve\n",
    "    p, r, _ = precision_recall_curve(y_true, probas_pred)\n",
    "    # calculate area under curve\n",
    "    return auc(r, p)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "# define evaluation procedure\n",
    "pipeline.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_libraries_to_conda_env(_conda_env,libraries=[],conda_dependencies=[]):\n",
    "    dependencies = _conda_env[\"dependencies\"]\n",
    "    dependencies = dependencies + conda_dependencies\n",
    "    pip_index = None\n",
    "    for _index,_element in enumerate(dependencies):\n",
    "        if type(_element) == dict:\n",
    "            if \"pip\" in _element.keys():\n",
    "                pip_index = _index\n",
    "                break\n",
    "    dependencies[pip_index][\"pip\"] =  dependencies[pip_index][\"pip\"] + libraries\n",
    "    _conda_env[\"dependencies\"] = dependencies\n",
    "    return _conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup MLFLOW\n",
    "tracking_uri = os.environ.get(\"TRACKING_URL\")\n",
    "client = MlflowClient(tracking_uri=tracking_uri)\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "experiments = client.list_experiments()\n",
    "experiment_names = []\n",
    "for exp in experiments:\n",
    "    experiment_names.append(exp.name)\n",
    "experiment_name = \"demo\"\n",
    "if experiment_name not in experiment_names:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"Model\",\"LightGBM\")\n",
    "    mlflow.log_param(\"ReasonCodes\",\"No\")\n",
    "    mlflow.log_param(\"Filters\",\"Yes\")\n",
    "    mlflow.log_param(\"Transforms\",\"Yes\")\n",
    "    conda_env = mlflow.sklearn.get_default_conda_env()\n",
    "    conda_env = add_libraries_to_conda_env(conda_env,libraries=[\"lightgbm==3.1.1\",\"python-dateutil==2.8.1\"],conda_dependencies=[\"shap==0.39.0\"])\n",
    "    mlflow.sklearn.log_model(pipeline,\"model\",conda_env=conda_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
