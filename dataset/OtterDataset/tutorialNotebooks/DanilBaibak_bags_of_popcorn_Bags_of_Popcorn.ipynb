{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental analysis \n",
    "The competition from Kaggel \"*Bag of Words Meets Bags of Popcorn*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can download data from the page of competition https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "\n",
    "imbd_train = pd.read_csv('data/labeledTrainData.tsv', delimiter='\\t')\n",
    "imbd_test = pd.read_csv('data/testData.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Number of the train and test datasets\n",
    "\n",
    "print(imbd_train.shape)\n",
    "print(imbd_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 3)\n"
     ]
    }
   ],
   "source": [
    "# The training dataset consists balanced number of the positive and negative reviews\n",
    "\n",
    "print(imbd_train[imbd_train.sentiment == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission function\n",
    "\n",
    "The helper for create submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(prediction, file_index):\n",
    "    response = pd.DataFrame(data={'id': imbd_test.id, 'sentiment': prediction})\n",
    "    response.to_csv('submissions/{}.csv'.format(file_index), index=False)\n",
    "    \n",
    "    print('The submission is ready {}.csv'.format(file_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline for finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'feature_processing', FeatureUnion(transformer_list=[\n",
    "            ('words_processing', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "            ])),\n",
    "            ('characters_processing', Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(analyzer='char')),\n",
    "            ]))\n",
    "        ])\n",
    "     ),\n",
    "    ('lr', LogisticRegression(n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'lr__C': (0.01, 0.1, 1, 10),\n",
    "    'lr__penalty': ('l1', 'l2'),\n",
    "    \n",
    "    'feature_processing__words_processing__tfidf__min_df': (0, 1, 3, 5, 8),\n",
    "    'feature_processing__words_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'feature_processing__words_processing__tfidf__max_features': (None, 9000, 12000, 14000),\n",
    "    \n",
    "    'feature_processing__characters_processing__tfidf__min_df': (0, 1, 3, 5, 8),\n",
    "    'feature_processing__characters_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'feature_processing__characters_processing__tfidf__max_features': (None, 500, 1000, 1500)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.StratifiedShuffleSplit(imbd_train.sentiment, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submissions are judged on area under the ROC curve. \n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, parameters, scoring='roc_auc', cv=cv, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 58min 21s, sys: 5min 9s, total: 2h 3min 30s\n",
      "Wall time: 2h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(labels=[1 1 ..., 0 1], n_iter=10, test_size=0.3, random_state=42),\n",
       "          error_score='raise',\n",
       "          estimator=Pipeline(steps=[('feature_processing', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('words_processing', Pipeline(steps=[('selecting', ItemSelector(key='review')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'feature_processing__words_processing__tfidf__max_features': (None, 9000, 12000, 14000), 'feature_processing__characters_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)), 'feature_processing__words_processing__tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)), 'feature_proc..., 1, 10), 'feature_processing__characters_processing__tfidf__max_features': (None, 500, 1000, 1500)},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(imbd_train.review, imbd_train.sentiment);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585418808888888"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_processing__characters_processing__tfidf__max_features': 1000,\n",
       " 'feature_processing__characters_processing__tfidf__min_df': 8,\n",
       " 'feature_processing__characters_processing__tfidf__ngram_range': (1, 3),\n",
       " 'feature_processing__words_processing__tfidf__max_features': 14000,\n",
       " 'feature_processing__words_processing__tfidf__min_df': 5,\n",
       " 'feature_processing__words_processing__tfidf__ngram_range': (1, 3),\n",
       " 'lr__C': 10,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set best parameters to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline.set_params(\n",
    "    feature_processing__characters_processing__tfidf__max_features=1000,\n",
    "    feature_processing__characters_processing__tfidf__min_df=8,\n",
    "    feature_processing__characters_processing__tfidf__ngram_range=(1, 3),\n",
    "    feature_processing__words_processing__tfidf__max_features=14000,\n",
    "    feature_processing__words_processing__tfidf__min_df=5,\n",
    "    feature_processing__words_processing__tfidf__ngram_range=(1, 3),\n",
    "    lr__C=1,\n",
    "    lr__penalty='l2'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross_val_score for investigate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 248 ms, total: 1.36 s\n",
      "Wall time: 2min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.95655167,  0.95327619,  0.95599876])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cross_val_score(pipeline, imbd_train.review, imbd_train.sentiment, scoring='roc_auc', cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 9.14 s, total: 1min 59s\n",
      "Wall time: 1min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_processing', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('words_processing', Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1....ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline.fit(imbd_train.review, imbd_train.sentiment);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission is ready tfidf_lr_final.csv\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.predict_proba(imbd_test.review)[:,1]\n",
    "make_submission(prediction, 'tfidf_lr_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The score for the _testing_ dataset is **0.95893**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis of the prediction model\n",
    "\n",
    "Let's see what words have the biggest influence to the positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=14000, min_df=5, ngram_range=(1, 3))\n",
    "tfidf.fit(imbd_train.review);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_important_features(feature_names, weights, n_top=30):\n",
    "    sorted_features_indices = weights[0].argsort()[::-1]\n",
    "    \n",
    "    print('The most important \"features\" (words) for the first class (positive reviews): \\n')\n",
    "    most_important = sorted_features_indices[:n_top]\n",
    "    print(\",\\n\".join(\"{0}: {1:.4f}\".format(feature_names[j], weights[0, j]) for j in most_important))\n",
    "\n",
    "    print('\\nThe most unimportant \"features\" (words) for the second class (negative reviews): \\n')\n",
    "    least_important = sorted_features_indices[-n_top:]\n",
    "    print(\",\\n\".join(\"{0}: {1:.4f}\".format(feature_names[j], weights[0, j]) for j in least_important))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important \"features\" (words) for the first class (positive reviews): \n",
      "\n",
      "great: 5.8698,\n",
      "excellent: 4.8374,\n",
      "wonderful: 4.0855,\n",
      "perfect: 4.0584,\n",
      "amazing: 3.7342,\n",
      "best: 3.4412,\n",
      "fun: 3.3535,\n",
      "today: 3.3492,\n",
      "the best: 3.1102,\n",
      "loved: 2.9518,\n",
      "superb: 2.8695,\n",
      "favorite: 2.8563,\n",
      "love: 2.8074,\n",
      "bit: 2.8020,\n",
      "brilliant: 2.7977\n",
      "\n",
      "The most unimportant \"features\" (words) for the second class (negative reviews): \n",
      "\n",
      "annoying: -3.3996,\n",
      "horrible: -3.4781,\n",
      "nothing: -3.5249,\n",
      "no: -3.6050,\n",
      "poorly: -3.6126,\n",
      "dull: -3.6754,\n",
      "worse: -3.8829,\n",
      "terrible: -4.0776,\n",
      "waste: -4.5680,\n",
      "poor: -4.7210,\n",
      "the worst: -5.0524,\n",
      "boring: -5.1172,\n",
      "awful: -5.8512,\n",
      "worst: -6.5875,\n",
      "bad: -6.6976\n"
     ]
    }
   ],
   "source": [
    "display_important_features(tfidf.get_feature_names(), pipeline.named_steps['lr'].coef_, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
