{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 680 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage import io\n",
    "from skimage.util import view_as_windows\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "sys.path.append('/home/tanuj/Workspace/power-grid-detection')\n",
    "\n",
    "%matplotlib inline\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "from utils.model.helpers import get_model_from_json\n",
    "from utils.img.helpers import sliding_window\n",
    "from utils.dataset.helpers import get_image_collection\n",
    "from utils.img.collection import ImageCollection\n",
    "from utils.dataset.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batch_size = 32\n",
    "batch_size=256\n",
    "n_epochs=500\n",
    "input_shape=(140, 140, 1)\n",
    "name = 'cnn_140_1_thr_dil_ero_lr_%f_conv_freeze' % lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f6a3368bd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_from_json('cnn_140_1_thr_dil_ero_lr_0.100000_final.json')\n",
    "model.load_weights('/home/tanuj/Workspace/power-grid-detection/training/cnn_140_1_thr_dil_ero_lr_0.100000_training_weights_best.hdf5')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7f6a3368bdd0>\n",
      "<keras.layers.convolutional.Convolution2D object at 0x7f6a3343b890>\n",
      "<keras.layers.core.Activation object at 0x7f6a3343b910>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6a33119710>\n",
      "<keras.layers.convolutional.Convolution2D object at 0x7f6a3340d5d0>\n",
      "<keras.layers.core.Activation object at 0x7f6a330bb4d0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6a3306f290>\n",
      "<keras.layers.convolutional.Convolution2D object at 0x7f6a33073110>\n",
      "<keras.layers.core.Activation object at 0x7f6a33073650>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6a330153d0>\n",
      "<keras.layers.core.Flatten object at 0x7f6a3301b250>\n",
      "<keras.layers.core.Dense object at 0x7f6a3301b790>\n",
      "<keras.layers.core.Dense object at 0x7f6a32f9b850>\n",
      "<keras.layers.core.Dense object at 0x7f6a32fa3990>\n",
      "<keras.layers.core.Dense object at 0x7f6a32facad0>\n",
      "<keras.layers.core.Activation object at 0x7f6a32f9b5d0>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    if not isinstance(layer, Dense):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 140, 140, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 140, 140, 128) 0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 140, 140, 128) 0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 70, 70, 128)   0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 70, 70, 64)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 70, 70, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 35, 35, 64)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 35, 35, 64)    0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 35, 35, 64)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18496)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          18940928    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           524800      dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1026        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 20516354\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(lr=lr)\n",
    "\n",
    "print('compiling model...')\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('%s_training.log' % name)\n",
    "best_model_checkpointer = ModelCheckpoint(filepath=(\"./%s_training_weights_best.hdf5\" % name), verbose=1,\n",
    "                                          save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generators...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing data generators...')\n",
    "train_data_gen = DataGenerator(dataset_file=config.train_data_file, batch_size=batch_size)\n",
    "validation_data_gen = DataGenerator(dataset_file=config.validation_data_file, batch_size=batch_size)\n",
    "test_data_gen = DataGenerator(dataset_file=config.test_data_file, batch_size=batch_size)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 2569011200 bytes of device memory (out of memory).\nApply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{3}.0, Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0)\nToposort index: 84\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(256), array(128), array(140), array(140)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nDebugprint of the apply node: \nGpuAllocEmpty [id A] <CudaNdarrayType(float32, 4D)> ''   \n |Shape_i{0} [id B] <TensorType(int64, scalar)> ''   \n | |input_1 [id C] <TensorType(float32, 4D)>\n |Shape_i{3} [id D] <TensorType(int64, scalar)> ''   \n | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n |Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)] [id F] <TensorType(int64, scalar)> ''   \n | |Shape_i{1} [id G] <TensorType(int64, scalar)> ''   \n | | |input_1 [id C] <TensorType(float32, 4D)>\n | |TensorConstant{2} [id H] <TensorType(int8, scalar)>\n | |Shape_i{0} [id I] <TensorType(int64, scalar)> ''   \n | | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n | |TensorConstant{1} [id J] <TensorType(int8, scalar)>\n |Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)] [id K] <TensorType(int64, scalar)> ''   \n   |Shape_i{2} [id L] <TensorType(int64, scalar)> ''   \n   | |input_1 [id C] <TensorType(float32, 4D)>\n   |TensorConstant{2} [id H] <TensorType(int8, scalar)>\n   |Shape_i{1} [id M] <TensorType(int64, scalar)> ''   \n   | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n   |TensorConstant{1} [id J] <TensorType(int8, scalar)>\n\nStorage map footprint:\n - dense_1_W, Shared Input, Shape: (18496, 1024), ElemSize: 4 Byte(s), TotalSize: 75759616 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (18496, 1024), ElemSize: 4 Byte(s), TotalSize: 75759616 Byte(s)\n - input_1, Input, Shape: (256, 140, 140, 1), ElemSize: 4 Byte(s), TotalSize: 20070400 Byte(s)\n - GpuContiguous.0, Shape: (256, 1, 140, 140), ElemSize: 4 Byte(s), TotalSize: 20070400 Byte(s)\n - dense_2_W, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - dense_3_W, Shared Input, Shape: (1024, 512), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 512), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - convolution2d_2_W, Shared Input, Shape: (5, 5, 128, 64), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - convolution2d_3_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_1_W, Shared Input, Shape: (7, 7, 1, 128), ElemSize: 4 Byte(s), TotalSize: 25088 Byte(s)\n - GpuContiguous.0, Shape: (128, 1, 7, 7), ElemSize: 4 Byte(s), TotalSize: 25088 Byte(s)\n - dense_2_b, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - dense_4_W, Shared Input, Shape: (512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - dense_1_b, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - activation_4_target, Input, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - dense_3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuFromHost.0, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - activation_4_sample_weights, Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - convolution2d_1_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - convolution2d_2_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_3_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - TensorConstant{[  1   1   1 128]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[ 1  1  1 64]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 1}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - dense_4_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + Composite{((i0 + i1) // i0)}(i2, i3)), i1), i1, (i0 + Composite{((i0 + i1) // i0)}(i2, i3))), Switch(LT(i0, Composite{((i0 + i1) // i0)}(i2, i3)), i0, Composite{((i0 + i1) // i0)}(i2, i3)))}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + Composite{((i0 + i1) // i0)}(i2, i3)), i1), i1, (i0 + Composite{((i0 + i1) // i0)}(i2, i3))), Switch(LT(i0, Composite{((i0 + i1) // i0)}(i2, i3)), i0, Composite{((i0 + i1) // i0)}(i2, i3)))}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99999988]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  1.00000001e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 205296971.0 Byte(s) 0.191 GB\n TotalSize inputs: 185197275.0 Byte(s) 0.172 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8893c16c06f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               callbacks=[csv_logger, best_model_checkpointer])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanuj/.tools/anaconda3/envs/py27/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Error allocating 2569011200 bytes of device memory (out of memory).\nApply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{3}.0, Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0)\nToposort index: 84\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(256), array(128), array(140), array(140)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nDebugprint of the apply node: \nGpuAllocEmpty [id A] <CudaNdarrayType(float32, 4D)> ''   \n |Shape_i{0} [id B] <TensorType(int64, scalar)> ''   \n | |input_1 [id C] <TensorType(float32, 4D)>\n |Shape_i{3} [id D] <TensorType(int64, scalar)> ''   \n | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n |Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)] [id F] <TensorType(int64, scalar)> ''   \n | |Shape_i{1} [id G] <TensorType(int64, scalar)> ''   \n | | |input_1 [id C] <TensorType(float32, 4D)>\n | |TensorConstant{2} [id H] <TensorType(int8, scalar)>\n | |Shape_i{0} [id I] <TensorType(int64, scalar)> ''   \n | | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n | |TensorConstant{1} [id J] <TensorType(int8, scalar)>\n |Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)] [id K] <TensorType(int64, scalar)> ''   \n   |Shape_i{2} [id L] <TensorType(int64, scalar)> ''   \n   | |input_1 [id C] <TensorType(float32, 4D)>\n   |TensorConstant{2} [id H] <TensorType(int8, scalar)>\n   |Shape_i{1} [id M] <TensorType(int64, scalar)> ''   \n   | |convolution2d_1_W [id E] <CudaNdarrayType(float32, 4D)>\n   |TensorConstant{1} [id J] <TensorType(int8, scalar)>\n\nStorage map footprint:\n - dense_1_W, Shared Input, Shape: (18496, 1024), ElemSize: 4 Byte(s), TotalSize: 75759616 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (18496, 1024), ElemSize: 4 Byte(s), TotalSize: 75759616 Byte(s)\n - input_1, Input, Shape: (256, 140, 140, 1), ElemSize: 4 Byte(s), TotalSize: 20070400 Byte(s)\n - GpuContiguous.0, Shape: (256, 1, 140, 140), ElemSize: 4 Byte(s), TotalSize: 20070400 Byte(s)\n - dense_2_W, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - dense_3_W, Shared Input, Shape: (1024, 512), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 512), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - convolution2d_2_W, Shared Input, Shape: (5, 5, 128, 64), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - convolution2d_3_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_1_W, Shared Input, Shape: (7, 7, 1, 128), ElemSize: 4 Byte(s), TotalSize: 25088 Byte(s)\n - GpuContiguous.0, Shape: (128, 1, 7, 7), ElemSize: 4 Byte(s), TotalSize: 25088 Byte(s)\n - dense_2_b, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - dense_4_W, Shared Input, Shape: (512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - dense_1_b, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - activation_4_target, Input, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - dense_3_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuElemwise{sub,no_inplace}.0, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuFromHost.0, Shape: (256, 2), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - activation_4_sample_weights, Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - convolution2d_1_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - convolution2d_2_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_3_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - TensorConstant{[  1   1   1 128]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[ 1  1  1 64]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 1}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - dense_4_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + Composite{((i0 + i1) // i0)}(i2, i3)), i1), i1, (i0 + Composite{((i0 + i1) // i0)}(i2, i3))), Switch(LT(i0, Composite{((i0 + i1) // i0)}(i2, i3)), i0, Composite{((i0 + i1) // i0)}(i2, i3)))}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{3}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), Switch(LT((i0 + Composite{((i0 + i1) // i0)}(i2, i3)), i1), i1, (i0 + Composite{((i0 + i1) // i0)}(i2, i3))), Switch(LT(i0, Composite{((i0 + i1) // i0)}(i2, i3)), i0, Composite{((i0 + i1) // i0)}(i2, i3)))}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((((i0 + (i1 * (i2 // i1))) - i2) // i3) + i3)}}[(0, 0)].0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[[ 0.5]]]]}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.99999988]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  1.00000001e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 205296971.0 Byte(s) 0.191 GB\n TotalSize inputs: 185197275.0 Byte(s) 0.172 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "history = model.fit_generator(train_data_gen,\n",
    "                              nb_epoch=n_epochs,\n",
    "                              samples_per_epoch=train_data_gen.n_batches * batch_size,\n",
    "                              validation_data=validation_data_gen,\n",
    "                              nb_val_samples=validation_data_gen.n_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, best_model_checkpointer])\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "score = model.evaluate_generator(test_data_gen, val_samples=test_data_gen.n_samples)\n",
    "print('done.')\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
