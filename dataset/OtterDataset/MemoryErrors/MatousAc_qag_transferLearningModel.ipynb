{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with Transformers and PyTorch on the potsawee T5 model\n",
    "In this notebook I demonstrate how to perform transfer learning on an existing T5 model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to first set up your environment as per [envSetup.ipynb](../envSetup.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I import generally useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/ac/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-26 03:26:33.379374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 03:26:33.925885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first check the python env and GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# check GPUs\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global setting variables (eventually should go into a .json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = ' <sep> '\n",
    "PBEDataSource = 'singlePointQuestions.csv'\n",
    "bibleDataSource = 'nkjv.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For the training to occur, I need to create a dataset in my code that includes all the inputs and outputs of my model. These come from two different sources. Inputs are technically the verses in [`nkjv.csv`](nkjv.csv) and the outputs are in my [`singlePointQuestions.csv`](singlePointQuestions.csv). Below I define functions that put these two sources together into a pandas data frame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I load the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>ChapterNumber</th>\n",
       "      <th>VerseNumber</th>\n",
       "      <th>Verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The earth was without form, and void; and dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Then God said, \"Let there be light\"; and there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good; and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>God called the light Day, and the darkness He ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Book  ChapterNumber  VerseNumber   \n",
       "0  Genesis              1            1  \\\n",
       "1  Genesis              1            2   \n",
       "2  Genesis              1            3   \n",
       "3  Genesis              1            4   \n",
       "4  Genesis              1            5   \n",
       "\n",
       "                                               Verse  \n",
       "0  In the beginning God created the heavens and t...  \n",
       "1  The earth was without form, and void; and dark...  \n",
       "2  Then God said, \"Let there be light\"; and there...  \n",
       "3  And God saw the light, that it was good; and G...  \n",
       "4  God called the light Day, and the darkness He ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nkjv = pd.read_csv(bibleDataSource)\n",
    "nkjv.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I define a function that will get any span of verses specified by parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And He said to him, \"Most assuredly, I say to you, hereafter you shall see heaven open, and the angels of God ascending and descending upon the Son of Man.\" On the third day there was a wedding in Cana of Galilee, and the mother of Jesus was there. Now both Jesus and His disciples were invited to the wedding. \n",
      "In the beginning God created the heavens and the earth. The earth was without form, and void; and darkness was on the face of the deep. And the Spirit of God was hovering over the face of the waters. Then God said, \"Let there be light\"; and there was light. \n",
      "But fornication and all uncleanness or covetousness, let it not even be named among you, as is fitting for saints; \n"
     ]
    }
   ],
   "source": [
    "# note that this function does not support verses across multiple books\n",
    "def getText(Book, StartChapter, StartVerse, EndChapter = None, EndVerse = None):\n",
    "  # default to start positions\n",
    "  EndChapter = EndChapter if EndChapter else StartChapter\n",
    "  EndVerse = EndVerse if EndVerse else StartVerse\n",
    "\n",
    "  text = \"\"\n",
    "  BookDf = nkjv[nkjv[\"Book\"] == Book]\n",
    "  for index, row in BookDf.iterrows():\n",
    "    chapter = row['ChapterNumber']\n",
    "    verse = row['VerseNumber']\n",
    "    if (chapter == StartChapter and verse >= StartVerse) or (chapter > StartChapter):\n",
    "      if chapter == EndChapter and verse > EndVerse:\n",
    "        break\n",
    "      text += row['Verse'] + \" \"\n",
    "  return text\n",
    "  \n",
    "\n",
    "print(getText(\"John\", 1, 51, 2, 2))   # John 1:51, 2:1-2\n",
    "print(getText(\"Genesis\", 1, 1, 1, 3)) # Genesis 1:1-3\n",
    "print(getText(\"Ephesians\", 5, 3))     # Ephesians 5:3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the function handles texts across multiple verses and chapters. It assumes no negative values or values too high (chapters and verses that don't exist).\n",
    "\n",
    "I also will need a simple helper function below to use df.apply later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextFromRawPBEData(r):\n",
    "  return getText(r['StartBook'], r['StartChapter'], r['StartVerse'], r['EndChapter'], r['EndVerse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also need a function that creates a data frame ready for training. Define this function and explain how I know what my data needs to look like in the [Preprocessing Data](#preprocessing-data) section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Transfer Learning Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format Research\n",
    "To know what format my data should take, I first try looking at the data format for other projects. I looked into the \"[Simplifying Paragraph-level Question Generation via Transformer Language Models](https://paperswithcode.com/paper/transformer-based-end-to-end-question)\" paper's hugging-face model as well as several T5 hugging-face packages for [Question Generation](https://huggingface.co/mrm8488/t5-base-finetuned-question-generation-ap). As shown in [`transferLearningResearch.ipynb`](transferLearningResearch.ipynb) the [Q&A Generation](https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer) model by potsawee is the best model currently.\n",
    "\n",
    "Here I load the model and its tokenizer and define a function for generating questions and answers to be used for comparison later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potsawee_T5 is a model taken from https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "\n",
    "def potsaweeAQG(text):\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "  outputs = model.generate(**inputs, max_length=100)\n",
    "  question_answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "  question_answer = question_answer.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
    "  return question_answer.split(tokenizer.sep_token)\n",
    " \n",
    "def getPotsaweeModel():\n",
    "  return AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I take a quick look at what the tokenizer does to the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And it was told the king of Jericho, saying, \"Behold, men have come here tonight from the children of Israel to search out the country.\"\n",
      "{'input_ids': [275, 34, 47, 1219, 8, 3, 1765, 13, 1022, 3723, 32, 6, 2145, 6, 96, 2703, 6134, 6, 1076, 43, 369, 270, 8988, 45, 8, 502, 13, 3352, 12, 960, 91, 8, 684, 535, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "joshua = nkjv[nkjv['Book'] == 'Joshua']\n",
    "joshua2 = joshua[joshua['ChapterNumber'] == 2]\n",
    "joshua2_2 = joshua2[joshua2[\"VerseNumber\"] == 2].iloc[0][\"Verse\"]\n",
    "print(joshua2_2)\n",
    "encoded_joshua2_2 = tokenizer(joshua2_2)\n",
    "print(encoded_joshua2_2)\n",
    "# print(json.dumps(encoded_joshua2_2, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And it was told the king of Jericho, saying, \"Behold, men have come here tonight from the children of Israel to search out the country.\"</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_joshua2_2[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, when we tokenize an input verse, we have the data encoded in the format that the model expects. It auto-adds a separator after the sentence: `</s>`\n",
    "\n",
    "It also appears that the data needs to be converted into a format similar to Word2Vec to be processed by the model.\n",
    "\n",
    "Before we do data pre-processing, I we need to know what python types and structures are being used for the fine-tuning APIs. I'm going to try to format my data in the way the datasets library expects it in [this tutorial](https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6Ijk2OTcxODA4Nzk2ODI5YTk3MmU3OWE5ZDFhOWZmZjExY2Q2MWIxZTMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2ODE0MDU5MzEsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTYyNTc2NjM3ODUwNzExNDYyMiIsImVtYWlsIjoibWFzaHVhMjQ2OEBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6Ik1hdG91xaEgSMO9YmwiLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUdObXl4WXpTcmVXdUVpbUt4R1NYNTZ6aVJKUVhZa0FjbzRZM3MwZ0VFeHFQUT1zOTYtYyIsImdpdmVuX25hbWUiOiJNYXRvdcWhIiwiZmFtaWx5X25hbWUiOiJIw71ibCIsImlhdCI6MTY4MTQwNjIzMSwiZXhwIjoxNjgxNDA5ODMxLCJqdGkiOiIxOWViNzFkNmFmY2EzNWZhMDdlYzRlOTNjMDRiYjgxODIxYzA1ZDZiIn0.WUmK7KYoJP6FCtwllBH0p84wCHSLficCTTcxKi7fmEbsHIoLHDXPbe9LNCD3kjWJ9gL1rLVNY9MmW_OJW7IjgavYp2C5xJs3a86T8bNfGkCDpScs9_6C5I-kzUz99tOWYitPob5ydmUsgkUwmDOldMf3SIrrhbV5DTBjcaLYJVCVcGng39e6b2OoIor08_iG6eMY030fTFb-R51RUI5TCfJOHEOLDjCglXMfDdtTGRSqzvTTC0kiIERCCpz1OY3Xb6nbBvACMCP5WRmiofoFpxBJHMB1y5_BaT5QZRPpuR2hbAHd1HJUMsrMAINbd2ToCvUsaOZrL2wBfOxA9YPLtA) which is where my sample data comes from. If I can get my data into that same format then I can be confident that the API will accept it.\n",
    "\n",
    "To run the following code, you need to get the `'medium-articles.zip'` file. After setting up a kaggle account and placing your `kaggle.json` in the proper place, run `kaggle datasets download -d fabiochiusano/medium-articles` in your terminal in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/home/ac/code/PBE_AQG/medium-articles.zip' at /home/ac/code/PBE_AQG",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# look at an sample dataset to see what it looks like\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample_data \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mcsv\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_files\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmedium-articles.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(sample_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/load.py:1767\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   1763\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   1764\u001b[0m )\n\u001b[1;32m   1766\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1767\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   1768\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1769\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1770\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1771\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1772\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1773\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1774\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1775\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1776\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1777\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1778\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1779\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   1780\u001b[0m )\n\u001b[1;32m   1782\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/load.py:1498\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1497\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[0;32m-> 1498\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1499\u001b[0m     path,\n\u001b[1;32m   1500\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1501\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1502\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1503\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1504\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1505\u001b[0m )\n\u001b[1;32m   1507\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/load.py:1133\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[39m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m# Try packaged\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[1;32m   1127\u001b[0m     \u001b[39mreturn\u001b[39;00m PackagedDatasetModuleFactory(\n\u001b[1;32m   1128\u001b[0m         path,\n\u001b[1;32m   1129\u001b[0m         data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1130\u001b[0m         data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1131\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1132\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m-> 1133\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m   1134\u001b[0m \u001b[39m# Try locally\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mendswith(filename):\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/load.py:708\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m base_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir)\u001b[39m.\u001b[39mresolve()) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(Path()\u001b[39m.\u001b[39mresolve())\n\u001b[1;32m    705\u001b[0m patterns \u001b[39m=\u001b[39m (\n\u001b[1;32m    706\u001b[0m     sanitize_patterns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m get_data_patterns_locally(base_path)\n\u001b[1;32m    707\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m data_files \u001b[39m=\u001b[39m DataFilesDict\u001b[39m.\u001b[39;49mfrom_local_or_remote(\n\u001b[1;32m    709\u001b[0m     patterns,\n\u001b[1;32m    710\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[1;32m    711\u001b[0m     base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[1;32m    712\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _MODULE_SUPPORTS_METADATA \u001b[39mand\u001b[39;00m patterns \u001b[39m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n\u001b[1;32m    714\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/data_files.py:796\u001b[0m, in \u001b[0;36mDataFilesDict.from_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    793\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m    794\u001b[0m \u001b[39mfor\u001b[39;00m key, patterns_for_key \u001b[39min\u001b[39;00m patterns\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    795\u001b[0m     out[key] \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 796\u001b[0m         DataFilesList\u001b[39m.\u001b[39;49mfrom_local_or_remote(\n\u001b[1;32m    797\u001b[0m             patterns_for_key,\n\u001b[1;32m    798\u001b[0m             base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[1;32m    799\u001b[0m             allowed_extensions\u001b[39m=\u001b[39;49mallowed_extensions,\n\u001b[1;32m    800\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[1;32m    803\u001b[0m         \u001b[39melse\u001b[39;00m patterns_for_key\n\u001b[1;32m    804\u001b[0m     )\n\u001b[1;32m    805\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/data_files.py:764\u001b[0m, in \u001b[0;36mDataFilesList.from_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_local_or_remote\u001b[39m(\n\u001b[1;32m    757\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    761\u001b[0m     use_auth_token: Optional[Union[\u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    762\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFilesList\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    763\u001b[0m     base_path \u001b[39m=\u001b[39m base_path \u001b[39mif\u001b[39;00m base_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(Path()\u001b[39m.\u001b[39mresolve())\n\u001b[0;32m--> 764\u001b[0m     data_files \u001b[39m=\u001b[39m resolve_patterns_locally_or_by_urls(base_path, patterns, allowed_extensions)\n\u001b[1;32m    765\u001b[0m     origin_metadata \u001b[39m=\u001b[39m _get_origin_metadata_locally_or_by_urls(data_files, use_auth_token\u001b[39m=\u001b[39muse_auth_token)\n\u001b[1;32m    766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(data_files, origin_metadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/data_files.py:362\u001b[0m, in \u001b[0;36mresolve_patterns_locally_or_by_urls\u001b[0;34m(base_path, patterns, allowed_extensions)\u001b[0m\n\u001b[1;32m    360\u001b[0m         data_files\u001b[39m.\u001b[39mappend(Url(pattern))\n\u001b[1;32m    361\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m         \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m _resolve_single_pattern_locally(base_path, pattern, allowed_extensions):\n\u001b[1;32m    363\u001b[0m             data_files\u001b[39m.\u001b[39mappend(path)\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_files:\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/datasets/data_files.py:306\u001b[0m, in \u001b[0;36m_resolve_single_pattern_locally\u001b[0;34m(base_path, pattern, allowed_extensions)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[39mif\u001b[39;00m allowed_extensions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m with any supported extension \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(allowed_extensions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(out)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/home/ac/code/PBE_AQG/medium-articles.zip' at /home/ac/code/PBE_AQG"
     ]
    }
   ],
   "source": [
    "\n",
    "# look at an sample dataset to see what it looks like\n",
    "sample_data = load_dataset(\"csv\", data_files=\"medium-articles.zip\")\n",
    "print(sample_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Loading Function\n",
    "Looks like we have a DatasetDict format. Let's see if we can get our data to look the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type                 Question Answer  NumberPoints StartBook   \n",
      "5750  bible-qna  How many were exempted?   None             1   1 Kings  \\\n",
      "\n",
      "      StartChapter  StartVerse  EndBook  EndChapter  EndVerse  \n",
      "5750            15          22  1 Kings          15        22  \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 9983\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# some of the answers are literally \"None\". to keep pandas \n",
    "# from converting them to NaN, we need to set keep_default_na to False\n",
    "def getRawPBEData():\n",
    "  return pd.read_csv(PBEDataSource, keep_default_na=False)\n",
    "pbe_data = getRawPBEData()\n",
    "print(pbe_data[pbe_data['Question'] == \"How many were exempted?\"])\n",
    "# convert the rest of the way and look at structure\n",
    "pbe_data = Dataset.from_pandas(pbe_data)\n",
    "pbe_data = DatasetDict({\"train\": pbe_data})\n",
    "print(pbe_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Look at that. I think I have the data in the correct format now. Hopefully this will allow me to use the hugging-face training functions.\n",
    "\n",
    "##### Data Splitting Function\n",
    "At this point I will define a function that streamlines this data-loading from a dataframe and also splits the data up into a training, validation, and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def dfToSplitDataDict(df):\n",
    "  # convert type\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  dataDict = DatasetDict({\"train\": dataset})\n",
    "  # split\n",
    "  train_test = dataDict[\"train\"].train_test_split(test_size=2000)\n",
    "  train_validation = train_test[\"train\"].train_test_split(test_size=1000)\n",
    "  dataDict[\"train\"] = train_validation[\"train\"]\n",
    "  dataDict[\"validation\"] = train_validation[\"test\"]\n",
    "  dataDict[\"test\"] = train_test[\"test\"]\n",
    "  \n",
    "  # shuffle\n",
    "  dataDict[\"train\"] = dataDict[\"train\"].shuffle().select(range(1000))\n",
    "  dataDict[\"validation\"] = dataDict[\"validation\"].shuffle().select(range(1000))\n",
    "  dataDict[\"test\"] = dataDict[\"test\"].shuffle().select(range(1000))\n",
    "\n",
    "  return dataDict\n",
    "\n",
    "# test function\n",
    "print(dfToSplitDataDict(getRawPBEData()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how in the function above I shuffle things. I do this for several reasons:\n",
    "* in case Tableau Prep Builder organized our data also, it is a good idea to shuffle \n",
    "* to separate out questions that are from different sources - some questions are from Babienco, Myaing, deFlutier, etc.\n",
    "* to ensure the question quality is about the same between training, validation, and testing data\n",
    "* make sure questions from different books are mixed up thoroughly - we don't want the model to remember context information from past questions, so feeding them in out of order might help that"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are about ready to pre-process. First I define a function that will generate `input_ids`, `attention_masks` and `labels` for each row. `input_ids` are the way the model/tokenizer keeps track of which words are which and `attention_masks` basically mark the important words. It seems to be an alternative to filtering stop words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How To Preprocess Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "Model-specific settings are very important for fine-tuning. Since I am fine-tuning a pre-existing model, it is important that I feed it the proper sizes of input, the correct command, and the correctly-formatted labels. Many of these configurations are taken from the values specified in the [`original_config`](./original_config/) folder which contains configuration files for the potsawee T5 model.\n",
    "\n",
    "Notice the `command` variable. The command tells T5 what to do. The form of the command is minimal. Examples usually show commands such as `\"summarize:\"` or `\"translate to german:\"`. The command is not specified in the model's documentation. The [`config.json`](./original_config/config.json) file contains a `\"summarize:\"` prefix under the `task_specific_params` key, so that may be work trying out. Other wise something like `\"generate question and answer:\"` will be tested.\n",
    "\n",
    "`max_verse_length`, and `max_qa_length` variables specify how long the input and output can be, aka. the largest input size and output size. In this case I am using `512` for the maximum input size for verses because it appears several times in the configuration. Otherwise there are also max lengths of `200` and `300`. If training the model takes too long, decreasing this size may be useful. The output length, `max_qa_length`, is set at `128` as no value is provided in the config.\n",
    "\n",
    "##### Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = \"generate question and answer: \"\n",
    "command = \"summarize: \"\n",
    "max_verse_length = 512\n",
    "max_qa_length = 128\n",
    "\n",
    "def tokenize(data):\n",
    "  inputs = [command + text for text in data[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_verse_length, truncation=True)\n",
    "\n",
    "  # Setup the potsawee_tokenizer for targets\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    qa = tokenizer(data[\"qa\"], max_length=max_qa_length, truncation=True)\n",
    "\n",
    "  model_inputs[\"labels\"] = qa[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Tokens\n",
    "One very interesting question is how the model is able to generate both a question and answer. All NLG pipelines generally produce a single stream of text as output, not two separate outputs.\n",
    "\n",
    "According to the [documentation online](https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer) the question and answer are output in the same string with the special added `<sep>` token separating the two (see [added_tokens.json](./original_config/added_tokens.json)). Thus, to continue training, this token must be inserted between the question and answer in \"labels.\"\n",
    "\n",
    "Documentation:\n",
    "* **Input**: context (e.g. news article)\n",
    "* **Output**: question `<sep>` answer\n",
    "\n",
    "##### Training Data Formatting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a dataframe passed to it in the PBE question format standardized\n",
    "# by https://pbeprep.com and turns it into the format that the model expects\n",
    "\n",
    "def qaCombine(r):\n",
    "  return r['Question'] + sep + r['Answer']\n",
    "\n",
    "def rawPBEToTrainingData(pbeData):\n",
    "  result = pd.DataFrame()\n",
    "  result[\"context\"] = pbeData.apply(getTextFromRawPBEData, axis=1)\n",
    "  result[\"qa\"] = pbeData.apply(qaCombine, axis=1)\n",
    "  return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the pieces in place let's test what our training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>qa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now it came to pass in the days of Ahasuerus (...</td>\n",
       "      <td>Which Ahasuerus is being spoken of in the book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>Where was King Ahasuerus' throne? (be specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>What was in Shushan the citadel? &lt;sep&gt; the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>In what year of King Ahasuerus' reign did he m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>Where was the throne of his kingdom? &lt;sep&gt; in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context   \n",
       "0  Now it came to pass in the days of Ahasuerus (...  \\\n",
       "1  in those days when King Ahasuerus sat on the t...   \n",
       "2  in those days when King Ahasuerus sat on the t...   \n",
       "3  in those days when King Ahasuerus sat on the t...   \n",
       "4  in those days when King Ahasuerus sat on the t...   \n",
       "\n",
       "                                                  qa  \n",
       "0  Which Ahasuerus is being spoken of in the book...  \n",
       "1  Where was King Ahasuerus' throne? (be specific...  \n",
       "2  What was in Shushan the citadel? <sep> the thr...  \n",
       "3  In what year of King Ahasuerus' reign did he m...  \n",
       "4  Where was the throne of his kingdom? <sep> in ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbe_data = getRawPBEData()\n",
    "pbe_data = rawPBEToTrainingData(pbe_data)\n",
    "pbe_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like the format we want. Thus, we can finally push our data through all the preparation steps. Let's wrap this up into one, succinct function.\n",
    "##### Process Data Function\n",
    "1. Get data in PBE db format\n",
    "2. Make into the input and output format that we need.\n",
    "3. Split dataset\n",
    "4. Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData():\n",
    "  raw = getRawPBEData()\n",
    "  pbe_df = rawPBEToTrainingData(raw)\n",
    "  pbe_dict = dfToSplitDataDict(pbe_df)\n",
    "  pbe_tokens = pbe_dict.map(tokenize, batched=True)\n",
    "  return pbe_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Training w/ Hugging Face"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]/home/ac/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'qa', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['context', 'qa', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['context', 'qa', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "pbe_tokens = processData()\n",
    "print(pbe_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to fine-tune the model. First we specify some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "model_location = './pbe_aqg_potsawee_t5'\n",
    "\n",
    "hyperparameters = Seq2SeqTrainingArguments(\n",
    "  model_location,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  eval_steps=100,\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=100,\n",
    "  save_strategy=\"steps\",\n",
    "  save_steps=200,\n",
    "  learning_rate=4e-5,\n",
    "  per_device_train_batch_size=batch_size,\n",
    "  per_device_eval_batch_size=batch_size,\n",
    "  weight_decay=0.01,\n",
    "  save_total_limit=3,\n",
    "  num_train_epochs=1,\n",
    "  predict_with_generate=True,\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"rouge1\",\n",
    "  report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an explanation for a few of the hyperparameters.\n",
    "* `model_location` is where the trained model will be stored\n",
    "* `evaluation_strategy` can be `\"no\"`, `\"steps\"`, or `\"epoch\"`. This determines whether the model is evaluated during training and how often\n",
    "* `eval_steps` tells the trainer to evaluate the model after every `100` steps. It is required when `evaluation_strategy` is`\"steps\"`\n",
    "* `logging_strategy`, `logging_steps`, `save_strategy`, and `save_steps` all follow the same format and function as `evaluation_strategy` and `eval_steps`\n",
    "* `learning_rate` the initial learning rate\n",
    "* `per_device_train_batch_size` and `per_device_eval_batch_size` refer to how large the batches are per each GPU/CPU\n",
    "* `weight_decay` is normal weight decay - see [explanation](https://vitalflux.com/weight-decay-in-machine-learning-concepts/#:~:text=Weight%20decay%20is%20a%20regularization%20technique%20that%20is%20used%20in,models%2C%20including%20deep%20neural%20networks.)\n",
    "* `num_train_epochs` specifies the number of epochs that should be performed by the trainer\n",
    "* `predict_with_generate` tells the trainer to evaluate the model while training\n",
    "* `metric_for_best_model` specifies the metric used to evaluate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have a make a data collator with our tokenizer which will split up our data into batches and pad it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set up our metric using the Hugging Face `evaluate` library.\n",
    "\n",
    "I have created a custom metric computation function. It is based on the [rouge score](https://huggingface.co/spaces/evaluate-metric/rouge). It:\n",
    "1. decodes prediction tokens into words\n",
    "2. decodes labels after padding\n",
    "3. computes ROUGE scores using the decoded predictions and labels\n",
    "\n",
    "This custom metrics function is a good place to tweak what we want the output to look like. Possibly, we will want to incentivize different outputs as we get better models trained.\n",
    "\n",
    "Getting this metric right is crucial to the training process. Unfortunately, using Python really sucks in this context because you don't know if something is wrong with your metric until you run the training. This became evident in this project when 7 rounds of training (5 hours each) failed during one of its last steps because the metric was not being computed correctly.\n",
    "\n",
    "All the issues were issues of object type and improper formatting of the computed metrics. A statically-typed language would be able to find the issues before even running the code. But with Python, it can take days to debug a simple function like this. The print statements below took **all night** to get. At this point, this function doesn't work yet and future work is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# compute takes a tuple of (predictions, labels)\n",
    "def compute_metrics(eval_pred):\n",
    "  print(\"eval_pred: \", eval_pred)\n",
    "  # eval_pred:  <transformers.trainer_utils.EvalPrediction object at 0x0000018ABBC6ED10>\n",
    "  \n",
    "  predictions, labels = eval_pred\n",
    "  print(\"predictions: \", predictions)\n",
    "  # predictions:  [[    0   363   410 ...     0     0     0]\n",
    "  #  [    0   363    19 ...     0     0     0]\n",
    "  #  [    0   363    19 ...     0     0     0]\n",
    "  #  ...\n",
    "  #  [    0  2645   410 ...     0     0     0]\n",
    "  #  [    0   363   410 ...     9    23     9]\n",
    "  #  [    0   363   410 ... 26783     1     0]]\n",
    "  print(\"labels: \", labels)\n",
    "  # labels:  [[ 125   47   16 ... -100 -100 -100]\n",
    "  #  [ 363  405 4173 ... -100 -100 -100]\n",
    "  #  [ 363   19   45 ... -100 -100 -100]\n",
    "  #  ...\n",
    "  #  [2645 1622   12 ... -100 -100 -100]\n",
    "  #  [   3 2544  520 ... -100 -100 -100]\n",
    "  #  [ 363  410  717 ... -100 -100 -100]]\n",
    "  \n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  \n",
    "  # replace -100 in the labels as we can't decode them.\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  \n",
    "  # rouge expects a newline after each sentence\n",
    "  decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "  decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "  \n",
    "  # compute ROUGE scores\n",
    "  result = metric.compute(predictions=decoded_preds, references=decoded_labels, \n",
    "                          use_stemmer=True, use_aggregator=True, tokenizer=tokenizer)\n",
    "  print(\"result: \", result)\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before training, we need to configure the trainer and point it to our data and pretrained model.\n",
    "\n",
    "We pass in a model initialization function `getPotsaweeModel` so that the trainer will always start with our base model rather than anything else whe may have done training on. We also pass in all the `hyperparameters` that we set up earlier.\n",
    "\n",
    "Also notice that we pass in our tokenized PBE data for training and validation.\n",
    "\n",
    "Finally, we give it the potsawee `tokenizer` and our own `compute_metrics` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "  model_init=getPotsaweeModel,\n",
    "  args=hyperparameters,\n",
    "  train_dataset=pbe_tokens[\"train\"],\n",
    "  eval_dataset=pbe_tokens[\"validation\"],\n",
    "  data_collator=data_collator,\n",
    "  tokenizer=tokenizer,\n",
    "  compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still in the process of getting a TensorBoard to work. When I do, we will get to see the training in progress. The board should display in the notebook right below its launching code cell. This code is still here however because without it you usually don't get to see a progress bar below the training block. So it's staying for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir f'{model_location}/runs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ac/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.73 GiB total capacity; 14.22 GiB already allocated; 7.12 MiB free; 14.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1667\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/transformers/trainer.py:1996\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1994\u001b[0m     optimizer_was_run \u001b[39m=\u001b[39m scale_before \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m scale_after\n\u001b[1;32m   1995\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1996\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m   1998\u001b[0m \u001b[39mif\u001b[39;00m optimizer_was_run \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed:\n\u001b[1;32m   1999\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PBE_AQG/lib/python3.11/site-packages/transformers/optimization.py:447\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    445\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[1;32m    446\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m--> 447\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39;49msqrt()\u001b[39m.\u001b[39madd_(group[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    449\u001b[0m step_size \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m group[\u001b[39m\"\u001b[39m\u001b[39mcorrect_bias\u001b[39m\u001b[39m\"\u001b[39m]:  \u001b[39m# No bias correction for Bert\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.73 GiB total capacity; 14.22 GiB already allocated; 7.12 MiB free; 14.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training takes approximately 5 hours. As mentioned before, this training has failed seven times due to various errors in the evaluation metric. Unfortunately, we can't try out the model if the training does not complete successfully."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the `compute_metric` function still has to be debugged. One way I plan to do this is to dig through all of Hugging Face's documentation on its `evaluate` library. Metric computation methods have changed recently, so no tutorials I have found online have yet been able to resolve my problem.\n",
    "\n",
    "Otherwise, the model hyperparameters should be adjusted and tested to produce a better model. The current setup is only a proof-of-concept for transfer learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
