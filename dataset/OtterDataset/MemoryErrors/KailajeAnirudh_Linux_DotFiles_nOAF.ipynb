{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 16:06:20.518683: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-08 16:06:20.691422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 16:06:20.691477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 16:06:20.716244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-08 16:06:20.769804: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-08 16:06:21.741709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# torch and torchvision imports\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "import numpy as np,  matplotlib.pyplot as plt, pandas as pd, pickle\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResnetModel import *\n",
    "from transformer import *\n",
    "writer = SummaryWriter()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104383/265309155.py:3: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  y_train = pd.read_csv('./data/Y_train.csv')[['Diag', 'Form', 'Rhythm']].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(np.transpose(np.load('./data/X_train.npz')['arr_0'], axes = (0,2,1))).float()\n",
    "X_test = torch.from_numpy(np.transpose(np.load('./data/X_val.npz')['arr_0'], axes = (0,2,1))).float()\n",
    "y_train = pd.read_csv('./data/Y_train.csv')[['Diag', 'Form', 'Rhythm']].to_numpy()\n",
    "y_test = pd.read_csv('./data/Y_val.csv')[['Diag', 'Form', 'Rhythm']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train).int()\n",
    "y_test = torch.from_numpy(y_test).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1000])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "x = X_train[0:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Transformer needs X input as (seq_len, batch_size, channels)\"\"\"\n",
    "model = Transformer(nhead=12, num_classes=3, hidden_size=128, depth=3, seq_length=200).to(device)\n",
    "# resnetModel = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=6).to(device)\n",
    "\n",
    "# resnetModel(X_train[0:1].to(device))\n",
    "print(summary(model.to(device), (1,200,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4*1024-23.86)/37.66 #Max batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test AUC metric\"\"\"\n",
    "ml_auroc = MultilabelAUROC(num_labels=3, average=\"macro\", thresholds=None)\n",
    "# ml_auroc(model(X_train[0:10].to(device)), train_label_mapping[0:10].to(device).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Max Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudhkailaje/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = Transformer(nhead=12, num_classes=3, drop_p=0.25, hidden_size=128, depth=3, seq_length=500).to(device)\n",
    "lr = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "lrs = []\n",
    "\n",
    "for i, (signal, labels) in enumerate(train_loader):\n",
    "    idx = np.random.randint(0, 1000-500)\n",
    "    signal = (signal[:, :, idx:idx+500]).to(device).transpose(0,1).transpose(0,2)\n",
    "    labels = labels.to(device)\n",
    "    output = model(signal)\n",
    "    loss = criterion(output, labels.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    train_loss.append(loss.item())\n",
    "    lrs.append(lr)\n",
    "    lr *= 1.1\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr \n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i > 200 or lr > 1:\n",
    "        break\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "lr_max = lrs[np.where(train_loss == train_loss.min())[0]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max = 0.0025/10\n",
    "lr = lr_max\n",
    "epochs = 100\n",
    "criterion = nn.BCELoss()\n",
    "model = Transformer(nhead=12, num_classes=3, drop_p=0.25, hidden_size=128, depth=3, seq_length=500).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "for t in range(T_max):\n",
    "    if t <= T_0:\n",
    "        lr = 10**(-5) + (t/T_0)*lr_max  \n",
    "    else: \n",
    "        lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6)\n",
    "    lrs.append(lr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacty of 3.61 GiB of which 575.94 MiB is free. Including non-PyTorch memory, this process has 3.02 GiB memory in use. Of the allocated memory 2.43 GiB is allocated by PyTorch, and 518.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(signal_sample)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/01_UPenn/01_ESE5460/03_Project/src/transformer.py:63\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__forward_impl(x)\n",
      "File \u001b[0;32m~/Documents/01_UPenn/01_ESE5460/03_Project/src/transformer.py:40\u001b[0m, in \u001b[0;36mTransformer.__forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     39\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(x)\n\u001b[0;32m---> 40\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     41\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x)\n\u001b[1;32m     42\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The output is (seq_len, batch_size, embedding_dim), \u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    we need (batch_size, seq_len, embedding_dim)\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    708\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    716\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    717\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    718\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/functional.py:5440\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5437\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5438\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5440\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5441\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5443\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacty of 3.61 GiB of which 575.94 MiB is free. Including non-PyTorch memory, this process has 3.02 GiB memory in use. Of the allocated memory 2.43 GiB is allocated by PyTorch, and 518.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "learning_rates = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (signal, labels) in enumerate(train_loader):\n",
    "        idx = np.random.randint(0, 1000-500)\n",
    "        signal_sample = (signal[:, :, idx:idx+500]).to(device).transpose(0,1).transpose(0,2)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(signal_sample)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        if t <= T_0:\n",
    "            lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "        else: \n",
    "            lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6) \n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr \n",
    "        learning_rates.append(lr)\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        t+=1\n",
    "        \n",
    "        train_AUC = ml_auroc(outputs, labels.int())\n",
    "        writer.add_scalar(\"Train_Loss\", loss, t)\n",
    "        writer.add_scalar(\"Learning rate\", lr, t)\n",
    "        writer.add_scalar(\"Batch Train AUC\", train_AUC, t)\n",
    "\n",
    "        if i%(len(train_loader)//10) == 0:\n",
    "            print(f\"Step: {i+1}/{len(train_loader)}  |  Train loss: {loss.item():.4f}  |  Train AUC: {train_AUC:.4f}\")\n",
    "           \n",
    "\n",
    "    # model.eval()\n",
    "    test_auc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (signal, labels) in enumerate(test_loader):\n",
    "            idx = np.random.randint(0, 1000-200)\n",
    "            signal = (signal[:, :, idx:idx+200]).to(device).transpose(0,1).transpose(0,2)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(signal)\n",
    "            test_auc += ml_auroc(outputs, labels.int())\n",
    "        test_auc /= len(test_loader)\n",
    "    writer.add_scalar(\"Test AUC\", test_auc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/src/Transformer_SuperClass.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m t\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('superclassmodel.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
