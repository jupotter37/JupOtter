{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# I am using this instead of -insctruct because it was the one given in the initial code\n",
    "model_name = \"HuggingFaceTB/SmolLM-135M\" \n",
    "\n",
    "# TODO: Load the model and the tokenizer from huggingface\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='cuda', use_cache=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True,\n",
    "                                          truncation=True, padding=True,\n",
    "                                          return_tensors=\"pt\")\n",
    "\n",
    "# Check special tokens\n",
    "print(f\"EOS token --> {tokenizer.eos_token}\")\n",
    "print(f\"BOS token --> {tokenizer.bos_token}\")\n",
    "print(f\"PAD token --> {tokenizer.pad_token}\")\n",
    "\n",
    "# Adding EOS token as padding token\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "print(f\"[UPDATE] PAD token --> {tokenizer.pad_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test if your model works properly\n",
    "def format_text(text: str) -> str:\n",
    "    # here you may have formatting of the input that you adopted for training\n",
    "    # The \"Fix grammatically\" instruction is already in the user prompt so\n",
    "    # there is no need to add it like we did in training\n",
    "    text = f\"{text} \\n ### Correct:\"\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Example of how to run inference on a single example\n",
    "text = \"Fix grammatically: I likes turtles\"\n",
    "# text = \"Fix grammaticality: First of all, from you read just to found in the poems or novel what well-known critic have already found out, you looses the pleasures of reading something which is expecting to be a new experience to you.\"\n",
    "inputs = tokenizer(format_text(text), return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=128, temperature=0.0,\n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               eos_token_id=tokenizer.eos_token_id,\n",
    "                              )\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download the GEC data\n",
    "full_train_ds = load_dataset(\"grammarly/coedit\", split=\"train\")\n",
    "full_test_ds = load_dataset(\"grammarly/coedit\", split=\"validation\")\n",
    "\n",
    "# TODO: Filter examples, keeping only GEC task\n",
    "# Explore the structure of the dataset\n",
    "\n",
    "print(f'--> Dataset strcutrue: \\n {full_train_ds.features}\\n')\n",
    "\n",
    "# Explore the different task in the dataset\n",
    "print(f'--> Tasks in the dataset {set(full_train_ds[\"task\"])}\\n')\n",
    "\n",
    "train_gec_ds = full_train_ds.filter(lambda example: example['task'] == 'gec', )\n",
    "test_gec_ds = full_test_ds.filter(lambda example: example['task'] == 'gec')\n",
    "\n",
    "# Check size of the filter data is correct\n",
    "assert len(train_gec_ds) == 19823, \"Wrong number of train samples\"\n",
    "assert len(test_gec_ds) == 485, \"Wrong number of test samples\"\n",
    "\n",
    "train_gec_ds, test_gec_ds\n",
    "\n",
    "# select a subset of 10 instances for sake of computational limitations\n",
    "# toy_train_data = train_gec_ds.select(range(10))\n",
    "# toy_test_data = test_gec_ds.select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Preferences Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1 (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_edit_distance import edit_distance\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# TODO: Create preference optimization dataset\n",
    "\n",
    "def generate_variants(model, tokenizer, input_text):\n",
    "    # Variant 1: Beam search decoding\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True,\n",
    "                       max_length=128).to(model.device)\n",
    "    beam_output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        num_beams=5,  # Use beam search with 5 beams\n",
    "        temperature = 0.0, # Deterministic output\n",
    "        length_penalty=-1.0,  # Adjust length penalty\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    variant_1 = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Variant 2: Sampling with temperature\n",
    "    sampling_output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        temperature=0.9,  # Use temperature-based sampling\n",
    "        top_k=50,  # Control diversity using top-k sampling\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    variant_2 = tokenizer.decode(sampling_output[0], skip_special_tokens=True)\n",
    "\n",
    "    return variant_1, variant_2\n",
    "\n",
    "# Create a preference dataset by comparing edit distance\n",
    "def create_preference_dataset(model, tokenizer, dataset):\n",
    "    variant_1_count = 0\n",
    "    variant_2_count = 0\n",
    "    preference_data = []\n",
    "\n",
    "    # Loop over the training dataset\n",
    "    for example in tqdm(dataset):\n",
    "        input_text = f\"Fix grammatically: {example['src']}\"  # Input prompt\n",
    "        ground_truth = example['tgt']  # Corrected sentence\n",
    "\n",
    "        # Generate two variants for the input\n",
    "        variant_1, variant_2 = generate_variants(model, tokenizer, input_text)\n",
    "\n",
    "        # Measure edit distance between the variants and the ground truth\n",
    "        dist_variant_1 = edit_distance(variant_1, ground_truth)\n",
    "        dist_variant_2 = edit_distance(variant_2, ground_truth)\n",
    "\n",
    "        # Label based on the smaller edit distance\n",
    "        if dist_variant_1 < dist_variant_2:\n",
    "            chosen = variant_1\n",
    "            rejected = variant_2\n",
    "            variant_1_count += 1\n",
    "        else:\n",
    "            chosen = variant_2\n",
    "            rejected = variant_1\n",
    "            variant_2_count += 1\n",
    "\n",
    "        # Add the comparison to the preference dataset\n",
    "        preference_data.append({\n",
    "            'input': input_text,\n",
    "            'ground_truth': ground_truth,\n",
    "            'variant_1': variant_1,\n",
    "            'variant_2': variant_2,\n",
    "            'chosen': chosen,\n",
    "            'rejected': rejected\n",
    "        })\n",
    "\n",
    "    # reporting statistics\n",
    "    norm_variant_1_count = variant_1_count/len(dataset)\n",
    "    norm_variant_2_count = variant_2_count/len(dataset)\n",
    "    print(f\"Variant 1 count: {variant_1_count} ({norm_variant_1_count:.2f}%)\")\n",
    "    print(f\"Variant 2 count: {variant_2_count} ({norm_variant_2_count:.2f}%)\")\n",
    "\n",
    "    return preference_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "toy_train_data = train_gec_ds.select(range(10))\n",
    "\n",
    "\n",
    "preference_dataset = create_preference_dataset(model, tokenizer, toy_train_data)\n",
    "\n",
    "# save preference_dataset to parqet to be loaded in pandas\n",
    "df = pd.DataFrame(preference_dataset)\n",
    "# df.to_parquet(\"dpo_preference_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        # call the decorated function\n",
    "        result = func(*args, **kwargs)\n",
    "        # remeasure the time\n",
    "        end_time = time.time()\n",
    "        # compute the elapsed time and print it\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")\n",
    "        # return the result of the decorated function execution\n",
    "        return result\n",
    "    # return reference to the wrapper function\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from fast_edit_distance import edit_distance\n",
    "\n",
    "\n",
    "@timer\n",
    "def generate_variants_batch(model, tokenizer, input_texts):\n",
    "    # Tokenize the batch of input texts\n",
    "    inputs = tokenizer(\n",
    "        input_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(model.device)\n",
    "\n",
    "    # Variant 1: Beam search decoding\n",
    "    beam_outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        num_beams=5,  # Use beam search with 5 beams\n",
    "        temperature=0.0,  # Deterministic output\n",
    "        length_penalty=-1.0,  # Adjust length penalty\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=1,  # Return only the best sequence\n",
    "    )\n",
    "    variants_1 = tokenizer.batch_decode(beam_outputs, skip_special_tokens=True)\n",
    "\n",
    "    # Variant 2: Sampling with temperature\n",
    "    sampling_outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        temperature=0.9,  # Use temperature-based sampling\n",
    "        top_k=50,  # Control diversity using top-k sampling\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    variants_2 = tokenizer.batch_decode(sampling_outputs, skip_special_tokens=True)\n",
    "\n",
    "    return variants_1, variants_2\n",
    "\n",
    "\n",
    "@timer\n",
    "def create_preference_dataset(model, tokenizer, dataset, batch_size=5):\n",
    "    variant_1_count = 0\n",
    "    variant_2_count = 0\n",
    "    preference_data = []\n",
    "\n",
    "    # Create a DataLoader for batching\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_texts = [f\"Fix grammatically: {src}\" for src in batch['src']]\n",
    "        ground_truths = batch['tgt']\n",
    "\n",
    "        # Generate two variants for the batch of inputs\n",
    "        variants_1, variants_2 = generate_variants_batch(model, tokenizer, input_texts)\n",
    "\n",
    "        # Measure edit distances between the variants and the ground truths\n",
    "        distances_1 = [edit_distance(v1, gt) for v1, gt in zip(variants_1, ground_truths)]\n",
    "        distances_2 = [edit_distance(v2, gt) for v2, gt in zip(variants_2, ground_truths)]\n",
    "\n",
    "        for i in range(len(input_texts)):\n",
    "            dist_variant_1 = distances_1[i]\n",
    "            dist_variant_2 = distances_2[i]\n",
    "            variant_1 = variants_1[i]\n",
    "            variant_2 = variants_2[i]\n",
    "            input_text = input_texts[i]\n",
    "            ground_truth = ground_truths[i]\n",
    "\n",
    "            # Label based on the smaller edit distance\n",
    "            if dist_variant_1 < dist_variant_2:\n",
    "                chosen = variant_1\n",
    "                rejected = variant_2\n",
    "                variant_1_count += 1\n",
    "            else:\n",
    "                chosen = variant_2\n",
    "                rejected = variant_1\n",
    "                variant_2_count += 1\n",
    "\n",
    "            # Add the comparison to the preference dataset\n",
    "            preference_data.append({\n",
    "                'input': input_text,\n",
    "                'ground_truth': ground_truth,\n",
    "                'variant_1': variant_1,\n",
    "                'variant_2': variant_2,\n",
    "                'chosen': chosen,\n",
    "                'rejected': rejected\n",
    "            })\n",
    "\n",
    "    # Reporting statistics\n",
    "    total_examples = len(dataset)\n",
    "    norm_variant_1_count = variant_1_count / total_examples * 100\n",
    "    norm_variant_2_count = variant_2_count / total_examples * 100\n",
    "    time.sleep(5)  # Simulate a long computation\n",
    "    print(f\"Variant 1 chosen: {variant_1_count} ({norm_variant_1_count:.2f}%)\")\n",
    "    print(f\"Variant 2 chosen: {variant_2_count} ({norm_variant_2_count:.2f}%)\")\n",
    "\n",
    "    return preference_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Huertas97/smollm-gec-sftt\", padding_side='left')\n",
    "best_model = AutoModelForCausalLM.from_pretrained(\"Huertas97/smollm-gec-sftt\",\n",
    "                                                  device_map='auto',\n",
    "                                                  use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "toy_train_data = train_gec_ds.select(range(1000))\n",
    "\n",
    "\n",
    "preference_dataset = create_preference_dataset(best_model, tokenizer, toy_train_data)\n",
    "\n",
    "# save preference_dataset to parqet to be loaded in pandas\n",
    "df = pd.DataFrame(preference_dataset)\n",
    "# df.to_parquet(\"dpo_preference_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"dpo_preference_dataset_1k.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SFT+DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Run Direct Preference Optimization (DPO)\n",
    "\n",
    "\n",
    "# Create DPO data with the required format with\n",
    "# 3 entries: prompt, chosen, rejected\n",
    "def return_prompt_and_responses(samples):\n",
    "    return {\n",
    "     \"prompt\": [\n",
    "      f\"### Input: ```{input}```\\n ### Correct: \"\n",
    "      for input in samples[\"input\"]\n",
    "      ],\n",
    "      \"chosen\": samples[\"chosen\"],\n",
    "      \"rejected\": samples[\"rejected\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Load the data generated from parquet\n",
    "dpo_preference_dataset = load_dataset(\"parquet\", data_files={\"train\": \"./dpo_preference_dataset_1k.parquet\"})\n",
    "original_columns = dpo_preference_dataset[\"train\"].column_names\n",
    "\n",
    "# Apply the formatting\n",
    "dpo_train_dataset = dpo_preference_dataset.map(\n",
    " return_prompt_and_responses,\n",
    " batched=True,\n",
    " remove_columns=original_columns\n",
    ")[\"train\"]\n",
    "\n",
    "dpo_train_dataset = dpo_train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from huggingface (in case it was not loaded)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Huertas97/smollm-gec-sftt\")\n",
    "best_model = AutoModelForCausalLM.from_pretrained(\"Huertas97/smollm-gec-sftt\",\n",
    "                                                  device_map='auto',\n",
    "                                                  use_cache=True,\n",
    "                                                  )\n",
    "\n",
    "best_model_ref = AutoModelForCausalLM.from_pretrained(\"Huertas97/smollm-gec-sftt\",\n",
    "                                                  device_map='auto',\n",
    "                                                  use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep over hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train_dpo():\n",
    "    # Initialize a new run for WandB\n",
    "    wandb.init()\n",
    "\n",
    "    # Access sweep-configured hyperparameters from WandB config\n",
    "    config = wandb.config\n",
    "\n",
    "    # Load the sftt trained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Huertas97/smollm-gec-sftt\", use_fast=True, trust_remote_code=True,\n",
    "                                              truncation=True, padding=True,\n",
    "                                              return_tensors=\"pt\")\n",
    "    best_model = AutoModelForCausalLM.from_pretrained(\"Huertas97/smollm-gec-sftt\",\n",
    "                                                      device_map='auto',\n",
    "                                                      use_cache=True,\n",
    "                                                      )\n",
    "    # best_model_ref = AutoModelForCausalLM.from_pretrained(\"Huertas97/smollm-gec-sftt\",\n",
    "    #                                                   device_map='auto',\n",
    "    #                                                   use_cache=True)\n",
    "\n",
    "\n",
    "    # Configure DPO with hyperparameters from WandB config\n",
    "    output_dir_sftt = \"smollm-gec-sftt\"\n",
    "    output_dir_dpo = \"smollm-gec-sftt\" + \"-dpo\"\n",
    "    dpo_config = DPOConfig(\n",
    "        output_dir = output_dir_dpo,\n",
    "        beta=config.beta,\n",
    "        learning_rate=config.learning_rate,\n",
    "        num_train_epochs=config.epochs,\n",
    "        weight_decay = config.weight_decay,\n",
    "        lr_scheduler_type = config.lr_scheduler_type,\n",
    "        loss_type=config.loss_type,\n",
    "        seed=config.seed,\n",
    "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    # Initialize the DPOtrainer with the model, datasets, and SFT configuration\n",
    "    dpo_trainer = DPOTrainer(\n",
    "        best_model,\n",
    "        best_model,\n",
    "        args=dpo_config,\n",
    "        train_dataset=dpo_train_dataset,\n",
    "        # eval_dataset=dpo_train_dataset,\n",
    "        tokenizer=tokenizer,  # for visual language models, use tokenizer=processor instead\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    dpo_trainer.train()\n",
    "\n",
    "    # Log any final metrics (you can log more metrics inside the training loop if needed)\n",
    "    wandb.log({\"final_eval_loss\": dpo_trainer.evaluate()[\"eval_loss\"]})\n",
    "\n",
    "    # Finish the WandB run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: s2l1bgj5\n",
      "Sweep URL: https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/sweeps/s2l1bgj5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ljlo4sqj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_type: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuertas_97\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/AI_projects/wandb/run-20240913_170204-ljlo4sqj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/runs/ljlo4sqj' target=\"_blank\">olive-sweep-1</a></strong> to <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/sweeps/s2l1bgj5' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/sweeps/s2l1bgj5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/sweeps/s2l1bgj5' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/sweeps/s2l1bgj5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/runs/ljlo4sqj' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/runs/ljlo4sqj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:671: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:684: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:719: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84f155ac785479b91146465d7f5e70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c146104f3ca2460f804ad2a62aa9b938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-1</strong> at: <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/runs/ljlo4sqj' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo/runs/ljlo4sqj</a><br/> View project at: <a href='https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo' target=\"_blank\">https://wandb.ai/huertas_97/C4AI-Challenge-smollm-sft-dpo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240913_170204-ljlo4sqj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ljlo4sqj errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_405241/3470824841.py\", line 49, in train_dpo\n",
      "    dpo_trainer.train()\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/transformers/trainer.py\", line 1859, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/transformers/trainer.py\", line 2266, in _inner_training_loop\n",
      "    self.optimizer.step()\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/accelerate/optimizer.py\", line 172, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/adamw.py\", line 177, in step\n",
      "    has_complex = self._init_group(\n",
      "  File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/adamw.py\", line 124, in _init_group\n",
      "    state[\"exp_avg\"] = torch.zeros_like(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ljlo4sqj errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_405241/3470824841.py\", line 49, in train_dpo\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     dpo_trainer.train()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/transformers/trainer.py\", line 1859, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner_training_loop(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/transformers/trainer.py\", line 2266, in _inner_training_loop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.optimizer.step()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/accelerate/optimizer.py\", line 172, in step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.optimizer.step(closure)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return wrapped(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     out = func(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ret = func(self, *args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/adamw.py\", line 177, in step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     has_complex = self._init_group(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/mnt/almacenamiento/miniconda3/envs/NLP_ENV/lib/python3.10/site-packages/torch/optim/adamw.py\", line 124, in _init_group\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     state[\"exp_avg\"] = torch.zeros_like(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # You can also use 'grid' or 'bayes'\n",
    "    \"metric\": {\"name\": \"final_eval_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [5e-5, 3e-5, 1e-4]  # Exploring different learning rates\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"values\": [0.0, 0.01, 0.1]  # Exploring weight decay\n",
    "        },\n",
    "        \"epochs\": {\n",
    "            \"values\": [1]\n",
    "        },\n",
    "        \"gradient_accumulation_steps\": {\n",
    "            \"values\": [2, 4]  # Exploring gradient accumulation for smaller GPUs\n",
    "        },\n",
    "        \"beta\": {\"values\": [0.1]}, # Higher beta means less divergence from the initial policy.\n",
    "        \"loss_type\": {\"values\": [\"sigmoid\", \"robust\"]},\n",
    "        \"lr_scheduler_type\": {\"values\": [\"linear\", \"cosine\"]},\n",
    "        \"seed\": {\"value\": 42},\n",
    "        \"per_device_train_batch_size\": {\"value\": 1},\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"C4AI-Challenge-smollm-sft-dpo\")\n",
    "\n",
    "# Launch the sweep\n",
    "wandb.agent(sweep_id, function=train_dpo, count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mSTSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_mstsb_train = pd.read_pickle(\"/home/AI_projects/Multilingual-STSB/Data/Multi-STSB-train.pkl\")\n",
    "df_mstsb_train_v1 = pd.read_pickle(\"/home/AI_projects/Multilingual-STSB/Data/Cross-lingual/Train/mSTSb_train_crosslingual_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stsb_train_1</th>\n",
       "      <th>stsb_train_2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-CN</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-TW</th>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stsb_train_1  stsb_train_2  score\n",
       "lang                                    \n",
       "ar             2063          2063   2063\n",
       "cs             2063          2063   2063\n",
       "de             2063          2063   2063\n",
       "en             2063          2063   2063\n",
       "es             2063          2063   2063\n",
       "fr             2063          2063   2063\n",
       "hi             2063          2063   2063\n",
       "it             2063          2063   2063\n",
       "ja             2063          2063   2063\n",
       "nl             2063          2063   2063\n",
       "pl             2063          2063   2063\n",
       "pt             2063          2063   2063\n",
       "ru             2063          2063   2063\n",
       "tr             2063          2063   2063\n",
       "zh-CN          2063          2063   2063\n",
       "zh-TW          2063          2063   2063"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mstsb_train.loc[ df_mstsb_train[\"score\"] >= 0.7].groupby(\"lang\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 178219 entries, 0 to 5748\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   task                178219 non-null  object \n",
      " 1   stsb_train_1_lang1  178219 non-null  object \n",
      " 2   stsb_train_2_lang2  178219 non-null  object \n",
      " 3   score_lang2         178219 non-null  float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_mstsb_train_v1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stsb_train_1_lang1</th>\n",
       "      <th>stsb_train_2_lang2</th>\n",
       "      <th>score_lang2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en;en</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en;en</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en;en</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en;en</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en;en</td>\n",
       "      <td>Some men are fighting.</td>\n",
       "      <td>Two men are fighting.</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>en;zh-TW</td>\n",
       "      <td>Tokyo shares open higher over buoyant U.S. market</td>\n",
       "      <td>東京股市開盤走高追踪美國漲幅</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>en;zh-TW</td>\n",
       "      <td>Hawaii preps for first hurricane in 22 years</td>\n",
       "      <td>夏威夷成為22年以來的第一場颶風</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>en;zh-TW</td>\n",
       "      <td>Tokyo shares open higher on buoyant U.S. market</td>\n",
       "      <td>東京股市在美國強勁表現後開盤走高</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>en;zh-TW</td>\n",
       "      <td>Lewis Hamilton Takes Pole for Russian GP</td>\n",
       "      <td>劉易斯·漢密爾頓（Lewis Hamilton）贏得首屆俄羅斯大獎賽</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>en;zh-TW</td>\n",
       "      <td>Suspected Boko Haram suicide bombers in Nigeri...</td>\n",
       "      <td>涉嫌博科聖地襲擊事件在尼日利亞造成數十人死亡</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63953 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          task                                 stsb_train_1_lang1  \\\n",
       "0        en;en                             A plane is taking off.   \n",
       "1        en;en                    A man is playing a large flute.   \n",
       "2        en;en      A man is spreading shreded cheese on a pizza.   \n",
       "4        en;en                        A man is playing the cello.   \n",
       "5        en;en                             Some men are fighting.   \n",
       "...        ...                                                ...   \n",
       "5668  en;zh-TW  Tokyo shares open higher over buoyant U.S. market   \n",
       "5670  en;zh-TW       Hawaii preps for first hurricane in 22 years   \n",
       "5673  en;zh-TW    Tokyo shares open higher on buoyant U.S. market   \n",
       "5676  en;zh-TW           Lewis Hamilton Takes Pole for Russian GP   \n",
       "5682  en;zh-TW  Suspected Boko Haram suicide bombers in Nigeri...   \n",
       "\n",
       "                                     stsb_train_2_lang2  score_lang2  \n",
       "0                           An air plane is taking off.         1.00  \n",
       "1                             A man is playing a flute.         0.76  \n",
       "2     A man is spreading shredded cheese on an uncoo...         0.76  \n",
       "4                    A man seated is playing the cello.         0.85  \n",
       "5                                 Two men are fighting.         0.85  \n",
       "...                                                 ...          ...  \n",
       "5668                                     東京股市開盤走高追踪美國漲幅         0.80  \n",
       "5670                                   夏威夷成為22年以來的第一場颶風         1.00  \n",
       "5673                                   東京股市在美國強勁表現後開盤走高         0.80  \n",
       "5676                 劉易斯·漢密爾頓（Lewis Hamilton）贏得首屆俄羅斯大獎賽         0.80  \n",
       "5682                             涉嫌博科聖地襲擊事件在尼日利亞造成數十人死亡         0.80  \n",
       "\n",
       "[63953 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mstsb_train_v1.loc[ df_mstsb_train_v1[\"score_lang2\"] >= 0.7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>stsb_train_1_lang1</th>\n",
       "      <th>stsb_train_2_lang2</th>\n",
       "      <th>score_lang2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>ja;ja</td>\n",
       "      <td>男は椅子に座って見つめていました。</td>\n",
       "      <td>少女は髪をポニーテールに入れています。</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>en;ar</td>\n",
       "      <td>A woman in a black dress smiles in front of a silver truck.</td>\n",
       "      <td>فتاة ترتدي قميصًا أسود تبتسم وشاحنة فضية في الخلفية.</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>en;es</td>\n",
       "      <td>A man is playing the piano.</td>\n",
       "      <td>El hombre toca el violín.</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>en;en</td>\n",
       "      <td>Strayhorn said it was the first time in Texas history a comptroller had not certified the appropriations act.</td>\n",
       "      <td>In a news release Thursday, Strayhorn said this was the first time a comptroller rejected a budget.</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>tr;tr</td>\n",
       "      <td>Çekimler, protestolar Tayland oylamasına gölge düşürdü</td>\n",
       "      <td>Taylandlı protestocular oylama sürecini aksattı</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>ru;ru</td>\n",
       "      <td>Лэй утверждал, что передача документов будет нарушением его прав по Пятой поправке против самооговора.</td>\n",
       "      <td>Лэй отказался передать документы, заявив о своем праве по Пятой поправке против самообвинения.</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>en;tr</td>\n",
       "      <td>A man and woman are driving down the street in a jeep.</td>\n",
       "      <td>Bir kadın ve bir erkek açık hava bir araçla yolda ilerliyor.</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>en;nl</td>\n",
       "      <td>A women laying across two men sitting on a sofa.</td>\n",
       "      <td>Een man en twee vrouwen glimlachen naar de camera terwijl ze op een blauwe bank zitten.</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>cs;cs</td>\n",
       "      <td>Americká stávka dronů zabila v Pákistánu 5 lidí</td>\n",
       "      <td>Pákistánská drone stávka zabije až šest</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>en;nl</td>\n",
       "      <td>A monkey is walking through the water.</td>\n",
       "      <td>Een man speelt op een trompet.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task  \\\n",
       "469   ja;ja   \n",
       "1635  en;ar   \n",
       "104   en;es   \n",
       "2990  en;en   \n",
       "5045  tr;tr   \n",
       "2989  ru;ru   \n",
       "132   en;tr   \n",
       "1043  en;nl   \n",
       "4921  cs;cs   \n",
       "928   en;nl   \n",
       "\n",
       "                                                                                                 stsb_train_1_lang1  \\\n",
       "469                                                                                               男は椅子に座って見つめていました。   \n",
       "1635                                                    A woman in a black dress smiles in front of a silver truck.   \n",
       "104                                                                                     A man is playing the piano.   \n",
       "2990  Strayhorn said it was the first time in Texas history a comptroller had not certified the appropriations act.   \n",
       "5045                                                         Çekimler, protestolar Tayland oylamasına gölge düşürdü   \n",
       "2989         Лэй утверждал, что передача документов будет нарушением его прав по Пятой поправке против самооговора.   \n",
       "132                                                          A man and woman are driving down the street in a jeep.   \n",
       "1043                                                               A women laying across two men sitting on a sofa.   \n",
       "4921                                                                Americká stávka dronů zabila v Pákistánu 5 lidí   \n",
       "928                                                                          A monkey is walking through the water.   \n",
       "\n",
       "                                                                                       stsb_train_2_lang2  \\\n",
       "469                                                                                   少女は髪をポニーテールに入れています。   \n",
       "1635                                                 فتاة ترتدي قميصًا أسود تبتسم وشاحنة فضية في الخلفية.   \n",
       "104                                                                             El hombre toca el violín.   \n",
       "2990  In a news release Thursday, Strayhorn said this was the first time a comptroller rejected a budget.   \n",
       "5045                                                      Taylandlı protestocular oylama sürecini aksattı   \n",
       "2989       Лэй отказался передать документы, заявив о своем праве по Пятой поправке против самообвинения.   \n",
       "132                                          Bir kadın ve bir erkek açık hava bir araçla yolda ilerliyor.   \n",
       "1043              Een man en twee vrouwen glimlachen naar de camera terwijl ze op een blauwe bank zitten.   \n",
       "4921                                                              Pákistánská drone stávka zabije až šest   \n",
       "928                                                                        Een man speelt op een trompet.   \n",
       "\n",
       "      score_lang2  \n",
       "469          0.00  \n",
       "1635         0.72  \n",
       "104          0.35  \n",
       "2990         0.64  \n",
       "5045         0.72  \n",
       "2989         0.76  \n",
       "132          0.80  \n",
       "1043         0.44  \n",
       "4921         0.60  \n",
       "928          0.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_mstsb_train_v1.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIME_SERIES_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
