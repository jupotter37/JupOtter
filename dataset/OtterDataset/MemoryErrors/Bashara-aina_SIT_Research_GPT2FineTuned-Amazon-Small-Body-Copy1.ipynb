{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7411c9b3-57ae-44d8-9354-2f5faf533061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_us_reviews (/home/z123010/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09885a5a1b624c4c9415b4462c43d9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating  \n",
       "customer_id                                                                  \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \n",
       "2714559      I love this dress. Absolute favorite for winte...            5  \n",
       "12608825     Nice socks, great colors, just enough support ...            5  \n",
       "25482800     I bought this for my husband and WOW, this is ...            5  \n",
       "9310286      Perfect dress and the customer service was awe...            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Limit the dataset to the first 10,000 rows\n",
    "train_data = train_data.select(range(1000))\n",
    "\n",
    "df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "df = df[['customer_id', 'review_headline', 'review_body', 'star_rating']]  # Select specific columns\n",
    "df.columns = ['customer_id', 'review_headline', 'review_body', 'star_rating']  # Rename the selected columns\n",
    "df.set_index('customer_id', inplace=True)\n",
    "df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a320e6-312f-4ff5-bb17-2eb31e804203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "5    683\n",
       "4    144\n",
       "1     76\n",
       "3     56\n",
       "2     41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81f4f09-54cd-4567-bb51-76731ca01bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['star_rating'].map({5: 'good', 4: 'good', 3: 'neutral', 2: 'bad', 1: 'bad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d6025f-390a-4e06-8447-2456e5e886b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "good       827\n",
       "bad        117\n",
       "neutral     56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9388025f-803f-4248-b2e6-0b8d90424bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.sentiment.unique() #Get unique category labels from the DataFrame column 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c525852-606f-4b24-ac4d-9e0f31b01b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {} #Create a dictionary to map each possible label to a unique index\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa1fbaf-1368-4644-b03b-1ce1506ce397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 0, 'neutral': 1, 'bad': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74cae2bf-c330-4f88-9f1b-76bf0356b7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26631939</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent for my 6 feet skinny 15 years old boy.</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48785098</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>Raw is the only way to go! Absolutely love thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39548589</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>A bit large.</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355866</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great fit!</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477484</th>\n",
       "      <td>Not my favorite.</td>\n",
       "      <td>Shirt a bit too long, with heavy hem, which in...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "26631939                                            Five Stars   \n",
       "48785098                                              Love it!   \n",
       "39548589                                           Three Stars   \n",
       "29355866                                            Five Stars   \n",
       "27477484                                      Not my favorite.   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "26631939      Excellent for my 6 feet skinny 15 years old boy.            5   \n",
       "48785098     Raw is the only way to go! Absolutely love thi...            5   \n",
       "39548589                                          A bit large.            4   \n",
       "29355866                                            Great fit!            5   \n",
       "27477484     Shirt a bit too long, with heavy hem, which in...            3   \n",
       "\n",
       "            sentiment  label  \n",
       "customer_id                   \n",
       "32158956         good      0  \n",
       "2714559          good      0  \n",
       "12608825         good      0  \n",
       "25482800         good      0  \n",
       "9310286          good      0  \n",
       "26631939         good      0  \n",
       "48785098         good      0  \n",
       "39548589         good      0  \n",
       "29355866         good      0  \n",
       "27477484      neutral      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.sentiment.replace(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd45ea81-a693-415f-9deb-69a36cdc46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fcc1638-d587-4df7-8eef-9204f359acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830c4f3c-4391-40c8-99ed-ee34821a2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0] #Set a new column 'data_type' for later data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0215b4-e6e8-43d8-8445-70b7acd4a8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "\n",
       "            sentiment  label data_type  \n",
       "customer_id                             \n",
       "32158956         good      0   not_set  \n",
       "2714559          good      0   not_set  \n",
       "12608825         good      0   not_set  \n",
       "25482800         good      0   not_set  \n",
       "9310286          good      0   not_set  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a03c2f8-8ce6-41c4-b86a-a63baa0bf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the 'data_type' column of the dataframe for training and validation data\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b919e0f0-41d4-4ebb-9265-6843a4b03cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_headline  review_body  sentiment\n",
       "star_rating label data_type                                         \n",
       "1           2     train                   65           65         65\n",
       "                  val                     11           11         11\n",
       "2           2     train                   34           34         34\n",
       "                  val                      7            7          7\n",
       "3           1     train                   48           48         48\n",
       "                  val                      8            8          8\n",
       "4           0     train                  116          116        116\n",
       "                  val                     28           28         28\n",
       "5           0     train                  548          548        548\n",
       "                  val                    135          135        135"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star_rating', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212019be-eff8-4c8c-8662-2fbdf93c9ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 16:35:02.019710: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-05 16:35:02.043253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 16:35:02.422863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa1ca9b-f491-4889-927f-f8731694bd47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = '[PAD]'\n",
    "encoded_data_train_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_train_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train_headline = encoded_data_train_headline['input_ids']\n",
    "attention_masks_train_headline = encoded_data_train_headline['attention_mask']\n",
    "\n",
    "input_ids_train_body = encoded_data_train_body['input_ids']\n",
    "attention_masks_train_body = encoded_data_train_body['attention_mask']\n",
    "\n",
    "input_ids_train = torch.cat((input_ids_train_headline, input_ids_train_body), dim=1)\n",
    "attention_masks_train = torch.cat((attention_masks_train_headline, attention_masks_train_body), dim=1)\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "\n",
    "encoded_data_val_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val_headline = encoded_data_val_headline['input_ids']\n",
    "attention_masks_val_headline = encoded_data_val_headline['attention_mask']\n",
    "\n",
    "input_ids_val_body = encoded_data_val_body['input_ids']\n",
    "attention_masks_val_body = encoded_data_val_body['attention_mask']\n",
    "\n",
    "input_ids_val = torch.cat((input_ids_val_headline, input_ids_val_body), dim=1)\n",
    "attention_masks_val = torch.cat((attention_masks_val_headline, attention_masks_val_body), dim=1)\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8df41f6-f750-48fd-a867-cd8211b4eea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06087a20-bb64-451f-930d-e4020b74cd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1be16f-2e08-451f-ad43-76262311d89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57dc7b55-a622-43f7-9127-ab13bdd6b839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHere, I use the GPT2ForSequenceClassification model, which is a GPT model for sequence classification\\ntask such as sentiment analysis. The pre-trained GPT model is loaded from 'gpt2', and we set the number of labels to be the length of unique labels in the dataset.\\n\\nI also set output_attentions and output_hidden_states to False, which means I only get the output\\nfrom the last layer of GPT.\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a GPT model for sequence classification task\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    'gpt2',\n",
    "    num_labels=len(label_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Here, I use the GPT2ForSequenceClassification model, which is a GPT model for sequence classification\n",
    "task such as sentiment analysis. The pre-trained GPT model is loaded from 'gpt2', and we set the number of labels to be the length of unique labels in the dataset.\n",
    "\n",
    "I also set output_attentions and output_hidden_states to False, which means I only get the output\n",
    "from the last layer of GPT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b9c932-47f8-4683-8a5c-45ac3feec88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ff5662-1ec8-43b0-98b1-4d299d584843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 1 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b361e31-7b47-4264-9b3e-bd27a35b3d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74eccba-b3d4-46e6-902d-f794dbdf0d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/.local/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),  # Passes the model parameters to the optimizer\n",
    "    lr=1e-5,             # Sets the learning rate for the optimizer to 1e-5\n",
    "    eps=1e-8             # Sets the epsilon value for numerical stability to 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c115596-a088-4b99-ba48-95c378dd9694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 3 #This sets the number of epochs or the number of times the model will iterate over the entire dataset during training to 10.\n",
    "\n",
    "#This creates a linear learning rate scheduler that increases the learning rate linearly over the course of training and uses the specified number of warm-up steps and total training steps.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, #This sets the number of warm-up steps during training to 0. Warm-up steps gradually increase the learning rate from an initial low value to the target learning rate.\n",
    "    num_training_steps=len(dataloader_train)*epochs #This sets the number of total training steps to the number of batches per epoch times the number of epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe17bbb8-191e-48be-b5f9-b1aa2f39a041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b611a8-c688-4fec-b2e7-eb16390cd8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score #F1 score is a measure of a model's accuracy, combining both precision and recall, used to evaluate binary classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97209521-74d4-4d9a-afa7-e67084dea77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32fea2e3-d16c-4978-8843-bd5d2ccb152a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dd050b1-a41d-4a72-a0fd-9a56091e052b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f803e9ea-087b-47df-b978-a418a8414aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb07e43-e584-4f7a-9e29-8f0bcde6254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07b81932-497f-471e-a464-470ae5c3717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cuda.max_split_size_mb = 5500\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "data = torch.randn([1, 3, 470, 446], dtype=torch.float, device='cuda', requires_grad=True)\n",
    "net = torch.nn.Conv2d(3, 64, kernel_size=[7, 7], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)\n",
    "net = net.cuda().float()\n",
    "out = net(data)\n",
    "out.backward(torch.randn_like(out))\n",
    "torch.cuda.synchronize()\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06411cac-b3ad-4e13-825b-b403fba46a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3950324a37a8485489959fa3e533163c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bb0996ccd349a784f1aa8e9574135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.80 GiB total capacity; 939.71 MiB already allocated; 19.69 MiB free; 1.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m loss_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.80 GiB total capacity; 939.71 MiB already allocated; 19.69 MiB free; 1.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total_training_time = 0\n",
    "\n",
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "f1_score_list = []\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc='Epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "        output = model(**inputs)\n",
    "        loss = output[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_training_time = end_time - start_time\n",
    "    total_training_time += epoch_training_time\n",
    "\n",
    "    torch.save(model.state_dict(), f'Models/Body/finetuned_gpt_ft_epoch{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "\n",
    "    # Convert predictions to discrete labels\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "\n",
    "    val_accuracy = accuracy_score(true_vals, predictions)\n",
    "    val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "\n",
    "    # Compute and store metrics\n",
    "    training_loss_list.append(loss_train_avg)\n",
    "    validation_loss_list.append(val_loss)\n",
    "    f1_score_list.append(val_f1)\n",
    "    accuracy_list.append(val_accuracy)\n",
    "    precision_list.append(val_precision)\n",
    "\n",
    "total_time_minutes = total_training_time / 60\n",
    "tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "\n",
    "final_accuracy = accuracy_list[-1]\n",
    "final_precision = precision_list[-1]\n",
    "tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "tqdm.write(f'Final Precision: {final_precision}')\n",
    "\n",
    "# Create a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "\n",
    "# Plot validation loss\n",
    "ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "\n",
    "# Plot F1-score\n",
    "ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "\n",
    "# Set legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199fa6a-4424-4bc8-abc0-8cbf81f13b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "\n",
    "# Plot validation loss\n",
    "ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "\n",
    "# Plot F1-score\n",
    "ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "\n",
    "# Set legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
