{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047066f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f300934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116db7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4be8e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1817c60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4fda66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a6d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9797, 24251]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764c8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-matias/Alan/newVenv/UQ-VAE/InvariantAlan/gh_uqvae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd91ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from trainuqvae import train_uqvae\n",
    "from uqvae import NNmodel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.quality import FoM\n",
    "#import utils.genmatrices\n",
    "#from utils.jwavematrix import build_sym_matrix\n",
    "from utils.genmatrices import genAj\n",
    "from utils.OAT import createForwMatdotdet\n",
    "\n",
    "##############################################################################\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \n",
    "    train = True\n",
    "    pretrain = False\n",
    "    ptepochs = 5\n",
    "    continuetrain = False\n",
    "    \n",
    "    precalcA = True\n",
    "    usesavedAj = False\n",
    "    \n",
    "    predict = False\n",
    "    numtest = 500\n",
    "    \n",
    "    # UQ-VAE parameters\n",
    "    #image_size = 128  # the image size and shape\n",
    "    image_size = 128  # the image size and shape\n",
    "    \n",
    "    lamba = 0.5 # sacling parameters\n",
    "    l = 0.5e-3 # [m] characteristic length\n",
    "    s0 = 0.25 # prior standard deviation\n",
    "    eta0 = 0.5 # prior expected value\n",
    "    etae = 0 # noise mean value\n",
    "    semin = 1e-3 # min value of the noise standard deviation\n",
    "    semax = 5e-3 # max value of the noise standard deviation\n",
    "    \n",
    "    # Training parameters    \n",
    "    train_batch_size = 20\n",
    "    num_epochs = 10\n",
    "    learning_rate = 1e-6\n",
    "    val_percent = 0.2\n",
    "    valid_loss_min = 100\n",
    "    \n",
    "    # OAT setup parameters\n",
    "    Ns = 36         # number of detectors\n",
    "    Nt = 1024       # number of time samples\n",
    "    dx = 115e-6     # pixel size  in the x direction [m] \n",
    "    \n",
    "    #nx = 128        # number of pixels in the x direction for a 2-D image region\n",
    "    nx = 128\n",
    "    Rs = 44e-3     # radius of the circunference where the detectors are placed [m]\n",
    "    arco = 360      # arc of the circunferencewhere the detectors are placed\n",
    "    vs = 1490       # speed of sound [m/s]\n",
    "    to = 21.5e-6    # initial time [s].\n",
    "    T = 25e-6       # durantion of the time window [s].\n",
    "    tf = to + T     # final time [s] \n",
    "    LBW = True      # Apply detector impulse reponse?\n",
    "    \n",
    "    # \n",
    "    cache_dir = './data/' \n",
    "    traindate = '24mar24'\n",
    "    \n",
    "    datadate = '24mar24F'\n",
    "    \n",
    "    plotresults = False \n",
    "    \n",
    "    ckp_last='uqvae' + traindate + '.pth' # name of the file of the saved weights of the trained net\n",
    "    ckp_best='uqvae_best' + traindate + '.pth'\n",
    "    \n",
    "    logfilename = 'TrainingLog_UQVAE' + traindate + '.log' \n",
    "\n",
    "###############################################################################\n",
    "def gettestndata(cache_dir,datadate):\n",
    "    \n",
    "    print('Obtaining data for testing...')\n",
    "    \n",
    "    Xt = np.load(cache_dir + 'Xdast' + datadate + '.npy')\n",
    "    Yt = np.load(cache_dir + 'Yt' + datadate + '.npy') \n",
    "    #Zt = np.load(cache_dir + 'ESt' + datadate + '.npy') \n",
    "    \n",
    "    Xt = Xt.astype(np.float32)\n",
    "    Yt = Yt.astype(np.float32)\n",
    "    #Zt = Zt.astype(np.float32)\n",
    "\n",
    "    print('done')\n",
    "    \n",
    "    return Xt,Yt#,Zt\n",
    "  \n",
    "##############################################################################\n",
    "def predict(config):\n",
    "    \n",
    "    numtest = config.numtest\n",
    "    device = 'cpu'\n",
    "    net = NNmodel().to(device=device)\n",
    "    Xt,Yt = gettestndata(config.cache_dir,config.datadate)\n",
    "    x = Xt[0:numtest,:,:]\n",
    "    y = Yt[0:numtest,:,:]\n",
    "    #z = Zt[0:numtest,:,:]\n",
    "    #\n",
    "    inp = torch.as_tensor(x)\n",
    "    inp = inp.to(device=device)\n",
    "    inp = inp.type(torch.float32)\n",
    "    checkpoint = torch.load(config.ckp_best,map_location=torch.device(device))\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "    m, logs2 = net.predict(inp)\n",
    "    \n",
    "    return x,y,m,logs2\n",
    "\n",
    "##############################################################################\n",
    "def quality(test,recons):\n",
    "      \n",
    "    numtest,H,W = test.shape\n",
    "    SSIM = np.zeros((numtest,))\n",
    "    PC = np.zeros((numtest,))\n",
    "    RMSE = np.zeros((numtest,))\n",
    "    PSNR = np.zeros((numtest,))\n",
    "    \n",
    "    for i in tqdm(range(numtest)):\n",
    "        SSIM[i],PC[i],RMSE[i],PSNR[i] = FoM(test[i,:,:],recons[i,:,:])\n",
    "        if PC[i] == 'nan':\n",
    "            PC[i] == 0\n",
    "    \n",
    "    print('Results:')    \n",
    "    print('SSIM: ',np.mean(SSIM),np.std(SSIM))\n",
    "    print('PC: ', np.mean([~np.isnan(PC)]),np.std([~np.isnan(PC)]))\n",
    "    print('RMSE: ', np.mean(RMSE),np.std(RMSE))\n",
    "    print('PSNR: ', np.mean(PSNR),np.std(PSNR))\n",
    "        \n",
    "    return SSIM, PC, RMSE, PSNR\n",
    "\n",
    "##############################################################################\n",
    "def genAo(config):\n",
    "    return createForwMatdotdet( config.Ns , config.Nt , config.dx , config.nx , config.Rs , config.arco , config.vs , config.to , config.tf )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80f6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to be used: cuda\n",
      "The number of parameters of the network to be trained is: 196269954\n",
      "Loading data...\n",
      "Obtaining data for training...\n",
      "done\n",
      "Creating Prior Distribution Matrix...\n",
      "Gp0:  torch.Size([16384, 16384])\n",
      "done\n",
      "Creating Le...\n",
      "done\n",
      "Creating Forward Model Matrix...\n",
      "Creating SIR Matrix...\n",
      "with shot noise effect reduction...\n",
      "with angle sensitivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36864/36864 [00:32<00:00, 1136.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PA Matrix...\n",
      "Applying Time Derivative Operator...\n",
      "Applying detector impulse response...\n",
      "Normalization...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/48 [00:00<?, ?sino/s]/opt/tljh/user/lib/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/tljh/user/lib/python3.9/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Epoch 1/10:   0%|          | 0/48 [00:01<?, ?sino/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.31 MiB is free. Process 285209 has 14.10 GiB memory in use. Including non-PyTorch memory, this process has 9.51 GiB memory in use. Of the allocated memory 7.81 GiB is allocated by PyTorch, and 131.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#Aj = genAj(config)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#Aj = genAo(config)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#Aj = sp.sparse.csc_matrix(Aj,dtype='float32')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#sp.sparse.save_npz(config.cache_dir+'Aj'+config.traindate+'.npz',Aj)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[0;32m---> 15\u001b[0m     EV,TLV,VLV \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_uqvae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlossUQVAE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtraindate\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m,E\u001b[38;5;241m=\u001b[39mEV,T\u001b[38;5;241m=\u001b[39mTLV,V\u001b[38;5;241m=\u001b[39mVLV)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpredict:\n",
      "File \u001b[0;32m~/Alan/newVenv/UQ-VAE/InvariantAlan/gh_uqvae/trainuqvae.py:232\u001b[0m, in \u001b[0;36mtrain_uqvae\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    230\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# net prediction\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m m, logs2 \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (pretrain)\u001b[38;5;241m&\u001b[39m(epoch\u001b[38;5;241m<\u001b[39mconfig\u001b[38;5;241m.\u001b[39mptepochs):\n",
      "File \u001b[0;32m~/Alan/newVenv/UQ-VAE/InvariantAlan/gh_uqvae/uqvae.py:162\u001b[0m, in \u001b[0;36mNNmodel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m x9 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet18(x9)      \u001b[38;5;66;03m# (B,512,32,32)\u001b[39;00m\n\u001b[1;32m    161\u001b[0m x10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet19(x9,x2)  \u001b[38;5;66;03m# (B,256,64,64)\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m x10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet20\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx10\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# (B,256,64,64)\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m#x11 = self.unet23(x10)  # MODIFICACION\u001b[39;00m\n\u001b[1;32m    166\u001b[0m x11 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet21(x10,x1) \u001b[38;5;66;03m# (B,128,128,128)\u001b[39;00m\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Alan/newVenv/UQ-VAE/InvariantAlan/gh_uqvae/uqvae.py:59\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 59\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnorm1(y)\n\u001b[1;32m     61\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(y)\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Alan/newVenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.31 MiB is free. Process 285209 has 14.10 GiB memory in use. Including non-PyTorch memory, this process has 9.51 GiB memory in use. Of the allocated memory 7.81 GiB is allocated by PyTorch, and 131.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "##############################################################################\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    config = TrainingConfig()\n",
    "    \n",
    "    if config.precalcA:\n",
    "        a = 0\n",
    "        #Aj = genAj(config)\n",
    "        #Aj = genAo(config)\n",
    "        #Aj = sp.sparse.csc_matrix(Aj,dtype='float32')\n",
    "        #sp.sparse.save_npz(config.cache_dir+'Aj'+config.traindate+'.npz',Aj)\n",
    "        \n",
    "    if config.train:\n",
    "        EV,TLV,VLV = train_uqvae(config)\n",
    "        np.savez('lossUQVAE'+config.traindate+'.npz',E=EV,T=TLV,V=VLV)\n",
    "    \n",
    "    if config.predict:\n",
    "        x,y,pm,plogs2 = predict(config)\n",
    "        SSIM, PC, RMSE, PSNR = quality(y,pm)\n",
    "        np.savez('qualityUQVAE'+config.traindate+'.npz',SSIM=SSIM,PC=PC,RMSE=RMSE,PSNR=PSNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21f7c512",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jax in /home/jupyter-matias/.local/lib/python3.9/site-packages (0.4.26)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/jupyter-matias/.local/lib/python3.9/site-packages (from jax) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/tljh/user/lib/python3.9/site-packages (from jax) (1.24.2)\n",
      "Requirement already satisfied: opt-einsum in /home/jupyter-matias/.local/lib/python3.9/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /home/jupyter-matias/.local/lib/python3.9/site-packages (from jax) (1.11.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/tljh/user/lib/python3.9/site-packages (from jax) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/tljh/user/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax) (3.13.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.5.6 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4888b1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36864, 16384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed42fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newVenv",
   "language": "python",
   "name": "newvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
