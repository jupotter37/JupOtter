{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be13b0c-a2d0-48ef-81d0-d8a1fbe461e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.31.0)\n",
      "Requirement already satisfied: optimum in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (12.535.133)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: coloredlogs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (2.19.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (4.25.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate optimum nvidia-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3eb5e6-2476-4b97-a0bf-304847b4c83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8ab46121f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import json\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd16d255-3252-4d0f-9b1b-e7c0ea85c6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def check_gpu(step):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"{step}: GPU memory used: {info.used // 1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df44f2c5-6f19-44ec-a5a7-b82164330a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def D(obj, label=None, c=True):\n",
    "    print()\n",
    "    if label:\n",
    "        print(label)\n",
    "        \n",
    "    if isinstance(obj, tuple):\n",
    "        print(len(obj))\n",
    "    elif isinstance(obj, torch.Tensor) or isinstance(obj, np.ndarray):\n",
    "        print(obj.shape)\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "    else:\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "            \n",
    "def DS(obj, label=None):\n",
    "    D(obj, label, c=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26136ca-dd13-48d6-a6d5-b6c1106df5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc6dc3d25994ce5bd102ebaa17cf9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "model init: GPU memory used: 7813 MB.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    "    use_cache=True,\n",
    "    # attn_implementation='flash_attention_2',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device', device)\n",
    "\n",
    "check_gpu('model init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37365508-011a-47db-96af-2617ad2f759e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_candidates = 16\n",
    "max_new_tokens = 3\n",
    "batch_size = 8\n",
    "p_falloff = 0.5 # UNIMPLEMENTED\n",
    "prune_similar_sequences = True # UNIMPLEMENTED\n",
    "prune_similar_branches = True # UNIMPLEMENTED\n",
    "prune_similar_embeddings = True # UNIMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a537c32-7c28-449a-b82a-37da1a247416",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  1556,  5972,  2078,   287,   310,\n",
       "         11203, 29973, 29871, 32007, 32001,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates init: GPU memory used: 7843 MB.\n"
     ]
    }
   ],
   "source": [
    "def init_candidates(text: str):\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    max_total_tokens = inputs.input_ids.shape[1] + max_new_tokens\n",
    "\n",
    "    # (max_candidates, max_total_tokens)\n",
    "    candidates = torch.zeros((max_candidates, max_total_tokens), dtype=torch.long, device=device)\n",
    "    # (max_candidates, max_total_tokens)\n",
    "    candidate_masks = torch.zeros((max_candidates, max_total_tokens), dtype=torch.bool, device=device)\n",
    "    # (max_candidates)\n",
    "    candidate_parents = torch.zeros((max_candidates), dtype=torch.long, device=device)\n",
    "    # (max_candidates)\n",
    "    candidate_logprobs = torch.zeros((max_candidates), dtype=torch.float32, device=device)\n",
    "\n",
    "    candidates[0, :inputs.input_ids.shape[1]] = inputs.input_ids\n",
    "    candidate_masks[0, :inputs.input_ids.shape[1]] = inputs.attention_mask\n",
    "    candidate_parents[0] = 0\n",
    "    candidate_logprobs[0] = 0.0\n",
    "\n",
    "    return candidates, candidate_masks, candidate_parents, candidate_logprobs\n",
    "\n",
    "candidates, candidate_masks, candidate_parents, candidate_logprobs = init_candidates('What is the most popular breed of dog?')\n",
    "D(candidates)\n",
    "D(candidate_masks)\n",
    "D(candidate_parents)\n",
    "D(candidate_logprobs)\n",
    "\n",
    "check_gpu('candidates init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a09268-495a-4b87-bd59-b31bcb374caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test addl inputs added: GPU memory used: 7843 MB.\n"
     ]
    }
   ],
   "source": [
    "# For testing batch inputs\n",
    "inputs2 = tokenizer(\"<|user|>\\n{} <|end|>\\n<|assistant|>\".format('What is the most popular breed of cat?'), return_tensors='pt')\n",
    "candidates[11, :inputs2.input_ids.shape[1]] = inputs2.input_ids\n",
    "candidate_masks[11, :inputs2.input_ids.shape[1]] = inputs2.attention_mask\n",
    "candidate_parents[11] = 0\n",
    "candidate_logprobs[11] = -1.3\n",
    "\n",
    "check_gpu('test addl inputs added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0159a1d-c1fd-48ce-826a-e85849e3d78a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[32000, 32000, 32000, 32000,     1,  1714,   319],\n",
       "        [32000,     1,  1714,   350,   607,   338,  5520],\n",
       "        [    1,  1714,   315,   607,   338,  1584,  5520]]), 'attention_mask': tensor([[0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_be = tokenizer([\"String A\", \"String B which is longer\", \"String C which is even longer\"], return_tensors=\"pt\", padding=True)\n",
    "test_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d584923-06bc-41a6-8ccc-e909108593a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|><|endoftext|><s> String A',\n",
       " '<|endoftext|><s> String B which is longer',\n",
       " '<s> String C which is even longer']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(test_be.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fdc2ad3-30dd-4f3a-9f7c-32447b083181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 8165 MB.\n",
      "torch.Size([8, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  1556,  5972,  2078,   287,   310,\n",
       "         11203, 29973, 29871, 32007, 32001,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch views made: GPU memory used: 8165 MB.\n",
      "torch.Size([8, 18, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8125,  1.3438, -0.4473,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 4.2812,  9.6875, 10.1250,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 6.0625,  2.9844,  3.8281,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 1.5859, -1.2031, -3.5625,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.0703,  0.7109, -5.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 3.5938, -3.8750, -3.3281,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch forward run: GPU memory used: 8165 MB.\n",
      "batch outputs deleted: GPU memory used: 8165 MB.\n",
      "torch.Size([8, 18, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8125,  1.3438, -0.4473,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 4.2812,  9.6875, 10.1250,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 6.0625,  2.9844,  3.8281,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 1.5859, -1.2031, -3.5625,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.0703,  0.7109, -5.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 3.5938, -3.8750, -3.3281,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.2031, -0.1865, -1.1719,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all batches run: GPU memory used: 8165 MB.\n"
     ]
    }
   ],
   "source": [
    "def infer(candidates, candidate_masks, candidate_parents, candidate_logprobs):\n",
    "    with torch.inference_mode():\n",
    "        batches = (max_candidates + batch_size - 1) // batch_size  # Round up to nearest whole number of batches\n",
    "\n",
    "        check_gpu('infer start')\n",
    "        for i in range(0, batches, 1):\n",
    "            batch_candidates = candidates[i * batch_size:(i + 1) * batch_size]\n",
    "            D(batch_candidates)\n",
    "            batch_candidate_masks = candidate_masks[i * batch_size:(i + 1) * batch_size]\n",
    "            D(batch_candidate_masks)\n",
    "\n",
    "            check_gpu('batch views made')\n",
    "\n",
    "            batch_outputs = model(input_ids=batch_candidates, attention_mask=batch_candidate_masks)\n",
    "            D(batch_outputs.logits)\n",
    "\n",
    "            # Possibly turn off caching to save memory here?\n",
    "            check_gpu('batch forward run')\n",
    "\n",
    "            # del batch_outputs\n",
    "\n",
    "            check_gpu('batch outputs deleted')\n",
    "            break\n",
    "            \n",
    "        return batch_outputs\n",
    "\n",
    "logits = infer(candidates, candidate_masks, candidate_parents, candidate_logprobs).logits\n",
    "D(logits)\n",
    "\n",
    "check_gpu('all batches run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca8be196-eac7-459a-bcf9-64fe0979ace4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9975e-01, 9.6088e-05, 8.4797e-05,  ..., 9.9887e-20, 5.6914e-20,\n",
       "         3.2429e-20],\n",
       "        [3.3339e-02, 1.7845e-02, 8.1702e-03,  ..., 4.3864e-09, 3.6364e-09,\n",
       "         3.3110e-09],\n",
       "        [3.3339e-02, 1.7845e-02, 8.1702e-03,  ..., 4.3864e-09, 3.6364e-09,\n",
       "         3.3110e-09],\n",
       "        ...,\n",
       "        [3.3339e-02, 1.7845e-02, 8.1702e-03,  ..., 4.3864e-09, 3.6364e-09,\n",
       "         3.3110e-09],\n",
       "        [3.3339e-02, 1.7845e-02, 8.1702e-03,  ..., 4.3864e-09, 3.6364e-09,\n",
       "         3.3110e-09],\n",
       "        [3.3339e-02, 1.7845e-02, 8.1702e-03,  ..., 4.3864e-09, 3.6364e-09,\n",
       "         3.3110e-09]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9998, 0.9998, 0.9999,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.0333, 0.0512, 0.0594,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.0333, 0.0512, 0.0594,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.0333, 0.0512, 0.0594,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.0333, 0.0512, 0.0594,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.0333, 0.0512, 0.0594,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actually, no attention mask is needed -- all candidates will always be the same number of tokens (having started from the same\n",
    "# base and with the same number of generations), so all we have to do is feed a view of the candidates tensor with just valid tokens\n",
    "# into the model). Separately keep track of length of candidate sequences.\n",
    "\n",
    "# def top_p_tokens(logits, top_p=0.9):\n",
    "#     \"\"\"logits of shape (batch_size, curr_seq_len, vocab_size)\"\"\"\n",
    "#     with torch.inference_mode():\n",
    "last_tok_logits = logits[:, -1, :]\n",
    "\n",
    "sorted_logits, sorted_indices = torch.sort(last_tok_logits, descending=True, dim=-1)\n",
    "sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "D(sorted_probs)\n",
    "cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "D(cum_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ef51c88-e3e1-4fe3-94fb-753f582b6e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "keep_indices = cum_probs < 0.9\n",
    "\n",
    "# Keep the last element that went over top_p\n",
    "keep_indices[:, 1:] = keep_indices[:, :-1].clone() # Is this inefficient?\n",
    "keep_indices[:, 0] = 1  # Always keep the first element\n",
    "\n",
    "D(keep_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5b48ba-5d74-453b-98d3-e5b7f185fc10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([29871, 24278, 26785,  ..., 15108, 15268, 16121], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9975e-01, 3.3339e-02, 1.7845e-02,  ..., 1.4587e-05, 1.4587e-05,\n",
       "        1.4587e-05], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_toks = sorted_indices[keep_indices]\n",
    "keep_probs = sorted_probs[keep_indices]\n",
    "\n",
    "D(keep_toks)\n",
    "D(keep_probs)\n",
    "\n",
    "# top_p_tokens(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44a5a01d-1ebe-4437-88ae-d0626bb2dcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D(candidates.index_select(0, keep_indices.nonzero()[:, 0])) # COMPONENT A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c78a6b8d-b1cc-4119-9ca0-18011e9869e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([29871, 24278, 26785,  ..., 15108, 15268, 16121], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D(sorted_indices[keep_indices]) # I think this is COMPONENT B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0d7981f-cd53-4285-a8d4-2ef9ed501e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9975e-01, 3.3339e-02, 1.7845e-02,  ..., 1.4587e-05, 1.4587e-05,\n",
       "        1.4587e-05], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D(sorted_probs[keep_indices]) # I think this is COMPONENT C, still needs to be ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88c98df2-ffd2-422e-822f-625df356c415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d45d2f9ebee45fea69f2ea1cb270862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the highest mountain?\n",
      "\n",
      "input_ids\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s><|user|> What is the highest mountain? <|end|><|assistant|>']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 203\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m output_logits, output_embeddings\n\u001b[1;32m    201\u001b[0m it \u001b[38;5;241m=\u001b[39m InferenceTensor()\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it\u001b[38;5;241m.\u001b[39mcandidates_generator(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the highest mountain?\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[49], line 56\u001b[0m, in \u001b[0;36mInferenceTensor.candidates_generator\u001b[0;34m(self, top_p, max_beams, prompt)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcandidates_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m, top_p: \u001b[38;5;28mfloat\u001b[39m, max_beams: \u001b[38;5;28mint\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[0;32m---> 56\u001b[0m     candidates, candidate_logprobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m level_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_new_tokens):\n\u001b[1;32m     58\u001b[0m         logits, embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer(candidates[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_candidates, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], candidate_logprobs[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_candidates, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "Cell \u001b[0;32mIn[49], line 85\u001b[0m, in \u001b[0;36mInferenceTensor._init_candidates\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     82\u001b[0m D(inputs\u001b[38;5;241m.\u001b[39minput_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(inputs\u001b[38;5;241m.\u001b[39minput_ids))\n\u001b[0;32m---> 85\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m candidate_logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidates, candidate_logprobs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pynvml import *\n",
    "\n",
    "def check_gpu(step):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"{step}: GPU memory used: {info.used // 1024**2} MB.\")\n",
    "    \n",
    "def D(obj, label=None, c=True):\n",
    "    print()\n",
    "    if label:\n",
    "        print(label)\n",
    "        \n",
    "    if isinstance(obj, tuple):\n",
    "        print(len(obj))\n",
    "    elif isinstance(obj, torch.Tensor) or isinstance(obj, np.ndarray):\n",
    "        print(obj.shape)\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "    else:\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "            \n",
    "def DS(obj, label=None):\n",
    "    D(obj, label, c=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class InferenceTensor:\n",
    "    def __init__(self):\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map='auto',\n",
    "            trust_remote_code=True,\n",
    "            use_cache=True,\n",
    "            # attn_implementation='flash_attention_2',\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.max_candidates = 20\n",
    "        self.max_new_tokens = 100\n",
    "        self.batch_size = 8\n",
    "        self.p_falloff = 0.5 # UNIMPLEMENTED\n",
    "        self.prune_similar_sequences = True # UNIMPLEMENTED\n",
    "        self.prune_similar_branches = True # UNIMPLEMENTED\n",
    "        self.prune_similar_embeddings = True # UNIMPLEMENTED\n",
    "        \n",
    "    def candidates_generator(self, top_p: float, max_beams: int, prompt: str):\n",
    "        print(prompt)\n",
    "        candidates, candidate_logprobs = self._init_candidates(prompt)\n",
    "        for level_idx in range(self.max_new_tokens):\n",
    "            logits, embeddings = self._infer(candidates[:self.max_candidates, ...], candidate_logprobs[:self.max_candidates, ...])\n",
    "        \n",
    "            if candidates.shape[0] > max_beams:\n",
    "                candidates, candidate_parents, candidate_logprobs = self._k_means(embeddings, candidates, candidate_logprobs, max_beams)\n",
    "                yield self._format_candidates('k_means', f\"{level_idx}-k\", candidates, candidate_parents, candidate_logprobs)\n",
    "\n",
    "            candidates, candidate_parents, candidate_logprobs = self._top_p(logits, candidates, candidate_logprobs, top_p)\n",
    "            yield self._format_candidates('top_p', f\"{level_idx}-p\", candidates, candidate_parents, candidate_logprobs)\n",
    "\n",
    "        yield f\"event: level\\nid: END\\ndata: []\\n\\n\"\n",
    "\n",
    "    def _format_candidates(self, event: str, idx: int, candidates, candidate_parents, candidate_logprobs):\n",
    "        D(candidate_parents, 'candidate_parents')\n",
    "        candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "        candidate_probs = candidate_logprobs.exp()\n",
    "        candidate_dicts = []\n",
    "        for i in range(len(candidate_texts)):\n",
    "            candidate_dicts.append({'content': candidate_texts[i], 'parents': candidate_parents[i], 'prob': candidate_probs[i].item()})\n",
    "        data = json.dumps(candidate_dicts)\n",
    "        return f\"event: {event}\\nid: {idx}\\ndata: {data}\\n\\n\"\n",
    "        \n",
    "    def _init_candidates(self, text: str):\n",
    "        prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "        inputs = tokenizer(prompt, return_tensors='pt')\n",
    "        D(inputs.input_ids, 'input_ids')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids))\n",
    "\n",
    "        candidates = inputs.input_ids.to(device)\n",
    "        candidate_logprobs = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "\n",
    "        return candidates, candidate_logprobs\n",
    "\n",
    "    def _k_means(self, embeddings, candidates, candidate_logprobs, max_beams):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        # === CPU ===\n",
    "        embeddings_np = embeddings.float().numpy(force=True)\n",
    "        D(embeddings_np, 'embeddings_np')\n",
    "        k_means = KMeans(n_clusters=min(2, embeddings_np.shape[0]), random_state=0, n_init=\"auto\")\n",
    "        k_mean_space = k_means.fit_transform(embeddings_np)\n",
    "        D(k_mean_space, 'k_mean_space')\n",
    "        k_mean_clusters = k_means.predict(embeddings_np)\n",
    "        D(k_mean_clusters, 'k_mean_clusters')\n",
    "        k_mean_logprob_mass = np.bincount(k_mean_clusters, weights=candidate_logprobs.cpu())\n",
    "        D(k_mean_logprob_mass, 'k_mean_logprob_mass')\n",
    "        closest = np.argmin(k_mean_space, axis=0)\n",
    "        D(closest, 'closest')\n",
    "        # === END CPU ===\n",
    "        \n",
    "        new_candidates = candidates.index_select(0, torch.from_numpy(closest).to(self.device))\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_parents = [torch.nonzero(torch.from_numpy(k_mean_clusters).to(device) == i).squeeze(-1).tolist() for i in range(new_candidates.shape[0])]\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "        new_candidate_logprobs = torch.from_numpy(k_mean_logprob_mass).to(self.device)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "        \n",
    "        return new_candidates, new_candidate_parents, new_candidate_logprobs\n",
    "        \n",
    "    def _top_p(self, logits, candidates, candidate_logprobs, top_p):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        \n",
    "        last_tok_logits = logits[:, -1, :]\n",
    "        D(last_tok_logits, 'last_tok_logits')\n",
    "\n",
    "        sorted_logits, sorted_indices = torch.sort(last_tok_logits, descending=True, dim=-1)\n",
    "        DS(sorted_logits, 'sorted_logits')\n",
    "        DS(sorted_indices, 'sorted_indices')\n",
    "        sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "        D(sorted_probs, 'sorted_probs')\n",
    "        display(sorted_probs.sum(dim=1))\n",
    "        cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        D(cum_probs, 'cum_probs')\n",
    "\n",
    "        # Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "        keep_indices = cum_probs < top_p\n",
    "\n",
    "        # Keep the last element that went over top_p\n",
    "        keep_indices[:, 1:] = keep_indices[:, :-1].clone() # Is this inefficient?\n",
    "        keep_indices[:, 0] = 1  # Always keep the first element\n",
    "        D(keep_indices, 'keep_indices')\n",
    "\n",
    "        new_candidate_parents = keep_indices.nonzero()[:, 0]\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "\n",
    "        # OPTIM: Potential optimization -- have a fixed tensor of size (max_candidates, max_tokens) and copy this into that (batch-aware).\n",
    "        # OPTIM: consider which of these operations can be done in-place to prevent new allocations?\n",
    "        carryover_candidates = candidates.index_select(0, new_candidate_parents)\n",
    "        D(carryover_candidates, 'carryover_candidates')\n",
    "\n",
    "        # Similar code could be used to trace entire origin of sequence. For now since server just traces parent of the preceding generation, not needed\n",
    "        # carryover_candidate_parents = candidate_parents.index_select(0, carryover_candidate_indices)  # Not strictly necessary since 1d\n",
    "        # D(carryover_candidate_parents, 'carryover_candidate_parents')\n",
    "\n",
    "        carryover_candidate_logprobs = candidate_logprobs.index_select(0, new_candidate_parents)  # Not strictly necessary since 1d\n",
    "        D(carryover_candidate_logprobs, 'carryover_candidate_logprobs')\n",
    "\n",
    "        new_candidate_toks = sorted_indices[keep_indices].unsqueeze(1)\n",
    "        D(new_candidate_toks, 'new_candidate_toks')\n",
    "        new_candidate_tok_logprobs = sorted_probs[keep_indices].log()\n",
    "        D(new_candidate_tok_logprobs, 'new_candidate_tok_logprobs')\n",
    "\n",
    "        new_candidates = torch.cat([carryover_candidates, new_candidate_toks], dim=1)\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_logprobs = carryover_candidate_logprobs.add_(new_candidate_tok_logprobs)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "\n",
    "        return new_candidates, new_candidate_parents.unsqueeze(-1).tolist(), new_candidate_logprobs\n",
    "\n",
    "\n",
    "    def _infer(self, candidates, candidate_logprobs):\n",
    "        with torch.inference_mode():\n",
    "            num_batches = (candidates.shape[0] + batch_size - 1) // batch_size  # Round up to nearest whole number of batches\n",
    "            print('\\nnum_batches', num_batches)\n",
    "\n",
    "            new_candidates_list = []\n",
    "            new_candidate_parents_list = []\n",
    "            new_candidate_logprobs_list = []\n",
    "\n",
    "            check_gpu('infer start')\n",
    "            output_logits_list = []\n",
    "            output_embeddings_list = []\n",
    "            for i in range(0, num_batches, 1):\n",
    "                batch_candidates = candidates[i * batch_size:(i + 1) * batch_size]\n",
    "                DS(batch_candidates, 'batch_candidates')\n",
    "                batch_candidate_logprobs = candidate_logprobs[i * batch_size:(i + 1) * batch_size]\n",
    "                DS(batch_candidate_logprobs, 'batch_candidate_logprobs')\n",
    "\n",
    "                batch_outputs = model(input_ids=batch_candidates, output_hidden_states=True)\n",
    "                DS(batch_outputs.logits, 'batch_logits')\n",
    "                DS(batch_outputs.hidden_states[-1], 'hidden_states[-1]')\n",
    "\n",
    "                output_logits_list.append(batch_outputs.logits)\n",
    "                output_embeddings_list.append(batch_outputs.hidden_states[-1][:,-1,:])\n",
    "                check_gpu('infer - after batch run')\n",
    "\n",
    "            output_logits = torch.cat(output_logits_list, dim=0)\n",
    "            output_embeddings = torch.cat(output_embeddings_list, dim=0)\n",
    "            \n",
    "            return output_logits, output_embeddings\n",
    "\n",
    "            \n",
    "\n",
    "it = InferenceTensor()\n",
    "\n",
    "for x in it.candidates_generator(0.9, 2, 'What is the highest mountain?'):\n",
    "    print(x)\n",
    "    print()\n",
    "    print('====================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc00638-8294-46be-af73-b05b57ba0a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17b31d3-df35-4577-b994-c60f368e706c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D(keep_indices.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa096391-6451-4e91-970d-c84f2b9d812a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1000, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_indices.flatten()[0:1000].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9373bb1-c635-4554-b24a-6b7ed65022d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[29871,   259, 29892,  ..., 22715, 25923, 24336],\n",
       "        [24278, 26785,  7066,  ..., 12645, 15084,  6941],\n",
       "        [24278, 26785,  7066,  ..., 12645, 15084,  6941],\n",
       "        ...,\n",
       "        [24278, 26785,  7066,  ..., 12645, 15084,  6941],\n",
       "        [24278, 26785,  7066,  ..., 12645, 15084,  6941],\n",
       "        [24278, 26785,  7066,  ..., 12645, 15084,  6941]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cf60c92-adde-4f6f-aadc-d8e342b6fe2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(90805, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([    1, 12972, 12972, 12972, 12972, 12972, 12972, 12972],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(keep_indices)\n",
    "print(keep_indices.sum())\n",
    "keep_indices.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef755d15-0de1-455b-b3bb-9015e349f440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90805])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([29871, 24278, 26785,  ..., 15108, 15268, 16121], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x = sorted_indices[keep_indices]\n",
    "D(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdb67901-86d1-45f1-ad05-8acd3df68685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2994, -0.1878,  1.9159,  0.6902, -2.3217],\n",
       "        [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "        [-1.3952,  0.4751, -0.8137,  0.9242, -0.2473],\n",
       "        [-1.4154,  0.9874, -1.4878,  0.5867,  0.1583],\n",
       "        [ 0.1102, -0.8188,  0.6328, -1.9169,  1.1711],\n",
       "        [ 0.0975,  0.9634,  0.8403, -1.2537,  0.9868],\n",
       "        [-0.4947, -1.2830,  0.9552,  1.2836, -0.6659],\n",
       "        [ 0.5651,  0.2877, -0.0334, -1.0619, -0.1144]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-0.2994, -0.1878,  1.9159,  0.6902, -2.3217],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]],\n",
       "\n",
       "        [[-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047],\n",
       "         [-1.1964,  0.1970, -1.1773,  0.1136,  1.1047]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(8, 5)\n",
    "D(a)\n",
    "b = torch.ones(8, 5, dtype=torch.long)\n",
    "b[0][1] = 0\n",
    "D(b)\n",
    "c = a[b]\n",
    "D(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6376f682-087c-44a7-82ef-704bbc3a39ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1],\n",
       "        [1, 2, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[10, 30, 20], [60, 40, 50]])\n",
    "sorted_idx = torch.argsort(t, dim=1)\n",
    "D(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11ec5c13-edae-4d85-a77b-315b5c4b1770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(35).reshape(5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81d10805-5386-4167-ae44-6b56f5277b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b = x > 20\n",
    "D(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5ef2457-aa59-41fb-9f96-3a25ac98a885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9a38859-265e-4525-89dd-c032dbf4178b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ebfdbb3-bd81-40b2-8abb-7d1528e2529f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 22, 23, 24, 25, 26, 27],\n",
       "       [28, 29, 30, 31, 32, 33, 34]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[b[:, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eedfded-80cb-4640-9b9e-44853573540e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e22bcc6e-536a-412f-ad0b-035e88632265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(5, 0), dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, b[2, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130162f5-e83d-4f99-addf-2573e4946417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17c3bba1-ed50-4c27-8d71-8912665bd666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def candidates_generator(text: str):\n",
    "#     print(text)\n",
    "#     candidates, candidate_masks, candidate_parents, candidate_logprobs = _init_candidates(text)\n",
    "\n",
    "#     return candidates, candidate_masks, candidate_parents, candidate_logprobs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f485248f-9354-4690-b014-611989befd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36ab64d4c9d4cd3aedfc35e700daf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the highest mountain?\n",
      "['<s><|user|> What is the highest mountain? <|end|><|assistant|>']\n",
      "\n",
      "num_batches 1\n",
      "event: level\n",
      "id: 1\n",
      "data: [{\"content\": \"The\", \"parent\": 0, \"prob\": -0.0789911225438118}, {\"content\": \"As\", \"parent\": 0, \"prob\": -2.578990936279297}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 1\n",
      "event: level\n",
      "id: 1\n",
      "data: [{\"content\": \"highest\", \"parent\": 0, \"prob\": -0.07979819923639297}, {\"content\": \"of\", \"parent\": 1, \"prob\": -2.578991651535034}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 1\n",
      "event: level\n",
      "id: 2\n",
      "data: [{\"content\": \"mountain\", \"parent\": 0, \"prob\": -0.079963319003582}, {\"content\": \"my\", \"parent\": 1, \"prob\": -2.6227312088012695}, {\"content\": \"current\", \"parent\": 1, \"prob\": -5.8727312088012695}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 1\n",
      "event: level\n",
      "id: 8\n",
      "data: [{\"content\": \"on\", \"parent\": 0, \"prob\": -0.3498345613479614}, {\"content\": \"in\", \"parent\": 0, \"prob\": -2.099834442138672}, {\"content\": \"above\", \"parent\": 0, \"prob\": -2.349834442138672}, {\"content\": \"last\", \"parent\": 1, \"prob\": -3.1989080905914307}, {\"content\": \"knowledge\", \"parent\": 1, \"prob\": -3.4489080905914307}, {\"content\": \"knowledge\", \"parent\": 2, \"prob\": -6.348952770233154}, {\"content\": \"data\", \"parent\": 2, \"prob\": -7.223952770233154}, {\"content\": \"records\", \"parent\": 2, \"prob\": -8.598953247070312}, {\"content\": \"ge\", \"parent\": 2, \"prob\": -9.723953247070312}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 2\n",
      "event: level\n",
      "id: 11\n",
      "data: [{\"content\": \"Earth\", \"parent\": 0, \"prob\": -0.3498673439025879}, {\"content\": \"terms\", \"parent\": 1, \"prob\": -2.2804079055786133}, {\"content\": \"the\", \"parent\": 1, \"prob\": -3.9054081439971924}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -2.3499860763549805}, {\"content\": \"update\", \"parent\": 3, \"prob\": -3.2131288051605225}, {\"content\": \"cut\", \"parent\": 4, \"prob\": -3.4495387077331543}, {\"content\": \",\", \"parent\": 5, \"prob\": -6.378312110900879}, {\"content\": \",\", \"parent\": 6, \"prob\": -7.230485439300537}, {\"content\": \",\", \"parent\": 7, \"prob\": -8.679941177368164}, {\"content\": \"and\", \"parent\": 7, \"prob\": -11.179941177368164}, {\"content\": \"ological\", \"parent\": 0, \"prob\": -10.308858871459961}, {\"content\": \"ographical\", \"parent\": 0, \"prob\": -10.558858871459961}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 2\n",
      "event: level\n",
      "id: 29\n",
      "data: [{\"content\": \",\", \"parent\": 0, \"prob\": -0.36185216903686523}, {\"content\": \"of\", \"parent\": 1, \"prob\": -2.2804079055786133}, {\"content\": \"world\", \"parent\": 2, \"prob\": -3.905439853668213}, {\"content\": \"level\", \"parent\": 3, \"prob\": -2.3499863147735596}, {\"content\": \"in\", \"parent\": 4, \"prob\": -3.216306686401367}, {\"content\": \"off\", \"parent\": 5, \"prob\": -3.4498002529144287}, {\"content\": \"the\", \"parent\": 6, \"prob\": -6.383649826049805}, {\"content\": \"the\", \"parent\": 7, \"prob\": -7.2466583251953125}, {\"content\": \"the\", \"parent\": 0, \"prob\": -8.696099281311035}, {\"content\": \"data\", \"parent\": 1, \"prob\": -12.504639625549316}, {\"content\": \"measurements\", \"parent\": 1, \"prob\": -12.629639625549316}, {\"content\": \"knowledge\", \"parent\": 1, \"prob\": -13.254639625549316}, {\"content\": \"understanding\", \"parent\": 1, \"prob\": -13.629639625549316}, {\"content\": \"ge\", \"parent\": 1, \"prob\": -13.754639625549316}, {\"content\": \"available\", \"parent\": 1, \"prob\": -14.254639625549316}, {\"content\": \"considering\", \"parent\": 1, \"prob\": -14.254639625549316}, {\"content\": \"known\", \"parent\": 1, \"prob\": -14.754639625549316}, {\"content\": \"information\", \"parent\": 1, \"prob\": -14.879639625549316}, {\"content\": \"based\", \"parent\": 1, \"prob\": -15.879639625549316}, {\"content\": \"scientific\", \"parent\": 1, \"prob\": -15.879639625549316}, {\"content\": \"understand\", \"parent\": 1, \"prob\": -16.004638671875}, {\"content\": \"knowledge\", \"parent\": 2, \"prob\": -11.033985137939453}, {\"content\": \"understanding\", \"parent\": 2, \"prob\": -11.783985137939453}, {\"content\": \"records\", \"parent\": 2, \"prob\": -12.533985137939453}, {\"content\": \"data\", \"parent\": 2, \"prob\": -12.783985137939453}, {\"content\": \"cons\", \"parent\": 2, \"prob\": -13.408985137939453}, {\"content\": \"and\", \"parent\": 2, \"prob\": -13.908985137939453}, {\"content\": \"knowledge\", \"parent\": 3, \"prob\": -10.81493854522705}, {\"content\": \"data\", \"parent\": 3, \"prob\": -12.56493854522705}, {\"content\": \"records\", \"parent\": 3, \"prob\": -13.31493854522705}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 77\n",
      "data: [{\"content\": \"as\", \"parent\": 0, \"prob\": -1.4413341283798218}, {\"content\": \"based\", \"parent\": 0, \"prob\": -1.4413341283798218}, {\"content\": \"in\", \"parent\": 0, \"prob\": -1.6913341283798218}, {\"content\": \"measured\", \"parent\": 0, \"prob\": -3.9413340091705322}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -3.1643893718719482}, {\"content\": \"height\", \"parent\": 1, \"prob\": -3.9143893718719482}, {\"content\": \"peak\", \"parent\": 1, \"prob\": -4.039389610290527}, {\"content\": \"above\", \"parent\": 1, \"prob\": -5.289389610290527}, {\"content\": \"sum\", \"parent\": 1, \"prob\": -5.789389610290527}, {\"content\": \"Earth\", \"parent\": 1, \"prob\": -5.789389610290527}, {\"content\": \"its\", \"parent\": 1, \"prob\": -5.914389610290527}, {\"content\": \"mass\", \"parent\": 1, \"prob\": -6.289389610290527}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -6.789389610290527}, {\"content\": \"global\", \"parent\": 1, \"prob\": -6.789389610290527}, {\"content\": \"official\", \"parent\": 1, \"prob\": -7.164389610290527}, {\"content\": \",\", \"parent\": 2, \"prob\": -4.177634239196777}, {\"content\": \"is\", \"parent\": 2, \"prob\": -5.927634239196777}, {\"content\": \"when\", \"parent\": 2, \"prob\": -6.427634239196777}, {\"content\": \"is\", \"parent\": 3, \"prob\": -2.3501737117767334}, {\"content\": \"\", \"parent\": 4, \"prob\": -3.2305867671966553}, {\"content\": \"in\", \"parent\": 5, \"prob\": -3.457406997680664}, {\"content\": \"highest\", \"parent\": 6, \"prob\": -6.3840179443359375}, {\"content\": \"highest\", \"parent\": 7, \"prob\": -7.2469916343688965}, {\"content\": \"highest\", \"parent\": 0, \"prob\": -8.696488380432129}, {\"content\": \",\", \"parent\": 1, \"prob\": -12.577061653137207}, {\"content\": \"available\", \"parent\": 1, \"prob\": -15.577061653137207}, {\"content\": \",\", \"parent\": 2, \"prob\": -12.631479263305664}, {\"content\": \",\", \"parent\": 3, \"prob\": -13.659238815307617}, {\"content\": \"up\", \"parent\": 3, \"prob\": -14.409238815307617}, {\"content\": \",\", \"parent\": 4, \"prob\": -13.632384300231934}, {\"content\": \"ological\", \"parent\": 5, \"prob\": -14.3663969039917}, {\"content\": \"ographical\", \"parent\": 5, \"prob\": -14.6163969039917}, {\"content\": \"data\", \"parent\": 6, \"prob\": -14.421874046325684}, {\"content\": \"information\", \"parent\": 6, \"prob\": -16.546875}, {\"content\": \"knowledge\", \"parent\": 6, \"prob\": -17.421875}, {\"content\": \"Earth\", \"parent\": 7, \"prob\": -14.947954177856445}, {\"content\": \"the\", \"parent\": 7, \"prob\": -16.072954177856445}, {\"content\": \"mountains\", \"parent\": 7, \"prob\": -16.572954177856445}, {\"content\": \"all\", \"parent\": 7, \"prob\": -16.697954177856445}, {\"content\": \"only\", \"parent\": 7, \"prob\": -18.322954177856445}, {\"content\": \"known\", \"parent\": 7, \"prob\": -18.447954177856445}, {\"content\": \"permanent\", \"parent\": 7, \"prob\": -18.447954177856445}, {\"content\": \"mountain\", \"parent\": 7, \"prob\": -18.697954177856445}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -18.822954177856445}, {\"content\": \"active\", \"parent\": 7, \"prob\": -18.947954177856445}, {\"content\": \"ge\", \"parent\": 7, \"prob\": -19.447954177856445}, {\"content\": \"height\", \"parent\": 7, \"prob\": -19.572954177856445}, {\"content\": \"natural\", \"parent\": 7, \"prob\": -19.572954177856445}, {\"content\": \"perman\", \"parent\": 7, \"prob\": -19.572954177856445}, {\"content\": \"earth\", \"parent\": 7, \"prob\": -19.947954177856445}, {\"content\": \"recognized\", \"parent\": 7, \"prob\": -20.197954177856445}, {\"content\": \"well\", \"parent\": 7, \"prob\": -20.322954177856445}, {\"content\": \"peak\", \"parent\": 7, \"prob\": -20.322954177856445}, {\"content\": \"non\", \"parent\": 7, \"prob\": -20.697954177856445}, {\"content\": \"above\", \"parent\": 7, \"prob\": -20.697954177856445}, {\"content\": \"data\", \"parent\": 0, \"prob\": -16.057802200317383}, {\"content\": \"ge\", \"parent\": 0, \"prob\": -16.307802200317383}, {\"content\": \"measurements\", \"parent\": 0, \"prob\": -16.307802200317383}, {\"content\": \"mountains\", \"parent\": 0, \"prob\": -16.682802200317383}, {\"content\": \"pe\", \"parent\": 0, \"prob\": -18.307802200317383}, {\"content\": \"information\", \"parent\": 0, \"prob\": -18.557802200317383}, {\"content\": \"mountain\", \"parent\": 0, \"prob\": -18.557802200317383}, {\"content\": \"height\", \"parent\": 0, \"prob\": -19.057802200317383}, {\"content\": \"to\", \"parent\": 0, \"prob\": -19.557802200317383}, {\"content\": \"land\", \"parent\": 0, \"prob\": -19.682802200317383}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -19.682802200317383}, {\"content\": \"facts\", \"parent\": 0, \"prob\": -19.932802200317383}, {\"content\": \"knowledge\", \"parent\": 0, \"prob\": -20.182802200317383}, {\"content\": \"standards\", \"parent\": 0, \"prob\": -20.182802200317383}, {\"content\": \",\", \"parent\": 1, \"prob\": -15.166950225830078}, {\"content\": \"available\", \"parent\": 1, \"prob\": -16.666950225830078}, {\"content\": \"up\", \"parent\": 1, \"prob\": -17.416950225830078}, {\"content\": \"on\", \"parent\": 2, \"prob\": -15.880056381225586}, {\"content\": \"cons\", \"parent\": 3, \"prob\": -16.689163208007812}, {\"content\": \"measurements\", \"parent\": 3, \"prob\": -17.314163208007812}, {\"content\": \"data\", \"parent\": 3, \"prob\": -18.064163208007812}, {\"content\": \"understanding\", \"parent\": 3, \"prob\": -18.189163208007812}, {\"content\": \"knowledge\", \"parent\": 3, \"prob\": -18.564163208007812}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 54\n",
      "data: [{\"content\": \"measured\", \"parent\": 0, \"prob\": -1.5956541299819946}, {\"content\": \"of\", \"parent\": 0, \"prob\": -3.845654010772705}, {\"content\": \"tradition\", \"parent\": 0, \"prob\": -4.970654010772705}, {\"content\": \"on\", \"parent\": 1, \"prob\": -1.4413490295410156}, {\"content\": \"terms\", \"parent\": 2, \"prob\": -1.6914875507354736}, {\"content\": \"from\", \"parent\": 3, \"prob\": -4.10174560546875}, {\"content\": \"by\", \"parent\": 3, \"prob\": -5.85174560546875}, {\"content\": \"ation\", \"parent\": 4, \"prob\": -3.164400100708008}, {\"content\": \"above\", \"parent\": 5, \"prob\": -3.9215824604034424}, {\"content\": \"elev\", \"parent\": 6, \"prob\": -4.398475170135498}, {\"content\": \"height\", \"parent\": 6, \"prob\": -5.648475170135498}, {\"content\": \"above\", \"parent\": 6, \"prob\": -6.398475646972656}, {\"content\": \"sea\", \"parent\": 7, \"prob\": -5.291145324707031}, {\"content\": \"mit\", \"parent\": 0, \"prob\": -5.789392948150635}, {\"content\": \"'\", \"parent\": 1, \"prob\": -5.7896857261657715}, {\"content\": \"sum\", \"parent\": 2, \"prob\": -6.940174102783203}, {\"content\": \"peak\", \"parent\": 2, \"prob\": -7.440174102783203}, {\"content\": \"height\", \"parent\": 2, \"prob\": -7.815174102783203}, {\"content\": \"Earth\", \"parent\": 2, \"prob\": -7.940174102783203}, {\"content\": \"global\", \"parent\": 2, \"prob\": -9.565174102783203}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -9.690174102783203}, {\"content\": \"above\", \"parent\": 2, \"prob\": -10.065174102783203}, {\"content\": \"mass\", \"parent\": 2, \"prob\": -10.315174102783203}, {\"content\": \"earth\", \"parent\": 2, \"prob\": -10.315174102783203}, {\"content\": \"alt\", \"parent\": 2, \"prob\": -10.440174102783203}, {\"content\": \"top\", \"parent\": 2, \"prob\": -10.565174102783203}, {\"content\": \"is\", \"parent\": 3, \"prob\": -7.050563812255859}, {\"content\": \"height\", \"parent\": 3, \"prob\": -8.05056381225586}, {\"content\": \"and\", \"parent\": 3, \"prob\": -8.67556381225586}, {\"content\": \"above\", \"parent\": 3, \"prob\": -8.67556381225586}, {\"content\": \"if\", \"parent\": 3, \"prob\": -8.80056381225586}, {\"content\": \",\", \"parent\": 3, \"prob\": -10.05056381225586}, {\"content\": \"if\", \"parent\": 3, \"prob\": -10.67556381225586}, {\"content\": \"(\", \"parent\": 3, \"prob\": -10.80056381225586}, {\"content\": \"when\", \"parent\": 3, \"prob\": -10.80056381225586}, {\"content\": \"itude\", \"parent\": 4, \"prob\": -6.7893967628479}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -7.313268184661865}, {\"content\": \"height\", \"parent\": 5, \"prob\": -8.438268661499023}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -9.438268661499023}, {\"content\": \"top\", \"parent\": 5, \"prob\": -9.938268661499023}, {\"content\": \"pe\", \"parent\": 5, \"prob\": -10.313268661499023}, {\"content\": \"alt\", \"parent\": 5, \"prob\": -10.563268661499023}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -10.938268661499023}, {\"content\": \"height\", \"parent\": 6, \"prob\": -7.249536514282227}, {\"content\": \"elev\", \"parent\": 6, \"prob\": -10.124536514282227}, {\"content\": \"when\", \"parent\": 7, \"prob\": -4.503608703613281}, {\"content\": \"measured\", \"parent\": 7, \"prob\": -6.378608703613281}, {\"content\": \"based\", \"parent\": 7, \"prob\": -6.753608703613281}, {\"content\": \"considering\", \"parent\": 7, \"prob\": -7.253608703613281}, {\"content\": \"as\", \"parent\": 7, \"prob\": -7.753608703613281}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -5.927862167358398}, {\"content\": \"measured\", \"parent\": 1, \"prob\": -6.5161919593811035}, {\"content\": \"meas\", \"parent\": 1, \"prob\": -9.266191482543945}, {\"content\": \"Mount\", \"parent\": 2, \"prob\": -2.350292921066284}, {\"content\": \"2\", \"parent\": 3, \"prob\": -3.2305867671966553}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 39\n",
      "data: [{\"content\": \"by\", \"parent\": 0, \"prob\": -1.6442663669586182}, {\"content\": \"from\", \"parent\": 0, \"prob\": -4.644266128540039}, {\"content\": \"my\", \"parent\": 1, \"prob\": -4.179198741912842}, {\"content\": \"current\", \"parent\": 1, \"prob\": -5.679198741912842}, {\"content\": \"now\", \"parent\": 1, \"prob\": -6.679198741912842}, {\"content\": \"our\", \"parent\": 1, \"prob\": -6.804198265075684}, {\"content\": \"ally\", \"parent\": 2, \"prob\": -4.970663070678711}, {\"content\": \"its\", \"parent\": 3, \"prob\": -1.77680242061615}, {\"content\": \"the\", \"parent\": 3, \"prob\": -3.0268023014068604}, {\"content\": \"peak\", \"parent\": 3, \"prob\": -4.651802062988281}, {\"content\": \"of\", \"parent\": 4, \"prob\": -1.6914875507354736}, {\"content\": \"sea\", \"parent\": 5, \"prob\": -4.3084330558776855}, {\"content\": \"its\", \"parent\": 5, \"prob\": -5.808432579040527}, {\"content\": \"its\", \"parent\": 6, \"prob\": -6.042631149291992}, {\"content\": \"the\", \"parent\": 6, \"prob\": -8.417631149291992}, {\"content\": \"peak\", \"parent\": 6, \"prob\": -8.417631149291992}, {\"content\": \"above\", \"parent\": 7, \"prob\": -3.1724603176116943}, {\"content\": \"sea\", \"parent\": 0, \"prob\": -3.92158842086792}, {\"content\": \"ation\", \"parent\": 1, \"prob\": -4.398599147796631}, {\"content\": \"above\", \"parent\": 2, \"prob\": -5.652233600616455}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -6.3984785079956055}, {\"content\": \"level\", \"parent\": 4, \"prob\": -5.291170597076416}, {\"content\": \"height\", \"parent\": 5, \"prob\": -6.51425313949585}, {\"content\": \"above\", \"parent\": 5, \"prob\": -6.76425313949585}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -7.889252662658691}, {\"content\": \"s\", \"parent\": 6, \"prob\": -5.7896857261657715}, {\"content\": \"mit\", \"parent\": 7, \"prob\": -6.9401750564575195}, {\"content\": \"above\", \"parent\": 0, \"prob\": -7.745050430297852}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -9.370050430297852}, {\"content\": \"'\", \"parent\": 0, \"prob\": -10.245050430297852}, {\"content\": \"height\", \"parent\": 0, \"prob\": -10.620050430297852}, {\"content\": \"above\", \"parent\": 1, \"prob\": -7.8173508644104}, {\"content\": \"'\", \"parent\": 2, \"prob\": -8.029622077941895}, {\"content\": \"-\", \"parent\": 2, \"prob\": -10.529622077941895}, {\"content\": \"peak\", \"parent\": 3, \"prob\": -10.417412757873535}, {\"content\": \"sum\", \"parent\": 3, \"prob\": -10.917412757873535}, {\"content\": \"height\", \"parent\": 3, \"prob\": -11.667412757873535}, {\"content\": \"elev\", \"parent\": 3, \"prob\": -11.667412757873535}, {\"content\": \"alt\", \"parent\": 3, \"prob\": -13.417413711547852}, {\"content\": \"top\", \"parent\": 3, \"prob\": -13.667413711547852}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 54\n",
      "data: [{\"content\": \"its\", \"parent\": 0, \"prob\": -1.9372596740722656}, {\"content\": \"the\", \"parent\": 0, \"prob\": -3.5622596740722656}, {\"content\": \"peak\", \"parent\": 0, \"prob\": -4.062259674072266}, {\"content\": \"sea\", \"parent\": 1, \"prob\": -4.715003967285156}, {\"content\": \"its\", \"parent\": 1, \"prob\": -7.465003967285156}, {\"content\": \"knowledge\", \"parent\": 2, \"prob\": -4.761585235595703}, {\"content\": \"last\", \"parent\": 2, \"prob\": -5.011585235595703}, {\"content\": \"measurements\", \"parent\": 3, \"prob\": -5.723343849182129}, {\"content\": \"knowledge\", \"parent\": 3, \"prob\": -9.723343849182129}, {\"content\": \",\", \"parent\": 4, \"prob\": -6.679218292236328}, {\"content\": \"current\", \"parent\": 5, \"prob\": -6.914953231811523}, {\"content\": \"knowledge\", \"parent\": 5, \"prob\": -9.164953231811523}, {\"content\": \"measured\", \"parent\": 6, \"prob\": -5.128613471984863}, {\"content\": \"defined\", \"parent\": 6, \"prob\": -7.378613471984863}, {\"content\": \"recognized\", \"parent\": 6, \"prob\": -8.003613471984863}, {\"content\": \"peak\", \"parent\": 7, \"prob\": -1.8974366188049316}, {\"content\": \"sum\", \"parent\": 7, \"prob\": -4.522436618804932}, {\"content\": \"height\", \"parent\": 7, \"prob\": -5.272436618804932}, {\"content\": \"sum\", \"parent\": 0, \"prob\": -3.831406593322754}, {\"content\": \"peak\", \"parent\": 0, \"prob\": -4.081406593322754}, {\"content\": \"height\", \"parent\": 0, \"prob\": -5.331406593322754}, {\"content\": \"total\", \"parent\": 0, \"prob\": -6.831406593322754}, {\"content\": \"alt\", \"parent\": 0, \"prob\": -6.956406593322754}, {\"content\": \"measurement\", \"parent\": 0, \"prob\": -7.456406593322754}, {\"content\": \"highest\", \"parent\": 0, \"prob\": -7.581406593322754}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -7.581406593322754}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -4.801254749298096}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -7.551254749298096}, {\"content\": \"above\", \"parent\": 1, \"prob\": -7.676254749298096}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -2.636526107788086}, {\"content\": \"height\", \"parent\": 2, \"prob\": -3.011526107788086}, {\"content\": \"peak\", \"parent\": 2, \"prob\": -3.511526107788086}, {\"content\": \"its\", \"parent\": 2, \"prob\": -4.761526107788086}, {\"content\": \"alt\", \"parent\": 2, \"prob\": -4.761526107788086}, {\"content\": \"above\", \"parent\": 2, \"prob\": -5.261526107788086}, {\"content\": \"sum\", \"parent\": 2, \"prob\": -5.886526107788086}, {\"content\": \"mass\", \"parent\": 2, \"prob\": -6.011526107788086}, {\"content\": \"level\", \"parent\": 3, \"prob\": -4.308433532714844}, {\"content\": \"base\", \"parent\": 4, \"prob\": -5.830377101898193}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -6.326883316040039}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -8.076883316040039}, {\"content\": \"height\", \"parent\": 5, \"prob\": -8.701883316040039}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -9.951883316040039}, {\"content\": \"height\", \"parent\": 6, \"prob\": -9.017290115356445}, {\"content\": \"sum\", \"parent\": 6, \"prob\": -9.892290115356445}, {\"content\": \"peak\", \"parent\": 6, \"prob\": -10.267290115356445}, {\"content\": \"alt\", \"parent\": 6, \"prob\": -12.142290115356445}, {\"content\": \"highest\", \"parent\": 6, \"prob\": -12.642290115356445}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -8.70071792602539}, {\"content\": \"above\", \"parent\": 7, \"prob\": -10.20071792602539}, {\"content\": \"height\", \"parent\": 7, \"prob\": -11.32571792602539}, {\"content\": \"sea\", \"parent\": 0, \"prob\": -3.1724658012390137}, {\"content\": \"level\", \"parent\": 1, \"prob\": -3.9215900897979736}, {\"content\": \"above\", \"parent\": 2, \"prob\": -4.4071197509765625}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -5.652247905731201}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 41\n",
      "data: [{\"content\": \"peak\", \"parent\": 0, \"prob\": -2.0586774349212646}, {\"content\": \"sum\", \"parent\": 0, \"prob\": -4.933677673339844}, {\"content\": \"height\", \"parent\": 0, \"prob\": -5.058677673339844}, {\"content\": \"height\", \"parent\": 1, \"prob\": -4.323467254638672}, {\"content\": \"sum\", \"parent\": 1, \"prob\": -5.073467254638672}, {\"content\": \"peak\", \"parent\": 1, \"prob\": -5.198467254638672}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -6.448467254638672}, {\"content\": \"highest\", \"parent\": 1, \"prob\": -7.448467254638672}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -7.448467254638672}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -4.19370698928833}, {\"content\": \"above\", \"parent\": 2, \"prob\": -6.56870698928833}, {\"content\": \"height\", \"parent\": 2, \"prob\": -7.94370698928833}, {\"content\": \"level\", \"parent\": 3, \"prob\": -4.7150044441223145}, {\"content\": \"base\", \"parent\": 4, \"prob\": -7.627735614776611}, {\"content\": \"peak\", \"parent\": 4, \"prob\": -9.377735137939453}, {\"content\": \"cut\", \"parent\": 5, \"prob\": -4.7664361000061035}, {\"content\": \"update\", \"parent\": 6, \"prob\": -5.02022647857666}, {\"content\": \",\", \"parent\": 7, \"prob\": -5.725315570831299}, {\"content\": \",\", \"parent\": 0, \"prob\": -9.728090286254883}, {\"content\": \"is\", \"parent\": 1, \"prob\": -6.6792311668396}, {\"content\": \"knowledge\", \"parent\": 2, \"prob\": -6.987006187438965}, {\"content\": \"measurements\", \"parent\": 2, \"prob\": -10.112006187438965}, {\"content\": \"cut\", \"parent\": 3, \"prob\": -9.183843612670898}, {\"content\": \"by\", \"parent\": 4, \"prob\": -5.907413482666016}, {\"content\": \"from\", \"parent\": 4, \"prob\": -5.907413482666016}, {\"content\": \",\", \"parent\": 4, \"prob\": -7.657413482666016}, {\"content\": \",\", \"parent\": 5, \"prob\": -7.651864051818848}, {\"content\": \"by\", \"parent\": 5, \"prob\": -8.901864051818848}, {\"content\": \",\", \"parent\": 6, \"prob\": -8.07686996459961}, {\"content\": \"by\", \"parent\": 6, \"prob\": -10.82686996459961}, {\"content\": \"'\", \"parent\": 7, \"prob\": -2.538968801498413}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -3.288968801498413}, {\"content\": \"above\", \"parent\": 7, \"prob\": -3.788968801498413}, {\"content\": \"height\", \"parent\": 7, \"prob\": -5.163969039916992}, {\"content\": \"mit\", \"parent\": 0, \"prob\": -4.52243709564209}, {\"content\": \"above\", \"parent\": 1, \"prob\": -5.274694442749023}, {\"content\": \"mit\", \"parent\": 2, \"prob\": -3.831895112991333}, {\"content\": \"'\", \"parent\": 3, \"prob\": -4.738916397094727}, {\"content\": \"reaching\", \"parent\": 3, \"prob\": -5.613916397094727}, {\"content\": \"above\", \"parent\": 3, \"prob\": -5.738916397094727}, {\"content\": \"that\", \"parent\": 3, \"prob\": -7.488916397094727}, {\"content\": \"elev\", \"parent\": 3, \"prob\": -7.488916397094727}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 33\n",
      "data: [{\"content\": \"'\", \"parent\": 0, \"prob\": -2.601608991622925}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -3.726609230041504}, {\"content\": \"above\", \"parent\": 0, \"prob\": -3.851609230041504}, {\"content\": \"height\", \"parent\": 0, \"prob\": -5.601609230041504}, {\"content\": \"mit\", \"parent\": 1, \"prob\": -4.933681488037109}, {\"content\": \"above\", \"parent\": 2, \"prob\": -5.060075759887695}, {\"content\": \"above\", \"parent\": 3, \"prob\": -4.363503456115723}, {\"content\": \"mit\", \"parent\": 4, \"prob\": -5.103218078613281}, {\"content\": \"'\", \"parent\": 5, \"prob\": -5.570906639099121}, {\"content\": \"above\", \"parent\": 5, \"prob\": -6.695906639099121}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -8.445906639099121}, {\"content\": \"reaching\", \"parent\": 5, \"prob\": -8.445906639099121}, {\"content\": \"itude\", \"parent\": 6, \"prob\": -6.448474884033203}, {\"content\": \"peak\", \"parent\": 7, \"prob\": -8.698309898376465}, {\"content\": \"point\", \"parent\": 7, \"prob\": -8.823309898376465}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -8.948309898376465}, {\"content\": \"sum\", \"parent\": 7, \"prob\": -9.073309898376465}, {\"content\": \"alt\", \"parent\": 7, \"prob\": -11.198309898376465}, {\"content\": \"ation\", \"parent\": 0, \"prob\": -7.448482036590576}, {\"content\": \"ation\", \"parent\": 1, \"prob\": -4.193939208984375}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -6.568719387054443}, {\"content\": \"above\", \"parent\": 3, \"prob\": -7.948344707489014}, {\"content\": \",\", \"parent\": 4, \"prob\": -4.715888977050781}, {\"content\": \"on\", \"parent\": 5, \"prob\": -7.7595601081848145}, {\"content\": \"to\", \"parent\": 5, \"prob\": -9.759559631347656}, {\"content\": \"above\", \"parent\": 6, \"prob\": -9.985147476196289}, {\"content\": \"to\", \"parent\": 6, \"prob\": -10.360147476196289}, {\"content\": \",\", \"parent\": 6, \"prob\": -11.985147476196289}, {\"content\": \"off\", \"parent\": 7, \"prob\": -4.767616271972656}, {\"content\": \"in\", \"parent\": 0, \"prob\": -5.099117279052734}, {\"content\": \",\", \"parent\": 0, \"prob\": -7.599117279052734}, {\"content\": \"is\", \"parent\": 1, \"prob\": -5.725315570831299}, {\"content\": \"is\", \"parent\": 2, \"prob\": -9.728090286254883}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -6.679309368133545}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 25\n",
      "data: [{\"content\": \"s\", \"parent\": 0, \"prob\": -2.601609706878662}, {\"content\": \"ation\", \"parent\": 1, \"prob\": -3.7267892360687256}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -3.851616621017456}, {\"content\": \"above\", \"parent\": 3, \"prob\": -5.60614013671875}, {\"content\": \"'\", \"parent\": 4, \"prob\": -4.939277172088623}, {\"content\": \"sea\", \"parent\": 5, \"prob\": -5.060262203216553}, {\"content\": \"sea\", \"parent\": 6, \"prob\": -4.363594055175781}, {\"content\": \"'\", \"parent\": 7, \"prob\": -5.104526042938232}, {\"content\": \"s\", \"parent\": 0, \"prob\": -5.570987701416016}, {\"content\": \"sea\", \"parent\": 1, \"prob\": -6.695943355560303}, {\"content\": \"ation\", \"parent\": 2, \"prob\": -8.446820259094238}, {\"content\": \"above\", \"parent\": 3, \"prob\": -9.113608360290527}, {\"content\": \"closest\", \"parent\": 3, \"prob\": -9.738608360290527}, {\"content\": \"the\", \"parent\": 3, \"prob\": -10.238608360290527}, {\"content\": \"far\", \"parent\": 3, \"prob\": -12.488608360290527}, {\"content\": \"of\", \"parent\": 4, \"prob\": -6.804147243499756}, {\"content\": \"above\", \"parent\": 4, \"prob\": -7.679147243499756}, {\"content\": \"above\", \"parent\": 5, \"prob\": -8.72024917602539}, {\"content\": \"above\", \"parent\": 6, \"prob\": -8.879401206970215}, {\"content\": \"on\", \"parent\": 6, \"prob\": -11.879401206970215}, {\"content\": \"ation\", \"parent\": 7, \"prob\": -8.950207710266113}, {\"content\": \"mit\", \"parent\": 0, \"prob\": -9.07331371307373}, {\"content\": \"itude\", \"parent\": 1, \"prob\": -11.198403358459473}, {\"content\": \"above\", \"parent\": 2, \"prob\": -7.671467304229736}, {\"content\": \"of\", \"parent\": 2, \"prob\": -9.171467781066895}, {\"content\": \"above\", \"parent\": 3, \"prob\": -4.226726531982422}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 25\n",
      "data: [{\"content\": \"height\", \"parent\": 0, \"prob\": -3.07869815826416}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -3.703697919845581}, {\"content\": \"alt\", \"parent\": 0, \"prob\": -5.70369815826416}, {\"content\": \"above\", \"parent\": 1, \"prob\": -3.751798152923584}, {\"content\": \"level\", \"parent\": 2, \"prob\": -3.8516170978546143}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -5.606266975402832}, {\"content\": \"s\", \"parent\": 4, \"prob\": -4.939277172088623}, {\"content\": \"level\", \"parent\": 5, \"prob\": -5.060263156890869}, {\"content\": \"level\", \"parent\": 6, \"prob\": -4.363595962524414}, {\"content\": \"s\", \"parent\": 7, \"prob\": -5.104526042938232}, {\"content\": \"height\", \"parent\": 0, \"prob\": -6.115875244140625}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -6.615875244140625}, {\"content\": \"alt\", \"parent\": 0, \"prob\": -8.490875244140625}, {\"content\": \"level\", \"parent\": 1, \"prob\": -6.695944786071777}, {\"content\": \"above\", \"parent\": 2, \"prob\": -8.496655464172363}, {\"content\": \",\", \"parent\": 2, \"prob\": -11.871655464172363}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -9.113814353942871}, {\"content\": \"to\", \"parent\": 4, \"prob\": -9.738706588745117}, {\"content\": \"greatest\", \"parent\": 5, \"prob\": -10.447940826416016}, {\"content\": \"highest\", \"parent\": 5, \"prob\": -11.947940826416016}, {\"content\": \"th\", \"parent\": 6, \"prob\": -12.519769668579102}, {\"content\": \"its\", \"parent\": 7, \"prob\": -6.804173469543457}, {\"content\": \"sea\", \"parent\": 0, \"prob\": -7.67921781539917}, {\"content\": \"sea\", \"parent\": 1, \"prob\": -8.720327377319336}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -8.879435539245605}, {\"content\": \"its\", \"parent\": 3, \"prob\": -11.886618614196777}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 29\n",
      "data: [{\"content\": \"above\", \"parent\": 0, \"prob\": -3.08427095413208}, {\"content\": \"ation\", \"parent\": 1, \"prob\": -3.703709840774536}, {\"content\": \"itude\", \"parent\": 2, \"prob\": -5.703699588775635}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -3.7519145011901855}, {\"content\": \",\", \"parent\": 4, \"prob\": -3.851623296737671}, {\"content\": \"level\", \"parent\": 5, \"prob\": -5.606269359588623}, {\"content\": \"elev\", \"parent\": 6, \"prob\": -5.43784236907959}, {\"content\": \"height\", \"parent\": 6, \"prob\": -6.18784236907959}, {\"content\": \"alt\", \"parent\": 6, \"prob\": -7.31284236907959}, {\"content\": \",\", \"parent\": 7, \"prob\": -5.060277462005615}, {\"content\": \",\", \"parent\": 0, \"prob\": -4.363687992095947}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -5.676590442657471}, {\"content\": \"height\", \"parent\": 1, \"prob\": -6.551590442657471}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -6.801590442657471}, {\"content\": \"above\", \"parent\": 2, \"prob\": -6.121394157409668}, {\"content\": \"ation\", \"parent\": 3, \"prob\": -6.615901470184326}, {\"content\": \"itude\", \"parent\": 4, \"prob\": -8.490877151489258}, {\"content\": \",\", \"parent\": 5, \"prob\": -6.696034908294678}, {\"content\": \"sea\", \"parent\": 6, \"prob\": -8.496878623962402}, {\"content\": \"is\", \"parent\": 7, \"prob\": -11.87186050415039}, {\"content\": \"level\", \"parent\": 0, \"prob\": -9.11383056640625}, {\"content\": \"sea\", \"parent\": 1, \"prob\": -10.260369300842285}, {\"content\": \"the\", \"parent\": 1, \"prob\": -11.135369300842285}, {\"content\": \"Earth\", \"parent\": 1, \"prob\": -11.635369300842285}, {\"content\": \"alt\", \"parent\": 2, \"prob\": -10.604608535766602}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -12.854608535766602}, {\"content\": \"height\", \"parent\": 2, \"prob\": -13.479608535766602}, {\"content\": \"elev\", \"parent\": 3, \"prob\": -12.709559440612793}, {\"content\": \"alt\", \"parent\": 3, \"prob\": -12.834558486938477}, {\"content\": \"above\", \"parent\": 3, \"prob\": -14.084558486938477}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \"sea\", \"parent\": 0, \"prob\": -3.0843539237976074}, {\"content\": \"above\", \"parent\": 1, \"prob\": -3.710651159286499}, {\"content\": \"above\", \"parent\": 2, \"prob\": -5.713656902313232}, {\"content\": \"level\", \"parent\": 3, \"prob\": -3.7519166469573975}, {\"content\": \"is\", \"parent\": 4, \"prob\": -3.851623296737671}, {\"content\": \",\", \"parent\": 5, \"prob\": -5.606274127960205}, {\"content\": \"ation\", \"parent\": 6, \"prob\": -5.437862873077393}, {\"content\": \"above\", \"parent\": 7, \"prob\": -6.219184875488281}, {\"content\": \"itude\", \"parent\": 0, \"prob\": -7.312843322753906}, {\"content\": \"is\", \"parent\": 1, \"prob\": -5.060277462005615}, {\"content\": \"is\", \"parent\": 2, \"prob\": -4.363687992095947}, {\"content\": \"ation\", \"parent\": 3, \"prob\": -5.676621913909912}, {\"content\": \"above\", \"parent\": 4, \"prob\": -6.563791751861572}, {\"content\": \"itude\", \"parent\": 5, \"prob\": -6.801591873168945}, {\"content\": \"sea\", \"parent\": 6, \"prob\": -6.121434688568115}, {\"content\": \"above\", \"parent\": 7, \"prob\": -6.643950939178467}, {\"content\": \"above\", \"parent\": 0, \"prob\": -8.501334190368652}, {\"content\": \"is\", \"parent\": 1, \"prob\": -6.696034908294678}, {\"content\": \"level\", \"parent\": 2, \"prob\": -8.496879577636719}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -11.871916770935059}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 20\n",
      "data: [{\"content\": \"level\", \"parent\": 0, \"prob\": -3.0843567848205566}, {\"content\": \"sea\", \"parent\": 1, \"prob\": -3.7107419967651367}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -5.713798522949219}, {\"content\": \",\", \"parent\": 3, \"prob\": -3.7519266605377197}, {\"content\": \"Mount\", \"parent\": 4, \"prob\": -3.851689577102661}, {\"content\": \"is\", \"parent\": 5, \"prob\": -5.606274127960205}, {\"content\": \"above\", \"parent\": 6, \"prob\": -5.4586501121521}, {\"content\": \"sea\", \"parent\": 7, \"prob\": -6.2193708419799805}, {\"content\": \"above\", \"parent\": 0, \"prob\": -7.34014892578125}, {\"content\": \"Mount\", \"parent\": 1, \"prob\": -5.060359954833984}, {\"content\": \"Mount\", \"parent\": 2, \"prob\": -4.363759994506836}, {\"content\": \"above\", \"parent\": 3, \"prob\": -5.736258506774902}, {\"content\": \"relative\", \"parent\": 3, \"prob\": -9.111258506774902}, {\"content\": \"sea\", \"parent\": 4, \"prob\": -6.563899993896484}, {\"content\": \"above\", \"parent\": 5, \"prob\": -6.828745365142822}, {\"content\": \"level\", \"parent\": 6, \"prob\": -6.12143611907959}, {\"content\": \"sea\", \"parent\": 7, \"prob\": -6.644120693206787}, {\"content\": \"sea\", \"parent\": 0, \"prob\": -8.501433372497559}, {\"content\": \"Mount\", \"parent\": 1, \"prob\": -6.69609260559082}, {\"content\": \",\", \"parent\": 2, \"prob\": -8.49692440032959}, {\"content\": \"Ever\", \"parent\": 3, \"prob\": -11.871920585632324}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \",\", \"parent\": 0, \"prob\": -3.084408760070801}, {\"content\": \"level\", \"parent\": 1, \"prob\": -3.7107439041137695}, {\"content\": \"level\", \"parent\": 2, \"prob\": -5.713800430297852}, {\"content\": \"is\", \"parent\": 3, \"prob\": -3.7519266605377197}, {\"content\": \"Ever\", \"parent\": 4, \"prob\": -3.8516979217529297}, {\"content\": \"Mount\", \"parent\": 5, \"prob\": -5.606368064880371}, {\"content\": \"sea\", \"parent\": 6, \"prob\": -5.45878267288208}, {\"content\": \"level\", \"parent\": 7, \"prob\": -6.219374179840088}, {\"content\": \"sea\", \"parent\": 0, \"prob\": -7.340533256530762}, {\"content\": \"Ever\", \"parent\": 1, \"prob\": -5.060364723205566}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -4.363763332366943}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -5.736412525177002}, {\"content\": \"to\", \"parent\": 4, \"prob\": -9.111261367797852}, {\"content\": \"level\", \"parent\": 5, \"prob\": -6.563901901245117}, {\"content\": \"sea\", \"parent\": 6, \"prob\": -6.828908920288086}, {\"content\": \",\", \"parent\": 7, \"prob\": -6.121532917022705}, {\"content\": \"level\", \"parent\": 0, \"prob\": -6.64412260055542}, {\"content\": \"level\", \"parent\": 1, \"prob\": -8.501435279846191}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -6.6960978507995605}, {\"content\": \"is\", \"parent\": 3, \"prob\": -8.49692440032959}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \"is\", \"parent\": 0, \"prob\": -3.084408760070801}, {\"content\": \",\", \"parent\": 1, \"prob\": -3.7107720375061035}, {\"content\": \",\", \"parent\": 2, \"prob\": -5.713836669921875}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -3.7520217895507812}, {\"content\": \"est\", \"parent\": 4, \"prob\": -3.851705312728882}, {\"content\": \"Ever\", \"parent\": 5, \"prob\": -5.606374263763428}, {\"content\": \"level\", \"parent\": 6, \"prob\": -5.458785057067871}, {\"content\": \",\", \"parent\": 7, \"prob\": -6.219459056854248}, {\"content\": \"level\", \"parent\": 0, \"prob\": -7.340535640716553}, {\"content\": \"est\", \"parent\": 1, \"prob\": -5.060370922088623}, {\"content\": \"est\", \"parent\": 2, \"prob\": -4.363770484924316}, {\"content\": \"level\", \"parent\": 3, \"prob\": -5.736414432525635}, {\"content\": \"sea\", \"parent\": 4, \"prob\": -9.112934112548828}, {\"content\": \",\", \"parent\": 5, \"prob\": -6.5639872550964355}, {\"content\": \"level\", \"parent\": 6, \"prob\": -6.8289103507995605}, {\"content\": \"is\", \"parent\": 7, \"prob\": -6.121532917022705}, {\"content\": \",\", \"parent\": 0, \"prob\": -6.644175052642822}, {\"content\": \",\", \"parent\": 1, \"prob\": -8.501511573791504}, {\"content\": \"est\", \"parent\": 2, \"prob\": -6.696104049682617}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -8.497018814086914}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \"Mount\", \"parent\": 0, \"prob\": -3.0845305919647217}, {\"content\": \"is\", \"parent\": 1, \"prob\": -3.7107720375061035}, {\"content\": \"is\", \"parent\": 2, \"prob\": -5.713836669921875}, {\"content\": \"Ever\", \"parent\": 3, \"prob\": -3.752028703689575}, {\"content\": \".\", \"parent\": 4, \"prob\": -3.8517305850982666}, {\"content\": \"est\", \"parent\": 5, \"prob\": -5.606382369995117}, {\"content\": \",\", \"parent\": 6, \"prob\": -5.458797931671143}, {\"content\": \"is\", \"parent\": 7, \"prob\": -6.219459056854248}, {\"content\": \",\", \"parent\": 0, \"prob\": -7.340563774108887}, {\"content\": \".\", \"parent\": 1, \"prob\": -5.060394287109375}, {\"content\": \".\", \"parent\": 2, \"prob\": -4.363805294036865}, {\"content\": \",\", \"parent\": 3, \"prob\": -5.736433506011963}, {\"content\": \"level\", \"parent\": 4, \"prob\": -9.112957000732422}, {\"content\": \"is\", \"parent\": 5, \"prob\": -6.5639872550964355}, {\"content\": \",\", \"parent\": 6, \"prob\": -6.828956127166748}, {\"content\": \"Mount\", \"parent\": 7, \"prob\": -6.121654987335205}, {\"content\": \"is\", \"parent\": 0, \"prob\": -6.644175052642822}, {\"content\": \"is\", \"parent\": 1, \"prob\": -8.501511573791504}, {\"content\": \".\", \"parent\": 2, \"prob\": -6.696146488189697}, {\"content\": \"Ever\", \"parent\": 3, \"prob\": -8.497024536132812}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 27\n",
      "data: [{\"content\": \"Ever\", \"parent\": 0, \"prob\": -3.084537982940674}, {\"content\": \"Mount\", \"parent\": 1, \"prob\": -3.7109100818634033}, {\"content\": \"Mount\", \"parent\": 2, \"prob\": -5.713978290557861}, {\"content\": \"est\", \"parent\": 3, \"prob\": -3.7520358562469482}, {\"content\": \"It\", \"parent\": 4, \"prob\": -4.618638515472412}, {\"content\": \"Its\", \"parent\": 4, \"prob\": -5.118638515472412}, {\"content\": \"Loc\", \"parent\": 4, \"prob\": -5.368638515472412}, {\"content\": \".\", \"parent\": 5, \"prob\": -5.606398582458496}, {\"content\": \"is\", \"parent\": 6, \"prob\": -5.458797931671143}, {\"content\": \"Mount\", \"parent\": 7, \"prob\": -6.219594955444336}, {\"content\": \"is\", \"parent\": 0, \"prob\": -7.340563774108887}, {\"content\": \"It\", \"parent\": 1, \"prob\": -5.7848029136657715}, {\"content\": \"Its\", \"parent\": 1, \"prob\": -6.2848029136657715}, {\"content\": \"Loc\", \"parent\": 1, \"prob\": -6.6598029136657715}, {\"content\": \"It\", \"parent\": 2, \"prob\": -5.021923065185547}, {\"content\": \"Its\", \"parent\": 2, \"prob\": -5.271923065185547}, {\"content\": \"Loc\", \"parent\": 2, \"prob\": -7.021923065185547}, {\"content\": \"is\", \"parent\": 3, \"prob\": -5.736433506011963}, {\"content\": \",\", \"parent\": 4, \"prob\": -9.112977981567383}, {\"content\": \"Mount\", \"parent\": 5, \"prob\": -6.564093589782715}, {\"content\": \"is\", \"parent\": 6, \"prob\": -6.828956127166748}, {\"content\": \"Ever\", \"parent\": 7, \"prob\": -6.121659755706787}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -6.644298076629639}, {\"content\": \"Mount\", \"parent\": 1, \"prob\": -8.501653671264648}, {\"content\": \"Its\", \"parent\": 2, \"prob\": -7.33845329284668}, {\"content\": \"It\", \"parent\": 2, \"prob\": -7.58845329284668}, {\"content\": \"Loc\", \"parent\": 2, \"prob\": -9.58845329284668}, {\"content\": \"est\", \"parent\": 3, \"prob\": -8.497031211853027}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 31\n",
      "data: [{\"content\": \"est\", \"parent\": 0, \"prob\": -3.084547996520996}, {\"content\": \"Ever\", \"parent\": 1, \"prob\": -3.71091890335083}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -5.713987350463867}, {\"content\": \".\", \"parent\": 3, \"prob\": -3.7520527839660645}, {\"content\": \"is\", \"parent\": 4, \"prob\": -5.621070861816406}, {\"content\": \"reaches\", \"parent\": 4, \"prob\": -5.621070861816406}, {\"content\": \"stands\", \"parent\": 4, \"prob\": -5.996070861816406}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -5.7170257568359375}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -6.8420257568359375}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -6.9670257568359375}, {\"content\": \"height\", \"parent\": 5, \"prob\": -7.4670257568359375}, {\"content\": \"ated\", \"parent\": 6, \"prob\": -5.36863899230957}, {\"content\": \"It\", \"parent\": 7, \"prob\": -6.519988059997559}, {\"content\": \"Its\", \"parent\": 7, \"prob\": -6.769988059997559}, {\"content\": \"Loc\", \"parent\": 7, \"prob\": -7.019988059997559}, {\"content\": \"Mount\", \"parent\": 7, \"prob\": -8.769988059997559}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -5.458920478820801}, {\"content\": \"Ever\", \"parent\": 1, \"prob\": -6.219598770141602}, {\"content\": \"Mount\", \"parent\": 2, \"prob\": -7.340721130371094}, {\"content\": \"reaches\", \"parent\": 3, \"prob\": -6.604644775390625}, {\"content\": \"is\", \"parent\": 3, \"prob\": -6.729644775390625}, {\"content\": \"stands\", \"parent\": 3, \"prob\": -7.604644775390625}, {\"content\": \"peak\", \"parent\": 4, \"prob\": -6.321586608886719}, {\"content\": \"ated\", \"parent\": 5, \"prob\": -6.65980339050293}, {\"content\": \"reaches\", \"parent\": 6, \"prob\": -5.739595413208008}, {\"content\": \"is\", \"parent\": 6, \"prob\": -5.989595413208008}, {\"content\": \"stands\", \"parent\": 6, \"prob\": -7.114595413208008}, {\"content\": \"peak\", \"parent\": 7, \"prob\": -5.308753490447998}, {\"content\": \"ated\", \"parent\": 0, \"prob\": -7.021923542022705}, {\"content\": \"Mount\", \"parent\": 1, \"prob\": -5.736554145812988}, {\"content\": \"is\", \"parent\": 2, \"prob\": -9.112977981567383}, {\"content\": \"Ever\", \"parent\": 3, \"prob\": -6.564096927642822}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 31\n",
      "data: [{\"content\": \".\", \"parent\": 0, \"prob\": -3.084571599960327}, {\"content\": \"est\", \"parent\": 1, \"prob\": -3.710926055908203}, {\"content\": \"est\", \"parent\": 2, \"prob\": -5.713995456695557}, {\"content\": \"It\", \"parent\": 3, \"prob\": -4.732705593109131}, {\"content\": \"Loc\", \"parent\": 3, \"prob\": -4.982705593109131}, {\"content\": \"Its\", \"parent\": 3, \"prob\": -4.982705593109131}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -6.982705593109131}, {\"content\": \"part\", \"parent\": 4, \"prob\": -5.850039958953857}, {\"content\": \"located\", \"parent\": 4, \"prob\": -7.225039958953857}, {\"content\": \"an\", \"parent\": 5, \"prob\": -5.6238226890563965}, {\"content\": \"at\", \"parent\": 6, \"prob\": -6.10287618637085}, {\"content\": \"approximately\", \"parent\": 6, \"prob\": -8.727875709533691}, {\"content\": \"ation\", \"parent\": 7, \"prob\": -5.717028617858887}, {\"content\": \"mit\", \"parent\": 0, \"prob\": -6.842028617858887}, {\"content\": \"stands\", \"parent\": 1, \"prob\": -7.707647800445557}, {\"content\": \"is\", \"parent\": 1, \"prob\": -7.957647800445557}, {\"content\": \"reaches\", \"parent\": 1, \"prob\": -9.457647323608398}, {\"content\": \"r\", \"parent\": 1, \"prob\": -9.707647323608398}, {\"content\": \"is\", \"parent\": 2, \"prob\": -7.472560882568359}, {\"content\": \"in\", \"parent\": 3, \"prob\": -5.368780612945557}, {\"content\": \"is\", \"parent\": 4, \"prob\": -7.386491775512695}, {\"content\": \"reaches\", \"parent\": 4, \"prob\": -7.511491775512695}, {\"content\": \"stands\", \"parent\": 4, \"prob\": -8.136491775512695}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -7.563559532165527}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -7.688559532165527}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -8.938559532165527}, {\"content\": \"ated\", \"parent\": 6, \"prob\": -7.019988536834717}, {\"content\": \"Ever\", \"parent\": 7, \"prob\": -8.769988059997559}, {\"content\": \"Ever\", \"parent\": 0, \"prob\": -5.458926677703857}, {\"content\": \"est\", \"parent\": 1, \"prob\": -6.219604015350342}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -7.340728759765625}, {\"content\": \"an\", \"parent\": 3, \"prob\": -6.615262985229492}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 41\n",
      "data: [{\"content\": \"It\", \"parent\": 0, \"prob\": -4.061916828155518}, {\"content\": \"Loc\", \"parent\": 0, \"prob\": -4.311916828155518}, {\"content\": \"Its\", \"parent\": 0, \"prob\": -4.311916828155518}, {\"content\": \".\", \"parent\": 1, \"prob\": -3.710953950881958}, {\"content\": \".\", \"parent\": 2, \"prob\": -5.714023590087891}, {\"content\": \"is\", \"parent\": 3, \"prob\": -5.596200942993164}, {\"content\": \"reaches\", \"parent\": 3, \"prob\": -5.721200942993164}, {\"content\": \"stands\", \"parent\": 3, \"prob\": -6.346200942993164}, {\"content\": \"ated\", \"parent\": 4, \"prob\": -4.982706069946289}, {\"content\": \"height\", \"parent\": 5, \"prob\": -5.794220924377441}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -6.169220924377441}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -6.919220924377441}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -7.419220924377441}, {\"content\": \"Ever\", \"parent\": 6, \"prob\": -6.982705593109131}, {\"content\": \"of\", \"parent\": 7, \"prob\": -5.850039958953857}, {\"content\": \"in\", \"parent\": 0, \"prob\": -7.225693702697754}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -5.930722713470459}, {\"content\": \"impress\", \"parent\": 1, \"prob\": -7.805722713470459}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -8.180723190307617}, {\"content\": \"aston\", \"parent\": 1, \"prob\": -8.430723190307617}, {\"content\": \"approximately\", \"parent\": 2, \"prob\": -6.534271240234375}, {\"content\": \"an\", \"parent\": 2, \"prob\": -7.159271240234375}, {\"content\": \"\", \"parent\": 3, \"prob\": -8.728912353515625}, {\"content\": \"is\", \"parent\": 4, \"prob\": -5.759345054626465}, {\"content\": \"stands\", \"parent\": 4, \"prob\": -9.009345054626465}, {\"content\": \"reaches\", \"parent\": 5, \"prob\": -7.008103847503662}, {\"content\": \"is\", \"parent\": 5, \"prob\": -9.88310432434082}, {\"content\": \"r\", \"parent\": 5, \"prob\": -9.88310432434082}, {\"content\": \"stands\", \"parent\": 5, \"prob\": -10.00810432434082}, {\"content\": \"at\", \"parent\": 6, \"prob\": -7.745132923126221}, {\"content\": \"approximately\", \"parent\": 7, \"prob\": -8.476022720336914}, {\"content\": \"\", \"parent\": 7, \"prob\": -8.976022720336914}, {\"content\": \"located\", \"parent\": 7, \"prob\": -11.726022720336914}, {\"content\": \"an\", \"parent\": 0, \"prob\": -9.520164489746094}, {\"content\": \"approximately\", \"parent\": 0, \"prob\": -12.270164489746094}, {\"content\": \"ises\", \"parent\": 1, \"prob\": -9.707647323608398}, {\"content\": \"approximately\", \"parent\": 2, \"prob\": -8.209774017333984}, {\"content\": \"currently\", \"parent\": 2, \"prob\": -9.334774017333984}, {\"content\": \"officially\", \"parent\": 2, \"prob\": -9.334774017333984}, {\"content\": \"widely\", \"parent\": 2, \"prob\": -9.459774017333984}, {\"content\": \"convention\", \"parent\": 2, \"prob\": -10.334774017333984}, {\"content\": \"the\", \"parent\": 3, \"prob\": -5.3687825202941895}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 34\n",
      "data: [{\"content\": \"reaches\", \"parent\": 0, \"prob\": -4.8169732093811035}, {\"content\": \"is\", \"parent\": 0, \"prob\": -5.1919732093811035}, {\"content\": \"stands\", \"parent\": 0, \"prob\": -5.6919732093811035}, {\"content\": \"ated\", \"parent\": 1, \"prob\": -4.311917304992676}, {\"content\": \"peak\", \"parent\": 2, \"prob\": -5.030865669250488}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -5.155865669250488}, {\"content\": \"sum\", \"parent\": 2, \"prob\": -7.030865669250488}, {\"content\": \"It\", \"parent\": 3, \"prob\": -4.626644134521484}, {\"content\": \"Loc\", \"parent\": 3, \"prob\": -4.876644134521484}, {\"content\": \"Its\", \"parent\": 3, \"prob\": -5.126644134521484}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -6.876644134521484}, {\"content\": \"It\", \"parent\": 4, \"prob\": -6.77105712890625}, {\"content\": \"Loc\", \"parent\": 4, \"prob\": -6.77105712890625}, {\"content\": \"Its\", \"parent\": 4, \"prob\": -7.02105712890625}, {\"content\": \"part\", \"parent\": 5, \"prob\": -5.824389934539795}, {\"content\": \"located\", \"parent\": 5, \"prob\": -7.199389934539795}, {\"content\": \"an\", \"parent\": 6, \"prob\": -5.728381156921387}, {\"content\": \"at\", \"parent\": 7, \"prob\": -6.523347854614258}, {\"content\": \"approximately\", \"parent\": 7, \"prob\": -8.648347854614258}, {\"content\": \"tall\", \"parent\": 7, \"prob\": -9.148347854614258}, {\"content\": \"in\", \"parent\": 0, \"prob\": -4.982873439788818}, {\"content\": \"is\", \"parent\": 1, \"prob\": -5.798550605773926}, {\"content\": \"stands\", \"parent\": 2, \"prob\": -6.943490028381348}, {\"content\": \"is\", \"parent\": 2, \"prob\": -7.068490028381348}, {\"content\": \"r\", \"parent\": 2, \"prob\": -8.693490028381348}, {\"content\": \"reaches\", \"parent\": 2, \"prob\": -9.193490028381348}, {\"content\": \"mit\", \"parent\": 3, \"prob\": -6.919222831726074}, {\"content\": \"ation\", \"parent\": 4, \"prob\": -7.419222831726074}, {\"content\": \"est\", \"parent\": 5, \"prob\": -6.982706546783447}, {\"content\": \"the\", \"parent\": 6, \"prob\": -5.850060939788818}, {\"content\": \"the\", \"parent\": 7, \"prob\": -7.225696086883545}, {\"content\": \"ation\", \"parent\": 0, \"prob\": -5.930727958679199}, {\"content\": \"ive\", \"parent\": 1, \"prob\": -7.805722713470459}, {\"content\": \"itude\", \"parent\": 2, \"prob\": -8.180726051330566}, {\"content\": \"ishing\", \"parent\": 3, \"prob\": -8.430729866027832}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 40\n",
      "data: [{\"content\": \"an\", \"parent\": 0, \"prob\": -4.82627534866333}, {\"content\": \"part\", \"parent\": 1, \"prob\": -5.449010372161865}, {\"content\": \"located\", \"parent\": 1, \"prob\": -6.699010848999023}, {\"content\": \"at\", \"parent\": 2, \"prob\": -6.022907733917236}, {\"content\": \"approximately\", \"parent\": 2, \"prob\": -7.1479082107543945}, {\"content\": \"tall\", \"parent\": 2, \"prob\": -8.772908210754395}, {\"content\": \"in\", \"parent\": 3, \"prob\": -4.312069892883301}, {\"content\": \"stands\", \"parent\": 4, \"prob\": -5.694551467895508}, {\"content\": \"is\", \"parent\": 4, \"prob\": -6.194551467895508}, {\"content\": \"reaches\", \"parent\": 4, \"prob\": -7.444551467895508}, {\"content\": \"r\", \"parent\": 4, \"prob\": -7.569551467895508}, {\"content\": \"ation\", \"parent\": 5, \"prob\": -5.155867576599121}, {\"content\": \"mit\", \"parent\": 6, \"prob\": -7.030869483947754}, {\"content\": \"is\", \"parent\": 7, \"prob\": -5.473495006561279}, {\"content\": \"reaches\", \"parent\": 7, \"prob\": -5.723495006561279}, {\"content\": \"stands\", \"parent\": 7, \"prob\": -6.098495006561279}, {\"content\": \"ated\", \"parent\": 0, \"prob\": -4.876644611358643}, {\"content\": \"peak\", \"parent\": 1, \"prob\": -5.777495861053467}, {\"content\": \"height\", \"parent\": 1, \"prob\": -6.402495384216309}, {\"content\": \"sum\", \"parent\": 1, \"prob\": -7.277495384216309}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -7.777495861053467}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -6.876644134521484}, {\"content\": \"reaches\", \"parent\": 3, \"prob\": -7.661868095397949}, {\"content\": \"is\", \"parent\": 3, \"prob\": -7.786868095397949}, {\"content\": \"stands\", \"parent\": 3, \"prob\": -8.28686809539795}, {\"content\": \"ated\", \"parent\": 4, \"prob\": -6.771057605743408}, {\"content\": \"peak\", \"parent\": 5, \"prob\": -7.530117511749268}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -8.53011703491211}, {\"content\": \"height\", \"parent\": 5, \"prob\": -9.280117988586426}, {\"content\": \"sum\", \"parent\": 5, \"prob\": -9.780117988586426}, {\"content\": \"of\", \"parent\": 6, \"prob\": -5.824389934539795}, {\"content\": \"in\", \"parent\": 7, \"prob\": -7.199976921081543}, {\"content\": \"elev\", \"parent\": 0, \"prob\": -6.6587815284729}, {\"content\": \"impress\", \"parent\": 0, \"prob\": -6.9087815284729}, {\"content\": \"aston\", \"parent\": 0, \"prob\": -7.4087815284729}, {\"content\": \"alt\", \"parent\": 0, \"prob\": -8.283781051635742}, {\"content\": \"approximately\", \"parent\": 1, \"prob\": -6.808894157409668}, {\"content\": \"an\", \"parent\": 1, \"prob\": -7.933894157409668}, {\"content\": \"\", \"parent\": 2, \"prob\": -8.649385452270508}, {\"content\": \"at\", \"parent\": 3, \"prob\": -9.258420944213867}, {\"content\": \"in\", \"parent\": 3, \"prob\": -11.508420944213867}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 39\n",
      "data: [{\"content\": \"elev\", \"parent\": 0, \"prob\": -5.205750942230225}, {\"content\": \"impress\", \"parent\": 0, \"prob\": -6.455750942230225}, {\"content\": \"aston\", \"parent\": 0, \"prob\": -7.455751419067383}, {\"content\": \"alt\", \"parent\": 0, \"prob\": -8.330751419067383}, {\"content\": \"of\", \"parent\": 1, \"prob\": -5.449010372161865}, {\"content\": \"in\", \"parent\": 2, \"prob\": -6.699532985687256}, {\"content\": \"approximately\", \"parent\": 3, \"prob\": -6.185640335083008}, {\"content\": \"an\", \"parent\": 3, \"prob\": -7.935640335083008}, {\"content\": \"\", \"parent\": 4, \"prob\": -7.148717403411865}, {\"content\": \"at\", \"parent\": 5, \"prob\": -8.835597038269043}, {\"content\": \"in\", \"parent\": 5, \"prob\": -11.83559799194336}, {\"content\": \"the\", \"parent\": 6, \"prob\": -4.312072277069092}, {\"content\": \"at\", \"parent\": 7, \"prob\": -5.785165786743164}, {\"content\": \"approximately\", \"parent\": 7, \"prob\": -8.785165786743164}, {\"content\": \"tall\", \"parent\": 7, \"prob\": -8.910165786743164}, {\"content\": \"approximately\", \"parent\": 0, \"prob\": -6.623330593109131}, {\"content\": \"\", \"parent\": 0, \"prob\": -7.373330593109131}, {\"content\": \"located\", \"parent\": 0, \"prob\": -10.123331069946289}, {\"content\": \"an\", \"parent\": 1, \"prob\": -7.5349626541137695}, {\"content\": \"approximately\", \"parent\": 1, \"prob\": -9.90996265411377}, {\"content\": \"ises\", \"parent\": 2, \"prob\": -7.569551467895508}, {\"content\": \"is\", \"parent\": 3, \"prob\": -5.206916332244873}, {\"content\": \"stands\", \"parent\": 3, \"prob\": -8.206916809082031}, {\"content\": \"reaches\", \"parent\": 4, \"prob\": -7.372945308685303}, {\"content\": \"is\", \"parent\": 4, \"prob\": -9.372944831848145}, {\"content\": \"stands\", \"parent\": 4, \"prob\": -9.372944831848145}, {\"content\": \"r\", \"parent\": 4, \"prob\": -9.872944831848145}, {\"content\": \"part\", \"parent\": 5, \"prob\": -5.759584426879883}, {\"content\": \"located\", \"parent\": 5, \"prob\": -6.884584426879883}, {\"content\": \"an\", \"parent\": 6, \"prob\": -5.731715202331543}, {\"content\": \"at\", \"parent\": 7, \"prob\": -6.332760810852051}, {\"content\": \"approximately\", \"parent\": 7, \"prob\": -7.957760810852051}, {\"content\": \"tall\", \"parent\": 7, \"prob\": -9.08276081085205}, {\"content\": \"in\", \"parent\": 0, \"prob\": -4.876780986785889}, {\"content\": \"stands\", \"parent\": 1, \"prob\": -6.4912919998168945}, {\"content\": \"is\", \"parent\": 1, \"prob\": -6.8662919998168945}, {\"content\": \"r\", \"parent\": 1, \"prob\": -8.116291999816895}, {\"content\": \"reaches\", \"parent\": 1, \"prob\": -8.366291999816895}, {\"content\": \"is\", \"parent\": 2, \"prob\": -6.408748149871826}, {\"content\": \"mit\", \"parent\": 3, \"prob\": -7.2774977684021}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 27\n",
      "data: [{\"content\": \"ation\", \"parent\": 0, \"prob\": -5.205756664276123}, {\"content\": \"ive\", \"parent\": 1, \"prob\": -6.455750942230225}, {\"content\": \"ishing\", \"parent\": 2, \"prob\": -7.455758571624756}, {\"content\": \"itude\", \"parent\": 3, \"prob\": -8.330755233764648}, {\"content\": \"the\", \"parent\": 4, \"prob\": -5.449032783508301}, {\"content\": \"the\", \"parent\": 5, \"prob\": -6.699535369873047}, {\"content\": \"\", \"parent\": 6, \"prob\": -6.185641288757324}, {\"content\": \"impress\", \"parent\": 7, \"prob\": -8.21374797821045}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -9.71374797821045}, {\"content\": \"aston\", \"parent\": 7, \"prob\": -11.213748931884766}, {\"content\": \"8\", \"parent\": 0, \"prob\": -7.577418327331543}, {\"content\": \"2\", \"parent\": 0, \"prob\": -8.202418327331543}, {\"content\": \"approximately\", \"parent\": 1, \"prob\": -8.86736011505127}, {\"content\": \"the\", \"parent\": 2, \"prob\": -11.835609436035156}, {\"content\": \"H\", \"parent\": 3, \"prob\": -4.412576675415039}, {\"content\": \"Mah\", \"parent\": 3, \"prob\": -6.662576675415039}, {\"content\": \"approximately\", \"parent\": 4, \"prob\": -5.801520824432373}, {\"content\": \"\", \"parent\": 5, \"prob\": -8.793782234191895}, {\"content\": \"at\", \"parent\": 6, \"prob\": -8.910252571105957}, {\"content\": \"\", \"parent\": 7, \"prob\": -6.623331546783447}, {\"content\": \"8\", \"parent\": 0, \"prob\": -7.80204439163208}, {\"content\": \"2\", \"parent\": 0, \"prob\": -8.427043914794922}, {\"content\": \"in\", \"parent\": 1, \"prob\": -10.475857734680176}, {\"content\": \"on\", \"parent\": 1, \"prob\": -11.350857734680176}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -7.645898818969727}, {\"content\": \"alt\", \"parent\": 2, \"prob\": -10.395898818969727}, {\"content\": \"impress\", \"parent\": 2, \"prob\": -11.270898818969727}, {\"content\": \"\", \"parent\": 3, \"prob\": -9.909963607788086}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 28\n",
      "data: [{\"content\": \"of\", \"parent\": 0, \"prob\": -5.205759525299072}, {\"content\": \"height\", \"parent\": 1, \"prob\": -6.641097068786621}, {\"content\": \"elev\", \"parent\": 1, \"prob\": -8.516097068786621}, {\"content\": \"alt\", \"parent\": 1, \"prob\": -9.766097068786621}, {\"content\": \"height\", \"parent\": 2, \"prob\": -7.615446090698242}, {\"content\": \"elev\", \"parent\": 2, \"prob\": -10.115446090698242}, {\"content\": \"alt\", \"parent\": 2, \"prob\": -10.365446090698242}, {\"content\": \"of\", \"parent\": 3, \"prob\": -8.330771446228027}, {\"content\": \"H\", \"parent\": 4, \"prob\": -5.449445724487305}, {\"content\": \"H\", \"parent\": 5, \"prob\": -6.778645992279053}, {\"content\": \"Mah\", \"parent\": 5, \"prob\": -9.278646469116211}, {\"content\": \"2\", \"parent\": 6, \"prob\": -6.659718036651611}, {\"content\": \"8\", \"parent\": 6, \"prob\": -7.1597185134887695}, {\"content\": \"ive\", \"parent\": 7, \"prob\": -8.21374797821045}, {\"content\": \"ation\", \"parent\": 0, \"prob\": -9.713788986206055}, {\"content\": \"ishing\", \"parent\": 1, \"prob\": -11.213759422302246}, {\"content\": \",\", \"parent\": 2, \"prob\": -7.577420234680176}, {\"content\": \"9\", \"parent\": 3, \"prob\": -8.202418327331543}, {\"content\": \"\", \"parent\": 4, \"prob\": -8.867361068725586}, {\"content\": \"H\", \"parent\": 5, \"prob\": -11.914926528930664}, {\"content\": \"Mah\", \"parent\": 5, \"prob\": -14.414926528930664}, {\"content\": \"imal\", \"parent\": 6, \"prob\": -4.41257905960083}, {\"content\": \"al\", \"parent\": 7, \"prob\": -6.662840366363525}, {\"content\": \"\", \"parent\": 0, \"prob\": -5.801520824432373}, {\"content\": \"8\", \"parent\": 1, \"prob\": -8.973526954650879}, {\"content\": \"2\", \"parent\": 1, \"prob\": -10.598526954650879}, {\"content\": \"approximately\", \"parent\": 2, \"prob\": -8.947515487670898}, {\"content\": \"8\", \"parent\": 3, \"prob\": -6.904481887817383}, {\"content\": \"2\", \"parent\": 3, \"prob\": -8.029481887817383}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 26\n",
      "data: [{\"content\": \"approximately\", \"parent\": 0, \"prob\": -5.222530841827393}, {\"content\": \"of\", \"parent\": 1, \"prob\": -6.641097545623779}, {\"content\": \"ation\", \"parent\": 2, \"prob\": -8.516097068786621}, {\"content\": \"itude\", \"parent\": 3, \"prob\": -9.766097068786621}, {\"content\": \"of\", \"parent\": 4, \"prob\": -7.6154465675354}, {\"content\": \"ation\", \"parent\": 5, \"prob\": -10.115446090698242}, {\"content\": \"itude\", \"parent\": 6, \"prob\": -10.365447044372559}, {\"content\": \"approximately\", \"parent\": 7, \"prob\": -8.361014366149902}, {\"content\": \"imal\", \"parent\": 0, \"prob\": -5.449446678161621}, {\"content\": \"imal\", \"parent\": 1, \"prob\": -6.778647422790527}, {\"content\": \"al\", \"parent\": 2, \"prob\": -9.278847694396973}, {\"content\": \"9\", \"parent\": 3, \"prob\": -6.659718036651611}, {\"content\": \",\", \"parent\": 4, \"prob\": -7.159718990325928}, {\"content\": \"\", \"parent\": 5, \"prob\": -8.80545425415039}, {\"content\": \"height\", \"parent\": 5, \"prob\": -9.43045425415039}, {\"content\": \"elev\", \"parent\": 5, \"prob\": -10.43045425415039}, {\"content\": \"alt\", \"parent\": 5, \"prob\": -11.43045425415039}, {\"content\": \"of\", \"parent\": 6, \"prob\": -9.713790893554688}, {\"content\": \"\", \"parent\": 7, \"prob\": -11.746602058410645}, {\"content\": \"height\", \"parent\": 7, \"prob\": -12.621603012084961}, {\"content\": \"elev\", \"parent\": 7, \"prob\": -13.621603012084961}, {\"content\": \"alt\", \"parent\": 7, \"prob\": -13.871602058410645}, {\"content\": \"8\", \"parent\": 0, \"prob\": -7.577426910400391}, {\"content\": \",\", \"parent\": 1, \"prob\": -8.202418327331543}, {\"content\": \"2\", \"parent\": 2, \"prob\": -9.390483856201172}, {\"content\": \"8\", \"parent\": 2, \"prob\": -9.765483856201172}, {\"content\": \"imal\", \"parent\": 3, \"prob\": -11.91492748260498}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 22\n",
      "data: [{\"content\": \"\", \"parent\": 0, \"prob\": -5.222530841827393}, {\"content\": \"approximately\", \"parent\": 1, \"prob\": -6.659832000732422}, {\"content\": \"of\", \"parent\": 2, \"prob\": -8.516097068786621}, {\"content\": \"of\", \"parent\": 3, \"prob\": -9.766097068786621}, {\"content\": \"approximately\", \"parent\": 4, \"prob\": -7.645997524261475}, {\"content\": \"of\", \"parent\": 5, \"prob\": -10.115446090698242}, {\"content\": \"of\", \"parent\": 6, \"prob\": -10.365447044372559}, {\"content\": \"\", \"parent\": 7, \"prob\": -8.361014366149902}, {\"content\": \"aya\", \"parent\": 0, \"prob\": -5.6096720695495605}, {\"content\": \"ay\", \"parent\": 0, \"prob\": -7.3596720695495605}, {\"content\": \"ay\", \"parent\": 1, \"prob\": -6.791157245635986}, {\"content\": \"ang\", \"parent\": 2, \"prob\": -9.279508590698242}, {\"content\": \",\", \"parent\": 3, \"prob\": -6.659718036651611}, {\"content\": \"8\", \"parent\": 4, \"prob\": -7.159728527069092}, {\"content\": \"2\", \"parent\": 5, \"prob\": -9.057388305664062}, {\"content\": \"8\", \"parent\": 5, \"prob\": -10.307388305664062}, {\"content\": \"of\", \"parent\": 6, \"prob\": -9.43045425415039}, {\"content\": \"ation\", \"parent\": 7, \"prob\": -10.43045425415039}, {\"content\": \"itude\", \"parent\": 0, \"prob\": -11.430455207824707}, {\"content\": \"approximately\", \"parent\": 1, \"prob\": -9.725519180297852}, {\"content\": \"2\", \"parent\": 2, \"prob\": -12.095054626464844}, {\"content\": \"8\", \"parent\": 2, \"prob\": -12.970054626464844}, {\"content\": \"of\", \"parent\": 3, \"prob\": -12.621603012084961}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 26\n",
      "data: [{\"content\": \"2\", \"parent\": 0, \"prob\": -5.570975303649902}, {\"content\": \"8\", \"parent\": 0, \"prob\": -6.445975303649902}, {\"content\": \"\", \"parent\": 1, \"prob\": -6.659832000732422}, {\"content\": \"approximately\", \"parent\": 2, \"prob\": -8.661349296569824}, {\"content\": \"\", \"parent\": 2, \"prob\": -10.536349296569824}, {\"content\": \"approximately\", \"parent\": 3, \"prob\": -9.837258338928223}, {\"content\": \"\", \"parent\": 3, \"prob\": -12.462258338928223}, {\"content\": \"\", \"parent\": 4, \"prob\": -7.645997524261475}, {\"content\": \"approximately\", \"parent\": 5, \"prob\": -10.278193473815918}, {\"content\": \"\", \"parent\": 5, \"prob\": -12.028194427490234}, {\"content\": \"approximately\", \"parent\": 6, \"prob\": -10.466838836669922}, {\"content\": \"\", \"parent\": 6, \"prob\": -12.716838836669922}, {\"content\": \"8\", \"parent\": 7, \"prob\": -8.9369535446167}, {\"content\": \"2\", \"parent\": 7, \"prob\": -9.1869535446167}, {\"content\": \"range\", \"parent\": 0, \"prob\": -5.616577625274658}, {\"content\": \"as\", \"parent\": 1, \"prob\": -7.672934055328369}, {\"content\": \"an\", \"parent\": 1, \"prob\": -8.672933578491211}, {\"content\": \"as\", \"parent\": 2, \"prob\": -6.791492462158203}, {\"content\": \"ur\", \"parent\": 3, \"prob\": -9.280082702636719}, {\"content\": \"0\", \"parent\": 4, \"prob\": -6.659718036651611}, {\"content\": \"4\", \"parent\": 5, \"prob\": -7.159728527069092}, {\"content\": \"9\", \"parent\": 6, \"prob\": -9.057388305664062}, {\"content\": \",\", \"parent\": 7, \"prob\": -10.307388305664062}, {\"content\": \"approximately\", \"parent\": 0, \"prob\": -9.46495532989502}, {\"content\": \"of\", \"parent\": 1, \"prob\": -10.43045425415039}, {\"content\": \"of\", \"parent\": 2, \"prob\": -11.430455207824707}, {\"content\": \"\", \"parent\": 3, \"prob\": -9.725519180297852}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 31\n",
      "data: [{\"content\": \"9\", \"parent\": 0, \"prob\": -5.570975303649902}, {\"content\": \",\", \"parent\": 1, \"prob\": -6.445975303649902}, {\"content\": \"2\", \"parent\": 2, \"prob\": -6.9730939865112305}, {\"content\": \"8\", \"parent\": 2, \"prob\": -7.973093509674072}, {\"content\": \"\", \"parent\": 3, \"prob\": -8.661349296569824}, {\"content\": \"2\", \"parent\": 4, \"prob\": -10.679024696350098}, {\"content\": \"8\", \"parent\": 4, \"prob\": -12.554024696350098}, {\"content\": \"\", \"parent\": 5, \"prob\": -9.837258338928223}, {\"content\": \"2\", \"parent\": 6, \"prob\": -12.775520324707031}, {\"content\": \"8\", \"parent\": 6, \"prob\": -13.775520324707031}, {\"content\": \"2\", \"parent\": 7, \"prob\": -8.074698448181152}, {\"content\": \"8\", \"parent\": 7, \"prob\": -8.699698448181152}, {\"content\": \"\", \"parent\": 0, \"prob\": -10.278193473815918}, {\"content\": \"2\", \"parent\": 1, \"prob\": -12.207939147949219}, {\"content\": \"8\", \"parent\": 1, \"prob\": -13.832939147949219}, {\"content\": \"\", \"parent\": 2, \"prob\": -10.466838836669922}, {\"content\": \"2\", \"parent\": 3, \"prob\": -12.997989654541016}, {\"content\": \"8\", \"parent\": 3, \"prob\": -14.122989654541016}, {\"content\": \",\", \"parent\": 4, \"prob\": -8.9369535446167}, {\"content\": \"9\", \"parent\": 5, \"prob\": -9.1869535446167}, {\"content\": \"in\", \"parent\": 6, \"prob\": -5.6331048011779785}, {\"content\": \"and\", \"parent\": 7, \"prob\": -7.703482627868652}, {\"content\": \"mountain\", \"parent\": 0, \"prob\": -8.936734199523926}, {\"content\": \"range\", \"parent\": 0, \"prob\": -10.311734199523926}, {\"content\": \"on\", \"parent\": 1, \"prob\": -7.521390914916992}, {\"content\": \"and\", \"parent\": 1, \"prob\": -8.021390914916992}, {\"content\": \",\", \"parent\": 1, \"prob\": -8.396390914916992}, {\"content\": \"H\", \"parent\": 2, \"prob\": -9.387995719909668}, {\"content\": \"mountain\", \"parent\": 2, \"prob\": -12.387995719909668}, {\"content\": \"range\", \"parent\": 2, \"prob\": -13.262995719909668}, {\"content\": \"2\", \"parent\": 3, \"prob\": -6.748657703399658}, {\"content\": \"3\", \"parent\": 3, \"prob\": -9.1236572265625}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 23\n",
      "data: [{\"content\": \",\", \"parent\": 0, \"prob\": -5.570975303649902}, {\"content\": \"8\", \"parent\": 1, \"prob\": -6.44598388671875}, {\"content\": \"9\", \"parent\": 2, \"prob\": -6.9730939865112305}, {\"content\": \",\", \"parent\": 3, \"prob\": -7.973093509674072}, {\"content\": \"2\", \"parent\": 4, \"prob\": -8.942499160766602}, {\"content\": \"8\", \"parent\": 4, \"prob\": -10.067499160766602}, {\"content\": \"9\", \"parent\": 5, \"prob\": -10.679024696350098}, {\"content\": \",\", \"parent\": 6, \"prob\": -12.554024696350098}, {\"content\": \"2\", \"parent\": 7, \"prob\": -10.265958786010742}, {\"content\": \"8\", \"parent\": 7, \"prob\": -10.890958786010742}, {\"content\": \"9\", \"parent\": 0, \"prob\": -12.775520324707031}, {\"content\": \",\", \"parent\": 1, \"prob\": -13.775520324707031}, {\"content\": \"9\", \"parent\": 2, \"prob\": -8.074698448181152}, {\"content\": \",\", \"parent\": 3, \"prob\": -8.699698448181152}, {\"content\": \"2\", \"parent\": 4, \"prob\": -10.626638412475586}, {\"content\": \"8\", \"parent\": 4, \"prob\": -11.501638412475586}, {\"content\": \"9\", \"parent\": 5, \"prob\": -12.207939147949219}, {\"content\": \",\", \"parent\": 6, \"prob\": -13.832939147949219}, {\"content\": \"2\", \"parent\": 7, \"prob\": -10.940916061401367}, {\"content\": \"8\", \"parent\": 7, \"prob\": -11.440916061401367}, {\"content\": \"9\", \"parent\": 0, \"prob\": -12.997989654541016}, {\"content\": \",\", \"parent\": 1, \"prob\": -14.122989654541016}, {\"content\": \"8\", \"parent\": 2, \"prob\": -8.93696117401123}, {\"content\": \",\", \"parent\": 3, \"prob\": -9.1869535446167}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \"0\", \"parent\": 0, \"prob\": -5.570975303649902}, {\"content\": \"4\", \"parent\": 1, \"prob\": -6.44598388671875}, {\"content\": \",\", \"parent\": 2, \"prob\": -6.9730939865112305}, {\"content\": \"8\", \"parent\": 3, \"prob\": -7.973111629486084}, {\"content\": \"9\", \"parent\": 4, \"prob\": -8.942499160766602}, {\"content\": \",\", \"parent\": 5, \"prob\": -10.067499160766602}, {\"content\": \",\", \"parent\": 6, \"prob\": -10.679024696350098}, {\"content\": \"8\", \"parent\": 7, \"prob\": -12.55405044555664}, {\"content\": \"9\", \"parent\": 0, \"prob\": -10.265958786010742}, {\"content\": \",\", \"parent\": 1, \"prob\": -10.890958786010742}, {\"content\": \",\", \"parent\": 2, \"prob\": -12.775520324707031}, {\"content\": \"8\", \"parent\": 3, \"prob\": -13.775548934936523}, {\"content\": \",\", \"parent\": 4, \"prob\": -8.074698448181152}, {\"content\": \"8\", \"parent\": 5, \"prob\": -8.699712753295898}, {\"content\": \"9\", \"parent\": 6, \"prob\": -10.626638412475586}, {\"content\": \",\", \"parent\": 7, \"prob\": -11.501638412475586}, {\"content\": \",\", \"parent\": 0, \"prob\": -12.207939147949219}, {\"content\": \"8\", \"parent\": 1, \"prob\": -13.832967758178711}, {\"content\": \"9\", \"parent\": 2, \"prob\": -10.940916061401367}, {\"content\": \",\", \"parent\": 3, \"prob\": -11.440916061401367}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 20\n",
      "data: [{\"content\": \"2\", \"parent\": 0, \"prob\": -5.64986515045166}, {\"content\": \"3\", \"parent\": 0, \"prob\": -8.14986515045166}, {\"content\": \"8\", \"parent\": 1, \"prob\": -6.446245193481445}, {\"content\": \"0\", \"parent\": 2, \"prob\": -6.9730939865112305}, {\"content\": \"4\", \"parent\": 3, \"prob\": -7.973111629486084}, {\"content\": \",\", \"parent\": 4, \"prob\": -8.942499160766602}, {\"content\": \"8\", \"parent\": 5, \"prob\": -10.067521095275879}, {\"content\": \"0\", \"parent\": 6, \"prob\": -10.679024696350098}, {\"content\": \"4\", \"parent\": 7, \"prob\": -12.55405044555664}, {\"content\": \",\", \"parent\": 0, \"prob\": -10.265958786010742}, {\"content\": \"8\", \"parent\": 1, \"prob\": -10.890972137451172}, {\"content\": \"0\", \"parent\": 2, \"prob\": -12.775520324707031}, {\"content\": \"4\", \"parent\": 3, \"prob\": -13.775548934936523}, {\"content\": \"0\", \"parent\": 4, \"prob\": -8.074698448181152}, {\"content\": \"4\", \"parent\": 5, \"prob\": -8.699712753295898}, {\"content\": \",\", \"parent\": 6, \"prob\": -10.626638412475586}, {\"content\": \"8\", \"parent\": 7, \"prob\": -11.501657485961914}, {\"content\": \"0\", \"parent\": 0, \"prob\": -12.207939147949219}, {\"content\": \"4\", \"parent\": 1, \"prob\": -13.832967758178711}, {\"content\": \",\", \"parent\": 2, \"prob\": -10.940916061401367}, {\"content\": \"8\", \"parent\": 3, \"prob\": -11.440933227539062}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 23\n",
      "data: [{\"content\": \"9\", \"parent\": 0, \"prob\": -5.64986515045166}, {\"content\": \"2\", \"parent\": 1, \"prob\": -8.228754997253418}, {\"content\": \"1\", \"parent\": 1, \"prob\": -10.728754997253418}, {\"content\": \".\", \"parent\": 2, \"prob\": -6.647674560546875}, {\"content\": \"meters\", \"parent\": 2, \"prob\": -8.147674560546875}, {\"content\": \"2\", \"parent\": 3, \"prob\": -7.0279765129089355}, {\"content\": \"3\", \"parent\": 3, \"prob\": -9.902976036071777}, {\"content\": \"8\", \"parent\": 4, \"prob\": -7.9736647605896}, {\"content\": \"0\", \"parent\": 5, \"prob\": -8.942499160766602}, {\"content\": \"4\", \"parent\": 6, \"prob\": -10.067521095275879}, {\"content\": \"2\", \"parent\": 7, \"prob\": -10.717065811157227}, {\"content\": \"8\", \"parent\": 0, \"prob\": -12.554159164428711}, {\"content\": \"0\", \"parent\": 1, \"prob\": -10.265958786010742}, {\"content\": \"4\", \"parent\": 2, \"prob\": -10.890972137451172}, {\"content\": \"2\", \"parent\": 3, \"prob\": -12.796062469482422}, {\"content\": \"8\", \"parent\": 4, \"prob\": -13.775614738464355}, {\"content\": \"2\", \"parent\": 5, \"prob\": -8.112739562988281}, {\"content\": \"8\", \"parent\": 6, \"prob\": -8.700422286987305}, {\"content\": \"0\", \"parent\": 7, \"prob\": -10.626638412475586}, {\"content\": \"4\", \"parent\": 0, \"prob\": -11.501657485961914}, {\"content\": \"2\", \"parent\": 1, \"prob\": -12.250938415527344}, {\"content\": \"3\", \"parent\": 1, \"prob\": -15.375938415527344}, {\"content\": \"8\", \"parent\": 2, \"prob\": -13.833064079284668}, {\"content\": \"0\", \"parent\": 3, \"prob\": -10.940916061401367}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 25\n",
      "data: [{\"content\": \"feet\", \"parent\": 0, \"prob\": -5.649869441986084}, {\"content\": \"feet\", \"parent\": 1, \"prob\": -8.229456901550293}, {\"content\": \".\", \"parent\": 2, \"prob\": -11.07755184173584}, {\"content\": \"feet\", \"parent\": 2, \"prob\": -11.95255184173584}, {\"content\": \"8\", \"parent\": 3, \"prob\": -6.647675037384033}, {\"content\": \"(\", \"parent\": 4, \"prob\": -8.149431228637695}, {\"content\": \"9\", \"parent\": 5, \"prob\": -7.0279765129089355}, {\"content\": \"2\", \"parent\": 6, \"prob\": -10.003183364868164}, {\"content\": \"1\", \"parent\": 6, \"prob\": -12.253183364868164}, {\"content\": \".\", \"parent\": 7, \"prob\": -8.175104141235352}, {\"content\": \"meters\", \"parent\": 7, \"prob\": -9.675104141235352}, {\"content\": \"2\", \"parent\": 0, \"prob\": -8.997381210327148}, {\"content\": \"3\", \"parent\": 0, \"prob\": -11.872381210327148}, {\"content\": \"8\", \"parent\": 1, \"prob\": -10.068230628967285}, {\"content\": \"9\", \"parent\": 2, \"prob\": -10.717065811157227}, {\"content\": \".\", \"parent\": 3, \"prob\": -12.555484771728516}, {\"content\": \"2\", \"parent\": 4, \"prob\": -10.295709609985352}, {\"content\": \"8\", \"parent\": 5, \"prob\": -10.891403198242188}, {\"content\": \"9\", \"parent\": 6, \"prob\": -12.796062469482422}, {\"content\": \".\", \"parent\": 7, \"prob\": -13.77731704711914}, {\"content\": \"9\", \"parent\": 0, \"prob\": -8.112739562988281}, {\"content\": \".\", \"parent\": 1, \"prob\": -8.827381134033203}, {\"content\": \"meters\", \"parent\": 1, \"prob\": -10.827381134033203}, {\"content\": \"2\", \"parent\": 2, \"prob\": -10.675226211547852}, {\"content\": \"3\", \"parent\": 2, \"prob\": -13.675226211547852}, {\"content\": \"8\", \"parent\": 3, \"prob\": -11.50236701965332}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 23\n",
      "data: [{\"content\": \"(\", \"parent\": 0, \"prob\": -5.650635242462158}, {\"content\": \"(\", \"parent\": 1, \"prob\": -8.22994613647461}, {\"content\": \"7\", \"parent\": 2, \"prob\": -11.077559471130371}, {\"content\": \"(\", \"parent\": 3, \"prob\": -11.957319259643555}, {\"content\": \"6\", \"parent\": 4, \"prob\": -6.647676944732666}, {\"content\": \"2\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \"feet\", \"parent\": 6, \"prob\": -7.027980327606201}, {\"content\": \"feet\", \"parent\": 7, \"prob\": -10.003637313842773}, {\"content\": \".\", \"parent\": 0, \"prob\": -12.640714645385742}, {\"content\": \"feet\", \"parent\": 0, \"prob\": -13.390714645385742}, {\"content\": \"8\", \"parent\": 1, \"prob\": -8.175105094909668}, {\"content\": \"(\", \"parent\": 2, \"prob\": -9.690423011779785}, {\"content\": \"9\", \"parent\": 3, \"prob\": -8.997381210327148}, {\"content\": \"2\", \"parent\": 4, \"prob\": -11.972588539123535}, {\"content\": \"1\", \"parent\": 4, \"prob\": -14.222588539123535}, {\"content\": \".\", \"parent\": 5, \"prob\": -10.38152027130127}, {\"content\": \"meters\", \"parent\": 5, \"prob\": -11.38152027130127}, {\"content\": \"feet\", \"parent\": 6, \"prob\": -10.717158317565918}, {\"content\": \"8\", \"parent\": 7, \"prob\": -12.555484771728516}, {\"content\": \"9\", \"parent\": 0, \"prob\": -10.295709609985352}, {\"content\": \".\", \"parent\": 1, \"prob\": -11.051650047302246}, {\"content\": \"meters\", \"parent\": 1, \"prob\": -12.801650047302246}, {\"content\": \"feet\", \"parent\": 2, \"prob\": -12.796982765197754}, {\"content\": \"8\", \"parent\": 3, \"prob\": -13.77731704711914}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 21\n",
      "data: [{\"content\": \"8\", \"parent\": 0, \"prob\": -5.655330181121826}, {\"content\": \"8\", \"parent\": 1, \"prob\": -8.246216773986816}, {\"content\": \"feet\", \"parent\": 2, \"prob\": -11.07774829864502}, {\"content\": \"8\", \"parent\": 3, \"prob\": -11.95927906036377}, {\"content\": \"meters\", \"parent\": 4, \"prob\": -6.647677898406982}, {\"content\": \"9\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \"(\", \"parent\": 6, \"prob\": -7.059189796447754}, {\"content\": \"(\", \"parent\": 7, \"prob\": -10.007145881652832}, {\"content\": \"7\", \"parent\": 0, \"prob\": -12.640717506408691}, {\"content\": \"(\", \"parent\": 1, \"prob\": -13.536516189575195}, {\"content\": \"or\", \"parent\": 1, \"prob\": -15.411516189575195}, {\"content\": \"6\", \"parent\": 2, \"prob\": -8.175107955932617}, {\"content\": \"2\", \"parent\": 3, \"prob\": -9.69463062286377}, {\"content\": \"feet\", \"parent\": 4, \"prob\": -8.997384071350098}, {\"content\": \"feet\", \"parent\": 5, \"prob\": -11.973102569580078}, {\"content\": \".\", \"parent\": 6, \"prob\": -14.57146167755127}, {\"content\": \"feet\", \"parent\": 6, \"prob\": -15.44646167755127}, {\"content\": \"8\", \"parent\": 7, \"prob\": -10.38152027130127}, {\"content\": \"(\", \"parent\": 0, \"prob\": -11.388062477111816}, {\"content\": \"(\", \"parent\": 1, \"prob\": -10.725554466247559}, {\"content\": \"6\", \"parent\": 2, \"prob\": -12.555486679077148}, {\"content\": \"feet\", \"parent\": 3, \"prob\": -10.295714378356934}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 21\n",
      "data: [{\"content\": \",\", \"parent\": 0, \"prob\": -5.655330181121826}, {\"content\": \",\", \"parent\": 1, \"prob\": -8.246216773986816}, {\"content\": \"(\", \"parent\": 2, \"prob\": -11.078152656555176}, {\"content\": \",\", \"parent\": 3, \"prob\": -11.95927906036377}, {\"content\": \"(\", \"parent\": 4, \"prob\": -6.647763729095459}, {\"content\": \",\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \"8\", \"parent\": 6, \"prob\": -7.0690436363220215}, {\"content\": \"8\", \"parent\": 7, \"prob\": -10.056132316589355}, {\"content\": \"or\", \"parent\": 7, \"prob\": -13.056132316589355}, {\"content\": \"feet\", \"parent\": 0, \"prob\": -12.641051292419434}, {\"content\": \"8\", \"parent\": 1, \"prob\": -13.540628433227539}, {\"content\": \"\", \"parent\": 2, \"prob\": -15.41694450378418}, {\"content\": \"meters\", \"parent\": 3, \"prob\": -8.175108909606934}, {\"content\": \"9\", \"parent\": 4, \"prob\": -9.69463062286377}, {\"content\": \"(\", \"parent\": 5, \"prob\": -9.003937721252441}, {\"content\": \"(\", \"parent\": 6, \"prob\": -11.975314140319824}, {\"content\": \"7\", \"parent\": 7, \"prob\": -14.571467399597168}, {\"content\": \"(\", \"parent\": 0, \"prob\": -15.487565994262695}, {\"content\": \"or\", \"parent\": 0, \"prob\": -18.737565994262695}, {\"content\": \"6\", \"parent\": 1, \"prob\": -10.381522178649902}, {\"content\": \"2\", \"parent\": 2, \"prob\": -11.39102840423584}, {\"content\": \"8\", \"parent\": 3, \"prob\": -10.75808334350586}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 20\n",
      "data: [{\"content\": \"8\", \"parent\": 0, \"prob\": -5.655330181121826}, {\"content\": \"8\", \"parent\": 1, \"prob\": -8.246216773986816}, {\"content\": \"8\", \"parent\": 2, \"prob\": -11.078794479370117}, {\"content\": \"8\", \"parent\": 3, \"prob\": -11.95927906036377}, {\"content\": \"2\", \"parent\": 4, \"prob\": -6.648175239562988}, {\"content\": \"0\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \",\", \"parent\": 6, \"prob\": -7.0690436363220215}, {\"content\": \",\", \"parent\": 7, \"prob\": -10.056132316589355}, {\"content\": \"about\", \"parent\": 0, \"prob\": -13.646614074707031}, {\"content\": \"\", \"parent\": 0, \"prob\": -13.896613121032715}, {\"content\": \"(\", \"parent\": 1, \"prob\": -12.643106460571289}, {\"content\": \",\", \"parent\": 2, \"prob\": -13.540628433227539}, {\"content\": \"8\", \"parent\": 3, \"prob\": -15.416966438293457}, {\"content\": \"(\", \"parent\": 4, \"prob\": -8.175827980041504}, {\"content\": \",\", \"parent\": 5, \"prob\": -9.69463062286377}, {\"content\": \"8\", \"parent\": 6, \"prob\": -9.0107421875}, {\"content\": \"8\", \"parent\": 7, \"prob\": -12.001931190490723}, {\"content\": \"feet\", \"parent\": 0, \"prob\": -14.571794509887695}, {\"content\": \"8\", \"parent\": 1, \"prob\": -15.490071296691895}, {\"content\": \"\", \"parent\": 2, \"prob\": -18.74446678161621}, {\"content\": \"meters\", \"parent\": 3, \"prob\": -10.381523132324219}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \"4\", \"parent\": 0, \"prob\": -5.655453681945801}, {\"content\": \"4\", \"parent\": 1, \"prob\": -8.25483226776123}, {\"content\": \",\", \"parent\": 2, \"prob\": -11.078794479370117}, {\"content\": \"4\", \"parent\": 3, \"prob\": -11.959280014038086}, {\"content\": \"9\", \"parent\": 4, \"prob\": -6.648175239562988}, {\"content\": \"2\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \"8\", \"parent\": 6, \"prob\": -7.0690436363220215}, {\"content\": \"8\", \"parent\": 7, \"prob\": -10.056132316589355}, {\"content\": \"\", \"parent\": 0, \"prob\": -13.646614074707031}, {\"content\": \"8\", \"parent\": 1, \"prob\": -13.896660804748535}, {\"content\": \"8\", \"parent\": 2, \"prob\": -12.644831657409668}, {\"content\": \"8\", \"parent\": 3, \"prob\": -13.540628433227539}, {\"content\": \",\", \"parent\": 4, \"prob\": -15.416966438293457}, {\"content\": \"2\", \"parent\": 5, \"prob\": -8.176600456237793}, {\"content\": \"0\", \"parent\": 6, \"prob\": -9.69463062286377}, {\"content\": \",\", \"parent\": 7, \"prob\": -9.0107421875}, {\"content\": \",\", \"parent\": 0, \"prob\": -12.001931190490723}, {\"content\": \"(\", \"parent\": 1, \"prob\": -14.573527336120605}, {\"content\": \",\", \"parent\": 2, \"prob\": -15.490071296691895}, {\"content\": \"8\", \"parent\": 3, \"prob\": -18.744474411010742}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 20\n",
      "data: [{\"content\": \"8\", \"parent\": 0, \"prob\": -5.658631324768066}, {\"content\": \"9\", \"parent\": 1, \"prob\": -8.381760597229004}, {\"content\": \"8\", \"parent\": 1, \"prob\": -10.381760597229004}, {\"content\": \"8\", \"parent\": 2, \"prob\": -11.078794479370117}, {\"content\": \"8\", \"parent\": 3, \"prob\": -11.97743034362793}, {\"content\": \",\", \"parent\": 4, \"prob\": -6.648175239562988}, {\"content\": \"9\", \"parent\": 5, \"prob\": -8.152002334594727}, {\"content\": \"4\", \"parent\": 6, \"prob\": -7.0690836906433105}, {\"content\": \"4\", \"parent\": 7, \"prob\": -10.067184448242188}, {\"content\": \"8\", \"parent\": 0, \"prob\": -13.646723747253418}, {\"content\": \",\", \"parent\": 1, \"prob\": -13.896660804748535}, {\"content\": \",\", \"parent\": 2, \"prob\": -12.644831657409668}, {\"content\": \"4\", \"parent\": 3, \"prob\": -13.540629386901855}, {\"content\": \"8\", \"parent\": 4, \"prob\": -15.416966438293457}, {\"content\": \"9\", \"parent\": 5, \"prob\": -8.176600456237793}, {\"content\": \"2\", \"parent\": 6, \"prob\": -9.69463062286377}, {\"content\": \"8\", \"parent\": 7, \"prob\": -9.0107421875}, {\"content\": \"8\", \"parent\": 0, \"prob\": -12.001931190490723}, {\"content\": \"8\", \"parent\": 1, \"prob\": -14.574710845947266}, {\"content\": \"8\", \"parent\": 2, \"prob\": -15.490071296691895}, {\"content\": \",\", \"parent\": 3, \"prob\": -18.744474411010742}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 23\n",
      "data: [{\"content\": \"meters\", \"parent\": 0, \"prob\": -6.132713317871094}, {\"content\": \".\", \"parent\": 0, \"prob\": -6.6327128410339355}, {\"content\": \"meters\", \"parent\": 1, \"prob\": -8.381780624389648}, {\"content\": \".\", \"parent\": 2, \"prob\": -10.54198932647705}, {\"content\": \"meters\", \"parent\": 2, \"prob\": -12.29198932647705}, {\"content\": \"4\", \"parent\": 3, \"prob\": -11.078794479370117}, {\"content\": \".\", \"parent\": 4, \"prob\": -12.364302635192871}, {\"content\": \"meters\", \"parent\": 4, \"prob\": -13.114302635192871}, {\"content\": \"0\", \"parent\": 5, \"prob\": -6.648175239562988}, {\"content\": \"feet\", \"parent\": 6, \"prob\": -8.152048110961914}, {\"content\": \"8\", \"parent\": 7, \"prob\": -7.074317455291748}, {\"content\": \"9\", \"parent\": 0, \"prob\": -10.194112777709961}, {\"content\": \"8\", \"parent\": 0, \"prob\": -12.194112777709961}, {\"content\": \",\", \"parent\": 1, \"prob\": -13.646723747253418}, {\"content\": \"8\", \"parent\": 2, \"prob\": -13.896660804748535}, {\"content\": \"8\", \"parent\": 3, \"prob\": -12.644831657409668}, {\"content\": \"8\", \"parent\": 4, \"prob\": -13.578670501708984}, {\"content\": \"4\", \"parent\": 5, \"prob\": -15.416974067687988}, {\"content\": \",\", \"parent\": 6, \"prob\": -8.176600456237793}, {\"content\": \"9\", \"parent\": 7, \"prob\": -9.69463062286377}, {\"content\": \"4\", \"parent\": 0, \"prob\": -9.010777473449707}, {\"content\": \"4\", \"parent\": 1, \"prob\": -12.016098976135254}, {\"content\": \",\", \"parent\": 2, \"prob\": -14.574710845947266}, {\"content\": \"4\", \"parent\": 3, \"prob\": -15.490072250366211}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 28\n",
      "data: [{\"content\": \").\", \"parent\": 0, \"prob\": -6.612161636352539}, {\"content\": \")\", \"parent\": 0, \"prob\": -7.112161636352539}, {\"content\": \"8\", \"parent\": 1, \"prob\": -6.632713317871094}, {\"content\": \").\", \"parent\": 2, \"prob\": -8.698871612548828}, {\"content\": \")\", \"parent\": 2, \"prob\": -9.698871612548828}, {\"content\": \"8\", \"parent\": 3, \"prob\": -10.548705101013184}, {\"content\": \").\", \"parent\": 4, \"prob\": -12.682417869567871}, {\"content\": \")\", \"parent\": 4, \"prob\": -13.432417869567871}, {\"content\": \"8\", \"parent\": 5, \"prob\": -11.079347610473633}, {\"content\": \"8\", \"parent\": 6, \"prob\": -12.364303588867188}, {\"content\": \").\", \"parent\": 7, \"prob\": -13.692537307739258}, {\"content\": \")\", \"parent\": 7, \"prob\": -13.942537307739258}, {\"content\": \"3\", \"parent\": 0, \"prob\": -6.648175239562988}, {\"content\": \")\", \"parent\": 1, \"prob\": -8.365056037902832}, {\"content\": \").\", \"parent\": 1, \"prob\": -9.865056037902832}, {\"content\": \".\", \"parent\": 2, \"prob\": -7.548397064208984}, {\"content\": \"meters\", \"parent\": 2, \"prob\": -8.048397064208984}, {\"content\": \"meters\", \"parent\": 3, \"prob\": -10.19412899017334}, {\"content\": \".\", \"parent\": 4, \"prob\": -12.321043968200684}, {\"content\": \"meters\", \"parent\": 4, \"prob\": -14.321043968200684}, {\"content\": \"8\", \"parent\": 5, \"prob\": -13.646723747253418}, {\"content\": \"4\", \"parent\": 6, \"prob\": -13.95862865447998}, {\"content\": \"5\", \"parent\": 6, \"prob\": -16.708629608154297}, {\"content\": \"4\", \"parent\": 7, \"prob\": -12.644831657409668}, {\"content\": \".\", \"parent\": 0, \"prob\": -13.83060073852539}, {\"content\": \"meters\", \"parent\": 0, \"prob\": -15.08060073852539}, {\"content\": \"8\", \"parent\": 1, \"prob\": -15.418476104736328}, {\"content\": \"0\", \"parent\": 2, \"prob\": -8.176600456237793}, {\"content\": \"feet\", \"parent\": 3, \"prob\": -9.69466495513916}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 40\n",
      "data: [{\"content\": \"However\", \"parent\": 0, \"prob\": -7.127671241760254}, {\"content\": \"Loc\", \"parent\": 0, \"prob\": -8.002671241760254}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -8.627671241760254}, {\"content\": \"and\", \"parent\": 1, \"prob\": -7.240841388702393}, {\"content\": \"above\", \"parent\": 1, \"prob\": -9.74084186553955}, {\"content\": \"in\", \"parent\": 1, \"prob\": -10.61584186553955}, {\"content\": \"6\", \"parent\": 2, \"prob\": -6.632726669311523}, {\"content\": \"However\", \"parent\": 3, \"prob\": -9.138738632202148}, {\"content\": \"Loc\", \"parent\": 3, \"prob\": -10.263738632202148}, {\"content\": \"Mount\", \"parent\": 3, \"prob\": -10.763738632202148}, {\"content\": \"and\", \"parent\": 4, \"prob\": -9.941781997680664}, {\"content\": \"above\", \"parent\": 4, \"prob\": -11.441781997680664}, {\"content\": \"in\", \"parent\": 4, \"prob\": -13.316781997680664}, {\"content\": \"6\", \"parent\": 5, \"prob\": -10.551227569580078}, {\"content\": \"However\", \"parent\": 6, \"prob\": -13.055915832519531}, {\"content\": \"Loc\", \"parent\": 6, \"prob\": -14.430915832519531}, {\"content\": \"Mount\", \"parent\": 6, \"prob\": -14.805915832519531}, {\"content\": \"and\", \"parent\": 7, \"prob\": -13.657816886901855}, {\"content\": \"above\", \"parent\": 7, \"prob\": -15.282816886901855}, {\"content\": \"in\", \"parent\": 7, \"prob\": -16.90781593322754}, {\"content\": \".\", \"parent\": 0, \"prob\": -11.079364776611328}, {\"content\": \"6\", \"parent\": 1, \"prob\": -12.364320755004883}, {\"content\": \"However\", \"parent\": 2, \"prob\": -14.082595825195312}, {\"content\": \"Loc\", \"parent\": 2, \"prob\": -15.457595825195312}, {\"content\": \"Mount\", \"parent\": 2, \"prob\": -15.707595825195312}, {\"content\": \"and\", \"parent\": 3, \"prob\": -14.090106964111328}, {\"content\": \"above\", \"parent\": 3, \"prob\": -16.215106964111328}, {\"content\": \"1\", \"parent\": 4, \"prob\": -6.648175239562988}, {\"content\": \"above\", \"parent\": 5, \"prob\": -8.914833068847656}, {\"content\": \"and\", \"parent\": 5, \"prob\": -9.289833068847656}, {\"content\": \"Loc\", \"parent\": 6, \"prob\": -10.582664489746094}, {\"content\": \"However\", \"parent\": 6, \"prob\": -11.207664489746094}, {\"content\": \"Mount\", \"parent\": 6, \"prob\": -11.332664489746094}, {\"content\": \"8\", \"parent\": 7, \"prob\": -7.548398017883301}, {\"content\": \").\", \"parent\": 0, \"prob\": -8.303503036499023}, {\"content\": \")\", \"parent\": 0, \"prob\": -9.553503036499023}, {\"content\": \").\", \"parent\": 1, \"prob\": -10.39887809753418}, {\"content\": \")\", \"parent\": 1, \"prob\": -11.89887809753418}, {\"content\": \"8\", \"parent\": 2, \"prob\": -12.335208892822266}, {\"content\": \").\", \"parent\": 3, \"prob\": -14.525796890258789}, {\"content\": \")\", \"parent\": 3, \"prob\": -16.02579689025879}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 19\n",
      "data: [{\"content\": \",\", \"parent\": 0, \"prob\": -7.127671718597412}, {\"content\": \"ated\", \"parent\": 1, \"prob\": -8.002671241760254}, {\"content\": \"Ever\", \"parent\": 2, \"prob\": -8.62767219543457}, {\"content\": \"is\", \"parent\": 3, \"prob\": -7.240979194641113}, {\"content\": \"sea\", \"parent\": 4, \"prob\": -9.741168975830078}, {\"content\": \"the\", \"parent\": 5, \"prob\": -10.615846633911133}, {\"content\": \"meters\", \"parent\": 6, \"prob\": -6.632728099822998}, {\"content\": \",\", \"parent\": 7, \"prob\": -9.138739585876465}, {\"content\": \"ated\", \"parent\": 0, \"prob\": -10.263738632202148}, {\"content\": \"Ever\", \"parent\": 1, \"prob\": -10.763741493225098}, {\"content\": \"is\", \"parent\": 2, \"prob\": -9.94201374053955}, {\"content\": \"sea\", \"parent\": 3, \"prob\": -11.442398071289062}, {\"content\": \"the\", \"parent\": 4, \"prob\": -13.316800117492676}, {\"content\": \"meters\", \"parent\": 5, \"prob\": -10.551229476928711}, {\"content\": \",\", \"parent\": 6, \"prob\": -13.055916786193848}, {\"content\": \"ated\", \"parent\": 7, \"prob\": -14.430915832519531}, {\"content\": \"Ever\", \"parent\": 0, \"prob\": -14.80591869354248}, {\"content\": \"is\", \"parent\": 1, \"prob\": -13.657989501953125}, {\"content\": \"sea\", \"parent\": 2, \"prob\": -15.283307075500488}, {\"content\": \"the\", \"parent\": 3, \"prob\": -16.907827377319336}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 29\n",
      "data: [{\"content\": \"if\", \"parent\": 0, \"prob\": -7.274637222290039}, {\"content\": \"it\", \"parent\": 0, \"prob\": -9.274637222290039}, {\"content\": \"in\", \"parent\": 1, \"prob\": -8.002933502197266}, {\"content\": \"est\", \"parent\": 2, \"prob\": -8.62767219543457}, {\"content\": \"located\", \"parent\": 3, \"prob\": -7.528229713439941}, {\"content\": \"part\", \"parent\": 3, \"prob\": -8.653229713439941}, {\"content\": \"level\", \"parent\": 4, \"prob\": -9.741172790527344}, {\"content\": \"H\", \"parent\": 5, \"prob\": -10.639927864074707}, {\"content\": \").\", \"parent\": 6, \"prob\": -6.756616115570068}, {\"content\": \")\", \"parent\": 6, \"prob\": -9.25661563873291}, {\"content\": \"),\", \"parent\": 6, \"prob\": -9.75661563873291}, {\"content\": \"if\", \"parent\": 7, \"prob\": -9.271968841552734}, {\"content\": \"it\", \"parent\": 7, \"prob\": -11.396968841552734}, {\"content\": \"in\", \"parent\": 0, \"prob\": -10.264267921447754}, {\"content\": \"est\", \"parent\": 1, \"prob\": -10.763741493225098}, {\"content\": \"located\", \"parent\": 2, \"prob\": -10.200220108032227}, {\"content\": \"part\", \"parent\": 2, \"prob\": -11.450220108032227}, {\"content\": \"level\", \"parent\": 3, \"prob\": -11.442402839660645}, {\"content\": \"H\", \"parent\": 4, \"prob\": -13.365832328796387}, {\"content\": \"Mah\", \"parent\": 4, \"prob\": -16.36583137512207}, {\"content\": \").\", \"parent\": 5, \"prob\": -10.65163516998291}, {\"content\": \")\", \"parent\": 5, \"prob\": -13.15163516998291}, {\"content\": \"if\", \"parent\": 6, \"prob\": -13.203230857849121}, {\"content\": \"it\", \"parent\": 6, \"prob\": -15.203231811523438}, {\"content\": \"in\", \"parent\": 7, \"prob\": -14.43139934539795}, {\"content\": \"est\", \"parent\": 0, \"prob\": -14.80591869354248}, {\"content\": \"located\", \"parent\": 1, \"prob\": -13.915461540222168}, {\"content\": \"part\", \"parent\": 1, \"prob\": -15.165461540222168}, {\"content\": \"level\", \"parent\": 2, \"prob\": -15.283310890197754}, {\"content\": \"H\", \"parent\": 3, \"prob\": -16.946409225463867}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 35\n",
      "data: [{\"content\": \"you\", \"parent\": 0, \"prob\": -8.11269760131836}, {\"content\": \"we\", \"parent\": 0, \"prob\": -8.11269760131836}, {\"content\": \"considering\", \"parent\": 0, \"prob\": -9.36269760131836}, {\"content\": \"'\", \"parent\": 1, \"prob\": -9.280250549316406}, {\"content\": \"the\", \"parent\": 2, \"prob\": -8.002935409545898}, {\"content\": \"is\", \"parent\": 3, \"prob\": -8.627676963806152}, {\"content\": \"in\", \"parent\": 4, \"prob\": -7.528690814971924}, {\"content\": \"of\", \"parent\": 5, \"prob\": -8.653229713439941}, {\"content\": \".\", \"parent\": 6, \"prob\": -9.796470642089844}, {\"content\": \",\", \"parent\": 6, \"prob\": -13.046470642089844}, {\"content\": \"imal\", \"parent\": 7, \"prob\": -10.63992977142334}, {\"content\": \"However\", \"parent\": 0, \"prob\": -7.5558342933654785}, {\"content\": \"Loc\", \"parent\": 0, \"prob\": -7.8058342933654785}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -8.430834770202637}, {\"content\": \"and\", \"parent\": 1, \"prob\": -9.443936347961426}, {\"content\": \"above\", \"parent\": 1, \"prob\": -11.318936347961426}, {\"content\": \"in\", \"parent\": 1, \"prob\": -13.318936347961426}, {\"content\": \"located\", \"parent\": 2, \"prob\": -10.617046356201172}, {\"content\": \"according\", \"parent\": 2, \"prob\": -10.992046356201172}, {\"content\": \"situated\", \"parent\": 2, \"prob\": -12.367046356201172}, {\"content\": \"although\", \"parent\": 2, \"prob\": -12.492046356201172}, {\"content\": \"though\", \"parent\": 2, \"prob\": -12.742046356201172}, {\"content\": \"as\", \"parent\": 2, \"prob\": -12.867046356201172}, {\"content\": \"making\", \"parent\": 2, \"prob\": -13.117046356201172}, {\"content\": \"you\", \"parent\": 3, \"prob\": -10.146020889282227}, {\"content\": \"we\", \"parent\": 3, \"prob\": -10.146020889282227}, {\"content\": \"considering\", \"parent\": 3, \"prob\": -11.146020889282227}, {\"content\": \"'\", \"parent\": 4, \"prob\": -11.402626991271973}, {\"content\": \"the\", \"parent\": 5, \"prob\": -10.264269828796387}, {\"content\": \"is\", \"parent\": 6, \"prob\": -10.763749122619629}, {\"content\": \"in\", \"parent\": 7, \"prob\": -10.200878143310547}, {\"content\": \"of\", \"parent\": 0, \"prob\": -11.450220108032227}, {\"content\": \".\", \"parent\": 1, \"prob\": -11.518915176391602}, {\"content\": \",\", \"parent\": 1, \"prob\": -14.518915176391602}, {\"content\": \"imal\", \"parent\": 2, \"prob\": -13.36583423614502}, {\"content\": \"al\", \"parent\": 3, \"prob\": -16.36589813232422}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 32\n",
      "data: [{\"content\": \"'\", \"parent\": 0, \"prob\": -8.401442527770996}, {\"content\": \"are\", \"parent\": 0, \"prob\": -9.901442527770996}, {\"content\": \"consider\", \"parent\": 0, \"prob\": -10.651442527770996}, {\"content\": \"consider\", \"parent\": 1, \"prob\": -8.139447212219238}, {\"content\": \"the\", \"parent\": 2, \"prob\": -9.443413734436035}, {\"content\": \"mountains\", \"parent\": 2, \"prob\": -12.943413734436035}, {\"content\": \"height\", \"parent\": 2, \"prob\": -13.943413734436035}, {\"content\": \"s\", \"parent\": 3, \"prob\": -9.280250549316406}, {\"content\": \"H\", \"parent\": 4, \"prob\": -8.18301773071289}, {\"content\": \"Mah\", \"parent\": 4, \"prob\": -9.80801773071289}, {\"content\": \"part\", \"parent\": 5, \"prob\": -9.01523494720459}, {\"content\": \"located\", \"parent\": 5, \"prob\": -9.76523494720459}, {\"content\": \"the\", \"parent\": 6, \"prob\": -7.52869176864624}, {\"content\": \"the\", \"parent\": 7, \"prob\": -8.6532621383667}, {\"content\": \"However\", \"parent\": 0, \"prob\": -10.36830997467041}, {\"content\": \"Loc\", \"parent\": 0, \"prob\": -11.36830997467041}, {\"content\": \"Mount\", \"parent\": 0, \"prob\": -11.36830997467041}, {\"content\": \"according\", \"parent\": 1, \"prob\": -14.045654296875}, {\"content\": \"located\", \"parent\": 1, \"prob\": -14.045654296875}, {\"content\": \"situated\", \"parent\": 1, \"prob\": -15.420654296875}, {\"content\": \"as\", \"parent\": 1, \"prob\": -15.795654296875}, {\"content\": \"making\", \"parent\": 1, \"prob\": -16.045654296875}, {\"content\": \"although\", \"parent\": 1, \"prob\": -16.545654296875}, {\"content\": \"ay\", \"parent\": 2, \"prob\": -10.640310287475586}, {\"content\": \",\", \"parent\": 3, \"prob\": -7.5558342933654785}, {\"content\": \"ated\", \"parent\": 4, \"prob\": -7.805834770202637}, {\"content\": \"Ever\", \"parent\": 5, \"prob\": -8.430838584899902}, {\"content\": \"is\", \"parent\": 6, \"prob\": -9.444182395935059}, {\"content\": \"sea\", \"parent\": 7, \"prob\": -11.318994522094727}, {\"content\": \"the\", \"parent\": 0, \"prob\": -13.318950653076172}, {\"content\": \"in\", \"parent\": 1, \"prob\": -10.620448112487793}, {\"content\": \"to\", \"parent\": 2, \"prob\": -10.992047309875488}, {\"content\": \"in\", \"parent\": 3, \"prob\": -12.370657920837402}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n",
      "event: level\n",
      "id: 33\n",
      "data: [{\"content\": \"re\", \"parent\": 0, \"prob\": -8.401446342468262}, {\"content\": \"asking\", \"parent\": 1, \"prob\": -10.347432136535645}, {\"content\": \"referring\", \"parent\": 1, \"prob\": -11.097432136535645}, {\"content\": \"considering\", \"parent\": 1, \"prob\": -12.847433090209961}, {\"content\": \"the\", \"parent\": 2, \"prob\": -10.68162727355957}, {\"content\": \"the\", \"parent\": 3, \"prob\": -8.159067153930664}, {\"content\": \"highest\", \"parent\": 4, \"prob\": -9.899386405944824}, {\"content\": \"height\", \"parent\": 4, \"prob\": -11.024386405944824}, {\"content\": \"sum\", \"parent\": 4, \"prob\": -12.149386405944824}, {\"content\": \"Earth\", \"parent\": 4, \"prob\": -12.899386405944824}, {\"content\": \"largest\", \"parent\": 4, \"prob\": -14.274386405944824}, {\"content\": \"diameter\", \"parent\": 4, \"prob\": -14.774386405944824}, {\"content\": \"top\", \"parent\": 4, \"prob\": -14.899386405944824}, {\"content\": \"base\", \"parent\": 4, \"prob\": -15.024386405944824}, {\"content\": \"entire\", \"parent\": 4, \"prob\": -15.274385452270508}, {\"content\": \"on\", \"parent\": 5, \"prob\": -13.044185638427734}, {\"content\": \"above\", \"parent\": 5, \"prob\": -15.919185638427734}, {\"content\": \"located\", \"parent\": 5, \"prob\": -16.669185638427734}, {\"content\": \"s\", \"parent\": 6, \"prob\": -13.944330215454102}, {\"content\": \"worth\", \"parent\": 7, \"prob\": -9.383319854736328}, {\"content\": \"important\", \"parent\": 7, \"prob\": -11.883319854736328}, {\"content\": \"imal\", \"parent\": 0, \"prob\": -8.183019638061523}, {\"content\": \"al\", \"parent\": 1, \"prob\": -9.808157920837402}, {\"content\": \"of\", \"parent\": 2, \"prob\": -9.01523494720459}, {\"content\": \"in\", \"parent\": 3, \"prob\": -9.7653226852417}, {\"content\": \"H\", \"parent\": 4, \"prob\": -7.641940593719482}, {\"content\": \"Mah\", \"parent\": 4, \"prob\": -9.76694107055664}, {\"content\": \"H\", \"parent\": 5, \"prob\": -8.65383243560791}, {\"content\": \",\", \"parent\": 6, \"prob\": -10.36830997467041}, {\"content\": \"ated\", \"parent\": 7, \"prob\": -11.36830997467041}, {\"content\": \"Ever\", \"parent\": 0, \"prob\": -11.36831283569336}, {\"content\": \"to\", \"parent\": 1, \"prob\": -14.045655250549316}, {\"content\": \"in\", \"parent\": 2, \"prob\": -14.051369667053223}, {\"content\": \"in\", \"parent\": 3, \"prob\": -15.426223754882812}]\n",
      "\n",
      "\n",
      "\n",
      "num_batches 3\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 22.17 GiB of which 18.38 MiB is free. Including non-PyTorch memory, this process has 22.14 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 120.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 117\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(new_candidates_list), torch\u001b[38;5;241m.\u001b[39mcat(new_candidate_parents_list), torch\u001b[38;5;241m.\u001b[39mcat(new_candidate_logprobs_list)\n\u001b[1;32m    115\u001b[0m it \u001b[38;5;241m=\u001b[39m InferenceTensor()\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m it\u001b[38;5;241m.\u001b[39mcandidates_generator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the highest mountain?\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n",
      "Cell \u001b[0;32mIn[93], line 42\u001b[0m, in \u001b[0;36mInferenceTensor.candidates_generator\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     40\u001b[0m candidates, candidate_logprobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_candidates(text)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_new_tokens):\n\u001b[0;32m---> 42\u001b[0m     candidates, candidate_parents, candidate_logprobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_logprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     candidate_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(candidates[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     44\u001b[0m     candidate_dicts \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[93], line 104\u001b[0m, in \u001b[0;36mInferenceTensor._infer\u001b[0;34m(self, candidates, candidate_logprobs)\u001b[0m\n\u001b[1;32m    101\u001b[0m batch_candidates \u001b[38;5;241m=\u001b[39m candidates[i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    102\u001b[0m batch_candidate_logprobs \u001b[38;5;241m=\u001b[39m candidate_logprobs[i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 104\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# TODO: Pruning step based on K-Means Clustering of embeddings here\u001b[39;00m\n\u001b[1;32m    108\u001b[0m new_batch_candidates, new_batch_candidate_parents, new_batch_candidate_logprobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_p_single_batch(batch_outputs\u001b[38;5;241m.\u001b[39mlogits, batch_candidates, batch_candidate_logprobs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-mini-4k-instruct/d269012bea6fbe38ce7752c8940fea010eea3383/modeling_phi3.py:1299\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1286\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1287\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1288\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1296\u001b[0m )\n\u001b[1;32m   1298\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1299\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m   1302\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 22.17 GiB of which 18.38 MiB is free. Including non-PyTorch memory, this process has 22.14 GiB memory in use. Of the allocated memory 21.80 GiB is allocated by PyTorch, and 120.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import json\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# Not directly comparable to legacy Inference yet --:\n",
    "# - Remove p falloff from original\n",
    "# - Are max candidates and max new tokens taken into account the same way?\n",
    "class InferenceTensor:\n",
    "    def __init__(self):\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map='auto',\n",
    "            trust_remote_code=True,\n",
    "            use_cache=True,\n",
    "            # attn_implementation='flash_attention_2',\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.max_candidates = 20\n",
    "        self.max_new_tokens = 10\n",
    "        self.batch_size = 8\n",
    "        self.p_falloff = 0.5 # UNIMPLEMENTED\n",
    "        self.prune_similar_sequences = True # UNIMPLEMENTED\n",
    "        self.prune_similar_branches = True # UNIMPLEMENTED\n",
    "        self.prune_similar_embeddings = True # UNIMPLEMENTED\n",
    "\n",
    "    def candidates_generator(self, text: str):\n",
    "        print(text)\n",
    "        candidates, candidate_logprobs = self._init_candidates(text)\n",
    "        for i in range(self.max_new_tokens):\n",
    "            candidates, candidate_parents, candidate_logprobs = self._infer(candidates[:self.max_candidates, ...], candidate_logprobs[:self.max_candidates, ...])\n",
    "            candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "            candidate_dicts = []\n",
    "            for i in range(len(candidate_texts)):\n",
    "                candidate_dicts.append({'content': candidate_texts[i], 'parent': candidate_parents[i].item(), 'prob': candidate_logprobs[i].item()})\n",
    "            data = json.dumps(candidate_dicts)\n",
    "            yield f\"event: level\\nid: {i}\\ndata: {data}\\n\\n\"\n",
    "\n",
    "        yield f\"event: level\\nid: END\\ndata: []\\n\\n\"\n",
    "\n",
    "    def _init_candidates(self, text: str):\n",
    "        prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt')\n",
    "        print(self.tokenizer.batch_decode(inputs.input_ids))\n",
    "\n",
    "        candidates = inputs.input_ids.to(self.device)\n",
    "        candidate_logprobs = torch.zeros((1), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        return candidates, candidate_logprobs\n",
    "\n",
    "    def _top_p_single_batch(self, logits, candidates, candidate_logprobs):\n",
    "        last_tok_logits = logits[:, -1, :]\n",
    "        \n",
    "        sorted_logits, sorted_indices = torch.sort(last_tok_logits, descending=True, dim=-1)\n",
    "        sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "        cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        \n",
    "        # Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "        keep_indices = cum_probs < 0.96\n",
    "\n",
    "        # Keep the last element that went over top_p\n",
    "        keep_indices[:, 1:] = keep_indices[:, :-1].clone() # Is this inefficient?\n",
    "        keep_indices[:, 0] = 1  # Always keep the first element\n",
    "        \n",
    "        new_candidate_parents = keep_indices.nonzero()[:, 0]\n",
    "        \n",
    "        # OPTIM: Potential optimization -- have a fixed tensor of size (max_candidates, max_tokens) and copy this into that (batch-aware).\n",
    "        # OPTIM: consider which of these operations can be done in-place to prevent new allocations?\n",
    "        carryover_candidates = candidates.index_select(0, new_candidate_parents)\n",
    "        carryover_candidate_logprobs = candidate_logprobs.index_select(0, new_candidate_parents)  # Not strictly necessary since 1d\n",
    "        \n",
    "        new_candidate_toks = sorted_indices[keep_indices].unsqueeze(1)\n",
    "        new_candidate_tok_logprobs = sorted_probs[keep_indices].log()\n",
    "        \n",
    "        new_candidates = torch.cat([carryover_candidates, new_candidate_toks], dim=1)\n",
    "        new_candidate_logprobs = carryover_candidate_logprobs.add_(new_candidate_tok_logprobs)\n",
    "        \n",
    "        return new_candidates, new_candidate_parents, new_candidate_logprobs\n",
    "        \n",
    "\n",
    "    def _infer(self, candidates, candidate_logprobs):\n",
    "        with torch.inference_mode():\n",
    "            num_batches = (candidates.shape[0] + self.batch_size - 1) // self.batch_size  # Round up to nearest whole number of batches\n",
    "            print('\\nnum_batches', num_batches)\n",
    "            new_candidates_list = []\n",
    "            new_candidate_parents_list = []\n",
    "            new_candidate_logprobs_list = []\n",
    "\n",
    "            for i in range(0, num_batches, 1):\n",
    "                batch_candidates = candidates[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                batch_candidate_logprobs = candidate_logprobs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                batch_outputs = self.model(input_ids=batch_candidates)\n",
    "                \n",
    "                # TODO: Pruning step based on K-Means Clustering of embeddings here\n",
    "                \n",
    "                new_batch_candidates, new_batch_candidate_parents, new_batch_candidate_logprobs = self._top_p_single_batch(batch_outputs.logits, batch_candidates, batch_candidate_logprobs)\n",
    "                new_candidates_list.append(new_batch_candidates)\n",
    "                new_candidate_parents_list.append(new_batch_candidate_parents)\n",
    "                new_candidate_logprobs_list.append(new_batch_candidate_logprobs)\n",
    "                \n",
    "            return torch.cat(new_candidates_list), torch.cat(new_candidate_parents_list), torch.cat(new_candidate_logprobs_list)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
