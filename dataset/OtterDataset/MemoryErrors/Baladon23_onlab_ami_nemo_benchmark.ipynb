{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuda out of memory error\n",
    "\n",
    "If you get Cuda out of memory error, you need to reduce the batch sizes in the downloaded YAML file. (The yaml file will only get downloaded when it is not found in the file system, so you can safely edit and save the file and not have to worry about restarting the notebook later.)\n",
    "\n",
    "## Ref. Speaker_Diarization_Inference.ipynb\n",
    "\n",
    "I believe MSDD failed with CUDA out of memory error, and when restarting the process, TitaNet tried to recalculate the embeddings which is just pointless.\n",
    "See the omegaconf .yaml file for exact model pipeline configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: ClusterDiarizer\n",
      "num_workers: 1\n",
      "sample_rate: 16000\n",
      "batch_size: 1\n",
      "device: null\n",
      "verbose: true\n",
      "diarizer:\n",
      "  manifest_filepath: ???\n",
      "  out_dir: ???\n",
      "  oracle_vad: false\n",
      "  collar: 0.25\n",
      "  ignore_overlap: true\n",
      "  vad:\n",
      "    model_path: vad_multilingual_marblenet\n",
      "    external_vad_manifest: null\n",
      "    parameters:\n",
      "      window_length_in_sec: 0.63\n",
      "      shift_length_in_sec: 0.01\n",
      "      smoothing: false\n",
      "      overlap: 0.5\n",
      "      onset: 0.9\n",
      "      offset: 0.5\n",
      "      pad_onset: 0\n",
      "      pad_offset: 0\n",
      "      min_duration_on: 0\n",
      "      min_duration_off: 0.6\n",
      "      filter_speech_first: true\n",
      "  speaker_embeddings:\n",
      "    model_path: titanet_large\n",
      "    parameters:\n",
      "      window_length_in_sec:\n",
      "      - 3.0\n",
      "      - 2.5\n",
      "      - 2.0\n",
      "      - 1.5\n",
      "      - 1.0\n",
      "      - 0.5\n",
      "      shift_length_in_sec:\n",
      "      - 1.5\n",
      "      - 1.25\n",
      "      - 1.0\n",
      "      - 0.75\n",
      "      - 0.5\n",
      "      - 0.25\n",
      "      multiscale_weights:\n",
      "      - 1\n",
      "      - 1\n",
      "      - 1\n",
      "      - 1\n",
      "      - 1\n",
      "      - 1\n",
      "      save_embeddings: true\n",
      "  clustering:\n",
      "    parameters:\n",
      "      oracle_num_speakers: false\n",
      "      max_num_speakers: 8\n",
      "      enhanced_count_thres: 80\n",
      "      max_rp_threshold: 0.25\n",
      "      sparse_search_volume: 30\n",
      "      maj_vote_spk_count: false\n",
      "      chunk_cluster_count: 50\n",
      "      embeddings_per_chunk: 10000\n",
      "  msdd_model:\n",
      "    model_path: null\n",
      "    parameters:\n",
      "      use_speaker_model_from_ckpt: true\n",
      "      infer_batch_size: 1\n",
      "      sigmoid_threshold:\n",
      "      - 0.7\n",
      "      seq_eval_mode: false\n",
      "      split_infer: true\n",
      "      diar_window_length: 50\n",
      "      overlap_infer_spk_limit: 5\n",
      "  asr:\n",
      "    model_path: stt_en_conformer_ctc_large\n",
      "    parameters:\n",
      "      asr_based_vad: false\n",
      "      asr_based_vad_threshold: 1.0\n",
      "      asr_batch_size: 1\n",
      "      decoder_delay_in_sec: null\n",
      "      word_ts_anchor_offset: null\n",
      "      word_ts_anchor_pos: start\n",
      "      fix_word_ts_with_VAD: false\n",
      "      colored_text: false\n",
      "      print_time: true\n",
      "      break_lines: false\n",
      "    ctc_decoder_parameters:\n",
      "      pretrained_language_model: null\n",
      "      beam_width: 32\n",
      "      alpha: 0.5\n",
      "      beta: 2.5\n",
      "    realigning_lm_parameters:\n",
      "      arpa_language_model: null\n",
      "      min_number_of_words: 3\n",
      "      max_number_of_words: 10\n",
      "      logprob_diff_threshold: 1.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "data_dir = \"/home/kozi/Documents/_onlab_git/ami/\"\n",
    "\n",
    "#MODEL_CONFIG = os.path.join(data_dir,'diar_infer_telephonic.yaml')\n",
    "MODEL_CONFIG = os.path.join(data_dir, 'diar_infer_meeting.yaml')\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    #config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_telephonic.yaml\"\n",
    "    config_url = \"https://github.com/NVIDIA/NeMo/blob/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_meeting.yaml\"\n",
    "    #MODEL_CONFIG = wget.download(config_url, data_dir) # do this manually or change the URL to raw.githubusercontent.com\n",
    "\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-18 17:35:59 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo I 2024-05-18 17:35:59 offline_diar_with_asr_infer:49] Hydra config: name: ClusterDiarizer\n",
      "    num_workers: 1\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    device: null\n",
      "    verbose: true\n",
      "    diarizer:\n",
      "      manifest_filepath: /home/kozi/Documents/_onlab_git/ami/AMItest_input_manifest.Array1-01.json\n",
      "      out_dir: /home/kozi/Documents/_onlab_git/ami/tmp2\n",
      "      oracle_vad: false\n",
      "      collar: 0.25\n",
      "      ignore_overlap: true\n",
      "      vad:\n",
      "        model_path: vad_multilingual_marblenet\n",
      "        external_vad_manifest: null\n",
      "        parameters:\n",
      "          window_length_in_sec: 0.63\n",
      "          shift_length_in_sec: 0.01\n",
      "          smoothing: false\n",
      "          overlap: 0.5\n",
      "          onset: 0.9\n",
      "          offset: 0.5\n",
      "          pad_onset: 0\n",
      "          pad_offset: 0\n",
      "          min_duration_on: 0\n",
      "          min_duration_off: 0.6\n",
      "          filter_speech_first: true\n",
      "      speaker_embeddings:\n",
      "        model_path: titanet_small\n",
      "        parameters:\n",
      "          window_length_in_sec:\n",
      "          - 3.0\n",
      "          - 2.5\n",
      "          - 2.0\n",
      "          - 1.5\n",
      "          - 1.0\n",
      "          - 0.5\n",
      "          shift_length_in_sec:\n",
      "          - 1.5\n",
      "          - 1.25\n",
      "          - 1.0\n",
      "          - 0.75\n",
      "          - 0.5\n",
      "          - 0.25\n",
      "          multiscale_weights:\n",
      "          - 1\n",
      "          - 1\n",
      "          - 1\n",
      "          - 1\n",
      "          - 1\n",
      "          - 1\n",
      "          save_embeddings: true\n",
      "      clustering:\n",
      "        parameters:\n",
      "          oracle_num_speakers: false\n",
      "          max_num_speakers: 8\n",
      "          enhanced_count_thres: 80\n",
      "          max_rp_threshold: 0.25\n",
      "          sparse_search_volume: 30\n",
      "          maj_vote_spk_count: false\n",
      "      msdd_model:\n",
      "        model_path: null\n",
      "        parameters:\n",
      "          use_speaker_model_from_ckpt: true\n",
      "          infer_batch_size: 25\n",
      "          sigmoid_threshold:\n",
      "          - 0.7\n",
      "          seq_eval_mode: false\n",
      "          split_infer: true\n",
      "          diar_window_length: 50\n",
      "          overlap_infer_spk_limit: 5\n",
      "      asr:\n",
      "        model_path: stt_en_quartznet15x5\n",
      "        parameters:\n",
      "          asr_based_vad: true\n",
      "          asr_based_vad_threshold: 1.0\n",
      "          asr_batch_size: null\n",
      "          decoder_delay_in_sec: null\n",
      "          word_ts_anchor_offset: null\n",
      "          word_ts_anchor_pos: start\n",
      "          fix_word_ts_with_VAD: false\n",
      "          colored_text: false\n",
      "          print_time: true\n",
      "          break_lines: false\n",
      "        ctc_decoder_parameters:\n",
      "          pretrained_language_model: null\n",
      "          beam_width: 32\n",
      "          alpha: 0.5\n",
      "          beta: 2.5\n",
      "        realigning_lm_parameters:\n",
      "          arpa_language_model: null\n",
      "          min_number_of_words: 3\n",
      "          max_number_of_words: 10\n",
      "          logprob_diff_threshold: 1.2\n",
      "    \n",
      "[NeMo I 2024-05-18 17:35:59 speaker_utils:93] Number of files to diarize: 16\n",
      "[NeMo I 2024-05-18 17:35:59 cloud:58] Found existing object /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo.\n",
      "[NeMo I 2024-05-18 17:35:59 cloud:64] Re-using file from: /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo\n",
      "[NeMo I 2024-05-18 17:35:59 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo W 2024-05-18 17:36:00 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data2/voices/train_1k.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /asr_set_1.2/train/train_{0..1023}.tar\n",
      "    num_workers: 20\n",
      "    \n",
      "[NeMo W 2024-05-18 17:36:00 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data2/voices/train_1k_samp.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo I 2024-05-18 17:36:00 features:289] PADDING: 16\n",
      "[NeMo I 2024-05-18 17:36:00 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2024-05-18 17:36:03 save_restore_connector:249] Model EncDecCTCModel was successfully restored from /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo.\n",
      "[NeMo W 2024-05-18 17:36:03 decoder_timestamps_utils:171] `ctc_decode` was set to True. Note that this is ignored.\n",
      "Transcribing:   0%|                                       | 0/4 [00:02<?, ?it/s]\n",
      "Error executing job with overrides: ['diarizer.manifest_filepath=/home/kozi/Documents/_onlab_git/ami/AMItest_input_manifest.Array1-01.json', 'diarizer.out_dir=/home/kozi/Documents/_onlab_git/ami/tmp2', 'diarizer.speaker_embeddings.model_path=titanet_small', 'diarizer.asr.model_path=stt_en_quartznet15x5', 'diarizer.asr.parameters.asr_based_vad=True', 'diarizer.speaker_embeddings.parameters.save_embeddings=True']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kozi/Documents/NeMo/examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_with_asr_infer.py\", line 54, in main\n",
      "    word_hyp, word_ts_hyp = asr_decoder_ts.run_ASR(asr_model)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py\", line 433, in run_ASR_QuartzNet_CTC\n",
      "    transcript_logits_list = asr_model.transcribe(\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/models/ctc_models.py\", line 198, in transcribe\n",
      "    logits, logits_len, greedy_predictions = self.forward(\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/core/classes/common.py\", line 1087, in __call__\n",
      "    outputs = wrapped(*args, **kwargs)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/models/ctc_models.py\", line 536, in forward\n",
      "    processed_signal, processed_signal_length = self.preprocessor(\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/core/classes/common.py\", line 1087, in __call__\n",
      "    outputs = wrapped(*args, **kwargs)\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/modules/audio_preprocessing.py\", line 91, in forward\n",
      "    processed_signal, processed_length = self.get_features(input_signal, length)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/modules/audio_preprocessing.py\", line 292, in get_features\n",
      "    return self.featurizer(input_signal, length)\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/parts/preprocessing/features.py\", line 418, in forward\n",
      "    x = self.stft(x)\n",
      "  File \"/home/kozi/Documents/NeMo/nemo/collections/asr/parts/preprocessing/features.py\", line 308, in <lambda>\n",
      "    self.stft = lambda x: torch.stft(\n",
      "  File \"/home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/functional.py\", line 641, in stft\n",
      "    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.27 GiB (GPU 0; 3.94 GiB total capacity; 2.20 GiB already allocated; 227.56 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "# this block of code is only here to test https://github.com/NVIDIA/NeMo/blob/main/examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_with_asr_infer.py\n",
    "!python3 /home/kozi/Documents/NeMo/examples/speaker_tasks/diarization/clustering_diarizer/offline_diar_with_asr_infer.py \\\n",
    "    diarizer.manifest_filepath=\"/home/kozi/Documents/_onlab_git/ami/AMItest_input_manifest.Array1-01.json\" \\\n",
    "    diarizer.out_dir=\"/home/kozi/Documents/_onlab_git/ami/tmp2\" \\\n",
    "    diarizer.speaker_embeddings.model_path=\"titanet_small\" \\\n",
    "    diarizer.asr.model_path=\"stt_en_quartznet15x5\" \\\n",
    "    diarizer.asr.parameters.asr_based_vad=True \\\n",
    "    diarizer.speaker_embeddings.parameters.save_embeddings=True\n",
    "\n",
    "# try\n",
    "#stt_en_quartznet15x5\n",
    "#stt_en_citrinet*\n",
    "#stt_en_conformer_ctc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-18 16:54:02 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo I 2024-05-18 16:54:03 der:176] Cumulative Results for collar 0.0 sec and ignore_overlap False: \n",
      "     FA: 0.0000\t MISS 0.2511\t                 Diarization ER: 0.2988\t, Confusion ER:0.0477\n",
      "[NeMo I 2024-05-18 16:54:04 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap False: \n",
      "     FA: 0.0000\t MISS 0.1944\t                 Diarization ER: 0.2279\t, Confusion ER:0.0335\n",
      "[NeMo I 2024-05-18 16:54:04 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap True: \n",
      "     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0398\t, Confusion ER:0.0398\n",
      "[NeMo I 2024-05-18 16:54:05 diarization_utils:1259] \n",
      "    DER                : 0.0398                      \n",
      "    FA                 : 0.0000                      \n",
      "    MISS               : 0.0000                      \n",
      "    CER                : 0.0398                      \n",
      "    Spk. counting acc. : 1.0000\n",
      "[NeMo I 2024-05-18 16:54:05 diarization_utils:1154] Writing /home/kozi/Documents/_onlab_git/ami/nemo_diar_score_output//pred_rttms/ctm_eval.csv\n"
     ]
    }
   ],
   "source": [
    "# this block of code is to calculate RTTM scores NeMo style\n",
    "\n",
    "!python /home/kozi/Documents/NeMo/scripts/speaker_tasks/eval_diar_with_asr.py \\\n",
    " --hyp_rttm_list=\"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/hyp_rttm_list.list\" \\\n",
    " --ref_rttm_list=\"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/ref_rttm_list.list\" \\\n",
    " --root_path=\"/home/kozi/Documents/_onlab_git/ami/nemo_diar_score_output/\"\n",
    "# the output directory stores a .csv file that contains the mapping of the reference RTTM file speaker IDs to the hypothesis ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-18 16:54:30 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo I 2024-05-18 16:54:30 der:176] Cumulative Results for collar 0.0 sec and ignore_overlap False: \n",
      "     FA: 0.0000\t MISS 0.2401\t                 Diarization ER: 0.2779\t, Confusion ER:0.0378\n",
      "[NeMo I 2024-05-18 16:54:31 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap False: \n",
      "     FA: 0.0000\t MISS 0.1971\t                 Diarization ER: 0.2226\t, Confusion ER:0.0255\n",
      "[NeMo I 2024-05-18 16:54:31 der:176] Cumulative Results for collar 0.25 sec and ignore_overlap True: \n",
      "     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0283\t, Confusion ER:0.0283\n",
      "[NeMo I 2024-05-18 16:54:31 diarization_utils:1259] \n",
      "    DER                : 0.0283                      \n",
      "    FA                 : 0.0000                      \n",
      "    MISS               : 0.0000                      \n",
      "    CER                : 0.0283                      \n",
      "    Spk. counting acc. : 1.0000\n",
      "[NeMo I 2024-05-18 16:54:31 diarization_utils:1154] Writing /home/kozi/Documents/_onlab_git/ami/nemo_diar_score_output//pred_rttms/ctm_eval.csv\n"
     ]
    }
   ],
   "source": [
    "!python /home/kozi/Documents/NeMo/scripts/speaker_tasks/eval_diar_with_asr.py \\\n",
    " --hyp_rttm_list=\"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/hyp2.list\" \\\n",
    " --ref_rttm_list=\"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/ref2.list\" \\\n",
    " --root_path=\"/home/kozi/Documents/_onlab_git/ami/nemo_diar_score_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref. https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/asr/speaker_diarization/datasets.html#ami-meeting-corpus\n",
    "# see <NeMo_git_root>/examples/speaker_tasks/diarization/conf/inference/diar_infer_meeting.yaml\n",
    "\n",
    "#python3 /home/kozi/Documents/NeMo/scripts/dataset_processing/speaker_tasks/get_ami_data.py --test_manifest_filepath /home/kozi/Documents/_onlab_git/ami/AMItest_input_manifest.json\n",
    "\n",
    "# <NeMo_git_root>/examples/speaker_tasks/diarization/conf/inference/diar_infer_meeting.yaml\n",
    "\n",
    "config.diarizer.manifest_filepath=\"/home/kozi/Documents/_onlab_git/ami/AMItest_input_manifest.Array1-01.json\"\n",
    "config.diarizer.oracle_num_speakers=None # Performing unknown number of speaker case\n",
    "#config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "config.diarizer.oracle_vad=True # Use oracle VAD extracted from RTTM files.\n",
    "config.diarizer.collar=0.25\n",
    "config.diarizer.ignore_overlap=True\n",
    "#config.diarizer.speaker_embeddings.model_path=\"titanet_large\"\n",
    "\n",
    "config.diarizer.out_dir = \"/home/kozi/Documents/_onlab_git/ami/tmp/\" # Directory to store intermediate files and prediction outputs\n",
    "pretrained_speaker_model = 'titanet_large'\n",
    "config.diarizer.speaker_embeddings.batch_size = 1\n",
    "#config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [1.5,1.25,1.0,0.75,0.5] \n",
    "#config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [0.75,0.625,0.5,0.375,0.1] \n",
    "#config.diarizer.speaker_embeddings.parameters.multiscale_weights= [1,1,1,1,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to only use the cell before this...\n",
    "# okay this cell is not necessary, do not run it.\n",
    "data_dir = \"/home/kozi/Documents/_onlab_git/ami/\"\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "MODEL_CONFIG = os.path.join(data_dir,'diar_infer_telephonic.yaml')\n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    config_url = \"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/diar_infer_telephonic.yaml\"\n",
    "    MODEL_CONFIG = wget.download(config_url,data_dir)\n",
    "\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "print(OmegaConf.to_yaml(config))\n",
    "\n",
    "config.diarizer.manifest_filepath=\"/home/kozi/Documents/ami_by_nemo/AMItest_input_manifest.Array1-01.json\"\n",
    "config.diarizer.out_dir = \"/home/kozi/Documents/ami_by_nemo/tmp\" # Directory to store intermediate files and prediction outputs\n",
    "#pretrained_speaker_model = 'titanet_large'\n",
    "config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "config.diarizer.speaker_embeddings.parameters.window_length_in_sec = [1.5,1.25,1.0,0.75,0.5] \n",
    "config.diarizer.speaker_embeddings.parameters.shift_length_in_sec = [0.75,0.625,0.5,0.375,0.1] \n",
    "config.diarizer.speaker_embeddings.parameters.multiscale_weights= [1,1,1,1,1] \n",
    "config.diarizer.oracle_vad = True # ----> ORACLE VAD \n",
    "config.diarizer.clustering.parameters.oracle_num_speakers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-16 23:36:22 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2024-05-16 23:36:22 cloud:58] Found existing object /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-16 23:36:22 cloud:64] Re-using file from: /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2024-05-16 23:36:22 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-16 23:36:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-16 23:36:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-16 23:36:23 features:289] PADDING: 16\n",
      "[NeMo I 2024-05-16 23:36:23 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2024-05-16 23:36:23 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/kozi/.cache/torch/NeMo/NeMo_1.21.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-16 23:36:23 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-16 23:36:23 speaker_utils:93] Number of files to diarize: 16\n",
      "[NeMo I 2024-05-16 23:36:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /home/kozi/Documents/_onlab_git/ami/tmp/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2024-05-16 23:36:24 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-05-16 23:36:24 collections:445] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-05-16 23:36:24 collections:446] Dataset loaded with 17039 items, total duration of  13.11 hours.\n",
      "[NeMo I 2024-05-16 23:36:24 collections:448] # 17039 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/6] extract embeddings:   5%|▍         | 818/17039 [00:24<08:08, 33.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClusteringDiarizer\n\u001b[1;32m      3\u001b[0m oracle_vad_clusdiar_model \u001b[38;5;241m=\u001b[39m ClusteringDiarizer(cfg\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m----> 5\u001b[0m \u001b[43moracle_vad_clusdiar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/models/clustering_diarizer.py:447\u001b[0m, in \u001b[0;36mClusteringDiarizer.diarize\u001b[0;34m(self, paths2audio_files, batch_size)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_segmentation(window, shift, scale_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_scale\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# Embedding Extraction for the current scale (scale_idx)\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsegments_manifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_embeddings_and_timestamps[scale_idx] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_stamps]\n\u001b[1;32m    451\u001b[0m embs_and_timestamps \u001b[38;5;241m=\u001b[39m get_embs_and_timestamps(\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_embeddings_and_timestamps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiscale_args_dict\n\u001b[1;32m    453\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/models/clustering_diarizer.py:359\u001b[0m, in \u001b[0;36mClusteringDiarizer._extract_embeddings\u001b[0;34m(self, manifest_file, scale_idx, num_scales)\u001b[0m\n\u001b[1;32m    357\u001b[0m audio_signal, audio_signal_len, labels, slices \u001b[38;5;241m=\u001b[39m test_batch\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m--> 359\u001b[0m     _, embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_speaker_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_signal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_signal_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_signal_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     emb_shape \u001b[38;5;241m=\u001b[39m embs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    361\u001b[0m     embs \u001b[38;5;241m=\u001b[39m embs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, emb_shape)\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/core/classes/common.py:1087\u001b[0m, in \u001b[0;36mtypecheck.__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m instance\u001b[38;5;241m.\u001b[39m_validate_input_types(input_types\u001b[38;5;241m=\u001b[39minput_types, ignore_collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_collections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# Call the method - this can be forward, or any other callable method\u001b[39;00m\n\u001b[0;32m-> 1087\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m instance\u001b[38;5;241m.\u001b[39m_attach_and_validate_output_types(\n\u001b[1;32m   1090\u001b[0m     output_types\u001b[38;5;241m=\u001b[39moutput_types, ignore_collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_collections, out_objects\u001b[38;5;241m=\u001b[39moutputs\n\u001b[1;32m   1091\u001b[0m )\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/models/label_models.py:346\u001b[0m, in \u001b[0;36mEncDecSpeakerLabelModel.forward\u001b[0;34m(self, input_signal, input_signal_length)\u001b[0m\n\u001b[1;32m    343\u001b[0m     processed_signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_augmentation(input_spec\u001b[38;5;241m=\u001b[39mprocessed_signal, length\u001b[38;5;241m=\u001b[39mprocessed_signal_len)\n\u001b[1;32m    345\u001b[0m encoded, length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(audio_signal\u001b[38;5;241m=\u001b[39mprocessed_signal, length\u001b[38;5;241m=\u001b[39mprocessed_signal_len)\n\u001b[0;32m--> 346\u001b[0m logits, embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, embs\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/core/classes/common.py:1087\u001b[0m, in \u001b[0;36mtypecheck.__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m instance\u001b[38;5;241m.\u001b[39m_validate_input_types(input_types\u001b[38;5;241m=\u001b[39minput_types, ignore_collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_collections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# Call the method - this can be forward, or any other callable method\u001b[39;00m\n\u001b[0;32m-> 1087\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m instance\u001b[38;5;241m.\u001b[39m_attach_and_validate_output_types(\n\u001b[1;32m   1090\u001b[0m     output_types\u001b[38;5;241m=\u001b[39moutput_types, ignore_collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_collections, out_objects\u001b[38;5;241m=\u001b[39moutputs\n\u001b[1;32m   1091\u001b[0m )\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/modules/conv_asr.py:875\u001b[0m, in \u001b[0;36mSpeakerDecoder.forward\u001b[0;34m(self, encoder_output, length)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;129m@typecheck\u001b[39m()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_output, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 875\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pooling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m     embs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_layers:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/parts/submodules/tdnn_attention.py:309\u001b[0m, in \u001b[0;36mAttentivePoolLayer.forward\u001b[0;34m(self, x, length)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     length \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 309\u001b[0m mask, num_values \u001b[38;5;241m=\u001b[39m \u001b[43mlens_to_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# encoder statistics\u001b[39;00m\n\u001b[1;32m    312\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m get_statistics_with_mask(x, mask \u001b[38;5;241m/\u001b[39m num_values)\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/collections/asr/parts/submodules/tdnn_attention.py:116\u001b[0m, in \u001b[0;36mlens_to_mask\u001b[0;34m(lens, max_len, device)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlens_to_mask\u001b[39m(lens: List[\u001b[38;5;28mint\u001b[39m], max_len: \u001b[38;5;28mint\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    outputs masking labels for list of lengths of audio features, with max length of any \u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    mask as max_len\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        num_values: sum of mask values for each feature (useful for computing statistics later)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     lens_mat \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     mask \u001b[38;5;241m=\u001b[39m lens_mat[:max_len]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m lens\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models import ClusteringDiarizer\n",
    "\n",
    "oracle_vad_clusdiar_model = ClusteringDiarizer(cfg=config)\n",
    "\n",
    "oracle_vad_clusdiar_model.diarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat {output_dir}/pred_rttms/an4_diarize_test.rttm\n",
    "!cat /home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002a.Array1-01.rttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Diarizer Result (RTTM format)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAADyCAYAAADAzN2uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgZ0lEQVR4nO3dd5hV1fn//c/0wlSmMkwFhqENVUUEUQFB7D32romiiUlMjMlPTXkSjearicaoMcESFQ0KWBHpRXoZZmjTmMo0pjK97uePM+fMaVNUDhB4v67LS84+u6y1973uvdZecLabYRiGAAAAAAAAAAAAXMD9ZBcAAAAAAAAAAACcvpiIAAAAAAAAAAAALsNEBAAAAAAAAAAAcBkmIgAAAAAAAAAAgMswEQEAAAAAAAAAAFyGiQgAAAAAAAAAAOAyTEQAAAAAAAAAAACXYSICAAAAAAAAAAC4DBMRAAAAAAAAAADAZZiIAAAAAAAAAAAALsNEBAAAAAAAAAAAcBkmIgAAAAAAAAAAgMswEQEAAAAAAAAAAFyGiQgAAAAAAAAAAOAyTEQAAAAAAAAAAACXYSLCxe666y5dffXVJ7sYOMURJ+gPMYKBIE4AAAAAAMCpiImI09Qrr7yixMRE+fr6aurUqdq+ffvJLhJOMRs2bNAVV1yhmJgYubm5admyZSe7SDjFPPPMMzr77LMVGBioyMhIXX311crMzDzZxcIp5tVXX9X48eMVFBSkoKAgTZs2TcuXLz/ZxQIAAAAAAKcQz++7g+a6luNRjgHxC/Y9Ycc6VbW1tcnb27vPdT788EP97Gc/02uvvaapU6fqr3/9q+bNm6fMzExFRkaeoJL2qGutO6HHC/YJPqHHOxUNJE4aGxs1YcIE3XPPPbr22mtPUMl6V9PYdsKOFTqo73NzJhhIjKxfv14LFizQ2WefrY6ODv3617/W3LlzdeDAAQ0aNOgElbRHZ1XVCT2eR1jYCT3eqWggcRIbG6tnn31WycnJMgxDb7/9tq666irt2bNHY8eOPUElBQAAAAAAp7LvPRHxzh0fHY9yDMgPP7ntW2/z0Ucf6Xe/+51ycnLk7++vSZMm6ZNPPtGCBQtUW1urSZMm6e9//7taW1t1yy236KWXXrI8dOnq6tKf//xn/fOf/1RZWZlGjhypJ598Utdff70kqbOzUw888IDWrFmjsrIyxcfH66GHHtJPfvKTXsuzY8cOXXrppXrsscf0+OOPq7a2Vo899pg++eQTtba26qyzztKLL76oCRMmSJJ++9vfatmyZXr44Yf1xz/+UQUFBerq6uqzzi+88ILuv/9+3X333ZKk1157TV988YUWLlyoX/3qV9/6HH5fty+/5YQe79Orv/jW25yJcTJ//nzNnz//W58rV5n/3NoTdqytv5v3rbc5E2Pkq6++svn81ltvKTIyUrt27dLMmTO/9Tn8vsrGTzyhxxt6pOhbb3MmxskVV1xh8/mPf/yjXn31VW3dupWJCAAAAAAAIOk4TEScykpLS3XzzTfrueee0zXXXKP6+npt3LhRhmFIklavXi1fX1+tW7dO+fn5uvvuuxUWFqY//vGPkkw/S/Luu+/qtddeU3JysjZs2KDbbrtNERERuuCCC9TV1aXY2FgtXrxYYWFh2rx5sx544AENGTJEN954o0N51qxZo2uvvVbPPfecHnjgAUnSDTfcID8/Py1fvlzBwcF6/fXXNXv2bGVlZWnw4MGSpJycHH388cdasmSJPDw8+qxzW1ubdu3apSeeeMKyzN3dXXPmzNGWLVuOy3k93ZyJcYJvhxgxqasz/esm8/5gizgxTZYsXrxYjY2NmjZt2vc5nQAAAAAA4DRy2k9EdHR06Nprr1VCQoIkKTU11fK9t7e3Fi5cKH9/f40dO1a///3v9Ytf/EJ/+MMf1N7erj/96U9atWqV5WHKsGHDtGnTJr3++uu64IIL5OXlpd/97neW/SUlJWnLli3673//6/BQaOnSpbrjjjv0r3/9Sz/4wQ8kSZs2bdL27dtVUVEhHx8fSdJf/vIXLVu2TB999JHlwVFbW5veeecdRURE9FvnyspKdXZ2KioqymZ5VFSUDh069G1P4RnhTIwTfDvEiOlv6z/66KOaPn26xo0b9623PxOcyXGSkZGhadOmqaWlRQEBAVq6dKnGjBnzHc4iAAAAAAA4HZ3WExETJkzQ7NmzlZqaqnnz5mnu3Lm6/vrrFRoaavne39/fsv60adPU0NCgoqIiNTQ0qKmpSRdffLHNPtva2jRp0iTL51deeUULFy5UYWGhmpub1dbWpokTJ9pss23bNn3++ef66KOPdPXVV1uW7927Vw0NDQqz+x3y5uZm5ebmWj4nJCTwcNmFiBP0hxiRFixYoH379mnTpk3fafszwZkcJykpKUpLS1NdXZ0++ugj3XnnnVq/fj2TEQAAAAAAQNJxmIi4453rj0c5XMLDw0MrV67U5s2b9fXXX+vll1/Wb37zG23btq3fbRsaGiRJX3zxhYYOHWrznflvkn7wwQd67LHH9H//93+aNm2aAgMD9fzzzzvsf/jw4QoLC9PChQt12WWXycvLy3KMIUOGaN26dQ7HDwkJsfz527wUNjw8XB4eHiovL7dZXl5erujo6AHv53j6z/z3T8pxB+pMjJNT0fJfXnSyi9CrMz1GHn74YX3++efasGGDYmNjv9M+jofo9LSTduyBOJPjxNvbWyNGjJAkTZkyRTt27NDf/vY3vf766996XwAAAAAA4PTzvSci/IJ9j0c5XMbNzU3Tp0/X9OnT9dRTTykhIUFLly6VZPrboc3NzfLz85Mkbd26VQEBAYqLi9PgwYPl4+OjwsJCXXDBBU73/c033+i8887TQw89ZFlm/bdKzcLDw7VkyRJdeOGFuvHGG/Xf//5XXl5emjx5ssrKyuTp6anExMTjUl9vb29NmTJFq1evtvxN2K6uLq1evVoPP/zwcTnGtxXsE3xSjvttnGlxcioKHeR9sovQpzMxRgzD0COPPKKlS5dq3bp1SkpKOm77/i487P4m/6noTIwTZ7q6utTa2urSYwAAAAAAgP8d7ie7AK60bds2/elPf9LOnTtVWFioJUuW6OjRoxo9erQk009e3HvvvTpw4IC+/PJLPf3003r44Yfl7u6uwMBAPfbYY/rpT3+qt99+W7m5udq9e7defvllvf3225Kk5ORk7dy5UytWrFBWVpaefPJJ7dixw2lZIiMjtWbNGh06dEg333yzOjo6NGfOHE2bNk1XX321vv76a+Xn52vz5s36zW9+o507d37nev/sZz/TG2+8obffflsHDx7Ugw8+qMbGRt19993feZ+nszM1ThoaGpSWlqa0tDRJUl5entLS0lRYWPid93m6OlNjZMGCBXr33Xf1/vvvKzAwUGVlZSorK1Nzc/N33ufp7EyNkyeeeEIbNmxQfn6+MjIy9MQTT2jdunW69dZbv/M+AQAAAADAacY4jR04cMCYN2+eERERYfj4+BgjR440Xn75ZcMwDOPOO+80rrrqKuOpp54ywsLCjICAAOP+++83WlpaLNt3dXUZf/3rX42UlBTDy8vLiIiIMObNm2esX7/eMAzDaGlpMe666y4jODjYCAkJMR588EHjV7/6lTFhwgTLPszHMSspKTFGjhxp3HjjjUZHR4dx7Ngx45FHHjFiYmIMLy8vIy4uzrj11luNwsJCwzAM4+mnn7bZ30C9/PLLRnx8vOHt7W2cc845xtatW7/9CTxDnKlxsnbtWkOSw3933nnndzqPp7MzNUacxYck48033/xO5/F0d6bGyT333GMkJCQY3t7eRkREhDF79mzj66+//m4nEQAAAAAAnJbcDMMwTtIcyEl11113qba2VsuWLTvZRcEpjDhBf4gRDARxAgAAAAAAzmSn9U8zAQAAAAAAAACAk4uJiP8xhYWFCggI6PU/ft8fEnGC/hEjGAjiBAAAAAAAHA9n7E8z/a/q6OhQfn5+r98nJibK09PzxBUIpyTiBP0hRjAQxAkAAAAAADgemIgAAAAAAAAAAAAuw08zAQAAAAAAAAAAl2EiAgAAAAAAAAAAuMyAfti5q6tLJSUlCgwMlJubm6vLBAAAAAAAAAAATmGGYai+vl4xMTFyd+/73zwMaCKipKREcXFxx6VwAAAAAAAAAADg9FBUVKTY2Ng+1xnQRERgYKBlh0FBQd+/ZAAAAAAAAAAA4H/WsWPHFBcXZ5k/6MuAJiLMP8cUFBTERAQAAAAAAAAAAJCkAb3OgZdVAwAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMp7fZuXSXfv00rYDyo0o0+DDhs6/8gJdnHyWDq7IVvSF4Xor81NtLyjRo9N/oJRBg/X14jVKHheovPde1LHxsZo77XZVLFkkjzlX6Os1e2Qke+jeSx5Q7JChOlx7WG9kvK55Q2/Qe1sz5eNWpDElkTp33mQtTf9aR9oSlBKRomsmD9OytEM60rFFj0y7USPCh/Rb7uqWai06+L5yarM1IiRZN4++RYN9B/e7zdLsJWrpaJEk+Xr66prkawe03Vd5y3XukGnaWrpFlyTN73ebgbDe75oDa9S4uV0NQ2p156w7FDtk6Lfe19LsJZJkU6cjpSX6ZNEXqomqtNnvkdISfb14jSbMGqc1B1drdspspa3bZ/l804ybHNade8MsDR0So/rMfB155h8a+sRDKvM6qsWLX9E5G9p1YL6nlHq21HaBbjl3pMIDfRzKmVNZqtd2fKRbJszRnqpvJEnnBc7Q6g93K9tzkLzDd2peeq4m/eRphcWnWLarzyxU+t+Xa/zD8xWYEu+w3+LSI/pg0wc25e7v/NjXy9k+jpSWaMW7a5QYnKiRVyRpQ+06pQSerbc379ePZ01TiE+o3vsmT5J06/QkhQf6KKeyVC9s+kANx0IUGFKt+xOnqvH9f2nUQ0/Y1Mne0aJMfb7yZc248E5taNzrcC3t6/Phso91OCdXM6bM1+r6av141jSNCI/udf/OrsOPzr7eob1Zn5fstSu0e+t/NPnc2zX+2qv0Vd5yTa0eqeo/vqXIe29U4Rc7NbihUPF/+KkCUxJt6nH5xY8oIq73+lof75OFbys0d6VGX/mIar8+qtaxsSqbVqErxlzZb1ur3L1ZFb98TIMnTlXEL34lj6ioAZ2D78pyncZdoYolixQ//x4VfnRQIy6foJpFSzT0iYcs50Lqid2wG2fqwz1VuvuacWrza3Y4/9Ut1Vqz80ON+bpcq93idOOd8xQ1LFaV9a1asj5XoypbNOXKUSrI26kdr/xG/u1tGnbLj5ReuqvPc51TWaY/f71a3gFl+ul5t2hE+BCbXOjr6auL4mZpbdEa1bXUqrSpVLeMuk0Hqw/o3CHTtPrwVpWVxKrS2OOQn8057IKQi1S67qiCJwfok/RlumnGTXKTmyWODBlO26d9HrLfbuiQGB09XKUt/9qlpGuG6tP8T5TY1aZpiw7p6EX3adzt52nQYH81Vjcpe+EKRW/8j+qe/JHeal6tG0fepIPVByz5uqowU4f+8YxGPfSEutzkEKPW31u304HGc05lmV5as8WhHVbWtzrkiKO5Rdr5wvNKH92ufI8ZGlURrhlXJmhtzhdOz4FkynHvfP0fDT4aoStunW9Z3ljdpN1vL9Wehg/kk3KBfHePVsGkQBV77pTREqPH512oEeHRKiqs1ZcLd2qMKjVi27vyHT9OQT/7qSRp71sf6ZPmYN27dZECJ6Sq+fpbtOTrvbrh5osUNSxWR3OLlPH/vSw3j6E66xfXOM3B5rJsX7FLhSm5Dm3XOpemzhmtgm3FGj0vWVnFWfps8XJdccN8TRo/0eb+Yt2OrK/HZ0uf0bC8JqX+9A8219IjIsIhz1e3VOvjA1+puSq11/uSWVr6Jh36y5NKDjlXxd7TNeb+0drQttZhf1/lLbeJqz0vPaXDwwfpmssf7zVGqluqtWj7ItWvbdGEyIlKvXqUNtSu0yVJ81Xd0OY0diRp68F0ff7hck2fO1VbdyxTRkuwHpk6UalTLtWS9bkKKsvSGv/1SvS7QVeMHqHNS/br0tsmKS4+RMWlR/Tp239V8BYv7Z8yXT+6e7ri40Ic9n3p1MkKf+O/CmwuU9jzz8p73Finddi1/E2tWLtIEe0zdE55tYY9/ajlGpUfLtYb//1Kx6IPa+6WAnkaZ2nKz6+zxIqz+6s5541bc1jb20rlfTBMuZcE687Lf+hwHzf3+bKOHlFg02zVt6Qp5fBgxUXGqHpymc4fNlMrd6xWcWaxLp18qQ7tzNbMKSlqfHmRagYlaPIvr1FdkIdeWPWOcjqb9OiMnj6tuZ2Vfb1Ve/7yqTpnTVTOhUd0pLVYD05YoBDfEEuey/isWJsbWnTF+UnavGKXSuMOqsYjSb+45MJe7785laX609p35Zl/SKMrspTaFKr4W3+pr9fm6YabL5K7YWj/i69r7E9/qIjhcZbt9u3Zoo/eX6em0Il6+PZpNteuqLBWX767R7POi1DnW+9Y2ov5fpN8xyytzdmr/XmvKaC6QROmXK6qiUk6J2K21mY06Jqz4vpsC/blN9+vQgrzVPSb36n+4kc05a5ZGjTYv9/tC4tq9ebSfZo9K1Kf7fpC0el+8r66QzeffYtDjvh68RrNnDtd9Z+nKWTjYpXPukeDL0nSyqWvKX5DmyY8fp3iLpip+sx8lfz2/zQ4MVRd9z+gTwta+qxTUWGtPvr3DpV6umlEVaXOLVyvloRE/dc3VfffOklhCYMd8rT9uQ6JPayOT95ToPcFmnrXPG3++GN9ONFLd42+WKUZR2zytSRLLgu55VrlfrbXpv/aWN2kzMXb1Fq8Qus6vHXFjfM1btI0y3aHnv2z1k6WSowJumrzLo08VqaI53pvm+a8OCS3RkWjwvrMRfaqW6r15d4vFZwRrgODMnTrhbfYtD/z9wlZIzRqerIKthUrclS4Ni/broZ5lbp28nWW3Pjl3i8VszdRg5qbNLx+jzovn6kvd79nuX86u0/21R/tjX3/XXKeY6zXs++H9DZusranfI8Wf/r/6fovpe03/VzXXzql1xgbSD2cjSeba1oc+kGtdW36cuEquV/RatNOnI1JnI1JK3dv1p4Xfq3dZyUpeWuksi72122X3jegsWVv40Zn593cL/EvD1Dj0HpdPeNKrateq/xjebon4X41bmnV6HnJljxhvkbjKjzk9v5mdQ4do+D5o9Xw1lL5/HCeDtbtlkdDqi677XIZMvTPj99QV6GbLrpipmaff5HD8e6cdYf8Q/20ceW/dfbCbxT+hz+qYcQQLc1eosCcUs14Z5fC//BH1XQc0+KlL6rK9xztCfTUglGp8lq21ibnHi3K1EerXpTXmNFKDZmmdUs36twLZ+mzHaVqicvUozNucriu5n5j1HU3a8OWRRqSW6PsMSFS9DgdLWrQHRffoeSU4f3GgPn65VSW6bXFX2nGnm2qGFGnkaUdMq66Wa+mZ+vWcyZqY1GGYg80KqpgnSYs+K1SYlPU+O578p03Ty0rVjj8f9Btt9qMiTrLy1W8aKE2pHQpfu1BDb3hdm3M+Mxh3FmdsUNffvSMxjQEadLjz/c5drXWWV6uxnffszmueZl1mTqPVqrg2ae19f7pumzqnZKkRQffV/6xPD0Yc5PCP93otOz1r72urqYmufv7K/emGfpH/ju6LvlGrSlapaSgYZoXd73WZjRo0jAv/fWbD3TkqJ/GBIQrsqxAbvEdunjaHH1aukxXR16n/Z9mKSI0XNWTy3TFmCvVXNNiaVtTr59sidnDtYf1951vKrr9St0zY7xlnG9u64MDfAb8jMi6P3reyCB9cOBTh3xhP2bzazd6bY/W685NmKO3vjmk6ZOrlBI4Wa9tX65AI15h4bWWsV9vjpSWaO3ry5SalaWQB6/SmuyPnY557HOm+bplHT2ioZ3XWs6Pvcr6Vn25Mk3npC/T51HHlBtwnq5MCtHRd/6q8Q8/rYnjZ0gyjZfT/rzY4bmCZGqfK/7zW034OldekyZofXCrqnKiNNqjSkfPcVfUlBu1MOsb/eS8GzTB26vX8Vxv4wd3Q5a2/EnalzroOVXjvaN1Y8FORdx7p00smnNFQHSczt/QquLqCEXePU2fFq3XpcPOVs3ihUq58QF1frVdBRHnaOx1E9V1tMJmbGP9XKuxoEQZf1mi1MeuVfTcc1Wfma+8p19SzaAEDbl/uj7KXGUZ+3V2+OvNpft06bQE7V6Zo0tvm6SQ5lqHcVP54WK9sPgzHfIwNL0uXjffP0Nx8SHd57n3vsmBXRuU/o/fafxDT2vMlJnK3r5C6f/4veKv/Ym2ZbTq7MtStbh0o67xidDONf/SZVf9QstbOvVp5jpdFZ6iSVs3auScG9T8t3dUEDFVKQ9eof05ZTbjwjU5+/S3zYv1o2HnyGvZO1qXFK49voMV5pmipy6boxCfUC3avk/NvruVXxSsn82ZadO/tr/XVhVm6sCzz6izY4Jl3GHud15zVqiq31/k0L+2Vn64WIsXrdUNN1+kA521em7V1xoa1ab7Rl+q3cu3qSaqUhdOvkwfZuTa9F3M/cqjAV760U0TFR8X4jDmzyjL1nNfb9DkqIm6c/o4fbZ2pcLXvqpJt/5EibuybXJ208cfS5ICf/RDSVLhOx/qv8PGq6R9p8ZneOmsvDybcZd1v29FcqLSjQTdN/0cnRM/3OY55PWj52npnmxL2c3PlSIK6rSxrVrNSRkaEeMrXy9PdbX7y6g7W5eMS9D6QxW6YFSk1h+q0JShvk7PnTPf6l9EVOTk6yv5qKnxqEbuS9LBvMNqqmnWrg8yVFZVpg0F6VLwbmWUFKii/KjaVktFB/dqxP4SrUioUXnWbiX+Z7XyMg/ItyxSu0J3qqyqzHQC6wu0v2qf0svzdLCwS7WN++SxwVuH8/O0Uwd0IC9ES7eX63BFgz7dm6m8zq+VX1MxoHLXtFRrRcFy5dblaEXBctW0VA9om09yl2pFwXKtKFiuT3KXDni7DzLfV2F9gT7IfH9A2wyE9X7XHVin1gPt2jZok+X8fdt9fZK71KFOFeVH1bCv2WG/5mt5OD9PG7zW6HBBvs1nZ+tWlB+VJDXlFitw5SI15RaroOygWivbNKhqh1bFVmr5kZ16f1OJKutbnZYzv6ZCWa1f6VBlnqW8BSUFqtvjrl3tx9RUt0mjP9iouuJcm+3q80u1r3CQ6vNLne63rKrModz9nR/7ejnbR0X5UbVvkrK/yFdZVZk+yHxfh44Waft+f+VXVamyvlWLthRo0ZYCS53zayqU17RXh0s8VdS1RoU5+5T4n9UOdbJXVZ6npYPzVFB20Om1tK/PocxMZY7L0L6CPEt5Bsp8HZy1N+vzUnogTetm+an0QJolXqvSsxWz91NV78pScWGHQr5ZoqbcYod6VJXnDagsFeVH1ZFdppkrsnU0bb8yj/hr764cfVy4eEBtrf5AuoIPFqlz0UfqrBhY/vg+zPUz577q9EPaVzhINWmHLO3CpnzdsZuXWablVY06UnrM6fmvaanW2t3/VdWylXpPsaooLpdk6sB9sv6wDi49oKaaZpXkZCi6sFLnrSlRceaOfs91flWVDhZ2qahrjeV41rnwk9ylKqwv0Ce5S7XuyFpl1hxSVm2mJTctOfS1VuwrcJqfzTFRUX5Uuz7IUFFxsaUNWcdRb+3TPg/ZbydJNUV1Kt1foYL8Qm3z+ka5e1eoZX+e0taUqammWZLUVNOsoqWb1Llzh/IL92p/1T5LHcwxVFeca2mHzmLU+ntn17u/eM6vqnLaDp3liJqCIwrZ9ZXWDW5W4eFg+e4+qtyCgl7PgWTKTwfa98lto4/N8qaaZuVs2KxVqV3aXXhYxfn1+jqvQEWt6crICrWUp6zkmLSnTLUrd6grfa+a3n1PnRUV6qyoUObna9SYnSuPjHQ1vfueyjMP6922SEsM1hQcUfSm9co6GtZrDjaXZcfKPU7brnUurSmq064PMtRU06zDBfmKSo/T4YJ80z6s7i/OVJXnaZcKlPzfLQ7X0lmer2mp1pJDX/d5XzIrzNmn81fnqHNthsqya1VUXOx0f/ZxNWjTHn0+pLzPGKlpqdaWrC0K3R2lwq9KLfeTmpbqXmNHkrIL8hW3Z6gy87JV3FKikqbztD/vkCUvHNi/T0Wq0adp9TqcVyNtO2K61jLFTG35IeX7jdeaTk8dKT3mdN9lew9q0Lav1JWepvasrF7rUJy5QwdGRiogw0fh6z+2uUYVxeX6Sj5qPLZFMWtylFkeYRMrznKAOefVfPmJihvrVBg8XNsidjm9j5v7fFmVpVp3qFRVDWny2Oatg5uz9HHhYhXWF2jboa3aG7tTh/Py1LZaqkrPlueub3So0hS3ZVVl2tdVKIXY9mnN7al2d7YK/cboQFaZ1pStUmbNIRXWF9jmuTWH9XVds7Kzjqr1cKH2emVqb3Zon/ff/JoKFTcdVmhrpnLiPDV62R4VH8iytLGagiNKXvq2agqO2GxXkJctr6IkbWh1d7h2ZSXHpG1HVJWeY9NezPebyswS7TiwU/6Vx7RpRphyC9P0Qeb7yq+q0r/X5fbbFuzLb75f1R9Il09OrQ6ur7Xk3/4cKT2m5VWNyiguUu3RbLXXtGlFlWO/3Xw9Sg+Xq2jpJjUdyFXamjIVFRertvyQjnidrer0Q5JMeSJgwzK1vfOmKorL+61TWckxNWVWaf+xFgXuK1DYts9VtPOQNnl7qCC/xmmetj/XpbnpmpTeqNKm4apJO6SSqhw1xezVobzDDvnaXMbAlYtUuzvbof/aVNOszMXbVZS+U4MPjFRBXrbNdh0HV2ttWLPKM901cuNX0t6+26Y5L4ZsO9hvLrJX01KtrzK+0sHNWfrGb51D+zN/f+CjHEvuPppdpcKiIn1ascwmN36V8ZWyv8jX4c/2qPXVv+vo4X02909nua6v/mhvertH9jV+sf++t3GTtazaTPnmlagxt0xvHajvM8YGUg9n40ln/aDSw+Vqrmx2aCfOxiTOyl5/IF0N9VXqLKhUjv9QbQ7bPuCxZW/jRvN39uOmA+371HaoS9sGbdLho4e1omC5MmsOqaCkwHKfNzNfg5p92YqrKFBR6wiVpR/SuJxvVHogTd941cjY5G+5Xkcbjyouc7hycnKdHq+sqkw1LdXau2WJjO271J6VZbmuh3Z8aVl29PA+bY3zVk2lu8qOjlbugUyHnFtVnqfloUX6tPRr5RTnKmRLlA7lHNHWxioVapXT62ruN5Zk77G0v1VRlUorPKS9sTtVVOzYj+nrmUJ+VZWO7GtTVPpq7fUtVfJ/t2h/3iEVVk3QnuIcldXtkXtelWauyFZJToY6KypU/8KLas/Kcvp/+zFRZ0WFSj54U1uzV2nEe+tVkr3H6bizJHuPMoe6afSyPf2OXe33b39c+zJ2VlSoPStLlTnpWlyzSjUt1Zb7e2bNIZXn7+u17I3/fEPN776nxn++ocyydB1tPqr0o2nKqsnUioLllvvbwfISlTVWqLk6RUeOVMsvd5B2Bm7VoYqD2l+1TznFuWrfJEv/wdwOzW3LOmYL6wt0sKJIS7ZW24zzzW392zwjsu6PHiwvcZov7MdsfbVH63V3FR3R0WNt2lD2hfaU5qrLp0DFFd42Y7/eVJQflcemeoWv/1hlh9J7HfPY50zrfpn1+bFXWd+q5av3quarj7U6uFF7csKVl7VXs784pMKcfZb16vNLnT5XkEzt83BDvgZnl6pmy3pltTUoIzhZ0Zmb9PnQUu0pzpERtFMZJQV9jud6Gz9Yt+VVg+q0Lz9MWzbnqPOVlx1i0ZwrtmavUtNHK7S/LFQFh3O1wWuNSnIylPif1ao/kK6qNxdpz+em56r2Yxvr51q1u7N12G+8aneb+gFNucWWvmvB4VybsZ+5P5WdddTS33c2bqooLtdmdzd1lMcrOL3WMi4w77+3vklJTobO/ypLJTkZkqTyrN06d2WhCvfv17ttkTpYlG+K28ydWn2Wj0qy92jPkTz5he9Xca7peVfjru1qOJSvA1WRpr6o3bgwo6RARtBO5WXt1aBNe7Q9oEtdfkXKOhxhebb24Y4DWlvwjXYfDHboX9vfa+uKcxW28qDNuMN8nor25zntX1urKC639Mf3lhSqvi5CFe4blV2Qb2l7+48UOvRdzP3KNQ2tlj66fV9yb0mhaiqGa3VGvQ5XNCg9fZfmfJmp8r07HXJ24z/fUOM/37CMzYv/86E+yy5SVUOa/Le1OIy7rPt9+3w81VQ5VruL8h2eQ+4tsS27Zfy4sUDbW6t1RBu1vmSlVhQs15c5G/T+phIdrmjQv9flWv6fd7Sx1/Nnj59mAgAAAAAAAAAALsNEBAAAAAAAAAAAcBkmIgAAAAAAAAAAgMt8q5dVq7lZkrflo1uL1NrQ5rBaW1ezmtubJElGe6dleUtX97pt7ZZljR2Nqmuts6zf3mH7m3GdrZ3qTXP3tv1paGtw+NzfdvbbfNftBrLNQDgrj9Rz/r7rvqzLZ74G9vs1L+9s7ZQ8pNauFpvPztZtb+xQc12L2pvb5SZJDXUyvHv2b62+uV01jY5x1NTaIUlq7ez5/cXW9hbHHdTVq9Pqd9iMelP92po71VznuH5bU7tDHa05Oz/29XK2D+vzZylvR4skTzW2dKresyfuzXU219FSts4Wp3Wy19Vdx+aunvr1FmvW9Wl36y53S6fTc+6MuYzO2pv1eenqMiRJLZ6djvHaanUdGuosdTPXo6GzaUBxbH2O3Vtsyz+QttbS0WzJYF21dX2e4+PBXD9L7mtqluSvzlbTubI+F1JP7Ha0dZm+butQs5Pz75hnulTT2Kb65p4Ya21oU0drp6n9qed89XWumzuarP5sOl5vucdhW7v4t48X+/10tJjq1djRKK92L0mmOOrwct4+7fOQ/XbNdS1q726XHa2dkpdt+Vob2tRc1+L0nmVdxrrWOjW1N8lHkurq1eXrYfrO6rxZf299/QYaz+bzbN8Ora+fJUe0dDhs39nSKfk6PwdST46zX95X3a3LY5+XJFN7cV6ZZkl+lhhsaumwtLHecrB9WezbrtNc2tCmjjZTubqauxzuL87asvl6SHK4ll5O8rx1jPZ2X7KUp733vok967iyLOsjRnprcw1tDWru6D2Ht7Wb8obRnT8kqaXD0yauLMu7z2V7Y7vNPa3nWB02+zfvu8tq30ZDQ6851Gi3O3dW18iod6yfdaw4u79+mz5QfznLOr5ajVZJHjZ9zbbmTrU1GT2frfq05vbU2d4h+yTT3N7k9NitHV02n/u6/zpre6Y2ZsrznW0dGiTJ7ZjdvaOlReb+uf21M++zw1zH7mthud+02Jav1d2w+dxfW3BW/uaORrV0WPXduvNvf8w5vLXDtn31liM6mm3PV4dVvmxvk22esNJXnZxeg26N7Z1O87T9tkZXzzm03O8ldRhtknxs8rKknjK2NEkaZNMe7PN2Z4ss37U7adtS322zy679DbT/JTm2Lfv2Z9PfbHIsm7NcaylzU5MU0FMeZ/fJvvqjvbFvu5LzHGO9nn0/pLdxkzX78clAYqyvejgbTza3m9qUdT+owyq/9Dam66vs1u3UbKBjy97Gjdbf2Y+bLN93Oh7XOk+Y1+8yenKBuV25t9n2cczXy7QTOT1eY0ejvNo8+q2TPfOt3jrn2rchSeqyenzh7Lpa+o1NzvNgk9H/vczm+nY4GVO3murc1mmb8Twbmhz6cEaD7b7tx0QOfb6mFsnfcdzZ1mlV8X7GrvbH64192ayP19u++ix7t/ZOZ30h5325lu4Lanou1fO4zLod9sV+nN/c0aiGNtt7a1/jVuu6mstoH1f2Y7bm9p7r7tAerdZt7+rJSx1256S/3GqTV1q6+yZO7iH2OdNeb/nRWX/VnOM86xud9yPtxgDO2qe1dsN0Tdq6mtXUrj7Hc+r+znr84Nve1dOW/W337RCLTsrS2WpI/lKrue009PymfmtDm2Q3trF+rmXue7Z19PRvbPZrrmNjh9rbzf2pru5l7U7HTfZ9cvO4QOq7b2LuU3o2NJnK2WJa7t5iOm5zp+m4nd0x1qR2Sz7vUnc/yyofWvdFzW2jrbsddnQ5vlPE/tmaeZmzPpk5rpvamyx/C99cF/t+p33/2pr5XDW0dalNPeW1zoOm56ReTvsupm07HJ7Z1De3d4+zHO9Rno229wzr/NhXHnX2vM1aW7u743PIrlZJ/payO2uP9uz30dxHH9ret5qIaHz9n9LtD1s+hy711BdLVzust7H2Te3NCdX5ukSVabVK6l6+tHadRkvyWLdZCrtSkvR/+X+W8nu2XVW0StJsy+eCL0qkOc7L80bmH/VG5repgcmTm3/z7Tf6jtt912MNlP35+7asyxdUGarxOsdhv0GVpmtZ8EWJdKX05dHPbT47W3fPcwe1RwcV1HhEMyV1/PRHajgrRBqZ6lCGR97Z6bRsnn4VGjxKWlqw0LJscfZijdblNuv53PeYrF/JVOcfI415RCvePCy9edhhv3Vh1Q7l7u/82NfL2T7M61hbnL1Y0s16ZkmppJ4X/Jjr7OlXocD4nvXXln6iaU7q5FCHOD/pV8l6o/ITh7I6k6TRkqRtgd9IitczS0r1jHp/kaw183Vw1t6sz0tH0DHpHGnpxDwttSuLz6fvSgnXSjLFgrlu5nr8vvTfUum/+y1LUGWozlGYJGnIxyuUM2ak5buBtLWzsqp1b/efq266ud/1vy9z/cy5z+tf70tjHlH6hgpLu3AWu+kbjkopoXpyZXav5z/OarufbqyWNq6VpO6zI33x1Gq1huYqpftz+LIN/Z7r9qYImfPvt82vr6b/Q1KE5XN/26d9vN/ShqzjqLf2aZ+H7Lfbo4OWdbPWHJautD3eF0/13KtieimTOYbiCpv0a5naYbmTGLX+3ub6DTCeTef55j7boTlHJFUW6Md23xV9ndPnOagLq5bOM61rf268+/h3kObyhDW125++nvYy7Byb5Q0v/1265ilLDCZVFujJ7u96y8EW3cFq33ad5dIvnlqtiqElilSMqt9r0jvvfWRzf3GWL+vi/KRbhkpydi171rM9vimGe7svmaW0HjGf4n5Zx9Vt3cv6i5EghTrdT1+xE+1RrPkKUfvGVpkb/kfF4/XROzstecHsnU15ulJSxktblKHumAm2OtbKbGllz0txLfve0NPZrnvi16p74tdOy992Toh02QTLZ5u8HxYv3fIjm/WtY6W3HBAnR9+lD/Rq+j8UrmhJ0pqWlTpflyj/8xKZS7vizcOmMlxg+mzdpzW3p/CaXCl0lMN+nfloX5l5V5LUZ7v39KuQ/xDbZV5vvG9pY0mVBfqLJP8F99nEfNNZKZLffZIcr525PRetyFGSeq6F+X6z5bMj0viefa1Nth309NcW7Mtvvl+dlVWt67uXW+ffvlT6eUopofpoX7nGWo1QessRme/k2+TztI/3W+J41wZ/7drQkycGWqewpvZe2/af00qktJJe92M+161VPQ9r0jdUWMqUZnzj9J5lLmPXewud9l+DrI5R+qG73vnwI8t2iU7K2VfbtM6LUv+5yJ51bnLW/szfb3pth8O2NmMOuxzX8PdXbO6fznJdX/3RXsvb2z2yj/FLX+OEvvqaZ1n9ua8Y+y71eHLzb5z2g4bkJGi4RjmUzdl91FnZz8qqlv3IbKB5tbdxo/XxbcZNVg3r3dK3HfZnnSfM1+BoR89LxqtKTLkpfsMqaaTpuJbrZe7sLvfVO8s/cjieuXzW12ggNud46lrZ5lxzX89a9coGaaLpz86uq7nf6PWv923an9k/G17RP5e/0mdZrK9fe1OEQuwylce6zVLKVG3IC1BieM/y5KdeUpVeslnXPj84HRPF+Vn+6PWv952OO0cX1ElBpkn5/sauA9Vb7uqt7Q10PLejYrvDsrc35cnXvoMkaXnl55JMz6Ws25F1O+yL9Tjf3Nbt9T9ujbCU0Vm+sB+z9dUerdfdWble0mRJ0taybfKw+jsV/eWkoMpQXdadMbreWzigMY+zevaVH5PsPu863KTrJE349V9V9uu/Suruvzh5riB1t89ZTi5qtx1NB+UbbOrb5fc1nutl/GDTln9s2wbtY9FZrkjfWGF6nlb5mSZK8v7DX9Xsb+rJfPHUaoexjfVzLXPfc8sON225w9S/mWC9X6uxX09/qszS3y9wMm6qC4uXbr/dUj7zuEDqu2/SGpqrVJnyS9lTL6lpdIAkKXzpeumaC/TeoUYNHiXtr90lxQbrH/5b1VgxRoP8pEYv04vHvf71vtRd9y2fHXEYF7bUxcs3WMps2qCz7a6j+dmap5/tMuv+tf29Nq6wSQu6vzPXxXyeFu8r11Q59q9trmdYvKU/7hVQLGmQJNPzO3Pb+7Lyc9n3Xaz7lfZ9dMnUHkz7s49+aeQr79uWwSo/WuItLF72HJ632d13tmeEaXfOAYfnkA5ld34qLJ774qDN579+PfCHR/w0EwAAAAAAAAAAcBkmIgAAAAAAAAAAgMswEQEAAAAAAAAAAFzmW70jYtAPH5Cs3lFTc02Hbps0z+G3X88PuVvThw5Vxme5Cp8YIh0yLb8m5EJJOeq88DyZf3zs54mPa+LoCdp8ZJNeTf+H5sTN0dLCnpetJFwWI7Xudlqe+1N+o5nDxvZb7vy6PJvfp/vDeX9UYrDjb3D1tc133W4g2wyEs/JIPefvu+7Lunz70w9o0+YdDvvdn35AGZ/lKuGyGG2SdGnE5apXh+Wzs3Un/XK0UseNVdWqLdKPJc8XX1PA4CJpxQaH8rx8x1kaER3osHxjXob+lSNdk3CP5T0RNyTfoH2rbF8S1fqvvyjhHKsXiaxNk/5Tqnl3D1PURZMd9rsnM02bSlb0eu6cnR/7ejnbh3kdazck36B/ZkpPXDtEMQFDLb+JaK7zxrwMvZre034uGnKVpP9zrJOduvS1Ut2buj/8KsvvdfYWa/l1eVq4911J0tT66fpKpvLMHDHKYV1nzNfBWXuzPi/ZX2yXdFTXpCVp8kP32cRr65W3SXtNycPzxdcUPvtcm3o8NeReJU+crf7sTz+gnZs+kCSVXjdPVj+xPKC2VlK7UNILkqSwDxbJa8zofo/5fZjrZ8597ffdIm2Wxs+MlA7angtJltgdPzNCn5V36A8XJ6s5JNzh/OfX5emfhT+1bPbi+YM1atoE5ZTV67evbZEkXfb72dq3t1p6x7RO5dUzJZX2ea435GTpz4WmhG0+Xm+5x96D4x/SS1sXWz7bx4v9fiZeN1ab2k1tyGuolyWOOrzanbZP+zxkv13quLE6vLlAm17boZGzhmmTXfku+/1shSWGqiq/Rnse2uO0DuYYKtq6UtJP1fqvvyjY18MhRq2/t26nA43nDTlZ+mNmtUM7zCmrd8gRBeu3q3mX7fZxc0dIcjx3qeNM53tPZprS002/hWu9vCq/Rit/u6XXcpnLk76zWIde2GzzXdgHi0x/+PWLNssDHnlYKu6JwYL126WvTd/1loPNZXn/b6Z4sW+7znLpZb+frW9yvlHtOy0afKu/Lp93qc39xaYddatLXytlmH5z2f5aeiUNc8jz+XV5+tWqv0rq/b5kturzHOk/vX5twzqu6t83/bZnXzGSX5en5z/9i9P9FB5tdxo7krRkTbM6djXI63wfqcK07PrYdF0w6x5LXjC7Y0aSarP2KPXH0zTprKHak5mmdYtW9hzr4mSdNSnWcd8zfSx5N/iZP8nvskud1sF74eOSet41YH2NqrbukzIKbda3jhVn91f7nGfm7D7eX856cPxDWly0RJI0y/ditUtKvDxGeqWnLCUxI7TqoKmi1n1aS655aZE27XTcb0zAUIdjXz8uWkfX9/zef1/33415Gfr7Ltu2137/LVKlqY35tQ2SlklNr/xLw87v+bVz/xUfS5+a/mx/7cztOW7eCNv7Tvf9ZtoVQ5VdsM+y/kXZvjbvieivLdiX33y/GlG7TYZM92tz/u3Pjj1H9NnaHF0/LkoHD/Us7y1HpNyRqPoXevL5xOvGaucqUxxPmdmksffdYckT1vqqU/rOYm161fG3xCXp8Ykxih0f45Cnrbc99MJm+YT1vMFy/MxIrdvbXT636ZJs87IkSxndb71H2mPbHqrya7Tx5+9Y1h3ygy5dfNmNlu2Knnf8be6+2qZ1XpT6zkX27HOTffuz/n7Gj852eE+Eda61z3EBDy+Q9LWlPM7uk331R3tj33+XnOcY6/Xs+yG9jZusfZK9VPnbX7d87ivGBlIPZ+PJxoJmh35Qh3uXdh1Idyibs/uos7KX1C7Uof0LbZYNdGzZ27jR+vjW4yZzv0SSbhtyp8N7IqzzhPkaRXhGSCqWJIXF+EqSCmfOkXRMkizXK29t9+9Sz2/RHTff5nC8nyc+rpCYIH2y/cF+62XtvBGmF29a51xzX8/a4IsDpKM1kpxfV3O/sf2+W6Sm9Q7HeSBggc4/f7rNsr6eKWzIydL739j2ZTsvPE8qlWYmNaiwvmd59u9/rHNHTrP5/frgZ/5k81vj9mOi9gMHVfiLe3o+33eLpB0O486j9Z9oac06SU7G431oP3Cw13c72JfNuv6S4zsHnJXd2b7PjjzH4T0Rd85I0ocH0xzWnR9+uZZXfq45cXNk/Zpc63bYF+txvrmtx4f5D/gZkXV/9M4ZSfqs0jGu7MdsYUPdem2P1uueFX6BNlaYAuTc6KnaUbXOsl5/uXV/+gEVfGB6luN+6z2SNjq9h9jnTMn2uvWWH3PK6vXCCwU2y6YMM91P9/7pUc27/C7TwrVp0mvd7+GwGwPUpa+VVv5fr3U423+0MlSo80Pu1vxQqdfxXC/jB9/QLlnast3LdOxj0VmuGH9+pOl5WvgVkl5U25OPSv/3X0mmHKicQ7ZjG6vnWo0Z7dq0U5p2tqHkR25Q1aotOvarJZb9pne/e33SL0erpT2kuz8VrbasWqX+eJriawsdxk1VW/dJB3oeqJjHBVLffZP1n1RLK0355fyr79HhpS9JTy9U5TWmt6LdOmqQlksaGzJFB5Wjh5rO1QeBwarWAQ1qHyfLc5H310mSpl0xVF9trpbU0zb+uWW1Ntb+Wyn+MyUtsjmP5mdrP138pc0y6/61/b3WlIefl9RTF3O/84ZxUU7719aqtu6TtrfoxfMHa6Pa9elOU86/aMhVqup+p8Kl4ZfrvUzbslj3K819dPsx/9q8di3Z6HjMrAW32Lwnwjo/msfmhxc87rCdw/O2DNt3EJ2TWqU5o8Y4PIdcYlV26+dKvfnlZaNt3hPx6NwU3f7nPjfpKePAVuvm5yc1dVo+Gr6ST4C3w2re7n7y8zIlDTevnrd/+7p3r+vd81acQZ6DFOwTbFnfy9NH1oNXDx8P2dwBrIvTvW1/ArwDHD73t539Nt91u4FsMxDOyiP1nL/vui/r8pmvgf1+zcs9fDykDsnH3Vf1arB8drau1yBP+QX7ysvPSx2SFBAsN3/nb6AP9PNS6CDHOPL3MYWnj0fPW2h8vHwl2U5EKDhQHmE9r1JxCzTVz9vPQ37Bvg779fb3cqijNWfnx75ezvZhff4s5fX0ldShQb4eCvTriXtznc11tJTNw9dpney5BwZIdZKfe0/9eos16/p4Gd3l9vVwes6dMZfRWXuzPi/u7m6SJN8OD8d49fGVZRYzINhSN3M9Ajz8BxTH1ue4y9e2/ANpa9VWbzRyDwnu8xwfD+b6WXKfv+n4Hj6mc2V9LqSe2PXsfqNwgLen3Jycf8c8467QQd42MeYT4C1PHw+ZM7b5fPV1rv08/a3+bDpeb7nHYVu7+LePF/v9ePp6Su2mNuTRfSvyGuQp9+4mYd8+7fOQ/XZ+wb7y6m6Xnj4esucT4C2/YF+n9yzrMgb7BKvKXJfgQLl7uzvEqPX31tdvoPFsOs/VDu3QWY446utpn/Hk4ethOUf250DqyXH2y/uqu9STF+zzkmRqL84rY4ppcwwe9fU05Xz1noPty2Lfdp3m0gBveXqbyuXu5+5wf3HWlt0DrWLO7lp6Ocnz1jHa233JUh4vxxjrjXVcmZ8N9BUjvbW5AO8A+Xm2ylnsSJK3l7s6JLlZvZHc17PDJq4sy73NceNlc0/rOZanzf7N+3a32rdbQECvOdTNy1vWfTnra+QW6Fg/61hxdn/9Nn2g/nKWdXz5uPmoXR2mvGJVFm//njZg3ac1tycPL8c24ufl7/TYPp62//i4r/uvs7Zn3cZ8uhOkEWR37/C17gvYXjvzPi15sftaWO43vrbl8+lys/ncX1twVn4/z0Hy9fSz5C5z/u2POYf7eNq2r95yhKef7fny9O357OUt2zxhpa86Ob0G3QZ5Oe/L2W/r5t5zDi33e0mebqZ1rfOypJ4y+prqZd0e7PO2h68s33k5adtS323T3a79DbT/JTm2Lfv2Z9Pf9Hcsm7Ncaymzv79NeZzdJ/vqj/bGvu1KznOMTX/Wrh/S27jJmml80mMgMdZXPZyNJ7u8TLFk3Q9q8Wx3WjZn91FnZbfuF5sNdGzZ27jR+jv7cZPlew/H41rnCfP67m49ucDcrrq8bfs47tZN1kdOjzfIc9CA+7PWzLd665xr7utZc/fp+bOz62rpN/r72vylTjN/t/7vZTbX19Px+srHVGdvD8NmcUeAv0Mfzi3Adt/2Y6JO+z6fv+m62I876zysKt7P2NWaw/77KJv18Zzpt+zdvDyc9YWc9+V8uy+ol6ePWtXz7Mu6HfbFfpzv5zlIAd6DbNbpa9xqXVdzGe3jyn7MZn07cGiPVut6uffkJU+7c9JfbrXJK77dfRMn9xD7nGmvt/zorL/q2d2H6ggc5LwfaTcGsL/H2fNyM10Tb3c/+Xt2X0tn4zkzu/GDt1eXabm/Y5/GPhad5Qpzn8DH3HYCeuLCJ8BbXXZjG+vnWi3dfU9vz57+jc1+u3OL1yBPdbaZ+1PuapOpv+/V6jhusu+Tm8cFUt99E3OfsiPA31TO7n5ol6+X1CL5ebhLnZJHd4z5y8uSz93Nj6CtzqF1X9TcNry726GndYLtZv9szbzMWZ/MHNdVXv6WkYm5Lvb9Tvv+tTXTuWpRgLe7vI2e8npb5UGf7hzprO9iqpunwzObQD8veXs5/6GijkG2cWadH3sdm0uOz9vseHt1OT6H7D7P5rI7a4/27Pfh10cf2h4/zQQAAAAAAAAAAFyGiQgAAAAAAAAAAOAyTEQAAAAAAAAAAACXYSICAAAAAAAAAAC4zLd6WXXkiERdUnVAuYMilDUuT+cnXSD/UD9NuSlV0WHhmpkwXtsLwpU6LkGRgwbLe7YUN3qCcsau0byCUEVNm6z822crKWWMso/s0ZSasxQdFi1Jig9M0NiwcRoflaSM+Ez5uI1T58w2DUscp7PSx+hIUq1SIlI0LDJAV05I0ZGOuUoMjRxQuUN9B2tewnzl1GZrREiyQn0HD2ibq4Zfo5YO0ytNfD19B7zdTSm3KD4wQTel3DKgbQbCer8XjrlQjbXtmto4w3L+vu2+rhp+jeXPZpFREQoY5+ew38ioCHnPloYlJmnmwVkaNixRx2bvs3x2tm5kVIQkyX94rI5cfLOGDo9VgpePtoevUWPY2ZpT7CmlniVFxCg80PEFNJKUGBqpkT6XaFR4kq5yM5U3ITBBOZOqNMUzSN7BM3TwpiGaFDvcZrvAxCEaF5+mwMQhTvcbHRbtUO7+zo99vZztIzIqQl4zpMTgREWHResmj1uUEhinc8buV2JYmEJ8fHTztARJstQ5MTRSSf4T1BDToUD3WYofNk75t8/WKLs62QuLStI16UlKGD9aVwU6Xkv7+oxKSZH3Pk+Nm5Kk8sHVSvwWL2k2Xwdn7c36vNSNmagL12RoyLkTLfEaFpGskglXKnLKSMWW7VTt4GsVPzzWoR5hU5IGVJbIqAh5Jkdrg3uyRk8cK6+Ko2odO0JR8UEDamuBY8arYnScBk+cKo/IgeWP78Ncv6hxptwXP36UxmUdVOjECarpbhc25euO3bCUaM1vqtLQIUFq8/NyOP+hvoN10eQbFXZ1uW5VsSJjx0oyxdVVFwzTqLEt8g/1U8yIVO2ID9exIUEalnK2ril17/NcJ4aFaXS8u7zdZ1mOZ50LfT19FR+YoKuGX6O6llqVNpVqZEiKJTddO2quyoJiVWk45mdzTESGRGjKTakKjg3QzHRTG3KTmyWODBlO26d9HrLfTpJC44I1ZGykEhKHamr+dCVOaJPvgUOaeFG0/ENNL1XzD/VT3DUz5LExT4nxEzS2udJSB3MMBccO16HudtjlJocYtf7e2fXuL54Tw8J0ztgsh3YYHuiYI0IThip3yiW6sLpd+cPq1BIQoeEJCZqZ4/wcSKb8NMZrnIzzW22W+4f6acTM8zQno1A+KcPkWxmouUmBKvYcr9iRNUoMm2DaPiZImhStEJ0t922Z8h0/ztJeUi6fpUPNweqsGq/ACamKShmm2wr2WmIwNGGoMmZcoJEeVQpMnNnrOfAP9dPZF09y2natc2loXLCm3JQq/1A/DUtI1P7xy3VOwnzTPqzuL86ERSVpihKUfWOEUu2upYeTPB/qO1jXjpqr5j7uS2bxI8Zp4+wRSg5JVbR3iOJiY3VVm+P+7OPq8IxJurx0UJ8xEuo7WNNGTlPN5HJNiJxouZ+E+g6WEdbmNHYkKTkhUZ9PWq7pSVNVU7lfNdqssUkTLXkhqKxDZarS+RMDNSwpVGVTh5qutUwxExI1SsGH0zXLY7qGDglyuu/UCZPVOPUSBTaXyWvkyF7rEJtytsasXaSG1FZVRl6nYVbXKDI2Spdoj44FTVPJrAKlGEdtYsXZ/dWc80JrDyu2rVTehbmaenSKoqc63sfNfb6so0cU6D9E9S0T1Tm1TaMjRyoqPkjxgQmaOupcFWcWa9jkJB2ana2w8clqnDJdowaZ4jY6yEPj3OOVU2vbpzW3p5DJyYpf86k6R06Ud/QcHWktVnxggkJ8Q3ry3KxWtTa0KHlkhI7mxWtCe6NqknvamTOJoZGK9R+mGp82jS7K0sGrJyl+zEjdVp6nyNixcjcM7b/mTo1NGGqzXUJSsnbErdNMn2CHaxcdEyRNHaqw8RGqt2ov5vtNeEqMzvY4S/vzdmrGpioNn3K5bkpJUmJYmO690KfftmBffvP9KnDMeNWOCNHoC0Is+bc/Q4cEaX7YIKXGRiq/PFleod6aFzbfaY7wni0NGRalgGtmyH9jqSbOitbg2FgdihqloZk7NHj8dZJMeaJk5tUanBiqyNgo3XthcJ91io4Jkn9KmMZ6uql+XIKqgi5XXEKiZrR1KiExVGFO8rT9uR4S26o94zM0xDtXoRPnKSZ3v/xLvDRq9DCVzj5ik5fNZTxy8c0KmZyscUf22vRf/UP9lHLDOWotrlFuR5amJ8232c5z9GxdVCWVpHQp6/xLNPJY323TnBdrpwbp8tKwAfe/JFPbuiT1EgUrXEZzq8N92vx9gs8IS+6OSA5T/P44XRl5tU1uvCT1EsV0JWpQc6R8LnxYEcPG6Zrdey3lcXaf7Ks/2hv7/rvUex++t35Ib+MmayNDUrQ3KUaDhkt3jQnsM8YGUg9n40nfKH+HflCrZ5v8wv0c2omzMYmzsgeOGa+AwDB5JIRrxNYj6qo6x2ledaa3caP5O/tx0xivcfIe5a6pjTM0LGKY5nnMV/6xPCXEJCj8pmibPGG+RqHjPFSUflRxPjkKHj9a+3ZP15AxEzW9brfcZjRZrlfEoAgVpeTqohEznR4vOixa/r5+mjDtWrkd/EZeI0darmugUSq3g7vkNXKkIjqide7elaoK71J04EENH5WqbLucGxaVpPkZcfIaM1ojQoZr3bSNOnfEWJ1b464WzXF6Xc39xpjkSZpSeUi1U4M0pzxEih+lo0WxirvYsR/T1zOFxLAwDR3nrfL22ZrQUqfsGyM0NmmU4uv3alLsRDUYzepKatSGecmaMCJVHpGRCvzZT+U1cqTT/9uPiTwiIxVz0906N7lLObcO1dDkSbomo9hh3GkkT1LK3q908OpJDuPxvpjLY31c+zJ6REZKbu4KHzFeN4ROt9R/XoIpbqJixvVa9kEP3K+upia5+/srJXq8IlrSND5ioipbKpUUNMxyfxsd5aXoQZE6MjhTQwPC1exRoLPqz9WocaM1tnOcRkQO1/4ZWRodOtLSX/WN8re0LeuYjQ9M0OjIOEWHDrYZ55vbeqivz4CfEVn3R0dHBWlklWO+sB+z+QUYvbZH63WnxA1VRmG9pkdfppTA4dpWlKXYyDaFWY39ehMZFaH9MwJVGXmdokeN1zXZ2U7vIc5yprlfNtTq/NgLD/TR/NkTFBpxnWbXHVPuiEolJU3Q6stGafyIcZb1AhOHKDbe0+G5gmRqn8MCElWd3KnQSRM00rtVYXXZKkuZocuPuCtqygjtyTpLqeMSFOzt1et4rrfxg7shS1uek1aqg4lVGj9yhDyGPuIQi+ZcEZAcJ//rWzW2ukaRw6ZpZtEsxYxIVf7ts5UyZrz8775ZkyKGyT/UT112Yxvr51ruboaGrVmikMnXSjL1Acq7+65Dhk3XmMyesV9nh7/mhw1S8sgI7e7u7/uHOo6bImOjdN4WQ4eiClXnG28ZF5j331vfJGZEqjZeMlLjR6RKkqJGTtbWi+MVP3asbsuo0Oi4VI0svUSJKRGavSZNMVdN0qSWTn2aOVaxw1OUf3uNRk45R+6bDmlMWIXCU6bqbA93m3FhakyC1uSfpaSRE9Q4Y5LOaXDXHt84jRx2VIlhExTi46MfnD1Gzb4tynevc+hf299rg2OH68jFo5XS0TPuMPc748aGOuR6e5GxUbrN+4AiY8dqQqePVgQfUmTX+UpOSFT9uHJNbZyhsSnxOmdsrk3fxdyvnBXgZemj24/5J8TEa0XkBk2OmqhhkQEaP36KVl26XZMmnKXAnwXb5OxBD9wvSZZ4i739B7piWJxK2ieqaaqXw7jLut83rrVD6eH7NTnuHIfnkBNi4nV4bLal7ObxY0RBnaraqtWs8zUixle+Xp7qaveXERGjYZEBuvfC4Zb/J0U4vsS9N26GYRj9rXTs2DEFBwerrq5OQUFB/a0OAAAAAAAAAABOY99m3oCfZgIAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHAZJiIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAgAAAAAAAAAAuAwTEQAAAAAAAAAAwGWYiAAAAAAAAAAAAC7DRAQAAAAAAAAAAHCZ7z0RUd1SrfcPvqfDtYf1/sH3VN1SfTzKBQAAAAAAAAAATgPfeyKipqVaH2S+r8L6An2Q+b5qmIgAAAAAAAAAAADd+GkmAAAAAAAAAADgMkxEAAAAAAAAAAAAlzluExHN7U3Ha1cAAAAAAAAAAOA0cdwmIl5N/8fx2hUAAAAAAAAAADhN8NNMAAAAAAAAAADAZZiIAAAAAAAAAAAALsNEBAAAAAAAAAAAcJnjNhHx4PiHjteuAAAAAAAAAADAaeK4TUT4efkfr10BAAAAAAAAAIDTBD/NBAAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALjM956ICPUdrJtSblF8YIJuSrlFob6Dj0e5AAAAAAAAAADAacDz++5gsO9g3TL6VknSsJBh37tAAAAAAAAAAADg9MFPMwEAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJfxHMhKhmFIko4dO+bSwgAAAAAAAAAAgFOfeb7APH/QlwFNRNTX10uS4uLivkexAAAAAAAAAADA6aS+vl7BwcF9ruNmDGC6oqurSyUlJQoMDJSbm9txKyBwshw7dkxxcXEqKipSUFDQyS4O8L0R0zidEM843RDTON0Q0zjdENM43RDTON0Q06cuwzBUX1+vmJgYubv3/RaIAf2LCHd3d8XGxh6XwgGnkqCgIBIYTivENE4nxDNON8Q0TjfENE43xDRON8Q0TjfE9Kmpv38JYcbLqgEAAAAAAAAAgMswEQEAAAAAAAAAAFyGiQickXx8fPT000/Lx8fnZBcFOC6IaZxOiGecbohpnG6IaZxuiGmcbohpnG6I6dPDgF5WDQAAAAAAAAAA8F3wLyIAAAAAAAAAAIDLMBEBAAAAAAAAAABchokIAAAAAAAAAADgMkxEAAAAAAAAAAAAl2EiAqeNZ555RmeffbYCAwMVGRmpq6++WpmZmTbrXHjhhXJzc7P570c/+pHNOoWFhbrsssvk7++vyMhI/eIXv1BHR8eJrAqg3/72tw6xOmrUKMv3LS0tWrBggcLCwhQQEKDrrrtO5eXlNvsglnEqSUxMdIhpNzc3LViwQBL5Gae+DRs26IorrlBMTIzc3Ny0bNkym+8Nw9BTTz2lIUOGyM/PT3PmzFF2drbNOtXV1br11lsVFBSkkJAQ3XvvvWpoaLBZJz09Xeeff758fX0VFxen5557ztVVwxmqr5hub2/X448/rtTUVA0aNEgxMTG64447VFJSYrMPZ7n92WeftVmHmMaJ0l+evuuuuxzi9ZJLLrFZhzyNU0l/Me2sb+3m5qbnn3/esg55GqeKgTyzO17POdatW6fJkyfLx8dHI0aM0FtvveXq6mGAmIjAaWP9+vVasGCBtm7dqpUrV6q9vV1z585VY2OjzXr333+/SktLLf9Z32Q7Ozt12WWXqa2tTZs3b9bbb7+tt956S0899dSJrg6gsWPH2sTqpk2bLN/99Kc/1WeffabFixdr/fr1Kikp0bXXXmv5nljGqWbHjh028bxy5UpJ0g033GBZh/yMU1ljY6MmTJigV155xen3zz33nF566SW99tpr2rZtmwYNGqR58+appaXFss6tt96q/fv3a+XKlfr888+1YcMGPfDAA5bvjx07prlz5yohIUG7du3S888/r9/+9rf65z//6fL64czTV0w3NTVp9+7devLJJ7V7924tWbJEmZmZuvLKKx3W/f3vf2+Tux955BHLd8Q0TqT+8rQkXXLJJTbxumjRIpvvydM4lfQX09axXFpaqoULF8rNzU3XXXedzXrkaZwKBvLM7ng858jLy9Nll12miy66SGlpaXr00Ud13333acWKFSe0vuiFAZymKioqDEnG+vXrLcsuuOAC4yc/+Umv23z55ZeGu7u7UVZWZln26quvGkFBQUZra6sriwvYePrpp40JEyY4/a62ttbw8vIyFi9ebFl28OBBQ5KxZcsWwzCIZZz6fvKTnxjDhw83urq6DMMgP+N/iyRj6dKlls9dXV1GdHS08fzzz1uW1dbWGj4+PsaiRYsMwzCMAwcOGJKMHTt2WNZZvny54ebmZhw5csQwDMP4xz/+YYSGhtrE9OOPP26kpKS4uEY409nHtDPbt283JBkFBQWWZQkJCcaLL77Y6zbENE4WZzF95513GldddVWv25CncSobSJ6+6qqrjFmzZtksI0/jVGX/zO54Pef45S9/aYwdO9bmWD/4wQ+MefPmubpKGAD+RQROW3V1dZKkwYMH2yx/7733FB4ernHjxumJJ55QU1OT5bstW7YoNTVVUVFRlmXz5s3TsWPHtH///hNTcKBbdna2YmJiNGzYMN16660qLCyUJO3atUvt7e2aM2eOZd1Ro0YpPj5eW7ZskUQs49TW1tamd999V/fcc4/c3Nwsy8nP+F+Vl5ensrIym7wcHBysqVOn2uTlkJAQnXXWWZZ15syZI3d3d23bts2yzsyZM+Xt7W1ZZ968ecrMzFRNTc0Jqg3gXF1dndzc3BQSEmKz/Nlnn1VYWJgmTZqk559/3ubnEYhpnGrWrVunyMhIpaSk6MEHH1RVVZXlO/I0/peVl5friy++0L333uvwHXkapyL7Z3bH6znHli1bbPZhXse8D5xcnie7AIArdHV16dFHH9X06dM1btw4y/JbbrlFCQkJiomJUXp6uh5//HFlZmZqyZIlkqSysjKbhCbJ8rmsrOzEVQBnvKlTp+qtt95SSkqKSktL9bvf/U7nn3++9u3bp7KyMnl7ezs8CIiKirLEKbGMU9myZctUW1uru+66y7KM/Iz/ZeYYdBaj1nk5MjLS5ntPT08NHjzYZp2kpCSHfZi/Cw0NdUn5gf60tLTo8ccf180336ygoCDL8h//+MeaPHmyBg8erM2bN+uJJ55QaWmpXnjhBUnENE4tl1xyia699lolJSUpNzdXv/71rzV//nxt2bJFHh4e5Gn8T3v77bcVGBho8zM2EnkapyZnz+yO13OO3tY5duyYmpub5efn54oqYYCYiMBpacGCBdq3b5/Nb+pLsvl9z9TUVA0ZMkSzZ89Wbm6uhg8ffqKLCfRq/vz5lj+PHz9eU6dOVUJCgv773/9y48T/vH//+9+aP3++YmJiLMvIzwBwampvb9eNN94owzD06quv2nz3s5/9zPLn8ePHy9vbWz/84Q/1zDPPyMfH50QXFejTTTfdZPlzamqqxo8fr+HDh2vdunWaPXv2SSwZ8P0tXLhQt956q3x9fW2Wk6dxKurtmR1Of/w0E047Dz/8sD7//HOtXbtWsbGxfa47depUSVJOTo4kKTo6WuXl5TbrmD9HR0e7oLTAwISEhGjkyJHKyclRdHS02traVFtba7NOeXm5JU6JZZyqCgoKtGrVKt133319rkd+xv8Scww6i1HrvFxRUWHzfUdHh6qrq8ndOGWZJyEKCgq0cuVKm38N4czUqVPV0dGh/Px8ScQ0Tm3Dhg1TeHi4TV+DPI3/RRs3blRmZma//WuJPI2Tr7dndsfrOUdv6wQFBfGXOk8BTETgtGEYhh5++GEtXbpUa9ascfjnhc6kpaVJkoYMGSJJmjZtmjIyMmw6oOZB15gxY1xSbmAgGhoalJubqyFDhmjKlCny8vLS6tWrLd9nZmaqsLBQ06ZNk0Qs49T15ptvKjIyUpdddlmf65Gf8b8kKSlJ0dHRNnn52LFj2rZtm01erq2t1a5duyzrrFmzRl1dXZaJt2nTpmnDhg1qb2+3rLNy5UqlpKTw0wg44cyTENnZ2Vq1apXCwsL63SYtLU3u7u6Wn7chpnEqKy4uVlVVlU1fgzyN/0X//ve/NWXKFE2YMKHfdcnTOFn6e2Z3vJ5zTJs2zWYf5nXM+8BJdpJflg0cNw8++KARHBxsrFu3zigtLbX819TUZBiGYeTk5Bi///3vjZ07dxp5eXnGJ598YgwbNsyYOXOmZR8dHR3GuHHjjLlz5xppaWnGV199ZURERBhPPPHEyaoWzlA///nPjXXr1hl5eXnGN998Y8yZM8cIDw83KioqDMMwjB/96EdGfHy8sWbNGmPnzp3GtGnTjGnTplm2J5ZxKurs7DTi4+ONxx9/3GY5+Rn/C+rr6409e/YYe/bsMSQZL7zwgrFnzx6joKDAMAzDePbZZ42QkBDjk08+MdLT042rrrrKSEpKMpqbmy37uOSSS4xJkyYZ27ZtMzZt2mQkJycbN998s+X72tpaIyoqyrj99tuNffv2GR988IHh7+9vvP766ye8vjj99RXTbW1txpVXXmnExsYaaWlpNn3r1tZWwzAMY/PmzcaLL75opKWlGbm5uca7775rREREGHfccYflGMQ0TqS+Yrq+vt547LHHjC1bthh5eXnGqlWrjMmTJxvJyclGS0uLZR/kaZxK+ut7GIZh1NXVGf7+/sarr77qsD15GqeS/p7ZGcbxec5x+PBhw9/f3/jFL35hHDx40HjllVcMDw8P46uvvjqh9YVzTETgtCHJ6X9vvvmmYRiGUVhYaMycOdMYPHiw4ePjY4wYMcL4xS9+YdTV1dnsJz8/35g/f77h5+dnhIeHGz//+c+N9vb2k1AjnMl+8IMfGEOGDDG8vb2NoUOHGj/4wQ+MnJwcy/fNzc3GQw89ZISGhhr+/v7GNddcY5SWltrsg1jGqWbFihWGJCMzM9NmOfkZ/wvWrl3rtJ9x5513GoZhGF1dXcaTTz5pREVFGT4+Psbs2bMdYr2qqsq4+eabjYCAACMoKMi4++67jfr6ept19u7da8yYMcPw8fExhg4dajz77LMnqoo4w/QV03l5eb32rdeuXWsYhmHs2rXLmDp1qhEcHGz4+voao0ePNv70pz/ZPNQ1DGIaJ05fMd3U1GTMnTvXiIiIMLy8vIyEhATj/vvvN8rKymz2QZ7GqaS/vodhGMbrr79u+Pn5GbW1tQ7bk6dxKunvmZ1hHL/nHGvXrjUmTpxoeHt7G8OGDbM5Bk4uN8MwDBf9YwsAAAAAAAAAAHCG4x0RAAAAAAAAAADAZZiIAAAAAAAAAAAALsNEBAAAAAAAAAAAcBkmIgAAAAAAAAAAgMswEQEAAAAAAAAAAFyGiQgAAAAAAAAAAOAyTEQAAAAAAAAAAACXYSICAAAAAAAAAAC4DBMRAAAAAGzcdddduvrqq092MQAAAACcJjxPdgEAAAAAnDhubm59fv/000/rb3/7mwzDOEElAgAAAHC6YyICAAAAOIOUlpZa/vzhhx/qqaeeUmZmpmVZQECAAgICTkbRAAAAAJym+GkmAAAA4AwSHR1t+S84OFhubm42ywICAhx+munCCy/UI488okcffVShoaGKiorSG2+8ocbGRt19990KDAzUiBEjtHz5cptj7du3T/Pnz1dAQICioqJ0++23q7Ky8gTXGAAAAMDJxkQEAAAAgH69/fbbCg8P1/bt2/XII4/owQcf1A033KDzzjtPu3fv1ty5c3X77berqalJklRbW6tZs2Zp0qRJ2rlzp7766iuVl5frxhtvPMk1AQAAAHCiMREBAAAAoF8TJkzQ//t//0/Jycl64okn5Ovrq/DwcN1///1KTk7WU089paqqKqWnp0uS/v73v2vSpEn605/+pFGjRmnSpElauHCh1q5dq6ysrJNcGwAAAAAnEu+IAAAAANCv8ePHW/7s4eGhsLAwpaamWpZFRUVJkioqKiRJe/fu1dq1a52+byI3N1cjR450cYkBAAAAnCqYiAAAAADQLy8vL5vPbm5uNsvc3NwkSV1dXZKkhoYGXXHFFfrzn//ssK8hQ4a4sKQAAAAATjVMRAAAAAA47iZPnqyPP/5YiYmJ8vRk2AEAAACcyXhHBAAAAIDjbsGCBaqurtbNN9+sHTt2KDc3VytWrNDdd9+tzs7Ok108AAAAACcQExEAAAAAjruYmBh988036uzs1Ny5c5WamqpHH31UISEhcndnGAIAAACcSdwMwzBOdiEAAAAAAAAAAMDpib+KBAAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJdhIgIAAAAAAAAAALgMExEAAAAAAAAAAMBlmIgAAAAAAAAAAAAuw0QEAAAAAAAAAABwGSYiAAAAAAAAAACAyzARAQAAAAAAAAAAXIaJCAAAAAAAAAAA4DJMRAAAAAAAAAAAAJf5/wHvIgEn1nCNzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7635b95953a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the very long cell at the end of the notebook before running this cell\n",
    "\n",
    "print(\"Clustering Diarizer Result (RTTM format)\")\n",
    "pred_labels_neural = rttm_to_labels(\"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002a.Array1-01.rttm\")\n",
    "hypothesis_neural = labels_to_pyannote_object(pred_labels_neural)\n",
    "hypothesis_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7635b975a070>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\"\n",
    "truth_labels = rttm_to_labels(truth)\n",
    "truth_graph = labels_to_pyannote_object(truth_labels)\n",
    "truth_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x735f8b914a60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = '/home/kozi/Documents/_onlab_git/ami/tinydiarize_output.rttm'\n",
    "truth_labels = rttm_to_labels(truth)\n",
    "truth_graph = labels_to_pyannote_object(truth_labels)\n",
    "truth_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x7c77806861f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = \"/home/kozi/Documents/_onlab_git/ami/whisper_cpp_tdrz_rttm.rttm\"\n",
    "truth_labels = rttm_to_labels(truth)\n",
    "truth_graph = labels_to_pyannote_object(truth_labels)\n",
    "truth_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading speaker turns from reference RTTMs...\n",
      "Loading speaker turns from system RTTMs...\n",
      "WARNING: No universal evaluation map specified. Approximating from reference and speaker turn extents...\n",
      "Trimming reference speaker turns to UEM scoring regions...\n",
      "Trimming system speaker turns to UEM scoring regions...\n",
      "Checking for overlapping reference speaker turns...\n",
      "Checking for overlapping system speaker turns...\n",
      "Scoring...\n",
      "File               DER    JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
      "---------------  -----  -----  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
      "EN2002a          29.88  34.69            0.54         0.79     0.64             0.72             0.47          1.64          0.57  1.62   0.60\n",
      "EN2002b          27.79  33.57            0.60         0.83     0.69             0.78             0.52          1.42          0.46  1.71   0.66\n",
      "*** OVERALL ***  28.97  34.13            0.56         0.81     0.66             0.78             0.53          1.54          0.52  2.65   0.73\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/kozi/Documents/_onlab_git/dscore/score.py -s \"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002a.rttm\" \"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002b.rttm\" -r \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\" \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002b.rttm\"\n",
    "# -s: system outputs [predicted rttm]; -r: reference [ground-truth rttm]\n",
    "# two errors: in metrics.py np.int is deprecated, the builtin int should be used\n",
    "#    global_der = file_to_der_base.get('ALL', 0.0) # a safe getter should be used to get 'ALL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading speaker turns from reference RTTMs...\n",
      "Loading speaker turns from system RTTMs...\n",
      "WARNING: No universal evaluation map specified. Approximating from reference and speaker turn extents...\n",
      "Trimming reference speaker turns to UEM scoring regions...\n",
      "Trimming system speaker turns to UEM scoring regions...\n",
      "Checking for overlapping reference speaker turns...\n",
      "Checking for overlapping system speaker turns...\n",
      "Scoring...\n",
      "File               DER    JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
      "---------------  -----  -----  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
      "EN2002a           5.43  34.69            0.54         0.79     0.64             0.72             0.47          1.64          0.57  1.62   0.60\n",
      "EN2002b           3.97  33.57            0.60         0.83     0.69             0.78             0.52          1.42          0.46  1.71   0.66\n",
      "*** OVERALL ***   4.78  34.13            0.56         0.81     0.66             0.78             0.53          1.54          0.52  2.65   0.73\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/kozi/Documents/_onlab_git/dscore/score.py --collar 0.100 --ignore_overlaps -s \"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002a.rttm\" \"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002b.rttm\" -r \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\" \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002b.rttm\"\n",
    "# -s: system outputs [predicted rttm]; -r: reference [ground-truth rttm]\n",
    "# two errors: in metrics.py np.int is deprecated, the builtin int should be used\n",
    "#    global_der = file_to_der_base.get('ALL', 0.0) # a safe getter should be used to get 'ALL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading speaker turns from reference RTTMs...\n",
      "Loading speaker turns from system RTTMs...\n",
      "Loading universal evaluation map...\n",
      "Trimming reference speaker turns to UEM scoring regions...\n",
      "Trimming system speaker turns to UEM scoring regions...\n",
      "Checking for overlapping reference speaker turns...\n",
      "Checking for overlapping system speaker turns...\n",
      "Scoring...\n",
      "File               DER    JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
      "---------------  -----  -----  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
      "EN2002a          29.88  34.69            0.54         0.79     0.64             0.72             0.47          1.64          0.57  1.62   0.61\n",
      "*** OVERALL ***  29.88  34.69            0.54         0.79     0.64             0.72             0.47          1.64          0.57  1.62   0.61\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/kozi/Documents/_onlab_git/dscore/score.py -u \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/uem/EN2002a.uem\" -s \"/home/kozi/Documents/_onlab_git/ami/tmp/pred_rttms/EN2002a.rttm\" -r \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\"\n",
    "# UEM [unpartitioned evaluation map] files do not change the scoring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import all functions from speaker_utils.py\n",
    "\n",
    "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import omegaconf\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from pyannote.core import Annotation, Segment\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nemo.collections.asr.data.audio_to_label import repeat_signal\n",
    "#from nemo.collections.asr.parts.utils.longform_clustering import LongFormSpeakerClustering\n",
    "#from nemo.collections.asr.parts.utils.offline_clustering import SpeakerClustering, get_argmin_mat, split_input_data\n",
    "#from nemo.utils import logging\n",
    "\n",
    "\"\"\"\n",
    "This file contains all the utility functions required for speaker embeddings part in diarization scripts\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_uniqname_from_filepath(filepath):\n",
    "    \"\"\"\n",
    "    Return base name from provided filepath\n",
    "    \"\"\"\n",
    "    if type(filepath) is str:\n",
    "        uniq_id = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        return uniq_id\n",
    "    else:\n",
    "        raise TypeError(\"input must be filepath string\")\n",
    "\n",
    "\n",
    "def get_uniq_id_from_manifest_line(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve `uniq_id` from the `audio_filepath` in a manifest line.\n",
    "    \"\"\"\n",
    "    dic = json.loads(line.strip())\n",
    "    uniq_id = get_uniqname_from_filepath(dic['audio_filepath'])\n",
    "    return uniq_id\n",
    "\n",
    "\n",
    "def get_uniq_id_with_dur(meta, decimals=3):\n",
    "    \"\"\"\n",
    "    Return basename with offset and end time labels\n",
    "    \"\"\"\n",
    "    # bare_uniq_id = get_uniqname_from_filepath(meta['audio_filepath'])\n",
    "    bare_uniq_id = get_uniqname_from_filepath(meta['rttm_filepath'])\n",
    "    if meta['offset'] is None and meta['duration'] is None:\n",
    "        return bare_uniq_id\n",
    "    if meta['offset']:\n",
    "        offset = str(int(round(meta['offset'], decimals) * pow(10, decimals)))\n",
    "    else:\n",
    "        offset = 0\n",
    "    if meta['duration']:\n",
    "        endtime = str(int(round(meta['offset'] + meta['duration'], decimals) * pow(10, decimals)))\n",
    "    else:\n",
    "        endtime = 'NULL'\n",
    "    uniq_id = f\"{bare_uniq_id}_{offset}_{endtime}\"\n",
    "    return uniq_id\n",
    "\n",
    "\n",
    "def audio_rttm_map(manifest, attach_dur=False):\n",
    "    \"\"\"\n",
    "    This function creates AUDIO_RTTM_MAP which is used by all diarization components to extract embeddings,\n",
    "    cluster and unify time stamps\n",
    "    Args: manifest file that contains keys audio_filepath, rttm_filepath if exists, text, num_speakers if known and uem_filepath if exists\n",
    "\n",
    "    returns:\n",
    "    AUDIO_RTTM_MAP (dict) : A dictionary with keys of uniq id, which is being used to map audio files and corresponding rttm files\n",
    "    \"\"\"\n",
    "\n",
    "    AUDIO_RTTM_MAP = {}\n",
    "    with open(manifest, 'r') as inp_file:\n",
    "        lines = inp_file.readlines()\n",
    "        logging.info(\"Number of files to diarize: {}\".format(len(lines)))\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "\n",
    "            meta = {\n",
    "                'audio_filepath': dic['audio_filepath'],\n",
    "                'rttm_filepath': dic.get('rttm_filepath', None),\n",
    "                'offset': dic.get('offset', None),\n",
    "                'duration': dic.get('duration', None),\n",
    "                'text': dic.get('text', None),\n",
    "                'num_speakers': dic.get('num_speakers', None),\n",
    "                'uem_filepath': dic.get('uem_filepath', None),\n",
    "                'ctm_filepath': dic.get('ctm_filepath', None),\n",
    "            }\n",
    "            if attach_dur:\n",
    "                uniqname = get_uniq_id_with_dur(meta)\n",
    "            else:\n",
    "                uniqname = get_uniqname_from_filepath(filepath=meta['audio_filepath'])\n",
    "\n",
    "            if uniqname not in AUDIO_RTTM_MAP:\n",
    "                AUDIO_RTTM_MAP[uniqname] = meta\n",
    "            else:\n",
    "                raise KeyError(\n",
    "                    \"file {} is already part of AUDIO_RTTM_MAP, it might be duplicated, Note: file basename must be unique\".format(\n",
    "                        meta['audio_filepath']\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return AUDIO_RTTM_MAP\n",
    "\n",
    "\n",
    "def parse_scale_configs(window_lengths_in_sec, shift_lengths_in_sec, multiscale_weights):\n",
    "    \"\"\"\n",
    "    Check whether multiscale parameters are provided correctly. window_lengths_in_sec, shift_lengfhs_in_sec and\n",
    "    multiscale_weights should be all provided in omegaconf.listconfig.ListConfig type. In addition, the scales\n",
    "    should be provided in descending order, from the longest scale to the base scale (the shortest).\n",
    "\n",
    "    Example:\n",
    "        Single-scale setting:\n",
    "            parameters.window_length_in_sec=1.5\n",
    "            parameters.shift_length_in_sec=0.75\n",
    "            parameters.multiscale_weights=null\n",
    "\n",
    "        Multiscale setting (base scale - window_length 0.5 s and shift_length 0.25):\n",
    "            parameters.window_length_in_sec=[1.5,1.0,0.5]\n",
    "            parameters.shift_length_in_sec=[0.75,0.5,0.25]\n",
    "            parameters.multiscale_weights=[1,1,1]\n",
    "\n",
    "    In addition, you can also specify session-by-session multiscale weight. In this case, each dictionary key\n",
    "    points to different weights.\n",
    "    \"\"\"\n",
    "    check_float_config = [isinstance(var, float) for var in (window_lengths_in_sec, shift_lengths_in_sec)]\n",
    "    check_list_config = [\n",
    "        isinstance(var, (omegaconf.listconfig.ListConfig, list, tuple))\n",
    "        for var in (window_lengths_in_sec, shift_lengths_in_sec, multiscale_weights)\n",
    "    ]\n",
    "    if all(check_list_config) or all(check_float_config):\n",
    "\n",
    "        # If bare floating numbers are provided, convert them to list format.\n",
    "        if all(check_float_config):\n",
    "            window_lengths, shift_lengths, multiscale_weights = (\n",
    "                [window_lengths_in_sec],\n",
    "                [shift_lengths_in_sec],\n",
    "                [1.0],\n",
    "            )\n",
    "        else:\n",
    "            window_lengths, shift_lengths, multiscale_weights = (\n",
    "                window_lengths_in_sec,\n",
    "                shift_lengths_in_sec,\n",
    "                multiscale_weights,\n",
    "            )\n",
    "\n",
    "        length_check = (\n",
    "            len(set([len(window_lengths), len(shift_lengths), len(multiscale_weights)])) == 1\n",
    "            and len(multiscale_weights) > 0\n",
    "        )\n",
    "        scale_order_check = (\n",
    "            list(window_lengths) == sorted(window_lengths)[::-1] and list(shift_lengths) == sorted(shift_lengths)[::-1]\n",
    "        )\n",
    "\n",
    "        # Check whether window lengths are longer than shift lengths\n",
    "        if len(window_lengths) > 1:\n",
    "            shift_length_check = all([w > s for w, s in zip(window_lengths, shift_lengths)])\n",
    "        else:\n",
    "            shift_length_check = window_lengths[0] > shift_lengths[0]\n",
    "\n",
    "        multiscale_args_dict = {'use_single_scale_clustering': False}\n",
    "        if all([length_check, scale_order_check, shift_length_check]):\n",
    "            if len(window_lengths) > 1:\n",
    "                multiscale_args_dict['scale_dict'] = {\n",
    "                    k: (w, s) for k, (w, s) in enumerate(zip(window_lengths, shift_lengths))\n",
    "                }\n",
    "            else:\n",
    "                multiscale_args_dict['scale_dict'] = {0: (window_lengths[0], shift_lengths[0])}\n",
    "            multiscale_args_dict['multiscale_weights'] = multiscale_weights\n",
    "            return multiscale_args_dict\n",
    "        else:\n",
    "            raise ValueError('Multiscale parameters are not properly setup.')\n",
    "\n",
    "    elif any(check_list_config):\n",
    "        raise ValueError(\n",
    "            'You must provide a list config for all three parameters: window, shift and multiscale weights.'\n",
    "        )\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_embs_and_timestamps(multiscale_embeddings_and_timestamps, multiscale_args_dict):\n",
    "    \"\"\"\n",
    "    The embeddings and timestamps in multiscale_embeddings_and_timestamps dictionary are\n",
    "    indexed by scale index. This function rearranges the extracted speaker embedding and\n",
    "    timestamps by unique ID to make the further processing more convenient.\n",
    "\n",
    "    Args:\n",
    "        multiscale_embeddings_and_timestamps (dict):\n",
    "            Dictionary of embeddings and timestamps for each scale.\n",
    "        multiscale_args_dict (dict):\n",
    "            Dictionary of scale information: window, shift and multiscale weights.\n",
    "\n",
    "    Returns:\n",
    "        embs_and_timestamps (dict)\n",
    "            A dictionary containing embeddings and timestamps of each scale, indexed by unique ID.\n",
    "    \"\"\"\n",
    "    embs_and_timestamps = {uniq_id: {} for uniq_id in multiscale_embeddings_and_timestamps[0][0].keys()}\n",
    "    if multiscale_args_dict['use_single_scale_clustering']:\n",
    "        _multiscale_args_dict = deepcopy(multiscale_args_dict)\n",
    "        _multiscale_args_dict['scale_dict'] = {0: multiscale_args_dict['scale_dict'][0]}\n",
    "        _multiscale_args_dict['multiscale_weights'] = multiscale_args_dict['multiscale_weights'][:1]\n",
    "    else:\n",
    "        _multiscale_args_dict = multiscale_args_dict\n",
    "\n",
    "    embeddings, timestamps = multiscale_embeddings_and_timestamps[0]\n",
    "    for uniq_id in embeddings.keys():\n",
    "        embeddings_list, time_stamps_list, segment_index_list = [], [], []\n",
    "        for scale_idx in sorted(_multiscale_args_dict['scale_dict'].keys()):\n",
    "            embeddings, timestamps = multiscale_embeddings_and_timestamps[scale_idx]\n",
    "            if len(embeddings[uniq_id]) != len(timestamps[uniq_id]):\n",
    "                raise ValueError(\"Mismatch of counts between embedding vectors and timestamps\")\n",
    "            time_stamps_tensor = torch.tensor(timestamps[uniq_id])\n",
    "            embeddings_list.append(embeddings[uniq_id])\n",
    "            segment_index_list.append(embeddings[uniq_id].shape[0])\n",
    "            time_stamps_list.append(time_stamps_tensor)\n",
    "\n",
    "        embs_and_timestamps[uniq_id]['multiscale_weights'] = (\n",
    "            torch.tensor(_multiscale_args_dict['multiscale_weights']).unsqueeze(0).float()\n",
    "        )\n",
    "        embs_and_timestamps[uniq_id]['embeddings'] = torch.cat(embeddings_list, dim=0)\n",
    "        embs_and_timestamps[uniq_id]['timestamps'] = torch.cat(time_stamps_list, dim=0)\n",
    "        embs_and_timestamps[uniq_id]['multiscale_segment_counts'] = torch.tensor(segment_index_list)\n",
    "\n",
    "    return embs_and_timestamps\n",
    "\n",
    "\n",
    "def get_timestamps(multiscale_timestamps, multiscale_args_dict):\n",
    "    \"\"\"\n",
    "    The timestamps in `multiscale_timestamps` dictionary are indexed by scale index.\n",
    "    This function rearranges the extracted speaker embedding and timestamps by unique ID to make the further processing more convenient.\n",
    "\n",
    "    Args:\n",
    "        multiscale_timestamps (dict):\n",
    "            Dictionary of timestamps for each scale.\n",
    "        multiscale_args_dict (dict):\n",
    "            Dictionary of scale information: window, shift and multiscale weights.\n",
    "\n",
    "    Returns:\n",
    "        timestamps_dict (dict)\n",
    "            A dictionary containing embeddings and timestamps of each scale, indexed by unique ID.\n",
    "    \"\"\"\n",
    "    timestamps_dict = {uniq_id: {'scale_dict': {}} for uniq_id in multiscale_timestamps[0].keys()}\n",
    "    for scale_idx in sorted(multiscale_args_dict['scale_dict'].keys()):\n",
    "        time_stamps = multiscale_timestamps[scale_idx]\n",
    "        for uniq_id in time_stamps.keys():\n",
    "            timestamps_dict[uniq_id]['scale_dict'][scale_idx] = {\n",
    "                'time_stamps': time_stamps[uniq_id],\n",
    "            }\n",
    "\n",
    "    return timestamps_dict\n",
    "\n",
    "\n",
    "def get_contiguous_stamps(stamps):\n",
    "    \"\"\"\n",
    "    Return contiguous time stamps\n",
    "    \"\"\"\n",
    "    lines = deepcopy(stamps)\n",
    "    contiguous_stamps = []\n",
    "    for i in range(len(lines) - 1):\n",
    "        start, end, speaker = lines[i].split()\n",
    "        next_start, next_end, next_speaker = lines[i + 1].split()\n",
    "        if float(end) > float(next_start):\n",
    "            avg = str((float(next_start) + float(end)) / 2.0)\n",
    "            lines[i + 1] = ' '.join([avg, next_end, next_speaker])\n",
    "            contiguous_stamps.append(start + \" \" + avg + \" \" + speaker)\n",
    "        else:\n",
    "            contiguous_stamps.append(start + \" \" + end + \" \" + speaker)\n",
    "    start, end, speaker = lines[-1].split()\n",
    "    contiguous_stamps.append(start + \" \" + end + \" \" + speaker)\n",
    "    return contiguous_stamps\n",
    "\n",
    "\n",
    "def merge_stamps(lines):\n",
    "    \"\"\"\n",
    "    Merge time stamps of the same speaker.\n",
    "    \"\"\"\n",
    "    stamps = deepcopy(lines)\n",
    "    overlap_stamps = []\n",
    "    for i in range(len(stamps) - 1):\n",
    "        start, end, speaker = stamps[i].split()\n",
    "        next_start, next_end, next_speaker = stamps[i + 1].split()\n",
    "        if float(end) == float(next_start) and speaker == next_speaker:\n",
    "            stamps[i + 1] = ' '.join([start, next_end, next_speaker])\n",
    "        else:\n",
    "            overlap_stamps.append(start + \" \" + end + \" \" + speaker)\n",
    "\n",
    "    start, end, speaker = stamps[-1].split()\n",
    "    overlap_stamps.append(start + \" \" + end + \" \" + speaker)\n",
    "\n",
    "    return overlap_stamps\n",
    "\n",
    "\n",
    "def labels_to_pyannote_object(labels, uniq_name=''):\n",
    "    \"\"\"\n",
    "    Convert the given labels to pyannote object to calculate DER and for visualization\n",
    "    \"\"\"\n",
    "    annotation = Annotation(uri=uniq_name)\n",
    "    for label in labels:\n",
    "        start, end, speaker = label.strip().split()\n",
    "        start, end = float(start), float(end)\n",
    "        annotation[Segment(start, end)] = speaker\n",
    "\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def labels_to_rttmfile(labels, uniq_id, out_rttm_dir):\n",
    "    \"\"\"\n",
    "    Write rttm file with uniq_id name in out_rttm_dir with timestamps in labels\n",
    "    \"\"\"\n",
    "    filename = os.path.join(out_rttm_dir, uniq_id + '.rttm')\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in labels:\n",
    "            line = line.strip()\n",
    "            start, end, speaker = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            start = float(start)\n",
    "            log = 'SPEAKER {} 1   {:.3f}   {:.3f} <NA> <NA> {} <NA> <NA>\\n'.format(uniq_id, start, duration, speaker)\n",
    "            f.write(log)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def string_to_float(x, round_digits):\n",
    "    \"\"\"\n",
    "    Convert string to float then round the number.\n",
    "    \"\"\"\n",
    "    return round(float(x), round_digits)\n",
    "\n",
    "\n",
    "def convert_rttm_line(rttm_line, round_digits=3):\n",
    "    \"\"\"\n",
    "    Convert a line in RTTM file to speaker label, start and end timestamps.\n",
    "\n",
    "    Args:\n",
    "        rttm_line (str):\n",
    "            A line in RTTM formatted file containing offset and duration of each segment.\n",
    "        round_digits (int):\n",
    "            Number of digits to be rounded.\n",
    "\n",
    "    Returns:\n",
    "        start (float)\n",
    "            Start timestamp in floating point number.\n",
    "        end (float):\n",
    "            End timestamp in floating point number.\n",
    "        speaker (str):\n",
    "            speaker string in RTTM lines.\n",
    "    \"\"\"\n",
    "    rttm = rttm_line.strip().split()\n",
    "    start = string_to_float(rttm[3], round_digits)\n",
    "    end = string_to_float(rttm[4], round_digits) + string_to_float(rttm[3], round_digits)\n",
    "    speaker = rttm[7]\n",
    "    return start, end, speaker\n",
    "\n",
    "\n",
    "def rttm_to_labels(rttm_filename):\n",
    "    \"\"\"\n",
    "    Prepare time stamps label list from rttm file\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    with open(rttm_filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            start, end, speaker = convert_rttm_line(line, round_digits=3)\n",
    "            labels.append('{} {} {}'.format(start, end, speaker))\n",
    "    return labels\n",
    "\n",
    "\n",
    "def write_cluster_labels(base_scale_idx, lines_cluster_labels, out_rttm_dir):\n",
    "    \"\"\"\n",
    "    Write cluster labels that are generated from clustering into a file.\n",
    "    Args:\n",
    "        base_scale_idx (int): The base scale index which is the highest scale index.\n",
    "        lines_cluster_labels (list): The start and end time-stamps of each segment with the predicted cluster label.\n",
    "        out_rttm_dir (str): The path where output rttm files are saved.\n",
    "    \"\"\"\n",
    "    out_label_name = os.path.join(\n",
    "        out_rttm_dir, '../speaker_outputs', f'subsegments_scale{base_scale_idx}_cluster.label'\n",
    "    )\n",
    "    with open(out_label_name, 'w') as f:\n",
    "        for clus_label_line in lines_cluster_labels:\n",
    "            f.write(clus_label_line)\n",
    "\n",
    "\n",
    "def generate_cluster_labels(segment_ranges: List[str], cluster_labels: List[int]):\n",
    "    \"\"\"\n",
    "    Generate cluster (speaker labels) from the segment_range list and cluster label list.\n",
    "\n",
    "    Args:\n",
    "        segment_ranges (list):\n",
    "            List containing intervals (start and end timestapms, ranges) of each segment\n",
    "        cluster_labels (list):\n",
    "            List containing a cluster label sequence\n",
    "\n",
    "    Returns:\n",
    "        diar_hyp (list):\n",
    "            List containing merged speaker-turn-level timestamps and labels in string format\n",
    "            Example:\n",
    "                >>>  diar_hyp = ['0.0 4.375 speaker_1', '4.375 5.125 speaker_0', ...]\n",
    "\n",
    "        lines (list)\n",
    "            List containing raw segment-level timestamps and labels in raw digits\n",
    "                >>>  diar_hyp = ['0.0 0.25 speaker_1', '0.25 0.5 speaker_1', ..., '4.125 4.375 speaker_1']\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for idx, label in enumerate(cluster_labels):\n",
    "        tag = 'speaker_' + str(label)\n",
    "        stt, end = segment_ranges[idx]\n",
    "        lines.append(f\"{stt} {end} {tag}\")\n",
    "    cont_lines = get_contiguous_stamps(lines)\n",
    "    diar_hyp = merge_stamps(cont_lines)\n",
    "    return diar_hyp, lines\n",
    "\n",
    "\n",
    "def perform_clustering(\n",
    "    embs_and_timestamps, AUDIO_RTTM_MAP, out_rttm_dir, clustering_params, device, verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs spectral clustering on embeddings with time stamps generated from VAD output\n",
    "\n",
    "    Args:\n",
    "        embs_and_timestamps (dict): This dictionary contains the following items indexed by unique IDs.\n",
    "            'embeddings' : Tensor containing embeddings. Dimensions:(# of embs) x (emb. dimension)\n",
    "            'timestamps' : Tensor containing ime stamps list for each audio recording\n",
    "            'multiscale_segment_counts' : Tensor containing the number of segments for each scale\n",
    "        AUDIO_RTTM_MAP (dict): AUDIO_RTTM_MAP for mapping unique id with audio file path and rttm path\n",
    "        out_rttm_dir (str): Path to write predicted rttms\n",
    "        clustering_params (dict): clustering parameters provided through config that contains max_num_speakers (int),\n",
    "        oracle_num_speakers (bool), max_rp_threshold(float), sparse_search_volume(int) and enhance_count_threshold (int)\n",
    "        use_torch_script (bool): Boolean that determines whether to use torch.jit.script for speaker clustering\n",
    "        device (torch.device): Device we are running on ('cpu', 'cuda').\n",
    "        verbose (bool): Enable TQDM progress bar.\n",
    "\n",
    "    Returns:\n",
    "        all_reference (list[uniq_name,Annotation]): reference annotations for score calculation\n",
    "        all_hypothesis (list[uniq_name,Annotation]): hypothesis annotations for score calculation\n",
    "\n",
    "    \"\"\"\n",
    "    all_hypothesis = []\n",
    "    all_reference = []\n",
    "    no_references = False\n",
    "    lines_cluster_labels = []\n",
    "\n",
    "    cuda = True\n",
    "    if device.type != 'cuda':\n",
    "        logging.warning(\"cuda=False, using CPU for eigen decomposition. This might slow down the clustering process.\")\n",
    "        cuda = False\n",
    "\n",
    "    speaker_clustering = LongFormSpeakerClustering(cuda=cuda)\n",
    "\n",
    "    if clustering_params.get('export_script_module', False):\n",
    "        speaker_clustering = torch.jit.script(speaker_clustering)\n",
    "        torch.jit.save(speaker_clustering, 'speaker_clustering_script.pt')\n",
    "\n",
    "    for uniq_id, audio_rttm_values in tqdm(AUDIO_RTTM_MAP.items(), desc='clustering', leave=True, disable=not verbose):\n",
    "        uniq_embs_and_timestamps = embs_and_timestamps[uniq_id]\n",
    "\n",
    "        if clustering_params.oracle_num_speakers:\n",
    "            num_speakers = audio_rttm_values.get('num_speakers', None)\n",
    "            if num_speakers is None:\n",
    "                raise ValueError(\"Provided option as oracle num of speakers but num_speakers in manifest is null\")\n",
    "        else:\n",
    "            num_speakers = -1\n",
    "\n",
    "        base_scale_idx = uniq_embs_and_timestamps['multiscale_segment_counts'].shape[0] - 1\n",
    "\n",
    "        cluster_labels = speaker_clustering.forward_infer(\n",
    "            embeddings_in_scales=uniq_embs_and_timestamps['embeddings'],\n",
    "            timestamps_in_scales=uniq_embs_and_timestamps['timestamps'],\n",
    "            multiscale_segment_counts=uniq_embs_and_timestamps['multiscale_segment_counts'],\n",
    "            multiscale_weights=uniq_embs_and_timestamps['multiscale_weights'],\n",
    "            oracle_num_speakers=int(num_speakers),\n",
    "            max_num_speakers=int(clustering_params.max_num_speakers),\n",
    "            max_rp_threshold=float(clustering_params.max_rp_threshold),\n",
    "            sparse_search_volume=int(clustering_params.sparse_search_volume),\n",
    "            chunk_cluster_count=clustering_params.get('chunk_cluster_count', None),\n",
    "            embeddings_per_chunk=clustering_params.get('embeddings_per_chunk', None),\n",
    "        )\n",
    "\n",
    "        del uniq_embs_and_timestamps\n",
    "        if cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            gc.collect()\n",
    "        timestamps = speaker_clustering.timestamps_in_scales[base_scale_idx]\n",
    "\n",
    "        cluster_labels = cluster_labels.cpu().numpy()\n",
    "        if len(cluster_labels) != timestamps.shape[0]:\n",
    "            raise ValueError(\"Mismatch of length between cluster_labels and timestamps.\")\n",
    "\n",
    "        labels, lines = generate_cluster_labels(timestamps, cluster_labels)\n",
    "\n",
    "        if out_rttm_dir:\n",
    "            labels_to_rttmfile(labels, uniq_id, out_rttm_dir)\n",
    "            lines_cluster_labels.extend([f'{uniq_id} {seg_line}\\n' for seg_line in lines])\n",
    "        hypothesis = labels_to_pyannote_object(labels, uniq_name=uniq_id)\n",
    "        all_hypothesis.append([uniq_id, hypothesis])\n",
    "\n",
    "        rttm_file = audio_rttm_values.get('rttm_filepath', None)\n",
    "        if rttm_file is not None and os.path.exists(rttm_file) and not no_references:\n",
    "            ref_labels = rttm_to_labels(rttm_file)\n",
    "            reference = labels_to_pyannote_object(ref_labels, uniq_name=uniq_id)\n",
    "            all_reference.append([uniq_id, reference])\n",
    "        else:\n",
    "            no_references = True\n",
    "            all_reference = []\n",
    "\n",
    "    if out_rttm_dir:\n",
    "        write_cluster_labels(base_scale_idx, lines_cluster_labels, out_rttm_dir)\n",
    "\n",
    "    return all_reference, all_hypothesis\n",
    "\n",
    "\n",
    "def get_vad_out_from_rttm_line(rttm_line):\n",
    "    \"\"\"\n",
    "    Extract VAD timestamp from the given RTTM lines.\n",
    "    \"\"\"\n",
    "    vad_out = rttm_line.strip().split()\n",
    "    if len(vad_out) > 3:\n",
    "        start, dur, _ = float(vad_out[3]), float(vad_out[4]), vad_out[7]\n",
    "    else:\n",
    "        start, dur, _ = float(vad_out[0]), float(vad_out[1]), vad_out[2]\n",
    "    return start, dur\n",
    "\n",
    "\n",
    "def get_offset_and_duration(AUDIO_RTTM_MAP, uniq_id, decimals=5):\n",
    "    \"\"\"\n",
    "    Extract offset and duration information from AUDIO_RTTM_MAP dictionary.\n",
    "    If duration information is not specified, a duration value is extracted from the audio file directly.\n",
    "\n",
    "    Args:\n",
    "        AUDIO_RTTM_MAP (dict):\n",
    "            Dictionary containing RTTM file information, which is indexed by unique file id.\n",
    "        uniq_id (str):\n",
    "            Unique file id\n",
    "    Returns:\n",
    "        offset (float):\n",
    "            The offset value that determines the beginning of the audio stream.\n",
    "        duration (float):\n",
    "            The length of audio stream that is expected to be used.\n",
    "    \"\"\"\n",
    "    audio_path = AUDIO_RTTM_MAP[uniq_id]['audio_filepath']\n",
    "    if AUDIO_RTTM_MAP[uniq_id].get('duration', None):\n",
    "        duration = round(AUDIO_RTTM_MAP[uniq_id]['duration'], decimals)\n",
    "        offset = round(AUDIO_RTTM_MAP[uniq_id]['offset'], decimals)\n",
    "    else:\n",
    "        sound = sf.SoundFile(audio_path)\n",
    "        duration = sound.frames / sound.samplerate\n",
    "        offset = 0.0\n",
    "    return offset, duration\n",
    "\n",
    "\n",
    "def write_overlap_segments(outfile, AUDIO_RTTM_MAP, uniq_id, overlap_range_list, decimals=5):\n",
    "    \"\"\"\n",
    "    Write the json dictionary into the specified manifest file.\n",
    "\n",
    "    Args:\n",
    "        outfile:\n",
    "            File pointer that indicates output file path.\n",
    "        AUDIO_RTTM_MAP (dict):\n",
    "            Dictionary containing the input manifest information\n",
    "        uniq_id (str):\n",
    "            Unique file id\n",
    "        overlap_range_list (list):\n",
    "            List containing overlapping ranges between target and source.\n",
    "        decimals (int):\n",
    "            Number of decimals to round the offset and duration values.\n",
    "    \"\"\"\n",
    "    audio_path = AUDIO_RTTM_MAP[uniq_id]['audio_filepath']\n",
    "    for (stt, end) in overlap_range_list:\n",
    "        meta = {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"offset\": round(stt, decimals),\n",
    "            \"duration\": round(end - stt, decimals),\n",
    "            \"label\": 'UNK',\n",
    "            \"uniq_id\": uniq_id,\n",
    "        }\n",
    "        json.dump(meta, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "\n",
    "def read_rttm_lines(rttm_file_path):\n",
    "    \"\"\"\n",
    "    Read rttm files and return the rttm information lines.\n",
    "\n",
    "    Args:\n",
    "        rttm_file_path (str):\n",
    "            An absolute path to an RTTM file\n",
    "\n",
    "    Returns:\n",
    "        lines (list):\n",
    "            List containing the strings from the RTTM file.\n",
    "    \"\"\"\n",
    "    if rttm_file_path and os.path.exists(rttm_file_path):\n",
    "        with open(rttm_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"Requested to construct manifest from rttm with oracle VAD option or from NeMo VAD but received filename as {}\".format(\n",
    "                rttm_file_path\n",
    "            )\n",
    "        )\n",
    "    return lines\n",
    "\n",
    "\n",
    "def validate_vad_manifest(AUDIO_RTTM_MAP, vad_manifest):\n",
    "    \"\"\"\n",
    "    This function will check the valid speech segments in the manifest file which is either\n",
    "    generated from NeMo voice activity detection(VAD) or oracle VAD.\n",
    "    If an audio file does not contain any valid speech segments, we ignore the audio file\n",
    "    (indexed by uniq_id) for the rest of the processing steps.\n",
    "    \"\"\"\n",
    "    vad_uniq_ids = set()\n",
    "    with open(vad_manifest, 'r') as vad_file:\n",
    "        for line in vad_file:\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "            if dic['duration'] > 0:\n",
    "                vad_uniq_ids.add(dic['uniq_id'])\n",
    "\n",
    "    provided_uniq_ids = set(AUDIO_RTTM_MAP.keys())\n",
    "    silence_ids = provided_uniq_ids - vad_uniq_ids\n",
    "    for uniq_id in silence_ids:\n",
    "        del AUDIO_RTTM_MAP[uniq_id]\n",
    "        logging.warning(f\"{uniq_id} is ignored since the file does not contain any speech signal to be processed.\")\n",
    "\n",
    "    if len(AUDIO_RTTM_MAP) == 0:\n",
    "        raise ValueError(\"All files present in manifest contains silence, aborting next steps\")\n",
    "\n",
    "\n",
    "def is_overlap(rangeA: List[float], rangeB: List[float]) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether two ranges have overlap.\n",
    "\n",
    "    Args:\n",
    "        rangeA (list, tuple):\n",
    "            List or tuple containing start and end value in float.\n",
    "        rangeB (list, tuple):\n",
    "            List or tuple containing start and end value in float.\n",
    "    Returns:\n",
    "        (bool):\n",
    "            Boolean that indicates whether the input ranges have overlap.\n",
    "    \"\"\"\n",
    "    start1, end1 = rangeA[0], rangeA[1]\n",
    "    start2, end2 = rangeB[0], rangeB[1]\n",
    "    return end1 > start2 and end2 > start1\n",
    "\n",
    "\n",
    "def get_overlap_range(rangeA: List[float], rangeB: List[float]):\n",
    "    \"\"\"\n",
    "    Calculate the overlapping range between rangeA and rangeB.\n",
    "\n",
    "    Args:\n",
    "        rangeA (list, tuple):\n",
    "            List or tuple containing start and end value in float.\n",
    "        rangeB (list, tuple):\n",
    "            List or tuple containing start and end value in float.\n",
    "\n",
    "    Returns:\n",
    "        (list):\n",
    "            List containing the overlapping range between rangeA and rangeB.\n",
    "    \"\"\"\n",
    "    assert is_overlap(rangeA, rangeB), f\"There is no overlap between rangeA:{rangeA} and rangeB:{rangeB}\"\n",
    "    return [max(rangeA[0], rangeB[0]), min(rangeA[1], rangeB[1])]\n",
    "\n",
    "\n",
    "def merge_int_intervals(intervals_in: List[List[int]]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Interval merging algorithm which has `O(N*logN)` time complexity. (N is number of intervals)\n",
    "    Merge the range pairs if there is overlap exists between the given ranges.\n",
    "    This algorithm needs a sorted range list in terms of the start time.\n",
    "    Note that neighboring numbers lead to a merged range.\n",
    "\n",
    "    Example:\n",
    "        input: [(1, 10), (11, 20)]\n",
    "        output: [(1, 20)]\n",
    "\n",
    "    Refer to the original code at https://stackoverflow.com/a/59378428\n",
    "\n",
    "    Args:\n",
    "        intervals_in (list):\n",
    "            List containing ranges.\n",
    "            Example:\n",
    "                >>> intervals_in\n",
    "                [(102, 103), (104, 109), (107, 120)]\n",
    "\n",
    "    Returns:\n",
    "        merged_list (list):\n",
    "            List containing the combined ranges.\n",
    "            Example:\n",
    "                >>> merged_list\n",
    "                [(102, 120)]\n",
    "    \"\"\"\n",
    "    num_intervals = len(intervals_in)\n",
    "    if num_intervals == 0:\n",
    "        return []\n",
    "    elif num_intervals == 1:\n",
    "        return intervals_in\n",
    "    else:\n",
    "        merged_list: List[List[int]] = []\n",
    "        stt2: int = 0\n",
    "        end2: int = 0\n",
    "\n",
    "        intervals_in = [[int(x[0]), int(x[1])] for x in intervals_in]\n",
    "        interval_tensor: torch.Tensor = torch.tensor(intervals_in)\n",
    "        _sorted, _ = torch.sort(interval_tensor, dim=0)\n",
    "        _sorted_int: List[List[int]] = [[int(x[0]), int(x[1])] for x in _sorted.cpu()]\n",
    "        intervals: List[List[int]] = _sorted_int\n",
    "\n",
    "        start, end = intervals[0][0], intervals[0][1]\n",
    "        for i in range(1, num_intervals):\n",
    "            stt2, end2 = intervals[i][0], intervals[i][1]\n",
    "            if end >= stt2:\n",
    "                end = max(end2, end)\n",
    "            else:\n",
    "                start, end = int(start), int(end)\n",
    "                merged_list.append([start, end])\n",
    "                start = stt2\n",
    "                end = max(end2, end)\n",
    "\n",
    "        start, end = int(start), int(end)\n",
    "        merged_list.append([start, end])\n",
    "        return merged_list\n",
    "\n",
    "\n",
    "def fl2int(x: float, decimals: int = 3) -> int:\n",
    "    \"\"\"\n",
    "    Convert floating point number to integer.\n",
    "    \"\"\"\n",
    "    return torch.round(torch.tensor([x * (10 ** decimals)]), decimals=0).int().item()\n",
    "\n",
    "\n",
    "def int2fl(x: int, decimals: int = 3) -> float:\n",
    "    \"\"\"\n",
    "    Convert integer to floating point number.\n",
    "    \"\"\"\n",
    "    return torch.round(torch.tensor([x / (10 ** decimals)]), decimals=decimals).item()\n",
    "\n",
    "\n",
    "def merge_float_intervals(ranges: List[List[float]], decimals: int = 5, margin: int = 2) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Combine overlaps with floating point numbers. Since neighboring integers are considered as continuous range,\n",
    "    we need to add margin to the starting range before merging then subtract margin from the result range.\n",
    "\n",
    "    Args:\n",
    "        ranges (list):\n",
    "            List containing ranges.\n",
    "            Example: [(10.2, 10.83), (10.42, 10.91), (10.45, 12.09)]\n",
    "        decimals (int):\n",
    "            Number of rounding decimals\n",
    "        margin (int):\n",
    "            margin for determining overlap of the two ranges when ranges are converted to integer ranges.\n",
    "            Default is margin=2 which follows the python index convention.\n",
    "\n",
    "        Examples:\n",
    "            If margin is 0:\n",
    "                [(1, 10), (10, 20)] -> [(1, 20)]\n",
    "                [(1, 10), (11, 20)] -> [(1, 20)]\n",
    "            If margin is 1:\n",
    "                [(1, 10), (10, 20)] -> [(1, 20)]\n",
    "                [(1, 10), (11, 20)] -> [(1, 10), (11, 20)]\n",
    "            If margin is 2:\n",
    "                [(1, 10), (10, 20)] -> [(1, 10), (10, 20)]\n",
    "                [(1, 10), (11, 20)] -> [(1, 10), (11, 20)]\n",
    "\n",
    "    Returns:\n",
    "        merged_list (list):\n",
    "            List containing the combined ranges.\n",
    "            Example: [(10.2, 12.09)]\n",
    "    \"\"\"\n",
    "    ranges_int: List[List[int]] = []\n",
    "    merged_ranges_int: List[List[int]] = []\n",
    "    for x in ranges:\n",
    "        stt, end = int(fl2int(x[0], decimals) + margin), int(fl2int(x[1], decimals))\n",
    "        if stt < end:\n",
    "            ranges_int.append([stt, end])\n",
    "    merged_ranges_int = merge_int_intervals(ranges_int)\n",
    "    merged_ranges_float: List[List[float]] = []\n",
    "    merged_ranges_float = [[int2fl(x[0] - margin, decimals), int2fl(x[1], decimals)] for x in merged_ranges_int]\n",
    "    return merged_ranges_float\n",
    "\n",
    "\n",
    "def get_sub_range_list(target_range: List[float], source_range_list: List[List[float]]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Get the ranges that has overlaps with the target range from the source_range_list.\n",
    "\n",
    "    Example:\n",
    "        source range:\n",
    "            |===--======---=====---====--|\n",
    "        target range:\n",
    "            |--------================----|\n",
    "        out_range:\n",
    "            |--------===---=====---==----|\n",
    "\n",
    "    Args:\n",
    "        target_range (list):\n",
    "            A range (a start and end value pair) that defines the target range we want to select.\n",
    "            target_range = [(start, end)]\n",
    "        source_range_list (list):\n",
    "            List containing the subranges that need to be selected.\n",
    "            source_range = [(start0, end0), (start1, end1), ...]\n",
    "    Returns:\n",
    "        out_range (list):\n",
    "            List containing the overlap between target_range and\n",
    "            source_range_list.\n",
    "    \"\"\"\n",
    "    if len(target_range) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        out_range: List[List[float]] = []\n",
    "        for s_range in source_range_list:\n",
    "            if is_overlap(s_range, target_range):\n",
    "                ovl_range = get_overlap_range(s_range, target_range)\n",
    "                out_range.append(ovl_range)\n",
    "        return out_range\n",
    "\n",
    "\n",
    "def write_rttm2manifest(\n",
    "    AUDIO_RTTM_MAP: str, manifest_file: str, include_uniq_id: bool = False, decimals: int = 5\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Write manifest file based on rttm files (or vad table out files). This manifest file would be used by\n",
    "    speaker diarizer to compute embeddings and cluster them. This function takes care of overlapping VAD timestamps\n",
    "    and trimmed with the given offset and duration value.\n",
    "\n",
    "    Args:\n",
    "        AUDIO_RTTM_MAP (dict):\n",
    "            Dictionary containing keys to unique names, that contains audio filepath and rttm_filepath as its contents,\n",
    "            these are used to extract oracle vad timestamps.\n",
    "        manifest (str):\n",
    "            The path to the output manifest file.\n",
    "\n",
    "    Returns:\n",
    "        manifest (str):\n",
    "            The path to the output manifest file.\n",
    "    \"\"\"\n",
    "    with open(manifest_file, 'w') as outfile:\n",
    "        for uniq_id in AUDIO_RTTM_MAP:\n",
    "            rttm_file_path = AUDIO_RTTM_MAP[uniq_id]['rttm_filepath']\n",
    "            rttm_lines = read_rttm_lines(rttm_file_path)\n",
    "            offset, duration = get_offset_and_duration(AUDIO_RTTM_MAP, uniq_id, decimals)\n",
    "            vad_start_end_list_raw = []\n",
    "            for line in rttm_lines:\n",
    "                start, dur = get_vad_out_from_rttm_line(line)\n",
    "                vad_start_end_list_raw.append([start, start + dur])\n",
    "            vad_start_end_list = merge_float_intervals(vad_start_end_list_raw, decimals)\n",
    "            if len(vad_start_end_list) == 0:\n",
    "                logging.warning(f\"File ID: {uniq_id}: The VAD label is not containing any speech segments.\")\n",
    "            elif duration <= 0:\n",
    "                logging.warning(f\"File ID: {uniq_id}: The audio file has negative or zero duration.\")\n",
    "            else:\n",
    "                overlap_range_list = get_sub_range_list(\n",
    "                    source_range_list=vad_start_end_list, target_range=[offset, offset + duration]\n",
    "                )\n",
    "                write_overlap_segments(outfile, AUDIO_RTTM_MAP, uniq_id, overlap_range_list, decimals)\n",
    "    return manifest_file\n",
    "\n",
    "\n",
    "def segments_manifest_to_subsegments_manifest(\n",
    "    segments_manifest_file: str,\n",
    "    subsegments_manifest_file: str = None,\n",
    "    window: float = 1.5,\n",
    "    shift: float = 0.75,\n",
    "    min_subsegment_duration: float = 0.05,\n",
    "    include_uniq_id: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate subsegments manifest from segments manifest file\n",
    "    Args:\n",
    "        segments_manifest file (str): path to segments manifest file, typically from VAD output\n",
    "        subsegments_manifest_file (str): path to output subsegments manifest file (default (None) : writes to current working directory)\n",
    "        window (float): window length for segments to subsegments length\n",
    "        shift (float): hop length for subsegments shift\n",
    "        min_subsegments_duration (float): exclude subsegments smaller than this duration value\n",
    "\n",
    "    Returns:\n",
    "        returns path to subsegment manifest file\n",
    "    \"\"\"\n",
    "    if subsegments_manifest_file is None:\n",
    "        pwd = os.getcwd()\n",
    "        subsegments_manifest_file = os.path.join(pwd, 'subsegments.json')\n",
    "\n",
    "    with open(segments_manifest_file, 'r') as segments_manifest, open(\n",
    "        subsegments_manifest_file, 'w'\n",
    "    ) as subsegments_manifest:\n",
    "        segments = segments_manifest.readlines()\n",
    "        for segment in segments:\n",
    "            segment = segment.strip()\n",
    "            dic = json.loads(segment)\n",
    "            audio, offset, duration, label = dic['audio_filepath'], dic['offset'], dic['duration'], dic['label']\n",
    "            subsegments = get_subsegments(offset=offset, window=window, shift=shift, duration=duration)\n",
    "            if include_uniq_id and 'uniq_id' in dic:\n",
    "                uniq_id = dic['uniq_id']\n",
    "            else:\n",
    "                uniq_id = None\n",
    "            for subsegment in subsegments:\n",
    "                start, dur = subsegment\n",
    "                if dur > min_subsegment_duration:\n",
    "                    meta = {\n",
    "                        \"audio_filepath\": audio,\n",
    "                        \"offset\": start,\n",
    "                        \"duration\": dur,\n",
    "                        \"label\": label,\n",
    "                        \"uniq_id\": uniq_id,\n",
    "                    }\n",
    "\n",
    "                    json.dump(meta, subsegments_manifest)\n",
    "                    subsegments_manifest.write(\"\\n\")\n",
    "\n",
    "    return subsegments_manifest_file\n",
    "\n",
    "\n",
    "def get_subsegments(offset: float, window: float, shift: float, duration: float) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Return subsegments from a segment of audio file\n",
    "    Args:\n",
    "        offset (float): start time of audio segment\n",
    "        window (float): window length for segments to subsegments length\n",
    "        shift (float): hop length for subsegments shift\n",
    "        duration (float): duration of segment\n",
    "    Returns:\n",
    "        subsegments (List[tuple[float, float]]): subsegments generated for the segments as list of tuple of start and duration of each subsegment\n",
    "    \"\"\"\n",
    "    subsegments: List[List[float]] = []\n",
    "    start = offset\n",
    "    slice_end = start + duration\n",
    "    base = math.ceil((duration - window) / shift)\n",
    "    slices = 1 if base < 0 else base + 1\n",
    "    for slice_id in range(slices):\n",
    "        end = start + window\n",
    "        if end > slice_end:\n",
    "            end = slice_end\n",
    "        subsegments.append([start, end - start])\n",
    "        start = offset + (slice_id + 1) * shift\n",
    "    return subsegments\n",
    "\n",
    "\n",
    "def get_target_sig(sig, start_sec: float, end_sec: float, slice_length: int, sample_rate: int,) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract time-series signal from the given audio buffer based on the start and end\n",
    "    timestamps.\n",
    "\n",
    "    Args:\n",
    "        start_sec (float):\n",
    "            Start of the targeted segments in second\n",
    "        end_sec (float):\n",
    "            Start of the targeted segments in second\n",
    "        slice_length (int):\n",
    "            Length of the entire audio segment that the samples are extracted from\n",
    "        sample_rate (int):\n",
    "            Sampling rate of the time-series audio signal\n",
    "\n",
    "    Returns:\n",
    "        (Tensor) Trimmed ime-series audio signal samples\n",
    "    \"\"\"\n",
    "    start_idx = int(start_sec * sample_rate)\n",
    "    end_idx = min(int(end_sec * sample_rate), int(slice_length + start_idx))\n",
    "    return sig[start_idx:end_idx]\n",
    "\n",
    "\n",
    "def check_ranges(range_tensor):\n",
    "    \"\"\"\n",
    "    Check whether the range list has any faulty timestamp order.\n",
    "\n",
    "    Args:\n",
    "        range_tensor (list):\n",
    "            List containing the start and end time of the segments.\n",
    "            Example:\n",
    "                >>> range_tensor = [[0.5, 3.12], [3.51, 7.26], ... ]\n",
    "    \"\"\"\n",
    "    for k in range(range_tensor.shape[0]):\n",
    "        range_tup = range_tensor[k]\n",
    "        if range_tup[1] < range_tup[0]:\n",
    "            raise ValueError(\"Range start time should be preceding the end time but we got: {range_tup}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def tensor_to_list(range_tensor: torch.Tensor) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    For online segmentation. Force the list elements to be float type.\n",
    "    \"\"\"\n",
    "    return [[float(range_tensor[k][0]), float(range_tensor[k][1])] for k in range(range_tensor.shape[0])]\n",
    "\n",
    "\n",
    "def get_speech_labels_for_update(\n",
    "    frame_start: float,\n",
    "    buffer_end: float,\n",
    "    vad_timestamps: torch.Tensor,\n",
    "    cumulative_speech_labels: torch.Tensor,\n",
    "    cursor_for_old_segments: float,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Bring the new speech labels from the current buffer. Followingly:\n",
    "\n",
    "    1. Concatenate the old speech labels from self.cumulative_speech_labels for the overlapped region.\n",
    "        - This goes to new_speech_labels.\n",
    "    2. Update the new 1 sec of speech label (speech_label_for_new_segments) to self.cumulative_speech_labels.\n",
    "    3. Return the speech label from cursor_for_old_segments to buffer end.\n",
    "\n",
    "    Args:\n",
    "        frame_start (float):\n",
    "            Start of the middle audio chunk in the audio buffer\n",
    "        buffer_end (float):\n",
    "            End of the audio buffer\n",
    "        vad_timestamps (Tensor):\n",
    "            Tensor containing VAD intervals (start and end timestamps)\n",
    "        cumulative_speech_labels (torch.Tensor):\n",
    "            Cumulative speech/non-speech timestamps (equivalent to VAD timestamps)\n",
    "        cursor_for_old_segments (float):\n",
    "            Floating point number that indicates the point where new segments should replace\n",
    "            the old segments\n",
    "\n",
    "    Returns:\n",
    "        speech_label_for_new_segments (Tensor):\n",
    "            The intervals (start and end) timestamps where the new incoming speech segments should\n",
    "            be collected from\n",
    "        cumulative_speech_labels (Tensor):\n",
    "            Cumulative speech/non-speech timestamps (equivalent to VAD timestamps) with newly added\n",
    "            speech/non-speech timestamps from the `vad_timestamps` input\n",
    "    \"\"\"\n",
    "    update_overlap_range: List[float] = []\n",
    "    if cursor_for_old_segments < frame_start:\n",
    "        update_overlap_range = [float(cursor_for_old_segments), float(frame_start)]\n",
    "\n",
    "    # Get VAD timestamps that are in (frame_start, buffer_end) range\n",
    "    vad_timestamps = tensor_to_list(vad_timestamps)\n",
    "    cumulative_speech_labels = tensor_to_list(cumulative_speech_labels)\n",
    "    new_incoming_speech_labels = get_sub_range_list(\n",
    "        target_range=[float(frame_start), float(buffer_end)], source_range_list=vad_timestamps\n",
    "    )\n",
    "\n",
    "    # Update the speech label by including overlapping region with the previous output\n",
    "    update_overlap_speech_labels = get_sub_range_list(\n",
    "        target_range=update_overlap_range, source_range_list=cumulative_speech_labels\n",
    "    )\n",
    "\n",
    "    # Speech segments for embedding extractions\n",
    "    speech_label_for_new_segments = merge_float_intervals(\n",
    "        update_overlap_speech_labels + new_incoming_speech_labels, margin=0\n",
    "    )\n",
    "\n",
    "    # Keep cumulative VAD labels for the future use\n",
    "    cumulative_speech_labels = merge_float_intervals(cumulative_speech_labels + new_incoming_speech_labels, margin=0)\n",
    "\n",
    "    # Convert the lists back to type torch.Tensor\n",
    "    speech_label_for_new_segments = torch.tensor(speech_label_for_new_segments)\n",
    "    cumulative_speech_labels = torch.tensor(cumulative_speech_labels)\n",
    "\n",
    "    return speech_label_for_new_segments, cumulative_speech_labels\n",
    "\n",
    "\n",
    "def get_new_cursor_for_update(frame_start: float, segment_range_ts: List[List[float]],) -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    Function for updating a cursor online speaker diarization. \n",
    "    Remove the old segments that overlap with the new frame (self.frame_start)\n",
    "    cursor_for_old_segments is set to the onset of the t_range popped lastly.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        frame_start (float):\n",
    "            Start of streaming pipeline frame\n",
    "        segment_range_ts (float):\n",
    "            Interval (start and end timestamps) of the targeted segments\n",
    "\n",
    "    Returns:\n",
    "        cursor_for_old_segments (float):\n",
    "            Floating point number that indicates the point where new segments should replace\n",
    "            the old segments\n",
    "        cursor_index (int):\n",
    "            The index of the first newly accepted segments\n",
    "    \"\"\"\n",
    "    cursor_for_old_segments = frame_start\n",
    "    cursor_index: int = len(segment_range_ts)\n",
    "    count = 0\n",
    "    while True and len(segment_range_ts) > 0:\n",
    "        t_range = segment_range_ts[-1 * (count + 1)]\n",
    "        if frame_start <= t_range[1]:\n",
    "            count += 1\n",
    "            cursor_for_old_segments = t_range[0]\n",
    "        else:\n",
    "            break\n",
    "    cursor_index = len(segment_range_ts) - count\n",
    "    return cursor_for_old_segments, cursor_index\n",
    "\n",
    "\n",
    "def get_online_segments_from_slices(\n",
    "    sig: torch.Tensor,\n",
    "    buffer_start: float,\n",
    "    buffer_end: float,\n",
    "    subsegments: List[List[float]],\n",
    "    ind_offset: int,\n",
    "    window: float,\n",
    "    sample_rate: int,\n",
    ") -> Tuple[int, List[torch.Tensor], List[List[float]], List[int]]:\n",
    "    \"\"\"\n",
    "    Create short speech segments from slices for online processing purpose.\n",
    "\n",
    "    Args:\n",
    "        sig (Tensor):\n",
    "            Tensor containing the raw time-series signal\n",
    "        buffer_start (float):\n",
    "            Start point of the time-series signal buffer\n",
    "        buffer_end (float):\n",
    "            End point of the time-series signal buffer\n",
    "        subsegments (list):\n",
    "            List containing the interval information (start and duration) of each segment\n",
    "        ind_offset (int):\n",
    "            Offset for index that compensates the point of the current position in the streaming session\n",
    "        window (float):\n",
    "            Window length in second\n",
    "        shift (float):\n",
    "            Shift length in second\n",
    "\n",
    "    Returns:\n",
    "        sigs_list  (list):\n",
    "            list of sliced input signal\n",
    "        audio_lengths (list):\n",
    "            list of audio sample lengths\n",
    "    \"\"\"\n",
    "    sig_rangel_list: List[List[float]] = []\n",
    "    sig_indexes: List[int] = []\n",
    "    sigs_list: List[torch.Tensor] = []\n",
    "    slice_length: int = int(window * sample_rate)\n",
    "    end_sec: float = 0.0\n",
    "    for subseg in subsegments:\n",
    "        start_sec, dur = subseg[0], subseg[1]\n",
    "\n",
    "        if start_sec > buffer_end:\n",
    "            continue\n",
    "        ind_offset += 1\n",
    "\n",
    "        buffer_len = buffer_end - buffer_start\n",
    "        end_sec = float(start_sec + dur)\n",
    "\n",
    "        if end_sec > buffer_len:\n",
    "            end_sec = float(min(end_sec, buffer_len))\n",
    "\n",
    "        signal = get_target_sig(sig, start_sec, end_sec, slice_length, sample_rate)\n",
    "\n",
    "        if len(signal) == 0:\n",
    "            raise ValueError(\"len(signal) is zero. Signal length should not be zero.\")\n",
    "        if len(signal) < slice_length:\n",
    "            signal = repeat_signal(signal, len(signal), slice_length)\n",
    "\n",
    "        start_abs_sec = buffer_start + start_sec\n",
    "        end_abs_sec = buffer_start + end_sec\n",
    "\n",
    "        sigs_list.append(signal)\n",
    "        sig_rangel_list.append([start_abs_sec, end_abs_sec])\n",
    "        sig_indexes.append(ind_offset)\n",
    "\n",
    "    if not len(sigs_list) == len(sig_rangel_list) == len(sig_indexes):\n",
    "        raise ValueError(\"Signal information lists have a mismatch.\")\n",
    "\n",
    "    return ind_offset, sigs_list, sig_rangel_list, sig_indexes\n",
    "\n",
    "\n",
    "def get_online_subsegments_from_buffer(\n",
    "    buffer_start: float,\n",
    "    buffer_end: float,\n",
    "    sample_rate: int,\n",
    "    speech_labels_for_update: torch.Tensor,\n",
    "    audio_buffer: torch.Tensor,\n",
    "    segment_indexes: List[int],\n",
    "    window: float,\n",
    "    shift: float,\n",
    ") -> Tuple[List[torch.Tensor], List[List[float]], List[int]]:\n",
    "    \"\"\"\n",
    "    Generate subsegments for online processing from the given segment information.\n",
    "    This function extracts subsegments (embedding vector level) time-series from the\n",
    "    raw time-series buffer based on the segment interval (start and end timestamps) information.\n",
    "\n",
    "    Args:\n",
    "        buffer_start (float):\n",
    "            Start point of the time-series signal buffer\n",
    "        buffer_end (float):\n",
    "            End point of the time-series signal buffer\n",
    "        sample_rate (int):\n",
    "            Sampling rate of the audio input\n",
    "        speech_labels_for_update (Tensor):\n",
    "            Tensor containing intervals (start and end timestamps) of the speech segments\n",
    "        audio_buffer (Tensor):\n",
    "            Tensor containing the raw time-series signal\n",
    "        segment_indexes (list):\n",
    "            List containing the unique indices of segments\n",
    "        window (float):\n",
    "            Window length in second\n",
    "        shift (float):\n",
    "            Shift length in second\n",
    "\n",
    "    Returns:\n",
    "        sigs_list (list):\n",
    "            List containing the tensors of the old and the newly added time-series signals\n",
    "        sig_rangel_list (list):\n",
    "            List containing the old and the newly added intervals (timestamps) of the speech segments\n",
    "        sig_indexes (list):\n",
    "            List containing the old and the newly added unique indices of segments\n",
    "    \"\"\"\n",
    "    sigs_list: List[torch.Tensor] = []\n",
    "    sig_rangel_list: List[List[float]] = []\n",
    "    sig_indexes: List[int] = []\n",
    "    if len(segment_indexes) > 0:\n",
    "        ind_offset = segment_indexes[-1]\n",
    "    else:\n",
    "        ind_offset = -1\n",
    "\n",
    "    for idx, range_spl in enumerate(speech_labels_for_update):\n",
    "        range_offs = [float(range_spl[0].item() - buffer_start), float(range_spl[1].item() - buffer_start)]\n",
    "        range_t = [max(0, range_offs[0]), range_offs[1]]\n",
    "\n",
    "        subsegments = get_subsegments(\n",
    "            offset=range_t[0], window=window, shift=shift, duration=(range_t[1] - range_t[0]),\n",
    "        )\n",
    "        ind_offset, sigs, ranges, inds = get_online_segments_from_slices(\n",
    "            sig=audio_buffer,\n",
    "            buffer_start=buffer_start,\n",
    "            buffer_end=buffer_end,\n",
    "            subsegments=subsegments,\n",
    "            window=window,\n",
    "            ind_offset=ind_offset,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "        sigs_list.extend(sigs)\n",
    "        sig_rangel_list.extend(ranges)\n",
    "        sig_indexes.extend(inds)\n",
    "\n",
    "    assert len(sigs_list) == len(sig_rangel_list) == len(sig_indexes)\n",
    "    return sigs_list, sig_rangel_list, sig_indexes\n",
    "\n",
    "\n",
    "def get_scale_mapping_argmat(uniq_embs_and_timestamps: Dict[str, dict]) -> Dict[int, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity values among speaker embeddings for each scale then\n",
    "    apply multiscale weights to calculate the fused similarity matrix.\n",
    "\n",
    "    Args:\n",
    "        uniq_embs_and_timestamps: (dict)\n",
    "            The dictionary containing embeddings, timestamps and multiscale weights.\n",
    "            If uniq_embs_and_timestamps contains only one scale, single scale diarization\n",
    "            is performed.\n",
    "\n",
    "    Returns:\n",
    "        scale_mapping_argmat (dict)\n",
    "            Dictionary containing scale mapping information matrix for each scale.\n",
    "    \"\"\"\n",
    "    scale_mapping_argmat = {}\n",
    "    embeddings_in_scales, timestamps_in_scales = split_input_data(\n",
    "        embeddings_in_scales=uniq_embs_and_timestamps['embeddings'],\n",
    "        timestamps_in_scales=uniq_embs_and_timestamps['timestamps'],\n",
    "        multiscale_segment_counts=uniq_embs_and_timestamps['multiscale_segment_counts'],\n",
    "    )\n",
    "    session_scale_mapping_list = get_argmin_mat(timestamps_in_scales)\n",
    "    for scale_idx in range(len(session_scale_mapping_list)):\n",
    "        mapping_argmat = session_scale_mapping_list[scale_idx]\n",
    "        scale_mapping_argmat[scale_idx] = mapping_argmat\n",
    "    return scale_mapping_argmat\n",
    "\n",
    "\n",
    "def get_overlap_stamps(cont_stamps: List[str], ovl_spk_idx: List[str]):\n",
    "    \"\"\"\n",
    "    Generate timestamps that include overlap speech. Overlap-including timestamps are created based on the segments that are\n",
    "    created for clustering diarizer. Overlap speech is assigned to the existing speech segments in `cont_stamps`.\n",
    "\n",
    "    Args:\n",
    "        cont_stamps (list):\n",
    "            Non-overlapping (single speaker per segment) diarization output in string format.\n",
    "            Each line contains the start and end time of segments and corresponding speaker labels.\n",
    "        ovl_spk_idx (list):\n",
    "            List containing segment index of the estimated overlapped speech. The start and end of segments are based on the\n",
    "            single-speaker (i.e., non-overlap-aware) RTTM generation.\n",
    "    Returns:\n",
    "        total_ovl_cont_list (list):\n",
    "            Rendered diarization output in string format. Each line contains the start and end time of segments and\n",
    "            corresponding speaker labels. This format is identical to `cont_stamps`.\n",
    "    \"\"\"\n",
    "    ovl_spk_cont_list = [[] for _ in range(len(ovl_spk_idx))]\n",
    "    for spk_idx in range(len(ovl_spk_idx)):\n",
    "        for idx, cont_a_line in enumerate(cont_stamps):\n",
    "            start, end, speaker = cont_a_line.split()\n",
    "            if idx in ovl_spk_idx[spk_idx]:\n",
    "                ovl_spk_cont_list[spk_idx].append(f\"{start} {end} speaker_{spk_idx}\")\n",
    "    total_ovl_cont_list = []\n",
    "    for ovl_cont_list in ovl_spk_cont_list:\n",
    "        if len(ovl_cont_list) > 0:\n",
    "            total_ovl_cont_list.extend(merge_stamps(ovl_cont_list))\n",
    "    return total_ovl_cont_list\n",
    "\n",
    "\n",
    "def get_adaptive_threshold(estimated_num_of_spks: int, min_threshold: float, overlap_infer_spk_limit: int):\n",
    "    \"\"\"\n",
    "    This function controls the magnitude of the sigmoid threshold based on the estimated number of speakers. As the number of\n",
    "    speakers becomes larger, diarization error rate is very sensitive on overlap speech detection. This function linearly increases\n",
    "    the threshold in proportion to the estimated number of speakers so more confident overlap speech results are reflected when\n",
    "    the number of estimated speakers are relatively high.\n",
    "\n",
    "    Args:\n",
    "        estimated_num_of_spks (int):\n",
    "            Estimated number of speakers from the clustering result.\n",
    "        min_threshold (float):\n",
    "            Sigmoid threshold value from the config file. This threshold value is minimum threshold value when `estimated_num_of_spks=2`\n",
    "        overlap_infer_spk_limit (int):\n",
    "            If the `estimated_num_of_spks` is less then `overlap_infer_spk_limit`, overlap speech estimation is skipped.\n",
    "\n",
    "    Returns:\n",
    "        adaptive_threshold (float):\n",
    "            Threshold value that is scaled based on the `estimated_num_of_spks`.\n",
    "    \"\"\"\n",
    "    adaptive_threshold = min_threshold - (estimated_num_of_spks - 2) * (min_threshold - 1) / (\n",
    "        overlap_infer_spk_limit - 2\n",
    "    )\n",
    "    return adaptive_threshold\n",
    "\n",
    "\n",
    "def generate_speaker_timestamps(\n",
    "    clus_labels: List[Union[float, int]], msdd_preds: List[torch.Tensor], **params\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    '''\n",
    "    Generate speaker timestamps from the segmentation information. If `use_clus_as_main=True`, use clustering result for main speaker\n",
    "    labels and use timestamps from the predicted sigmoid values. In this function, the main speaker labels in `maj_labels` exist for\n",
    "    every subsegment steps while overlap speaker labels in `ovl_labels` only exist for segments where overlap-speech is occuring.\n",
    "\n",
    "    Args:\n",
    "        clus_labels (list):\n",
    "            List containing integer-valued speaker clustering results.\n",
    "        msdd_preds (list):\n",
    "            List containing tensors of the predicted sigmoid values.\n",
    "            Each tensor has shape of: (Session length, estimated number of speakers).\n",
    "        params:\n",
    "            Parameters for generating RTTM output and evaluation. Parameters include:\n",
    "                infer_overlap (bool): If False, overlap-speech will not be detected.\n",
    "                use_clus_as_main (bool): Add overlap-speech detection from MSDD to clustering results. If False, only MSDD output\n",
    "                                         is used for constructing output RTTM files.\n",
    "                overlap_infer_spk_limit (int): Above this limit, overlap-speech detection is bypassed.\n",
    "                use_adaptive_thres (bool): Boolean that determines whehther to use adaptive_threshold depending on the estimated\n",
    "                                           number of speakers.\n",
    "                max_overlap_spks (int): Maximum number of overlap speakers detected. Default is 2.\n",
    "                threshold (float): Sigmoid threshold for MSDD output.\n",
    "\n",
    "    Returns:\n",
    "        maj_labels (list):\n",
    "            List containing string-formated single-speaker speech segment timestamps and corresponding speaker labels.\n",
    "            Example: [..., '551.685 552.77 speaker_1', '552.99 554.43 speaker_0', '554.97 558.19 speaker_0', ...]\n",
    "        ovl_labels (list):\n",
    "            List containing string-formated additional overlapping speech segment timestamps and corresponding speaker labels.\n",
    "            Note that `ovl_labels` includes only overlapping speech that is not included in `maj_labels`.\n",
    "            Example: [..., '152.495 152.745 speaker_1', '372.71 373.085 speaker_0', '554.97 555.885 speaker_1', ...]\n",
    "    '''\n",
    "    msdd_preds.squeeze(0)\n",
    "    estimated_num_of_spks = msdd_preds.shape[-1]\n",
    "    overlap_speaker_list = [[] for _ in range(estimated_num_of_spks)]\n",
    "    infer_overlap = estimated_num_of_spks < int(params['overlap_infer_spk_limit'])\n",
    "    main_speaker_lines = []\n",
    "    if params['use_adaptive_thres']:\n",
    "        threshold = get_adaptive_threshold(\n",
    "            estimated_num_of_spks, params['threshold'], params['overlap_infer_spk_limit']\n",
    "        )\n",
    "    else:\n",
    "        threshold = params['threshold']\n",
    "    for seg_idx, cluster_label in enumerate(clus_labels):\n",
    "        msdd_preds.squeeze(0)\n",
    "        spk_for_seg = (msdd_preds[0, seg_idx] > threshold).int().cpu().numpy().tolist()\n",
    "        sm_for_seg = msdd_preds[0, seg_idx].cpu().numpy()\n",
    "\n",
    "        if params['use_clus_as_main']:\n",
    "            main_spk_idx = int(cluster_label[2])\n",
    "        else:\n",
    "            main_spk_idx = np.argsort(msdd_preds[0, seg_idx].cpu().numpy())[::-1][0]\n",
    "\n",
    "        if sum(spk_for_seg) > 1 and infer_overlap:\n",
    "            idx_arr = np.argsort(sm_for_seg)[::-1]\n",
    "            for ovl_spk_idx in idx_arr[: params['max_overlap_spks']].tolist():\n",
    "                if ovl_spk_idx != int(main_spk_idx):\n",
    "                    overlap_speaker_list[ovl_spk_idx].append(seg_idx)\n",
    "        main_speaker_lines.append(f\"{cluster_label[0]} {cluster_label[1]} speaker_{main_spk_idx}\")\n",
    "    cont_stamps = get_contiguous_stamps(main_speaker_lines)\n",
    "    maj_labels = merge_stamps(cont_stamps)\n",
    "    ovl_labels = get_overlap_stamps(cont_stamps, overlap_speaker_list)\n",
    "    return maj_labels, ovl_labels\n",
    "\n",
    "\n",
    "def get_uniq_id_list_from_manifest(manifest_file: str):\n",
    "    \"\"\"Retrieve `uniq_id` values from the given manifest_file and save the IDs to a list.\n",
    "    \"\"\"\n",
    "    uniq_id_list = []\n",
    "    with open(manifest_file, 'r', encoding='utf-8') as manifest:\n",
    "        for i, line in enumerate(manifest.readlines()):\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "            uniq_id = get_uniqname_from_filepath(dic['audio_filepath'])\n",
    "            uniq_id_list.append(uniq_id)\n",
    "    return uniq_id_list\n",
    "\n",
    "\n",
    "def get_id_tup_dict(uniq_id_list: List[str], test_data_collection, preds_list: List[torch.Tensor]):\n",
    "    \"\"\"\n",
    "    Create session-level dictionary containing data needed to construct RTTM diarization output.\n",
    "\n",
    "    Args:\n",
    "        uniq_id_list (list):\n",
    "            List containing the `uniq_id` values.\n",
    "        test_data_collection (collections.DiarizationLabelEntity):\n",
    "            Class instance that is containing session information such as targeted speaker indices, audio filepath and RTTM filepath.\n",
    "        preds_list (list):\n",
    "            List containing tensors of predicted sigmoid values.\n",
    "\n",
    "    Returns:\n",
    "        session_dict (dict):\n",
    "            Dictionary containing session-level target speakers data and predicted simoid values in tensor format.\n",
    "    \"\"\"\n",
    "    session_dict = {x: [] for x in uniq_id_list}\n",
    "    for idx, line in enumerate(test_data_collection):\n",
    "        uniq_id = get_uniqname_from_filepath(line.audio_file)\n",
    "        session_dict[uniq_id].append([line.target_spks, preds_list[idx]])\n",
    "    return session_dict\n",
    "\n",
    "\n",
    "def prepare_split_data(manifest_filepath, _out_dir, multiscale_args_dict, global_rank):\n",
    "    \"\"\"\n",
    "    This function is needed for preparing diarization training data for multiscale diarization decoder (MSDD).\n",
    "    Prepare multiscale timestamp data for training. Oracle VAD timestamps from RTTM files are used as VAD timestamps.\n",
    "    In this function, timestamps for embedding extraction are extracted without extracting the embedding vectors.\n",
    "\n",
    "    Args:\n",
    "        manifest_filepath (str):\n",
    "            Input manifest file for creating audio-to-RTTM mapping.\n",
    "        _out_dir (str):\n",
    "            Output directory where timestamp json files are saved.\n",
    "\n",
    "    Returns:\n",
    "        multiscale_args_dict (dict):\n",
    "            - Dictionary containing two types of arguments: multi-scale weights and subsegment timestamps for each data sample.\n",
    "            - Each data sample has two keys: `multiscale_weights` and `scale_dict`.\n",
    "                - `multiscale_weights` key contains a list containing multiscale weights.\n",
    "                - `scale_dict` is indexed by integer keys which are scale index.\n",
    "            - Each data sample is indexed by using the following naming convention: `<uniq_id>_<start time in ms>_<end time in ms>`\n",
    "                Example: `fe_03_00106_mixed_626310_642300`\n",
    "    \"\"\"\n",
    "    speaker_dir = os.path.join(_out_dir, 'speaker_outputs')\n",
    "\n",
    "    # Only if this is for the first run of modelPT instance, remove temp folders.\n",
    "    if global_rank == 0:\n",
    "        if os.path.exists(speaker_dir):\n",
    "            shutil.rmtree(speaker_dir)\n",
    "        os.makedirs(speaker_dir)\n",
    "    split_audio_rttm_map = audio_rttm_map(manifest_filepath, attach_dur=True)\n",
    "\n",
    "    # Speech Activity Detection part\n",
    "    _speaker_manifest_path = os.path.join(speaker_dir, f'oracle_vad_manifest.json')\n",
    "    logging.info(f\"Extracting oracle VAD timestamps and saving at {speaker_dir}\")\n",
    "    if not os.path.exists(_speaker_manifest_path):\n",
    "        write_rttm2manifest(split_audio_rttm_map, _speaker_manifest_path, include_uniq_id=True)\n",
    "\n",
    "    multiscale_timestamps_by_scale = {}\n",
    "\n",
    "    # Segmentation\n",
    "    for scale_idx, (window, shift) in multiscale_args_dict['scale_dict'].items():\n",
    "        subsegments_manifest_path = os.path.join(speaker_dir, f'subsegments_scale{scale_idx}.json')\n",
    "        if not os.path.exists(subsegments_manifest_path):\n",
    "            # Sub-segmentation for the current scale (scale_idx)\n",
    "            segments_manifest_to_subsegments_manifest(\n",
    "                segments_manifest_file=_speaker_manifest_path,\n",
    "                subsegments_manifest_file=subsegments_manifest_path,\n",
    "                window=window,\n",
    "                shift=shift,\n",
    "                include_uniq_id=True,\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"Subsegmentation for timestamp extracted for: scale-{scale_idx} at {subsegments_manifest_path}\"\n",
    "            )\n",
    "        multiscale_timestamps = extract_timestamps(subsegments_manifest_path)\n",
    "        multiscale_timestamps_by_scale[scale_idx] = multiscale_timestamps\n",
    "\n",
    "    multiscale_timestamps_dict = get_timestamps(multiscale_timestamps_by_scale, multiscale_args_dict)\n",
    "    return multiscale_timestamps_dict\n",
    "\n",
    "\n",
    "def extract_timestamps(manifest_file: str):\n",
    "    \"\"\"\n",
    "    This method extracts timestamps from segments passed through manifest_file.\n",
    "\n",
    "    Args:\n",
    "        manifest_file (str):\n",
    "            Manifest file containing segmentation information.\n",
    "    Returns:\n",
    "        time_stamps (dict):\n",
    "            Dictionary containing lists of timestamps.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Extracting timestamps from {manifest_file} for multiscale subsegmentation.\")\n",
    "    time_stamps = {}\n",
    "    with open(manifest_file, 'r', encoding='utf-8') as manifest:\n",
    "        for i, line in enumerate(manifest.readlines()):\n",
    "            line = line.strip()\n",
    "            dic = json.loads(line)\n",
    "            uniq_name = dic['uniq_id']\n",
    "            if uniq_name not in time_stamps:\n",
    "                time_stamps[uniq_name] = []\n",
    "            start = dic['offset']\n",
    "            end = start + dic['duration']\n",
    "            time_stamps[uniq_name].append([start, end])\n",
    "    return time_stamps\n",
    "\n",
    "\n",
    "def make_rttm_with_overlap(\n",
    "    manifest_file_path: str,\n",
    "    clus_label_dict: Dict[str, List[Union[float, int]]],\n",
    "    msdd_preds: List[torch.Tensor],\n",
    "    **params,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create RTTM files that include detected overlap speech. Note that the effect of overlap detection is only\n",
    "    notable when RTTM files are evaluated with `ignore_overlap=False` option.\n",
    "\n",
    "    Args:\n",
    "        manifest_file_path (str):\n",
    "            Path to the input manifest file.\n",
    "        clus_label_dict (dict):\n",
    "            Dictionary containing subsegment timestamps in float type and cluster labels in integer type.\n",
    "            Indexed by `uniq_id` string.\n",
    "        msdd_preds (list):\n",
    "            List containing tensors of the predicted sigmoid values.\n",
    "            Each tensor has shape of: (Session length, estimated number of speakers).\n",
    "        params:\n",
    "            Parameters for generating RTTM output and evaluation. Parameters include:\n",
    "                infer_overlap (bool): If False, overlap-speech will not be detected.\n",
    "            See docstrings of `generate_speaker_timestamps` function for other variables in `params`.\n",
    "\n",
    "    Returns:\n",
    "        all_hypothesis (list):\n",
    "            List containing Pyannote's `Annotation` objects that are created from hypothesis RTTM outputs.\n",
    "        all_reference\n",
    "            List containing Pyannote's `Annotation` objects that are created from ground-truth RTTM outputs\n",
    "    \"\"\"\n",
    "    AUDIO_RTTM_MAP = audio_rttm_map(manifest_file_path)\n",
    "    manifest_file_lengths_list = []\n",
    "    all_hypothesis, all_reference = [], []\n",
    "    no_references = False\n",
    "    with open(manifest_file_path, 'r', encoding='utf-8') as manifest:\n",
    "        for i, line in enumerate(manifest.readlines()):\n",
    "            uniq_id = get_uniq_id_from_manifest_line(line)\n",
    "            manifest_dic = AUDIO_RTTM_MAP[uniq_id]\n",
    "            clus_labels = clus_label_dict[uniq_id]\n",
    "            manifest_file_lengths_list.append(len(clus_labels))\n",
    "            maj_labels, ovl_labels = generate_speaker_timestamps(clus_labels, msdd_preds[i], **params)\n",
    "            if params['infer_overlap']:\n",
    "                hyp_labels = maj_labels + ovl_labels\n",
    "            else:\n",
    "                hyp_labels = maj_labels\n",
    "            hypothesis = labels_to_pyannote_object(hyp_labels, uniq_name=uniq_id)\n",
    "            if params['out_rttm_dir']:\n",
    "                hyp_labels = sorted(hyp_labels, key=lambda x: float(x.split()[0]))\n",
    "                labels_to_rttmfile(hyp_labels, uniq_id, params['out_rttm_dir'])\n",
    "            all_hypothesis.append([uniq_id, hypothesis])\n",
    "            rttm_file = manifest_dic.get('rttm_filepath', None)\n",
    "            if rttm_file is not None and os.path.exists(rttm_file) and not no_references:\n",
    "                ref_labels = rttm_to_labels(rttm_file)\n",
    "                reference = labels_to_pyannote_object(ref_labels, uniq_name=uniq_id)\n",
    "                all_reference.append([uniq_id, reference])\n",
    "            else:\n",
    "                no_references = True\n",
    "                all_reference = []\n",
    "    return all_reference, all_hypothesis\n",
    "\n",
    "\n",
    "def embedding_normalize(embs, use_std=False, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Mean and l2 length normalize the input speaker embeddings\n",
    "\n",
    "    Args:\n",
    "        embs: embeddings of shape (Batch,emb_size)\n",
    "    Returns:\n",
    "        embs: normalized embeddings of shape (Batch,emb_size)\n",
    "    \"\"\"\n",
    "    embs = embs - embs.mean(axis=0)\n",
    "    if use_std:\n",
    "        embs = embs / (embs.std(axis=0) + eps)\n",
    "    embs_l2_norm = np.expand_dims(np.linalg.norm(embs, ord=2, axis=-1), axis=1)\n",
    "    embs = embs / embs_l2_norm\n",
    "\n",
    "    return embs\n",
    "\n",
    "\n",
    "class OnlineSegmentor:\n",
    "    \"\"\"\n",
    "    Online Segmentor for online (streaming) diarizer.\n",
    "    - The class instances created by this class takes time-series signal from the audio buffer and\n",
    "      creates subsegments for embedding extraction.\n",
    "    - Since online segmentation is based on a short audio buffer, the methods in this class extracts\n",
    "      a few subsegments from the given intervals for the raw time-series signal.\n",
    "\n",
    "    Attributes:\n",
    "        frame_start (float):\n",
    "            Start of the middle chunk\n",
    "        buffer_start (float):\n",
    "            Start of the entire buffer\n",
    "        buffer_end (float):\n",
    "            End of the entire buffer\n",
    "        sample_rate (int):\n",
    "            Sampling rate of the input time-series signal\n",
    "        cumulative_speech_labels (Tensor):\n",
    "            Torch tensor matrix containing culmulative VAD (speech activity) timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate: int):\n",
    "        self.frame_start: float = 0.0\n",
    "        self.buffer_start: float = 0.0\n",
    "        self.buffer_end: float = 0.0\n",
    "        self.sample_rate: int = sample_rate\n",
    "        self.cumulative_speech_labels: torch.Tensor = torch.tensor([])\n",
    "\n",
    "    def run_online_segmentation(\n",
    "        self,\n",
    "        audio_buffer: torch.Tensor,\n",
    "        vad_timestamps: torch.Tensor,\n",
    "        segment_raw_audio: List[torch.Tensor],\n",
    "        segment_range_ts: List[List[float]],\n",
    "        segment_indexes: List[int],\n",
    "        window: float,\n",
    "        shift: float,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Remove the old segments that overlap with the new frame (self.frame_start)\n",
    "        cursor_for_old_segments is pointing at the onset of the t_range popped most recently.\n",
    "\n",
    "        Frame is in the middle of the buffer.\n",
    "\n",
    "        |___Buffer___[___________]____________|\n",
    "        |____________[   Frame   ]____________|\n",
    "\n",
    "        | <- buffer start\n",
    "        |____________| <- frame start\n",
    "\n",
    "\n",
    "        Args:\n",
    "            audio_buffer (Tensor):\n",
    "                Tensor containing raw time-series signal\n",
    "            vad_timestamps (Tensor):\n",
    "                Tensor containing VAD intervals (start and end timestamps)\n",
    "            segment_raw_audio (list):\n",
    "                List containing the previously added tensors of the raw time-series signal segments\n",
    "            segment_range_ts (list):\n",
    "                List containing the previously added intervals (start and end timestamps) of each segment\n",
    "            segment_indexes (list):\n",
    "                List containing the previously added global integer indicies of the segments from\n",
    "                start to current cursor\n",
    "            window (float):\n",
    "                Window length in second\n",
    "            shift (float):\n",
    "                Shift length in second\n",
    "\n",
    "        Returns:\n",
    "            segment_raw_audio (list):\n",
    "                List containing the newly added tensors of the raw time-series signal\n",
    "            segment_range_ts (list):\n",
    "                List containing the newly added interval (start and end timestamps) of each segment\n",
    "            segment_indexes (list):\n",
    "                List containing the newly added global integer indicies of the segments from\n",
    "                start to current cursor\n",
    "        \"\"\"\n",
    "        if self.buffer_start >= 0:\n",
    "            # Check if this is the very first step\n",
    "            if len(segment_raw_audio) == 0 and vad_timestamps.shape[0] > 0:\n",
    "                vad_timestamps[0][0] = max(vad_timestamps[0][0], 0.0)\n",
    "                speech_labels_for_update = vad_timestamps\n",
    "                self.cumulative_speech_labels = speech_labels_for_update\n",
    "            else:\n",
    "                # Calculate a cursor for the update point\n",
    "                cursor_for_old_segments, cursor_index = get_new_cursor_for_update(self.frame_start, segment_range_ts)\n",
    "\n",
    "                segment_range_ts = segment_range_ts[:cursor_index]\n",
    "                segment_raw_audio = segment_raw_audio[:cursor_index]\n",
    "                segment_indexes = segment_indexes[:cursor_index]\n",
    "\n",
    "                if not len(segment_raw_audio) == len(segment_range_ts) == len(segment_indexes):\n",
    "                    raise ValueError(\"Scale-wise segment information has a mismatch in length.\")\n",
    "\n",
    "                speech_labels_for_update, self.cumulative_speech_labels = get_speech_labels_for_update(\n",
    "                    self.frame_start,\n",
    "                    self.buffer_end,\n",
    "                    self.cumulative_speech_labels,\n",
    "                    vad_timestamps,\n",
    "                    cursor_for_old_segments,\n",
    "                )\n",
    "\n",
    "            # Collect the timeseries signal from the buffer\n",
    "            sigs_list, sig_rangel_list, sig_indexes = get_online_subsegments_from_buffer(\n",
    "                buffer_start=self.buffer_start,\n",
    "                buffer_end=self.buffer_end,\n",
    "                sample_rate=self.sample_rate,\n",
    "                speech_labels_for_update=speech_labels_for_update,\n",
    "                audio_buffer=audio_buffer,\n",
    "                segment_indexes=segment_indexes,\n",
    "                window=window,\n",
    "                shift=shift,\n",
    "            )\n",
    "\n",
    "            segment_raw_audio.extend(sigs_list)\n",
    "            segment_range_ts.extend(sig_rangel_list)\n",
    "            segment_indexes.extend(sig_indexes)\n",
    "\n",
    "        if not len(segment_raw_audio) == len(segment_range_ts) == len(segment_indexes):\n",
    "            raise ValueError(\"Segment information has a mismatch in length.\")\n",
    "        return segment_raw_audio, segment_range_ts, segment_indexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
