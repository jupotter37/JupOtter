{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMjCF4Cyu4iU/6avwmRecMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaishnavi-TCD/TCD/blob/main/Final_ML_Initial%20all%20version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwk1xC1ONn8d",
        "outputId": "45f41c8f-3898-450b-d4e7-108219a14fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.651214 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-fb5a7b478578>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(torch.tensor(loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.6910, val loss 2.6946, train perplexity 14.7471, val perplexity 14.7997, train accuracy 0.0665, val accuracy 0.0701\n",
            "step 500: train loss 1.6156, val loss 1.5390, train perplexity 5.0308, val perplexity 4.6599, train accuracy 0.4043, val accuracy 0.4275\n",
            "step 1000: train loss 1.3920, val loss 1.3461, train perplexity 4.0230, val perplexity 3.8426, train accuracy 0.5115, val accuracy 0.5256\n",
            "step 1500: train loss 1.3045, val loss 1.2728, train perplexity 3.6858, val perplexity 3.5708, train accuracy 0.5485, val accuracy 0.5591\n",
            "step 2000: train loss 1.2738, val loss 1.2534, train perplexity 3.5743, val perplexity 3.5022, train accuracy 0.5599, val accuracy 0.5659\n",
            "step 2500: train loss 1.2471, val loss 1.2409, train perplexity 3.4803, val perplexity 3.4588, train accuracy 0.5695, val accuracy 0.5726\n",
            "step 3000: train loss 1.2364, val loss 1.2377, train perplexity 3.4434, val perplexity 3.4475, train accuracy 0.5738, val accuracy 0.5752\n",
            "step 3500: train loss 1.2251, val loss 1.2275, train perplexity 3.4046, val perplexity 3.4126, train accuracy 0.5777, val accuracy 0.5777\n",
            "step 4000: train loss 1.2065, val loss 1.2211, train perplexity 3.3418, val perplexity 3.3911, train accuracy 0.5844, val accuracy 0.5811\n",
            "step 4500: train loss 1.2004, val loss 1.2238, train perplexity 3.3216, val perplexity 3.4000, train accuracy 0.5873, val accuracy 0.5810\n",
            "step 4999: train loss 1.1870, val loss 1.2185, train perplexity 3.2772, val perplexity 3.3820, train accuracy 0.5923, val accuracy 0.5837\n",
            "Generated Melody (GPT Model):\n",
            "\n",
            "RfEEDFFEECEDCBCCCCCCEECCDCCARAffEfAfEDRfffREEDFFEEDRFDaFEDDFEECCGCCCARAAGGfRCCCCCDEFFEEDCgFRAAacFECECGCCCCCCEGCGACRGFCCAaARAAAAGGfRDaDCCCCDEFFECCEGCECEDEFECCECREEDCEFFECCECCCGCGACRACCCARGFGAaccccaEFCEEDDCEFECCGFEECGFEEDDEFCCEECCCCCDDDRBCCCCCaCCCEGCECCCCCCCCCARDCCARAAGGDCCRCCCCCCARFFcEEEDEFECCEFECREFECCgEECCCCCaaCCCGACRAGGRFCCFfEEDDEEFECCCCGFGECCCCGFEEEDCCECCCCCCCCDDARFFcBBBBBcDBDCEFECCCGFEECCCCCCDRFFcECCCGFGECGCEFECCCGFEECCCCCGFEECCCARAGGRFFcECCCCdCCGFCEECCCGFECCCCGGFECCCCCCGFEEECCCGFEECCCCCGFEE\n",
            "BLEU Score: 0.1324\n",
            "Generated Melody (Unigram Model):\n",
            "EBRAEdfFGRBBDEffgARaBADafGdCRGDgaRgFRdfBFCggFBcffFRGACaEggFFEAgfaDARfRGCEAfEAaABBgGdRGdagDfDaBffBafDARRDFFaAFcDGACCFEdaDFcaEcfgDDcgBEDBccgDRdCDRGAAacafdGDcCRcBdFA\n",
            "aFBBaaFDgCEBFdCcDFCaFgcdAgcDRBCRaEBGBCdEGfgGCEBRDaACDaFfAFFDaGBFgDDfcddGcfFfCdRdRGECcaREFDAffGgcAdBgBEdRfFgfEARBAFagCGCBGgaBdACafBBagcEFaFDFBEdGCaFEBfCBaaBRagcRdBAEBDBaEBRggEDEAgfGDFaDBdcdAFAgFAGDcDCAcFRcfGARcgAGfRGACDCAFRaCCFffRECBRGCRcacdARDGFfCcFafRBAgBEBDBCfFFGBGAEcBCCERfdDEdFaRBECdEfAgGBaggCdgcFfdcdfAFDFdRCGggDECddGFREGgGfdaCEAFCD\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.2\n",
        "\n",
        "n_embd= 256\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('inputMelodiesAugmented.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            # Reshape logits to match (B, T, C)\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)  # Restore original shape\n",
        "            predictions = logits.argmax(dim=-1)  # Get predicted indices\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()  # Compare predictions with targets\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    # BLEU score computation\n",
        "    reference = [list(reference)]  # BLEU expects a list of reference sequences\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss, accuracy, and BLEU score\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "# Calculate BLEU score against a reference (for demonstration purposes, use a subset of the dataset as reference)\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "# Generate melody using unigram baseline\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "unigram_generated = unigram_generate(500)\n",
        "print(unigram_generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Steps\n",
        "# normalize the dataset\n",
        "# Normalization: Convert all notes to uppercase\n",
        "def normalize_notes(melodies):\n",
        "    normalized = []\n",
        "    for melody in melodies:\n",
        "        normalized.append(melody.strip().upper())  # Convert to uppercase and remove extra spaces\n",
        "    return normalized\n",
        "\n",
        "# Load melodies\n",
        "with open('inputMelodiesAugmented.txt', 'r') as file:\n",
        "    melodies = file.readlines()\n",
        "\n",
        "# Apply normalization\n",
        "normalized_melodies = normalize_notes(melodies)\n",
        "\n",
        "# Save normalized melodies\n",
        "with open('normalizedMelodies.txt', 'w') as file:\n",
        "    for melody in normalized_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Normalization completed. Saved to 'normalizedMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAf4lJw5OsYy",
        "outputId": "7ba9daf8-b39a-4640-acab-2f16a80c41e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization completed. Saved to 'normalizedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# introduce rhythm and duration\n",
        "import random\n",
        "\n",
        "# Define rhythmic durations\n",
        "durations = [\"1/4\", \"1/8\", \"1/16\"]\n",
        "\n",
        "# Add rhythm and duration to notes\n",
        "def add_rhythm(melodies):\n",
        "    rhythmic_melodies = []\n",
        "    for melody in melodies:\n",
        "        rhythmic_melody = []\n",
        "        for note in melody.split():\n",
        "            if note != \"R\":  # Only notes get durations, rests remain the same\n",
        "                rhythmic_melody.append(f\"{note}:{random.choice(durations)}\")\n",
        "            else:\n",
        "                rhythmic_melody.append(note)  # Keep rests as is\n",
        "        rhythmic_melodies.append(\" \".join(rhythmic_melody))\n",
        "    return rhythmic_melodies\n",
        "\n",
        "# Apply rhythm\n",
        "rhythmic_melodies = add_rhythm(normalized_melodies)\n",
        "\n",
        "# Save rhythmic melodies\n",
        "with open('rhythmicMelodies.txt', 'w') as file:\n",
        "    for melody in rhythmic_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Rhythm added. Saved to 'rhythmicMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75xIhLVvRgZa",
        "outputId": "b728811b-d29b-45c2-f0df-13a1691269ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rhythm added. Saved to 'rhythmicMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ocatve expansion.. transpose melodies into lower and higher ocatves\n",
        "# Define pitch-shifting function\n",
        "def transpose_octave(melodies, shift):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    transposed_melodies = []\n",
        "    for melody in melodies:\n",
        "        transposed_melody = []\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:  # Token with duration\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    transposed_note = notes[(index + shift) % 12]  # Transpose note\n",
        "                    transposed_melody.append(f\"{transposed_note}:{duration}\")\n",
        "                else:\n",
        "                    transposed_melody.append(token)  # Keep rests unchanged\n",
        "            elif token in notes and token != \"R\":  # Plain note\n",
        "                index = notes.index(token)\n",
        "                transposed_note = notes[(index + shift) % 12]\n",
        "                transposed_melody.append(transposed_note)\n",
        "            else:\n",
        "                transposed_melody.append(token)\n",
        "        transposed_melodies.append(\" \".join(transposed_melody))\n",
        "    return transposed_melodies\n",
        "\n",
        "# Apply octave expansion\n",
        "expanded_melodies = []\n",
        "for shift in [-1, 0, 1]:  # Shift down an octave, keep original, shift up an octave\n",
        "    expanded_melodies += transpose_octave(rhythmic_melodies, shift)\n",
        "\n",
        "# Save expanded melodies\n",
        "with open('expandedMelodies.txt', 'w') as file:\n",
        "    for melody in expanded_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Octave expansion completed. Saved to 'expandedMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmwBoeJ8Rikr",
        "outputId": "2f9e68c1-57a3-4ce6-dd85-f93e61a87a9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Octave expansion completed. Saved to 'expandedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# additional data sugmentation techniques\n",
        "#Apply random pitch-shifting, inversion, and noise injection.\n",
        "# Data Augmentation Techniques\n",
        "\n",
        "# Random pitch shifting\n",
        "def random_pitch_shift(melodies, semitones_range=2):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    shifted_melodies = []\n",
        "    for melody in melodies:\n",
        "        shifted_melody = []\n",
        "        shift = random.randint(-semitones_range, semitones_range)  # Random shift within range\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    shifted_note = notes[(index + shift) % 12]\n",
        "                    shifted_melody.append(f\"{shifted_note}:{duration}\")\n",
        "                else:\n",
        "                    shifted_melody.append(token)\n",
        "            elif token in notes and token != \"R\":\n",
        "                index = notes.index(token)\n",
        "                shifted_note = notes[(index + shift) % 12]\n",
        "                shifted_melody.append(shifted_note)\n",
        "            else:\n",
        "                shifted_melody.append(token)\n",
        "        shifted_melodies.append(\" \".join(shifted_melody))\n",
        "    return shifted_melodies\n",
        "\n",
        "# Invert melody\n",
        "def invert_melody(melodies):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    inverted_melodies = []\n",
        "    for melody in melodies:\n",
        "        inverted_melody = []\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    inverted_note = notes[-(index + 1)]  # Invert by reversing the index\n",
        "                    inverted_melody.append(f\"{inverted_note}:{duration}\")\n",
        "                else:\n",
        "                    inverted_melody.append(token)\n",
        "            else:\n",
        "                inverted_melody.append(token)\n",
        "        inverted_melodies.append(\" \".join(inverted_melody))\n",
        "    return inverted_melodies\n",
        "\n",
        "# Apply augmentations\n",
        "pitch_shifted_melodies = random_pitch_shift(expanded_melodies)\n",
        "inverted_melodies = invert_melody(expanded_melodies)\n",
        "\n",
        "# Combine all augmented datasets\n",
        "augmented_dataset = expanded_melodies + pitch_shifted_melodies + inverted_melodies\n",
        "\n",
        "# Save the final augmented dataset\n",
        "with open('finalAugmentedMelodies.txt', 'w') as file:\n",
        "    for melody in augmented_dataset:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Data augmentation completed. Saved to 'finalAugmentedMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOSpGQY1RlGZ",
        "outputId": "0287a733-93e0-45b8-ed33-51331205472f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation completed. Saved to 'finalAugmentedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.2\n",
        "\n",
        "n_embd= 256\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('/content/finalAugmentedMelodies.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            # Reshape logits to match (B, T, C)\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)  # Restore original shape\n",
        "            predictions = logits.argmax(dim=-1)  # Get predicted indices\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()  # Compare predictions with targets\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    # BLEU score computation\n",
        "    reference = [list(reference)]  # BLEU expects a list of reference sequences\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss, accuracy, and BLEU score\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "# Calculate BLEU score against a reference (for demonstration purposes, use a subset of the dataset as reference)\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "# Calculate BLEU score for the unigram model\n",
        "unigram_generated = unigram_generate(500)\n",
        "unigram_bleu_score = calculate_bleu(reference_melody, unigram_generated)\n",
        "print(f\"BLEU Score (Unigram Model): {unigram_bleu_score:.4f}\")\n",
        "\n",
        "\n",
        "# Generate melody using unigram baseline\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(unigram_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRx6MtLsRoVe",
        "outputId": "b5c8b70a-e907-43f3-89af-4251a4df1d0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.651727 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ed86fc7054ed>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(torch.tensor(loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.8170, val loss 2.8147, train perplexity 16.7271, val perplexity 16.6874, train accuracy 0.1070, val accuracy 0.1088\n",
            "step 500: train loss 1.4998, val loss 1.4944, train perplexity 4.4810, val perplexity 4.4567, train accuracy 0.4227, val accuracy 0.4263\n",
            "step 1000: train loss 1.2736, val loss 1.2690, train perplexity 3.5736, val perplexity 3.5571, train accuracy 0.5393, val accuracy 0.5407\n",
            "step 1500: train loss 1.2077, val loss 1.2045, train perplexity 3.3457, val perplexity 3.3352, train accuracy 0.5665, val accuracy 0.5683\n",
            "step 2000: train loss 1.1921, val loss 1.1876, train perplexity 3.2941, val perplexity 3.2791, train accuracy 0.5716, val accuracy 0.5745\n",
            "step 2500: train loss 1.1730, val loss 1.1681, train perplexity 3.2315, val perplexity 3.2158, train accuracy 0.5802, val accuracy 0.5825\n",
            "step 3000: train loss 1.1740, val loss 1.1746, train perplexity 3.2350, val perplexity 3.2370, train accuracy 0.5791, val accuracy 0.5794\n",
            "step 3500: train loss 1.1586, val loss 1.1540, train perplexity 3.1854, val perplexity 3.1707, train accuracy 0.5881, val accuracy 0.5899\n",
            "step 4000: train loss 1.1395, val loss 1.1371, train perplexity 3.1252, val perplexity 3.1178, train accuracy 0.5943, val accuracy 0.5956\n",
            "step 4500: train loss 1.1273, val loss 1.1302, train perplexity 3.0873, val perplexity 3.0963, train accuracy 0.6004, val accuracy 0.5997\n",
            "step 4999: train loss 1.1196, val loss 1.1194, train perplexity 3.0635, val perplexity 3.0631, train accuracy 0.6029, val accuracy 0.6027\n",
            "Generated Melody (GPT Model):\n",
            "\n",
            "RFEGGAGARFEDCRDGGEDCRGGGEDCRCEFFGEDCDCDFCRCCCDCBEDDGERCEFGAAAAARAAAGABGFERFFERFERFE:1/16\n",
            "GGGGGGDFGGGFGGGGGDFGGFGGGGAFDDCCFFGGGGGGGGDCCFFFFFGGFFDFGCCRGGGAFERGGGGGDFGGGGGFGDFGGFFGGGGGGGGGFGGGGDFDCDCFFGDFGGGGGGGGAFDDCAFGGGGGGGGGGGGGGDFGFFDDCDCFCCRGGGAFRGGGFGGGGAFFDFDDCDCFFGGGGGGGGGFFFDDCDCDCFFGFFFDDCCFGDCGGGGGGGGGDFGGGGGGGGGGGGFGFGGGGGDFDFDDDCDCFFFFFGGGGGGGGGGGGGGGGGGDGAGGGGGGGGGGGGGGGGGGGGFGGGGGDFDCDCFGGGGGGDFDCFGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGFGGGGGGGGGGGGGGGGFGGGGGGGGGGGGGGGGGGGGFGGGGGGGFGGRGGFG\n",
            "BLEU Score: 0.2730\n",
            "BLEU Score (Unigram Model): 0.2488\n",
            "Generated Melody (Unigram Model):\n",
            "AAGEAFFFAFARDDCRCGGDADEFBDFGRC/RGFBCBFEFGGGEEDCARDBCGCCEGDRBFDBGAFBAABCCABAFFADCEDGBFGDDGAAFGBRDGFREDFRFCGGEGRGDADGFAEEDFFARCFRGCFBDCARDFAEFRCABGERAADFCACRRFFEEGRGCDAGGBARAADECFRAGBFA\n",
            "CCFCRCADDCCCBRGDBGBGFCDFFFRCGDRCDGACFCEGFRBFCFEB8BCBDRDGFFDAAACEGBCCEAEGADBDFEFDGGCGFBRGDFDCDDFRCGGAEGERAFFBFFRC/AGCFDGACADCAGACGRGGDFEECDBABBGDFCDGG/ACAAGDDGBFGDEGBAGBABCCAADGFDFCF1GDACBAGAACADEAABDEFGERFGBFRBRDERGRGGFGFABCGBDRDGGDRDGERCADGRFFFCEDRDFGCBGGGBDGCGEAGCDCBFFDADCRBCGECGGACGDBFGAGFCABAGCCEGACCEEGAFDFGD1F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architectural Enhacements:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 3000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.3\n",
        "\n",
        "n_embd= 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "# Gradient clipping threshold\n",
        "grad_clip = 1.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('/content/finalAugmentedMelodies.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            # Reshape logits to match (B, T, C)\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)  # Restore original shape\n",
        "            predictions = logits.argmax(dim=-1)  # Get predicted indices\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()  # Compare predictions with targets\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    # BLEU score computation\n",
        "    reference = [list(reference)]  # BLEU expects a list of reference sequences\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class RelativePositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.encoding = nn.Parameter(torch.zeros(max_len, d_model))\n",
        "\n",
        "        # Initialize positional encodings\n",
        "        nn.init.xavier_uniform_(self.encoding)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape  # Batch size and sequence length\n",
        "        if T > self.max_len:\n",
        "            raise ValueError(\"Sequence length exceeds the maximum length of positional encoding.\")\n",
        "        return self.encoding[:T, :]  # Return encodings for the given sequence length\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # Scaled dot-product attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.relative_pos_encoding = RelativePositionalEncoding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.relative_pos_encoding(idx)  # Adjusted for sequence length\n",
        "        pos_emb = pos_emb.unsqueeze(0).expand(B, -1, -1)  # Match batch size\n",
        "        x = tok_emb + pos_emb  # Combine embeddings\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "unigram_generated = unigram_generate(500)\n",
        "unigram_bleu_score = calculate_bleu(reference_melody, unigram_generated)\n",
        "print(f\"BLEU Score (Unigram Model): {unigram_bleu_score:.4f}\")\n",
        "\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(unigram_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02r7oZZzZODf",
        "outputId": "93032a8d-45ba-4fde-ddb1-e73d575ea79e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.052559 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-366085a6911e>:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(torch.tensor(loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.8724, val loss 2.8751, train perplexity 17.6788, val perplexity 17.7272, train accuracy 0.0655, val accuracy 0.0650\n",
            "step 500: train loss 1.5286, val loss 1.5196, train perplexity 4.6119, val perplexity 4.5704, train accuracy 0.4112, val accuracy 0.4131\n",
            "step 1000: train loss 1.1970, val loss 1.1895, train perplexity 3.3103, val perplexity 3.2855, train accuracy 0.5689, val accuracy 0.5720\n",
            "step 1500: train loss 1.0662, val loss 1.0633, train perplexity 2.9043, val perplexity 2.8960, train accuracy 0.6216, val accuracy 0.6225\n",
            "step 2000: train loss 1.0209, val loss 1.0132, train perplexity 2.7756, val perplexity 2.7543, train accuracy 0.6374, val accuracy 0.6403\n",
            "step 2500: train loss 0.9652, val loss 0.9629, train perplexity 2.6252, val perplexity 2.6193, train accuracy 0.6549, val accuracy 0.6559\n",
            "step 2999: train loss 0.9012, val loss 0.9006, train perplexity 2.4625, val perplexity 2.4610, train accuracy 0.6742, val accuracy 0.6748\n",
            "Generated Melody (GPT Model):\n",
            "\n",
            "REFGFFFFFGFFEREFEGGFGGFGAGFGFGFRFGFFFFREFEGGGFGGFRFGFFFREFECBGERFFFFFFFGFGGFGFGFGFFREFCBERFECBGERFFGFFFFGFFFREFEGGFGGGFFGFREFEGGFGFGFREFEGFGGFGFFFREFECBBERFERFECBGEDRAGFFFFFGFEEDEDABAGFFFAGGFFDABAAGABGGFGFEGCBCEGBGGERFFECABEDDCCDCDCDCADCCGBCEBBADGGFRAGBABAECBABBBBBCBADGFFADDCRBCDFDCBCDEGGRBDCDEGGRBDCDERDCDEGGRBDCDEGGRBDCDEGGRBDCDERFGGRBBCBCBCBGGABCEBRAGGBBE:1/4\n",
            "RCCGCGCGGACADAAAGRCCGCGCGGAGCGCCCCGGCGCCGCGGAGFGCCCCGCGCGGGDDCACCCDCCCGAGAGDDCAGACCDEDCCCDCCRCCDEDCCCDERCCDEDCARADDCCCCCDCAGFGFGFGFGFGFA\n",
            "BLEU Score: 0.2637\n",
            "BLEU Score (Unigram Model): 0.2496\n",
            "Generated Melody (Unigram Model):\n",
            "CCGRDEGGEGRFGAEFFCABFDCEDACAGAAGFFFDRAARGFDFCEFEADB:DBDBAGGCCGGDGCADAEBGACAAAGBCAERDRCGEGCRCCDCCCEARBDEEGGBD1DCDRCAERCGCCFBGFDGDFFAADRACAFEGRCAEEFDCAGBGRBAADGFEFCGDGGRDGEFAFFFACADRGCCFAFGRAGRGAFGFRDFACFCAAEFDDAFCGGCGCABCGEAG/DCRADRCRARCDFFACDAGEEB4BDFCRAED1FCDGBRDEDFBFAERBAEGGFDBDBFAFACRGGAGGCBFGFGARGDCCEFBFFGBGCDDFABDBAEBCDDFGGERADBGGAAEAFGGBARBBGDBGAGFCCACFGGGFGDGDGBBAECCBAAACFFGF1ARGFECFGCACGEEBBCEAGGAEGEEGEFBBDFCECEDFFFGAAFCEAREDFAECDDFACCFRECGFCCCAFACFFDCEBCCBCCFFDRFAFBGFDCCAGCEACCFRGFCCDCD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model architecture and training hyperparameters modifications\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 128 # Increased batch size\n",
        "block_size = 512 # Increased block size\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.3\n",
        "\n",
        "n_embd = 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "grad_clip = 1.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('/content/finalAugmentedMelodies.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l])  # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    reference = [list(reference)]\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class RelativePositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.encoding = nn.Parameter(torch.zeros(max_len, d_model))\n",
        "        nn.init.xavier_uniform_(self.encoding)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "        if T > self.encoding.size(0):\n",
        "            raise ValueError(\"Sequence length exceeds the maximum length of positional encoding.\")\n",
        "        return self.encoding[:T, :]\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.relative_pos_encoding = RelativePositionalEncoding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.relative_pos_encoding(idx).unsqueeze(0).expand(B, -1, -1)\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "        lr_scheduler.step(metrics['val']['loss'])\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "unigram_generated = unigram_generate(500)\n",
        "unigram_bleu_score = calculate_bleu(reference_melody, unigram_generated)\n",
        "print(f\"BLEU Score (Unigram Model): {unigram_bleu_score:.4f}\")\n",
        "\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(unigram_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "C0pVqO-vn-vv",
        "outputId": "04027529-e43f-4032-c948-bc4360739caa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.183631 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-16-804c466c2bc9>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(torch.tensor(loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.7907, val loss 2.7925, train perplexity 16.2917, val perplexity 16.3213, train accuracy 0.1011, val accuracy 0.0988\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 33.06 MiB is free. Process 8425 has 14.71 GiB memory in use. Of the allocated memory 14.22 GiB is allocated by PyTorch, and 368.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36m<cell line: 227>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_pos_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-804c466c2bc9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 33.06 MiB is free. Process 8425 has 14.71 GiB memory in use. Of the allocated memory 14.22 GiB is allocated by PyTorch, and 368.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architectural Enhacements:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.3\n",
        "\n",
        "n_embd= 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "# Gradient clipping threshold\n",
        "grad_clip = 1.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('/content/finalAugmentedMelodies.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            # Reshape logits to match (B, T, C)\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)  # Restore original shape\n",
        "            predictions = logits.argmax(dim=-1)  # Get predicted indices\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()  # Compare predictions with targets\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    # BLEU score computation\n",
        "    reference = [list(reference)]  # BLEU expects a list of reference sequences\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class RelativePositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.encoding = nn.Parameter(torch.zeros(max_len, d_model))\n",
        "\n",
        "        # Initialize positional encodings\n",
        "        nn.init.xavier_uniform_(self.encoding)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape  # Batch size and sequence length\n",
        "        if T > self.max_len:\n",
        "            raise ValueError(\"Sequence length exceeds the maximum length of positional encoding.\")\n",
        "        return self.encoding[:T, :]  # Return encodings for the given sequence length\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # Scaled dot-product attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.relative_pos_encoding = RelativePositionalEncoding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.relative_pos_encoding(idx)  # Adjusted for sequence length\n",
        "        pos_emb = pos_emb.unsqueeze(0).expand(B, -1, -1)  # Match batch size\n",
        "        x = tok_emb + pos_emb  # Combine embeddings\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "unigram_generated = unigram_generate(500)\n",
        "unigram_bleu_score = calculate_bleu(reference_melody, unigram_generated)\n",
        "print(f\"BLEU Score (Unigram Model): {unigram_bleu_score:.4f}\")\n",
        "\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(unigram_generated)\n"
      ],
      "metadata": {
        "id": "qi7QOKQD-YWg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}