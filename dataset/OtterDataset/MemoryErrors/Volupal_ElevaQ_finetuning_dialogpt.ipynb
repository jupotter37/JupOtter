{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453318c-3fa5-4b1e-86d1-af7ec9ef15a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:04:42.056197Z",
     "iopub.status.busy": "2024-03-02T17:04:42.055131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./env/lib/python3.10/site-packages (4.37.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install datasets\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f3a7cc-f23a-43fd-8f29-050ddc6bf431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:43.633102Z",
     "iopub.status.busy": "2024-03-02T17:27:43.632916Z",
     "iopub.status.idle": "2024-03-02T17:27:43.650406Z",
     "shell.execute_reply": "2024-03-02T17:27:43.649694Z",
     "shell.execute_reply.started": "2024-03-02T17:27:43.633086Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e90f14-a776-47b2-9265-ff4fb8689608",
   "metadata": {},
   "source": [
    "> this notebook will follow the tutorial in:\n",
    "https://blog.gopenai.com/fine-tuning-dialogpt-medium-on-daily-dialog-dataset-a-step-by-step-guide-4eaecc1b9323"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a8aa2-047a-43ae-bcde-56e23f48c6c9",
   "metadata": {},
   "source": [
    "# make my own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f0a4b1-a071-446a-8fb9-2604542b6447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:43.651422Z",
     "iopub.status.busy": "2024-03-02T17:27:43.651154Z",
     "iopub.status.idle": "2024-03-02T17:27:43.659201Z",
     "shell.execute_reply": "2024-03-02T17:27:43.658608Z",
     "shell.execute_reply.started": "2024-03-02T17:27:43.651395Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/learn/nlp-course/chapter5/5\n",
    "# https://huggingface.co/learn/nlp-course/chapter5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5eb83a7-2330-46ad-a22f-a80cca669419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:43.659898Z",
     "iopub.status.busy": "2024-03-02T17:27:43.659738Z",
     "iopub.status.idle": "2024-03-02T17:27:44.232186Z",
     "shell.execute_reply": "2024-03-02T17:27:44.231681Z",
     "shell.execute_reply.started": "2024-03-02T17:27:43.659883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterdays/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92d28bf-d212-464e-a7c1-31d181ddf324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:44.233915Z",
     "iopub.status.busy": "2024-03-02T17:27:44.233368Z",
     "iopub.status.idle": "2024-03-02T17:27:44.249129Z",
     "shell.execute_reply": "2024-03-02T17:27:44.248597Z",
     "shell.execute_reply.started": "2024-03-02T17:27:44.233896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/DL103_2008.json',\n",
       " 'data/0288702916.json',\n",
       " 'data/DL320_2002.json',\n",
       " 'data/L65_2013.json',\n",
       " 'data/dlr7_2016-m.json',\n",
       " 'data/0331103315.json',\n",
       " 'data/DLR4_2012_A.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('data/*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ef9a0-624d-4557-83b1-2d77bf194189",
   "metadata": {},
   "source": [
    "we can also set the splits\n",
    "\n",
    "`data_files = {\"train\": \"json_example.json\", \"test\": \"json_example.json\"}`\n",
    "`dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a66f020-e58e-4f87-8c59-54c361828133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:44.250172Z",
     "iopub.status.busy": "2024-03-02T17:27:44.249994Z",
     "iopub.status.idle": "2024-03-02T17:27:45.435549Z",
     "shell.execute_reply": "2024-03-02T17:27:45.434445Z",
     "shell.execute_reply.started": "2024-03-02T17:27:44.250153Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=glob('data/*.json'))\n",
    "\n",
    "# train test split\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebcdf67-1352-46d6-a383-3fef1db122ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:45.437395Z",
     "iopub.status.busy": "2024-03-02T17:27:45.436972Z",
     "iopub.status.idle": "2024-03-02T17:27:45.467909Z",
     "shell.execute_reply": "2024-03-02T17:27:45.466852Z",
     "shell.execute_reply.started": "2024-03-02T17:27:45.437354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'page'],\n",
       "        num_rows: 84\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'page'],\n",
       "        num_rows: 22\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c149d2a5-a476-4cce-8c9a-114be87d2a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:45.469884Z",
     "iopub.status.busy": "2024-03-02T17:27:45.469127Z",
     "iopub.status.idle": "2024-03-02T17:27:45.499525Z",
     "shell.execute_reply": "2024-03-02T17:27:45.498520Z",
     "shell.execute_reply.started": "2024-03-02T17:27:45.469842Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Diário da República, 1.ª série — N.º 12 — 17 de janeiro de 2012 Artigo 8.º Responsabilidade pelo projeto e pela execução A responsabilidade técnica pela demonstração do cum- primento das exigências decorrentes do presente diploma apenas pode ser assumida por técnicos que cumpram o disposto no artigo 97.º do Decreto Legislativo Regional n.º 16/2009/A, de 13 de outubro, considerando- se uma qualificação específica para o efeito a definir nos termos do n.º 2 daquele artigo',\n",
       "  'Artigo 9.º Obrigação de conformidade Apenas podem ser instalados dispositivos e seus com- ponentes de segurança em relação aos quais tenha sido emitida uma declaração CE de conformidade e que osten- tem aposta, nos termos legais e regulamentares aplicáveis, a respetiva marcação CE de conformidade',\n",
       "  'Artigo 10.º Competências das câmaras municipais 1 — Sem prejuízo das atribuições e competências le- galmente atribuídas ou delegadas a outras entidades, as câmaras municipais, no âmbito do presente diploma, são competentes para: a) Efetuar o licenciamento das instalações, quando as mesmas, nos termos legais e regulamentares, estejam in- tegradas em obra sujeita a licenciamento municipal no âmbito do regime jurídico da urbanização e edificação; b) Verificar a conformidade da DCR e fiscalizar a cons- trução e instalação dos dispositivos; c) Efetuar fiscalizações ordinárias e extraordinárias, sempre que o considerem necessário, ou a pedido funda- mentado dos interessados; d) Verificar a existência e conformidade do CE antes da emissão das autorizações de utilização para as quais sejam competentes; e) Fiscalizar o cumprimento das obrigações de manu- tenção e inspeção e as condições de utilização dos dispo- sitivos; f) Realizar inquéritos a acidentes decorrentes da utili- zação ou das operações de manutenção das instalações e dos dispositivos',\n",
       "  '2 — É cobrada uma taxa, a fixar pela autarquia nos ter- mos legais aplicáveis às taxas municipais, pela realização das atividades referidas nas alíneas a), c) e f) do número anterior, quando realizadas a pedido dos interessados',\n",
       "  '3 — Para o exercício das competências a que se refere o n.º 1 do presente artigo, as câmaras municipais podem recorrer às entidades inspetoras previstas no artigo 20.º e seguintes do presente diploma',\n",
       "  '4 — As câmaras municipais podem definir, mediante a celebração de contrato ou por via de regulamento munici- pal, as condições de prestação de serviços pelas entidades mencionadas no número anterior',\n",
       "  'Artigo 11.º Registo e disponibilização de informação 1 — O SCE mantém em página adequada do seu portal na Internet, de acesso restrito aos peritos e entidades certi- ficadas no âmbito daquele sistema, um registo atualizado',\n",
       "  '232 D que não esteja sujeita a legislação especial, e os deveres que lhes são aplicáveis, e seus regulamentos, e com o presente diploma; d) O cálculo dos valores das necessidades nominais de energia do dispositivo e estimativa do seu consumo mensal face às condições de utilização previstas; e) Declaração de Conformidade Regulamentar (DCR) subscrita por perito qualificado no âmbito do SCE',\n",
       "  '3 — A entidade distribuidora de energia elétrica só pode celebrar contrato de fornecimento de energia elétrica às instalações que possuam dispositivos aos quais se aplica o presente diploma após lhe ter sido apresentada cópia da respetiva DCR',\n",
       "  '4 — O requerimento de licença ou autorização de uti- lização deve incluir o certificado de vistoria da instalação emitido por perito qualificado no âmbito do SCE',\n",
       "  '5 — O disposto nos números anteriores é aplicável, com as devidas adaptações, às operações urbanísticas de edificação promovidas pela administração pública e pelas entidades concessionárias de obras ou serviços públicos, isentas de licenciamento',\n",
       "  'Artigo 6.º Licenciamento de dispositivos em edifícios existentes 1 — O disposto no artigo anterior aplica- se, com as necessárias adaptações, à instalação de dispositivos em edifícios preexistentes e à substituição dos dispositivos já existentes nos edifícios, mesmo nos casos em que tal inter- venção não esteja sujeita a licenciamento municipal',\n",
       "  '2 — O disposto no artigo anterior aplica- se igualmente às grandes intervenções de reabilitação de dispositivos instalados, entendendo -se como tal a realização de qual- quer das obras de beneficiação a que se refere a parte B do anexo III ao presente diploma, do qual é parte integrante',\n",
       "  '3 — A emissão de uma DCR no âmbito do licencia- mento a que se referem os números anteriores implica obri- gatoriamente, após a conclusão e vistoria final da obra, a emissão para o imóvel de novo certificado energético (CE), nos termos da alínea b) do n.º 1 do artigo 18.º do Decreto Legislativo Regional n.º 16/2009/A, de 13 de outubro, no qual deve estar registada a existência e características do dispositivo',\n",
       "  'Artigo 7.º Substituição das instalações 1 — Sem prejuízo do disposto no artigo anterior quanto à emissão de DCR, a substituição das instalações está su- jeita ao cumprimento dos requisitos de conceção, fabrico, instalação, ensaios e controlo final constantes do Decreto- -Lei n.º 295/98, de 22 de setembro',\n",
       "  '2 — A substituição parcial das instalações também se encontra sujeita à observância dos requisitos constantes do diploma referido no número anterior que estejam direta- mente relacionados com a substituição em causa',\n",
       "  '3 — Sempre que se tratar de uma substituição parcial importante, deve proceder -se a uma inspeção, nos termos aplicáveis do presente diploma, antes da reposição em serviço das instalações',\n",
       "  '4 — Consideram -se importantes as mudanças listadas no anexo E.2 das NP EN 81 -1 e NP EN 81 -2 e na secção n.º 16 da NP EN 115.'],\n",
       " 'page': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff05d794-de18-4674-83bb-44c8d10d3c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:45.500902Z",
     "iopub.status.busy": "2024-03-02T17:27:45.500714Z",
     "iopub.status.idle": "2024-03-02T17:27:45.515144Z",
     "shell.execute_reply": "2024-03-02T17:27:45.514644Z",
     "shell.execute_reply.started": "2024-03-02T17:27:45.500886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate all utterances within a dialogue and map to 'dialog' key\n",
    "def concatenate_paragraphs(example):\n",
    "    example['page'] = \" \".join(example['text'])\n",
    "    return example\n",
    "\n",
    "# dataset = dataset.map(concatenate_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb19276-8bd1-472d-b254-639882c4d365",
   "metadata": {},
   "source": [
    "> Note: not sure if this is really needed, but for simplicity will make a whole text per example\n",
    ">\n",
    "> The DialogPT is based on short context, this doesn't lead to good results! Will be trying without concatenating as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fd709e-7a50-46f5-a48d-3ca11bec411b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:45.516389Z",
     "iopub.status.busy": "2024-03-02T17:27:45.515960Z",
     "iopub.status.idle": "2024-03-02T17:27:45.553018Z",
     "shell.execute_reply": "2024-03-02T17:27:45.552513Z",
     "shell.execute_reply.started": "2024-03-02T17:27:45.516366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 6727.29 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 3803.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def flatten_list_of_dict(batch):\n",
    "    return {\"page\": [ex_string for ex_list in batch[\"text\"] for ex_string in ex_list]}\n",
    "\n",
    "dataset = dataset.map(flatten_list_of_dict, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e2b7af-030e-41b4-bc50-8920248106e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:46.091520Z",
     "iopub.status.busy": "2024-03-02T17:27:46.091048Z",
     "iopub.status.idle": "2024-03-02T17:27:46.165923Z",
     "shell.execute_reply": "2024-03-02T17:27:46.165380Z",
     "shell.execute_reply.started": "2024-03-02T17:27:46.091468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1436/1436 [00:00<00:00, 34529.33 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:00<00:00, 30399.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# re-joining the words separated by \"-\"\n",
    "def text_processing(example):\n",
    "    example['page'] = example['page'].replace(\"- \", \"\")\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f66bb2-4027-4053-bd13-0215cea0bbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:48.334815Z",
     "iopub.status.busy": "2024-03-02T17:27:48.334455Z",
     "iopub.status.idle": "2024-03-02T17:27:48.365142Z",
     "shell.execute_reply": "2024-03-02T17:27:48.363544Z",
     "shell.execute_reply.started": "2024-03-02T17:27:48.334783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': ['Diário da República, 1.ª série — N.º 12 — 17 de janeiro de 2012 Artigo 8.º Responsabilidade pelo projeto e pela execução A responsabilidade técnica pela demonstração do cumprimento das exigências decorrentes do presente diploma apenas pode ser assumida por técnicos que cumpram o disposto no artigo 97.º do Decreto Legislativo Regional n.º 16/2009/A, de 13 de outubro, considerandose uma qualificação específica para o efeito a definir nos termos do n.º 2 daquele artigo',\n",
       "  'Artigo 9.º Obrigação de conformidade Apenas podem ser instalados dispositivos e seus componentes de segurança em relação aos quais tenha sido emitida uma declaração CE de conformidade e que ostentem aposta, nos termos legais e regulamentares aplicáveis, a respetiva marcação CE de conformidade',\n",
       "  'Artigo 10.º Competências das câmaras municipais 1 — Sem prejuízo das atribuições e competências legalmente atribuídas ou delegadas a outras entidades, as câmaras municipais, no âmbito do presente diploma, são competentes para: a) Efetuar o licenciamento das instalações, quando as mesmas, nos termos legais e regulamentares, estejam integradas em obra sujeita a licenciamento municipal no âmbito do regime jurídico da urbanização e edificação; b) Verificar a conformidade da DCR e fiscalizar a construção e instalação dos dispositivos; c) Efetuar fiscalizações ordinárias e extraordinárias, sempre que o considerem necessário, ou a pedido fundamentado dos interessados; d) Verificar a existência e conformidade do CE antes da emissão das autorizações de utilização para as quais sejam competentes; e) Fiscalizar o cumprimento das obrigações de manutenção e inspeção e as condições de utilização dos dispositivos; f) Realizar inquéritos a acidentes decorrentes da utilização ou das operações de manutenção das instalações e dos dispositivos',\n",
       "  '2 — É cobrada uma taxa, a fixar pela autarquia nos termos legais aplicáveis às taxas municipais, pela realização das atividades referidas nas alíneas a), c) e f) do número anterior, quando realizadas a pedido dos interessados',\n",
       "  '3 — Para o exercício das competências a que se refere o n.º 1 do presente artigo, as câmaras municipais podem recorrer às entidades inspetoras previstas no artigo 20.º e seguintes do presente diploma',\n",
       "  '4 — As câmaras municipais podem definir, mediante a celebração de contrato ou por via de regulamento municipal, as condições de prestação de serviços pelas entidades mencionadas no número anterior',\n",
       "  'Artigo 11.º Registo e disponibilização de informação 1 — O SCE mantém em página adequada do seu portal na Internet, de acesso restrito aos peritos e entidades certificadas no âmbito daquele sistema, um registo atualizado',\n",
       "  '232 D que não esteja sujeita a legislação especial, e os deveres que lhes são aplicáveis, e seus regulamentos, e com o presente diploma; d) O cálculo dos valores das necessidades nominais de energia do dispositivo e estimativa do seu consumo mensal face às condições de utilização previstas; e) Declaração de Conformidade Regulamentar (DCR) subscrita por perito qualificado no âmbito do SCE',\n",
       "  '3 — A entidade distribuidora de energia elétrica só pode celebrar contrato de fornecimento de energia elétrica às instalações que possuam dispositivos aos quais se aplica o presente diploma após lhe ter sido apresentada cópia da respetiva DCR',\n",
       "  '4 — O requerimento de licença ou autorização de utilização deve incluir o certificado de vistoria da instalação emitido por perito qualificado no âmbito do SCE']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d08da-201f-47a4-9e80-d99d8fe4ddae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DETOUR!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2f8d6e-733c-4051-9c61-0c567354faa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:49.166322Z",
     "iopub.status.busy": "2024-03-02T17:27:49.165924Z",
     "iopub.status.idle": "2024-03-02T17:27:49.194376Z",
     "shell.execute_reply": "2024-03-02T17:27:49.193229Z",
     "shell.execute_reply.started": "2024-03-02T17:27:49.166284Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5902f014-698e-41bc-86e6-afb0f094a498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T20:18:06.817723Z",
     "iopub.status.busy": "2024-02-19T20:18:06.817333Z",
     "iopub.status.idle": "2024-02-19T20:19:58.062024Z",
     "shell.execute_reply": "2024-02-19T20:19:58.061454Z",
     "shell.execute_reply.started": "2024-02-19T20:18:06.817698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./env/lib/python3.10/site-packages (from torch==2.0.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.10/site-packages (from torch==2.0.1) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (65.5.0)\n",
      "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1)\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=3249284b82d28d23e7cecf4a8bc3f24e97db258f30bb14af7619eeb4961eaba5\n",
      "  Stored in directory: /home/ana/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, wheel, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed cmake-3.28.3 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0 wheel-0.42.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: FIX TORCH VERSION  -> this one was not the one original!!\n",
    "!pip3 install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98330274-66a1-45a1-a5d9-bd5df4f6584c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DialogGPT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71b8c4-f5fd-4e3f-aee1-32e84a432e4d",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55af3c70-e86f-4865-bc9b-49830c1d29d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:18.091107Z",
     "iopub.status.busy": "2024-02-19T22:35:18.090882Z",
     "iopub.status.idle": "2024-02-19T22:35:20.571854Z",
     "shell.execute_reply": "2024-02-19T22:35:20.571405Z",
     "shell.execute_reply.started": "2024-02-19T22:35:18.091091Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('microsoft/DialoGPT-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b777bdb8-7a90-4ac0-b985-6ce39d818ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:20.572783Z",
     "iopub.status.busy": "2024-02-19T22:35:20.572566Z",
     "iopub.status.idle": "2024-02-19T22:35:22.627456Z",
     "shell.execute_reply": "2024-02-19T22:35:22.627055Z",
     "shell.execute_reply.started": "2024-02-19T22:35:20.572769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████| 1477/1477 [00:00<00:00, 2606.05 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 2216.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the dataset\n",
    "# https://huggingface.co/docs/transformers/en/pad_truncation\n",
    "def encode(examples):\n",
    "    encoded = tokenizer(examples['page'],\n",
    "                        truncation=True, \n",
    "                        padding='max_length',\n",
    "                        max_length=128\n",
    "                       )\n",
    "    encoded['labels'] = encoded['input_ids'][:]\n",
    "\n",
    "    return encoded\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4190f6-3656-4781-a05f-a0fc5d401ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T22:46:09.102739Z",
     "iopub.status.busy": "2024-02-05T22:46:09.102005Z",
     "iopub.status.idle": "2024-02-05T22:46:09.143052Z",
     "shell.execute_reply": "2024-02-05T22:46:09.141608Z",
     "shell.execute_reply.started": "2024-02-05T22:46:09.102656Z"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa65fdb-9802-4f32-a248-8c1d82bf8720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:25.302964Z",
     "iopub.status.busy": "2024-02-19T22:35:25.302607Z",
     "iopub.status.idle": "2024-02-19T22:35:26.100367Z",
     "shell.execute_reply": "2024-02-19T22:35:26.099914Z",
     "shell.execute_reply.started": "2024-02-19T22:35:25.302948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=tempfile.mkdtemp(),   # output directory\n",
    "    num_train_epochs=25,             # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,                # directory for storing logs\n",
    "    fp16=True                        # use floating point 16 bit precision for training\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de615ecb-e60c-4388-808e-a672b0305fea",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b036b987-e794-41d1-b7ed-2cdb1a69a18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:26.937816Z",
     "iopub.status.busy": "2024-02-19T22:35:26.937242Z",
     "iopub.status.idle": "2024-02-19T22:35:29.134362Z",
     "shell.execute_reply": "2024-02-19T22:35:29.133874Z",
     "shell.execute_reply.started": "2024-02-19T22:35:26.937793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate before fine-tuning\n",
    "pre_eval_results = trainer.evaluate(encoded_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77244853-6b0e-4ef9-9df9-b1b54f33bc39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:29.135338Z",
     "iopub.status.busy": "2024-02-19T22:35:29.135205Z",
     "iopub.status.idle": "2024-02-19T22:35:29.278398Z",
     "shell.execute_reply": "2024-02-19T22:35:29.277796Z",
     "shell.execute_reply.started": "2024-02-19T22:35:29.135325Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46356329-c14a-474e-b854-3af16cf54049",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e73fc018-0493-4089-bc87-93fe375a2cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:35:29.782025Z",
     "iopub.status.busy": "2024-02-19T22:35:29.781393Z",
     "iopub.status.idle": "2024-02-19T22:46:54.521789Z",
     "shell.execute_reply": "2024-02-19T22:46:54.521403Z",
     "shell.execute_reply.started": "2024-02-19T22:35:29.782001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4625' max='4625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4625/4625 11:24, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.835400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4625, training_loss=1.423659377639358, metrics={'train_runtime': 684.5815, 'train_samples_per_second': 53.938, 'train_steps_per_second': 6.756, 'total_flos': 2412052070400000.0, 'train_loss': 1.423659377639358, 'epoch': 25.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e04eb3-2e2d-486e-8910-4ec87c3eaf7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:56:01.859308Z",
     "iopub.status.busy": "2024-02-19T22:56:01.859059Z",
     "iopub.status.idle": "2024-02-19T22:56:03.807036Z",
     "shell.execute_reply": "2024-02-19T22:56:03.806641Z",
     "shell.execute_reply.started": "2024-02-19T22:56:01.859292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results before fine-tuning : 9.061310768127441\n",
      "Evaluation Results after fine-tuning  : 1.5355618000030518\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))\n",
    "# Evaluate after fine-tuning\n",
    "post_eval_results = trainer.evaluate(encoded_dataset['test'])\n",
    "\n",
    "# Print the evaluation losses before and after fine-tuning\n",
    "print('Evaluation Results before fine-tuning :', pre_eval_results['eval_loss'])\n",
    "print('Evaluation Results after fine-tuning  :', post_eval_results['eval_loss'])\n",
    "\n",
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "post_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))\n",
    "\n",
    "# Zip the pre and post tuning predictions\n",
    "predictions = zip(pre_val_predictions.predictions, post_val_predictions.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aceb47-b8c8-4437-8f51-2cea2d490e01",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4579fed6-e435-42c3-8eb2-ddd436a0852b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T22:56:34.854727Z",
     "iopub.status.busy": "2024-02-19T22:56:34.854529Z",
     "iopub.status.idle": "2024-02-19T22:56:34.925117Z",
     "shell.execute_reply": "2024-02-19T22:56:34.924596Z",
     "shell.execute_reply.started": "2024-02-19T22:56:34.854713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth 0 \n",
      "DAREPÚBLICA—ISÉRIE-A 8161 d) Empresa de manutenção de ascensores (EMA) a entidadequeefectuaeéresponsávelpelamanu- tenção das instalações, cujo estatuto constitui o anexo I a este diploma e que dele faz parte integrante; e) Entidade inspectora (EI) a empresa habilitada a efectuar inspecções a instalações, bem como a realizar inquéritos, peritagens, relatórios e pareceres, cujo estatuto constitui o anexo IV a este diploma e que dele faz parte integrante\n",
      "\n",
      "Pre-prediction \n",
      " —EPÚBLICA—ISÉRIE-A 8165 8) Apresresa de manutenção de ascensores,M) 1)idade gest souncuar)cnabilvel posutenêsehaã,as Ealações o porjo ascatuto dui- proprietexo IV aoja, que se faz parte integrante; e) Emidade queore deEMAI), eopresa dejailitar;ofetuar;petção�es peroalações, om\n",
      "\n",
      "Post-prediction \n",
      " —EPÚBLICA—ISÉRIE-A 8165 8) Apresresa de manutenção de ascensores,M) 1)idade gest souncuar)cnabilvel posutenêsehaã,as Ealações o porjo ascatuto dui- proprietexo IV aoja, que se faz parte integrante; e) Emidade queore deEMAI), eopresa dejailitar;ofetuar;petção�es peroalações, om\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 1 \n",
      "CAPÍTULOII Manutenção Artigo3.o Obrigaçãodemanutenção 1—Asinstalaçõesabrangidaspelopresentediploma ficam,obrigatoriamente,sujeitasamanutençãoregular, a qual é assegurada por uma EMA, que assumirá a responsabilidade, criminal e civil, pelos acidentes cau- sados pela deficiente manutenção das instalações ou peloincumprimentodasnormasaplicáveis\n",
      "\n",
      "Pre-prediction \n",
      " —TULO II Disutenção Artigo15.o Competbrigaç�odeasutenção 1—Asinsalaçõesderasidoseloprediploma,icaam obnomrigatoriamente,djeitas-utençãocom-ist,secompan de assegurada por uma EMA, a deleirá a responsabilidade do pel o criminal, pelo acidentes causumpç ros daela Ee manutenção deas instalações abu,as instarcerrimentoesemaninst\n",
      "\n",
      "Post-prediction \n",
      " —TULO II Disutenção Artigo15.o Competbrigaç�odeasutenção 1—Asinsalaçõesderasidoseloprediploma,icaam obnomrigatoriamente,djeitas-utençãocom-ist,secompan de assegurada por uma EMA, a deleirá a responsabilidade do pel o criminal, pelo acidentes causumpç ros daela Ee manutenção deas instalações abu,as instarcerrimentoesemaninst\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 2 \n",
      "2—O proprietário da instalação é responsável soli- dariamente, nos termos do número anterior, sem pre- juízo da transferência da responsabilidade para uma entidadeseguradora\n",
      "\n",
      "Pre-prediction \n",
      " —A prodário da instalação é responsável peli- daráente, por termos da número anterior, os preju vízo da instência da atabilidade civil ama Eidade insuranantora\n",
      "\n",
      "Post-prediction \n",
      " —A prodário da instalação é responsável peli- daráente, por termos da número anterior, os preju vízo da instência da atabilidade civil ama Eidade insuranantora\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 3 \n",
      "3—Paraefeitosderesponsabilidadecriminaloucivil, presume-se que os contratos de manutenção a que res- peita o artigo seguinte integram sempre os requisitos mínimos estabelecidos para o respectivo tipo, estabe- lecidosnoartigo5.o 4—A EMA tem o dever de informar por escrito o proprietário das reparações que se torne necessário efectuar\n",
      "\n",
      "Pre-prediction \n",
      " —Osara eitosnveabilidadecivil,a,se - pl que os protectatos de manutenção de que sepe pita a contrigo seguinte:ram sempre os requisitos deínimos estabelecidos no o artivo contro de aele- cceridos noartigo12.o —O EMA de o tipver de informar o entrito, proprietário,as instarações, sejamne aário,fetuar\n",
      "\n",
      "Post-prediction \n",
      " —Osara eitosnveabilidadecivil,a,se - pl que os protectatos de manutenção de que sepe pita a contrigo seguinte:ram sempre os requisitos deínimos estabelecidos no o artivo contro de aele- cceridos noartigo12.o —O EMA de o tipver de informar o entrito, proprietário,as instarações, sejamne aário,fetuar\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 4 \n",
      "5—Caso sejadetectadasituaçãodegraveriscopara o funcionamento da instalação, a EMA deve proceder àsuaimediataimobilização,dandodissoconhecimento, por escrito, ao proprietário e à câmara municipal res- pectiva,noprazodequarentaeoitohoras\n",
      "\n",
      "Pre-prediction \n",
      " —Oso disjaasáu comadosopãodinsuniáosréçuionamento da malação, o EMA deve serer à suaaplomaservizaçãoseeverereecocstrucimentocdobrito, noo proprietário e a DGâmara municipal competentpe ponsados aomeresentodeelementalidificquividosp-\n",
      "\n",
      "Post-prediction \n",
      " —Oso disjaasáu comadosopãodinsuniáosréçuionamento da malação, o EMA deve serer à suaaplomaservizaçãoseeverereecocstrucimentocdobrito, noo proprietário e a DGâmara municipal competentpe ponsados aomeresentodeelementalidificquividosp-\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 5 \n",
      "Artigo4.o Contratodemanutenção 1—O proprietário de uma instalação em serviço é obrigado a celebrar um contrato de manutenção com umaEMA\n",
      "\n",
      "Pre-prediction \n",
      "igo 5.o Distrodemanutenção 1—Ocontário d uma instalação, serviço d obrigat a instar um contrato de manutenção a uma E\n",
      "\n",
      "Post-prediction \n",
      "igo 5.o Distrodemanutenção 1—Ocontário d uma instalação, serviço d obrigat a instar um contrato de manutenção a uma E\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 6 \n",
      "2—O contrato de manutenção, no caso de insta- lações novas, deverá iniciar a sua vigência no momento da entrada em serviço da instalação, sem prejuízo do dispostononúmeroseguinte\n",
      "\n",
      "Pre-prediction \n",
      " —A prodato de manutenção sim a caso de manala- lações,vas, beverá sericiar a sua vigência, momento da entrada em serviço da instalação, oprejuízo da dispostoibrioolevinte:\n",
      "\n",
      "Post-prediction \n",
      " —A prodato de manutenção sim a caso de manala- lações,vas, beverá sericiar a sua vigência, momento da entrada em serviço da instalação, oprejuízo da dispostoibrioolevinte:\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 7 \n",
      "3—Durante o primeiro ano de funcionamento da instalação, a entidade instaladora fica obrigada, direc- tamente ou através de uma EMA, a assegurar a sua manutenção,salvoseoproprietárioadesobrigar,através da celebração de um contrato de manutenção com umaEMA\n",
      "\n",
      "Pre-prediction \n",
      " —Osante asuiro apo a instionamento da instalação, o entidade gestaladora fica obrigada, peltç mentamente ou retravés de umma EMI, a entsegurar que sua imutenção, avoigormbresentetárioosminist-rigatorseravésd instração de u anato de manutenção, uma E,\n",
      "\n",
      "Post-prediction \n",
      " —Osante asuiro apo a instionamento da instalação, o entidade gestaladora fica obrigada, peltç mentamente ou retravés de umma EMI, a entsegurar que sua imutenção, avoigormbresentetárioosminist-rigatorseravésd instração de u anato de manutenção, uma E,\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 8 \n",
      "Artigo5.o Tiposdecontratodemanutenção 1—O contrato de manutenção, a estabelecer entre o proprietário de uma instalação e uma EMA, pode corresponderaumdosseguintestipos: a) Contrato de manutenção simples, destinado a manterainstalaçãoemboascondiçõesdesegu-\n",
      "\n",
      "Pre-prediction \n",
      "igo 5.o Distosasontrolodemanutenção 1—Sem prodato de manutenção de a Eelecer entre o proprietário e uma Ealação e uma EMA, aode soliciter aainsseguintesipuld a) Erato de manutenção,ples, oinado a manter adaicção,penquesensição�es;egí l\n",
      "\n",
      "Post-prediction \n",
      "igo 5.o Distosasontrolodemanutenção 1—Sem prodato de manutenção de a Eelecer entre o proprietário e uma Ealação e uma EMA, aode soliciter aainsseguintesipuld a) Erato de manutenção,ples, oinado a manter adaicção,penquesensição�es;egí l\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth 9 \n",
      "N.o300—28deDezembrode2002 DIÁRIOD Porseuturno,opresentediplomavisa,também,trans- ferir para as câmaras municipais a competência para o licenciamento e fiscalização destas instalações, até ao momentoatribuídaàsdirecçõesregionaisdeeconomia, em obediência à alínea a) do n.o 2 do artigo 17.o da Lei n.o 159/99, de 14 de Setembro, que estabelece o quadro de transferência de atribuições e competências paraasautarquiaslocais\n",
      "\n",
      "Pre-prediction \n",
      " —o300—28deDezembrode2002 DIÁRIOD ArtORiroodaDdresentediplomaaealiopseravém rsemiss missid o o pâmaras municipais,oência da a trenciamento da àização doin,alações, arav sero municipaloodouíd,sdaccção�esparais,veian esrig-ncia desínea a) do n.o 1 do artigo 4.º; Const n.o 433/\n",
      "\n",
      "Post-prediction \n",
      " —o300—28deDezembrode2002 DIÁRIOD ArtORiroodaDdresentediplomaaealiopseravém rsemiss missid o o pâmaras municipais,oência da a trenciamento da àização doin,alações, arav sero municipaloodouíd,sdaccção�esparais,veian esrig-ncia desínea a) do n.o 1 do artigo 4.º; Const n.o 433/\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (pre, post) in enumerate(predictions):\n",
    "    pre_pred = tokenizer.decode(np.argmax(pre, axis=-1), skip_special_tokens=True)\n",
    "    post_pred = tokenizer.decode(np.argmax(post, axis=-1), skip_special_tokens=True)\n",
    "    ground_truth = encoded_dataset['test'][idx][\"page\"]\n",
    "    \n",
    "    print(f'Ground truth {idx} \\n' + ground_truth + '\\n')\n",
    "    print('Pre-prediction \\n' + \"\".join(pre_pred) + '\\n')\n",
    "    print('Post-prediction \\n'+ \"\".join(post_pred) + '\\n')\n",
    "    print('----------------------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d8fa6-f3c5-46c6-8ab7-d970845a61f8",
   "metadata": {},
   "source": [
    "# GPT2 IN PORTUGUES\n",
    "pierreguillou/gpt2-small-portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fb6ec5-081b-4951-82c9-a4413c62c9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:10:53.914491Z",
     "iopub.status.busy": "2024-03-02T17:10:53.914272Z",
     "iopub.status.idle": "2024-03-02T17:10:53.943744Z",
     "shell.execute_reply": "2024-03-02T17:10:53.942609Z",
     "shell.execute_reply.started": "2024-03-02T17:10:53.914473Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/pierreguillou/gpt2-small-portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e5d772-21d7-4a8c-a6a8-72f722a7300f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:53.436089Z",
     "iopub.status.busy": "2024-03-02T17:27:53.434898Z",
     "iopub.status.idle": "2024-03-02T17:27:57.107584Z",
     "shell.execute_reply": "2024-03-02T17:27:57.106927Z",
     "shell.execute_reply.started": "2024-03-02T17:27:53.436032Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterdays/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1581: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/home/peterdays/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
    "\n",
    "# Get sequence length max of 1024\n",
    "tokenizer.model_max_length=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab2df8-50c0-44a7-a7e0-ff73587ee3dd",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3878a5d-20a9-4efb-9065-1b6db814b78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:57.108592Z",
     "iopub.status.busy": "2024-03-02T17:27:57.108369Z",
     "iopub.status.idle": "2024-03-02T17:27:58.549799Z",
     "shell.execute_reply": "2024-03-02T17:27:58.549078Z",
     "shell.execute_reply.started": "2024-03-02T17:27:57.108576Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('pierreguillou/gpt2-small-portuguese')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('pierreguillou/gpt2-small-portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a5d018-7c7b-4170-80a8-8b9fc88d5c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:27:58.550520Z",
     "iopub.status.busy": "2024-03-02T17:27:58.550371Z",
     "iopub.status.idle": "2024-03-02T17:28:01.587757Z",
     "shell.execute_reply": "2024-03-02T17:28:01.587047Z",
     "shell.execute_reply.started": "2024-03-02T17:27:58.550506Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1436/1436 [00:01<00:00, 1350.17 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:00<00:00, 1243.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the dataset\n",
    "# https://huggingface.co/docs/transformers/en/pad_truncation\n",
    "def encode(examples):\n",
    "    encoded = tokenizer(examples['page'],\n",
    "                        truncation=True,\n",
    "                        padding='max_length',\n",
    "                        max_length=1024\n",
    "                       )\n",
    "    encoded['labels'] = encoded['input_ids'][:]\n",
    "\n",
    "    return encoded\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce47ca9-fc19-47e4-b5c6-b0ba4434bf4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T22:46:09.102739Z",
     "iopub.status.busy": "2024-02-05T22:46:09.102005Z",
     "iopub.status.idle": "2024-02-05T22:46:09.143052Z",
     "shell.execute_reply": "2024-02-05T22:46:09.141608Z",
     "shell.execute_reply.started": "2024-02-05T22:46:09.102656Z"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5701cff-502c-4f7a-8b62-c4f6e50d10be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:28:01.589065Z",
     "iopub.status.busy": "2024-03-02T17:28:01.588731Z",
     "iopub.status.idle": "2024-03-02T17:28:01.834381Z",
     "shell.execute_reply": "2024-03-02T17:28:01.833709Z",
     "shell.execute_reply.started": "2024-03-02T17:28:01.589046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=tempfile.mkdtemp(),   # output directory\n",
    "    num_train_epochs=5,             # total number of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    per_device_eval_batch_size=1,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,                # directory for storing logs\n",
    "    fp16=True,                       # use floating point 16 bit precision for training\n",
    "    # eval_accumulation_steps=250  # accumulate the tensors to cpu after 1k steps\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a83c7-68e0-4c1f-a87a-069d1984ba0f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475c96de-a395-4374-b9cb-0461de41f29b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:28:01.835156Z",
     "iopub.status.busy": "2024-03-02T17:28:01.835014Z",
     "iopub.status.idle": "2024-03-02T17:28:29.488932Z",
     "shell.execute_reply": "2024-03-02T17:28:29.487994Z",
     "shell.execute_reply.started": "2024-03-02T17:28:01.835141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate before fine-tuning\n",
    "pre_eval_results = trainer.evaluate(encoded_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49120df5-53e2-486d-8888-f4abb706a45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:28:29.489637Z",
     "iopub.status.busy": "2024-03-02T17:28:29.489456Z",
     "iopub.status.idle": "2024-03-02T17:28:31.453117Z",
     "shell.execute_reply": "2024-03-02T17:28:31.452535Z",
     "shell.execute_reply.started": "2024-03-02T17:28:29.489618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "pre_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61aefb-33e7-4ad9-9ff9-9966a9ce9a17",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9630696a-6adc-45f5-8e5c-131a7fccf1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:28:31.454952Z",
     "iopub.status.busy": "2024-03-02T17:28:31.454573Z",
     "iopub.status.idle": "2024-03-02T17:56:52.299963Z",
     "shell.execute_reply": "2024-03-02T17:56:52.299262Z",
     "shell.execute_reply.started": "2024-03-02T17:28:31.454928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7180' max='7180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7180/7180 28:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.089600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7180, training_loss=0.2449612054320099, metrics={'train_runtime': 1700.71, 'train_samples_per_second': 4.222, 'train_steps_per_second': 4.222, 'total_flos': 3752153579520000.0, 'train_loss': 0.2449612054320099, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be03f7b4-1ff2-4442-9539-ff34428520d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:27.149107Z",
     "iopub.status.busy": "2024-03-02T17:58:27.148297Z",
     "iopub.status.idle": "2024-03-02T17:58:28.042948Z",
     "shell.execute_reply": "2024-03-02T17:58:28.041923Z",
     "shell.execute_reply.started": "2024-03-02T17:58:27.149059Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"gpt2_portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eea311c-3341-4678-ab00-8205868df335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:35.228766Z",
     "iopub.status.busy": "2024-03-02T18:00:35.228250Z",
     "iopub.status.idle": "2024-03-02T18:00:35.291113Z",
     "shell.execute_reply": "2024-03-02T18:00:35.289915Z",
     "shell.execute_reply.started": "2024-03-02T18:00:35.228717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 14.016154289245605,\n",
       " 'eval_runtime': 27.6294,\n",
       " 'eval_samples_per_second': 15.056,\n",
       " 'eval_steps_per_second': 15.056}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e04a1042-2651-4a69-80bd-0dd8fcc1613c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:19.374263Z",
     "iopub.status.busy": "2024-03-02T18:00:19.374057Z",
     "iopub.status.idle": "2024-03-02T18:00:19.426001Z",
     "shell.execute_reply": "2024-03-02T18:00:19.424941Z",
     "shell.execute_reply.started": "2024-03-02T18:00:19.374246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14035974442958832,\n",
       " 'eval_runtime': 27.5374,\n",
       " 'eval_samples_per_second': 15.107,\n",
       " 'eval_steps_per_second': 15.107,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de91c8b-8879-4ae6-b4be-fffc29e85975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:52.062091Z",
     "iopub.status.busy": "2024-03-02T18:00:52.061875Z",
     "iopub.status.idle": "2024-03-02T18:00:52.088622Z",
     "shell.execute_reply": "2024-03-02T18:00:52.087449Z",
     "shell.execute_reply.started": "2024-03-02T18:00:52.062073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.trainer_utils.PredictionOutput"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pre_val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e96b2c8-f881-46c4-91ae-4ca4517be7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:45.910539Z",
     "iopub.status.busy": "2024-03-02T17:58:45.910203Z",
     "iopub.status.idle": "2024-03-02T17:59:14.915290Z",
     "shell.execute_reply": "2024-03-02T17:59:14.914220Z",
     "shell.execute_reply.started": "2024-03-02T17:58:45.910508Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='424' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [416/416 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results before fine-tuning : 14.016154289245605\n",
      "Evaluation Results after fine-tuning  : 0.14035974442958832\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacty of 5.79 GiB of which 1.72 GiB is free. Including non-PyTorch memory, this process has 4.06 GiB memory in use. Of the allocated memory 3.16 GiB is allocated by PyTorch, and 807.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation Results after fine-tuning  :\u001b[39m\u001b[38;5;124m'\u001b[39m, post_eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Get predictions for validation set before fine tuning for 10 samples\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m post_val_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Zip the pre and post tuning predictions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(pre_val_predictions\u001b[38;5;241m.\u001b[39mpredictions, post_val_predictions\u001b[38;5;241m.\u001b[39mpredictions)\n",
      "File \u001b[0;32m~/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:3171\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3168\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3170\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3171\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3174\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer.py:3310\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3308\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[1;32m   3309\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[0;32m-> 3310\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[0;32m~/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:123\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    126\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    127\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/personal/Volupal/ElevaQ/env/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:82\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     79\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     85\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacty of 5.79 GiB of which 1.72 GiB is free. Including non-PyTorch memory, this process has 4.06 GiB memory in use. Of the allocated memory 3.16 GiB is allocated by PyTorch, and 807.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Evaluate after fine-tuning\n",
    "post_eval_results = trainer.evaluate(encoded_dataset['test'])\n",
    "\n",
    "# Print the evaluation losses before and after fine-tuning\n",
    "print('Evaluation Results before fine-tuning :', pre_eval_results['eval_loss'])\n",
    "print('Evaluation Results after fine-tuning  :', post_eval_results['eval_loss'])\n",
    "\n",
    "# Get predictions for validation set before fine tuning for 10 samples\n",
    "post_val_predictions = trainer.predict(encoded_dataset['test'].select(range(10)))\n",
    "\n",
    "# Zip the pre and post tuning predictions\n",
    "predictions = zip(pre_val_predictions.predictions, post_val_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044a18b-e094-4a5d-89b9-875870c21933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b984c0ea-a0e2-47ad-9344-c66534713d71",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3721cb-c26c-46af-a085-27714c9b19fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T16:49:29.804346Z",
     "iopub.status.busy": "2024-03-02T16:49:29.803851Z",
     "iopub.status.idle": "2024-03-02T16:49:29.837675Z",
     "shell.execute_reply": "2024-03-02T16:49:29.836755Z",
     "shell.execute_reply.started": "2024-03-02T16:49:29.804301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth 0 \n",
      "Diário da República, 1.ª série — N.º 120 — 24 de Junho de 2008 Por ocasião dessas visitas, o organismo notificado poderá, se necessário, efectuar ou mandar efectuar ensaios destinados a verificar o bom funcionamento do sistema de qualidade. Fornecerá ao fabricante um relatório de visita e, caso tenha sido feito um ensaio, um relatório de ensaio\n",
      "\n",
      "Pre-prediction \n",
      " da República, 1.ª série — N.º 112 — 24 de Junho de 2008 b motivos da emissões, as organismo notificado deve efetuar nos necessário, efetuar, mandar efectuar, para a verificar a bom funcionamento do asc da qualidade, Taisornecerá, organismo, relatório da avaliação e um se lhe sido emitido um ensaio, um relatório da ensaio\n",
      "\n",
      "Post-prediction \n",
      " da República, 1.ª série — N.º 112 — 24 de Junho de 2008 b motivos da emissões, as organismo notificado deve efetuar nos necessário, efetuar, mandar efectuar, para a verificar a bom funcionamento do asc da qualidade, Taisornecerá, organismo, relatório da avaliação e um se lhe sido emitido um ensaio, um relatório da ensaio\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (pre, post) in enumerate(predictions):\n",
    "    pre_pred = tokenizer.decode(np.argmax(pre, axis=-1), skip_special_tokens=True)\n",
    "    post_pred = tokenizer.decode(np.argmax(post, axis=-1), skip_special_tokens=True)\n",
    "    ground_truth = encoded_dataset['test'][idx][\"page\"]\n",
    "\n",
    "    print(f'Ground truth {idx} \\n' + ground_truth + '\\n')\n",
    "    print('Pre-prediction \\n' + \"\".join(pre_pred) + '\\n')\n",
    "    print('Post-prediction \\n'+ \"\".join(post_pred) + '\\n')\n",
    "    print('----------------------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4a247-ebcc-40a1-b843-37d492df9652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
