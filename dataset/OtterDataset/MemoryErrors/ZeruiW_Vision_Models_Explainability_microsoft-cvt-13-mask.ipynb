{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [22:00<00:00, 13.20s/it]\n",
      " 79%|███████▉  | 79/100 [17:11<04:38, 13.25s/it]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: fdadcfe1-d4f5-4870-b674-a28a64823650)')' thrown while requesting HEAD https://huggingface.co/microsoft/cvt-13/resolve/main/config.json\n",
      " 89%|████████▉ | 89/100 [19:39<02:29, 13.55s/it]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b8d4d612-17ba-438a-9321-a082b5a14a31)')' thrown while requesting HEAD https://huggingface.co/microsoft/cvt-13/resolve/main/config.json\n",
      "100%|██████████| 100/100 [22:17<00:00, 13.38s/it]\n",
      "100%|██████████| 100/100 [23:26<00:00, 14.07s/it]\n",
      "100%|██████████| 100/100 [22:23<00:00, 13.44s/it]\n",
      "100%|██████████| 100/100 [22:50<00:00, 13.70s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def load_images_from_directory(root_path: str):\n",
    "    \"\"\"\n",
    "    Load images from a directory with subfolders named after ImageNet labels.\n",
    "    Return a list of (image, label, filename) triples.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    # Iterate over each subfolder\n",
    "    for label in os.listdir(root_path):\n",
    "        label_path = os.path.join(root_path, label)\n",
    "        \n",
    "        # Check if it's indeed a folder\n",
    "        if os.path.isdir(label_path):\n",
    "            \n",
    "            # Iterate over each image in the subfolder\n",
    "            for image_file in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image_file)\n",
    "                \n",
    "                # Check if it's an image file\n",
    "                if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img = Image.open(image_path)\n",
    "                    dataset.append((img, label, image_file))  # Add image filename here\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# current_dir = \"/home/z/Music/code/CAIN\"\n",
    "# detail_dir = \"/imagenet/val_images10k\"\n",
    "\n",
    "# dataset_path = f\"{current_dir}{detail_dir}\"\n",
    "\n",
    "\n",
    "\n",
    "# dataset = load_images_from_directory(dataset_path)\n",
    "\n",
    "current_dir = \"/home/z/Music/code/CAIN\"\n",
    "dataset_dirs = [\n",
    "    \"/imagenet/val_images10k\",\n",
    "    # \"/imagenet/val_images10k_attack/gaussian_noise/1\",\n",
    "    # \"/imagenet/val_images10k_attack/gaussian_noise/2\",\n",
    "    # \"/imagenet/val_images10k_attack/gaussian_noise/3\",\n",
    "    # \"/imagenet/val_images10k_attack/defocus_blur/1\",\n",
    "    # \"/imagenet/val_images10k_attack/defocus_blur/2\",\n",
    "    # \"/imagenet/val_images10k_attack/defocus_blur/3\", \n",
    "    # \"/imagenet/val_images10k_attack/pixelate/1\",\n",
    "    # \"/imagenet/val_images10k_attack/pixelate/2\",\n",
    "    # \"/imagenet/val_images10k_attack/pixelate/3\",\n",
    "]\n",
    "\n",
    "for detail_dir in dataset_dirs:\n",
    "\n",
    "    dataset_path = f\"{current_dir}{detail_dir}\"\n",
    "    dataset = load_images_from_directory(dataset_path)\n",
    "    \n",
    "    with open(f\"{current_dir}/imagenet/imagenet_class_index.json\", \"r\") as f:\n",
    "        imagenet_class_index = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    label_to_index_description = {v[0]: (k, v[1]) for k, v in imagenet_class_index.items()}\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    from codecarbon import track_emissions\n",
    "    from torchvision import transforms\n",
    "    from datasets import load_dataset\n",
    "    from pytorch_grad_cam import run_dff_on_image\n",
    "    from pytorch_grad_cam import (\n",
    "        GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "        AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "        LayerCAM, FullGrad, GradCAMElementWise\n",
    "    )\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import torch\n",
    "    from typing import List, Callable, Optional\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA!\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU!\")\n",
    "    # dataset = load_dataset(\"huggingface/cats-image\")\n",
    "    # image = dataset[\"test\"][\"image\"][0]\n",
    "    # img_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "    \"\"\" Model wrapper to return a tensor\"\"\"\n",
    "    class HuggingfaceToTensorModelWrapper(torch.nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super(HuggingfaceToTensorModelWrapper, self).__init__()\n",
    "            self.model = model\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x).logits\n",
    "\n",
    "    \"\"\" Translate the category name to the category index.\n",
    "        Some models aren't trained on Imagenet but on even larger datasets,\n",
    "        so we can't just assume that 761 will always be remote-control.\n",
    "\n",
    "    \"\"\"\n",
    "    def category_name_to_index(model, category_name):\n",
    "        name_to_index = dict((v, k) for k, v in model.config.id2label.items())\n",
    "        return name_to_index[category_name]\n",
    "        \n",
    "    \"\"\" Helper function to run GradCAM on an image and create a visualization.\n",
    "        (note to myself: this is probably useful enough to move into the package)\n",
    "        If several targets are passed in targets_for_gradcam,\n",
    "        e.g different categories,\n",
    "        a visualization for each of them will be created.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    ############################################################################################################\n",
    "\n",
    "    # Define the CAM algorithm you want to use\n",
    "    # Options: GradCAM, HiResCAM, GradCAMPlusPlus, XGradCAM, \n",
    "    # EigenGradCAM, LayerCAM, GradCAMElementWise\n",
    "    # #    GradCAM, HiResCAM, GradCAMPlusPlus, XGradCAM, LayerCAM\n",
    "    CAM_ALGORITHMS = [GradCAM, HiResCAM, GradCAMPlusPlus, XGradCAM, LayerCAM]\n",
    "\n",
    "    for CAM_ALGORITHM in CAM_ALGORITHMS:\n",
    "        cam_algorithm_name = CAM_ALGORITHM.__name__\n",
    "\n",
    "        #@track_emissions()\n",
    "        def run_grad_cam_on_image(model: torch.nn.Module,\n",
    "                                target_layer: torch.nn.Module,\n",
    "                                targets_for_gradcam: List[Callable],\n",
    "                                input_tensor: torch.nn.Module,\n",
    "                                input_image: Image,\n",
    "                                reshape_transform: Optional[Callable] = None,\n",
    "                                method: Callable = CAM_ALGORITHM):\n",
    "            with method(model=HuggingfaceToTensorModelWrapper(model),\n",
    "                        target_layers=[target_layer],\n",
    "                        reshape_transform=reshape_transform) as cam:\n",
    "\n",
    "                # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n",
    "                repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)\n",
    "\n",
    "                batch_results = cam(input_tensor=repeated_tensor,\n",
    "                                    targets=targets_for_gradcam)\n",
    "                results = []\n",
    "                grayscale_cams = []\n",
    "                for grayscale_cam in batch_results:\n",
    "                    visualization = show_cam_on_image(np.float32(input_image) / 255,\n",
    "                                                    grayscale_cam,\n",
    "                                                    use_rgb=True)\n",
    "                    # Make it weight less in the notebook:\n",
    "                    visualization = cv2.resize(visualization,\n",
    "                                            (visualization.shape[1] // 2, visualization.shape[0] // 2))\n",
    "                    results.append(visualization)\n",
    "                    grayscale_cams.append(grayscale_cam)\n",
    "                return np.hstack(results), grayscale_cams\n",
    "            \n",
    "        def print_top_categories(model, img_tensor, top_k=5):\n",
    "            logits = model(img_tensor.unsqueeze(0)).logits\n",
    "            indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]\n",
    "            for i in indices:\n",
    "                print(f\"Predicted class {i}: {model.config.id2label[i]}\")\n",
    "\n",
    "        # Generate targets_for_gradcam based on model's predictions\n",
    "        def get_top_k_targets(model, input_tensor, k=5):\n",
    "            logits = model(input_tensor.unsqueeze(0)).logits\n",
    "            top_k_indices = logits[0].argsort(descending=True)[:k].cpu().numpy()\n",
    "            return [ClassifierOutputTarget(index) for index in top_k_indices]\n",
    "        def apply_mask_to_image(image_path, mask_path, output_path):\n",
    "            # Read the original image and mask\n",
    "            original_image = cv2.imread(image_path)\n",
    "            grayscale_mask = np.load(mask_path)\n",
    "            \n",
    "            # Ensure the mask has the same dimensions as the image\n",
    "            h, w, _ = original_image.shape\n",
    "            grayscale_mask = cv2.resize(grayscale_mask, (w, h))\n",
    "            \n",
    "            # Normalize grayscale mask to [0, 1]\n",
    "            grayscale_mask = (grayscale_mask - grayscale_mask.min()) / (grayscale_mask.max() - grayscale_mask.min())\n",
    "\n",
    "            # Convert the mask to 3D\n",
    "            grayscale_mask_3d = np.repeat(grayscale_mask[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "            # Apply the mask to the original image\n",
    "            masked_image = (original_image * grayscale_mask_3d).astype(np.uint8)\n",
    "            \n",
    "            # Save the masked image\n",
    "            cv2.imwrite(output_path, masked_image)\n",
    "        import os\n",
    "        from tqdm import tqdm\n",
    "        from collections import defaultdict\n",
    "        import gc\n",
    "        ###################\n",
    "        from transformers import CvtForImageClassification\n",
    "        from functools import partial\n",
    "        import torch\n",
    "        from PIL import Image\n",
    "        import datetime\n",
    "\n",
    "        ###################\n",
    "\n",
    "        def reshape_transform_cvt_huggingface(tensor, model, width, height):\n",
    "            tensor = tensor[:, 1 :, :]\n",
    "            tensor = tensor.reshape(tensor.size(0),\n",
    "                                    height,\n",
    "                                    width,\n",
    "                                    tensor.size(-1))\n",
    "            \n",
    "            # https://github.com/huggingface/transformers/blob/a2c90a7f7b1f8a2a8217c962a04a1a65638121d5/src/transformers/models/cvt/modeling_cvt.py#L699\n",
    "            norm = model.layernorm(tensor)\n",
    "            return norm.transpose(2, 3).transpose(1, 2)\n",
    "\n",
    "        def reshape_gradcam_transform_cvt_huggingface(tensor, model, width, height):\n",
    "            tensor = tensor[:, 1 :, :]\n",
    "            tensor = tensor.reshape(tensor.size(0),\n",
    "                                    height,\n",
    "                                    width,\n",
    "                                    tensor.size(-1))\n",
    "            return tensor.transpose(2, 3).transpose(1, 2)\n",
    "\n",
    "\n",
    "        model_name = \"microsoft/cvt-13\"\n",
    "\n",
    "        # Initialize tracking variables\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "        def ensure_rgb(img):\n",
    "            if img.mode != 'RGB':\n",
    "                return img.convert('RGB')\n",
    "            return img\n",
    "\n",
    "        def is_valid_image_file(filepath):\n",
    "            \"\"\"Check if the file is a valid image file.\"\"\"\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    img.verify()  # verify that it is a valid image\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        BATCH_SIZE = 100\n",
    "        num_batches = len(dataset) // BATCH_SIZE + (1 if len(dataset) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "        save_dir = f\"{current_dir}/results/{detail_dir}/{model_name}/{cam_algorithm_name}\"\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "        for batch_num in tqdm(range(num_batches)):\n",
    "            start_idx = batch_num * BATCH_SIZE\n",
    "            end_idx = min((batch_num + 1) * BATCH_SIZE, len(dataset))\n",
    "\n",
    "            model = CvtForImageClassification.from_pretrained(\"microsoft/cvt-13\").to(device)\n",
    "\n",
    "            target_layer_dff = model.cvt.encoder.stages[-1].layers[-1]\n",
    "            target_layer_gradcam = model.cvt.encoder.stages[-1].layers[-2]\n",
    "            \n",
    "\n",
    "            transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "            for idx in range(start_idx, end_idx):\n",
    "                img, label, filename = dataset[idx]\n",
    "                try:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    img = ensure_rgb(img)\n",
    "                    resize_transform = transforms.Resize((480, 640))\n",
    "                    img = resize_transform(img)\n",
    "                    img_tensor = transform(img).to(device)\n",
    "                    #print(img_tensor.shape)\n",
    "                    reshape_transform = partial(reshape_transform_cvt_huggingface,\n",
    "                                                model=model,\n",
    "                                                width=img_tensor.shape[2]//16,\n",
    "                                                height=img_tensor.shape[1]//16)\n",
    "                    reshape_transform_gradcam = partial(reshape_gradcam_transform_cvt_huggingface,\n",
    "                                                model=model,\n",
    "                                                width=img_tensor.shape[2]//16,\n",
    "                                                height=img_tensor.shape[1]//16)\n",
    "\n",
    "                    index_description = label_to_index_description.get(label)\n",
    "                    if index_description is None:\n",
    "                        print(f\"Warning: Label '{label}' not found in the JSON file!\")\n",
    "                        continue\n",
    "\n",
    "                    index_str, description = index_description\n",
    "                    index = int(index_str)\n",
    "                    dynamic_targets_for_gradcam = [ClassifierOutputTarget(index)]\n",
    "\n",
    "                    \n",
    "\n",
    "                    # print(\"Input tensor shape:\", img_tensor.shape)\n",
    "                    # print(\"Calculated width:\", img_tensor.shape[2]//32)\n",
    "                    # print(\"Calculated height:\", img_tensor.shape[1]//32)\n",
    "\n",
    "\n",
    "                    gradcam_result, grayscale_cams = run_grad_cam_on_image(\n",
    "                        model=model,\n",
    "                        target_layer=target_layer_gradcam,\n",
    "                        targets_for_gradcam=dynamic_targets_for_gradcam,\n",
    "                        input_tensor=img_tensor,\n",
    "                        input_image=img,\n",
    "                        reshape_transform=reshape_transform_gradcam\n",
    "                    )\n",
    "\n",
    "                    logits = model(img_tensor.unsqueeze(0)).logits\n",
    "                    top_indices = logits[0].argsort(descending=True)[:5].cpu().numpy()\n",
    "                    predictions = {index: {\"score\": logits[0][index].item(), \"label\": model.config.id2label[index]} for index in top_indices}\n",
    "                    \n",
    "                    img_dir = os.path.join(save_dir, filename.rsplit('.', 1)[0])\n",
    "                    if not os.path.exists(img_dir):\n",
    "                        os.makedirs(img_dir)\n",
    "\n",
    "                    img_name = os.path.join(img_dir, \"original.jpg\")\n",
    "                    gradcam_name = os.path.join(img_dir, \"gradcam.jpg\")\n",
    "                    grayscale_name = os.path.join(img_dir, \"grayscale.jpg\")\n",
    "                    grayscale_npy_name = os.path.join(img_dir, \"grayscale.npy\")\n",
    "                    scores_name = os.path.join(img_dir, \"scores.npy\")\n",
    "                    info_name = os.path.join(img_dir, \"info.txt\")\n",
    "                    masked_image_name = os.path.join(img_dir, \"masked_image.jpg\")\n",
    "\n",
    "                    img.save(img_name)\n",
    "                    Image.fromarray(gradcam_result).save(gradcam_name)\n",
    "                    Image.fromarray((grayscale_cams[0] * 255).astype(np.uint8)).save(grayscale_name)\n",
    "                    np.save(grayscale_npy_name, grayscale_cams[0])\n",
    "\n",
    "\n",
    "                    apply_mask_to_image(img_name, grayscale_npy_name, masked_image_name)\n",
    "                    # 对masked_image.jpg进行model inference\n",
    "                    masked_image = Image.open(masked_image_name).resize((384, 384))\n",
    "                    masked_tensor = transforms.ToTensor()(masked_image).to(device)\n",
    "                    masked_logits = model(masked_tensor.unsqueeze(0)).logits\n",
    "                    top_indices_masked = masked_logits[0].argsort(descending=True)[:].cpu().numpy()\n",
    "                    predictions_masked = {index: {\"score\": masked_logits[0][index].item(), \"label\": model.config.id2label[index]} for index in top_indices_masked}\n",
    "            \n",
    "                \n",
    "                    # 保存masked_image的inference结果到info_masked.txt\n",
    "                    info_masked_name = os.path.join(img_dir, \"info_masked.txt\")\n",
    "                    with open(info_masked_name, 'w') as f:\n",
    "                        for index, data in predictions_masked.items():\n",
    "                            label = data[\"label\"]\n",
    "                            score = data[\"score\"]\n",
    "                            f.write(f\"Class {index} ({label}): {score:.2f}\\n\")\n",
    "\n",
    "                    scores = [data[\"score\"] for _, data in predictions.items()]\n",
    "                    np.save(scores_name, scores)\n",
    "\n",
    "                    with open(info_name, 'w') as f:\n",
    "                        for index, data in predictions.items():\n",
    "                            label = data[\"label\"]\n",
    "                            score = data[\"score\"]\n",
    "                            f.write(f\"Class {index} ({label}): {score:.2f}\\n\")\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"CUDA out of memory\" in str(e):\n",
    "                        print(f\"CUDA OutOfMemoryError encountered for file: {filename}\")\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "            # del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
