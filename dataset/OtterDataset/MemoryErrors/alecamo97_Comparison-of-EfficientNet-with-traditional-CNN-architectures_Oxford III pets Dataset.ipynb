{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNHkUv5-zv8F"
      },
      "source": [
        "### **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9CJx4x1pzxtc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from sklearn.metrics import f1_score\n",
        "import torchvision.datasets as datasets\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjiLMc300PrZ",
        "outputId": "1e9e08a1-7b2e-4789-8521-30729fbe3b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsU6DNdy0bAM"
      },
      "source": [
        "### **Dataset**\n",
        "\n",
        "The **Oxford-IIIT Pet** dataset consists of of 7,349 color images, each of size 224x224 pixels, divided into 38 classes with around 200 images per class.\n",
        "\n",
        "In this case, images are resized to match the required input size of some models as most of them require a 224x224 image size as they were programmed on ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Size tranformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match models' expected input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet mean values\n",
        "])\n",
        "\n",
        "# Size tranformation for InceptionV3\n",
        "transform_inception = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize to 299x299 pixels for InceptionV3\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the Flower-102 dataset\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'oxford_iiit_pet',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Convert TFDS datasets to ImageFolder-like structure for PyTorch\n",
        "def tfds_to_imagefolder(ds, transform):\n",
        "    images, labels = [], []\n",
        "    for image, label in tfds.as_numpy(ds):\n",
        "        image = transform(transforms.ToPILImage()(image))\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "    dataset = list(zip(images, labels))\n",
        "    return dataset\n",
        "\n",
        "trainset = tfds_to_imagefolder(ds_train, transform)\n",
        "testset = tfds_to_imagefolder(ds_test, transform)\n",
        "trainset_inception = tfds_to_imagefolder(ds_train, transform_inception)\n",
        "testset_inception = tfds_to_imagefolder(ds_test, transform_inception)\n",
        "\n",
        "# Create DataLoaders\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "trainloader_inception = DataLoader(trainset_inception, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader_inception = DataLoader(testset_inception, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1C7_Hb10seV"
      },
      "source": [
        "The CNN architectures that will be considered are the following:\n",
        "\n",
        "\n",
        "- **AlexNet:** Original architecture\n",
        "- **ResNet:** ResNet-50\n",
        "- **VGGNet:** VGG-16\n",
        "- **GoogleNet:** Inception v3\n",
        "- **EfficientNet:** EfficientNet-B1, EfficientNet-B3 EfficientNet-B5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrgUd4ZB1OJ5",
        "outputId": "e23b4017-f02d-4244-b67c-88507ded051b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'AlexNet': torchvision.models.alexnet(pretrained=True),\n",
        "    'ResNet50': torchvision.models.resnet50(pretrained=True),\n",
        "    'VGG16': torchvision.models.vgg16(pretrained=True),\n",
        "    'InceptionV3': torchvision.models.inception_v3(pretrained=True, aux_logits=True),\n",
        "    'EfficientNet-B1': torchvision.models.efficientnet_b1(pretrained=True),\n",
        "    'EfficientNet-B3': torchvision.models.efficientnet_b3(pretrained=True),\n",
        "    'EfficientNet-B5': torchvision.models.efficientnet_b5(pretrained=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code ensures that each model is adapted to the Flower-102 dataset by replacing the final layer of the model. For models like AlexNet, VGG, and EfficientNet, this modification is made to the classifier's last layer, while for Inception and other models, it's made to the last fully connected layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mKU72Ur81ifC"
      },
      "outputs": [],
      "source": [
        "# Modify the final layer to match CIFAR-100 classes\n",
        "for name, model in models.items():\n",
        "    if 'EfficientNet' in name:\n",
        "        num_ftrs = model.classifier[1].in_features\n",
        "        model.classifier[1] = nn.Linear(num_ftrs, 37)\n",
        "    elif 'Inception' in name:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 37)\n",
        "    elif 'AlexNet' in name or 'VGG' in name:\n",
        "        num_ftrs = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(num_ftrs, 37)\n",
        "    else:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 37)\n",
        "    models[name] = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This part initializes the loss function used for training the models. Cross-entropy loss measures how well a model's predicted probability distribution matches the actual distribution of the labels.\n",
        "\n",
        "The mathematical definition of the cross-entropy loss for a dataset is defined as:\n",
        "\n",
        "$$\n",
        "L = -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^C y_{ni} \\log(p_{ni})\n",
        "$$\n",
        "\n",
        "- \\(N\\): The number of samples.\n",
        "- \\(y_{ni}\\): The actual binary indicator for sample \\(n\\) and class \\(i\\).\n",
        "- \\(p_{ni}\\): The predicted probability for sample \\(n\\) and class \\(i\\)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the following part:\n",
        "\n",
        "The **train_model** funtion trains a given model on the training dataset for a specified number of epochs while tracking the loss and accuracy.\n",
        "\n",
        "The **evaluate_model** functio evaluates the trained model on the test dataset.\n",
        "\n",
        "The **train_model_inception** function trains the InceptionV3 model with accuracy tracking. The function outputs a tuple when *aux_logits* is *True*. The code checks if the output is a tuple and uses only the main output (ignoring auxiliary outputs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mYq_yD2h2ZCa"
      },
      "outputs": [],
      "source": [
        "# Function to train the model with accuracy tracking\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start_time = time.time()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = correct / total\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, testloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "# Define a modified train function for InceptionV3\n",
        "def train_model_inception(model, trainloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Use only the main output\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        end_time = time.time()\n",
        "        epoch_accuracy = correct / total\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}, Accuracy: {epoch_accuracy * 100:.2f}%, Time: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model's training**\n",
        "\n",
        "Now, each one of the architectures previously mentioned are trained in the same way. The models are trained in the training data for 25 epochs using the Adam optimizer with a learning rate of 0.001. The most important definition of this section are the following:\n",
        "\n",
        "- **Epoch** refers to one complete pass of the entire training dataset through the learning algorithm. \n",
        "\n",
        "- **Adam optimizer** (*optim.Adam*) is an adaptive learning rate optimization algorithm designed specifically for training deep neural networks. It combines the advantages of two other extensions of stochastic gradient descent: AdaGrad and RMSProp.\n",
        "\n",
        "- **Learning rate** controls how much to change the model in response to the estimated error each time the model weights are updated during training. \n",
        "\n",
        "After training, the model is evaluated on the test data (testloader) to calculate the accuracy and F1 score. Finally, the results including the accuracy, F1 score, and training time are printed to the console."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvVVRhzZ5jC8",
        "outputId": "ffcbb461-5a89-44b9-a99f-9b0eb1c465f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training AlexNet...\n",
            "\n",
            "Epoch 1, Loss: 3.6336, Accuracy: 0.0234, Time: 28.92 seconds\n",
            "Epoch 2, Loss: 3.6128, Accuracy: 0.0217, Time: 16.61 seconds\n",
            "Epoch 3, Loss: 3.6116, Accuracy: 0.0239, Time: 14.09 seconds\n",
            "Epoch 4, Loss: 3.6116, Accuracy: 0.0220, Time: 14.21 seconds\n",
            "Epoch 5, Loss: 3.6114, Accuracy: 0.0261, Time: 14.88 seconds\n",
            "Epoch 6, Loss: 3.6114, Accuracy: 0.0226, Time: 14.03 seconds\n",
            "Epoch 7, Loss: 3.6116, Accuracy: 0.0207, Time: 15.83 seconds\n",
            "Epoch 8, Loss: 3.6115, Accuracy: 0.0193, Time: 14.14 seconds\n",
            "Epoch 9, Loss: 3.6117, Accuracy: 0.0255, Time: 14.14 seconds\n",
            "Epoch 10, Loss: 3.6145, Accuracy: 0.0239, Time: 14.28 seconds\n",
            "Epoch 11, Loss: 3.6171, Accuracy: 0.0236, Time: 14.03 seconds\n",
            "Epoch 12, Loss: 3.6124, Accuracy: 0.0212, Time: 13.81 seconds\n",
            "Epoch 13, Loss: 3.6117, Accuracy: 0.0266, Time: 13.94 seconds\n",
            "Epoch 14, Loss: 3.6115, Accuracy: 0.0207, Time: 13.92 seconds\n",
            "Epoch 15, Loss: 3.6118, Accuracy: 0.0245, Time: 14.33 seconds\n",
            "Epoch 16, Loss: 3.6115, Accuracy: 0.0245, Time: 13.80 seconds\n",
            "Epoch 17, Loss: 3.6116, Accuracy: 0.0201, Time: 13.99 seconds\n",
            "Epoch 18, Loss: 3.6117, Accuracy: 0.0207, Time: 14.55 seconds\n",
            "Epoch 19, Loss: 3.6118, Accuracy: 0.0272, Time: 16.97 seconds\n",
            "Epoch 20, Loss: 3.6123, Accuracy: 0.0209, Time: 13.98 seconds\n",
            "Epoch 21, Loss: 3.6118, Accuracy: 0.0212, Time: 13.77 seconds\n",
            "Epoch 22, Loss: 3.6115, Accuracy: 0.0215, Time: 13.70 seconds\n",
            "Epoch 23, Loss: 3.6116, Accuracy: 0.0209, Time: 13.83 seconds\n",
            "Epoch 24, Loss: 3.6115, Accuracy: 0.0187, Time: 13.79 seconds\n",
            "Epoch 25, Loss: 3.6114, Accuracy: 0.0258, Time: 13.76 seconds\n",
            "AlexNet - Top-1 Accuracy: 2.73%\n",
            "AlexNet - F1 Score: 0.14%\n",
            "AlexNet - Training Time: 373.33 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate AlexNet\n",
        "model_name = 'AlexNet'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # lr=0.001 is considered standar for the learning rate\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25) # num_epochs=25 due to hardware limitation\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **ResNet-50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfnZpVcf2d5o",
        "outputId": "4a335ff2-d3ac-4375-8aa3-0795908dadf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training ResNet50...\n",
            "\n",
            "Epoch 1, Loss: 2.2090, Accuracy: 0.3519, Time: 292.24 seconds\n",
            "Epoch 2, Loss: 1.4822, Accuracy: 0.5380, Time: 290.04 seconds\n",
            "Epoch 3, Loss: 1.0116, Accuracy: 0.6715, Time: 286.74 seconds\n",
            "Epoch 4, Loss: 0.8466, Accuracy: 0.7220, Time: 302.06 seconds\n",
            "Epoch 5, Loss: 0.6111, Accuracy: 0.7943, Time: 291.81 seconds\n",
            "Epoch 6, Loss: 0.4466, Accuracy: 0.8598, Time: 285.60 seconds\n",
            "Epoch 7, Loss: 0.4088, Accuracy: 0.8679, Time: 285.66 seconds\n",
            "Epoch 8, Loss: 0.4812, Accuracy: 0.8432, Time: 292.26 seconds\n",
            "Epoch 9, Loss: 0.3014, Accuracy: 0.8995, Time: 277.23 seconds\n",
            "Epoch 10, Loss: 0.2504, Accuracy: 0.9255, Time: 276.89 seconds\n",
            "Epoch 11, Loss: 0.1651, Accuracy: 0.9503, Time: 276.93 seconds\n",
            "Epoch 12, Loss: 0.2067, Accuracy: 0.9364, Time: 280.37 seconds\n",
            "Epoch 13, Loss: 0.2453, Accuracy: 0.9234, Time: 300.74 seconds\n",
            "Epoch 14, Loss: 0.2667, Accuracy: 0.9079, Time: 290.67 seconds\n",
            "Epoch 15, Loss: 0.2254, Accuracy: 0.9266, Time: 290.46 seconds\n",
            "Epoch 16, Loss: 0.1484, Accuracy: 0.9500, Time: 283.36 seconds\n",
            "Epoch 17, Loss: 0.1106, Accuracy: 0.9674, Time: 279.42 seconds\n",
            "Epoch 18, Loss: 0.0654, Accuracy: 0.9799, Time: 279.95 seconds\n",
            "Epoch 19, Loss: 0.1016, Accuracy: 0.9652, Time: 279.52 seconds\n",
            "Epoch 20, Loss: 0.1540, Accuracy: 0.9519, Time: 280.18 seconds\n",
            "Epoch 21, Loss: 0.2118, Accuracy: 0.9413, Time: 280.34 seconds\n",
            "Epoch 22, Loss: 0.2186, Accuracy: 0.9345, Time: 280.46 seconds\n",
            "Epoch 23, Loss: 0.1553, Accuracy: 0.9538, Time: 280.88 seconds\n",
            "Epoch 24, Loss: 0.0513, Accuracy: 0.9840, Time: 276.95 seconds\n",
            "Epoch 25, Loss: 0.0762, Accuracy: 0.9745, Time: 277.23 seconds\n",
            "ResNet50 - Top-1 Accuracy: 63.34%\n",
            "ResNet50 - F1 Score: 62.95%\n",
            "ResNet50 - Training Time: 7118.03 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate ResNet50\n",
        "model_name = 'ResNet50'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oZfYjdj5sNf",
        "outputId": "eb5e5f80-a2a2-40f1-b0f6-018e69ad97f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training VGG16...\n",
            "\n",
            "Epoch 1, Loss: 3.6632, Accuracy: 0.0253, Time: 652.60 seconds\n",
            "Epoch 2, Loss: 3.6194, Accuracy: 0.0291, Time: 628.79 seconds\n",
            "Epoch 3, Loss: 3.6097, Accuracy: 0.0318, Time: 623.50 seconds\n",
            "Epoch 4, Loss: 3.5931, Accuracy: 0.0389, Time: 651.59 seconds\n",
            "Epoch 5, Loss: 3.5831, Accuracy: 0.0351, Time: 633.40 seconds\n",
            "Epoch 6, Loss: 3.5656, Accuracy: 0.0383, Time: 615.75 seconds\n",
            "Epoch 7, Loss: 3.5575, Accuracy: 0.0424, Time: 604.34 seconds\n",
            "Epoch 8, Loss: 3.5214, Accuracy: 0.0495, Time: 605.08 seconds\n",
            "Epoch 9, Loss: 3.4742, Accuracy: 0.0573, Time: 604.79 seconds\n",
            "Epoch 10, Loss: 3.4518, Accuracy: 0.0668, Time: 612.66 seconds\n",
            "Epoch 11, Loss: 3.3979, Accuracy: 0.0753, Time: 613.74 seconds\n",
            "Epoch 12, Loss: 3.3268, Accuracy: 0.0927, Time: 613.15 seconds\n",
            "Epoch 13, Loss: 3.2965, Accuracy: 0.0981, Time: 614.07 seconds\n",
            "Epoch 14, Loss: 3.1939, Accuracy: 0.1255, Time: 614.23 seconds\n",
            "Epoch 15, Loss: 3.1582, Accuracy: 0.1313, Time: 614.65 seconds\n",
            "Epoch 16, Loss: 3.0005, Accuracy: 0.1701, Time: 614.42 seconds\n",
            "Epoch 17, Loss: 2.8935, Accuracy: 0.1807, Time: 615.02 seconds\n",
            "Epoch 18, Loss: 2.7690, Accuracy: 0.2136, Time: 615.31 seconds\n",
            "Epoch 19, Loss: 2.6615, Accuracy: 0.2432, Time: 615.08 seconds\n",
            "Epoch 20, Loss: 2.5162, Accuracy: 0.2769, Time: 615.97 seconds\n",
            "Epoch 21, Loss: 2.3460, Accuracy: 0.3141, Time: 615.33 seconds\n",
            "Epoch 22, Loss: 2.0990, Accuracy: 0.3894, Time: 615.80 seconds\n",
            "Epoch 23, Loss: 1.8961, Accuracy: 0.4462, Time: 607.54 seconds\n",
            "Epoch 24, Loss: 1.6399, Accuracy: 0.5245, Time: 607.06 seconds\n",
            "Epoch 25, Loss: 1.4700, Accuracy: 0.5668, Time: 607.39 seconds\n",
            "VGG16 - Top-1 Accuracy: 9.21%\n",
            "VGG16 - F1 Score: 8.78%\n",
            "VGG16 - Training Time: 15431.27 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate AlexNet\n",
        "model_name = 'VGG16'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # lr=0.001 is considered standar for the learning rate\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25) # num_epochs=25 due to hardware limitation\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **GoogleNet: Inception V3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CdsQ_ie5vbj",
        "outputId": "123992f0-275f-4873-c7b4-b974dc76d8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training InceptionV3...\n",
            "\n",
            "Epoch 1, Loss: 1.609910361663155, Accuracy: 52.88%, Time: 1269.5452840328217 seconds\n",
            "Epoch 2, Loss: 0.923236914821293, Accuracy: 72.15%, Time: 1257.8459775447845 seconds\n",
            "Epoch 3, Loss: 0.7464942776638529, Accuracy: 76.36%, Time: 1260.9836275577545 seconds\n",
            "Epoch 4, Loss: 0.5269273367912873, Accuracy: 83.75%, Time: 1267.3705883026123 seconds\n",
            "Epoch 5, Loss: 0.45045023275458296, Accuracy: 85.22%, Time: 1274.8507289886475 seconds\n",
            "Epoch 6, Loss: 0.28518909782819124, Accuracy: 90.92%, Time: 1283.828443288803 seconds\n",
            "Epoch 7, Loss: 0.26359525316435356, Accuracy: 91.39%, Time: 1293.1750679016113 seconds\n",
            "Epoch 8, Loss: 0.2554628939408323, Accuracy: 91.82%, Time: 1301.6602628231049 seconds\n",
            "Epoch 9, Loss: 0.2650840433395427, Accuracy: 91.85%, Time: 1311.5917851924896 seconds\n",
            "Epoch 10, Loss: 0.23584739147968914, Accuracy: 92.31%, Time: 1322.4633672237396 seconds\n",
            "Epoch 11, Loss: 0.19334339828675856, Accuracy: 94.21%, Time: 1333.7199556827545 seconds\n",
            "Epoch 12, Loss: 0.18816026577159115, Accuracy: 93.78%, Time: 1343.14160323143 seconds\n",
            "Epoch 13, Loss: 0.14656395932416552, Accuracy: 95.05%, Time: 1355.9118602275848 seconds\n",
            "Epoch 14, Loss: 0.1396045221866149, Accuracy: 95.84%, Time: 1368.4024188518524 seconds\n",
            "Epoch 15, Loss: 0.16944640796307636, Accuracy: 95.00%, Time: 1380.6955659389496 seconds\n",
            "Epoch 16, Loss: 0.134432795467665, Accuracy: 95.82%, Time: 1394.0050609111786 seconds\n",
            "Epoch 17, Loss: 0.13225981526319747, Accuracy: 95.76%, Time: 1409.1137535572052 seconds\n",
            "Epoch 18, Loss: 0.17374311771000858, Accuracy: 94.59%, Time: 1425.7831449508667 seconds\n",
            "Epoch 19, Loss: 0.18142031340900322, Accuracy: 94.18%, Time: 1441.5324885845184 seconds\n",
            "Epoch 20, Loss: 0.14016577024417726, Accuracy: 95.57%, Time: 1459.025750875473 seconds\n",
            "Epoch 21, Loss: 0.14398870499521169, Accuracy: 95.71%, Time: 1477.9699552059174 seconds\n",
            "Epoch 22, Loss: 0.08827910938543146, Accuracy: 97.55%, Time: 1547.0228641033173 seconds\n",
            "Epoch 23, Loss: 0.06854095453669762, Accuracy: 97.66%, Time: 1569.291291475296 seconds\n",
            "Epoch 24, Loss: 0.07792966809609662, Accuracy: 97.74%, Time: 1551.8640413284302 seconds\n",
            "Epoch 25, Loss: 0.06374319687728648, Accuracy: 98.02%, Time: 1577.650199174881 seconds\n",
            "InceptionV3 - Top-1 Accuracy: 74.52%\n",
            "InceptionV3 - F1 Score: 0.74\n",
            "Training and evaluation time for InceptionV3: 34478.46559548378 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating InceptionV3\n",
        "print(\"\\nTraining InceptionV3...\\n\")\n",
        "model_inceptionv3 = models['InceptionV3']\n",
        "optimizer_inceptionv3 = optim.Adam(model_inceptionv3.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model_inception(model_inceptionv3, trainloader_inception, criterion, optimizer_inceptionv3, num_epochs=25)\n",
        "end_time = time.time()\n",
        "\n",
        "accuracy_inceptionv3, f1_inceptionv3 = evaluate_model(model_inceptionv3, testloader_inception)\n",
        "print(f\"InceptionV3 - Top-1 Accuracy: {accuracy_inceptionv3 * 100:.2f}%\")\n",
        "print(f\"InceptionV3 - F1 Score: {f1_inceptionv3:.2f}%\")\n",
        "print(f\"Training and evaluation time for InceptionV3: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **EfficientNet-B1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ029lrz5yeF",
        "outputId": "db055e97-bb9f-4501-e7e3-b779c9da15d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training EfficientNet-B1...\n",
            "\n",
            "Epoch 1, Loss: 1.0842, Accuracy: 0.7073, Time: 480.45 seconds\n",
            "Epoch 2, Loss: 0.3706, Accuracy: 0.8842, Time: 480.69 seconds\n",
            "Epoch 3, Loss: 0.1906, Accuracy: 0.9421, Time: 484.11 seconds\n",
            "Epoch 4, Loss: 0.1444, Accuracy: 0.9568, Time: 485.00 seconds\n",
            "Epoch 5, Loss: 0.1425, Accuracy: 0.9554, Time: 486.38 seconds\n",
            "Epoch 6, Loss: 0.1237, Accuracy: 0.9611, Time: 487.85 seconds\n",
            "Epoch 7, Loss: 0.1460, Accuracy: 0.9543, Time: 490.78 seconds\n",
            "Epoch 8, Loss: 0.1115, Accuracy: 0.9649, Time: 493.35 seconds\n",
            "Epoch 9, Loss: 0.0842, Accuracy: 0.9736, Time: 495.58 seconds\n",
            "Epoch 10, Loss: 0.0753, Accuracy: 0.9780, Time: 496.48 seconds\n",
            "Epoch 11, Loss: 0.0549, Accuracy: 0.9815, Time: 499.75 seconds\n",
            "Epoch 12, Loss: 0.0652, Accuracy: 0.9793, Time: 501.13 seconds\n",
            "Epoch 13, Loss: 0.0757, Accuracy: 0.9761, Time: 505.63 seconds\n",
            "Epoch 14, Loss: 0.0855, Accuracy: 0.9731, Time: 505.63 seconds\n",
            "Epoch 15, Loss: 0.0816, Accuracy: 0.9723, Time: 507.61 seconds\n",
            "Epoch 16, Loss: 0.0650, Accuracy: 0.9783, Time: 509.87 seconds\n",
            "Epoch 17, Loss: 0.0488, Accuracy: 0.9856, Time: 511.07 seconds\n",
            "Epoch 18, Loss: 0.0372, Accuracy: 0.9905, Time: 518.88 seconds\n",
            "Epoch 19, Loss: 0.0558, Accuracy: 0.9818, Time: 514.11 seconds\n",
            "Epoch 20, Loss: 0.0732, Accuracy: 0.9769, Time: 513.12 seconds\n",
            "Epoch 21, Loss: 0.0822, Accuracy: 0.9734, Time: 514.46 seconds\n",
            "Epoch 22, Loss: 0.0621, Accuracy: 0.9793, Time: 515.11 seconds\n",
            "Epoch 23, Loss: 0.0629, Accuracy: 0.9807, Time: 516.78 seconds\n",
            "Epoch 24, Loss: 0.0627, Accuracy: 0.9788, Time: 516.59 seconds\n",
            "Epoch 25, Loss: 0.0639, Accuracy: 0.9807, Time: 517.80 seconds\n",
            "EfficientNet-B1 - Top-1 Accuracy: 78.80%\n",
            "EfficientNet-B1 - F1 Score: 0.78\n",
            "EfficientNet-B1 - Training Time: 12548.20 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating EfficientNet-B1\n",
        "print(\"\\nTraining EfficientNet-B1...\\n\")\n",
        "model_efficientnet_b1 = models['EfficientNet-B1'].to(device)  # Ensure the model is on GPU\n",
        "optimizer_efficientnet_b1 = optim.Adam(model_efficientnet_b1.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(model_efficientnet_b1, trainloader, criterion, optimizer_efficientnet_b1, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "accuracy_efficientnet_b1, f1_efficientnet_b1 = evaluate_model(model_efficientnet_b1, testloader)\n",
        "print(f\"EfficientNet-B1 - Top-1 Accuracy: {accuracy_efficientnet_b1 * 100:.2f}%\")\n",
        "print(f\"EfficientNet-B1 - F1 Score: {f1_efficientnet_b1:.2f}\")\n",
        "print(f\"EfficientNet-B1 - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **EfficientNet-B3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8W82ErW51hc",
        "outputId": "c24ffc42-313d-4418-e871-d975824f5ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training EfficientNet-B3...\n",
            "\n",
            "Epoch 1, Loss: 1.1324, Accuracy: 0.7019, Time: 904.40 seconds\n",
            "Epoch 2, Loss: 0.3803, Accuracy: 0.8837, Time: 903.99 seconds\n",
            "Epoch 3, Loss: 0.1780, Accuracy: 0.9484, Time: 925.47 seconds\n",
            "Epoch 4, Loss: 0.1479, Accuracy: 0.9492, Time: 951.82 seconds\n",
            "Epoch 5, Loss: 0.1219, Accuracy: 0.9633, Time: 904.46 seconds\n",
            "Epoch 6, Loss: 0.1098, Accuracy: 0.9674, Time: 902.85 seconds\n",
            "Epoch 7, Loss: 0.1035, Accuracy: 0.9685, Time: 905.43 seconds\n",
            "Epoch 8, Loss: 0.0886, Accuracy: 0.9715, Time: 902.53 seconds\n",
            "Epoch 9, Loss: 0.1027, Accuracy: 0.9688, Time: 902.52 seconds\n",
            "Epoch 10, Loss: 0.1015, Accuracy: 0.9707, Time: 962.46 seconds\n",
            "Epoch 11, Loss: 0.0630, Accuracy: 0.9804, Time: 902.94 seconds\n",
            "Epoch 12, Loss: 0.0728, Accuracy: 0.9785, Time: 942.58 seconds\n",
            "Epoch 13, Loss: 0.0972, Accuracy: 0.9709, Time: 924.88 seconds\n",
            "Epoch 14, Loss: 0.1045, Accuracy: 0.9655, Time: 899.98 seconds\n",
            "Epoch 15, Loss: 0.0862, Accuracy: 0.9745, Time: 901.31 seconds\n",
            "Epoch 16, Loss: 0.0666, Accuracy: 0.9799, Time: 902.46 seconds\n",
            "Epoch 17, Loss: 0.0693, Accuracy: 0.9804, Time: 900.24 seconds\n",
            "Epoch 18, Loss: 0.0449, Accuracy: 0.9875, Time: 901.47 seconds\n",
            "Epoch 19, Loss: 0.0710, Accuracy: 0.9788, Time: 900.50 seconds\n",
            "Epoch 20, Loss: 0.0805, Accuracy: 0.9753, Time: 899.99 seconds\n",
            "Epoch 21, Loss: 0.0510, Accuracy: 0.9845, Time: 900.44 seconds\n",
            "Epoch 22, Loss: 0.0278, Accuracy: 0.9916, Time: 899.48 seconds\n",
            "Epoch 23, Loss: 0.0413, Accuracy: 0.9853, Time: 900.44 seconds\n",
            "Epoch 24, Loss: 0.0473, Accuracy: 0.9859, Time: 951.21 seconds\n",
            "Epoch 25, Loss: 0.0340, Accuracy: 0.9894, Time: 913.64 seconds\n",
            "EfficientNet-B3 - Top-1 Accuracy: 81.33%\n",
            "EfficientNet-B3 - F1 Score: 0.81\n",
            "EfficientNet-B3 - Training Time: 22807.49 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating EfficientNet-B3\n",
        "print(\"\\nTraining EfficientNet-B3...\\n\")\n",
        "model_efficientnet_b3 = models['EfficientNet-B3'].to(device)  # Ensure the model is on GPU\n",
        "optimizer_efficientnet_b3 = optim.Adam(model_efficientnet_b3.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(model_efficientnet_b3, trainloader, criterion, optimizer_efficientnet_b3, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "accuracy_efficientnet_b3, f1_efficientnet_b3 = evaluate_model(model_efficientnet_b3, testloader)\n",
        "print(f\"EfficientNet-B3 - Top-1 Accuracy: {accuracy_efficientnet_b3 * 100:.2f}%\")\n",
        "print(f\"EfficientNet-B3 - F1 Score: {f1_efficientnet_b3:.2f}\")\n",
        "print(f\"EfficientNet-B3 - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **EfficientNet-B5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMYZ4Vy16UqV",
        "outputId": "368203f5-2245-426a-c4ff-2567662dcc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training EfficientNet-B5...\n",
            "\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m optimizer_efficientnet_b5 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_efficientnet_b5\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_efficientnet_b5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_efficientnet_b5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     10\u001b[0m accuracy_efficientnet_b5, f1_efficientnet_b5 \u001b[38;5;241m=\u001b[39m evaluate_model(model_efficientnet_b5, testloader)\n",
            "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, trainloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
          ]
        }
      ],
      "source": [
        "\n",
        "# Training and evaluating EfficientNet-B5\n",
        "print(\"\\nTraining EfficientNet-B5...\\n\")\n",
        "model_efficientnet_b5 = models['EfficientNet-B5'].to(device)  # Ensure the model is on GPU\n",
        "optimizer_efficientnet_b5 = optim.Adam(model_efficientnet_b5.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(model_efficientnet_b5, trainloader, criterion, optimizer_efficientnet_b5, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "accuracy_efficientnet_b5, f1_efficientnet_b5 = evaluate_model(model_efficientnet_b5, testloader)\n",
        "print(f\"EfficientNet-B5 - Top-1 Accuracy: {accuracy_efficientnet_b5 * 100:.2f}%\")\n",
        "print(f\"EfficientNet-B5 - F1 Score: {f1_efficientnet_b5:.2f}\")\n",
        "print(f\"EfficientNet-B5 - Training Time: {training_time:.2f} seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
