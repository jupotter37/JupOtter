{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d24e86-f76f-4a44-90ef-0777752075a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/lvwerra/trl.git@25fa1bd\n",
      "  Cloning https://github.com/lvwerra/trl.git (to revision 25fa1bd) to /tmp/pip-req-build-8y3fp86x\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-8y3fp86x\n",
      "\u001b[33m  WARNING: Did not find branch or tag '25fa1bd', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 25fa1bd\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 25fa1bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /home/qblocks/.local/lib/python3.8/site-packages (from trl==0.4.2.dev0) (2.0.0+cu118)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.8/dist-packages (from trl==0.4.2.dev0) (4.28.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/qblocks/.local/lib/python3.8/site-packages (from trl==0.4.2.dev0) (1.21.1)\n",
      "Requirement already satisfied: accelerate in /home/qblocks/.local/lib/python3.8/site-packages (from trl==0.4.2.dev0) (0.18.0)\n",
      "Requirement already satisfied: datasets in /home/qblocks/.local/lib/python3.8/site-packages (from trl==0.4.2.dev0) (2.10.1)\n",
      "Requirement already satisfied: filelock in /home/qblocks/.local/lib/python3.8/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in /home/qblocks/.local/lib/python3.8/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.3.0)\n",
      "Requirement already satisfied: sympy in /home/qblocks/.local/lib/python3.8/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/qblocks/.local/lib/python3.8/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.0.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/qblocks/.local/lib/python3.8/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/qblocks/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/qblocks/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (16.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2022.7.9)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/qblocks/.local/lib/python3.8/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.64.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate->trl==0.4.2.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (1.4.3)\n",
      "Requirement already satisfied: xxhash in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (2022.7.1)\n",
      "Requirement already satisfied: aiohttp in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/qblocks/.local/lib/python3.8/site-packages (from datasets->trl==0.4.2.dev0) (0.18.0)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /home/qblocks/.local/lib/python3.8/site-packages (from responses<0.19->datasets->trl==0.4.2.dev0) (1.26.11)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (20.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/qblocks/.local/lib/python3.8/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->trl==0.4.2.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->trl==0.4.2.dev0) (2021.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/qblocks/.local/lib/python3.8/site-packages (from sympy->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.4.2.dev0) (1.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets->trl==0.4.2.dev0) (2.8)\n",
      "Building wheels for collected packages: trl\n",
      "  Building wheel for trl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trl: filename=trl-0.4.2.dev0-py3-none-any.whl size=67540 sha256=bb3c2014e39239efda0ec4e087def2c28706c18a9a50c21bb585a37cee47d306\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hez8ozun/wheels/83/c2/4f/abce0f74327d238d71d1fdaa7a23c24cf393212007035862ce\n",
      "Successfully built trl\n",
      "\u001b[33mWARNING: Error parsing requirements for torch-spline-conv: [Errno 2] No such file or directory: '/home/qblocks/.local/lib/python3.8/site-packages/torch_spline_conv-1.2.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: trl\n",
      "Successfully installed trl-0.4.2.dev0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --disable-pip-version-check \\\n",
    "#     torch==1.13.1 \\\n",
    "#     torchdata==0.5.1 --quiet\n",
    "\n",
    "# %pip install \\\n",
    "#     transformers==4.27.2 \\\n",
    "#     datasets==2.11.0 \\\n",
    "#     evaluate==0.4.0 \\\n",
    "#     rouge_score==0.1.2 \\\n",
    "#     peft==0.3.0 --quiet\n",
    "\n",
    "# Installing the Reinforcement Learning library directly from github.\n",
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3c076-d9d2-40e3-b005-9dd66b5a163a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfd06e-c747-43e0-b86c-0398628e1c32",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import the necessary components. Some of them are new for this week, they will be discussed later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-08-23 13:27:53.812611: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 13:27:55.202676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-23 13:27:55.202785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-23 13:27:55.202800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978d8eb3-3d01-48d2-9afa-ca9d994f232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a9b8-7c47-4da5-a734-83eb663fdd0d",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ead23b-f9ab-451c-b004-eef7240db3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeftModel:\n",
    "    @staticmethod\n",
    "    def load_base_model(model_path=\"google/flan-t5-base\"):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            model_path, torch_dtype=torch.bfloat16\n",
    "        ).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_peft_adapter(\n",
    "        base_model_path, peft_model_path, train=False, merge_adapter=True\n",
    "    ):\n",
    "        model, tokenizer = self.load_base_model(base_model_path)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = PeftModel.from_pretrained(\n",
    "            model, peft_model_path, torch_dtype=torch.bfloat16, is_trainable=train\n",
    "        ).to(device)\n",
    "\n",
    "        if merge_adapter:\n",
    "            model = model.merge_and_unload()\n",
    "\n",
    "            if train:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # merge the adapter to the main model\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def save_peft_adapter(model, tokenizer, model_path):\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_peft_and_save(model, tokenizer, model_path):\n",
    "        model = model.merge_and_unload()\n",
    "        model.save_pretrained(model_path)\n",
    "        tokenizer.save_pretrained(model_path)\n",
    "        \n",
    "        \n",
    "peft_model, tokenizer = PeftModel.load_base_model(\"./checkpoint/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eea84-8e3a-4487-9692-613977e6c8e3",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Load FLAN-T5 Model, Prepare Reward Model and Toxicity Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc0211-4032-4967-946d-3a538829d5c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "You will keep working with the same Hugging Face dataset [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) and the pre-trained model [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Summarize this news article in 50 words.\\n\\nNandan Nilekani Infosys Chairman Nandan Nilekani said on June 22 that e-commerce companies will need Open Network for Digital Commerce (ONDC) for online purchases to grow from the current 80 million monthly transacting users (MTUs) to 500 million. \"ONDC will create a new class of e-commerce users. Suddenly, people who didn\\'t think of e-commerce earlier will start thinking of it for convenience and order from their neighbourhood stores via ONDC,\" he said. \"The number of platforms which are in e-commerce will go up. It won\\'t be just two guys, but 10 guys. It might not benefit one guy, but it will benefit India,\" he added. Nilekani, who has been instrumental in creating India\\'s digital public infrastructure from Aadhaar and UPI to Fastag and ONDC, was speaking at an event organised by management consulting firm Redseer. The Infosys veteran highlighted the rapid growth of digital public infrastructure in India, and how it has increased bank account penetration from around 20 percent to over 80 percent in less than a decade. He pointed out that a confluence of four important events in 2016 has led to the rapid digital adoption in India: Aadhaar hit the 1 billion user mark on April 4, the unified payments interface was launched on April 11, the launch of Jio in September that year which quickly brought down the cost of data and demonetisation in November. “Aadhaar also laid the foundation of Covid vaccination. You could take one dose in one location and second in another... India is doing irreversible non-linear changes and each change is acting as input for next. This combinatorial innovation at population scale is why it is called digital public infrastructure,” he said. “Digitisation is leading to formalisation and therefore the rate of tax growth is greater than rate of GDP growth because of compliance growing,” he added. Nilekani argued that while the internet has grown in the US on the back of the high advertising revenue of $862 per capita shifting online, India can’t take this approach as the number for the country is as low as $7 per capita. “We needed a different kind of internet infra than West... Essentially, Indian internet is not advertising led, but transaction led... Your transaction history is itself a form of capital that will be unlocked at scale,” he said.\\n\\nSummary: ',\n",
       " 'Infosys Chairman Nandan Nilekani said e-commerce firms will need Open Network for Digital Commerce (ONDC) for online purchases to grow to 500 million monthly transacting users from the current 80 million. \"ONDC will create a new class of e-commerce users. Suddenly, people who didn\\'t think of e-commerce earlier will start thinking of it for convenience,\" he said.',\n",
       " 'Infosys Chairman Nandan Nilekani said that e-commerce companies will need Open Network for Digital Commerce (ONDC) for online purchases to grow from the current 80 million monthly transacting users (MTUs) to 500 million. \"Suddenly, people who didn\\'t think of e-commerce earlier will start thinking of it for convenience and order from their neighbourhood stores via ONDC,\" he added.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "save_pkl = lambda data, filepath: pickle.dump(data, open(filepath, \"wb\"))\n",
    "load_pkl = lambda filepath: pickle.load(open(filepath, \"rb\"))\n",
    "\n",
    "training_data = load_pkl(\"./rank_data/data.pkl\")\n",
    "training_data[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c4036b-e054-4db1-909b-4ca06ac65bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': \"Summarize this news article in 50 words.\\n\\nMy teachers have taught me that patience and perseverance always do wonders in everyone’s life, says Sonu Sood My teachers have taught me that patience and perseverance always do wonders in everyone’s life, says Sonu Sood He exclusively spoke to us about the importance of Teacher`s Day, amongst other things Official Instagram Account of Sonu Sood The pandemic saw the reel-life actor Sonu Sood turning a real-life hero. Besides facilitating the travel of the needy to meet their loved ones, providing free education, medical help and much moreâ\\x80¦ Sood lent a helping hand to many. He was even nicknamed as â\\x80\\x98Messiah' in lieu of the help which he rendered during the pandemic. Mid-Day Online caught up with Sonu Sood for an exclusive interview on Teacher's Day. Since Sonu's mother was a teacher herself, Sonu spoke about the importance of the day, besides jogging down memory lane. Who was your favourite teacher in school or college and why? My favourite teacher has always been my mother. What is that one thing you have learnt from your teachers, that will remain with you forever? I have learnt that, one should never lose patience and to be perseverant in life. My teachers have taught me that, patience and perseverance always do wonders in anyone's life. These two factors are extremely important to reach one's goals. Which was your favourite subject and least favourite subject in school? My most favourite subject was Mathematics of course, while the least favourite was Geography. If you were not an actor, would you have become a teacher? I would have surely done that. But, through the medium of â\\x80\\x98Sood Charity Foundation', we are helping lots of students to pursue their education. This way, the dream of becoming a teacher is getting fulfilled even after becoming an actor. Also Read: Blackpink become artiste with highest subscribers on Youtube, 'Pink Venom' excluded from music bank How were you as a student in school? Were you a front bencher or a last bencher? I was good student, if not great. I was a last bencher during my ninth and tenth standard. I was always trying to do my bit. Since my mother was a teacher herself, there was no excuse for me to have secured less marks. Have you ever been punished in school by your teachers? Yes, many a times. Those times, the punishments used to be kneeling down outside the class. I had been punished this way do a couple of times during my school days. Is there any punishment that you will remember for the rest of your life? Yes! During my school days, three students (including me) were told to stand outside the class as a punishment. On the pretext of going outside the class, we simply vanished from there and went to watch a movie! We were called the next day and were given a good piece of scolding and beating for that. After that, we never dared to do anything of that sort! Play Quiz: Is this the first time Ranbir Kapoor and Alia Bhatt are paired together?\\n\\nSummary: \",\n",
       " 'summary': 'Sonu Sood said if he wasn\\'t an actor, he would have been a teacher. He said his dream is now coming true with \\'Sood Charity Foundation\\', which is helping many students to pursue education. Calling his mother his \"favourite teacher\", Sonu shared, \"Since my mother was a teacher herself, there was no excuse for me to have secured less marks.\"',\n",
       " 'input_ids': tensor([12198,  1635,  1737,    48,  1506,  1108,    16,   943,  1234,     5,\n",
       "           499,  3081,    43,  4436,   140,    24, 11998,    11, 22644,   663,\n",
       "           373,   103,  3337,     7,    16,   921,    22,     7,   280,     6,\n",
       "           845,  3885,    76,   264,    32,    26,   499,  3081,    43,  4436,\n",
       "           140,    24, 11998,    11, 22644,   663,   373,   103,  3337,     7,\n",
       "            16,   921,    22,     7,   280,     6,   845,  3885,    76,   264,\n",
       "            32,    26,   216,  9829,  5468,    12,   178,    81,     8,  3172,\n",
       "            13, 17476,     2,     7,  1430,     6,   859,     7,    17,   119,\n",
       "           378, 13686,  4601,  6288,    13,  3885,    76,   264,    32,    26,\n",
       "            37,  2131,   221,  3113,  1509,     8, 14495,    18,  4597,  7556,\n",
       "          3885,    76,   264,    32,    26,  5074,     3,     9,   490,    18,\n",
       "          4597,   160,    32,     5,     3,  8500,     3, 24962,     8,  1111,\n",
       "            13,     8,   174,    63,    12,   942,    70,  1858,  2102,     6,\n",
       "          1260,   339,  1073,     6,  1035,   199,    11,   231,    72,  1439,\n",
       "             2,   264,    32,    26,     3,  6987,     3,     9,  2022,   609,\n",
       "            12,   186,     5,   216,    47,   237, 24649,    26,    38,     3,\n",
       "          1439,     2,   329,    15,     7,     7,    23,     9,   107,    31,\n",
       "            16,  4618,    13,     8,   199,    84,     3,    88, 20518,   383,\n",
       "             8,  2131,   221,  3113,     5,  6650,    18, 16803,  1777,  4682,\n",
       "            95,    28,  3885,    76,   264,    32,    26,    21,    46,  3839,\n",
       "          2772,    30, 17476,    31,     7,  1430,     5,  1541,  3885,    76,\n",
       "            31,     7,  2039,    47,     3,     9,  3145,  6257,     6,  3885,\n",
       "            76,  5468,    81,     8,  3172,    13,     8,   239,     6,     3,\n",
       "         15262,     3,  1927,  4102,    53,   323,  2594,     3,  8102,     5,\n",
       "          2645,    47,    39,  3960,  3145,    16,   496,    42,  1900,    11,\n",
       "           572,    58,   499,  3960,  3145,    65,   373,   118,    82,  2039,\n",
       "             5,   363,    19,    24,    80,   589,    25,    43,   669,    17,\n",
       "            45,    39,  3081,     6,    24,    56,  2367,    28,    25,  6276,\n",
       "            58,    27,    43,   669,    17,    24,     6,    80,   225,   470,\n",
       "          2615, 11998,    11,    12,    36, 22644,   288,    16,   280,     5,\n",
       "           499,  3081,    43,  4436,   140,    24,     6, 11998,    11, 22644,\n",
       "           663,   373,   103,  3337,     7,    16,  1321,    31,     7,   280,\n",
       "             5,   506,   192,  2580,    33,  2033,   359,    12,  1535,    80,\n",
       "            31,     7,  1766,     5,  4073,    47,    39,  3960,  1426,    11,\n",
       "           709,  3960,  1426,    16,   496,    58,   499,   167,  3960,  1426,\n",
       "            47, 23516,    13,   503,     6,   298,     8,   709,  3960,    47,\n",
       "           961,  5984,     5,   156,    25,   130,    59,    46,  7556,     6,\n",
       "           133,    25,    43,   582,     3,     9,  3145,    58,    27,   133,\n",
       "            43,  8460,   612,    24,     5,   299,     6,   190,     8,  2768,\n",
       "            13,     3,  1439,     2,  5231,    32,    26, 25997,  2941,    31,\n",
       "             6,    62,    33,  2022,  1995,    13,   481,    12,  6665,    70,\n",
       "          1073,     5,   100,   194,     6,     8,  2461,    13,  2852,     3,\n",
       "             9,  3145,    19,   652, 20795,   237,   227,  2852,    46,  7556,\n",
       "             5,  1203,  3403,    10,  1589,  3180,   157,   582,     3, 20591,\n",
       "            28,  2030, 17303,    30, 18116,     6,     3,    31,   345,  6090,\n",
       "          3901,  3114,    31, 19678,    45,   723,  2137,   571,   130,    25,\n",
       "            38,     3,     9,  1236,    16,   496,    58,   101,    60,    25,\n",
       "             3,     9,   851,  8453,    49,    42,     3,     9,   336,  8453,\n",
       "            49,    58,    27,    47,   207,  1236,     6,     3,    99,    59,\n",
       "           248,     5,    27,    47,     3,     9,   336,  8453,    49,   383,\n",
       "            82, 24651,    11,     3,   324,   189,  1068,     5,    27,    47,\n",
       "           373,  1119,    12,   103,    82,   720,     5,  1541,    82,  2039,\n",
       "            47,     3,     9,  3145,  6257,     6,   132,    47,   150, 10553,\n",
       "            21,   140,    12,    43, 10774,   705,  6784,     5,  2114,    25,\n",
       "           664,   118, 31171,    16,   496,    57,    39,  3081,    58,  2163,\n",
       "             6,   186,     3,     9,   648,     5,     3,  3405,   648,     6,\n",
       "             8, 19372,     7,   261,    12,    36,  6476,   697,   323,  1067,\n",
       "             8,   853,     5,    27,   141,   118, 31171,    48,   194,   103,\n",
       "             3,     9,  1158,    13,   648,   383,    82,   496,   477,     5,\n",
       "            27,     7,   132,   136, 19372,    24,    25,    56,  1423,    21,\n",
       "             8,   880,    13,    39,   280,    58,  2163,    55,     3,  2092,\n",
       "            82,   496,   477,     6,   386,   481,    41,  5751,   140,    61,\n",
       "           130,  1219,    12,  1518,  1067,     8,   853,    38,     3,     9,\n",
       "         19372,     5,   461,     8,   554,  6327,    13,   352,  1067,     8,\n",
       "           853,     6,    62,   914,  4049, 11904,    45,   132,    11,   877,\n",
       "            12,  1605,     3,     9,  1974,    55,   101,   130,   718,     8,\n",
       "           416,   239,    11,   130,   787,     3,     9,   207,  1466,    13,\n",
       "             3,     7,  3297,    26,    53,    11, 16201,    21,    24,     5,\n",
       "           621,    24,     6,    62,   470,   836,  1271,    12,   103,   959,\n",
       "            13,    24,  1843,    55,  2911,  6590,   172,    10,    27,     7,\n",
       "            48,     8,   166,    97, 15039,  8781, 12232,    32,   127,    11,\n",
       "          5429,     9,   272,   547,    17,    33,     3, 13804,   544,    58,\n",
       "         20698,    10,     3,     1]),\n",
       " 'query': \"Summarize this news article in 50 words. My teachers have taught me that patience and perseverance always do wonders in everyone’s life, says Sonu Sood My teachers have taught me that patience and perseverance always do wonders in everyone’s life, says Sonu Sood He exclusively spoke to us about the importance of Teacher<unk>s Day, amongst other things Official Instagram Account of Sonu Sood The pandemic saw the reel-life actor Sonu Sood turning a real-life hero. Besides facilitating the travel of the needy to meet their loved ones, providing free education, medical help and much moreâ<unk> Sood lent a helping hand to many. He was even nicknamed as â<unk>Messiah' in lieu of the help which he rendered during the pandemic. Mid-Day Online caught up with Sonu Sood for an exclusive interview on Teacher's Day. Since Sonu's mother was a teacher herself, Sonu spoke about the importance of the day, besides jogging down memory lane. Who was your favourite teacher in school or college and why? My favourite teacher has always been my mother. What is that one thing you have learnt from your teachers, that will remain with you forever? I have learnt that, one should never lose patience and to be perseverant in life. My teachers have taught me that, patience and perseverance always do wonders in anyone's life. These two factors are extremely important to reach one's goals. Which was your favourite subject and least favourite subject in school? My most favourite subject was Mathematics of course, while the least favourite was Geography. If you were not an actor, would you have become a teacher? I would have surely done that. But, through the medium of â<unk>Sood Charity Foundation', we are helping lots of students to pursue their education. This way, the dream of becoming a teacher is getting fulfilled even after becoming an actor. Also Read: Blackpink become artiste with highest subscribers on Youtube, 'Pink Venom' excluded from music bank How were you as a student in school? Were you a front bencher or a last bencher? I was good student, if not great. I was a last bencher during my ninth and tenth standard. I was always trying to do my bit. Since my mother was a teacher herself, there was no excuse for me to have secured less marks. Have you ever been punished in school by your teachers? Yes, many a times. Those times, the punishments used to be kneeling down outside the class. I had been punished this way do a couple of times during my school days. Is there any punishment that you will remember for the rest of your life? Yes! During my school days, three students (including me) were told to stand outside the class as a punishment. On the pretext of going outside the class, we simply vanished from there and went to watch a movie! We were called the next day and were given a good piece of scolding and beating for that. After that, we never dared to do anything of that sort! Play Quiz: Is this the first time Ranbir Kapoor and Alia Bhatt are paired together? Summary: </s>\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_len = tokenizer.model_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # self.data[index] = [prompt, human text, model text]\n",
    "        prompt, summary, _ = self.data[index]\n",
    "        inputs = self.tokenizer(prompt)\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        query = self.tokenizer.decode(input_ids)\n",
    "\n",
    "        return {\n",
    "            'prompt': prompt,\n",
    "            'summary': summary,\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'query': query\n",
    "        }\n",
    "    \n",
    "    \n",
    "train_ratio = 0.8\n",
    "train_size = int(len(training_data) * train_ratio)\n",
    "\n",
    "train_data = training_data[:train_size].copy()\n",
    "test_data = training_data[train_size:].copy()\n",
    "\n",
    "training_set = CustomDataset(train_data, tokenizer)\n",
    "testing_set = CustomDataset(test_data, tokenizer)\n",
    "\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f06806-a194-4c14-b64d-e31afd7b658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainable model parameters: 247577856\\nall model parameters: 247577856\\npercentage of trainable model parameters: 100.00%'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print_number_of_trainable_model_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda",
   "metadata": {
    "tags": []
   },
   "source": [
    "Add the adapter to the original FLAN-T5 model. In the previous lab you were adding the fully trained adapter only for inferences, so there was no need to pass LoRA configurations doing that. Now you need to pass them to the constructed PEFT model, also putting `is_trainable=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17",
   "metadata": {},
   "source": [
    "In this lab, you are preparing to fine-tune the LLM using Reinforcement Learning (RL). RL will be briefly discussed in the next section of this lab, but at this stage, you just need to prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 247578625\n",
      "all model parameters: 247578625\n",
      "percentage of trainable model parameters: 100.00%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913ef05-737e-4cdf-9bac-467ee6cf9f76",
   "metadata": {},
   "source": [
    "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters can be computed as $(n+1)*m$, where $n$ is the number of input units (here $n=768$) and $m$ is the number of output units (you have $m=1$). The $+1$ term in the equation takes into account the bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e",
   "metadata": {},
   "source": [
    "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training. This is on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 247578625\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a14848-e83d-4fdd-bc68-eb770c5951d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Everything is set. It is time to prepare the reward model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Prepare Reward Model\n",
    "\n",
    "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b5e165-f861-4804-a472-8d04f30e0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35f9e10-56ac-44f6-af08-62ad8f44f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_len = tokenizer.model_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # [prompt, human text, model text]\n",
    "        inputs = self.tokenizer(self.data[index],             \n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_token_type_ids=True,\n",
    "                                truncation=True,\n",
    "                                padding=\"max_length\")\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RewardModel(torch.nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.l1 = GPT2Model.from_pretrained(\"gpt2\")\n",
    "        \n",
    "        for param in self.l1.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(768, 1),\n",
    "        )\n",
    "        self.outl = nn.Sigmoid()\n",
    "        \n",
    "    def gpt2(self, ids, attention_mask, token_type_ids):\n",
    "        # logits shape: [batch=16, seqlen=1024, dim=768]\n",
    "        logits, _ = self.l1(ids, \n",
    "                         attention_mask=attention_mask,\n",
    "                         token_type_ids=token_type_ids,\n",
    "                         return_dict=False)\n",
    "        \n",
    "        sequence_lengths = (torch.eq(ids[:, 0], tokenizer.pad_token_id).long().argmax(-1) - 1).to(\n",
    "                    logits.device\n",
    "                )\n",
    "        \n",
    "        batch_size = ids.shape[0]\n",
    "        \n",
    "        # pooled logits shape: [batch=16, dim=768]\n",
    "        pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths]\n",
    "        return pooled_logits\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        ids shape = [batch, 3, 512]\n",
    "        3: prompt, human_text, model_text\n",
    "        \"\"\"  \n",
    "        prompt = self.gpt2(ids[:, 0], \n",
    "                         attention_mask=mask[:, 0], \n",
    "                         token_type_ids=token_type_ids[:, 0])\n",
    "        \n",
    "        human_text = self.gpt2(ids[:, 1], \n",
    "                             attention_mask=mask[:, 1], \n",
    "                             token_type_ids=token_type_ids[:, 1])\n",
    "            \n",
    "        model_text = self.gpt2(ids[:, 2], \n",
    "                             attention_mask=mask[:, 2], \n",
    "                             token_type_ids=token_type_ids[:, 2])\n",
    "\n",
    "        human_score = self.l2(prompt + human_text)\n",
    "        model_score = self.l2(prompt + model_text)\n",
    "        \n",
    "        return self.outl(human_score - model_score)\n",
    "    \n",
    "    def predict(self, ids, mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        ids shape: [batch, 2, 512]\n",
    "        2: prompt, text\n",
    "        \"\"\"\n",
    "        prompt = self.gpt2(ids[:, 0], \n",
    "                         attention_mask=mask[:, 0], \n",
    "                         token_type_ids=token_type_ids[:, 0])\n",
    "        \n",
    "        text = self.gpt2(ids[:, 1], \n",
    "                       attention_mask=mask[:, 1], \n",
    "                       token_type_ids=token_type_ids[:, 1])\n",
    "        \n",
    "        return self.l2(prompt + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd115a3-b0f0-446c-baf3-118f97cf6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model = RewardModel().to(device)\n",
    "\n",
    "model_path = \"./reward_model_checkpoint/gpt2_last_layer_trained_model.pt\"\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    reward_model.load_state_dict(\n",
    "        torch.load(model_path, map_location=device), strict=False\n",
    "    )\n",
    "\n",
    "\n",
    "reward_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "reward_tokenizer.pad_token = reward_tokenizer.eos_token\n",
    "\n",
    "def reward(inputs):\n",
    "    \"\"\"\n",
    "    inputs = [[prompt, summary], [prompt, summary]]\n",
    "    \"\"\"\n",
    "    reward_model.eval()\n",
    "    \n",
    "    dataset = CustomDataset(inputs, reward_tokenizer)\n",
    "    params = {'batch_size': len(inputs),\n",
    "              'shuffle': False,\n",
    "              'num_workers': 0}\n",
    "    dataloader = DataLoader(dataset, **params)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        reward = []\n",
    "        \n",
    "        for idx, data in enumerate(dataloader):\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "            pred = reward_model.predict(ids, mask, token_type_ids)\n",
    "            reward.append(pred.squeeze(-1))\n",
    "            \n",
    "        return [tensor for tensor in torch.cat(reward, dim=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6c1677-c1d1-4cbd-8403-e20973db67f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(9.2640, device='cuda:0'), tensor(8.7152, device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward([[\"kjhgf hgf\", \"gtreef regef\"],[\"54y435tgr\", \"regtw5exqwe\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d68799-a6e8-42d7-8d61-002e47210c18",
   "metadata": {
    "tags": []
   },
   "source": [
    "Take some non-toxic text, tokenize it, and pass it to the model. Print the output logits, probabilities, and the corresponding reward that will be used for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516e318-8fce-4ca7-bf19-b7baf5255480",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 - Initialize `PPOTrainer`\n",
    " \n",
    "For the `PPOTrainer` initialization, you will need a collator. Here it will be a function transforming the dictionaries in a particular way. You can define and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c2e92-4988-4944-8353-0e1bb2048072",
   "metadata": {},
   "source": [
    "Set up the configuration parameters. Load the `ppo_model` and the tokenizer. You will also load a frozen version of the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=2\n",
    "batch_size=4\n",
    "\n",
    "config = PPOConfig(\n",
    "    # model_name=model_name,    \n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model, \n",
    "                         ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, \n",
    "                         dataset=training_set, \n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62",
   "metadata": {},
   "source": [
    "The fine-tuning loop consists of the following main steps:\n",
    "1. Get the query responses from the policy LLM (PEFT model).\n",
    "2. Get sentiments for query/responses from hate speech RoBERTa model.\n",
    "3. Optimize policy with PPO using the (query, response, reward) triplet.\n",
    "\n",
    "The operation is running if you see the following metrics appearing:\n",
    "* `objective/kl`: minimize kl divergence,\n",
    "* `ppo/returns/mean`: maximize mean returns,\n",
    "* `ppo/policy/advantages_mean`: maximize advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "1it [00:14, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0\n",
      "ppo/returns/mean: 0.8067174553871155\n",
      "ppo/policy/advantages_mean: 3.448037233511059e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:19,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.011627238243818283\n",
      "ppo/returns/mean: 3.6164681911468506\n",
      "ppo/policy/advantages_mean: 4.9511168498383995e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:29,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.04975392669439316\n",
      "ppo/returns/mean: 1.574193000793457\n",
      "ppo/policy/advantages_mean: 1.7660635620586618e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:35,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.04581354185938835\n",
      "ppo/returns/mean: 2.6833877563476562\n",
      "ppo/policy/advantages_mean: 1.4901161193847656e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:39,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.03948284685611725\n",
      "ppo/returns/mean: 4.1326141357421875\n",
      "ppo/policy/advantages_mean: 1.1850539749502786e-07\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:44,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.008993538096547127\n",
      "ppo/returns/mean: 3.083159923553467\n",
      "ppo/policy/advantages_mean: -6.3578298181710124e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:52,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.004829383920878172\n",
      "ppo/returns/mean: 3.3645436763763428\n",
      "ppo/policy/advantages_mean: -8.944515172970569e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:57,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.042150747030973434\n",
      "ppo/returns/mean: 2.579322338104248\n",
      "ppo/policy/advantages_mean: -6.866894608492657e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:04,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.04402057081460953\n",
      "ppo/returns/mean: 2.261643886566162\n",
      "ppo/policy/advantages_mean: 3.698776751548394e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:07,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.019870169460773468\n",
      "ppo/returns/mean: 4.865118980407715\n",
      "ppo/policy/advantages_mean: 9.930337085961582e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:13,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.06629962474107742\n",
      "ppo/returns/mean: 2.0928871631622314\n",
      "ppo/policy/advantages_mean: 3.2511625391862253e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:21,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.013500824570655823\n",
      "ppo/returns/mean: 3.302504539489746\n",
      "ppo/policy/advantages_mean: 5.026468130608919e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [01:26,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.05105065554380417\n",
      "ppo/returns/mean: 3.0877737998962402\n",
      "ppo/policy/advantages_mean: -1.899537593885725e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [01:31,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.03421386331319809\n",
      "ppo/returns/mean: 3.4848129749298096\n",
      "ppo/policy/advantages_mean: 5.2867008548673766e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:39,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.01963803358376026\n",
      "ppo/returns/mean: 2.0179033279418945\n",
      "ppo/policy/advantages_mean: -3.3200393545484985e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [01:44,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.012761603109538555\n",
      "ppo/returns/mean: 3.654768228530884\n",
      "ppo/policy/advantages_mean: 2.5981509566008754e-07\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [01:51,  6.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1438028/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1419551812.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">57</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 22&gt;</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1438028/1419551812.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3.8/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@wraps</span>(func)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>(*args, **kwds):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._recreate_cm():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwds)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qblocks/.local/lib/python3.8/site-packages/trl/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ppo_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">666</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 663 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model, batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"queries\"</span>], batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"responses\"</span>], model_inputs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 664 │   │   │   │   │   </span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 665 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 666 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>train_stats = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_minibatch(                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 667 │   │   │   │   │   </span>batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"logprobs\"</span>],                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 668 │   │   │   │   │   </span>batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"values\"</span>],                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 669 │   │   │   │   │   </span>batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"rewards\"</span>],                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3.8/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@wraps</span>(func)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inner</span>(*args, **kwds):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._recreate_cm():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwds)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qblocks/.local/lib/python3.8/site-packages/trl/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ppo_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">927</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_minibatch</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 924 │   │   </span>loss_p, loss_v, train_stats = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loss(old_logprobs, values, rewards, logits, v  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 925 │   │   </span>loss = loss_p + loss_v                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 926 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.zero_grad()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 927 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 928 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 929 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.max_grad_norm <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 930 │   │   │   </span>torch.nn.utils.clip_grad_norm_(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qblocks/.local/lib/python3.8/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1683</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1680 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1681 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1682 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1683 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1684 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1685 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1686 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qblocks/.local/lib/python3.8/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qblocks/.local/lib/python3.8/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.63</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.54</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.90</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">954.88</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.03</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1438028/\u001b[0m\u001b[1;33m1419551812.py\u001b[0m:\u001b[94m57\u001b[0m in \u001b[92m<cell line: 22>\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1438028/1419551812.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.8/\u001b[0m\u001b[1;33mcontextlib.py\u001b[0m:\u001b[94m75\u001b[0m in \u001b[92minner\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minner\u001b[0m(*args, **kwds):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._recreate_cm():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 75 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwds)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/qblocks/.local/lib/python3.8/site-packages/trl/trainer/\u001b[0m\u001b[1;33mppo_trainer.py\u001b[0m:\u001b[94m666\u001b[0m in \u001b[92mstep\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 663 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.model, batch[\u001b[33m\"\u001b[0m\u001b[33mqueries\u001b[0m\u001b[33m\"\u001b[0m], batch[\u001b[33m\"\u001b[0m\u001b[33mresponses\u001b[0m\u001b[33m\"\u001b[0m], model_inputs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 664 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 665 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 666 \u001b[2m│   │   │   │   \u001b[0mtrain_stats = \u001b[96mself\u001b[0m.train_minibatch(                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 667 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mlogprobs\u001b[0m\u001b[33m\"\u001b[0m],                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 668 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mvalues\u001b[0m\u001b[33m\"\u001b[0m],                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 669 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mrewards\u001b[0m\u001b[33m\"\u001b[0m],                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.8/\u001b[0m\u001b[1;33mcontextlib.py\u001b[0m:\u001b[94m75\u001b[0m in \u001b[92minner\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minner\u001b[0m(*args, **kwds):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._recreate_cm():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 75 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwds)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/qblocks/.local/lib/python3.8/site-packages/trl/trainer/\u001b[0m\u001b[1;33mppo_trainer.py\u001b[0m:\u001b[94m927\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mtrain_minibatch\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 924 \u001b[0m\u001b[2m│   │   \u001b[0mloss_p, loss_v, train_stats = \u001b[96mself\u001b[0m.loss(old_logprobs, values, rewards, logits, v  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 925 \u001b[0m\u001b[2m│   │   \u001b[0mloss = loss_p + loss_v                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 926 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.zero_grad()                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 927 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 928 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 929 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.config.max_grad_norm \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 930 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.nn.utils.clip_grad_norm_(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/qblocks/.local/lib/python3.8/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1683\u001b[0m in \u001b[92mbackward\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1680 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1681 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward(**kwargs)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1682 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1683 \u001b[2m│   │   │   \u001b[0mloss.backward(**kwargs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1684 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1685 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92munscale_gradients\u001b[0m(\u001b[96mself\u001b[0m, optimizer=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1686 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/qblocks/.local/lib/python3.8/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/qblocks/.local/lib/python3.8/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m1.63\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m47.54\u001b[0m GiB total capacity; \u001b[1;36m39.90\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m954.88\u001b[0m MiB free; \u001b[1;36m43.03\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_min_length = 200\n",
    "output_max_length = 400\n",
    "not_hate_index = 0\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    # \"min_length\": 5,\n",
    "    # \"top_k\": 0.0,\n",
    "    # \"top_p\": 1.0,\n",
    "    # \"do_sample\": True\n",
    "    \"max_new_tokens\": 200\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "# max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    # if step >= max_ppo_steps:\n",
    "    #     break   \n",
    "\n",
    "    # prompt tensors is a list of 1D tensors\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "    # print(prompt_tensors[0].shape, \"prompt tensor shape\")\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for idx, prompt_tensor in enumerate(prompt_tensors):\n",
    "        max_new_tokens = output_length_sampler()        \n",
    "            \n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        # if idx == 0:\n",
    "        #     print(max_new_tokens, \"max new tokens\")\n",
    "        #     print(summary.shape, \"summary shape\")\n",
    "        #     print(summary.squeeze()[-max_new_tokens:].shape, \"summary shape post processing\")\n",
    "        #     print(summary.squeeze()[-max_new_tokens:].squeeze().shape, \"summary shape post processing 2\")\n",
    "        #     print(summary.squeeze()[-max_new_tokens:].squeeze())\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = list(zip(batch[\"query\"], batch[\"response\"]))\n",
    "    reward_tensors = reward(query_response_pairs)\n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66030581-b6f7-41d7-a7e6-2466226833be",
   "metadata": {},
   "source": [
    "<a name='3.4'></a>\n",
    "### 3.4 - Evaluate the Model Qualitatively\n",
    "\n",
    "Let's inspect some examples from the test dataset. You can compare the original `ref_model` to the fine-tuned/detoxified `ppo_model` using the toxicity evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c49704-e8fa-43ae-8b26-755d810d7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 8,\n",
    "               'shuffle': False,\n",
    "               'num_workers': 0\n",
    "                }\n",
    "\n",
    "loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "compare_results = {}\n",
    "\n",
    "# df_batch = next(iter(loader))\n",
    "df_batch = collator([testing_set[51]])\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "compare_results[\"human_summary\"] = df_batch[\"summary\"]\n",
    "\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = list(zip(compare_results[\"query\"], compare_results[\"response_before\"]))\n",
    "rewards_before = reward(texts_before)\n",
    "compare_results[\"reward_before\"] = rewards_before\n",
    "\n",
    "texts_after = list(zip(compare_results[\"query\"], compare_results[\"response_after\"]))\n",
    "rewards_after = reward(texts_after)\n",
    "compare_results[\"reward_after\"] = rewards_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368195af-6428-4985-b221-443fd68990e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ['Give a title to the given news article in not more than 10 words. Mumbai-based automobile classifieds company CarTrade has converted itself from a private limited company to a public limited company via special resolution ahead of its initial public offering (IPO) this year, according to the company\\'s filings with the Registrar of Companies (ROC) at the Ministry of Corporate Affairs (MCA). Special Resolution allows provisions under Companies Act 2013 to alter its conditions such as conversion of a Private Company into a Public Company. \"The name was changed and conversion from Private to Public vide Special Resolution passed by the Members at the Extraordinary General Meeting of the Company held on April 29, 2021,\" read the filings. The company’s registered name is now CarTrade Tech Limited. The documents also stated that CarTrade\\'s co-founder, Vinay Vinod Sanghi, will take position as Managing Director effective from March 31, 2021 till March 30, 2026. Started in 2010, CarTrade offers its dealings across India with a strong network of more than 4000 dealers. Some of the features of CarTrade includes used car price information, certified used cars, on road dealers prices, and expert reviews that empowers buyers and sellers to choose the most suitable vehicles at the most affordable prices. Besides, CarTrade.com also runs other platforms like Carwale.com and Bikewale.com. It also provides services like automobile inspection, valuation, certification etc through Adroit. It also owns pre-owned commercial vehicles platform Shriram Automall India, which it acquired in January 2018 at a deal of Rs 157 crore for 51 percent stake. CarTrade is backed by the likes of American private equity giant Warburg Pincus, Singapore’s state investor Temasek, JPMorgan and March Capital Partners. YourStory has reached out to CarTrade for a comment and will update the story as soon as we hear back from them. Summary: Mumbai-based CarTrade has converted itself from a private limited company to a public company ahead of its planned initial public offering (IPO), according to filings at the Ministry of Corporate Affairs. The online automobile classifieds startup is now registered as CarTrade Tech Limited. As per reports, CarTrade is expected to go public this year and could raise about <unk>2,000 crore. Title: </s>'],\n",
       " 'human_summary': ['CarTrade converts itself to a public company ahead of IPO'],\n",
       " 'response_before': ['<pad> CarTrade converts from private to public company ahead of IPO</s>'],\n",
       " 'response_after': ['<pad> CarTrade converts from private to public company ahead of IPO</s>'],\n",
       " 'reward_before': [tensor(7.6310, device='cuda:0')],\n",
       " 'reward_after': [tensor(7.6310, device='cuda:0')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7666ce1-714c-4db1-9281-7bc59b1e7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': [\"Summarize this news article in 50 words. Arc Ventures has tied up with Japan-based Leave A Nest to set up ArcNest It includes an initial INR 50 Cr fund for ideas that are combating India's environmental concerns India’s rising pollution stats have opened up more opportunities for cleantech startups to succeed The world has become hotter in the last five years and so have cleantech startups in India. Be it monitoring air quality or solving complex issues like stubble burning with innovative ideas, cleantech startups, backed by the sharpest minds from IITs and IIMs, bet high on making a difference while running a sustainable business. With shocking reports coming in about the impact of pollution — like the centre for science and environment (CSE)’s report in June this year, which said life expectancy in India is going down by 2.6 years due to air pollution —- innovative ideas from across the country are being appreciated by government, masses and investors alike. “Our country is currently facing a great deal of environmental issues. Some of the main contributors of pollution in India include the large scale burning of fuelwood and biomass such as dried waste from livestock. There is a lack of organised garbage and waste disposal services and not near enough sewage treatment facilities,” Arc Ventures cofounder Arjun Aggarwal told Inc42. Founded by Aggarwal and Cibi Karthic, Arc Ventures supports and invests in a multitude of companies bringing ideas from several fields of expertise and delivery. The firm not only supports tech products or services but also high social impact projects. Its investment thesis revolves around improving the global happiness index through the use of technology. “We believe that radical improvements in the world can be brought bounteously by virtue of science. We search, identify, support and innovate to bring these advantages to make the human condition better and the world a peaceful place to live. The model of support goes from pushing companies to prototyping stage up to building business with them by bridging with other companies, expertise or both,” the cofounder added. Recently, Arc Ventures tied up with Japan-based research firm Leave A Nest to set up ArcNest in India. ArcNest will offer top science and engineering talent to develop advanced scalable systems that can help sustain the long term viability of life on Earth. Additionally, the companies have set up an initial fund of INR 50 Cr for seed concepts that are suitable for combating India’s environmental concerns. “Recognise the pressing environmental issues our world currently faces and divert attention towards them.” ArcNest’s began with a 24000 sq ft incubator facility located in Coimbatore. Here, it plans to offer startups a modern workplace with access to advanced tooling and hardware. It plans to tackle environmental issues like air and water pollution and solid waste management problems in India. ArcNest’s infrastructure-scale life support solutions include air, land & marine technologies. The startup hub aims to tackle the problems at their source and repair the already damaged components of the ecosystem through non-invasive environmental engineering technologies. ArcNest has also completed work on technology to fight air pollution called an urban scale outdoor air-purification system. It can clean and filter the air of neighborhoods and entire cities. “As air pollution is an ever increasing problem, especially in cities, it becomes imperative that we find ways to address this before we lose our chance to rewind. Starting with ultra-large scale removal of harmful pollutants from the air, our air purification network promises to accomplish just that,” Aggarwal added. Currently, ArcNest is working on the pilot with the system and will be revealing more details later. How Bad Is Pollution In India? “Our flood control and monsoon water drainage systems are obsolete and to make matters worse we divert consumer waste directly into our rivers. Cremation practices near major rivers and government mandated protection of highly polluting ageing public transportation,” Aggarwal said while stressing on the need for urgent action. More than 377 Mn urban people live in 7,935 towns and cities in India. The populations generate 62 Mn tonnes of solid waste every year, and only 43 Mn tonnes of waste is collected, out of which only a meagre 11.9 Mn tonne is treated and 31 Mn is dumped in landfill sites. India is home to 17-18% of global population and just 4% of the world’s fresh water. Increased urban migration has put pressure on water supply in cities and the infrastructure is an issue for distribution to rural and semi-urban areas. “Culturally, we were not tuned to treat water with respect — our lakes are a reflection of that. And what have we done to the river we respect the most?” asked Mohammad Iqbal, founder of WaterScience. Established in 2014 by Iqbal, Pavithra Rao, Sudeep Nadukkandy, the Bengaluru-based startup aims to make clean water affordable and accessible to all. With more than 700 Mn youth population, India now stands at a point of no return. If critical action is not taken by those in power, citizens face an unprecedented health emergency, feel experts. While the decision makers recognise this impending crisis, solutions which are not only sustainable but also provide rapid and effective results are the need of the hour. Iqbal told Inc42 that Bengaluru is the perfect example for inadequate infrastructure and planning disaster. “The city grew really fast, but infrastructure development is years and perhaps decades behind. The borewell boom sucked out whatever water was available, and in some areas from as deep as 2000 feet,” he says. The surface run-off of rainwater is upwards of 70-80% and the infrastructure to collect, route, treat and store rainwater — also called rainwater harvesting — at a city level is of utmost necessity today. “When availability becomes the bigger issue, quality gets compromised. We try and use whatever water we can get, regardless of the quality. We will need a few thousand lakes more to be sustainable in Bengaluru,” the WaterScience cofounder said. Can Startups and Technology Save India? The pollution reduction industry throws up a $15 Tn opportunity for businesses, making it all the more possible for cleantech startups such as AirOK, Ambee, Air-Ink and others use technology to ensure intergenerational equity. “The good thing is that since we are behind on our infrastructure in a lot of cities, we can really invest in the latest tech available now,” Iqbal added. For instance, the cleantech startups use IoT and smart metres to track and manage water usage. Technology helps in improving the quality of water when the quality of the available water is inadequate. Innovations in water purification has eased off the pressure on water sources, as water from sources previously considered unusable has now become available for usage. WaterScience started off working on solving a very specific challenge — bath water filtration. Poor water quality affects hair and skin health and its shower and tap filtration product called Cleo addresses this. Later, it introduced a water-efficient shower-filter with a 3-star (ultra-efficient) certification from IAPMO. It is said to use up to 70% less water compared to a regular showerhead. With an average cost of around INR 1500, and per liter filtration cost of less than 3 paise, the products have seen faster adoption especially in metros – where the startup has sold over 100K units and seen 44% return users for replacement cartridges. Another most innovative solutions from the cleantech space is the Air-Ink produced by Graviky Labs. The company captures air pollution and recycles it into inks. Soot, an important ingredient in ink, used to make it black, is also found in vehicular emissions. Thus, Graviky has developed an ink, called Air-Ink, made from air pollution, in which soot is a major ingredient. Air-Ink repurposes pollution and turns it into tools for art. The process upcycles carbon from air-pollution emissions and enables carbon-negative printing and production. Founded by Anirudh Sharma and Nikhil Kaushik in 2013, the startup uses a soot trap called Kaalink, which is attached to exhaust pipes of cars and diesel generators to harvest the pollutants. Each such Kaalink collects up to 95% of the pollutants emitted from the tailpipe, including particulates between 2.5 and 10 micrometres in diameter. One Kaalink can collect enough carbon to produce enough liquid to fill a pen in 45 minutes, Graviky claims. Bengaluru-based environment intelligence startup Ambee measures hyperlocal air quality data in real-time. Founded in 2017 by Madhusudan Anand, Akshay Joshi and Jaideep Singh Bachher, Ambee is on a mission to create an environmentally-informed society. “Ambee was started with an aim to empower the common man with data about hyperlocal air quality in real time that can help them understand the impact of air pollution, take precautions and find solutions,” CEO and cofounder Akshay Joshi told Inc42. In North India, where pollution has reached unprecedented levels in the past few years, stubble burning is a major contributor to the hazardous air quality. A2P Energy is working on the ground to resolve stubble burning in Punjab, the major contributor of pollution in New Delhi and neighbouring states. Founded in March 2018 by Sukhmeet Singh, A2P Energy buys crop residue from farmers and converts this waste into useful products. It not only solves the problem of pollution, but also ensures more income for farmers as they volunteer to not burn straw and sell it. The startup buys straw from farmers, processes it to develop an alternative to coal and wood in the form of pellets, which are sold to clients in food processing, pharmaceutical and dyeing industries including mega corporations such as Pepsico and Hindustan Unilever. These pellets can be used as an alternative fuel. Can Investors, Govt Back The Cleantech Movement? India is home to many more such cleantech startups. But starting a cleantech company is often more expensive at the initial stages. This poses a challenge for startups because they cannot compete on price with established players, and businesses are naturally not willing to pay anything other than the best price. A lot of administrations around the world have stepped in to level the playing field, with subsidies and incentives for cleantech. The government of India has come out with the FAME architecture (Faster Adoption and Manufacturing of (Hybrid and) Electric Vehicles), which is an example of an incentive scheme but restricted to the automotive segment. Collaborations such as ArcNest are what cleantech startups in India need to navigate through the tough initial stages. “The importance of clean initiatives, and by extension cleantech, is something that is only now coming into mainstream awareness. A combination of government initiatives like Bharat Stage VI emission norms are a great example,” Ambee’s Joshi added. He also believes that public awareness campaigns and protests against air pollution in Delhi can spur a change in the thinking of decision makers. “Major corporations are taking a step towards sustainability initiatives, and cleantech startups and companies are now able to leverage this awareness for business.” Also, cleantech, by definition, is a technology play and requires a certain kind of investor thesis, one which is comfortable with deeper technology and longer return cycles. “This is also the reason why a lot of cleantech investments come from foundations, governments, or corporate capital – notably oil and gas companies,” Joshi told us. The other major issue being faced by Indian cleantech startups is the lack of awareness for the severe need to fight environmental problems among the general population. “Cleantech entrepreneurs must offer domain specific and cost effective solutions that our govt can afford,” Arc Ventures’ Aggarwal said. But it’s not just about awareness, but changing lifestyles and habits. Fixing leaks in taps and pipes, using water-saving taps and showers, collecting water and using, rather than directly from a hose or tap are some of the examples of conserving water that Iqbal rattled off. These, he believes, can be implemented immediately to see a reduction in consumption and wastage. “Start with usage and wastage. Education and awareness are the key. We can EASILY live on 50% of the water we use currently with simple changes.” Summary: </s>\"],\n",
       " 'human_summary': ['Delhi-based ARC Ventures has tied up with Japan-based research firm Leave a Nest to create ArcNest in India to tackle environmental issues. Moreover, the companies have set up an initial fund of ₹50 crore for seed concepts towards suitable ideas for curbing environmental concerns. ArcNest aims to develop technology and scalable systems using top science and engineering talent.'],\n",
       " 'response_before': ['<pad> Mumbai-based RL Gas and Rodents Innovation and Research Co-founder Arjun Aggarwal said that India is facing a \"great deal\" of environmental issues. The company has started an initial INR 50 crore fund and is currently working on digitally integrated solutions for air and water pollution in India. \"This is an awesome impetus for us propelling the cleantech movement around the world,\" he added.</s>'],\n",
       " 'response_after': [\"<pad> US pharma giant Tenor Research and technology kick-starter Arc Ventures is between running a biotech startup and industry rival Calliwagan Electronics. Arc Ventures aims to nurture innovative designs like 'Liberty Circle' and train innovative operators using genuinely sustainable technologies. To train those who nurture innovation, the startup also invests in organic entrepreneurs. Arc Ventures was launched to evaluate fossil fuel technology.</s>\"],\n",
       " 'reward_before': [tensor(5.8041, device='cuda:0')],\n",
       " 'reward_after': [tensor(5.8094, device='cuda:0')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97dbe3d0-3060-4622-858a-9b9a79079cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': [\"Summarize this news article in 50 words. Arc Ventures has tied up with Japan-based Leave A Nest to set up ArcNest It includes an initial INR 50 Cr fund for ideas that are combating India's environmental concerns India’s rising pollution stats have opened up more opportunities for cleantech startups to succeed The world has become hotter in the last five years and so have cleantech startups in India. Be it monitoring air quality or solving complex issues like stubble burning with innovative ideas, cleantech startups, backed by the sharpest minds from IITs and IIMs, bet high on making a difference while running a sustainable business. With shocking reports coming in about the impact of pollution — like the centre for science and environment (CSE)’s report in June this year, which said life expectancy in India is going down by 2.6 years due to air pollution —- innovative ideas from across the country are being appreciated by government, masses and investors alike. “Our country is currently facing a great deal of environmental issues. Some of the main contributors of pollution in India include the large scale burning of fuelwood and biomass such as dried waste from livestock. There is a lack of organised garbage and waste disposal services and not near enough sewage treatment facilities,” Arc Ventures cofounder Arjun Aggarwal told Inc42. Founded by Aggarwal and Cibi Karthic, Arc Ventures supports and invests in a multitude of companies bringing ideas from several fields of expertise and delivery. The firm not only supports tech products or services but also high social impact projects. Its investment thesis revolves around improving the global happiness index through the use of technology. “We believe that radical improvements in the world can be brought bounteously by virtue of science. We search, identify, support and innovate to bring these advantages to make the human condition better and the world a peaceful place to live. The model of support goes from pushing companies to prototyping stage up to building business with them by bridging with other companies, expertise or both,” the cofounder added. Recently, Arc Ventures tied up with Japan-based research firm Leave A Nest to set up ArcNest in India. ArcNest will offer top science and engineering talent to develop advanced scalable systems that can help sustain the long term viability of life on Earth. Additionally, the companies have set up an initial fund of INR 50 Cr for seed concepts that are suitable for combating India’s environmental concerns. “Recognise the pressing environmental issues our world currently faces and divert attention towards them.” ArcNest’s began with a 24000 sq ft incubator facility located in Coimbatore. Here, it plans to offer startups a modern workplace with access to advanced tooling and hardware. It plans to tackle environmental issues like air and water pollution and solid waste management problems in India. ArcNest’s infrastructure-scale life support solutions include air, land & marine technologies. The startup hub aims to tackle the problems at their source and repair the already damaged components of the ecosystem through non-invasive environmental engineering technologies. ArcNest has also completed work on technology to fight air pollution called an urban scale outdoor air-purification system. It can clean and filter the air of neighborhoods and entire cities. “As air pollution is an ever increasing problem, especially in cities, it becomes imperative that we find ways to address this before we lose our chance to rewind. Starting with ultra-large scale removal of harmful pollutants from the air, our air purification network promises to accomplish just that,” Aggarwal added. Currently, ArcNest is working on the pilot with the system and will be revealing more details later. How Bad Is Pollution In India? “Our flood control and monsoon water drainage systems are obsolete and to make matters worse we divert consumer waste directly into our rivers. Cremation practices near major rivers and government mandated protection of highly polluting ageing public transportation,” Aggarwal said while stressing on the need for urgent action. More than 377 Mn urban people live in 7,935 towns and cities in India. The populations generate 62 Mn tonnes of solid waste every year, and only 43 Mn tonnes of waste is collected, out of which only a meagre 11.9 Mn tonne is treated and 31 Mn is dumped in landfill sites. India is home to 17-18% of global population and just 4% of the world’s fresh water. Increased urban migration has put pressure on water supply in cities and the infrastructure is an issue for distribution to rural and semi-urban areas. “Culturally, we were not tuned to treat water with respect — our lakes are a reflection of that. And what have we done to the river we respect the most?” asked Mohammad Iqbal, founder of WaterScience. Established in 2014 by Iqbal, Pavithra Rao, Sudeep Nadukkandy, the Bengaluru-based startup aims to make clean water affordable and accessible to all. With more than 700 Mn youth population, India now stands at a point of no return. If critical action is not taken by those in power, citizens face an unprecedented health emergency, feel experts. While the decision makers recognise this impending crisis, solutions which are not only sustainable but also provide rapid and effective results are the need of the hour. Iqbal told Inc42 that Bengaluru is the perfect example for inadequate infrastructure and planning disaster. “The city grew really fast, but infrastructure development is years and perhaps decades behind. The borewell boom sucked out whatever water was available, and in some areas from as deep as 2000 feet,” he says. The surface run-off of rainwater is upwards of 70-80% and the infrastructure to collect, route, treat and store rainwater — also called rainwater harvesting — at a city level is of utmost necessity today. “When availability becomes the bigger issue, quality gets compromised. We try and use whatever water we can get, regardless of the quality. We will need a few thousand lakes more to be sustainable in Bengaluru,” the WaterScience cofounder said. Can Startups and Technology Save India? The pollution reduction industry throws up a $15 Tn opportunity for businesses, making it all the more possible for cleantech startups such as AirOK, Ambee, Air-Ink and others use technology to ensure intergenerational equity. “The good thing is that since we are behind on our infrastructure in a lot of cities, we can really invest in the latest tech available now,” Iqbal added. For instance, the cleantech startups use IoT and smart metres to track and manage water usage. Technology helps in improving the quality of water when the quality of the available water is inadequate. Innovations in water purification has eased off the pressure on water sources, as water from sources previously considered unusable has now become available for usage. WaterScience started off working on solving a very specific challenge — bath water filtration. Poor water quality affects hair and skin health and its shower and tap filtration product called Cleo addresses this. Later, it introduced a water-efficient shower-filter with a 3-star (ultra-efficient) certification from IAPMO. It is said to use up to 70% less water compared to a regular showerhead. With an average cost of around INR 1500, and per liter filtration cost of less than 3 paise, the products have seen faster adoption especially in metros – where the startup has sold over 100K units and seen 44% return users for replacement cartridges. Another most innovative solutions from the cleantech space is the Air-Ink produced by Graviky Labs. The company captures air pollution and recycles it into inks. Soot, an important ingredient in ink, used to make it black, is also found in vehicular emissions. Thus, Graviky has developed an ink, called Air-Ink, made from air pollution, in which soot is a major ingredient. Air-Ink repurposes pollution and turns it into tools for art. The process upcycles carbon from air-pollution emissions and enables carbon-negative printing and production. Founded by Anirudh Sharma and Nikhil Kaushik in 2013, the startup uses a soot trap called Kaalink, which is attached to exhaust pipes of cars and diesel generators to harvest the pollutants. Each such Kaalink collects up to 95% of the pollutants emitted from the tailpipe, including particulates between 2.5 and 10 micrometres in diameter. One Kaalink can collect enough carbon to produce enough liquid to fill a pen in 45 minutes, Graviky claims. Bengaluru-based environment intelligence startup Ambee measures hyperlocal air quality data in real-time. Founded in 2017 by Madhusudan Anand, Akshay Joshi and Jaideep Singh Bachher, Ambee is on a mission to create an environmentally-informed society. “Ambee was started with an aim to empower the common man with data about hyperlocal air quality in real time that can help them understand the impact of air pollution, take precautions and find solutions,” CEO and cofounder Akshay Joshi told Inc42. In North India, where pollution has reached unprecedented levels in the past few years, stubble burning is a major contributor to the hazardous air quality. A2P Energy is working on the ground to resolve stubble burning in Punjab, the major contributor of pollution in New Delhi and neighbouring states. Founded in March 2018 by Sukhmeet Singh, A2P Energy buys crop residue from farmers and converts this waste into useful products. It not only solves the problem of pollution, but also ensures more income for farmers as they volunteer to not burn straw and sell it. The startup buys straw from farmers, processes it to develop an alternative to coal and wood in the form of pellets, which are sold to clients in food processing, pharmaceutical and dyeing industries including mega corporations such as Pepsico and Hindustan Unilever. These pellets can be used as an alternative fuel. Can Investors, Govt Back The Cleantech Movement? India is home to many more such cleantech startups. But starting a cleantech company is often more expensive at the initial stages. This poses a challenge for startups because they cannot compete on price with established players, and businesses are naturally not willing to pay anything other than the best price. A lot of administrations around the world have stepped in to level the playing field, with subsidies and incentives for cleantech. The government of India has come out with the FAME architecture (Faster Adoption and Manufacturing of (Hybrid and) Electric Vehicles), which is an example of an incentive scheme but restricted to the automotive segment. Collaborations such as ArcNest are what cleantech startups in India need to navigate through the tough initial stages. “The importance of clean initiatives, and by extension cleantech, is something that is only now coming into mainstream awareness. A combination of government initiatives like Bharat Stage VI emission norms are a great example,” Ambee’s Joshi added. He also believes that public awareness campaigns and protests against air pollution in Delhi can spur a change in the thinking of decision makers. “Major corporations are taking a step towards sustainability initiatives, and cleantech startups and companies are now able to leverage this awareness for business.” Also, cleantech, by definition, is a technology play and requires a certain kind of investor thesis, one which is comfortable with deeper technology and longer return cycles. “This is also the reason why a lot of cleantech investments come from foundations, governments, or corporate capital – notably oil and gas companies,” Joshi told us. The other major issue being faced by Indian cleantech startups is the lack of awareness for the severe need to fight environmental problems among the general population. “Cleantech entrepreneurs must offer domain specific and cost effective solutions that our govt can afford,” Arc Ventures’ Aggarwal said. But it’s not just about awareness, but changing lifestyles and habits. Fixing leaks in taps and pipes, using water-saving taps and showers, collecting water and using, rather than directly from a hose or tap are some of the examples of conserving water that Iqbal rattled off. These, he believes, can be implemented immediately to see a reduction in consumption and wastage. “Start with usage and wastage. Education and awareness are the key. We can EASILY live on 50% of the water we use currently with simple changes.” Summary: </s>\"],\n",
       " 'response_before': ['<pad> The San Francisco-based startup Arc Ventures has set up an initial fund of INR 50 crore for seed concepts for combating India\\'s endangered air pollutants, which mostly cost $17.2 billion compared to revenues generated from fossil fuels. As of March 2019, more than 1.0 crore solar units were being produced. What archaeologists found was a \"vast scale extraction of pollutants\" from dirt.</s>'],\n",
       " 'response_after': ['<pad> San Diego-based startup Arc Ventures has been turned over to Japan-based research firm Leave A Nest. The firm will make it an opportunity to \"inventure the core city of freedom and live in an environment that\\'s safe and going the distance\". Stephen Rao has effected a number of pollution investigations for the US. Some technology firms are working in Bengaluru.</s>'],\n",
       " 'reward_before': [tensor(5.4701, device='cuda:0')],\n",
       " 'reward_after': [tensor(5.8585, device='cuda:0')]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_resultse_results"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
