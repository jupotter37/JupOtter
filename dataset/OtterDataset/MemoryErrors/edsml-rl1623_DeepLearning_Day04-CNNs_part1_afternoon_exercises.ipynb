{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1DvKhAzLtk-Hilu7Le73WAOz2EBR5d41G\" width=\"500\"/>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9YehS8enAmDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNNs: convolutional neural networks**\n",
        "\n",
        "\n",
        "#### **Morning contents/agenda**\n",
        "\n",
        "1. What are convolutions?\n",
        "\n",
        "2. How do we use them? (`Torch` layer operations)\n",
        "\n",
        "3. Visual roadmap of a CNN\n",
        "\n",
        "4. Implementation of a network similar to LeNet5\n",
        "\n",
        "5. Training our LeNet5-like network on `FasionMNIST`\n",
        "\n",
        "\n",
        "#### **Learning outcomes**\n",
        "\n",
        "1. Have a clear idea of how convolutions work\n",
        "\n",
        "2. Understand the parameters trained in a CNN\n",
        "\n",
        "3. CNN architectures and combinations with other types of layers\n",
        "\n",
        "4. Implementation of  asimple CNN in `PyTorch`\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Afternoon contents/agenda**\n",
        "\n",
        "1. Dropout and batch normalisation\n",
        "\n",
        "2. Training with data augmentation\n",
        "\n",
        "#### **Learning outcomes**\n",
        "\n",
        "1. Implement dropout and batchnorm layers in `PyTorch`\n",
        "\n",
        "2. Perform data augmentations and understand its effects\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "<br/>"
      ],
      "metadata": {
        "id": "JgF-9hCV7x33"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmWrPqcDCp2d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K61HwZdSCp8V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm livelossplot\n",
        "!pip install torchsummary\n",
        "%pylab inline\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "_kYki018eTFJ",
        "outputId": "1a136598-acee-4b0e-edb8-68709e6baaf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycm in /usr/local/lib/python3.10/dist-packages (4.0)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: art>=1.8 in /usr/local/lib/python3.10/dist-packages (from pycm) (6.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pycm) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['seed', 'indices']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "metadata": {
        "id": "LI8sNA9feT3H",
        "outputId": "1421571f-d812-4d10-edc7-2be4466b98da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dropout and batch normalisation\n",
        "\n",
        "Modify your LeNet-5 network to include dropout and batch normalisation\n",
        "\n",
        "Only run the final training (with all the training data, no splits) with all the data and compare the accuracy and loss values with the network we trained this morning without dropout or batch normalisation."
      ],
      "metadata": {
        "id": "8CRenRypN6yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### modify the network below to add one bathnorm layer and one dropout layer (play with their positions in the network)\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5, self).__init__()\n",
        "    # in_channels=1 表示输入通道数为 1（例如，对于灰度图像），而 out_channels=6 表示输出通道数为 6。这意味着这个卷积层会产生 6 个不同的特征图，每个特征图都是通过应用一个不同的卷积核（或过滤器）获得的。\n",
        "    self.c1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # define a 2D convolutional layer\n",
        "    # 6对应于self.c1产生的特征图的数量\n",
        "    self.bn1 = nn.BatchNorm2d(6)\n",
        "    self.s2 = nn.MaxPool2d(kernel_size=2, stride=2)               # define a maxpool layer\n",
        "    self.c3 = nn.Conv2d(6, 16, kernel_size=5, stride=1)           # new 2D convolutional layer\n",
        "    self.bn2 = nn.BatchNorm2d(16)\n",
        "    self.s4 = nn.MaxPool2d(kernel_size=2, stride=2)               # another maxpool layer\n",
        "    self.c5 = nn.Linear(16*5*5, 120)\n",
        "    self.dropout = nn.Dropout(p=0.5)                         # first linear layer\n",
        "    self.f6 = nn.Linear(120, 84)                                  # second linear layer\n",
        "    self.output = nn.Linear(84, 10)                               # final output layer\n",
        "    self.act = nn.ReLU()                                          # activation function\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.act(self.bn1(self.c1(x)))                                  # activate pass through the first layer\n",
        "    x = self.act(self.s2(x))                                      # activate pass through the second layer\n",
        "    x = self.act(self.bn2(self.c3(x)))                                      # activate pass through the third layer\n",
        "    x = self.act(self.s4(x))                                      # activate pass through the fourth layer\n",
        "    x = x.view(-1, x.size(1)*x.size(2)*x.size(3))                 # flatten (return a \"flattened\" view of the 3d tensor as inputs for the fully connected layer)\n",
        "    x = self.act(self.c5(x))\n",
        "    x = self.dropout(x)                               # activate pass through fifth layer\n",
        "    x = self.act(self.f6(x))                                      # activate pass through last layer\n",
        "    return self.output(x)                                         # return output\n",
        "\n",
        "x = torch.randn((1, 1, 28, 28))\n",
        "model = LeNet5()\n",
        "y = model(x)\n",
        "print(y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "_DQSI5mVOHqi",
        "outputId": "cf75de61-ee82-49af-df1e-e06e37605f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3916, -0.1521,  0.4207,  0.1956, -0.0019, -0.3029,  0.1620, -0.1212,\n",
            "         -0.0064,  0.1238]], grad_fn=<AddmmBackward0>)\n",
            "LeNet5(\n",
            "  (c1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (s2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (c3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (s4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (c5): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (f6): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (output): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (act): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = MNIST(\"./\", download=True, train=True)\n",
        "### download MNIST train\n",
        "mnist_test =  MNIST(\"./\", download=True, train=False)\n",
        "### download MNIST test"
      ],
      "metadata": {
        "id": "Ba3ZEvLZND8k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate and create a ```StratifiedShuffleSplit``` using sklearn.\n",
        "1. Create a ```sklearn.model_selection.StratifiedShuffleSplit``` object with 1-split and a test-size of 10%.\n",
        "2. Get the training and validation indices from the shuffel-split"
      ],
      "metadata": {
        "id": "Lndb4nqhOFcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "shuffler = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42).split(mnist_train.train_data, mnist_train.train_labels)### your code goes here\n",
        "# 第一次分层随机划分的训练集和验证集索引 indice[0]是训练集的索引，indice[1]是验证集索引\n",
        "indices =  [(train_idx, validation_idx) for train_idx, validation_idx in shuffler][0]\n",
        "train_indices, validation_indices = indices\n",
        "X_train = mnist_train.train_data[train_indices]\n",
        "y_train = mnist_train.train_labels[train_indices]\n",
        "\n",
        "X_validation = mnist_train.train_data[validation_indices]\n",
        "y_validation = mnist_train.train_labels[validation_indices]\n",
        "X_validation\n",
        "### your code goes here"
      ],
      "metadata": {
        "id": "ca114gl7NTyb",
        "outputId": "8cb71053-d286-4041-8813-d5660f1db7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardise and split the MNIST dataset:\n",
        "\n",
        "The original MNIST data is given in gray-scale values between 0 and 255.\n",
        "You will need to write a normalisation method that takes in a ```torch.Tensor``` and performs normalisation.\n",
        "The mean of MNIST is 0.1307 and it's standard deviation is 0.3081 (after division by 255)."
      ],
      "metadata": {
        "id": "lSXLG4ksOUxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_standardization(X): # define an standardisation function\n",
        "  ### your code goes here\n",
        "  X = X.float()\n",
        "  X /= 255.\n",
        "  X -= 0.1307\n",
        "  X /= 0.3081\n",
        "  return X"
      ],
      "metadata": {
        "id": "pzaVKkcaORaS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardise the data\n",
        "X_train, y_train = apply_standardization(mnist_train.train_data[indices[0]]), mnist_train.train_labels[indices[0]] ### your code goes here\n",
        "X_val, y_val = apply_standardization(mnist_train.train_data[indices[1]]), mnist_train.train_labels[indices[1]] ### your code goes here\n",
        "X_test, y_test = apply_standardization(mnist_test.test_data), mnist_test.test_labels  ### your code goes here"
      ],
      "metadata": {
        "id": "NpRWm3ByOUMq",
        "outputId": "428fb224-53bc-41eb-f8a7-0eefb7ccb200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate a ```torch.utils.data.TensorDataset``` for training, validation and test data:\n",
        "\n",
        "Remember that we use TensorDataset to be able to operate on the dataset without having to load it all in memory.\n",
        "\n",
        "And remember that torch likes all categorical data to be in a ```.long()``` format."
      ],
      "metadata": {
        "id": "bDeXtYyxPhpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the TensorDatasets containing mnist_train, mnist_validate, and mnist_test\n",
        "mnist_train = TensorDataset(X_train, y_train.long())  ### your code goes here\n",
        "mnist_validate = TensorDataset(X_val, y_val.long())### your code goes here\n",
        "mnist_test = TensorDataset(X_test, y_test.long())   ### your code goes here"
      ],
      "metadata": {
        "id": "aiNJegkdPcZw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provided Train, Validation and Evaluate Functions\n",
        "\n",
        "There is an error in these functions. Can you spot it?"
      ],
      "metadata": {
        "id": "t4v_90F-XALf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    ### set the model to train\n",
        "    train_loss, train_accuracy = 0, 0 ### initialise the loss and the accuracy\n",
        "    for X, y in data_loader:\n",
        "        ### your code goes here\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        a2 = model(X.view(-1, 1, 28, 28))\n",
        "        loss = criterion(a2, y)\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()\n",
        "\n",
        "    return  train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "\n",
        "\n",
        "def validate(model, criterion, data_loader):\n",
        "    ### set the model to evaluate\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0,0### initialise the loss and the accuracy\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "           ### your code goes here\n",
        "           X, y = X.to(device),y.to(device)\n",
        "           a2 = model(X.view(-1, 1, 28, 28))\n",
        "           loss = criterion(a2,y)\n",
        "           validation_loss += loss*X.size(0)\n",
        "           y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "           validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy()) * X.size(0)\n",
        "\n",
        "\n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    ### set the model to evaluate\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "            ### your code goes here\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(-1, 1, 28, 28))\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "\n",
        "\n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "metadata": {
        "id": "eF6ACgGlPuJg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the hyperparameters of your model\n",
        "\n",
        "- Seed: 42\n",
        "- learning rate: 1e-2\n",
        "- Optimizer: SGD\n",
        "- momentum: 0.9\n",
        "- Number of Epochs: 30\n",
        "- Batchsize: 64\n",
        "- Test Batch Size (no effect on training apart from time): 1000\n",
        "- Shuffle the training set every epoch: Yes"
      ],
      "metadata": {
        "id": "alGiYGXzYDqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 30"
      ],
      "metadata": {
        "id": "u7UXTrQTX9-i"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform the training of the network and validation\n",
        "\n",
        "- Instantiate our model, optimizer and loss function\n",
        "- Set the random number generator seed using ```set_seed``` to make everything reproducible.\n",
        "- Use a sensible loss (criterion) for the multi-class classification problem."
      ],
      "metadata": {
        "id": "xmSrFBryYHNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(momentum):\n",
        "  set_seed(seed)\n",
        "  model = LeNet5().to(device)### your code goes here\n",
        "\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)### your code goes here\n",
        "  criterion = nn.CrossEntropyLoss()### your code goes here\n",
        "\n",
        "  train_loader = DataLoader(mnist_train, batch_size= batch_size, shuffle =True, num_workers=0)### your code goes here\n",
        "  validation_loader = DataLoader(mnist_train, batch_size= batch_size, shuffle =False, num_workers=0)### your code goes here\n",
        "  test_loader = DataLoader(mnist_train, batch_size= batch_size, shuffle =False, num_workers=0)### your code goes here\n",
        "\n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(30):\n",
        "      logs = {}\n",
        "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "      logs['' + 'log loss'] = train_loss.item()\n",
        "      logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
        "      logs['val_' + 'log loss'] = validation_loss.item()\n",
        "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "      liveloss.update(logs)\n",
        "      liveloss.draw()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = train_model(0.5)### train the model using momentum = 0.5"
      ],
      "metadata": {
        "id": "kJ6Xr5acYvsi",
        "outputId": "ab05c39c-ee86-473c-b628-0437ffa0d219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-87278487c20c>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### train the model using momentum = 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-87278487c20c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(momentum)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 832.00 KiB is free. Process 3777 has 14.74 GiB memory in use. Of the allocated memory 13.78 GiB is allocated by PyTorch, and 143.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the evaluation function defined above to make predictions.\n",
        "\n",
        "This method performs the same as validate but doesn't report losses, but simply returns all predictions on a given dataset (training, validation, test-set)"
      ],
      "metadata": {
        "id": "hrBcU1Edcwij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n",
        "y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"
      ],
      "metadata": {
        "id": "nWkXr0EvY0JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWavLY-Ic2Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "poGNyBmUYYXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training with data augmentation\n",
        "\n",
        "\n",
        "Reminder of Custom Datasets and Transforms (from Debbie's lectures):\n",
        "\n",
        "Pytorch allows us to simply extend the available Datasets to more custom functionality. Here we provide an example of such a custom dataset class. You can see that there are 3 functions we need to implement:\n",
        "\n",
        "- init(args, *kwargs): this will handle everything prior to actually using the dataset\n",
        "- len(self): returns the length of the dataset i.e. the number of data items\n",
        "- getitem(self, idx): this method takes an index of a specific data item and returns that item:\n",
        "  - you can do whatever you want in these functions: apply transforms, normalize data, perform another computation, etc.\n",
        "  - here we also have the functionality to apply a set of [torchvision.transforms](https://pytorch.org/tutorials/beginner/data_loading_tutorial.\n",
        "\n"
      ],
      "metadata": {
        "id": "S1a8D_LPYbSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a custom image TensorDataset:"
      ],
      "metadata": {
        "id": "R6NUgmanbdxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageTensorDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        sample = sample.view(1, 28, 28).float()/255.\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label"
      ],
      "metadata": {
        "id": "y_ktXAzfWOwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E77N_2_sIf7F"
      },
      "source": [
        "### Transforms\n",
        "\n",
        "Transforms can be used to perform manipulation of individual data prior to passing the data to our models.\n",
        "This is useful for:\n",
        " - Data-augmentation i.e. creating slightly modified instance of the data we have while preserving their labels.\n",
        " - Data Preprocessing: Such as Normalization, Histogram Equalization\n",
        " - Transforming Targets: You may have complex labels that should change together with changes in the preprocessing of the images\n",
        "\n",
        " Pytorch and especially torchvision provides a [number of transforms](https://pytorch.org/docs/stable/torchvision/index.html) for you to use!\n",
        " A nice tutorial on custom dataloaders and transforms can be found [here](https://github.com/utkuozbulak/pytorch-custom-dataset-examples).\n",
        "\n",
        " The (probably) most state-of-the-art library for image augmentation is [albumentations](https://github.com/albu/albumentations) which has been successfully applied in winning kaggle competitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EquGHuKiIf7G"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n",
        "\n",
        "\n",
        "#Often we will want to apply more transformations at training time than test time, therefore here we have two different ones\n",
        "train_transform = Compose([\n",
        "    ToPILImage(),\n",
        "    ### add a random rotation of 10 degrees here\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.1307], std=[0.3081]),\n",
        "]) ## Compose different transforms together. PIL is Python Imaging Library useful for opening, manipulating, and saving many different image file formats.\n",
        "\n",
        "#In Validation and Test Mode we only want to normalize our images, because they are already tensors\n",
        "validation_test_transform = Compose([ ### if you think it is adequate, add a random rotation here as well\n",
        "    Normalize(mean=[0.1307], std=[0.3081])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo_-JHavIf7G"
      },
      "source": [
        "### `code along` Training with data augmentation\n",
        "\n",
        "- Instantiate a ```CustomImageTensorDataset``` with data from the MNIST dataset\n",
        "- Provide the training and validation and testing datasets with the right transforms\n",
        "- Train LeNet-5 with data-augmentation on a validation set, then train on the full training set and report accuracies. Did you improve the model?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Create the ```CustomImageTensorDataset```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh2m9wJyIf7H"
      },
      "outputs": [],
      "source": [
        "mnist_train = MNIST(\"./\", download=True, train=True)   # download mnist\n",
        "X_train, y_train = mnist_train.data[indices[0]], mnist_train.targets[indices[0]]    # split in train and validation\n",
        "X_val, y_val = mnist_train.data[indices[1]], mnist_train.targets[indices[1]]\n",
        "\n",
        "custom_mnist_train = CustomImageTensorDataset(X_train, y_train, transform=train_transform)     # create train custom dataset\n",
        "mnist_validation = CustomImageTensorDataset(X_val, y_val, transform=validation_test_transform) # create validation custom dataset\n",
        "mnist_test = CustomImageTensorDataset(X_test, y_test, transform=validation_test_transform)     # create test custom dataset\n",
        "\n",
        "print(custom_mnist_train.__len__())\n",
        "print(mnist_validation.__len__())\n",
        "print(mnist_test.__len__())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0y9iJl_If7H"
      },
      "source": [
        "### Training LeNet5 with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5, self).__init__()\n",
        "    self.c1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # define a 2D convolutional layer\n",
        "    self.s2 = nn.MaxPool2d(kernel_size=2, stride=2)               # define a maxpool layer\n",
        "    self.c3 = nn.Conv2d(6, 16, kernel_size=5, stride=1)           # new 2D convolutional layer\n",
        "    self.s4 = nn.MaxPool2d(kernel_size=2, stride=2)               # another maxpool layer\n",
        "    self.c5 = nn.Linear(16*5*5, 120)                              # first linear layer\n",
        "    self.f6 = nn.Linear(120, 84)                                  # second linear layer\n",
        "    self.output = nn.Linear(84, 10)                               # final output layer\n",
        "    self.act = nn.ReLU()                                          # activation function\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.act(self.c1(x))                                      # activate pass through the first layer\n",
        "    x = self.act(self.s2(x))                                      # activate pass through the second layer\n",
        "    x = self.act(self.c3(x))                                      # activate pass through the third layer\n",
        "    x = self.act(self.s4(x))                                      # activate pass through the fourth layer\n",
        "    x = x.view(-1, x.size(1)*x.size(2)*x.size(3))                 # flatten (return a \"flattened\" view of the 3d tensor as inputs for the fully connected layer)\n",
        "    x = self.act(self.c5(x))                                      # activate pass through fifth layer\n",
        "    x = self.act(self.f6(x))                                      # activate pass through last layer\n",
        "    return self.output(x)                                         # return output\n",
        "\n",
        "x = torch.randn((1, 1, 28, 28))\n",
        "model = LeNet5()\n",
        "y = model(x)\n",
        "print(y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "lRwa3fpoc67f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2YjquZWIf7H"
      },
      "outputs": [],
      "source": [
        "def train_model_augmented(train_dataset, validation_dataset, momentum=0.5):\n",
        "  set_seed(seed)\n",
        "  model = LeNet5().to(device)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "  validation_loader = DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(30):\n",
        "      logs = {}\n",
        "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "      logs['' + 'log loss'] = train_loss.item()\n",
        "      logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
        "      logs['val_' + 'log loss'] = validation_loss.item()\n",
        "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "      liveloss.update(logs)\n",
        "      liveloss.draw()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = train_model_augmented(custom_mnist_train, mnist_validation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n",
        "y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"
      ],
      "metadata": {
        "id": "v4mqrRRnh68w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "101_0Wvph68w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHXp9ATcIf7I"
      },
      "source": [
        "### Alternative implementation of the transforms\n",
        "\n",
        "We can also define transforms directly when we get MNIST from [`torchvision.datasets.MNIST`](https://pytorch.org/vision/stable/datasets.html#mnist)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddkqUKHoIf7I"
      },
      "outputs": [],
      "source": [
        "pretransform_mnist_train = MNIST(\"./\", download=True, train=True, transform=Compose([\n",
        "    ### add your transforms here\n",
        "\n",
        "]))\n",
        "\n",
        "model = train_model_augmented(pretransform_mnist_train, mnist_validation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n",
        "y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"
      ],
      "metadata": {
        "id": "uCOtWiojiEJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j5f242yWiEJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference result from this morning plain Lenet-5 implementation for reference:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1Q9dWZOCYKE_-looC8455K5hxEokZ7i5B\" width=\"600\"/>"
      ],
      "metadata": {
        "id": "edbEiroVigoT"
      }
    }
  ]
}