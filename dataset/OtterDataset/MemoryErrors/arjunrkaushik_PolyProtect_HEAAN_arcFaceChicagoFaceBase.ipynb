{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EthnicitySelf</th>\n",
       "      <th>GenderSelf</th>\n",
       "      <th>AgeSelf</th>\n",
       "      <th>AgeRated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF-200</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF-201</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF-202</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF-203</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF-204</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.137931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model EthnicitySelf GenderSelf  AgeSelf   AgeRated\n",
       "0  AF-200             A          F      NaN  32.571429\n",
       "1  AF-201             A          F      NaN  23.666667\n",
       "2  AF-202             A          F      NaN  24.448276\n",
       "3  AF-203             A          F      NaN  22.758621\n",
       "4  AF-204             A          F      NaN  30.137931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.gender_mapping = {'M': 0, 'F': 1}\n",
    "        self.ethnicity_mapping = {'A': 0, 'B': 1, 'L': 2, 'W': 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "        \n",
    "    def getAgeLabel(self,value1):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        if(class_ranges[0][0]<=value1 and value1<class_ranges[0][1]):\n",
    "            return 0\n",
    "        elif(class_ranges[1][0]<=value1 and value1<class_ranges[1][1]):\n",
    "            return 1\n",
    "        elif(class_ranges[2][0]<=value1 and value1<class_ranges[2][1]):\n",
    "            return 2\n",
    "        elif(class_ranges[3][0]<=value1 and value1<class_ranges[3][1]):\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        folder_path  = '/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/Images/CFD/'+row['Model'] # Assuming images are in a folder named 'images'\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        image_file_path = os.path.join(folder_path, image_files[0])\n",
    "    \n",
    "\n",
    "        image = Image.open(image_file_path)\n",
    "        age = row['AgeRated']\n",
    "        \n",
    "        if(row['AgeRated']<=0):\n",
    "            age=35\n",
    "        label = {\n",
    "            'age': self.getAgeLabel(age),\n",
    "            'gender': self.gender_mapping.get(row['GenderSelf'], 0),  # -1 for unknown\n",
    "            'ethnicity': self.ethnicity_mapping.get(row['EthnicitySelf'], 0)\n",
    "        \n",
    "        }\n",
    "        #print(row['name'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/home/csgrad/byalavar/FHE/celebSet/celebSET_final_v1.csv'  # Replace with the actual path to your CSV file\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Create a list to store the indices of rows with missing files\n",
    "# rows_to_remove = []\n",
    "# count=0\n",
    "# # Iterate through the DataFrame and check if the files exist\n",
    "# for index, row in df.iterrows():\n",
    "#     image_path = '/home/csgrad/byalavar/FHE/celebSet/CELEBTEST/CELEBTEST/'+row['name']+'/' + row['filename'] \n",
    "#     if not os.path.exists(image_path):\n",
    "#         rows_to_remove.append(index)\n",
    "#         count=count+1\n",
    "# df = df.drop(rows_to_remove)\n",
    "# df.to_csv(csv_file, index=False)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to the desired size\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "transformAugment = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine([-45,45]),\n",
    "    transforms.ElasticTransform(),\n",
    "    transforms.GaussianBlur([3,3]),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "transformAugment2 = transforms.Compose([\n",
    "\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "# trainloader = DataLoader(trainSet, batch_size=128, shuffle=False)\n",
    "\n",
    "dataSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#datasetAugment = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transformAugment)\n",
    "\n",
    "\n",
    "#dataSet = torch.utils.data.ConcatDataset([dataSet])\n",
    "\n",
    "\n",
    "\n",
    "# Specify the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(dataSet))\n",
    "testSize = len(dataSet) - train_size\n",
    "\n",
    "# Use random_split to create training and validation datasets\n",
    "train_dataset, test_dataset = random_split(dataSet, [train_size, testSize])\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSLklEQVR4nO29e3Qc1ZXvv1X9KJXarZbkRmrLlo0MAgMGAjZxYkhsAphJIIQfsxLCIyGXTMaER3A8E8AhGQQTbGAyHu5gQgJ3LiEhBFZugCFZZAYnBAPjSTB+gDEBg1GM/OgIIanVbrf6VfX7w+Paex9LtpzIuCR9P2t5rV1Vp6pOldV9qr5n93dXeZ7nEQAAABBArMPdAQAAAGAoMEgBAAAILBikAAAABBYMUgAAAAILBikAAACBBYMUAACAwIJBCgAAQGDBIAUAACCwYJACAAAQWDBIAQAACCyHdZD63ve+R62trVRdXU2zZs2iF1544XB2BwAAQMA4bIPUY489RosWLaKbb76Z1q9fTx/72Mfok5/8JL377ruHq0sAAAACRtXhMpidM2cOnXrqqXTffff564477ji68MILadmyZfvd13Vd2rFjB8XjcaqqqjrUXQUAADDCeJ5H2WyWmpubybKGfl8Kf4B98ikWi7R27Vq66aab1PoFCxbQ6tWr92lfKBSoUCj4y9u3b6fjjz/+kPcTAADAoaWzs5OmTJky5PbDMkh1d3dTpVKhpqYmtb6pqYnS6fQ+7ZctW0a33nrrPus7Ozuptrb2kPUTAADAoaG/v59aWlooHo/vt91hGaT2Ykp1nucNKt8tWbKEFi9e7C/vvbja2loMUgAAMIo50JTNYRmkkskkhUKhfd6aurq69nm7IiKybZts2/6gugcAACAgHJbsvmg0SrNmzaKVK1eq9StXrqS5c+ceji4BAAAIIIdN7lu8eDF94QtfoNmzZ9NHP/pRuv/+++ndd9+lq6666nB1CQAAQMA4bIPUxRdfTO+//z7ddttttHPnTpo5cyY9/fTTNG3atMPVJQAAAAHjsP1O6i+hv7+fEokEZTIZJE4AAMAoZLjf4/DuAwAAEFgwSAEAAAgsGKQAAAAEFgxSAAAAAgsGKQAAAIEFgxQAAIDAgkEKAABAYMEgBQAAILBgkAIAABBYMEgBAAAILBikAAAABBYMUgAAAAILBikAAACBBYMUAACAwHLY6kkBMJZ59tV31PI/3nKLH7/0u9/78e4/desdvV6xID+e1apZpD7px5dfeaUf3/qdb6t2LXo3AEYdeJMCAAAQWDBIAQAACCyozAvAX8Czr2714y9ecrEfb3/994M1/8BpmXm6Hz+7+kU/Pjp+OHoDAIPKvAAAAEY9GKQAAAAEFgxSAAAAAgtS0AE4SK675bt+vOK2bxzGnhyYztf+y4/baiN+fPPy+/z4O1//mw+0TwAcDHiTAgAAEFgwSAEAAAgskPsAOACnnnmBWl7/3C8OU0/+Usp+dPvir/jxC79dpVqteurHH1iPADgQeJMCAAAQWDBIAQAACCyQ+wAYhKkzPuLHnW8Gwz3iUPH8Lx5Wy80z3vDjHW+s+aC7A4ACb1IAAAACCwYpAAAAgQWDFAAAgMCCOSkwbuk2/P9bm472413vbfmAexMcdr75sh9XOZP8+A/b3lXtZkyMEACHGrxJAQAACCwYpAAAAAQWyH1gXLE1y/FRk1vUtkp224idxxTC9HKVH4WrHLUl5xX92BUOESYfWKXSgbQfHndEk9r0XqXHj5NVBMAhAW9SAAAAAgsGKQAAAIEFch8YVxx/1DF+/OfKezUijoq4KOKj6mUrIrJY8Is6CV5va7lvRzdLaG4hzxtcLf1liwN+XBDrTZmxJOIK/YV4vWqx5YhWP853d/ylRwdgUPAmBQAAILBgkAIAABBYMEgBAAAILJiTAmOe42ad48e733vLjyeEJ6h2tnhkK4k5n7KRCp6q5o9NvcOzUtk8t4ta+vmvsamezxNv8GPLqVXtGhrq/Lj7Tzt5Q7Go2lGJ56usYo6blXRfRZcoK+Iu0Wa46ewhNQNHNPD+H/04dfQsP06/vXaYRwTgwOBNCgAAQGDBIAUAACCwQO4DY47ZZ16glt9Y92s/rhESnxMNqXaFPCdzJ6pZ2opY+mOSELpgY9z246TDCeCWIfclq7ldoiHmx60zZqh2VpjPtWMrp3V3b9+p2u3o3OHHboQTzS1DksvkWSasdzkJvb7AIl/aUBIzIg4Ld4y6Gp0u/95u3vFPW9b58QVfvEa1e+pH9xIAfy54kwIAABBYMEgBAAAILJD7wJjgzvsf8+O1z/3C2MqSVSzMEl+pWFCtEhP4mS0VZ2kraXxKnJDL+8RYxouIR75ELCZ3oVhdHW+bzEatx7Y2q3Z1ol3XEXyMDlv7RSQjLLXl+vjEuby+pnCF++qKZ9I6kaEYNzIH389xGqAb5usLO1pKtEKcsfinLLtR/OLH31Ptfn/LP/rxnKMaCICDAW9SAAAAAgsGKQAAAIEFch8Ytcgfod501VeHbDcpzj+YbRAyVy6npbEjhMQ3rU7IfVrlorD4cW8swsdzHJbGqg25z0nwckOcY3cgp9rl+liei4lPZ31MZ9aFU0k/zlic3dfbo5qRcwTHIrmPSsTnaSzbJMkl+dk1Lyxry2F9Tf3ix8GWeN7dmX1ftfurT5zJ/dv6CgFwMOBNCgAAQGDBIAUAACCwYJACAAAQWDAnBUYtp515IS8YBfkkSTEHVG3xXMzUhkbdTjhGJET1QNsoFyif7OwwL0VFHDIcJ9RSWRQzLOg5qYroH5V4rilkPE66Zd5mR3hOKRrRxyuVeUdXzENZIjXdtvWkW1QUaKx3xPxZWM+L9RREeruY8DLnpPrefdWPb1jK7hN3fVM7UwAwGCP+JrVs2TI67bTTKB6PU2NjI1144YX05ptvqjae51F7ezs1NzeT4zg0f/582rRp00h3BQAAwChnxAepVatW0TXXXEO/+93vaOXKlVQul2nBggWUy/ET3l133UXLly+nFStW0Jo1ayiVStE555xD2Wx2pLsDAABgFFPled5wy8n8Wbz33nvU2NhIq1atoo9//OPkeR41NzfTokWL6MYbbyQiokKhQE1NTXTnnXfSwoULD3jM/v5+SiQSlMlkqLa29oDtwdihS6Q9N0WqBm1zRLWuE3Vkkpdb6qr9uDGu5atYhN0orArLaWFXp6qTlM3k/iIF3Xbiao9ovM6P4w3sulBba7QTqetF4R6R6+lW7bq7ebmc5wfAbI/OQc8Jg9mK6PdAsURDURJyX8hJ+HFNg+EWIdwo3s+zhPlfr2xWzd55X0qx/H/heXgoHc8M93v8kCdOZDJ7PJUb/ucPvKOjg9LpNC1YsMBvY9s2zZs3j1avXj3oMQqFAvX396t/AAAAxj6HdJDyPI8WL15MZ5xxBs2cOZOIiNLpNBERNTU1qbZNTU3+NpNly5ZRIpHw/7W0tBzKbgMAAAgIhzS779prr6VXX32VXnzxxX22VVVpqcbzvH3W7WXJkiW0ePFif7m/vx8D1TjlM5/87KDra8Sf8nHT9ANQSy0/ix0h5LSI8YhmuUJLFAl9ZdfV7YRsFrFZMrQsYcZqR2hIRCZcqaRlt0ofS2AyY07nFxKRJaRJ2x40JiKKutyuWGL5MCo++WXjWTUk7mWlIsxmK7qvcZE1GavjTMmuvrxqp+W+XX500z//wI/v+LsDy/xgfHLIBqnrrruOnnrqKXr++edpypQp/vpUKkVEe96oJk2a5K/v6ura5+1qL7Ztk218+AAAAIx9Rlzu8zyPrr32Wnr88cfp2WefpdbWVrW9tbWVUqkUrVy50l9XLBZp1apVNHfu3JHuDgAAgFHMiL9JXXPNNfTII4/Qv//7v1M8HvfnmRKJBDmOQ1VVVbRo0SJaunQptbW1UVtbGy1dupRqamro0ksvHenuAAAAGMWMeAr6UPNKDz74IH3pS18ioj1vW7feeiv94Ac/oN7eXpozZw7de++9fnLFgUAK+vjBTJSOVsm5Hp4vmTWFiweedHRK7ZMSThKWmOcpi/mWPSvE/IuYv6Gy7oUwliBLzA1J54ZYreGCHqvz45o4p53LOS0iLW24Yi6sVNJp8Jm+zKDtctldql1RpKcXRDq6nO8y73FZpKDL+aqwoyX3RJLnoSLCmSJvCDSrVq/3499t+SNvqJroh56rU+zB2Ge43+Mj/iY1nDGvqqqK2tvbqb29faRPDwAAYAwBg1kAAACBBQazINDc/J17jDUsyVWLtTOns8TXmtTOCK4wcZVZ5sWKTi2Xz2wuSeNYLXNZIXO/vRsig8f60IqSqyXHkMg1lw4R5fL++irWGqnvYZf7LvxgSVrKWkZ+e0jE4RAvman4OWFj5rjcH8co+Hj6aSf78Rtb+beQfWU2on34V/qH/Jd/EklUYA94kwIAABBYMEgBAAAILJD7QKD5wb33DrntQ638I/FjW/mH4cWM9nbMC6NWSxZmMoo0SeUtGmHZzDGdKcSyzJKL2iITzqgnJZfLIovQ/ABWtHhHQxERdhnlAh/PMvYJRzl7MFwREqHog9FV1Ve5yZQcB3axs4SrJEPdLi6yGT8263g//sXv1/nxrd/6ttrn8k/+hgAgwpsUAACAAINBCgAAQGDBIAUAACCwYE4KBI5X3u3z4/70m0O2+9jJx/ixI+ZRiiWd1u3KuScZDpFJTkRkyXkZ0y69IudzOEU7YoXFer2PdE4PSxd1KhvtRL9Fu5AxzyMPL6aaKGx8ol3R0HVFero0bDb6Ks+UL4r+lXOqXUkUTtzPrVQXNW1Sw6BN3l73rD62iPfjJw/GAXiTAgAAEFgwSAEAAAgskPtA4PiX79415LYj4wk/bk5yanN5l5Ci9kmpZknOVbnSQ0toEbFgRw3HCZIp2sK8Vlg1RIxjyw+aLUoYWmXD7kHrfRyaZrhiWyQkV1tDtnOECWxJFXXUu0hnCpl27hpOtEpW3ce9QyDk1phIRz8iXOPH75V3q13u/fFTfrzoCxcMfWww5sGbFAAAgMCCQQoAAEBggdwHAscTP3t8yG3HtST9WP7xFqT5qWGEOtwnMSn3RUXtpOqYrvlkC3tWS9qxukNnu8nsPEtId1KqIyKquIP3Nuya7YTRrsgqLJv2EWK/cJT7HVVNjPw54dAxIFabPVM1qUSmXziiv1asPDtTSOn0yGbO9HvvXS33/d/77vNjyH3jG7xJAQAACCwYpAAAAAQWyH0gcPSntwy5rTmZGHIbo5+9pNTmVoaWBaVpa0yUgm+YEFftHFk/XshupRJLXrmizsYLiz454jzmj35lzSa3xLGRA0iWrmHP+4Rss6XohNyH25k/VpYZgpkM14wySl/J0l7qvhZzedVMlre3xHkba3XdKcnGV14bchsYX+BNCgAAQGDBIAUAACCwYJACAAAQWDAnBQKBp5bMyQ/Gjor5FzEP4kpnBMMaoVSS2zi2jfmgqFh2hAFr1HCcqHFEAreYqCkWeC6mWDRyxt2hnBvKQzUjkqncxoRQRGyzZP9C+iOtDDZCnGpeEWnrobBOQXddvo58gTtbLhmWE+LY8v4X3KJqpn4eYPG5Ys5+rGN3bxt6GxhX4E0KAABAYMEgBQAAILBA7gOB4Ge//t2w2rkuWzQUy8LhwXQ/HXJ/mdZt1HKyomZzIiKybb0+JlKnpWFEfz8/81UL1wYiopBQvEpl3mYYTlBJXB+VhWxm6ST0kPjoSocH25DuKqJdVjg/SF/bcklLk4UC35eyiAtFfU0VIeuVCuKajJR2uVSW8uEwK0W9so3Ng0+eMnTaOhib4E0KAABAYMEgBQAAILBA7gOBYN1La4fVriRkvUKe5SZdJkrLVzLzTD6VRYzsvpA1uItD2TiezFAriIy33ULic40iTcWSlMp4W9zWkld4yLL1+qMaFga4EZHdZxnPnWFRy6lc5nMVRbuSYWqrjGPLLPe5JS2PhsR9UbKlWVvKKolN4ng0PDZt3OjHJ0/5yDD3AmMFvEkBAAAILBikAAAABBYMUgAAAAIL5qRAQBjeDMWASImWj1jaadtIgbbEPIg6jW5XEenfeTHf1d+XVe2kmbj8AIXFxEwlrI/tiHksOe8UjRhO7MIJQm4xaxlaYeE4Ia4jYsxxVcT8ki2KHtoRLuTYbVxfocjXrs5jFDMkkboeFfNnZXNOSvw6oCx+NlComN7ug/PmG6/zwicxJzXewJsUAACAwIJBCgAAQGCB3AcCwbatncNq19PT78fFJi6AWBEyUmQf6VA+i/G2kpFaHhbHIJelsZChtTm2cHsQ6wsivTrsOCRxi+z2IJXAkPGcKFPXw1HZ0HBnEH0vC2cKyzbS6oVRrjSpLZRE+r6ZYi8oF4dOQVfaqTT7NQ4nnT3skuz38CTerq7uYbUDYxO8SQEAAAgsGKQAAAAEFsh9IBD09PQMut40YC0KiUgmh8l27j5yn5CYhEOEZUho0sUhHq/146ij60nJ+lSqXFOYJULX1ZlrKuNQyG4Vs69CNrPKwn2CDGQWoDiXNIQlIgpFRN/FQYp5kWVX0Max8h6VS3qbpCTPK417Db2vLE4cUrWlhveMPNTfBhgf4E0KAABAYMEgBQAAILBgkAIAABBYMCcFAoFZrG8vpidBX44L4JWFQ7d24db7uGXpwi02mBNeCjEfFDI+JmIuRadvi/kkw3XBtqUdhfKSMM7K2+Qu4ahxf0RqeVF8jPfxcBDzTVHhehEVx4vYes7NEenzsRgXGSyUdWHJkphbk3GxZMzHRQZ/FjadQYaitxtzUuMZvEkBAAAILBikAAAABBbIfSAQRO3qYbWTZqq2cH6ggpCiSkYKtHBKEAohuRGt9zkOH68siisWjTTsWDXLY3W1suCgcItw9POfLVwX8nl2n3ANCU1KYFGL+xexjY+qWHTFRVlmwUfVULhCCCeJSllfnzTAjU1guS9f1O3kFRbF/R8wLSdESjsJKXG4jhOtrdOG1Q6MTfAmBQAAILBgkAIAABBYIPeBQBCvdQZdb+b8STcJ5fYgpLHKvsWXOLSkKapuJuWnQoENWGNGjSY7xDtGxXOeI5xjw0Y9qYgqfiW6YHRVCZDC0cHVqiCFRUZeVBzPNa5dCWrSvFZs2SfJURrlCpnSvK1l5R4hNhjZfFYlJJqJrMmwziociubJTcNqB8YmeJMCAAAQWDBIAQAACCwYpAAAAAQWzEmBQBATruOSCFWpZVc8V0mjcVvMO1FITzZVXJE6LSZWrIhu55Y4NTwiDudYUdXOsXi+SmStk6xRGHHNAoFl0U6kgof0jJBb4cknmUkfMqfZxJyS43D6vkxHJ9KZ+fIWyX7HwjoVPC+Wc2LizrZ0u4wqnCiuz5hrsqNyHmrwubn9kRcuI2D8gTcpAAAAgQWDFAAAgMACuQ8EgsgQZqMF8tRyPMap6paQyqJhjsvFvNrHlgaqQrJKRLTedESMU80b6nifxgadHl9fx/KfLc4blcaz+aLaxxU55BGZ+258AlWmuczwNvLE5TGEAQa5RoHGuDhBXkiB0lRWyoVERDXiGDJV3SItJVaktCiuPecaKehDKHzWvna4g9I8DY4T45lD/ia1bNkyqqqqokWLFvnrPM+j9vZ2am5uJsdxaP78+bRp06ZD3RUAAACjjEM6SK1Zs4buv/9+Oumkk9T6u+66i5YvX04rVqygNWvWUCqVonPOOYey2eyh7A4AAIBRxiGT+3bt2kWXXXYZPfDAA/Sd73zHX+95Ht199910880300UXXURERA899BA1NTXRI488QgsXLjxUXQIBJlYbH3S9mQAWEdlhkbD885XOCNohwonxPtUWC2oxQ75KJbkPLS2T/bg+Wa/ayTpP0ahYEEatRdJmrG5RZO3t46PBSEcMyxKOE8aNsCrcdzssjW0NFwdLGODmhTuGkDbjxtdAQmiOsRhLgbHtup0tM/WkppfXnZUSpszOzPUML2vPsQd3IwHjg0P2JnXNNdfQeeedR2effbZa39HRQel0mhYsWOCvs22b5s2bR6tXrx70WIVCgfr7+9U/AAAAY59D8ib16KOP0rp162jNmjX7bEun00RE1NSk/biamppo69atgx5v2bJldOutt458RwEAAASaER+kOjs76frrr6dnnnmGqquHrhFUVaV/pOl53j7r9rJkyRJavHixv9zf308tLS0j02EQCD4y94xhtUt387xlVtRlqo5z3aOwrbPGYtUsbVlF8SNYo2R9bUODH8cbhMQX0XKTK+Q1N8LHKMo6Ufv0XJSFDw8tYMhy9FaIj72Pwaz4da/6EbFh7ipFx5A0yhXXZBlfA+EwS4mOyKZsSDaodtJgNt3H1x41FMew+HFvvsDHLtDw5L5TZ31oWO3A2GTEB6m1a9dSV1cXzZo1y19XqVTo+eefpxUrVtCbb75JRHveqCZNmuS36erq2uftai+2bes0YgAAAOOCEZ+TOuuss2jjxo20YcMG/9/s2bPpsssuow0bNtD06dMplUrRypUr/X2KxSKtWrWK5s6dO9LdAQAAMIoZ8TepeDxOM2fOVOtisRhNnDjRX79o0SJaunQptbW1UVtbGy1dupRqamro0ksvHenuAAAAGMUcFseJG264gfL5PF199dXU29tLc+bMoWeeeYbi8cHTkMHY5+zTTxRLPDfpGY4TPRmek6oIZ4OQmBuyjSKF4TLPl2wTac8F488/b/f58ZaMPIDxMRFmqoUCz/pYBT52i5E13Sz8c1MNPH9mGbNXUtpQBRodLXro4ogc5ndpt42t3b1+3JvnubpuYYiRKWg7i1xBpL4L9w7HuA09Pbxtay9f+3u7dGr/sce08vEs4XoR2UXDYdZRKHo4nvlABqnnnntOLVdVVVF7ezu1t7d/EKcHAAAwSoHBLAAAgMACg1kQCLRAFxOxloSS9QluJdLOow6bvpqp5ekdfX789PpOP86WdKp6afXbfuwKQW2flHGRD14SKdUNQpL76NE6XfvMGUk/FkYSlJigP4JlcTxZe8k1LCciMb72YpGltvR7Oq179WtpP+4QaeKdWb6GVW90qX0yZT5XVDzH1lXrDNuKuA/FIvc7o21yqX5Ssx8nG1j3dHr35ySR2M82MJ7AmxQAAIDAgkEKAABAYIHcBwLH0W3H+PHWt9arbUr0EkayjsPSkanOvfo2y1lvZDhtzzBxGJri0JuksBgXiXV9PboTHds5lsa2bZMN81pRn6qS5x7uz8FC0tPdp5Zzwueys7PHj7dlBvw4Y5Sc3z1E3DcwQH8OL7zylh//9V+xs0h1TMp92m3mtNM/+medC4w98CYFAAAgsGCQAgAAEFgwSAEAAAgsmJMCgeNTF57vx//6T+vUtoKYiokICwSZjt61PS13oa5unos5bSKnNpeKelYqIuaKsrt4IiqtTS/oPRErrwbRLp/TqeC9vTx71S0yueOWToMXU1JkywKGFT0Hlc9LZwl+1ny/O6Pb5UQ7MfeUzYpUdxoek43lVDXff0sUPdxd1H1ND3Cf8sKhI6KKU+qbfPmX/2aYvQJjHbxJAQAACCwYpAAAAAQWyH0gcHzo1FlDbstkWUYLh1gbiwrlKNvbI3ehGUlOdU7FWUILG0nosiBfZoBlqVfffl+1i4mU9E6x/g0R9/Zq+Wp3Hxu9RsV5beMx0bH5IxnuZ6nO0h6wZEf5mvqy3O7N7b2q3e/fZqltg8gn305DI081Q8QnTtXp8nVCjiyV+Zp6cwXVLtzDqeuukCnD4lqrjK+iBeeetZ8egvEE3qQAAAAEFgxSAAAAAgvkPnBYuOX8M9RynzCV7cgP/eyUEC4FsSibyrpCqotZOrtseqMwYxVZdx07tSxYdNgUtofYEPa/i1rua6me6Mcfmz7Nj/+4eYsfd5V1lt1Wof6l/sR9aEzUqnYph8W2Upkz/yKGwWy5wprjtm6usfVapz7vJiHxyZxHKenFja+BjMhylLJgyo2pdu/tYCePVJz/z1IJXRcuHudrjIf5OvLC6MIj7Xqx5MpLuN07LKR+847vqnYfv+ivCYxt8CYFAAAgsGCQAgAAEFgwSAEAAAgsmJMCHxilHTv9eOsrr6ht9ckmPy5u7/ZjXb6QyLE57VmmZZdFanPUcAiXLhXPrt/mx1sMd/NtwvPbMJlQ/HGAn+0+Us/zWNn4Du5Dr54bkrM5eZc7btlR1S5Rx2neMVsUXozqj2pOTuh08RyXkf2tztso11fV8EKyRe3T996bHIv1v9m2TbWTvuWNPC1Gp07Uz75HtfCZxSWR5coUdM3WF17k7omdXvjVr1Q7zEmNffAmBQAAILBgkAIAABBYIPeBD4xI8yQ/Tm/bpbYdN5lTvmuPafbjHlc/R2UrohCgSDvP51nyKhfyap83OzlVeqOQ+PqM/l08/2w/fuy55/3Y26fqIUt5P/z+P/rxMz/6iR8/8eP/p/YoJ1h4s/Kc+m7bWtBsaWXpLW7Loo5aFuzLcZ/e7GAZNWa0OzbJ97U+wun7Z19wrh93OUm1z/VLb6PBaKqeopYbG1h63biD0+83vL9btYvFWAtM2hN4g8Nmvw2k+z2ljtuVuzh5vrG+kcD4Am9SAAAAAgsGKQAAAIEFch84LCSrdT5XyuYUvHKCZaTWpHYv2JJjiS8c5mesfA/Lfb19upZTdx/Lf/JoZx51pGp3z63X+XHkDpbnfvyrf1ftzjvt47xQ5nP17GC7WdfSz3+xOpa2wiFhsmpkIuaFgW48InLzDNmTSpzGJ27DPnJfaAJfcbnE59qymV0c2s74hD62+lrg+33L4stUq6iQLb/yL1sG2WMPvRmW+yybJUd7Mt+TeI2j9qmzxPWJumEf/tg8AuMLvEkBAAAILBikAAAABBbIfeCwcOTxJ6hll/r9OCES3ups1YxaYg1iieWr3ABLaHmzLLzFf+ZTE/wj1lx/VrV79P7/48dfuoiz36ZOm6baRbL8Y+PF/2uRH2eznLE48Zij1D6OqL3U29XhxwOGme67HUIyLHDWXTSkZcH33uO+yxLxIUNsS4iswqjDRq+vvv62H7+88W21z7nHzvTjk2af7MdHhHUfnnr6OT+Wd8h88q0UOBOxKH50HRHyY31My5SpOv4jSAu58ORPnktgfIE3KQAAAIEFgxQAAIDAgkEKAABAYMGcFDgsnP6ZC9Xylmd+xAt9fX7Y0ZlW7SaeyI4Dsg6gW+B5KMfR6cxHtrDTxXFiW1dvn2r3y6d/68f/8ds1fpzLa9fWco7nSBKxaj9uO+ZoP07V6T6890eeh5qoNul5HplO7gjHiWhYP0/mB7ppMBK2blfIcZp44+TJflzM8XzXljc2q32ywuHhv9Pc72f7dWp/2eP5rxNTXAgyRJqKdAAp8z6lMt9XO6L3iqm8epGKj2+scQfepAAAAAQWDFIAAAACC16ewWHhk397lVr+VyH3bRMSX1evNndNWSyBWUoqE+nMcVlFiSiV5PTvGlGXqUErckTCpDbT3+fHMoWdiCghzHCntbAZ7hQhK277Y6faJ1xk2S0Z5/5MNPqaTHCaeGOSHRkqWhWkZD07SeSEDJfN6xT0jCskugLHs0/h1HJTIux4m90jssIBI2bcr1iMTWCnJnmjKfdJA5CMKO5liWvKFSpqn3Q3/yShdebJBMYveJMCAAAQWDBIAQAACCyQ+8DhITVZLdq17CSR6+Ay7AnDiDZs85+sW+aMPin9xRz9Zx2P8XJM1JxPHtmg2qUaWELLFlk2m9ioaxg1JBJiieXHzh1c14mE+SoRUVuKZb1EjOW+ZJ020E3UibpTIuMtbEiO1SLzLy50uMay1gWdEj+HZjNcV6vhxBl+vODcM9U+XTM5S/HdzZz5l89mVDuZgBcRcaGsHT8q4lk4W+L7Kt0nohFdV0tmbk455ngC4xe8SQEAAAgsGKQAAAAEFgxSAAAAAgvmpEAgsOJJscDPThHh6EBEZEfF3IWZl/0/uOa8jHgUi09gt+2EkVN97AzuQ2Mrz9nUJiepdn3dPN+0ZTM7iHe8sdGPT5yeVPtIN/dqMZkTr9Up6PLa3RKnZVu28VEV12SJCaG4MR9XrvAckBPjdt2dW/34uHO1s/hR01N+fPpH2BF92xuvq3Zd77AbRUa4cPRoc3nKCJd2iety3xoS+j4kxBxjvEHfSzC+wJsUAACAwIJBCgAAQGCB3AcCgRWr82Np51pyteOElPJcl1OdI0Ims4xHL5mebomigBGjXV2c5b/aBu4PGY4M5HIPsz2c1n3sMZxW31irU6ozOzk9Pe7wtpKRrp3LsT2DI6S7uKV9HMpFvqaiKB6o5FAiIpeltokJvr5InGXP94X0R0Q0e+4cP85n2Mi2ebL+2QDlREr6TlF0smx+rZgeFHuoCLk2n9MmvlmLl8uWcU1gXIE3KQAAAIEFgxQAAIDAArkPBAKZwRWpZReGeFlnhlWLLLewkIHKEV4fNR69okLus+V6R8tIYXEMacZaEPWtiIi6hDyWmsT9bm1lOaxr6ztqn1z3n3hB9G/3Ln19pbKQN4XBrBUa+qMq1D4qu9qo1RL3yBbHaDu6xY/TQookItrWwQazR7ZyO7uis+zyPdy/bD9nPIYN6U47U/BCMcSxlDmJiPrC4hiRKIHxC96kAAAABBYMUgAAAAILBikAAACBBXNSIBAkJ0/xY6ua3QcGCtq+wI7yrJL0lZBp5yHj0SsiVkjH8FhMuxzE4rU0GKWynmOpE27pjdOm8waHj+126DmpYoHnmlxR4K9U1kUKpYN73OFr1QUeiaJioicicukzfbpdQc5XCQdyx+a+TjtSp5Z3d7KLRtTiFPnmSXpOylb3T3yVGEYgrpgnk5n0YbGLY7h/5Ap83gQcJ8Y1eJMCAAAQWDBIAQAACCyQ+0AgmPmReX78Hz+934/rYzr9WDo0uK5IIXdlG603WUILjEq5L55Q7SJ1YjnM542RlgEnJEWxRCF5eT19ftzd1U2Svn7hjhFi2c1Ml4/ZQuITlxE22wlp0QrzfcgWdCp3Qeh9+SL3IZ9nCdOJ2WqflCjymM/y8TKOluRKouBjwWUdr2jIfVLQdMVzsSzkmDCKPw7s7PPjo2aeTGD8ckjepLZv306XX345TZw4kWpqauhDH/oQrV271t/ueR61t7dTc3MzOY5D8+fPp02bNh2KrgAAABjFjPgg1dvbS6effjpFIhH61a9+Ra+//jr98z//M9XV1flt7rrrLlq+fDmtWLGC1qxZQ6lUis455xzKZrNDHxgAAMC4Y8TlvjvvvJNaWlrowQcf9NcdeeSRfux5Ht199910880300UXXURERA899BA1NTXRI488QgsXLhzpLoFRQONHz/Dj1hbONksYGXcZId1Jd4WKsF0oa/WKytLg1OL6VJZt1HKqCPlQ6HBVITNdjQUsr4vdGrZ17vDj7m79wLWjl2WzhChw1ZjQEpojZMaouFbbcM2NCXks3tPPXTPaZYp8j6YJeU7WcorFGtQ+UZFVmBVyX29PRrUbyAvpVUh3BW16oRwxVA0wkernhPU9jk/iPh3/8bkExi8j/ib11FNP0ezZs+mzn/0sNTY20imnnEIPPPCAv72jo4PS6TQtWLDAX2fbNs2bN49Wr1496DELhQL19/erfwAAAMY+Iz5IvfPOO3TfffdRW1sb/ed//iddddVV9LWvfY1+9KMfERFROp0mIqKmpia1X1NTk7/NZNmyZZRIJPx/LS0tg7YDAAAwthjxQcp1XTr11FNp6dKldMopp9DChQvpK1/5Ct13332qXVVVlVr2PG+fdXtZsmQJZTIZ/19nZ+dIdxsAAEAAGfE5qUmTJtHxxx+v1h133HH085//nIiIUqkUEe15o5o0aZLfpqura5+3q73Ytk22bQ+6DYw9jjyeU44L619W2+RMT0FOdrgcF7RBBGXF3EkmN+DHEWOOJVbH8yAhaZBe0ZMshW5OL0//qc+Pu7rZCby3T89JuRVZmJD/lhtkcUUiamzh9G9HWjJEtGN7Uswjvbud+1Pv6M+JMLpQqeAF4b7uFozCkmJeKyZS9l3DDb4gClIWxP3PGTnoIvOd8uLnAaUi/0dFjLm0ZLKRACA6BG9Sp59+Or355ptq3ebNm2natGlERNTa2kqpVIpWrlzpby8Wi7Rq1SqaOxcTpAAAAJgRf5P6+te/TnPnzqWlS5fS5z73OXrppZfo/vvvp/vv3/MDzaqqKlq0aBEtXbqU2traqK2tjZYuXUo1NTV06aWXjnR3AAAAjGJGfJA67bTT6IknnqAlS5bQbbfdRq2trXT33XfTZZdd5re54YYbKJ/P09VXX029vb00Z84ceuaZZygej+/nyGC88InL/9aPV/32RbUtZwnRqsBxWEhKYcPhNCddF4RxaS6vdcFintOtHWI5rJDTclj3eyzr9WV4H+nO4BpZ68k6R8TsbGGapzqnCDUhLUxqS9qINnLCR/w49hobwiZrdVp9RBRylM4bUj3M53apfaShriVkdlNyd8U9l5JqtqD7Ku+/rIdYEAt2WMuZx552JgFAdIhskc4//3w6//zzh9xeVVVF7e3t1N7efihODwAAYIwAg1kAAACBBQazIHDYx57ix0edOFNtW7eVf0uXE3qTlWdJyaWS2icmZL1sjmW8WJ2W+woF3lYSUlS2T5u2domswGyW27lCkkvEtZNE0pF1rNj1Itenf5ie3/i6Hzuu2GZkv1Ve5qzH9E7O7jOMG6jeZhktL2pDleS12lpqK5RZ3ozIVEkjw1Aa1uaKvI9pMJsTNbPywiWkLLIzGxJapvzKnd8lAIjwJgUAACDAYJACAAAQWCD3gUDzlft+qpa/eSVniXa8ztKYlKUGLCMTLiuMTIXxq+2Y5q4sJdo2G732G3JfNstSmSWMVR1Zj8ooOV9fJzLjxI+Dt3RsU+12bGWT2takkMCMdMEtXRv8+I2dLAs21ulriosf44akoass/b7Po6r4wa2Q6op5neWYy/F9ye3i683ltdyaG+LHvEWRBXjxNdfrLgxuPgPGIXiTAgAAEFgwSAEAAAgsGKQAAAAEFsxJgVHF8bPZaeG19a/yhiLPb7iWNoTtF3MkXSJlPG7MNSXiPE/jurK4ovEsF+b5JZlOHhcGtbm+HrXLujfYPaJjJ6ewv9XZp9o11nGRx5kpdmCpFPQ8zx+6uO+/7+AU9AZHp4m3tXCfTj2pzY+tEM9PRcL6a6Aknl1zImV/wDCizQgT3V5RVbu7P6/a5Qb4/2O3dAmJ83k/9zdXEgCDgTcpAAAAgQWDFAAAgMACuQ+MLsKcGl4U7gVuiWM7ElK7ZIXBqZNnuSlX1KnqebFs25y6bRnGqnIpNoGXhJcr5V3dh1++xKnl3cJl4qQTZqh2mX6WAl/Y2ufHFdIyXixW58cNcZbXtvRqs9iCkBOPE2XesqIPbkynrYdlar54jM3ntYzXK44hDWZlmjkRUUGmtIv1NY52mQBgMPAmBQAAILBgkAIAABBYIPeBUUU8xtlvLrGkJivJG4YH5Aq5KSnkwlxBZwEOiP1KwuEhEjae5UQ7uS0rysqXczpz8LiWlB/vEG4WiZiWEpsbuGy6JbLuypaW5LKidlVWnKuVtITZ3Ngw6D7pnV1+3JCsU/vUiPu1W8p4A9pFQ949KfENlLTcVxbPwmXxlePEUD8OHBi8SQEAAAgsGKQAAAAEFgxSAAAAAgvmpMCoYuIkntuRDuQy67lMeq5J1Pqj3hy7JtQbjuFZUcSvWjg8OEYRv7CYs+nu6vXjXD+nf+cNhwhLTD3FxDwRxfW8jOXwPJslCh2GKarakUhxt1PcLmrra+oRxQ13CIcIOypcJYyU8WSZ75+o40i5XToFPd3Dc1y9u2Rqvz5eUf53iGuKx2sJgAOBNykAAACBBYMUAACAwAK5D4wqUqmWQde7KtZyU0hITH0iDTuT044H6T5RzFCsN9PEpQbW1dPnx2XhWNGT16ngGeFTEU1yccRYskG1a4hw32O26Hfe0ByFoUVJXF/WkO7yQhLdlhMp5JkBP0wYh86VWKqMRNjpQhZ7JCJKZ1g6lca9BdeQW4WZbVj0O3mEvnYABgNvUgAAAAILBikAAACBBXIfGFWkJrPcF47IZyzWrFxDvhL+sirvr3eXdlCwwywFWuIghZKW7mTWXTo/+HkLEf3RijWwtBWu5hpUtiFNhkvcp4qsY2W4OESE2WusLDIWY9qI1rJY0iwVeFtXSbhA6NtAZVfIni7fk7JxHwZkl2QmYlj3oSgkSFc8FycbkwTAgcCbFAAAgMCCQQoAAEBgwSAFAAAgsGBOCowqJiQ4lds25j72IueMiPSTWETMFcl0dCKiqEiPFoYMFDZc0IsWnzcvPkJZkYIeCWvnh2iU20XkPFS2T7XL5NgVoq+P+7e7oCeO6iewW0OyoZ775hZVu1xWLIs5vKJwsMiUdYHGfJlT0F3hsG5V9LxYf172ibeVjTT4UqUySCui1ORWAuBA4E0KAABAYMEgBQAAILBA7gOjF4tlpLCQ+EzHCfks5oo06gGjVVakddvikxGxtayYt4S0JU41IOSwoiGNuUKus0VhwnhtQrXLl/lcIZEKfkRtne5sjNO3t2znYovhqDaibRTLXXkh3dVyarosrkhE5IrU90yB9wm72jR3QFxTSdyIckU7TlBIyol87CmtkPvAgcGbFAAAgMCCQQoAAEBggdwHRi1xIYH1iLpO+z55CfeIMkttsh4VEVEuz5lwcUdk8BnZam6Yl6URRE4YuNbbuhfV4lRd6R4//q/nN+o+5FiEdET/qh1tcpstvM3xAMuCbpXO1HOEbpmazK4XBZGJaDlacpSGvCVxNyuG40SpJJ0kmLApj4r751TzdRx38ikEwIHAmxQAAIDAgkEKAABAYIHcB0Yt9Y2Nfrz1nQ4/LpXN7D5eDovnsnJZy1eukKncCrczS8HnxY9YM7t4WzbDP8SNxrXk9Vbnn/x4Rzrjx5b5nCjLtZPICDRKslfENRVFcamCpzPregf4gDu27PDjIyaKmlZN+mvAqebMv4LIeIzs80zLy/IH1K5lfq1wH8IRzjY8+aSjCYADgTcpAAAAgQWDFAAAgMCCQQoAAEBgwZwUGLVMm36MH2/43Ro/LhoFAqUDhRWRzhSastivKOarcoa5a1ZUUezu5vmlNze/48evep4+togbhblrmIyCiiKOiLmmetJOEnJbH/G8UdH4SHeLq3yNOMV+y/vc71MjMbVP3bS4H+fFerOYpHL2EPNQRaOhnK+KJ1HoEBwceJMCAAAQWDBIAQAACCyQ+8CoZd65F/jxvz/y0yHbWaHBzWdNxwlL1JoqucK8tmxKctzODXGc9zjtvEy6rtOHohP9+PSjp/nxSfUNql04y+fK9PT7caGg+zC5hfezGliuSxsmsG/1sEFsYjOn6b8nhLyphtFrqczypszmdw3HiWJZpsGL/U25L8wuE8eeeDIBcDDgTQoAAEBgwSAFAAAgsEDuA6OWU+awQakj6iMNFPOqXbHCMpV0koiEDMNUoVIVSyxRlSs6u68kPFydKJeJ/+ipM/3YNlwv2pJ1fjx7ejPv09qi2tWK58aeNJvmSumPiKi5ld02CsIp47/e2a7akcvXOO1oPu9khy9iYpOWHHe8y8dQMqMh45XEI67c4urbSuUyS6czZ51GABwMeJMCAAAQWDBIAQAACCwYpAAAAAQWzEmBMcGxJ3Nq88urnlfbxJQI5csyWTpstAuJdqJQX1Q7msv5l1iM564sscGZoJ//rFi1H7+3i+fM3krrOaTW+jo/jjbyPvX1RoHGMhdH7NzZ5cd/2LJVtesRGelhW1xfnlPTs319ap/8AG9TTvHGI610kihJl/aw+bXC5w1beC4GBwf+YgAAAAQWDFIAAAACC+Q+MCb40lf/zo/XvbBabbNCrPeVyqLooZFSXRYuE7rOoXZxkI92tpD7asJsAvt+V5fcg7orfIwpSTbGzVq2ardlB+8XE/sYPaD3RYHFtNjoxrRZ7MDObj/e0cVFD8NCfiz36GPnRFFHKemVDTeLgaKUAvnaXSHvEREVhN6a6ekmAA6GEX+TKpfL9K1vfYtaW1vJcRyaPn063XbbbeSKLwTP86i9vZ2am5vJcRyaP38+bdq0aaS7AgAAYJQz4oPUnXfeSd///vdpxYoV9Ic//IHuuusu+qd/+ie65557/DZ33XUXLV++nFasWEFr1qyhVCpF55xzDmWz2f0cGQAAwHhjxOW+//7v/6bPfOYzdN555xER0ZFHHkk//elP6eWXXyaiPW9Rd999N91888100UUXERHRQw89RE1NTfTII4/QwoULR7pLYBxw8qkn+PG0o49R297Y+IofSzOEiJFpJo1RLZHDFzE+JmGxW6nEElgsxu16SfN+N8t4G0Vm3u5p2tw1ISW1Pq755Ja11JYLc8Zh3maJr2PnDtWuY2sn7yOOUW8LY9y8dugYKHAGZEVcX9kd2qHDlffE6Gu5wg17uyH3gYNjxN+kzjjjDPrNb35DmzdvJiKiV155hV588UX61Kc+RUREHR0dlE6nacGCBf4+tm3TvHnzaPXq1YMes1AoUH9/v/oHAABg7DPib1I33ngjZTIZmjFjBoVCIapUKnT77bfTJZdcQkRE6XSaiIiamprUfk1NTbR169Z9jkdEtGzZMrr11ltHuqsAAAACzoi/ST322GP08MMP0yOPPELr1q2jhx56iL773e/SQw89pNpVVVWpZc/z9lm3lyVLllAmk/H/dXZ2DtoOAADA2GLE36S+8Y1v0E033USf//zniYjoxBNPpK1bt9KyZcvoiiuuoFQqRUR73qgmTZrk79fV1bXP29VebNsm27YH3QaAyWf/5hq1fMt1f+vHyvEgpP/8i6KoX0gUQCyUdKp6vsBzOLY8XC07ok9rjKt9OtOc1v2GmCda+/pm3XlxLkemuuusburJc1/zwlGDIvpBLyI+NynhZuFEeX3amJOSnhrK3dy1jFainZjPk3NQRERuka8922PO1gGwf0b8TWr37t3qtxVERKFQyP8jbm1tpVQqRStXrvS3F4tFWrVqFc2dO3ekuwMAAGAUM+JvUp/+9Kfp9ttvp6lTp9IJJ5xA69evp+XLl9OVV15JRHtkvkWLFtHSpUupra2N2traaOnSpVRTU0OXXnrpSHcHAADAKGbEB6l77rmHvv3tb9PVV19NXV1d1NzcTAsXLqR/+Id/8NvccMMNlM/n6eqrr6be3l6aM2cOPfPMMxSPx/dzZACGx+yPzFHLUnwyBSuJFeKtUkEznRbCljScHVyMqJ+g5elSYoJY4BTvd7W1BfUJKTEn1jsRbXJbjLLDgyxGWCecJIiIErV83rjY5gq1I1yOqn2iIlG/ovU+1a5cEQ4dopika9wTSxykpxcp6ODgGPFBKh6P091330133333kG2qqqqovb2d2tvbR/r0AAAAxhAwmAUAABBYYDALxhyTUnVqOSxkvbJ4LovsUyBp8OMZKhc5Dn9soiK9ryDOUzA+WjGHpbbWpqQfp2q1IWxRyH95V9a00vKh7Gq+yBJhOGxkwYosxaKQKaV3RLhACldkObpC+DQNeaWRrKzSRWXtTGF5fILeP+0kAA4GvEkBAAAILBikAAAABBbIfWDMExNmql19bO5qkc5qs2yWw0LSRdbI7jPUP5+8+CFufVzLbqnJtX5czLL3ZKXgqHYh8dwoDW9tW39UjTw7P7KM0u19on5WRsh6OSHpxUr6WTVblPofS3olw2CWIuL+yVtU0tUMnLAoW49KB+AgwZsUAACAwIJBCgAAQGDBIAUAACCwYE4KjHkch+d9Ij1cSLA7o3Ovk/XseBKzeZ+SMRWTL8gVYnZIPPIVKaH2sUQf4iIt3CrpPljSqNWcA1INxTHE9FehopuFcmJeS/QvW+D1xbJpoMsJ5UVR9ND05JTzVYXdfX4cN75VwqKvuX7MSYGDA29SAAAAAgsGKQAAAIEFch8Y80SjnFqeEG4RpZyW03ozbOnaUMsp4xHDxCEn6i8lYtzOFga1ubzyYKBsnmWzmMXnTRiFokT3qOxyinfedIUI8X6qzJPx2BkWGl84wrJeZmef6Js+uDSWkGaxEaOm2/t9LN1FqoTJraNT+wtCPiwUzdpVAOwfvEkBAAAILBikAAAABBbIfWDME7FZfrLDLP3FwjqrLSPkvq07ue5RqkHXOSuIdL/sAMtXjpC53Jx2qbBCLI01RPlj15DUdaLCQv6zxcfTTKzr0WrikJRF9mF3D/e1S2Q59udzap8BkdEnTDSoXDKyAMW1T4lz9mKYjBRD4d4hv3B2pvv82DQFBmAveJMCAAAQWDBIAQAACCwYpAAAAAQWzEmBMU/MmeDHPSK/OhbRz2hThOPEjizPt+wwbM8TjnAW3yXSty2ed0roaSwSWfDkCreHmK3T4OuLfGy3xH3oMTK3s2JOyo6KfYzHzr4BPtd73T1+XBBO52XTcaIoih5aPM/Wl9VzV401XLCxIcZfJQUj/d6SLu2if0//7Kd+/OXrvkoADAbepAAAAAQWDFIAAAACC+Q+MOaZ2MCyVKdIj4472kEhLrSoiDCCeOtPPapd2GrwY0umeAsHBjNd2xUuFTFx3nxePyfGwiyV2eIQfTmd1j0gzF1locN4rS6imMmxrNfd18frRX/yhjwne57N8bZIRafVOyG+jrAlHTCMZ1/hgCuP8NMf/l8/htwHhgJvUgAAAAILBikAAACBBXIfGPNIT4c6UddJGp8SEUmjhITDe7UldW2odG6XH+eIpayQEMoGctq0NWsLSU4cu9qQxuocPoYrnB/6i9qI1o5Wcztx3nSvPl5mF19jOtPP/RYZhrmCzjAseBz3E+9/ZLW+DxVxv2Rfq23dh6LU+ER2ZfeOHX68/H//QO2z+PqFBAAR3qQAAAAEGAxSAAAAAgsGKQAAAIEFc1JgzNMtnBaiNs8HVcp6LqZcGXw+aOIEnaruCKfyzd08zxMR1REtI11bFkqUxg3VYf0RfE/ML4Ut6SSh3dJdV6SQC/eIgj4t9Q4M+LG+WnaSyJFOl5dPrtOj7NYxRaTyExEVxT0KiymzkPHoGxZnlmdyxT16/bVXCYDBwJsUAACAwIJBCgAAQGCB3AfGHL/+1dNqOZdjfa1cEnnTFS1zOUKnkqqZbXxKevtZamsQ6dY7RNHEcNRIBS+y7GZxuM9TovSLcKqquD+ebucSr8io9RrpU6GVQE4t18ntRK01LPG1Jtldozqij14WGp8lrmSgaLjhCqKiACKFeP9sT88grQHAmxQAAIAAg0EKAABAYIHcB8Ycr72iM8Vkpl5MuD2YOpc0iy0Ig9h0T1a1c2QdKpGBN6WeD9ib1+JaiVi6KwupzlDxqF/EEY+3mjKeXDaPcbA0V0XVcirG98gts3Rn9iHmiGw/V2TwlfWzryUk0YI6iBAjS9qhA4C94E0KAABAYMEgBQAAILBgkAIAABBYMCcFxhx/eGWjWi4L5+1Cgec+4rZ2cZBTVIUSz7HUxfScTTjC+8XEfFejzY4TScNZPNzFfXhbuEDsj9KBmxwU1SI+SqSZ19iGw7pYrBZp5moOinRhyHyZU9odo5hkQUxEuS5flXT4cCL6/wKAveBNCgAAQGDBIAUAACCwQO4DY47udFotVwuXg4gogeiYVhLimc0R5rPlgtmKZaqYkLYKZV6vBUKitkZ2bkiIgojpnoxqt93TMuHBUmUsy/TyFlG80ZKmr2UtLCbi3C4RY4mvXNRFIktC6nSEUW7BMO61I4N/zVQsTkFPNiYHbQMA3qQAAAAEFgxSAAAAAgvkPjCqkMqbPUSbqPFXHRFGplHxJ18saVmqWjhJJOJs9eoYNZ+yec7Ok+a1UZH95tj6+S8vMtzqhOtFrCmu2h0lTBjcIstpmZzOCHStwV0vTOrr+PiuuN6S0DCT8Vq1j3TUyGdZjoyE9XlMY9q9hI3+lKVXhZD4yiIDMtUybYijgfEO3qQAAAAEFgxSAAAAAgvkPjCqyO1mec2uiQ3axjF+dFruYYnJFT/sNeWqiJD1wvKXqq5+lnNc+eNUXl8pS1lLH1tmBIbFD1otQxqTy4lalhyTMd3bvOhTWZwsb/yIuCDK1rvCNDcpSsE7xu9oo6KvEYfvidnXcJh3zIsMwYHC0BmKlpBebfGr4eNOOWXIfcD4Bm9SAAAAAgsGKQAAAIEFgxQAAIDAgjkpMMrg5yrpkyCnVaYd2ar22JreLPYWz2WuLuOXL7CjQsxip4ZYzFHtZCp2VMS9GU4TzxpFDy3RTqanZ/vzql1BzpSJQoJxI/2bxPxS/wDP0xUNV9qYI65DzHFZwhUiahjtypqO8rTRsG4nZ55Cot/hkL6vpSHmARONKT8+/uSTCIDBwJsUAACAwIJBCgAAQGCB3AdGFZl+4fAQZSkrIuoeHTXzRLXPWy/8yo/rhamsZdrACnktl2PpL2xkuseEPJYQsSPS1qP92pW2W5jKlsR5wpZOLe8XDhaZLKfO54yaTzmZ5i2kyahh5uoIic6S9ZtEannMcMeQ6fJSEZW1oIiILFEDKizaGX68SmKtiD58eMEn/bi1uYkAGIyDfpN6/vnn6dOf/jQ1NzdTVVUVPfnkk2q753nU3t5Ozc3N5DgOzZ8/nzZt2qTaFAoFuu666yiZTFIsFqMLLriAtm3b9hddCAAAgLHHQQ9SuVyOTj75ZFqxYsWg2++66y5avnw5rVixgtasWUOpVIrOOeccymazfptFixbRE088QY8++ii9+OKLtGvXLjr//POpUqkMekwAAADjkyrP87w/e+eqKnriiSfowgsvJKI9b1HNzc20aNEiuvHGG4loz1tTU1MT3XnnnbRw4ULKZDJ0xBFH0I9//GO6+OKLiYhox44d1NLSQk8//TSde+65Bzxvf38/JRIJymQyVFtbe8D2YOzQV+QHGSmVTRAqV8eWTrXPDRfx31TSZrlJylpE2ki2IrLfIsajnCNS3mqE3FcWrgu9RtZeOsvL3TmOTYcIaSTbI8o37dZdUJmNKRE31GgJMy7qQUVFcl5MyJ4xQ/SXNaTMUvCSvLhHA4WSWK/va0Fc44DFRey/+ZMn/fi0004e8jxgbDLc7/ERTZzo6OigdDpNCxYs8NfZtk3z5s2j1atXExHR2rVrqVQqqTbNzc00c+ZMv41JoVCg/v5+9Q8AAMDYZ0QHqfT/VERtatKToE1NTf62dDpN0WiU6uvrh2xjsmzZMkokEv6/lpaWkew2AACAgHJIUtCrqnQRa8/z9llnsr82S5YsoUwm4//r7OwctB0AAICxxYimoKdSe9TxdDpNkyZN8td3dXX5b1epVIqKxSL19vaqt6muri6aO3fuoMe1bZtse2htHIwf6qI8D7VrCLPt1qP0m/a043m+o+/1NX7s2PrPvyTmWBxROdE15ljkVFZRuIxHbZ4Pam7QGrsyEBd53V3C5YJIzxUVRJHCAWPmWHpgxKL8cBczriku0sujog8xcR9TDQndB2GLLueacnmdXK7uirimckm3k+ny0+Z+3I9PwjwUGAYj+ibV2tpKqVSKVq5c6a8rFou0atUqfwCaNWsWRSIR1Wbnzp302muvDTlIAQAAGJ8c9JvUrl276O233/aXOzo6aMOGDdTQ0EBTp06lRYsW0dKlS6mtrY3a2tpo6dKlVFNTQ5deeikRESUSCfryl79Mf/d3f0cTJ06khoYG+vu//3s68cQT6eyzzx65KwMAADDqOehB6uWXX6YzzzzTX168eDEREV1xxRX0wx/+kG644QbK5/N09dVXU29vL82ZM4eeeeYZisfj/j7/8i//QuFwmD73uc9RPp+ns846i374wx9SKGSWoQNgaCYM86/3ry69zI8f/cdXeENF64VyqVDkJfOvsiCcF/Qv+4R0Z+StJ4SEFg5xinfMMI7tFo4TjtAIUzS05GiL1Pm4o48nlxviLEFWR7jnMaPoYbHAEmZJGlsYn8+iTDsXhre5vL6vA+Jr5jNfuZr7TQAcmIMepObPn0/7+2lVVVUVtbe3U3t7+5Btqqur6Z577qF77rnnYE8PAABgHAGDWQAAAIEFBrNgzHP2p8/34zVPP+nH2156TrUrl1kCKxSFGashyYUdQx/7H/LCcUIei4ioYonjiTS7qUntXlsfYxEsI5wpcoYzRUGcyxYmsvEJuvZVvJodHsIh0SchF2Z25UgR4v65FY5zRd0Hme3XIxw2Bsq63QmfutiPzz57HgFwMOBNCgAAQGDBIAUAACCwYJACAAAQWDAnBcYVX775H/349ssuUNvKfV0ci9zrTEGnf5fFnEsiJuaALJ4bKpS0C3pZpGi7JX42dIxUdTXdJRZkocU9xxdu5yIz3Jg+o/wAu6pbIqXdVe30ThFxudk8769LHhLl85xyXxaFHEvxpGq38JbbCYA/F7xJAQAACCwYpAAAAAQWyH1gXNE4hY2P53/pq2rbz++8hReKLG5Jo1ciIlc4TkSF24NU5Czj+a8gJEIpm7mu6SRhLO/dv6DFtqIwva0o91rTddcaNJSnMZ9UI0pa5K15w2BWuuZm8nzAy779TdXs+LbJBMCfC96kAAAABBYMUgAAAAIL5D4wbvn//teVannD77jW1JqnfurHtqXdI8KucIXIsltDMs7rLUs//0n5T9ZoKpspc7Iuk8iYqxjNBqT0Js5VMuRCJTtagz+TOo5h9SpOli8KJ4mi7mxPjrP7Tjj/Ej/+4jVaRgXgLwFvUgAAAAILBikAAACBBXIfAP/DrT+4z4+/unOnH7/x/H+qdnGR7ZdTKXPyR75aQpNPg1GRPCd/5EukS9gPlFh3qxgyXlH0IS+MX2VtKSJd0l5KiTGHf4RsZiJK49ickPi6+7QRbeOHz/Ljpf/nB35ci28VMILgTQoAAEBgwSAFAAAgsGCQAgAAEFigHgMwCMv/35N+/MVzzlTbdohiiVGryo9d13R7YOQclXwyLBkFAnMiPX2gwCne+bxup3bbT5a5Jeau5PxURDjRFsp6visvlrtybDBrz/iwarfiyV/6cWPcSGMHYITAmxQAAIDAgkEKAABAYIHcB8AgOCJz+99+9YzatkQ4Vfz+yZ/4cURIcJldup6UE+WPWlgWgNrfc6JU4UJ6U0Wcy4mw5Eiu9qbQ6eV8wHyB+1coarkvneODp04724/vffIp1a4xrmtcAXAowJsUAACAwIJBCgAAQGCB3AfAAait0bLWvY/92I8fffBTvP5bN/hxX9c2tU/MtkXMH7tiSZu2yrL1YZGBF3aNj2pYukywFlhxTStapijKvQ8IZ4pKrS73fvH1X/fjL9+42I+dKgLgAwdvUgAAAAILBikAAACBBYMUAACAwFLleZ53uDtxsPT391MikaBMJkO1tbWHuzsAEBFRTy+7hC/9+tfVtld/yUUUJ9qc8l0r3MiJiHJ5PkZFZYbr50lX5KDnB3iuKaMz3xVOIuHHZ15+hR//9XV/r9odfVQL90GsN7LgAfiLGO73ON6kAAAABJZRmd239+Wvv7//MPcEAKa/n9+CCsWi2lZ2WbAoibho1ImS2/SblBY8XHk8sam8H11E9mGgwDWjstmsaic/V3iTAoeKvX9nBxLzRqXct23bNmppaTlwQwAAAIGms7OTpkyZMuT2UTlIua5LO3bsIM/zaOrUqdTZ2Tmu56b6+/uppaUF9wH3gYhwH/aC+7CHoN4Hz/Mom81Sc3MzWaZ9v2BUyn2WZdGUKVP818Xa2tpA3fzDBe7DHnAf9oD7sAfchz0E8T4kRDLPUCBxAgAAQGDBIAUAACCwjOpByrZtuuWWW8i2x3dVUNyHPeA+7AH3YQ+4D3sY7fdhVCZOAAAAGB+M6jcpAAAAYxsMUgAAAAILBikAAACBBYMUAACAwDJqB6nvfe971NraStXV1TRr1ix64YUXDneXDinLli2j0047jeLxODU2NtKFF15Ib775pmrjeR61t7dTc3MzOY5D8+fPp02bNh2mHn8wLFu2jKqqqmjRokX+uvFyH7Zv306XX345TZw4kWpqauhDH/oQrV271t8+Hu5DuVymb33rW9Ta2kqO49D06dPptttuI1d4Io7F+/D888/Tpz/9aWpubqaqqip68skn1fbhXHOhUKDrrruOkskkxWIxuuCCC2jbNl1ROhB4o5BHH33Ui0Qi3gMPPOC9/vrr3vXXX+/FYjFv69ath7trh4xzzz3Xe/DBB73XXnvN27Bhg3feeed5U6dO9Xbt2uW3ueOOO7x4PO79/Oc/9zZu3OhdfPHF3qRJk7z+/v7D2PNDx0svveQdeeSR3kknneRdf/31/vrxcB96enq8adOmeV/60pe83//+915HR4f361//2nv77bf9NuPhPnznO9/xJk6c6P3yl7/0Ojo6vJ/97GfehAkTvLvvvttvMxbvw9NPP+3dfPPN3s9//nOPiLwnnnhCbR/ONV911VXe5MmTvZUrV3rr1q3zzjzzTO/kk0/2yuXyB3w1+2dUDlIf/vCHvauuukqtmzFjhnfTTTcdph598HR1dXlE5K1atcrzPM9zXddLpVLeHXfc4bcZGBjwEomE9/3vf/9wdfOQkc1mvba2Nm/lypXevHnz/EFqvNyHG2+80TvjjDOG3D5e7sN5553nXXnllWrdRRdd5F1++eWe542P+2AOUsO55r6+Pi8SiXiPPvqo32b79u2eZVnef/zHf3xgfR8Oo07uKxaLtHbtWlqwYIFav2DBAlq9evVh6tUHTyaTISKihoYGIiLq6OigdDqt7ott2zRv3rwxeV+uueYaOu+88+jss89W68fLfXjqqado9uzZ9NnPfpYaGxvplFNOoQceeMDfPl7uwxlnnEG/+c1vaPPmzURE9Morr9CLL75In/rUp4ho/NwHyXCuee3atVQqlVSb5uZmmjlzZuDuy6gzmO3u7qZKpUJNTU1qfVNTE6XT6cPUqw8Wz/No8eLFdMYZZ9DMmTOJiPxrH+y+bN269QPv46Hk0UcfpXXr1tGaNWv22TZe7sM777xD9913Hy1evJi++c1v0ksvvURf+9rXyLZt+uIXvzhu7sONN95ImUyGZsyYQaFQiCqVCt1+++10ySWXENH4+XuQDOea0+k0RaNRqq+v36dN0L5HR90gtZeqqiq17HnePuvGKtdeey29+uqr9OKLL+6zbazfl87OTrr++uvpmWeeoerq6iHbjfX74LouzZ49m5YuXUpERKeccgpt2rSJ7rvvPvriF7/otxvr9+Gxxx6jhx9+mB555BE64YQTaMOGDbRo0SJqbm6mK664wm831u/DYPw51xzE+zLq5L5kMkmhUGif0b6rq2ufJ4exyHXXXUdPPfUU/fa3v1WFwlKpFBHRmL8va9eupa6uLpo1axaFw2EKh8O0atUq+td//VcKh8P+tY71+zBp0iQ6/vjj1brjjjuO3n33XSIaP38P3/jGN+imm26iz3/+83TiiSfSF77wBfr6179Oy5YtI6Lxcx8kw7nmVCpFxWKRent7h2wTFEbdIBWNRmnWrFm0cuVKtX7lypU0d+7cw9SrQ4/neXTttdfS448/Ts8++yy1traq7a2trZRKpdR9KRaLtGrVqjF1X8466yzauHEjbdiwwf83e/Zsuuyyy2jDhg00ffr0cXEfTj/99H1+grB582aaNm0aEY2fv4fdu3fvUzAvFAr5Kejj5T5IhnPNs2bNokgkotrs3LmTXnvtteDdl8OWsvEXsDcF/d/+7d+8119/3Vu0aJEXi8W8P/7xj4e7a4eMr371q14ikfCee+45b+fOnf6/3bt3+23uuOMOL5FIeI8//ri3ceNG75JLLhn1qbbDQWb3ed74uA8vvfSSFw6Hvdtvv9176623vJ/85CdeTU2N9/DDD/ttxsN9uOKKK7zJkyf7KeiPP/64l0wmvRtuuMFvMxbvQzab9davX++tX7/eIyJv+fLl3vr16/2f4Qznmq+66ipvypQp3q9//Wtv3bp13ic+8QmkoI8k9957rzdt2jQvGo16p556qp+KPVYhokH/Pfjgg34b13W9W265xUulUp5t297HP/5xb+PGjYev0x8Q5iA1Xu7DL37xC2/mzJmebdvejBkzvPvvv19tHw/3ob+/37v++uu9qVOnetXV1d706dO9m2++2SsUCn6bsXgffvvb3w76fXDFFVd4nje8a87n8961117rNTQ0eI7jeOeff7737rvvHoar2T8o1QEAACCwjLo5KQAAAOMHDFIAAAACCwYpAAAAgQWDFAAAgMCCQQoAAEBgwSAFAAAgsGCQAgAAEFgwSAEAAAgsGKQAAAAEFgxSAAAAAgsGKQAAAIEFgxQAAIDA8v8D7s34vO/CJPcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(0) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "tempIter = iter(testloader)\n",
    "images,labels = next(tempIter)\n",
    "index = 10\n",
    "imshow(images[index])\n",
    "print(labels['age'][index],labels['gender'][index],labels['ethnicity'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout, MaxPool2d, \\\n",
    "    AdaptiveAvgPool2d, Sequential, Module\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# Support: ['IR_50', 'IR_101', 'IR_152', 'IR_SE_50', 'IR_SE_101', 'IR_SE_152']\n",
    "\n",
    "\n",
    "class Flatten(Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "def l2_norm(input, axis=1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class SEModule(Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight.data)\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class bottleneck_IR(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False), BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False), PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False), BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class bottleneck_IR_SE(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR_SE, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            SEModule(depth, 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "\n",
    "\n",
    "def get_block(in_channel, depth, num_units, stride=2):\n",
    "\n",
    "    return [Bottleneck(in_channel, depth, stride)] + [Bottleneck(depth, depth, 1) for i in range(num_units - 1)]\n",
    "\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=8),\n",
    "            get_block(in_channel=128, depth=256, num_units=36),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, input_size, num_layers, mode='ir'):\n",
    "        super(Backbone, self).__init__()\n",
    "        assert input_size[0] in [112, 224], \"input_size should be [112, 112] or [224, 224]\"\n",
    "        assert num_layers in [50, 100, 152], \"num_layers should be 50, 100 or 152\"\n",
    "        assert mode in ['ir', 'ir_se'], \"mode should be ir or ir_se\"\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64),\n",
    "                                      PReLU(64))\n",
    "        if input_size[0] == 112:\n",
    "            self.output_layer = Sequential(BatchNorm2d(512),\n",
    "                                           Dropout(),\n",
    "                                           Flatten(),\n",
    "                                           Linear(512 * 7 * 7, 512),\n",
    "                                           BatchNorm1d(512))\n",
    "        else:\n",
    "            self.output_layer = Sequential(BatchNorm2d(512),\n",
    "                                           Dropout(),\n",
    "                                           Flatten(),\n",
    "                                           Linear(512 * 14 * 14, 512),\n",
    "                                           BatchNorm1d(512))\n",
    "\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel,\n",
    "                                bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.body(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def IR_50(input_size):\n",
    "    \"\"\"Constructs a ir-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_101(input_size):\n",
    "    \"\"\"Constructs a ir-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_152(input_size):\n",
    "    \"\"\"Constructs a ir-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_50(input_size):\n",
    "    \"\"\"Constructs a ir_se-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_101(input_size):\n",
    "    \"\"\"Constructs a ir_se-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_152(input_size):\n",
    "    \"\"\"Constructs a ir_se-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir_se')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcFaceModel = IR_50([112,112])\n",
    "arcFaceModel.to(device)\n",
    "arcFaceModel.load_state_dict(torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/backbone_ir50_ms1m_epoch120.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 1; 79.15 GiB total capacity; 58.64 GiB already allocated; 49.44 MiB free; 60.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m ethn_label \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39methnicity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#race_label = data[\"race\"].to(device=device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#inputs = inputs.cpu().detach().numpy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#inputs = np.transpose(inputs, (0, 2, 3, 1))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#print(inputs.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m embeddings \u001b[39m=\u001b[39m arcFaceModel(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m processedTensor[count:count\u001b[39m+\u001b[39membeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m embeddings\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m ageLabelTensor[count:count\u001b[39m+\u001b[39mage_label\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m age_label\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=167'>168</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layer(x)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=168'>169</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody(x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     shortcut \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshortcut_layer(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_layer(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res \u001b[39m+\u001b[39m shortcut\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 1; 79.15 GiB total capacity; 58.64 GiB already allocated; 49.44 MiB free; 60.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "processedTensor = torch.zeros((len(train_dataset),512))\n",
    "#processedTensor = torch.zeros((len(train_dataloader.dataset),128))\n",
    "ageLabelTensor = torch.zeros((len(train_dataset)))\n",
    "genderLabelTensor = torch.zeros((len(train_dataset)))\n",
    "ethnLabelTensor = torch.zeros((len(train_dataset)))\n",
    "arcFaceModel.to(device)\n",
    "count = 0\n",
    "\n",
    "for i,data in enumerate(trainloader):\n",
    "    \n",
    "    inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "    age_label = data[1]['age'].to(device=device)\n",
    "    gender_label = data[1]['gender'].to(device=device)\n",
    "    ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "    #race_label = data[\"race\"].to(device=device)\n",
    "    #inputs = inputs.cpu().detach().numpy()\n",
    "    #inputs = np.transpose(inputs, (0, 2, 3, 1))\n",
    "    #print(inputs.shape)\n",
    "    embeddings = arcFaceModel(inputs)\n",
    "  \n",
    "   \n",
    "\n",
    "    processedTensor[count:count+embeddings.shape[0]] = embeddings\n",
    "    ageLabelTensor[count:count+age_label.shape[0]] = age_label\n",
    "    genderLabelTensor[count:count+gender_label.shape[0]] = gender_label\n",
    "    ethnLabelTensor[count:count+ethn_label.shape[0]] = ethn_label\n",
    "\n",
    "    count = count + embeddings.shape[0]\n",
    "    \n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(processedTensor,\"arcFaceCfBaseInputs.pt\")\n",
    "torch.save(ageLabelTensor,\"arcFaceCfBaseAge.pt\")\n",
    "torch.save(genderLabelTensor,\"arcFaceCfBaseGender.pt\")\n",
    "torch.save(ethnLabelTensor,\"arcFaceCfBaseEthn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedTensor = torch.load(\"arcFaceCfBaseInputs.pt\")\n",
    "ageLabelTensor = torch.load(\"arcFaceCfBaseAge.pt\")\n",
    "genderLabelTensor = torch.load(\"arcFaceCfBaseGender.pt\")\n",
    "ethnLabelTensor = torch.load(\"arcFaceCfBaseEthn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedTensor = processedTensor[:768]\n",
    "ageLabelTensor = ageLabelTensor[:768]\n",
    "genderLabelTensor = genderLabelTensor[:768]\n",
    "ethnLabelTensor = ethnLabelTensor[:768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "processedTensorTest = torch.zeros((len(test_dataset),512))\n",
    "#processedTensor = torch.zeros((len(train_dataloader.dataset),128))\n",
    "ageLabelTensorTest = torch.zeros((len(test_dataset)))\n",
    "genderLabelTensorTest = torch.zeros((len(test_dataset)))\n",
    "ethnLabelTensorTest = torch.zeros((len(test_dataset)))\n",
    "arcFaceModel.to(device)\n",
    "count = 0\n",
    "\n",
    "for i,data in enumerate(testloader):\n",
    "    \n",
    "    inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "    age_label = data[1]['age'].to(device=device)\n",
    "    gender_label = data[1]['gender'].to(device=device)\n",
    "    ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "    #race_label = data[\"race\"].to(device=device)\n",
    "    #inputs = inputs.cpu().detach().numpy()\n",
    "    #inputs = np.transpose(inputs, (0, 2, 3, 1))\n",
    "    #print(inputs.shape)\n",
    "    embeddings = arcFaceModel(inputs)\n",
    "  \n",
    "   \n",
    "\n",
    "    processedTensorTest[count:count+embeddings.shape[0]] = embeddings\n",
    "    ageLabelTensorTest[count:count+age_label.shape[0]] = age_label\n",
    "    genderLabelTensorTest[count:count+gender_label.shape[0]] = gender_label\n",
    "    ethnLabelTensorTest[count:count+ethn_label.shape[0]] = ethn_label\n",
    "\n",
    "    count = count + embeddings.shape[0]\n",
    "    \n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class faceAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1=nn.Sequential(nn.Linear(512,512),nn.Dropout(0.5),nn.ReLU(),nn.Linear(512,256))\n",
    "        \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "        self.layer2=nn.Linear(256,128)\n",
    "        #self.layer3=nn.Linear(1024,512)\n",
    "        self.layer4=nn.Linear(128,64)\n",
    "        self.dropout2=nn.Dropout(0.5)\n",
    "        self.genderOut=nn.Sequential(nn.Linear(64,32),nn.ReLU(),nn.Linear(32,2))\n",
    "        self.ageOut=nn.Linear(64,4)\n",
    "        self.ethnicityOut = nn.Linear(64,4)\n",
    "\n",
    "        # self.maxVal = 0\n",
    "        # self.min=0\n",
    "        \n",
    "    \n",
    "    def writeResult(self,result):\n",
    "       output_directory=\"\"\n",
    "       file_name = \"resultAge.txt\"\n",
    "\n",
    "       with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in result:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        #print(\"Input\",x[0])\n",
    "        x=self.layer1(x)\n",
    "        #x=nn.functional.tanh(x)\n",
    "        #print(x[0])\n",
    "        #x=nn.functional.relu(x)\n",
    "        #x=self.dropout1(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        x=self.layer2(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        #self.writeResult(x[0])\n",
    "       # x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        #print(torch.max(torch.abs(x)))\n",
    "        #x=nn.functional.relu(x)\n",
    "        \n",
    "        x=self.dropout2(x)\n",
    "        gender=self.genderOut(x)\n",
    "        #gender = nn.functional.relu(gender)\n",
    "        age=self.ageOut(x)\n",
    "\n",
    "        ethn = self.ethnicityOut(x)\n",
    "        #self.writeResult(age[0])\n",
    "        #print(gender)\n",
    "        return gender,age,ethn\n",
    "    \n",
    "    \n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False    \n",
    "    \n",
    "\n",
    "    def trainModel(self,trainloader,testloader,arcFace,device,episodes):\n",
    "        self.train()\n",
    "        #maxVal = 0\n",
    "        learningRate=0.005\n",
    "        gender_loss = nn.CrossEntropyLoss() \n",
    "        age_loss = nn.CrossEntropyLoss() \n",
    "        ethn_loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learningRate,weight_decay=8e-2)\n",
    "        #optimizer = torch.optim.SGD(self.parameters(), lr=learningRate,\n",
    "        #momentum=0.9, weight_decay=5e-4)\n",
    "        #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=episodes)\n",
    "        trainingAcc = []\n",
    "        for e in range(0,episodes):\n",
    "         total_training_loss =0\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         ageAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "    \n",
    "         batchSize = 256\n",
    "         \n",
    "        #  ageLabelTensor = ageLabelTensor.type(torch.LongTensor)\n",
    "        #  genderLabelTensor = genderLabelTensor.type(torch.LongTensor)\n",
    "        #  ethnLabelTensor = ethnLabelTensor.type(torch.LongTensor)\n",
    "\n",
    "        #  while(count<tempPT.shape[0]):\n",
    "        #     if(count+batchSize<=tempPT.shape[0]):\n",
    "        #      inputs = tempPT[count:count+batchSize].to(device=device)\n",
    "        #      age_label = ageLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      gender_label = genderLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      ethn_label = ethnLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #     else:\n",
    "        #        inputs = tempPT[count:].to(device=device)\n",
    "        #        age_label = ageLabelTensor[count:].to(device=device)\n",
    "        #        gender_label = genderLabelTensor[count:].to(device=device)\n",
    "        #        ethn_label = ethnLabelTensor[count:].to(device=device)\n",
    "        \n",
    "\n",
    "         for i,data in enumerate(trainloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings = arcFaceModel(inputs)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "            # age=torch.squeeze(age)\n",
    "            # age=age.type(torch.float32)\n",
    "            #print(age.shape,age_label.shape)\n",
    "            #print(gender.shape,gender_label.shape)\n",
    "            # predictedGender = torch.argmax(gender,dim=1)\n",
    "            # predictedGender = predictedGender.type(torch.float32)\n",
    "            #print(gender)\n",
    "            ageLoss = age_loss(age,age_label)\n",
    "           \n",
    "            loss = 3*gender_loss(gender,gender_label) + ageLoss + 2*ethn_loss(ethn,ethn_label) \n",
    "            #print(gender)\n",
    "            #print(gender_label)\n",
    "            #totalGenderLoss = totalGenderLoss + loss.item()\n",
    "            loss.backward()\n",
    "            #print(\"Loss:\",loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #total_training_loss = total_training_loss+loss.item()*512\n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #print(predictedGender)\n",
    "            #print(gender_label)\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j].item()):\n",
    "                    genderAcc=genderAcc+1\n",
    "            \n",
    "                if(predictedEthn[j].item()==ethn_label[j].item()):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "  \n",
    "                if(predictedAge[j].item()==age_label[j].item()):\n",
    "                    ageAcc=ageAcc+1\n",
    "            #print(count)\n",
    "         genderAccuracy =  genderAcc/count\n",
    "         trainingAcc.append(genderAccuracy)\n",
    "         print(\"Episode:\",e, \"Gender Accuracy:\", genderAccuracy,\"Age Acc:\", ageAcc/count, \" ethnAcc:\", ethnAcc/count)\n",
    "         #print(\"total training loss:\",total_training_loss/16595,\"\\n\")\n",
    "         #print(\"\\n\")\n",
    "         #scheduler.step()\n",
    "         #print(\"max observed value: \", maxVal)\n",
    "         if(e%2==0):\n",
    "          self.test(testloader,arcFace,device)\n",
    "             \n",
    "        return trainingAcc\n",
    "\n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def test(self,testloader,arcFace,device):\n",
    "\n",
    "         self.eval()\n",
    "         age_loss = nn.L1Loss()\n",
    "\n",
    "         totalAgeError = 0\n",
    "         genderAccuracy = 0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "         maxAge = 0\n",
    "         minAge = 0\n",
    "         ageAccuracy = 0\n",
    "         total_training_loss =0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         batchSize = 256\n",
    "\n",
    "         for i,data in enumerate(testloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings = arcFaceModel(inputs)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "        \n",
    "         \n",
    "            #gender,age,ethn = self(inputs)\n",
    "         \n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #age = get_original_age_value(age)\n",
    "\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j]):\n",
    "                    genderAcc=genderAcc+1\n",
    "                if(predictedEthn[j].item()==ethn_label[j]):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "                if(predictedAge[j].item()==age_label[j]):\n",
    "                   ageAccuracy = ageAccuracy +1\n",
    "\n",
    "         genderAccuracy =  genderAcc/count\n",
    "         \n",
    "         print(\"Gender Accuracy Test:\", genderAccuracy,\"Age Accuracy Test:\", ageAccuracy/count, \" Ethnicity Accuracy Test:\", ethnAcc/count)\n",
    "\n",
    "         return genderAccuracy,totalAgeError\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Gender Accuracy: 0.519916142557652 Age Acc: 0.6834381551362684  ethnAcc: 0.3480083857442348\n",
      "Gender Accuracy Test: 0.65 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.5333333333333333\n",
      "Episode: 1 Gender Accuracy: 0.5786163522012578 Age Acc: 0.8406708595387841  ethnAcc: 0.5681341719077568\n",
      "Episode: 2 Gender Accuracy: 0.5513626834381551 Age Acc: 0.8364779874213837  ethnAcc: 0.5744234800838575\n",
      "Gender Accuracy Test: 0.7583333333333333 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.5833333333333334\n",
      "Episode: 3 Gender Accuracy: 0.7023060796645703 Age Acc: 0.8406708595387841  ethnAcc: 0.5932914046121593\n",
      "Episode: 4 Gender Accuracy: 0.7442348008385744 Age Acc: 0.8406708595387841  ethnAcc: 0.5932914046121593\n",
      "Gender Accuracy Test: 0.675 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.5583333333333333\n",
      "Episode: 5 Gender Accuracy: 0.7568134171907757 Age Acc: 0.8406708595387841  ethnAcc: 0.6058700209643606\n",
      "Episode: 6 Gender Accuracy: 0.7840670859538784 Age Acc: 0.8406708595387841  ethnAcc: 0.6205450733752621\n",
      "Gender Accuracy Test: 0.7916666666666666 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.6333333333333333\n",
      "Episode: 7 Gender Accuracy: 0.8113207547169812 Age Acc: 0.8406708595387841  ethnAcc: 0.6121593291404612\n",
      "Episode: 8 Gender Accuracy: 0.8280922431865828 Age Acc: 0.8406708595387841  ethnAcc: 0.6771488469601677\n",
      "Gender Accuracy Test: 0.6583333333333333 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.625\n",
      "Episode: 9 Gender Accuracy: 0.8029350104821803 Age Acc: 0.8406708595387841  ethnAcc: 0.7023060796645703\n",
      "Episode: 10 Gender Accuracy: 0.8637316561844863 Age Acc: 0.8406708595387841  ethnAcc: 0.689727463312369\n",
      "Gender Accuracy Test: 0.7916666666666666 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.525\n",
      "Episode: 11 Gender Accuracy: 0.8930817610062893 Age Acc: 0.8406708595387841  ethnAcc: 0.6561844863731656\n",
      "Episode: 12 Gender Accuracy: 0.8616352201257862 Age Acc: 0.8406708595387841  ethnAcc: 0.7274633123689728\n",
      "Gender Accuracy Test: 0.8333333333333334 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.65\n",
      "Episode: 13 Gender Accuracy: 0.8490566037735849 Age Acc: 0.8406708595387841  ethnAcc: 0.7463312368972747\n",
      "Episode: 14 Gender Accuracy: 0.8763102725366876 Age Acc: 0.8406708595387841  ethnAcc: 0.7253668763102725\n",
      "Gender Accuracy Test: 0.725 Age Accuracy Test: 0.875  Ethnicity Accuracy Test: 0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "#tempModel=torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.pt\")\n",
    "#model=torch.load(\"arcFaceCelebSetBase.pt\")\n",
    "#model.ethnicityOut = nn.Linear(64,4)\n",
    "model.to(device)\n",
    "count = 0\n",
    "#processedTensor=[]  \n",
    "# for i in model.named_parameters():\n",
    "\n",
    "#     #print(i[0],count)\n",
    "#     if(count<4):\n",
    "#         i[1].requires_grad = False\n",
    "#     else:\n",
    "#         i[1].requires_grad = True\n",
    "#     count = count +1\n",
    "    #print(i)\n",
    "print(count)\n",
    "arcFaceModel.to(device)\n",
    "arcFaceModel.eval()\n",
    "trainingAcc = model.trainModel(trainloader,testloader,arcFaceModel,device,15)\n",
    "#torch.save(model,\"bestFaceAn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faceAnalytics(\n",
       "  (layer1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (genderOut): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (ageOut): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (ethnicityOut): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Verify that the weights are copied\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m param_a, param_b \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tempModel\u001b[39m.\u001b[39mparameters(), model\u001b[39m.\u001b[39mparameters()):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceChicagoFaceBase.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mallclose(param_a, param_b))  \n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "\n",
    "# Verify that the weights are copied\n",
    "for param_a, param_b in zip(tempModel.parameters(), model.parameters()):\n",
    "    print(torch.allclose(param_a, param_b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"negGenderBaseWiki.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ccd692eb0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model92.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "input1=[]\n",
    "for i,data in enumerate(val_dataloader):\n",
    "    \n",
    "    if(count==0):\n",
    "     inputs=resnet(data[\"image\"].to(device))\n",
    "\n",
    " \n",
    "     input1 = polyprotect(0,inputs[0])\n",
    "\n",
    "     break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "tensor([-0.0765, -0.1069, -0.0411,  0.0238,  0.0118,  0.0784, -0.0193, -0.0194,\n",
      "        -0.0132,  0.0487,  0.0409, -0.0441, -0.1003,  0.0050,  0.0179,  0.0378,\n",
      "        -0.0322,  0.0842, -0.0395, -0.0201,  0.0457, -0.0654, -0.0586,  0.0188,\n",
      "        -0.0772,  0.0069,  0.0861, -0.0244,  0.0486, -0.0309, -0.0071,  0.0655,\n",
      "        -0.1047,  0.0400,  0.0215, -0.0451,  0.0729, -0.0582, -0.0285,  0.0711,\n",
      "        -0.0588, -0.0468, -0.0742, -0.0929,  0.0281,  0.0036, -0.0665, -0.0713,\n",
      "        -0.0775,  0.0966,  0.0213,  0.0536, -0.0497, -0.0261,  0.0736, -0.0707,\n",
      "        -0.0635,  0.0039,  0.0356,  0.0208, -0.0432,  0.0132,  0.0090, -0.0508,\n",
      "         0.0649, -0.0474,  0.0852,  0.0400,  0.0783,  0.0792, -0.0682, -0.0400,\n",
      "         0.0074, -0.0067,  0.0327,  0.0179, -0.0077, -0.0110,  0.0008,  0.0626,\n",
      "         0.0268, -0.0395, -0.0766,  0.0686, -0.0601,  0.0466,  0.0655,  0.0477,\n",
      "        -0.0761,  0.0306,  0.0702, -0.0810,  0.0598,  0.0180, -0.0715, -0.0503,\n",
      "        -0.0228, -0.0253,  0.0304, -0.0354, -0.0314, -0.0703, -0.0203,  0.0615,\n",
      "         0.0830,  0.0707,  0.0716, -0.0595, -0.0409, -0.0479, -0.0437,  0.0757,\n",
      "        -0.0215, -0.0659,  0.0782, -0.0438,  0.0741, -0.1035, -0.0170,  0.0418,\n",
      "         0.0713, -0.0575,  0.0096, -0.0349, -0.0885,  0.0735,  0.0153, -0.0870],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2496, device='cuda:0', grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    print(param[0])\n",
    "    print(torch.dot(input1,param[1]))\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"input1.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in input1:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ageAccuracy:  0.638671875\n",
      "ageAccuracy:  0.62109375\n",
      "ageAccuracy:  0.6087239583333334\n",
      "ageAccuracy:  0.6162109375\n",
      "ageAccuracy:  0.626953125\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.62890625\n",
      "ageAccuracy:  0.628662109375\n",
      "ageAccuracy:  0.6271701388888888\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.6296164772727273\n",
      "ageAccuracy:  0.6300455729166666\n",
      "ageAccuracy:  0.6275540865384616\n",
      "ageAccuracy:  0.6256975446428571\n",
      "ageAccuracy:  0.62578125\n",
      "ageAccuracy:  0.627197265625\n",
      "ageAccuracy:  0.6246553308823529\n",
      "ageAccuracy:  0.6252170138888888\n",
      "ageAccuracy:  0.6258223684210527\n",
      "ageAccuracy:  0.62392578125\n",
      "ageAccuracy:  0.6255580357142857\n",
      "ageAccuracy:  0.6242009943181818\n",
      "ageAccuracy:  0.6240658967391305\n",
      "ageAccuracy:  0.624267578125\n",
      "ageAccuracy:  0.6246875\n",
      "ageAccuracy:  0.6246995192307693\n",
      "ageAccuracy:  0.6237702546296297\n",
      "ageAccuracy:  0.6241629464285714\n",
      "ageAccuracy:  0.6245285560344828\n",
      "ageAccuracy:  0.6251953125\n",
      "ageAccuracy:  0.6246219758064516\n",
      "ageAccuracy:  0.62457275390625\n",
      "ageAccuracy:  0.6244081439393939\n",
      "ageAccuracy:  0.6249425551470589\n",
      "ageAccuracy:  0.6246651785714286\n",
      "ageAccuracy:  0.6248372395833334\n",
      "ageAccuracy:  0.6230996621621622\n",
      "ageAccuracy:  0.6235608552631579\n",
      "ageAccuracy:  0.6234475160256411\n",
      "ageAccuracy:  0.62275390625\n",
      "ageAccuracy:  0.6228563262195121\n",
      "ageAccuracy:  0.6216982886904762\n",
      "ageAccuracy:  0.6209574854651163\n",
      "ageAccuracy:  0.6209161931818182\n",
      "ageAccuracy:  0.6213541666666667\n",
      "ageAccuracy:  0.621475883152174\n",
      "ageAccuracy:  0.6214261968085106\n",
      "ageAccuracy:  0.62158203125\n",
      "ageAccuracy:  0.6218510841836735\n",
      "ageAccuracy:  0.6220703125\n",
      "ageAccuracy:  0.6222043504901961\n",
      "ageAccuracy:  0.6222581129807693\n",
      "ageAccuracy:  0.6218676297169812\n",
      "ageAccuracy:  0.6221426504629629\n",
      "ageAccuracy:  0.6223011363636364\n",
      "ageAccuracy:  0.6221400669642857\n",
      "ageAccuracy:  0.621813322368421\n",
      "ageAccuracy:  0.6223060344827587\n",
      "ageAccuracy:  0.6223847987288136\n",
      "ageAccuracy:  0.6228515625\n",
      "ageAccuracy:  0.6227587090163934\n",
      "ageAccuracy:  0.6231098790322581\n",
      "ageAccuracy:  0.6231398809523809\n",
      "ageAccuracy:  0.623321533203125\n",
      "ageAccuracy:  0.6232572115384616\n",
      "ageAccuracy:  0.6234907670454546\n",
      "ageAccuracy:  0.6238922574626866\n",
      "ageAccuracy:  0.6239372702205882\n",
      "ageAccuracy:  0.6240942028985508\n",
      "ageAccuracy:  0.6241908482142857\n",
      "ageAccuracy:  0.6242572623239436\n",
      "ageAccuracy:  0.6239691840277778\n",
      "ageAccuracy:  0.6239030393835616\n",
      "ageAccuracy:  0.6237595016891891\n",
      "ageAccuracy:  0.62421875\n",
      "ageAccuracy:  0.624254728618421\n",
      "ageAccuracy:  0.624416599025974\n",
      "ageAccuracy:  0.624198717948718\n",
      "ageAccuracy:  0.6240302367217028\n",
      "Test Gender Accuracy: 0.9118510045752934 \n",
      "\n",
      "Test Age Accuracy: 0.6240302367217028 \n",
      "\n",
      "Test Age Loss: 0.313527571161588 \n",
      "\n",
      "\n",
      "\n",
      "Max 0\n",
      "Min 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9118510045752934, 4815.783493041992)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/modelUsing0.pt\")\n",
    "model.to(device)\n",
    "model.test(dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"modelUsing0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-0.0608, -0.0217,  0.0529, -0.0089,  0.0091,  0.0046, -0.0850,  0.0737,\n",
      "         0.0143,  0.0217, -0.0977,  0.0810, -0.0564,  0.0011,  0.0722, -0.0247,\n",
      "         0.0400, -0.0504, -0.0266,  0.0041,  0.0306, -0.0060, -0.0088, -0.0187,\n",
      "         0.0724, -0.0828, -0.0848, -0.0345, -0.0290,  0.0105,  0.0145, -0.0039,\n",
      "        -0.0052, -0.0191,  0.0698, -0.0620, -0.0487, -0.1063,  0.0467, -0.0002,\n",
      "         0.0537,  0.0358, -0.0329,  0.0654, -0.0006, -0.1011, -0.0192, -0.0640,\n",
      "        -0.0694,  0.0320, -0.1085,  0.0418, -0.0238, -0.0615, -0.0560,  0.0657,\n",
      "        -0.0512,  0.0451, -0.0391,  0.0244, -0.0777, -0.0340,  0.0475,  0.0886,\n",
      "         0.0003, -0.0109, -0.0577, -0.0619, -0.0323, -0.0008, -0.0176,  0.0066,\n",
      "         0.0504,  0.0278, -0.0135,  0.0303,  0.0313, -0.0311,  0.0308, -0.0487,\n",
      "         0.0603, -0.0842,  0.0063, -0.0263,  0.0686,  0.0789,  0.0931,  0.0091,\n",
      "        -0.0183, -0.0787,  0.0457,  0.0954,  0.0281, -0.0374,  0.0159, -0.0512,\n",
      "        -0.0433, -0.0511, -0.0834,  0.0953, -0.1000,  0.0523, -0.0116,  0.0425,\n",
      "        -0.0527, -0.0206, -0.0190, -0.0797,  0.0660, -0.0485, -0.0466,  0.0153,\n",
      "        -0.0169,  0.0452, -0.0746, -0.0683,  0.0565,  0.0540, -0.0384,  0.0310,\n",
      "         0.0139,  0.0437, -0.0087, -0.0292,  0.0351, -0.0614, -0.0722,  0.0297,\n",
      "         0.1136,  0.0672, -0.0866,  0.1015, -0.0465,  0.0330,  0.0159, -0.0102,\n",
      "         0.0414,  0.0236,  0.0637,  0.0466,  0.0528, -0.0651, -0.0702, -0.0829,\n",
      "        -0.0911,  0.0808, -0.0970,  0.0308,  0.1084,  0.0431,  0.0110,  0.0354,\n",
      "        -0.0004,  0.0313, -0.0509,  0.0891, -0.0619, -0.0549,  0.0235, -0.0453,\n",
      "         0.0305,  0.0650,  0.0026,  0.0656,  0.0059,  0.0531, -0.0560,  0.0448,\n",
      "         0.0648, -0.0330, -0.0089, -0.1149,  0.0918, -0.0469,  0.0221, -0.0289,\n",
      "         0.0285,  0.1076, -0.0770, -0.0513,  0.0834,  0.0107, -0.0912, -0.0662,\n",
      "        -0.0766,  0.0287,  0.0123, -0.0207, -0.0837, -0.0780,  0.0546,  0.0836,\n",
      "        -0.0027,  0.1223, -0.0599, -0.0164,  0.0038,  0.0645,  0.0602, -0.0260,\n",
      "        -0.1117, -0.0681, -0.0433,  0.0739,  0.0762,  0.0478,  0.0897, -0.0819,\n",
      "         0.0830, -0.0597,  0.0852,  0.0506,  0.0303,  0.0344, -0.0822, -0.0732,\n",
      "        -0.0964,  0.0137, -0.0595, -0.0760,  0.0394,  0.0083, -0.0690,  0.0529,\n",
      "         0.0407, -0.0937,  0.0200,  0.0386,  0.0058,  0.0301, -0.0113,  0.0929,\n",
      "         0.0309, -0.0483, -0.0190, -0.0249,  0.0614, -0.0806,  0.0442,  0.0468,\n",
      "         0.0455,  0.0116, -0.0451, -0.0917,  0.0322, -0.0705,  0.0507, -0.0204,\n",
      "         0.0007, -0.0027,  0.0428,  0.0796, -0.0316,  0.0552, -0.0604,  0.0575,\n",
      "         0.0360,  0.0643,  0.0433, -0.0074,  0.0539, -0.0003,  0.0321,  0.0552,\n",
      "         0.0537, -0.0608, -0.0301,  0.0042,  0.0934,  0.0286, -0.1056, -0.0474,\n",
      "        -0.0313, -0.0984,  0.0300,  0.0091, -0.0760,  0.0004, -0.0812,  0.0902,\n",
      "        -0.0741,  0.0695, -0.0525, -0.0741,  0.0278, -0.0640, -0.0199, -0.0633,\n",
      "         0.0149, -0.0275, -0.0856, -0.0580, -0.0747, -0.0139,  0.0040,  0.0315,\n",
      "        -0.0552, -0.0549,  0.0007, -0.0453, -0.0781,  0.0112,  0.0050,  0.0232,\n",
      "        -0.0420,  0.0694,  0.0666,  0.0664,  0.0244, -0.0461, -0.0278, -0.0601,\n",
      "         0.0799, -0.0605, -0.0106, -0.0346,  0.0085,  0.0739, -0.0433, -0.0053,\n",
      "         0.0755, -0.0756, -0.0710, -0.0266,  0.0126, -0.0906,  0.0843, -0.0450,\n",
      "        -0.0306,  0.0114, -0.0750,  0.0695,  0.0847,  0.0204,  0.0869,  0.0717,\n",
      "         0.0892,  0.0096, -0.0551, -0.0669, -0.0853, -0.0864,  0.1047, -0.0818,\n",
      "        -0.0770,  0.0931,  0.0221,  0.0545, -0.0748,  0.0771,  0.0588, -0.0495,\n",
      "         0.0075, -0.0071, -0.0681,  0.0002,  0.0290, -0.0568, -0.0345,  0.0315,\n",
      "         0.0363, -0.0928,  0.0599, -0.0570,  0.0604,  0.0524,  0.0424, -0.1010,\n",
      "        -0.1053, -0.0505, -0.0577,  0.0719,  0.0369,  0.0338,  0.0068,  0.0026,\n",
      "         0.0439,  0.0258, -0.0427,  0.0594, -0.0648, -0.0282, -0.0707, -0.0582,\n",
      "        -0.0210, -0.0880,  0.0366, -0.0133, -0.0476,  0.0635, -0.0333,  0.0534,\n",
      "        -0.0450,  0.0781, -0.0265, -0.0237,  0.0189, -0.0033, -0.0879,  0.0066,\n",
      "        -0.0582,  0.0313, -0.0012, -0.0256,  0.0776, -0.0801,  0.0883, -0.0772,\n",
      "        -0.0547,  0.0284, -0.0085, -0.0172, -0.0248, -0.0611, -0.0257, -0.0427,\n",
      "        -0.0368,  0.0097, -0.0731,  0.0816, -0.0421, -0.0192, -0.0546,  0.0163,\n",
      "         0.0369,  0.0193, -0.0264, -0.0645, -0.0581, -0.0677, -0.0154,  0.0552,\n",
      "        -0.0798,  0.0711,  0.0431,  0.0272, -0.0204,  0.0371, -0.0032,  0.0675,\n",
      "        -0.0399, -0.0378, -0.0247,  0.0556, -0.0469, -0.0313,  0.0346, -0.0774,\n",
      "         0.0135, -0.0863, -0.0374, -0.0790,  0.0758, -0.0534, -0.0496, -0.0032,\n",
      "         0.0652, -0.0750, -0.0940, -0.0387, -0.0594, -0.0751,  0.0502,  0.0511,\n",
      "        -0.0417,  0.0018, -0.0762, -0.0004,  0.0037,  0.0627,  0.0120,  0.0338,\n",
      "        -0.0688,  0.0400,  0.0855,  0.0265,  0.0423, -0.0375,  0.0245,  0.0013,\n",
      "         0.0121, -0.0373, -0.0252,  0.0247,  0.0048,  0.0476,  0.0585, -0.0490,\n",
      "         0.0448, -0.0205, -0.0537, -0.0524,  0.0103,  0.0989, -0.0534,  0.0832,\n",
      "         0.0281,  0.0697, -0.0782,  0.0404, -0.0589,  0.0134, -0.0148, -0.0104,\n",
      "         0.0143, -0.0749, -0.0312,  0.0053, -0.0827, -0.0643, -0.0590,  0.0067],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    count=count+1\n",
    "    if(count==2):\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 tensor([[0.1725, 0.7784, 0.7692, 0.3667]])\n",
      "param Parameter containing:\n",
      "tensor([[ 0.0794, -0.2791,  0.0171, -0.2814],\n",
      "        [-0.0677, -0.3197, -0.2683, -0.3466]], requires_grad=True)\n",
      "param Parameter containing:\n",
      "tensor([ 0.0877, -0.3602], requires_grad=True)\n",
      "tensor([[-0.2058, -0.9542]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a=nn.Linear(4,2)\n",
    "input1=torch.rand((1,4))\n",
    "print(\"input1\",input1)\n",
    "for param in a.parameters():\n",
    "    print(\"param\",param)\n",
    "print(a(input1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m        ageBias \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(ageBias),\u001b[39mlen\u001b[39;49m(ageBias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"modelUsing0.pt\")\n",
    "model.to(device)\n",
    "count=0\n",
    "ageBias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==7):\n",
    "       ageBias = param.tolist()\n",
    "    count=count+1\n",
    "print(len(ageBias),len(ageBias[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09601110219955444]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007277209311723709,\n",
       " -0.0321158841252327,\n",
       " -0.031418390572071075,\n",
       " -0.006457424722611904,\n",
       " 0.0034283681306988,\n",
       " 0.018647771328687668,\n",
       " 0.010360945016145706,\n",
       " -0.046598006039857864,\n",
       " -0.05573476478457451,\n",
       " 0.01843833737075329,\n",
       " 0.0027071069926023483,\n",
       " 0.03294723108410835,\n",
       " 0.02504689060151577,\n",
       " -0.03142755106091499,\n",
       " -0.022691987454891205,\n",
       " 0.03483140096068382,\n",
       " -0.05341877415776253,\n",
       " 0.04222894087433815,\n",
       " -0.01728733628988266,\n",
       " -0.04929398000240326,\n",
       " 0.00046024261973798275,\n",
       " -0.044817082583904266,\n",
       " 0.0034655649214982986,\n",
       " -0.03304927796125412,\n",
       " -0.0016231774352490902,\n",
       " -0.04087826982140541,\n",
       " 0.01253503654152155,\n",
       " -0.030864598229527473,\n",
       " -0.013328468427062035,\n",
       " 0.012476014904677868,\n",
       " -0.037187058478593826,\n",
       " 0.006219789385795593,\n",
       " -0.013966446742415428,\n",
       " 0.01565675437450409,\n",
       " 0.0035794111900031567,\n",
       " -0.005585063714534044,\n",
       " 0.006055895704776049,\n",
       " 0.00048314392915926874,\n",
       " -0.010381164960563183,\n",
       " -0.018931696191430092,\n",
       " 0.012918422929942608,\n",
       " 0.014919551089406013,\n",
       " -0.015488061122596264,\n",
       " -0.01959354802966118,\n",
       " 0.038306545466184616,\n",
       " -0.05790992081165314,\n",
       " -0.017201725393533707,\n",
       " -0.03371630981564522,\n",
       " -0.024791700765490532,\n",
       " -0.031961359083652496,\n",
       " -0.030725467950105667,\n",
       " -0.045284777879714966,\n",
       " -0.012051970697939396,\n",
       " 0.01729130558669567,\n",
       " -0.058299340307712555,\n",
       " -0.008241587318480015,\n",
       " 0.008392270654439926,\n",
       " 0.012528457678854465,\n",
       " -0.02050808258354664,\n",
       " 0.018400557339191437,\n",
       " -0.05368071794509888,\n",
       " -0.04868054389953613,\n",
       " -0.011333262547850609,\n",
       " 0.036896102130413055,\n",
       " -0.029022417962551117,\n",
       " 0.023950502276420593,\n",
       " 0.019032996147871017,\n",
       " 0.0386575311422348,\n",
       " 0.04340917244553566,\n",
       " -0.05563858523964882,\n",
       " -0.02269531600177288,\n",
       " -0.008079467341303825,\n",
       " 0.027136100456118584,\n",
       " 0.024767564609646797,\n",
       " 0.0464879646897316,\n",
       " -0.034298501908779144,\n",
       " -0.05876478925347328,\n",
       " 0.019566943868994713,\n",
       " -0.00596601003780961,\n",
       " 0.012794088572263718,\n",
       " 0.028237752616405487,\n",
       " 0.0027152879629284143,\n",
       " -0.018138255923986435,\n",
       " 0.024093421176075935,\n",
       " 0.014445447362959385,\n",
       " -0.029630817472934723,\n",
       " -0.009077931754291058,\n",
       " 0.04275999963283539,\n",
       " 0.019907813519239426,\n",
       " 0.03173178434371948,\n",
       " -0.010339722968637943,\n",
       " 0.021917376667261124,\n",
       " 0.00547691760584712,\n",
       " 0.04024359956383705,\n",
       " 0.00037949683610349894,\n",
       " -0.043355707079172134,\n",
       " -0.029875755310058594,\n",
       " 0.012577931396663189,\n",
       " -0.01590362749993801,\n",
       " -0.02837674878537655,\n",
       " -0.0026315744034945965,\n",
       " 0.029960552230477333,\n",
       " 0.048201654106378555,\n",
       " 0.05135548114776611,\n",
       " -0.059926338493824005,\n",
       " -0.022241834551095963,\n",
       " -0.047569092363119125,\n",
       " 0.007798505946993828,\n",
       " 0.024846207350492477,\n",
       " -0.06639613211154938,\n",
       " -0.0007212079362943769,\n",
       " -0.022007303312420845,\n",
       " 0.0007844719802960753,\n",
       " -0.03660847619175911,\n",
       " 0.010727467015385628,\n",
       " -0.024773655459284782,\n",
       " 0.015029202215373516,\n",
       " 0.009059355594217777,\n",
       " 0.02116716280579567,\n",
       " 0.04279369115829468,\n",
       " -0.07188471406698227,\n",
       " -0.002769036218523979,\n",
       " 0.03128764033317566,\n",
       " 0.018925964832305908,\n",
       " -0.01784098893404007,\n",
       " 0.029889674857258797,\n",
       " 0.0049612135626375675,\n",
       " -0.006710418500006199]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with shape (512, 128)\n",
    "\n",
    "\n",
    "# Define the directory where you want to save the text files\n",
    "output_directory = \"ageWeights\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Write each list to a separate text file\n",
    "\n",
    "\n",
    "# Write each list to a separate text file\n",
    "for i, sublist in enumerate(ageWeights):\n",
    "    # Define the file name with leading zeros\n",
    "    file_name = f\"{i:03d}.txt\"\n",
    "\n",
    "    # Write each value in the sublist on a new line\n",
    "    with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in sublist:\n",
    "            file.write(f\"{value}\\n\")\n",
    "\n",
    "print(\"Files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 39\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m        \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(layer1Bias),\u001b[39mlen\u001b[39;49m(layer1Bias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "layer1Bias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==2):\n",
    "       layer1Bias = param.tolist()\n",
    "       break\n",
    "    count=count+1\n",
    "print(len(layer1Bias),len(layer1Bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"ageBias.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in ageBias:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
