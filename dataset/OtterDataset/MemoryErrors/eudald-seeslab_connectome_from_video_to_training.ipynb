{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T07:03:29.877127Z",
     "start_time": "2024-03-06T07:03:25.105745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# stupid cuda stuff\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:100'\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch import device, cuda, autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flyvision_ans import ResponseProcessor, DECODING_CELLS\n",
    "from from_retina_to_connectome_funcs import from_retina_to_model, get_decision_making_neurons\n",
    "from graph_models import GNNModel\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "torch.manual_seed(42)\n",
    "batch_size = 10\n",
    "last_good_frame = 8"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "decision_making_vector = get_decision_making_neurons()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T11:38:51.180683Z",
     "start_time": "2024-03-03T11:38:51.162068Z"
    }
   },
   "id": "19c3dad6db455873",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.66it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 21.27it/s]\n"
     ]
    }
   ],
   "source": [
    "response_processor = ResponseProcessor(\"toy_videos/yellow\")\n",
    "# compute the layer activations\n",
    "layer_activations_yellow = response_processor.compute_layer_activations()\n",
    "response_processor = ResponseProcessor(\"toy_videos/blue\")\n",
    "layer_activations_blue = response_processor.compute_layer_activations()\n",
    "combined_activations = layer_activations_yellow + layer_activations_blue\n",
    "\n",
    "# Create labels tensor\n",
    "labels_0 = torch.zeros(len(layer_activations_yellow), dtype=torch.long)\n",
    "labels_1 = torch.ones(len(layer_activations_blue), dtype=torch.long)\n",
    "combined_labels = torch.cat((labels_0, labels_1), dim=0)\n",
    "\n",
    "del layer_activations_yellow, layer_activations_blue\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T11:43:02.561956Z",
     "start_time": "2024-03-03T11:38:51.181561Z"
    }
   },
   "id": "7ba2fc4828f7544",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# shuffle (since the dataloader shuffle is broken, we have to do it by hand)\n",
    "indices = list(range(len(combined_activations)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "shuffled_list = [combined_activations[i] for i in indices]\n",
    "shuffled_labels = combined_labels[torch.tensor(indices)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T11:43:02.565956Z",
     "start_time": "2024-03-03T11:43:02.563292Z"
    }
   },
   "id": "810b9fdd8a3f4b5d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:18<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "loader, labels = from_retina_to_model(shuffled_list, shuffled_labels, DECODING_CELLS, last_good_frame, batch_size)\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T11:43:21.981606Z",
     "start_time": "2024-03-03T11:43:02.566830Z"
    }
   },
   "id": "ce3f08bac654031c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 7.58 GiB of which 249.81 MiB is free. Process 3968 has 33.52 MiB memory in use. Process 22873 has 2.28 GiB memory in use. Including non-PyTorch memory, this process has 4.93 GiB memory in use. Of the allocated memory 3.69 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m criterion \u001B[38;5;241m=\u001B[39m BCEWithLogitsLoss()\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, batch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(loader)):\n\u001B[1;32m     14\u001B[0m     batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m     15\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/tqdm/std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:55\u001B[0m, in \u001B[0;36mCollater.collate_fn\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, OnDiskDataset):\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mmulti_get(batch))\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:28\u001B[0m, in \u001B[0;36mCollater.__call__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     26\u001B[0m elem \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, BaseData):\n\u001B[0;32m---> 28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_data_list\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfollow_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexclude_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_collate(batch)\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/data/batch.py:93\u001B[0m, in \u001B[0;36mBatch.from_data_list\u001B[0;34m(cls, data_list, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_data_list\u001B[39m(\u001B[38;5;28mcls\u001B[39m, data_list: List[BaseData],\n\u001B[1;32m     83\u001B[0m                    follow_batch: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     84\u001B[0m                    exclude_keys: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     85\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m    Python list of :class:`~torch_geometric.data.Data` or\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;124;03m    :obj:`follow_batch`.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 93\u001B[0m     batch, slice_dict, inc_dict \u001B[38;5;241m=\u001B[39m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mincrement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     batch\u001B[38;5;241m.\u001B[39m_num_graphs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data_list)\n\u001B[1;32m    103\u001B[0m     batch\u001B[38;5;241m.\u001B[39m_slice_dict \u001B[38;5;241m=\u001B[39m slice_dict\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/data/collate.py:92\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m# Collate attributes into a unified representation:\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m value, slices, incs \u001B[38;5;241m=\u001B[39m \u001B[43m_collate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mincrement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, Tensor) \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mis_cuda:\n\u001B[1;32m     96\u001B[0m     device \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mdevice\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/data/collate.py:177\u001B[0m, in \u001B[0;36m_collate\u001B[0;34m(key, values, data_list, stores, increment)\u001B[0m\n\u001B[1;32m    174\u001B[0m             shape[cat_dim] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(slices[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    175\u001B[0m         out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;241m*\u001B[39mshape)\n\u001B[0;32m--> 177\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcat_dim\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value, slices, incs\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, TensorFrame):\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacty of 7.58 GiB of which 249.81 MiB is free. Process 3968 has 33.52 MiB memory in use. Process 22873 has 2.28 GiB memory in use. Including non-PyTorch memory, this process has 4.93 GiB memory in use. Of the allocated memory 3.69 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = GNNModel(\n",
    "    num_node_features=1, \n",
    "    decision_making_vector=decision_making_vector\n",
    ").to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "model.train()\n",
    "for batch_idx, batch in tqdm(enumerate(loader)):\n",
    "    batch = batch.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast(device_type):\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y.unsqueeze(-1).float())    \n",
    "        \n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T11:43:22.457396Z",
     "start_time": "2024-03-03T11:43:21.982710Z"
    }
   },
   "id": "cc3390834697f7ab",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "efea5bc051bf0997"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23966978364e77a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Literature review to identify the \"thinking\" neurons [x]\n",
    "2. Identify these neurons in the classification dataframe and create a class_labels tensor [x]\n",
    "3. Train the model with the class_labels tensor [x]\n",
    "4. Check model accuracy and weber ratio\n",
    "5. Try with other model architectures, specially with a one-hot encoding for each neuron type to simulate different neurons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267ef921becd0439"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55b695cfd9488c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
