{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4fd19-5a09-4232-bdc4-42bbef0b6802",
   "metadata": {},
   "source": [
    "last updated 07 11 24\n",
    "\n",
    "This notebook is to get the run times for each model on the highets and lowest Resolutions; to estimate an average run time.IG DICITONARY!\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6be64f-3efe-4c20-885c-1333846ffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e97a-adf8-4aa3-aadf-a32df7852d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6dbd95-2129-42b5-b70b-ee9f057b24c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.Utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import collections\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from functions import import_imagedata, ImageProcessor, label_oh_tf, IDSWDataSetLoader2\n",
    "from fns4wandb import set_lossfn\n",
    "from architectures import sevennet, smallnet1, smallnet2, smallnet3\n",
    "from architectures import PrintLayer, smallnet3\n",
    "from loop_fns import loop#, loop_batch, test_loop_batch\n",
    "from plotting import learning_curve, accuracy_curve, plot_confusion\n",
    "\n",
    "\n",
    "\n",
    "#import torch.Utils.data.DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ace79-5b6a-4955-9fd3-52aeaddf0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = torch.cuda.memory_summary(device, abbreviated=False)\n",
    "#Pp = pprint.PrettyPrinter(indent=4)\n",
    "#Pp.pprint(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c1e605-9a3b-48dc-a38e-8a955bd3c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "_save_location = r'/its/home/nn268/antvis/antvis/optics/res_big_loop_saves/models/batch/schedulerRuns/4c/150E/RoP/' #vgg16\n",
    "\n",
    "data_path = r'/its/home/nn268/antvis/antvis/optics/AugmentedDS_IDSW/'\n",
    "\n",
    "gitHASH = '3e1975b1ac9d8c07dae424e08dacb2d2ce5f54f9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1481ccd-4d87-4c05-84d5-77e29ee981b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaughticalnonsence\u001b[0m (\u001b[33mantvis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49eb7e06-506f-48e6-b28c-8caa7641b11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datetime\n",
    "\n",
    "d = date.today()\n",
    "#print(str(d), type(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87383b",
   "metadata": {},
   "source": [
    "452 144 5/452 *100 = 1%\n",
    "226 72 5/226 *100 = 2%\n",
    "113 36 5/113 *100 = 4% -- 2/113 *100= 1.7% ~ 2%\n",
    "57 18 (56.5,) 5/57 *100 = 8% -- 2/57 *100 = 3.5% ~ 4%. 1/57 = 1.75%\n",
    "29 9 (28.5,) 5/29 *100 = 17% -- 2/29 *100 = 6.89 ~ 7% 1/28 = 3.57 ~ 4%\n",
    "15 5 (14.5, 4.5)\n",
    "8 3 (7.5,2.5)\n",
    "4, 2 (, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ddbb49-828b-4de8-a31c-2a576cd736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries                                                                                  * * * *   SETTINGS   * * * *\n",
    "\n",
    "date = date.today()\n",
    "\n",
    "model_card_vgg = {'name': 'vgg', 'model': 'vgg16',\n",
    "                  'f_lin_lay':[200704,#200704,     #129024,#4096,  # (1x229376 and 25088x4096)  1x229376 and 25088x4096) 1x229376 and 25088x4096)\n",
    "                             200704,      #(16x64512 and 129024x4096)    (16x200704 and 64512x4096)\n",
    "                             14336,\n",
    "                             3584,\n",
    "                             768,\n",
    "                             4096,\n",
    "                             4096,\n",
    "                            ],\n",
    "                 'idx': 0,\n",
    "                 'dropout':0.2}\n",
    "\n",
    "\n",
    "model_card_7c3l = {'name': '7c3l', 'model': '7c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[248832,    # 452 144 # p5\n",
    "                            59904,      # 226 72 # p5\n",
    "                            11264,      # 113 36 # p2\n",
    "                            1536,       # 57 18 # p1\n",
    "                            172032,           # 29 9\n",
    "                            172032,          # 15 5\n",
    "                            172032,         # 8 3\n",
    "                              ], \n",
    "                   'idx': 1,\n",
    "                  'dropout':0.2}\n",
    "\n",
    "\n",
    "\n",
    "model_card_4c3l = {'name': '4c3l', 'model': '4c3l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[539904,# 1055232,#539904,    # 452 144 # p5  (64x539904 and 1055232x100)\n",
    "                             141056, #141056,    # 226 72 # p5   64x141056 and 267264x100)\n",
    "                             35840,     # 113 36 # p2   (64x35840 and 304640x100)\n",
    "                             9984,      # 57 18 # p1 \n",
    "                             2304,      # 29 9\n",
    "                             512,       # 15 5\n",
    "                             256],      # 8 3\n",
    "                  'idx': 2,\n",
    "                  'dropout':0.2}      \n",
    "\n",
    "model_card_3c2l = {'name': '3c2l', 'model': '3c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1069888,    # 452 144 # p5\n",
    "                             274688,     #226 72 # p5\n",
    "                             68096,      # 113 36 # p2\n",
    "                             17280,      # 57 18 # p1\n",
    "                             3840,       # 29 9\n",
    "                             960,        # 15 5\n",
    "                             256],\n",
    "                  'idx': 3,\n",
    "                  'dropout':0.2}       # 8 3\n",
    "\n",
    "model_card_2c2l = {'name': '2c2l', 'model': '2c2l', 'channels': 3, 'Ks': (3,5),\n",
    "                  'f_lin_lay':[1055232 , #1032192,# 16883712,#33767424,    # 452 144 # p5 # (1x33767424 and 1055232x100) (1x5276160 and 15828480x100) 1x33767424 and 5276160x100)\n",
    "                             267264,     #226 72 # p5                   (1x1032192 and 64512x100)\n",
    "                             64512,#   1032192,#64512,      # 113 36 # p2    ### (16x1055232 and 1032192x100) ###  16x1055232 and 1032192x100)\n",
    "                             15552,      # 57 18 # p1\n",
    "                             3072,       # 29 9\n",
    "                             640,        # 15 5\n",
    "                             128],\n",
    "                  'idx': 4,\n",
    "                  'dropout':0.1}       # 8 3\n",
    "\n",
    "resolution_card_452144 = {'resolution':[452,144], 'padding':5, 'index':0}\n",
    "resolution_card_22672 = {'resolution':[226,72], 'padding':5, 'index':1}\n",
    "resolution_card_11336 = {'resolution':[113,36], 'padding':2, 'index':2}\n",
    "resolution_card_5715 = {'resolution':[57,18], 'padding':1, 'index':3}\n",
    "\n",
    "resolution_card_299 = {'resolution':[29,9], 'padding':0, 'index':4} # \n",
    "resolution_card_155 = {'resolution':[15,5], 'padding':0, 'index':5}\n",
    "resolution_card_83 = {'resolution':[8,3], 'padding':0, 'index':6}\n",
    "\n",
    "\n",
    "\n",
    "resolution_cards = [resolution_card_452144, resolution_card_11336, resolution_card_5715, resolution_card_155]#[resolution_card_11336, resolution_card_5715,\n",
    "#resolution_card_299, resolution_card_155, resolution_card_83]#]#resolution_card_452144, \n",
    "#resolution_cards = [resolution_card_11336]\n",
    "\n",
    "#learning_rate_cards = [5e-5, 6e-5, 8e-5]\n",
    "#learning_rate_cards = [8.21592E-05, 6.62E-05, 6.01E-05, 5.97E-05]\n",
    "learning_rate_cards=  [1e-3] #[0.1,0.01, 1e-3,1e-4, 1e-5]#, 6e-5, 7e-5, 8e-5]\n",
    "#wd_cards = [4e-5, 5e-5, 3.00E-05, 2.00E-05]\n",
    "wd_cards =[0]\n",
    "scheduler_cards = [0]#, 0.1, 0.2]\n",
    "\n",
    "seeds = [8,2,4, 42]#,2,3] # 4, 5,6\n",
    "\n",
    "#model_cards =[model_card_vgg, model_card_7c3l, model_card_4c3l, model_card_3c2l, model_card_2c2l]\n",
    "model_cards =[model_card_4c3l]\n",
    "\n",
    "loss_fn_cards = ['MSE'] #,'CrossEntropy' \n",
    "                        \n",
    "config = dict({'parameters': 'parameters for big loop run'})\n",
    "config.update({'model_cards':model_cards})\n",
    "config.update({'resolution_cards':resolution_cards})\n",
    "config.update({'learning_rate_cards':learning_rate_cards})\n",
    "config.update({'wd_cards':wd_cards})\n",
    "config.update({'scheduler_cards':scheduler_cards})\n",
    "config.update({'seeds':seeds})\n",
    "config.update({'loss_fn_cards': loss_fn_cards})\n",
    "\n",
    "\n",
    "config.update({'batch_size': 64})\n",
    "config.update({'epochs': 150}) #60\n",
    "\n",
    "#print(model_card_vgg)\n",
    "#print('')\n",
    "#Pp.pprint(Config) # dictionary of dictionaries of lists and lists of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8393-e7da-43eb-b0e7-b11c4a46c8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "Pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def save2csv_nest_dict(nested_dict, file_name, save_location:str):\n",
    "    # flattern nested dictionary\n",
    "    flatterend_dict = {}\n",
    "    for k,v in nested_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for nested_key, nested_val in v.items():\n",
    "                flatterend_dict[f\"{k}_{nested_key}\"] = nested_val\n",
    "        else:\n",
    "            flatterend_dict[k] =v\n",
    "    \n",
    "    columns = list(flatterend_dict.keys())\n",
    "    \n",
    "    with open(save_location+str(file_name)+'.csv', \"a+\", newline=\"\") as f:\n",
    "        # using dictwriter\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        # using writeheader function\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(flatterend_dict)\n",
    "        f.close()\n",
    "\n",
    "# check dictionary values for json and csv\n",
    "\n",
    "def check_obj4np(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: check_obj4np(value) for key, value in obj.items()}\n",
    "    if isinstance(obj,list):\n",
    "        return [check_obj4np(item) for item in obj]\n",
    "    if isinstance(obj,np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# save to json\n",
    "def save2josn_nested_dict(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    with open(save_location+str(file_name)+'.json', 'a+') as f:\n",
    "        f.write(json_obj)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "#save_location+str(file_name)+'.csv'\n",
    "def save2csv(nested_dict, file_name, save_location:str):\n",
    "    \n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    \n",
    "    columns = list(nested_dict.keys())\n",
    "    path = os.path.join(save_location, file_name +\".csv\")\n",
    "    try:\n",
    "        with open(path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            # using dictwriter\n",
    "            # using writeheader function\n",
    "            if f.tell() == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(nested_dict)\n",
    "            f.close()\n",
    "    except IOError as e:\n",
    "        print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "    except ValueError:\n",
    "              print(\"could not convert to string\")\n",
    "    except:\n",
    "              print(\"unexpected error: \", sys.exc_info()[0])\n",
    "        \n",
    "\n",
    "def save2json(nested_dict, file_name, save_location:str):\n",
    "    nested_dict = check_obj4np(nested_dict)\n",
    "    #print(nested_dict)\n",
    "    #print(nested_dict.items())\n",
    "    json_obj = json.dumps(nested_dict, indent=4)\n",
    "    #print(json_obj)\n",
    "    path = os.path.join(save_location, file_name+\".json\")\n",
    "    #print(path)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_obj)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def read_in_json(file_path, file_name):\n",
    "    path = os.path.join(file_path, 'file_name')\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            #obj = f.read()\n",
    "            dj = json.load(f, object_pairs_hook= collections.OrderedDict) #obj, \n",
    "            #print(dj)\n",
    "    except Exception as e:\n",
    "        print(\"Error decoding Json\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "class Flattern(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flattern, self).__init__()\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.flatten()\n",
    "        return x\n",
    "\n",
    "\n",
    "def choose_model(model_name, lin_lay, dropout):\n",
    "\n",
    "    if model_name == '4c3l':\n",
    "        return smallnet1(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '3c2l':\n",
    "        return smallnet2(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks = (3,5), dropout=dropout)\n",
    "    elif model_name == '2c2l':\n",
    "        return smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == '7c3l':\n",
    "        return sevennet(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout)\n",
    "    elif model_name == 'vgg16':\n",
    "        #model_vgg16 = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "        #vgg_feats = model_vgg16.features\n",
    "        #vgg_classifier = model_vgg16.classifier\n",
    "        #vgg_classifier.pop(6)\n",
    "\n",
    "        #vgg = nn.Sequential(\n",
    "        #    vgg_feats,\n",
    "        #    Flattern(),\n",
    "        #    vgg_classifier,\n",
    "        #    nn.Linear(4096,11), # cheanging the output layer\n",
    "        #    nn.Softmax(dim=0),    (1x1032192 and 4096x4096)\n",
    "        #    )\n",
    "        \n",
    "        class VGG16Smaller(nn.Module):\n",
    "            def __init__(self,lin_lay, num_classes=11): #64512\n",
    "                super(VGG16Smaller, self).__init__()\n",
    "                self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU())\n",
    "                self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(), \n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.layer3 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU())\n",
    "                self.layer4 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.layer5 = nn.Sequential(\n",
    "                    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU())\n",
    "                self.layer6 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU())\n",
    "                self.layer7 = nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "                self.fc = nn.Sequential(\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(lin_lay, 4096), # 1032192 and 4096x4096)\n",
    "                    nn.ReLU())\n",
    "                self.fc1 = nn.Sequential(\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(4096, 4096),\n",
    "                    nn.ReLU())\n",
    "                self.fc2= nn.Sequential(\n",
    "                    nn.Linear(4096, num_classes))\n",
    "                \n",
    "            def forward(self, x):\n",
    "                out = self.layer1(x)\n",
    "                out = self.layer2(out)\n",
    "                out = self.layer3(out)\n",
    "                out = self.layer4(out)\n",
    "                out = self.layer5(out)\n",
    "                out = self.layer6(out)\n",
    "                out = self.layer7(out)\n",
    "                PrintLayer()\n",
    "                out = out.reshape(out.size(0), -1)\n",
    "                out = out.flatten(start_dim=1)\n",
    "                PrintLayer()\n",
    "                out = self.fc(out)\n",
    "                out = self.fc1(out)\n",
    "                out = self.fc2(out)\n",
    "                out = F.log_softmax(out, dim=1) \n",
    "                return out\n",
    "        vgg = VGG16Smaller(lin_lay)\n",
    "        return vgg\n",
    "    else:\n",
    "        print('Model Name Not Recognised')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_model_sizes_bits(model):\n",
    "    bits = 32\n",
    "    mods = list(model.modules())\n",
    "    sizes = []\n",
    "    total_bits = 0\n",
    "    \n",
    "    for i in range(1,len(mods)):\n",
    "        m = mods[i]\n",
    "        p = list(m.parameters())\n",
    "        for j in range(len(p)):\n",
    "            sizes.append(np.array(p[j].size()))\n",
    "    \n",
    "    for i in range(len(sizes)):\n",
    "        s = sizes[i]\n",
    "        bitz = np.prod(np.array(s))*bits\n",
    "        total_bits += bitz\n",
    "    total_bytes = total_bits/8\n",
    "    total_megabytes = total_bytes/1e+6\n",
    "    total_gigabytes = total_megabytes/1000\n",
    "    print(total_bits, 'bits    ', total_bytes, \"bytes    \", total_megabytes, \"MegaBytes    \", total_gigabytes,\"GigaBytes\") # 148480\n",
    "\n",
    "\n",
    "def ptrblk_fin_mod_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    size_all_gb = size_all_mb/953.674\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    print('model size: {:.3f}GB'.format(size_all_gb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495f38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_batch(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device): #train_dl, val_dl, \n",
    "    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3) \n",
    "    model.train()\n",
    "\n",
    "    t_loss_list = []\n",
    "    v_loss_list = []\n",
    "    t_predict_list = []\n",
    "    v_predict_list = []\n",
    "    t_accuracy_list = []\n",
    "    v_accuracy_list = []\n",
    "    t_label_list = []\n",
    "    v_label_list = []\n",
    "    #labels = []\n",
    "    sample = False\n",
    "    \n",
    "    \n",
    "    total_epochs = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        #if epoch == 1:\n",
    "        #    sample = True\n",
    "        random_value = random.randrange(0,batch_size)\n",
    "        #else:\n",
    "        #    random_value = None\n",
    "        #    sample = False\n",
    "        #print(random_value)\n",
    "\n",
    "        \n",
    "        print('Training...')\n",
    "        #!nvidia-smi\n",
    "        #print(len(train)) #Using a target size \n",
    "\n",
    "        \n",
    "        t_loss, train_prediction, train_targets, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
    "        print('training..  2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        t_loss_list.append(t_loss)\n",
    "        [t_predict_list.append(pred.argmax()) for pred in train_prediction]\n",
    "        wandb.log({'t_loss':t_loss})\n",
    "    \n",
    "        train_acc = (t_correct/(len(train)*batch_size)*100) ###\n",
    "        print('train accuracy: ', train_acc )\n",
    "        t_accuracy_list.append(train_acc)\n",
    "        wandb.log({'train_acc':train_acc})\n",
    "        \n",
    "        \n",
    "            \n",
    "        print('validating...')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        v_loss, val_prediction, val_targets, val_correct= loop_batch(model, val, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =False)\n",
    "\n",
    "        v_loss_list.append(v_loss)\n",
    "        [v_predict_list.append(pred.argmax()) for pred in val_prediction]\n",
    "        wandb.log({'v_loss':v_loss})\n",
    "        \n",
    "        val_acc = (val_correct/(len(val)*batch_size)*100)\n",
    "        v_accuracy_list.append(val_acc)\n",
    "        print('validation accuracy: ', val_acc )\n",
    "        wandb.log({'val_acc':val_acc})\n",
    "    \n",
    "        total_epochs += 1\n",
    "        \n",
    "    save_dict['Current_Epoch'] = epochs\n",
    "    save_dict['training_samples'] = len(train)\n",
    "    save_dict['validation_samples'] = len(val)\n",
    "    \n",
    "    save_dict['t_accuracy_list'] = t_accuracy_list \n",
    "    save_dict['v_accuracy_list'] = v_accuracy_list  #\n",
    "            \n",
    "    #model = best_model\n",
    "    save_dict['t_loss_list'] = t_loss_list\n",
    "    save_dict['v_loss_list'] = v_loss_list\n",
    "    \n",
    "    save_dict['t_labels'] = train_targets\n",
    "    save_dict['v_labels'] = val_targets\n",
    "    \n",
    "    save_dict['t_predict_list'] = t_predict_list \n",
    "    save_dict['v_predict_list'] = v_predict_list  #\n",
    "    \n",
    "    return model, save_dict\n",
    "\n",
    "from functions import ImageProcessor\n",
    "\n",
    "def loop_batch(model, data, loss_fn, batch_size, sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =None, scheduler= None, train =True):\t# Train and Val loops. Default is train\n",
    "    model = model\n",
    "    total_samples = len(data)\n",
    "    if optimizer:\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=10)\n",
    "    if train:\n",
    "        model.train()\n",
    "        where ='tra'\n",
    "        #lr_ls = []\n",
    "    else:\n",
    "        model.eval()   #  (torch.Size([16, 11])) that is different to the input size (torch.Size([11]))\n",
    "        where = 'val'\n",
    "\n",
    "    predict_list = []\n",
    "    total_count = 0\n",
    "    num_correct = 0\n",
    "    current_loss = 0\n",
    "    labels =[]\n",
    "\n",
    "    \n",
    "    for i, batch in enumerate(data,0):\n",
    "        #print('loop batch 1')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        if sample == True:\n",
    "            IP = ImageProcessor(device) #img, scale:int, save_dict;dict, epoch:int, where:str\n",
    "            i = IP.view(x_batch[random_value],1, loop_run_name, save_dict, epoch, where)\n",
    "            # \n",
    "            sample= False\n",
    "\n",
    "        #print(\"x_batch item check \", x_batch[0].shape)\n",
    "        #print(\"y_batch item check \", y_batch[0].shape)\n",
    "        #print(\"-----   x batch shape   -----\",x_batch.shape) #torch.Size([16, 3, 144, 462])\n",
    "\n",
    "        #print(x_batch[0].shape) # torch.Size([3, 144, 462])\n",
    "        #print(y_batch[0].shape) # torch.Size([11])\n",
    "\n",
    "        #print('loop batch 2')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        \n",
    "        \n",
    "        prediction = model.forward(x_batch)\n",
    "\n",
    "        #print(prediction.shape)  # torch.Size([11])\n",
    "        #print(y_batch.shape)     # torch.Size([16, 11])\n",
    "\n",
    "        #print('loop batch 3')\n",
    "        #!nvidia-smi\n",
    "        #print(\"checking range nums  \", len(y_batch), len(y_batch)-1)\n",
    "        #print(\"len x batch \", len(x_batch))\n",
    "        #print(\"len prediction \", len(prediction))\n",
    "        #print(\"prediction  \", prediction.argmax(), prediction.shape)\n",
    "        #print(\"prediction[1]\", prediction[1].argmax())\n",
    "        #print(\"y batch[1]\", y_batch[1].argmax(), y_batch[1].shape)\n",
    "\n",
    "        loss = loss_fn(prediction, y_batch)\n",
    "        \n",
    "        #print('loop batch 4')\n",
    "        #!nvidia-smi\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print('loop batch 5')\n",
    "        #!nvidia-smi\n",
    "            \n",
    "        [predict_list.append(pred.argmax()) for pred in prediction]#.argmax())\n",
    "        [labels.append(y.argmax()) for y in y_batch]\n",
    "        \n",
    "        \n",
    "        for i in range(len(y_batch)-1):\n",
    "            \n",
    "            #print(\"y \",y_batch[i].argmax())\n",
    "            #print(\"pred \", prediction[i].argmax())\n",
    "            if y_batch[i].argmax() == prediction[i].argmax():\n",
    "                num_correct +=1\n",
    "\n",
    "        \"\"\"\n",
    "        if y_batch[i].argmax() == prediction[i].argmax():\n",
    "        IndexError: index 11 is out of bounds for dimension 0 with size 11\n",
    "        \"\"\"\n",
    "\n",
    "        total_count+= batch_size\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        #print('loop batch 6')\n",
    "        #!nvidia-smi\n",
    "        \n",
    "    if scheduler:\n",
    "        scheduler.step(loss)\n",
    "\n",
    "    if train:\n",
    "        return current_loss, predict_list, y_batch, num_correct, model, optimizer #, lr_ls\n",
    "    else:\n",
    "        return current_loss, predict_list, y_batch, num_correct\n",
    "\n",
    "\n",
    "def test_loop(model, model_name, X, Y, res, pad, save_dict, loss_fn, device, av_lum, num_classes=11):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    current_loss = 0\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    colour ='colour'\n",
    "    size =  res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Testing...') \n",
    "        for idx, img in enumerate(X):\n",
    "\n",
    "            #image pre processing\n",
    "            prepro = ImageProcessor(device)\n",
    "            if model_name == 'vgg16':\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True) #[29, 9], 15, 5, [8,3]\n",
    "            elif (model_name == '7c3l' and size == [29, 9]) or (model_name == '7c3l' and size == [15, 5]) or (model_name == '7c3l' and size ==[8, 3]):\n",
    "                tense = prepro.colour_size_tense(img, colour, size, av_lum, pad, vg=True)\n",
    "            else:\n",
    "                tense = prepro.colour_size_tense(img, colour, size,av_lum,  pad)\n",
    "\n",
    "\n",
    "            tense = tense.unsqueeze(dim=0)\n",
    "\n",
    "            prediction = model.forward(tense)\n",
    "            label = label_oh_tf(Y[idx], num_classes).to(device)\n",
    "\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "            loss = loss_fn(prediction, label)\n",
    "\n",
    "            if prediction.argmax()==label.argmax():\n",
    "                num_correct +=1\n",
    "            total_count +=1\n",
    "            correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "\n",
    "            predict_list.append(prediction.argmax())\n",
    "\n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    return accuracy, predict_list, Y, current_loss\n",
    "\n",
    "## model, data, loss_fn, device, optimizer =None, scheduler= None, train =True\n",
    "def test_loop_batch(model,data, loss_fn, batch_size, device):\n",
    "    model = model.eval()\n",
    "    predict_list = []\n",
    "    label_list = []\n",
    "    total_count =0\n",
    "    num_correct = 0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data,0):\n",
    "            #tense = tense.to(device)\n",
    "            tense, label = batch\n",
    "            label = label.to(device)\n",
    "            \n",
    "            prediction = model.forward(tense.to(device))\n",
    "            #print('p', prediction.shape, 'l ', label.shape)\n",
    "            #label = label_oh_tf(Y[idx], device, num_classes)\n",
    "            for i in range(len(label)-1):\n",
    "                #print(len(label), label[0].argmax(), len(label)-1)\n",
    "                if label[i].argmax() == prediction[i].argmax():\n",
    "                    num_correct +=1\n",
    "            [predict_list.append(pred.argmax()) for pred in prediction]\n",
    "            [label_list.append(lab.argmax()) for lab in label]\n",
    "            # label[i] == predictoin[i]. \n",
    "    \n",
    "            #if prediction.argmax()==label.argmax():\n",
    "            #    num_correct +=1\n",
    "            total_count += batch_size\n",
    "            #correct +=(prediction.argmax()==label.argmax()).sum().item()\n",
    "    \n",
    "        acc = num_correct/total_count\n",
    "        accuracy = 100*(acc)\n",
    "\n",
    "        print(accuracy)\n",
    "\n",
    "        #print(len(predict_list), len(label_list))\n",
    "    \n",
    "        #X = list(X)\n",
    "        #log_test_score(acc, accuracy, X) # test_acc,test_predict_list, y_test, test_loss \n",
    "        return accuracy, predict_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "def get_data(random_seed):\n",
    "    file_path =  data_path\n",
    "    #print(file_path)\n",
    "    img_len = len(os.listdir(file_path))\n",
    "    \n",
    "    x, y = import_imagedata(file_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.3, train_size=0.7,\n",
    "                                     random_state=random_seed, shuffle=True)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "    \n",
    "def get_lin_lay(model_card, resolution):\n",
    "    if resolution == [452, 144]:\n",
    "        lin_lay = model_card['f_lin_lay'][0]\n",
    "    elif resolution == [226, 72]:\n",
    "        lin_lay = model_card['f_lin_lay'][1]\n",
    "    elif resolution == [113, 36]:\n",
    "        lin_lay = model_card['f_lin_lay'][2]\n",
    "    elif resolution == [57, 18]:\n",
    "        lin_lay = model_card['f_lin_lay'][3]\n",
    "    elif resolution == [29, 9]:\n",
    "        lin_lay = model_card['f_lin_lay'][4]\n",
    "    elif resolution == [15, 5]:\n",
    "        lin_lay = model_card['f_lin_lay'][5]\n",
    "    elif resolution == [8, 3]:\n",
    "        lin_lay = model_card['f_lin_lay'][6]\n",
    "    else:\n",
    "        print(\"PARAMETER NOT FOUND: \\n f_lin_lay FROM MODEL CARD\")\n",
    "    return lin_lay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb440d2-6fa6-43a4-a083-63a07edbdb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141056\n"
     ]
    }
   ],
   "source": [
    "for model_card in model_cards:\n",
    "    lin = get_lin_lay(model_card,[226,72])\n",
    "    print(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf5ca7f-b59a-427b-8da3-2848fa6d3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def _go(config=None):\n",
    "    #print('1')\n",
    "    #!nvidia-smi\n",
    "    \n",
    "    #print(\"Max allocated memory (GB):\", torch.cuda.max_memory_allocated() / 1024 ** 3)\n",
    "    \n",
    "    if len(gitHASH) <1:\n",
    "        print(\"YOU FORGET THE GIT HASH\")\n",
    "        return\n",
    "    else:\n",
    "        #print('Git Hash registered')\n",
    "        pass\n",
    "        \n",
    "    with wandb.init(config=config, project=f\"4c. 100E. RoP sched. Adam\", notes=\"4c. 100E. RoP sched. Adam\",):\n",
    "        config = wandb.config\n",
    "        start = time.process_time()\n",
    "            \n",
    "        for model_idx, model_card in enumerate(config['model_cards']):\n",
    "            #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                    \n",
    "            model_name = model_card['model']\n",
    "            model_index = model_card['idx']\n",
    "            dropout = model_card['dropout'] \n",
    "            for res_idx, resolution_card in enumerate(config['resolution_cards']):\n",
    "                #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "            \n",
    "                resolution = resolution_card['resolution']\n",
    "                pad = resolution_card['padding']\n",
    "                lin_lay = get_lin_lay(model_card, resolution)\n",
    "                print('lin lay', lin_lay)\n",
    "            \n",
    "                for lr_idx, lr in enumerate(config['learning_rate_cards']):\n",
    "                    for wd_idx, wd_card in enumerate(wd_cards):\n",
    "                        for sched_idx, scheduler_value in enumerate(config['scheduler_cards']):\n",
    "                            \n",
    "                            for seed_idx, seed in enumerate(config['seeds']):\n",
    "                                seed = seed\n",
    "                                for lossfn_idx, loss in enumerate(config['loss_fn_cards']):\n",
    "                                    \n",
    "                                    torch.cuda.empty_cache()\n",
    "                                    #print('2')\n",
    "                                    #!nvidia-smi\n",
    "  \n",
    "                                    config['batch_size']\n",
    "\n",
    "                                    print('Model: ', str(model_name), f\" idx: {model_idx} / {len(config.model_cards)}\")\n",
    "                                    print('resolution: ', str(resolution), f\" idx: {res_idx} / {len(config['resolution_cards'])}\")\n",
    "                                    print('learning rate: ', str(lr), f\" idx: {lr_idx} / {len(config['learning_rate_cards'])}\")\n",
    "                                    print('weight decay: ', str(wd_card), f\" idx: {wd_idx} / {len(config['wd_cards'])}\")\n",
    "                                    print('scheduler: ', str(scheduler_value), f\" idx: {sched_idx} / {len(config['scheduler_cards'])}\")\n",
    "                                    print('seed: ', str(seed), f\" idx: {seed_idx} / {len(config['seeds'])}\")\n",
    "                                    print('loss function: ', str(loss), f\" idx: {lossfn_idx} / {len(config['loss_fn_cards'])}\")\n",
    "                                    print('Batch size: ', config['batch_size'])\n",
    "                                    print('Training epochs: ', config['epochs'])\n",
    "                                    run_start_time = time.process_time()\n",
    "                                    print('start time: ',run_start_time)\n",
    "   \n",
    "                                    print(time.process_time() - start)\n",
    "\n",
    "                                    epochs = config['epochs'] #40\n",
    "\n",
    "                                    IP = ImageProcessor(device)\n",
    "\n",
    "                                    wandb.log({'gitHash':gitHASH})\n",
    "                                    wandb.log({'Epochs': epochs})\n",
    "                                    \n",
    "                                    #print('3')\n",
    "                                    #!nvidia-smi\n",
    "                                    \n",
    "                                    # set save dictionary\n",
    "                                    save_dict = {'Run' : f\"{model_name}_{resolution}_{date}_100E_RoPscheduler\",\n",
    "                                                 'Current_Epoch': 0,\n",
    "                                                 'save_location' : _save_location}\n",
    "          \n",
    "                                    model = choose_model(model_name, lin_lay, dropout).to(device)\n",
    "                                    #print(\"Before model init - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    #model = smallnet3(in_chan=3, f_lin_lay=int(lin_lay), l_lin_lay=11, ks= (3,5), dropout= dropout).to(device)\n",
    "\n",
    "                                    #print('4')\n",
    "                                    #!nvidia-smi\n",
    "\n",
    "                                    #print(\"After model init, Before data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "                                    x_train, y_train, x_val, y_val, x_test, y_test = get_data(seed)\n",
    "                                    av_lum = IP.new_luminance(x_train)\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    \n",
    "                                    train_ds = IDSWDataSetLoader2(x_train, y_train, resolution,pad,av_lum,model_name, device)# av_lum, res,pad,\n",
    "                                    train = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "\n",
    "                                    \n",
    "                                    test_ds = IDSWDataSetLoader2(x_test, y_test, resolution,pad,av_lum,model_name, device)\n",
    "                                    test = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    #print(\"Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "                                    val_ds = IDSWDataSetLoader2(x_val, y_val, resolution,pad,av_lum,model_name, device)\n",
    "                                    val = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=True, drop_last=True) #, num_workers=2\n",
    "                                    \n",
    "                                    #print(\"After data loading - Current allocated memory (GB):\", torch.cuda.memory_allocated() / 1024 ** 3)\n",
    "\n",
    "\n",
    "                                    #print('5')\n",
    "                                    #!nvidia-smi\n",
    "\n",
    "                                    loss_fn = set_lossfn(loss)\n",
    "                                    \n",
    "                                    # set optimizer\n",
    "                                    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "                                    wandb.watch(model, loss_fn, log='all', log_freq=2, idx = model_index)\n",
    "                                    #print('6')\n",
    "                                    #!nvidia-smi\n",
    "                                    loop_run_name = f\"{save_dict['Run']}_{resolution}_{lr}_{scheduler_value}_{seed}_{loss}\"\n",
    "         \n",
    "                                    model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
    "\n",
    "                                    test_acc,test_predict_list, y_test = test_loop_batch(model,test, loss_fn, config['batch_size'], device) #model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\n",
    "                                    \n",
    "                                    #print(test_predict_list)\n",
    "                                    print(' \\n train Acc: ', save_dict['t_accuracy_list'][-1])\n",
    "                                    print(' \\n val Acc: ', save_dict['v_accuracy_list'][-1])\n",
    "                                    print(' \\n test Acc: ', test_acc)\n",
    "                                    \n",
    "                                    save_dict.update({'test_acc': test_acc})\n",
    "                                    save_dict.update({'test_predict': test_predict_list})\n",
    "                                    save_dict.update({'test_labels': list(y_test)})\n",
    "                                    #save_dict.update({'test_loss':test_loss})\n",
    "\n",
    "                                    \n",
    "\n",
    "\n",
    "                                    learning_curve(save_dict['t_loss_list'], save_dict['v_loss_list'], save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    accuracy_curve(save_dict['t_accuracy_list'], save_dict['v_accuracy_list'],save_location=save_dict['save_location'],run_name=loop_run_name)\n",
    "                                    test_predict_list=[pred.cpu() for pred in test_predict_list]\n",
    "                                    plot_confusion(predictions= test_predict_list, actual= y_test, title = \"Test Confusion matrix\", run_name = loop_run_name,save_location =save_dict['save_location'])\n",
    "                                    \n",
    "                                    wandb.log({'test_acc': test_acc})\n",
    "                                    wandb.log({'test_predict': test_predict_list})\n",
    "                                    wandb.log({'test_labels': list(y_test)})\n",
    "                                    #saving\n",
    "                                    diction = {}\n",
    "                                    d = date.today()\n",
    "                                    d=str(d)\n",
    "                                    diction.update({'Date':d})\n",
    "                                    diction.update({'gitHASH':str(gitHASH)})\n",
    "                                    diction.update({'model_name': str(model_name)})\n",
    "                                    diction.update({'loss_fn': str(loss)})\n",
    "                                    diction.update({'lr': str(lr)})\n",
    "                                    diction.update({'wd': str(wd_card)})\n",
    "                                    diction.update({'scheduler value': str(scheduler_value)})\n",
    "                                    diction.update({'seed': str(seed)})\n",
    "                                    diction.update({'resolution': str(resolution)})\n",
    "                                    diction.update({'pad': int(pad)})\n",
    "                                    diction.update({'lin_lay': int(lin_lay)})\n",
    "                                    diction.update({'run time': (time.process_time() - run_start_time)})\n",
    "                                    diction.update(save_dict)\n",
    "                                    \n",
    "                                    save_location = save_dict['save_location']\n",
    "                                    title = save_dict['Run']\n",
    "                                    save2json(diction, loop_run_name, save_location)\n",
    "                                    save2csv(diction, title, save_location)\n",
    "        \n",
    "                                    diction['model.state_dict'] = model.state_dict() #to('cpu').\n",
    "        \n",
    "                                    with open(f\"{save_location}{loop_run_name}.pkl\", 'wb+') as f:\n",
    "                                        pickle.dump(diction, f)\n",
    "                                    \n",
    "                                    clear_output()\n",
    "                                    \n",
    "                                    print(f' \\n END {model_name} {resolution} Run Time: ',time.process_time() - run_start_time)\n",
    "                                    #!nvidia-smi\n",
    "                                    torch.cuda.empty_cache()\n",
    "        print('Final Run time: ',time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58d7d27-ef9d-43d9-98a8-1f11ff50090d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/its/home/nn268/antvis/antvis/optics/Batchcode/wandb/run-20241107_175132-p4mt9mdk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/runs/p4mt9mdk' target=\"_blank\">radiant-frost-5</a></strong> to <a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam' target=\"_blank\">https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/runs/p4mt9mdk' target=\"_blank\">https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/runs/p4mt9mdk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin lay 539904\n",
      "Model:  4c3l  idx: 0 / 1\n",
      "resolution:  [452, 144]  idx: 0 / 4\n",
      "learning rate:  0.001  idx: 0 / 1\n",
      "weight decay:  0  idx: 0 / 1\n",
      "scheduler:  0  idx: 0 / 1\n",
      "seed:  8  idx: 0 / 4\n",
      "loss function:  MSE  idx: 0 / 1\n",
      "Batch size:  64\n",
      "Training epochs:  150\n",
      "start time:  10.481294933\n",
      "0.0010863140000001437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                 | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/its/home/nn268/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "  0%|                 | 0/150 [00:01<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_328415/1315113482.py\", line 117, in _go\n",
      "    model, save_dict=  train_val_batch(model, train,val, loop_run_name,save_dict, lr, loss_fn,epochs, config['batch_size'], optimizer, scheduler_value, device)\n",
      "  File \"/tmp/ipykernel_328415/3606399789.py\", line 34, in train_val_batch\n",
      "    t_loss, train_prediction, train_targets, t_correct, model, optimizer = loop_batch(model, train, loss_fn, batch_size,sample,random_value,epoch,loop_run_name, save_dict, device, optimizer =optimizer, scheduler= scheduler_value, train =True) #, scheduler =scheduler\n",
      "  File \"/tmp/ipykernel_328415/3606399789.py\", line 151, in loop_batch\n",
      "    loss.backward()\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/its/home/nn268/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacty of 23.55 GiB of which 346.50 MiB is free. Process 327746 has 15.75 GiB memory in use. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 11.6%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epochs</td><td>150</td></tr><tr><td>gitHash</td><td>3e1975b1ac9d8c07dae4...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-frost-5</strong> at: <a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/runs/p4mt9mdk' target=\"_blank\">https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/runs/p4mt9mdk</a><br/> View job at <a href='https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ4NjM3NDMzNw==/version_details/v3' target=\"_blank\">https://wandb.ai/antvis/4c.%20100E.%20RoP%20sched.%20Adam/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ4NjM3NDMzNw==/version_details/v3</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241107_175132-p4mt9mdk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacty of 23.55 GiB of which 346.50 MiB is free. Process 327746 has 15.75 GiB memory in use. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_go\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 117\u001b[0m, in \u001b[0;36m_go\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#print('6')\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n\u001b[1;32m    115\u001b[0m loop_run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m model, save_dict\u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_val_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m test_acc,test_predict_list, y_test \u001b[38;5;241m=\u001b[39m test_loop_batch(model,test, loss_fn, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], device) \u001b[38;5;66;03m#model, model_name, X, Y, res, pad, loss_fn, device, num_classes=11\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#print(test_predict_list)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m, in \u001b[0;36mtrain_val_batch\u001b[0;34m(model, train, val, loop_run_name, save_dict, lr, loss_fn, epochs, batch_size, optimizer, scheduler_value, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#print(len(train)) #Using a target size \u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m t_loss, train_prediction, train_targets, t_correct, model, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mloop_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloop_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, scheduler =scheduler\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining..  2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 151\u001b[0m, in \u001b[0;36mloop_batch\u001b[0;34m(model, data, loss_fn, batch_size, sample, random_value, epoch, loop_run_name, save_dict, device, optimizer, scheduler, train)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m    150\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m#print('loop batch 5')\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacty of 23.55 GiB of which 346.50 MiB is free. Process 327746 has 15.75 GiB memory in use. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "_go(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b31e-4bae-4f65-bc46-ee1334a8f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.58 GiB. GPU 0 has a total capacty of 23.65 GiB of which 8.04 GiB is free\n",
    "23.65-8.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daceaa-fa47-4c76-90d6-f23550f85694",
   "metadata": {},
   "source": [
    "\n",
    "pred torch.Size([11])\n",
    "\n",
    "lab  torch.Size([5, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5d251-dbcc-482b-aac0-ac24617279e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
