{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhFmVnYYdgWU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6YfyImodqTl",
        "outputId": "cb746737-0233-402b-a6a5-ca844f8bc53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cptac==1.1.0 in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.7.1 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (4.12.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (1.13.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (2.2.3)\n",
            "Requirement already satisfied: openpyxl>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (3.1.5)\n",
            "Requirement already satisfied: packaging>=19.2 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (24.2)\n",
            "Requirement already satisfied: xlrd>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (2.0.1)\n",
            "Requirement already satisfied: statsmodels>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (0.14.4)\n",
            "Requirement already satisfied: flask>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (3.0.3)\n",
            "Requirement already satisfied: gtfparse>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (2.5.0)\n",
            "Requirement already satisfied: mygene>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from cptac==1.1.0) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.7.1->cptac==1.1.0) (2.6)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.0->cptac==1.1.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.0->cptac==1.1.0) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.0->cptac==1.1.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.0->cptac==1.1.0) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.0->cptac==1.1.0) (1.9.0)\n",
            "Requirement already satisfied: polars<0.21.0,>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from gtfparse>=1.2.1->cptac==1.1.0) (0.20.31)\n",
            "Requirement already satisfied: pyarrow<14.1.0,>=14.0.2 in /usr/local/lib/python3.10/dist-packages (from gtfparse>=1.2.1->cptac==1.1.0) (14.0.2)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene>=3.2.2->cptac==1.1.0) (0.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=2.6.0->cptac==1.1.0) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->cptac==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->cptac==1.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->cptac==1.1.0) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->cptac==1.1.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->cptac==1.1.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->cptac==1.1.0) (2024.8.30)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.10.0->cptac==1.1.0) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask>=1.1.0->cptac==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->cptac==1.1.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cptac==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alyTdQsnerbH"
      },
      "outputs": [],
      "source": [
        "import cptac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-5fCjOxm-44"
      },
      "source": [
        "# Data Collection and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7vxELR_dzty",
        "outputId": "84e8c084-80e4-4c50-d169-5d636976c032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "cptac warning: Your version of cptac (1.1.0) is out-of-date. Latest is 1.5.14. Please run 'pip install --upgrade cptac' to update it. (/usr/lib/python3.10/threading.py, line 953)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "#lung adenocarcinoma\n",
        "cptac.download('luad')\n",
        "lu = cptac.Luad()\n",
        "\n",
        "#Breast Invasive Carcinoma\n",
        "cptac.download('brca')\n",
        "br = cptac.Brca()\n",
        "\n",
        "#Head and neck squamous cell carcinoma\n",
        "cptac.download('hnscc')\n",
        "hn = cptac.Hnscc()\n",
        "\n",
        "#Glioblastoma\n",
        "cptac.download('gbm')\n",
        "gbm = cptac.Gbm()\n",
        "\n",
        "#Ovarian\n",
        "cptac.download('ovarian')\n",
        "ov = cptac.Ovarian()\n",
        "\n",
        "#renal cell\n",
        "cptac.download('ccrcc')\n",
        "cc = cptac.Ccrcc()\n",
        "\n",
        "#Endometrial\n",
        "cptac.download(\"endometrial\")\n",
        "en = cptac.Endometrial()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6tBSskehGqO"
      },
      "outputs": [],
      "source": [
        "lu_transcriptome = lu.get_transcriptomics()\n",
        "lu_proteome = lu.get_proteomics()\n",
        "\n",
        "hn_transcriptome = hn.get_transcriptomics()\n",
        "hn_proteome = hn.get_proteomics()\n",
        "\n",
        "gbm_transcriptome = gbm.get_transcriptomics()\n",
        "gbm_proteome = gbm.get_proteomics()\n",
        "\n",
        "br_transcriptome = br.get_transcriptomics()\n",
        "br_proteome = br.get_proteomics()\n",
        "\n",
        "ov_transcriptome = ov.get_transcriptomics()\n",
        "ov_proteome = ov.get_proteomics()\n",
        "\n",
        "cc_transcriptome = cc.get_transcriptomics()\n",
        "cc_proteome = cc.get_proteomics()\n",
        "\n",
        "en_transcriptome = en.get_transcriptomics()\n",
        "en_proteome = en.get_proteomics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY2KClVlozb6"
      },
      "outputs": [],
      "source": [
        "lu_combined = pd.concat([lu_transcriptome, lu_proteome], axis=1)\n",
        "hn_combined = pd.concat([hn_transcriptome, hn_proteome], axis=1)\n",
        "gbm_combined = pd.concat([gbm_transcriptome, gbm_proteome], axis=1)\n",
        "br_combined = pd.concat([br_transcriptome, br_proteome], axis=1)\n",
        "ov_combined = pd.concat([ov_transcriptome, ov_proteome], axis=1)\n",
        "cc_combined = pd.concat([cc_transcriptome, cc_proteome], axis=1)\n",
        "en_combined = pd.concat([en_transcriptome, en_proteome], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1YZf8xKskaw",
        "outputId": "5263f60e-7837-4203-b155-62502b3d2d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(lu_combined.columns.duplicated().any())\n",
        "print(hn_combined.columns.duplicated().any())\n",
        "print(gbm_combined.columns.duplicated().any())\n",
        "print(br_combined.columns.duplicated().any())\n",
        "print(ov_combined.columns.duplicated().any())\n",
        "print(cc_combined.columns.duplicated().any())\n",
        "print(en_combined.columns.duplicated().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqxcH2URszi7"
      },
      "outputs": [],
      "source": [
        "hn_combined = hn_combined.loc[:, ~hn_combined.columns.duplicated()]\n",
        "en_combined = en_combined.loc[:, ~en_combined.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd_RSUWSsNNz"
      },
      "outputs": [],
      "source": [
        "lu_combined = lu_combined.add_prefix('Lung_')\n",
        "hn_combined = hn_combined.add_prefix('HeadNeck_')\n",
        "gbm_combined = gbm_combined.add_prefix('Brain_')\n",
        "br_combined = br_combined.add_prefix('Breast_')\n",
        "ov_combined = ov_combined.add_prefix('Ovarian_')\n",
        "cc_combined = cc_combined.add_prefix('Renal_')\n",
        "en_combined = en_combined.add_prefix('Endometrial_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGobBWbOwtMG"
      },
      "outputs": [],
      "source": [
        "cancer_labels = ['Lung', 'Breast', 'Head and Neck', 'Brain', 'Ovarian', 'Renal Cell', 'Endometrial']\n",
        "lu_combined['Cancer'] = cancer_labels[0]\n",
        "hn_combined['Cancer'] = cancer_labels[2]\n",
        "gbm_combined['Cancer'] = cancer_labels[3]\n",
        "br_combined['Cancer'] = cancer_labels[1]\n",
        "ov_combined['Cancer'] = cancer_labels[4]\n",
        "cc_combined['Cancer'] = cancer_labels[5]\n",
        "en_combined['Cancer'] = cancer_labels[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_zp5_O7pje0"
      },
      "outputs": [],
      "source": [
        "all_data = pd.concat([lu_combined, hn_combined, gbm_combined, br_combined,\n",
        "                          ov_combined, cc_combined, en_combined], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EL6AUxpvB8T",
        "outputId": "17ccf879-5e6d-4a93-d0bb-ac63af197705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lung_A1BG               880\n",
            "Lung_A1CF               880\n",
            "Lung_A2M                880\n",
            "Lung_A2ML1              880\n",
            "Lung_A3GALT2            888\n",
            "                       ... \n",
            "Endometrial_MT-ND3     1067\n",
            "Endometrial_MT-ND4      947\n",
            "Endometrial_MT-ND4L    1069\n",
            "Endometrial_MT-ND5      947\n",
            "Endometrial_MT-ND6      998\n",
            "Length: 263882, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "missing_values = all_data.isnull().sum()\n",
        "print(missing_values[missing_values > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAMZoIYEwlFT"
      },
      "outputs": [],
      "source": [
        "all_data_cleaned = all_data.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "4R_m6lXax7bB",
        "outputId": "36387359-fbab-47d8-9941-eeb26e3fcd68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_data_cleaned"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2d4ecfbb-481a-4100-8101-b5323ca5020c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lung_A1BG</th>\n",
              "      <th>Lung_A1CF</th>\n",
              "      <th>Lung_A2M</th>\n",
              "      <th>Lung_A2ML1</th>\n",
              "      <th>Lung_A3GALT2</th>\n",
              "      <th>Lung_A4GALT</th>\n",
              "      <th>Lung_A4GNT</th>\n",
              "      <th>Lung_AAAS</th>\n",
              "      <th>Lung_AACS</th>\n",
              "      <th>Lung_AADAC</th>\n",
              "      <th>...</th>\n",
              "      <th>Endometrial_MT-CO2</th>\n",
              "      <th>Endometrial_MT-CO3</th>\n",
              "      <th>Endometrial_MT-CYB</th>\n",
              "      <th>Endometrial_MT-ND1</th>\n",
              "      <th>Endometrial_MT-ND2</th>\n",
              "      <th>Endometrial_MT-ND3</th>\n",
              "      <th>Endometrial_MT-ND4</th>\n",
              "      <th>Endometrial_MT-ND4L</th>\n",
              "      <th>Endometrial_MT-ND5</th>\n",
              "      <th>Endometrial_MT-ND6</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Patient_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C3L-00001</th>\n",
              "      <td>2.2545</td>\n",
              "      <td>-2.7845</td>\n",
              "      <td>8.0488</td>\n",
              "      <td>-3.6051</td>\n",
              "      <td>-1.3305</td>\n",
              "      <td>0.8208</td>\n",
              "      <td>-1.0519</td>\n",
              "      <td>3.4780</td>\n",
              "      <td>2.6953</td>\n",
              "      <td>-3.3578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3L-00009</th>\n",
              "      <td>1.4770</td>\n",
              "      <td>-1.9278</td>\n",
              "      <td>8.9855</td>\n",
              "      <td>0.4851</td>\n",
              "      <td>-2.4401</td>\n",
              "      <td>1.7417</td>\n",
              "      <td>-1.5157</td>\n",
              "      <td>4.1043</td>\n",
              "      <td>2.8091</td>\n",
              "      <td>0.0472</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3L-00080</th>\n",
              "      <td>1.5103</td>\n",
              "      <td>-4.9913</td>\n",
              "      <td>7.4303</td>\n",
              "      <td>-4.3766</td>\n",
              "      <td>-2.1868</td>\n",
              "      <td>-0.3121</td>\n",
              "      <td>-2.3936</td>\n",
              "      <td>4.6577</td>\n",
              "      <td>3.0394</td>\n",
              "      <td>1.2233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3L-00083</th>\n",
              "      <td>3.0398</td>\n",
              "      <td>-3.5440</td>\n",
              "      <td>9.4109</td>\n",
              "      <td>-3.1840</td>\n",
              "      <td>-3.2313</td>\n",
              "      <td>4.3862</td>\n",
              "      <td>-3.0231</td>\n",
              "      <td>3.9942</td>\n",
              "      <td>3.4665</td>\n",
              "      <td>-1.7667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3L-00093</th>\n",
              "      <td>1.7528</td>\n",
              "      <td>-5.2883</td>\n",
              "      <td>9.1136</td>\n",
              "      <td>-2.9449</td>\n",
              "      <td>-1.9313</td>\n",
              "      <td>1.5985</td>\n",
              "      <td>-3.3751</td>\n",
              "      <td>3.8190</td>\n",
              "      <td>3.1688</td>\n",
              "      <td>-2.3956</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 263883 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d4ecfbb-481a-4100-8101-b5323ca5020c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d4ecfbb-481a-4100-8101-b5323ca5020c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d4ecfbb-481a-4100-8101-b5323ca5020c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a8aa413-d15a-41a6-8bcd-c072705abcfc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a8aa413-d15a-41a6-8bcd-c072705abcfc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a8aa413-d15a-41a6-8bcd-c072705abcfc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Lung_A1BG  Lung_A1CF  Lung_A2M  Lung_A2ML1  Lung_A3GALT2  \\\n",
              "Patient_ID                                                             \n",
              "C3L-00001      2.2545    -2.7845    8.0488     -3.6051       -1.3305   \n",
              "C3L-00009      1.4770    -1.9278    8.9855      0.4851       -2.4401   \n",
              "C3L-00080      1.5103    -4.9913    7.4303     -4.3766       -2.1868   \n",
              "C3L-00083      3.0398    -3.5440    9.4109     -3.1840       -3.2313   \n",
              "C3L-00093      1.7528    -5.2883    9.1136     -2.9449       -1.9313   \n",
              "\n",
              "            Lung_A4GALT  Lung_A4GNT  Lung_AAAS  Lung_AACS  Lung_AADAC  ...  \\\n",
              "Patient_ID                                                             ...   \n",
              "C3L-00001        0.8208     -1.0519     3.4780     2.6953     -3.3578  ...   \n",
              "C3L-00009        1.7417     -1.5157     4.1043     2.8091      0.0472  ...   \n",
              "C3L-00080       -0.3121     -2.3936     4.6577     3.0394      1.2233  ...   \n",
              "C3L-00083        4.3862     -3.0231     3.9942     3.4665     -1.7667  ...   \n",
              "C3L-00093        1.5985     -3.3751     3.8190     3.1688     -2.3956  ...   \n",
              "\n",
              "            Endometrial_MT-CO2  Endometrial_MT-CO3  Endometrial_MT-CYB  \\\n",
              "Patient_ID                                                               \n",
              "C3L-00001                  0.0                 0.0                 0.0   \n",
              "C3L-00009                  0.0                 0.0                 0.0   \n",
              "C3L-00080                  0.0                 0.0                 0.0   \n",
              "C3L-00083                  0.0                 0.0                 0.0   \n",
              "C3L-00093                  0.0                 0.0                 0.0   \n",
              "\n",
              "            Endometrial_MT-ND1  Endometrial_MT-ND2  Endometrial_MT-ND3  \\\n",
              "Patient_ID                                                               \n",
              "C3L-00001                  0.0                 0.0                 0.0   \n",
              "C3L-00009                  0.0                 0.0                 0.0   \n",
              "C3L-00080                  0.0                 0.0                 0.0   \n",
              "C3L-00083                  0.0                 0.0                 0.0   \n",
              "C3L-00093                  0.0                 0.0                 0.0   \n",
              "\n",
              "            Endometrial_MT-ND4  Endometrial_MT-ND4L  Endometrial_MT-ND5  \\\n",
              "Patient_ID                                                                \n",
              "C3L-00001                  0.0                  0.0                 0.0   \n",
              "C3L-00009                  0.0                  0.0                 0.0   \n",
              "C3L-00080                  0.0                  0.0                 0.0   \n",
              "C3L-00083                  0.0                  0.0                 0.0   \n",
              "C3L-00093                  0.0                  0.0                 0.0   \n",
              "\n",
              "            Endometrial_MT-ND6  \n",
              "Patient_ID                      \n",
              "C3L-00001                  0.0  \n",
              "C3L-00009                  0.0  \n",
              "C3L-00080                  0.0  \n",
              "C3L-00083                  0.0  \n",
              "C3L-00093                  0.0  \n",
              "\n",
              "[5 rows x 263883 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzPS5ozavcwR"
      },
      "outputs": [],
      "source": [
        "X = all_data_cleaned.drop('Cancer', axis=1)\n",
        "y = all_data_cleaned['Cancer']\n",
        "\n",
        "\n",
        "selected_columns = random.sample(list(X.columns), 4000)\n",
        "X_sample = X[selected_columns]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_sample, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xGwqIPJ4W87",
        "outputId": "b802f8cf-a9d6-44ef-9403-224d37dcc9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (872, 4000)\n",
            "X_test shape: (219, 4000)\n",
            "y_train shape: (872,)\n",
            "y_test shape: (219,)\n",
            "y_train distribution:\n",
            "Cancer\n",
            "Lung             166\n",
            "Renal Cell       161\n",
            "Head and Neck    144\n",
            "Endometrial      120\n",
            "Ovarian          102\n",
            "Breast            94\n",
            "Brain             85\n",
            "Name: count, dtype: int64\n",
            "y_test distribution:\n",
            "Cancer\n",
            "Head and Neck    45\n",
            "Lung             45\n",
            "Renal Cell       33\n",
            "Breast           28\n",
            "Endometrial      24\n",
            "Brain            24\n",
            "Ovarian          20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_val.shape)\n",
        "\n",
        "# Check class balance in the target variable\n",
        "print(\"y_train distribution:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"y_test distribution:\")\n",
        "print(y_val.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I9YoB3Y_Ouf"
      },
      "source": [
        "# Define Tokens and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgxyHflC_OBO"
      },
      "outputs": [],
      "source": [
        "def tokenize(gene_data, protein_data, embedding_dim, batch_size = 32):\n",
        "\n",
        "    gene_array = gene_data.to_numpy()\n",
        "    protein_array = protein_data.to_numpy()\n",
        "\n",
        "    print('step 1')\n",
        "\n",
        "\n",
        "    gene_tensor = torch.tensor(gene_array, dtype=torch.float32)\n",
        "    protein_tensor = torch.tensor(protein_array, dtype=torch.float32)\n",
        "\n",
        "    print('hello')\n",
        "\n",
        "    num_samples, num_genes = gene_tensor.shape\n",
        "    num_samples, num_proteins = protein_tensor.shape\n",
        "\n",
        "    print(num_samples, num_genes, num_proteins)\n",
        "\n",
        "    gene_embedding = nn.Embedding(num_genes, embedding_dim)\n",
        "    protein_embedding = nn.Embedding(num_proteins, embedding_dim)\n",
        "    value_encoder = nn.Linear(1, embedding_dim)\n",
        "\n",
        "    gene_tokens_list = []\n",
        "    protein_tokens_list = []\n",
        "\n",
        "    for start in range(0, num_samples, batch_size):\n",
        "        print(start)\n",
        "        end = min(start + batch_size, num_samples)\n",
        "        gene_batch = gene_data.iloc[start:end].to_numpy()\n",
        "        protein_batch = protein_data.iloc[start:end].to_numpy()\n",
        "\n",
        "        gene_tensor = torch.tensor(gene_batch, dtype=torch.float32)\n",
        "        protein_tensor = torch.tensor(protein_batch, dtype=torch.float32)\n",
        "\n",
        "        batch_size_actual = gene_tensor.size(0)\n",
        "\n",
        "        gene_ids = torch.arange(num_genes).unsqueeze(0).repeat(batch_size_actual, 1).long()\n",
        "        protein_ids = torch.arange(num_proteins).unsqueeze(0).repeat(batch_size_actual, 1).long()\n",
        "\n",
        "        gene_id_embeddings = gene_embedding(gene_ids)\n",
        "        protein_id_embeddings = protein_embedding(protein_ids)\n",
        "\n",
        "        gene_values = gene_tensor.unsqueeze(-1)\n",
        "        protein_values = protein_tensor.unsqueeze(-1)\n",
        "\n",
        "        gene_value_embeddings = value_encoder(gene_values)\n",
        "        protein_value_embeddings = value_encoder(protein_values)\n",
        "\n",
        "        print('tokenizing')\n",
        "\n",
        "        gene_tokens = gene_id_embeddings + gene_value_embeddings\n",
        "        protein_tokens = protein_id_embeddings + protein_value_embeddings\n",
        "\n",
        "        # Yield this batch of tokens instead of storing them\n",
        "        yield gene_tokens, protein_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uctbrX-2I7bP"
      },
      "outputs": [],
      "source": [
        "class omics_dataset(Dataset):\n",
        "    def __init__(self, gene_data, protein_data, labels, gene_embedding, protein_embedding, value_encoder):\n",
        "        self.gene_data = gene_data\n",
        "        self.protein_data = protein_data\n",
        "        self.labels = labels\n",
        "        self.gene_embedding = gene_embedding\n",
        "        self.protein_embedding = protein_embedding\n",
        "        self.value_encoder = value_encoder\n",
        "        self.num_genes = gene_data.shape[1]\n",
        "        self.num_proteins = protein_data.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        gene_row = self.gene_data[idx]\n",
        "        protein_row = self.protein_data[idx] # shape (1, num_proteins)\n",
        "\n",
        "        gene_tensor = torch.tensor(gene_row, dtype=torch.float32)     # (1, num_genes)\n",
        "        protein_tensor = torch.tensor(protein_row, dtype=torch.float32)# (1, num_proteins)\n",
        "\n",
        "        gene_ids = torch.arange(self.num_genes).unsqueeze(0).long()      # (1, num_genes)\n",
        "        protein_ids = torch.arange(self.num_proteins).unsqueeze(0).long()# (1, num_proteins)\n",
        "\n",
        "        gene_id_embeddings = self.gene_embedding(gene_ids)\n",
        "        protein_id_embeddings = self.protein_embedding(protein_ids)\n",
        "\n",
        "        gene_values = gene_tensor.unsqueeze(-1)    # (1, num_genes, 1)\n",
        "        protein_values = protein_tensor.unsqueeze(-1) # (1, num_proteins, 1)\n",
        "\n",
        "        gene_value_embeddings = self.value_encoder(gene_values)\n",
        "        protein_value_embeddings = self.value_encoder(protein_values)\n",
        "\n",
        "        gene_tokens = gene_id_embeddings + gene_value_embeddings   # (1, num_genes, embedding_dim)\n",
        "        protein_tokens = protein_id_embeddings + protein_value_embeddings # (1, num_proteins, embedding_dim)\n",
        "\n",
        "        # Squeeze out the batch dimension since we return a single sample\n",
        "        gene_tokens = gene_tokens.squeeze(0)\n",
        "        protein_tokens = protein_tokens.squeeze(0)\n",
        "\n",
        "        return gene_tokens, protein_tokens, self.labels[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3CEjBDnnCKP"
      },
      "source": [
        "# Architecture Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaCrqjBCmOE5",
        "outputId": "31ed3c8a-473a-4422-9bff-7679ae80b231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "KPOpqK83nHr8",
        "outputId": "c19d967d-bf0f-4ff3-e053-6750b6eb2036"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9af9886b7c18>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_val_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDvvdN7M7JRx"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train.values)\n",
        "y_val_encoded = label_encoder.transform(y_val.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hchFG5LT6f_R"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long).to(device)\n",
        "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvoFV0TLCdnI"
      },
      "outputs": [],
      "source": [
        "class cross_attention_layer(nn.Module):\n",
        "    def __init__(self, embedding_dim, nhead = 8, dropout = 0.1):\n",
        "        super(cross_attention_layer, self).__init__()\n",
        "        self.gene_to_protein = nn.MultiheadAttention(embedding_dim, nhead, dropout=dropout)\n",
        "        self.protein_to_gene = nn.MultiheadAttention(embedding_dim, nhead, dropout=dropout)\n",
        "\n",
        "        self.norm_gene = nn.LayerNorm(embedding_dim)\n",
        "        self.norm_protein = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.ff_gene = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 4*embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*embedding_dim, embedding_dim)\n",
        "        )\n",
        "        self.ff_protein = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 4*embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*embedding_dim, embedding_dim)\n",
        "        )\n",
        "\n",
        "        def forward(self, gene_tokens, protein_tokens):\n",
        "            gene_updated, _ = self.gene_to_protein(gene_tokens, protein_tokens, protein_tokens)\n",
        "\n",
        "            gene_encoded = self.norm_gene(gene_tokens + gene_updated)\n",
        "            gene_encoded = self.norm_gene(gene_encoded + self.ff_gene(gene_encoded))\n",
        "\n",
        "            protein_updated, _ = self.protein_to_gene(protein_tokens, gene_encoded, gene_encoded)\n",
        "\n",
        "            protein_encoded = self.norm_protein(protein_tokens + protein_updated)\n",
        "            protein_encoded = self.norm_protein(protein_encoded + self.ff_protein(protein_encoded))\n",
        "\n",
        "            return gene_encoded, protein_encoded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkJiGwySDyEl"
      },
      "outputs": [],
      "source": [
        "class omics_transformer(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_cancers, nhead = 8, num_layers = 10, dim_feedforward = 256, dropout = 0.1):\n",
        "        super(omics_transformer, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        gene_encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
        "                                                        nhead=nhead,\n",
        "                                                        dim_feedforward=dim_feedforward,\n",
        "                                                        dropout=dropout)\n",
        "\n",
        "        self.gene_encoder = nn.TransformerEncoder(gene_encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        protein_encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim,\n",
        "                                                            nhead=nhead,\n",
        "                                                            dim_feedforward=dim_feedforward,\n",
        "                                                            dropout=dropout)\n",
        "\n",
        "        self.protein_encoder = nn.TransformerEncoder(protein_encoder_layer, num_layers=num_layers)\n",
        "        self.cross_attention = cross_attention_layer(embedding_dim, nhead, dropout)\n",
        "\n",
        "        self.combine = nn.Linear(2*embedding_dim, embedding_dim)\n",
        "\n",
        "        self.final = nn.Linear(embedding_dim, num_cancers)\n",
        "\n",
        "    def forward(self, gene_tokens, protein_tokens):\n",
        "        gene_tokens = gene_tokens.permute(1,0,2)\n",
        "        protein_tokens = protein_tokens.permute(1,0,2)\n",
        "\n",
        "        gene_encoded = self.gene_encoder(gene_tokens)\n",
        "        protein_encoded = self.protein_encoder(protein_tokens)\n",
        "\n",
        "        gene_cross, protein_cross = self.cross_attention(gene_encoded, protein_encoded)\n",
        "\n",
        "        gene_pooled = torch.mean(gene_cross, dim=1)\n",
        "        protein_pooled = torch.mean(protein_cross, dim=1)\n",
        "\n",
        "        combined = torch.cat([gene_pooled, protein_pooled], dim = 1)\n",
        "        combined = self.combine(combined)\n",
        "\n",
        "        logits = self.final(combined)\n",
        "\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_lr_PpOGKg_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhNygtHyGMfA"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\"):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for gene_tokens, protein_tokens, labels in train_loader:\n",
        "\n",
        "            print('\\nTraining')\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            gene_tokens = gene_tokens.to(device)\n",
        "            protein_tokens = protein_tokens.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(gene_tokens, protein_tokens)\n",
        "            loss_value = loss(outputs, labels)\n",
        "\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss_value.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for gene_tokens, protein_tokens, labels in val_loader:\n",
        "\n",
        "                gene_tokens = gene_tokens.to(device)\n",
        "                protein_tokens = protein_tokens.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(gene_tokens, protein_tokens)\n",
        "                loss_value = loss(outputs, labels)\n",
        "                val_loss += loss_value.item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etOq5kaMGco0"
      },
      "outputs": [],
      "source": [
        "cancer_labels = ['Lung', 'Breast', 'Head and Neck', 'Brain', 'Ovarian', 'Renal Cell', 'Endometrial']\n",
        "label_to_id = {label: idx for idx, label in enumerate(cancer_labels)}\n",
        "\n",
        "\n",
        "lu_transcriptome['Cancer'] = cancer_labels[0]\n",
        "br_transcriptome['Cancer'] = cancer_labels[1]\n",
        "hn_transcriptome['Cancer'] = cancer_labels[2]\n",
        "gbm_transcriptome['Cancer'] = cancer_labels[3]\n",
        "ov_transcriptome['Cancer'] = cancer_labels[4]\n",
        "cc_transcriptome['Cancer'] = cancer_labels[5]\n",
        "en_transcriptome['Cancer'] = cancer_labels[6]\n",
        "\n",
        "lu_proteome['Cancer'] = cancer_labels[0]\n",
        "br_proteome['Cancer'] = cancer_labels[1]\n",
        "hn_proteome['Cancer'] = cancer_labels[2]\n",
        "gbm_proteome['Cancer'] = cancer_labels[3]\n",
        "ov_proteome['Cancer'] = cancer_labels[4]\n",
        "cc_proteome['Cancer'] = cancer_labels[5]\n",
        "en_proteome['Cancer'] = cancer_labels[6]\n",
        "\n",
        "all_transcriptome_data = pd.concat([lu_transcriptome, br_transcriptome, hn_transcriptome, gbm_transcriptome,\n",
        "                                    ov_transcriptome, cc_transcriptome, en_transcriptome], axis = 0)\n",
        "all_proteome_data = pd.concat([lu_proteome, br_proteome, hn_proteome, gbm_proteome,\n",
        "                                    ov_proteome, cc_proteome, en_proteome], axis = 0)\n",
        "\n",
        "all_transcriptome_data = all_transcriptome_data.dropna(subset=['Cancer'])\n",
        "all_proteome_data = all_proteome_data.dropna(subset=['Cancer'])\n",
        "\n",
        "all_labels = all_transcriptome_data['Cancer'].values\n",
        "\n",
        "numeric_labels = [label_to_id[label] for label in all_labels]\n",
        "labels_tensor = torch.tensor(numeric_labels, dtype=torch.long).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itwAJO_Iagnf"
      },
      "outputs": [],
      "source": [
        "common_samples = all_transcriptome_data.index.intersection(all_proteome_data.index)\n",
        "all_transcriptome_data = all_transcriptome_data.loc[common_samples]\n",
        "all_proteome_data = all_proteome_data.loc[common_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Ii7pb4kZAy",
        "outputId": "c4b52409-7a89-4b00-b922-487f1aef55dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "all_transcriptome_data = all_transcriptome_data.fillna(0)\n",
        "all_proteome_data = all_proteome_data.fillna(0)\n",
        "\n",
        "all_transcriptome_data = all_transcriptome_data.drop('Cancer', axis = 1)\n",
        "all_proteome_data = all_proteome_data.drop('Cancer', axis = 1)\n",
        "\n",
        "gene_array = all_transcriptome_data.astype(float).to_numpy()\n",
        "protein_array = all_proteome_data.astype(float).to_numpy()\n",
        "\n",
        "print([i for i in gene_array[0] if type(i) is object])\n",
        "\n",
        "print(gene_array.dtype)\n",
        "\n",
        "gene_tensor = torch.tensor(gene_array, dtype=torch.float32)\n",
        "protein_tensor = torch.tensor(protein_array, dtype=torch.float32)\n",
        "\n",
        "num_samples, num_genes = gene_tensor.shape\n",
        "num_samples, num_proteins = protein_tensor.shape\n",
        "\n",
        "embedding_dim = 128\n",
        "\n",
        "gene_embedding = nn.Embedding(num_genes, embedding_dim)\n",
        "protein_embedding = nn.Embedding(num_proteins, embedding_dim)\n",
        "value_encoder = nn.Linear(1, embedding_dim)\n",
        "\n",
        "#gene_tokens, protein_tokens = tokenize(all_transcriptome_data.drop('Cancer', axis = 1),\n",
        "                                      # all_proteome_data.drop('Cancer', axis = 1), 128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gene_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho1fNuKshl-j",
        "outputId": "056d237e-84b8-4709-d216-9b3fa83a72ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.2 4.46 13.49 ... 0.0 0.0 0.0]\n",
            " [5.44 3.46 13.6 ... 0.0 0.0 0.0]\n",
            " [5.14 3.4 14.44 ... 0.0 0.0 0.0]\n",
            " ...\n",
            " [7.36 2.99 15.17 ... 9.87 9.62 4.44]\n",
            " [6.8 2.72 16.02 ... 9.64 9.11 5.32]\n",
            " [7.61 2.4 16.07 ... 10.33 8.99 4.85]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyZqSyS_nFjI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "599c5afd-0ada-461e-953c-45159e0e7fa6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Cancer'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4de3dcf47635>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_proteome_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_proteome_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgene_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_transcriptome_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cancer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprotein_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_proteome_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cancer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Cancer'] not found in axis\""
          ]
        }
      ],
      "source": [
        "all_transcriptome_data = all_transcriptome_data.fillna(0)\n",
        "all_proteome_data = all_proteome_data.fillna(0)\n",
        "\n",
        "gene_array = all_transcriptome_data.drop('Cancer', axis = 1).to_numpy()\n",
        "protein_array = all_proteome_data.drop('Cancer', axis = 1).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWL-V-S0nKI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999da3eb-45ed-4a11-fc24-37b2f5bb31f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(260, 100891)\n",
            "(260, 45237)\n"
          ]
        }
      ],
      "source": [
        "print(gene_array.shape)\n",
        "print(protein_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XtHfdOLJM1-"
      },
      "outputs": [],
      "source": [
        "# #num_samples = gene_tokens.size(0)\n",
        "\n",
        "train_indices, val_indices = train_test_split(list(range(num_samples)), test_size=0.3, random_state=42)\n",
        "train_gene_data = gene_array[train_indices]\n",
        "train_protein_data = protein_array[train_indices]\n",
        "train_labels = labels_tensor[train_indices]\n",
        "\n",
        "val_gene_data = gene_array[val_indices]\n",
        "val_protein_data = protein_array[val_indices]\n",
        "val_labels = labels_tensor[val_indices]\n",
        "\n",
        "# train_gene_tokens = gene_tokens[train_indices]\n",
        "# train_protein_tokens = protein_tokens[train_indices]\n",
        "# train_labels = labels_tensor[train_indices]\n",
        "\n",
        "# val_gene_tokens = gene_tokens[val_indices]\n",
        "# val_protein_tokens = protein_tokens[val_indices]\n",
        "# val_labels = labels_tensor[val_indices]\n",
        "\n",
        "# train_dataset = omics_dataset(train_gene_tokens, train_protein_tokens, train_labels)\n",
        "# val_dataset = omics_dataset(val_gene_tokens, val_protein_tokens, val_labels)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "train_dataset = omics_dataset(train_gene_data, train_protein_data, train_labels, gene_embedding, protein_embedding, value_encoder)\n",
        "val_dataset = omics_dataset(val_gene_data, val_protein_data, val_labels, gene_embedding, protein_embedding, value_encoder)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saMJZKfrJ0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a2afcf9-1974-44dc-9066-2cf6c6b26e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "Training Progress:   0%|          | 0/5000 [00:00<?, ?epoch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/5000 [03:24<?, ?epoch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 14.75 GiB of which 39.06 MiB is free. Process 56333 has 14.71 GiB memory in use. Of the allocated memory 13.51 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0d150dd9c217>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-983d7ce1aaa6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f3573d18e6c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, gene_tokens, protein_tokens)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprotein_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotein_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgene_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgene_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprotein_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    902\u001b[0m             x = self.norm1(\n\u001b[1;32m    903\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             )\n\u001b[1;32m    906\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         )[0]\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 14.75 GiB of which 39.06 MiB is free. Process 56333 has 14.71 GiB memory in use. Of the allocated memory 13.51 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "model = omics_transformer(128, len(cancer_labels)).to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 5000\n",
        "\n",
        "train_loss, val_loss = train_model(model, train_loader, val_loader, loss, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xa9lBfzKgRW"
      },
      "source": [
        "# Predictions and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra3ZDQaCKfmL"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, val_loader, device, label_to_id, accuracy = True):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for gene_tokens, protein_tokens, labels in val_loader:\n",
        "            gene_tokens = gene_tokens.to(device)\n",
        "            protein_tokens = protein_tokens.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(gene_tokens, protein_tokens)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            predictions.append(preds.cpu().numpy())\n",
        "            true_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    predictions = torch.cat(predictions)\n",
        "    true_labels = torch.cat(true_labels)\n",
        "\n",
        "    pred_labels = [label_to_id[p.item()] for p in predictions]\n",
        "    true_labels = [label_to_id[t.item()] for t in true_labels]\n",
        "\n",
        "    if accuracy:\n",
        "        accuracy = (pred_labels == true_labels).sum().item() / len(true_labels)\n",
        "    else:\n",
        "        accuracy = None\n",
        "\n",
        "    return pred_labels, true_labels, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kilOV7jMWXa"
      },
      "outputs": [],
      "source": [
        "pred_labels, true_labels, accuracy = get_predictions(model, val_loader, device, label_to_id, accuracy = True)\n",
        "print(f'Model Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS3ShkuOMfRR"
      },
      "outputs": [],
      "source": [
        "print(classification_report(true_labels, pred_labels, target_names=label_to_id.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH_rlPlXGFqi"
      },
      "source": [
        "# Archived Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJI2xcA_xaOW"
      },
      "outputs": [],
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, latent_dim):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, input_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kggsxuiwxrBQ"
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\"):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for x in train_loader:\n",
        "            x = x[0].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            reconstructed = model(x)\n",
        "            loss_value = loss(reconstructed, x)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss_value.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x in val_loader:\n",
        "                x = x[0].to(device)\n",
        "                reconstructed = model(x)\n",
        "                loss_value = loss(reconstructed, x)\n",
        "                val_loss += loss_value.item()\n",
        "\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx9EoRSD64Mx"
      },
      "outputs": [],
      "source": [
        "class cancer_transformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, nhead=4, num_layers=10, dim_feedforward=256, dropout=0.1):\n",
        "        super(cancer_transformer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(1, hidden_size)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, input_size, hidden_size))\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "                          nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout),\n",
        "                          num_layers=num_layers)\n",
        "        self.final = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1,0,2)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=0)\n",
        "        x = self.final(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21CK9kfmagnn"
      },
      "outputs": [],
      "source": [
        "class cancer_mlp(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(cancer_mlp, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 2*hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2*hidden_size, 3*hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(3*hidden_size, 2*hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2*hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HEIQyvu8p2q",
        "outputId": "33552d00-aa4a-4745-ee01-995678a3111d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "num_features = X_train_tensor.shape[1]\n",
        "hidden_size = 128\n",
        "num_classes = len(torch.unique(y_train_tensor))\n",
        "\n",
        "model = cancer_transformer(num_features, hidden_size, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSFIl-_79t-x"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_tensor.cpu().numpy()), y=y_train_tensor.cpu().numpy())\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss(weight = class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 5000\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTPdeeUdyYjT"
      },
      "outputs": [],
      "source": [
        "latent_dim = 64\n",
        "auto_loss = nn.MSELoss()\n",
        "autoencoder_model = autoencoder(num_features, latent_dim).to(device)\n",
        "auto_optimizer = torch.optim.Adam(autoencoder_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0-qXoJ9yVoG",
        "outputId": "8138e558-3a49-403d-f727-8b4f1d66a833"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 5000/5000 [03:30<00:00, 23.73epoch/s]\n"
          ]
        }
      ],
      "source": [
        "train_auto, val_auto = train_autoencoder(autoencoder_model, train_loader, val_loader, auto_loss, auto_optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DM_DWTuo9shj",
        "outputId": "6c510691-6eb8-4728-963a-972d77412494"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_auto, label='Training Loss')\n",
        "plt.plot(val_auto, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6SKbysiye6u",
        "outputId": "63d9467c-c6e3-48b3-b48f-91e6a1f8c56a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'autoencoder_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_latent \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder_model\u001b[49m\u001b[38;5;241m.\u001b[39mencoder(X_train_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m X_val_latent \u001b[38;5;241m=\u001b[39m autoencoder_model\u001b[38;5;241m.\u001b[39mencoder(X_val_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      4\u001b[0m new_train_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(X_train_latent, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), y_train_tensor)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'autoencoder_model' is not defined"
          ]
        }
      ],
      "source": [
        "X_train_latent = autoencoder_model.encoder(X_train_tensor.to(device)).detach().cpu().numpy()\n",
        "X_val_latent = autoencoder_model.encoder(X_val_tensor.to(device)).detach().cpu().numpy()\n",
        "\n",
        "new_train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train_latent, dtype=torch.float32), y_train_tensor)\n",
        "new_val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val_latent, dtype=torch.float32), y_val_tensor)\n",
        "\n",
        "new_train_loader = torch.utils.data.DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "new_val_loader = torch.utils.data.DataLoader(new_val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "num_classes = len(torch.unique(y_train_tensor))\n",
        "model = cancer_mlp(latent_dim, hidden_size, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmpzJPXkagnn"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\"):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        x,y = next(iter(train_loader))\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss_value = loss(outputs, y)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss_value.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            x,y = next(iter(val_loader))\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            loss_value = loss(outputs, y)\n",
        "            val_loss += loss_value.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDfhpZE495qr",
        "outputId": "28dde769-e796-4407-86d4-daa01d747763"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress: 100%|██████████| 5000/5000 [06:25<00:00, 12.97epoch/s]\n"
          ]
        }
      ],
      "source": [
        "train_losses, val_losses = train_model(model, new_train_loader, new_val_loader, loss, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fGC7WxeBgh6"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, X, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "        y_pred = model(X_tensor)\n",
        "        probs = F.softmax(y_pred, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "    return preds.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TqeJwybBxlS"
      },
      "outputs": [],
      "source": [
        "y_pred_classes = get_predictions(model, X_val_latent, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ZmEEXiB0cl"
      },
      "outputs": [],
      "source": [
        "y_true = y_val_tensor.cpu().numpy()\n",
        "y_true_labels = label_encoder.inverse_transform(y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9aUs-UlJVlS",
        "outputId": "8663d16f-afb5-4a7f-d916-438af96f0b74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast', 'Breast', 'Breast', 'Breast',\n",
              "       'Breast', 'Breast', 'Breast'], dtype=object)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
        "y_pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW5qfwl0_TTV",
        "outputId": "6b4297be-cbd0-49be-9642-9baa0db0e7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.1278538812785388\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Brain       0.00      0.00      0.00        24\n",
            "       Breast       0.13      1.00      0.23        28\n",
            "  Endometrial       0.00      0.00      0.00        24\n",
            "Head and Neck       0.00      0.00      0.00        45\n",
            "         Lung       0.00      0.00      0.00        45\n",
            "      Ovarian       0.00      0.00      0.00        20\n",
            "   Renal Cell       0.00      0.00      0.00        33\n",
            "\n",
            "     accuracy                           0.13       219\n",
            "    macro avg       0.02      0.14      0.03       219\n",
            " weighted avg       0.02      0.13      0.03       219\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_true_labels, y_pred_labels))\n",
        "print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLdD1PDLJX5B",
        "outputId": "fdf19427-f11c-4b11-8753-9c2504fc5e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Renal Cell', 'Renal Cell', 'Endometrial', 'Endometrial',\n",
              "       'Renal Cell', 'Head and Neck', 'Head and Neck', 'Lung',\n",
              "       'Head and Neck', 'Renal Cell', 'Lung', 'Breast', 'Renal Cell',\n",
              "       'Lung', 'Head and Neck', 'Breast', 'Breast', 'Lung', 'Ovarian',\n",
              "       'Head and Neck', 'Head and Neck', 'Ovarian', 'Endometrial', 'Lung',\n",
              "       'Renal Cell', 'Head and Neck', 'Head and Neck', 'Lung',\n",
              "       'Renal Cell', 'Brain', 'Lung', 'Lung', 'Lung', 'Brain', 'Ovarian',\n",
              "       'Ovarian', 'Endometrial', 'Brain', 'Renal Cell', 'Breast',\n",
              "       'Breast', 'Head and Neck', 'Lung', 'Endometrial', 'Renal Cell',\n",
              "       'Brain', 'Lung', 'Head and Neck', 'Lung', 'Lung', 'Breast',\n",
              "       'Ovarian', 'Breast', 'Lung', 'Breast', 'Ovarian', 'Breast',\n",
              "       'Head and Neck', 'Endometrial', 'Lung', 'Endometrial', 'Lung',\n",
              "       'Renal Cell', 'Brain', 'Head and Neck', 'Brain', 'Breast',\n",
              "       'Breast', 'Head and Neck', 'Lung', 'Brain', 'Ovarian',\n",
              "       'Endometrial', 'Renal Cell', 'Renal Cell', 'Endometrial',\n",
              "       'Renal Cell', 'Head and Neck', 'Endometrial', 'Renal Cell',\n",
              "       'Head and Neck', 'Renal Cell', 'Head and Neck', 'Breast',\n",
              "       'Head and Neck', 'Breast', 'Endometrial', 'Brain', 'Lung',\n",
              "       'Breast', 'Renal Cell', 'Lung', 'Renal Cell', 'Head and Neck',\n",
              "       'Ovarian', 'Breast', 'Brain', 'Head and Neck', 'Endometrial',\n",
              "       'Lung', 'Lung', 'Brain', 'Breast', 'Renal Cell', 'Head and Neck',\n",
              "       'Breast', 'Renal Cell', 'Brain', 'Lung', 'Brain', 'Endometrial',\n",
              "       'Ovarian', 'Renal Cell', 'Ovarian', 'Brain', 'Ovarian', 'Ovarian',\n",
              "       'Brain', 'Lung', 'Breast', 'Renal Cell', 'Renal Cell',\n",
              "       'Head and Neck', 'Lung', 'Renal Cell', 'Lung', 'Head and Neck',\n",
              "       'Breast', 'Endometrial', 'Head and Neck', 'Renal Cell',\n",
              "       'Endometrial', 'Head and Neck', 'Endometrial', 'Brain', 'Brain',\n",
              "       'Head and Neck', 'Breast', 'Head and Neck', 'Renal Cell', 'Lung',\n",
              "       'Renal Cell', 'Brain', 'Endometrial', 'Brain', 'Brain',\n",
              "       'Head and Neck', 'Head and Neck', 'Brain', 'Lung', 'Breast',\n",
              "       'Renal Cell', 'Head and Neck', 'Lung', 'Ovarian', 'Breast', 'Lung',\n",
              "       'Lung', 'Endometrial', 'Lung', 'Lung', 'Renal Cell', 'Ovarian',\n",
              "       'Brain', 'Breast', 'Ovarian', 'Head and Neck', 'Lung',\n",
              "       'Head and Neck', 'Ovarian', 'Endometrial', 'Ovarian', 'Renal Cell',\n",
              "       'Head and Neck', 'Lung', 'Lung', 'Lung', 'Renal Cell',\n",
              "       'Head and Neck', 'Lung', 'Lung', 'Breast', 'Brain',\n",
              "       'Head and Neck', 'Ovarian', 'Head and Neck', 'Breast',\n",
              "       'Endometrial', 'Brain', 'Head and Neck', 'Head and Neck',\n",
              "       'Endometrial', 'Lung', 'Endometrial', 'Lung', 'Lung', 'Lung',\n",
              "       'Head and Neck', 'Breast', 'Brain', 'Head and Neck', 'Breast',\n",
              "       'Ovarian', 'Lung', 'Head and Neck', 'Head and Neck', 'Renal Cell',\n",
              "       'Breast', 'Head and Neck', 'Endometrial', 'Head and Neck',\n",
              "       'Endometrial', 'Renal Cell', 'Head and Neck', 'Head and Neck',\n",
              "       'Ovarian', 'Lung', 'Lung', 'Renal Cell'], dtype=object)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irum1mT28fkn",
        "outputId": "31f08678-9018-4199-d57b-e391c168b897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_true_labels, y_pred_classes))\n",
        "# print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "bl0S3rvlIqlm",
        "outputId": "72f3dff1-5c49-4125-b5ff-2941b462d70f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}