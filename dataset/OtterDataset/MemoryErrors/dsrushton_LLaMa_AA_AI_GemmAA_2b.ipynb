{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1L8-LLWiM_g4n09kYfcKa4Ro9S8PThGis",
      "authorship_tag": "ABX9TyOYW+oNgVfY8ymDyx/nS3DD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b848be7156e46c7a25929d448e35308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1ab9962b87b4cea83c963442bb8f595",
              "IPY_MODEL_fef93f42c8924bae80a5e608af9ef032",
              "IPY_MODEL_e6b6fb2862d548189e2a75b439b4a5d8"
            ],
            "layout": "IPY_MODEL_a4e0cc3aa50c41a58c4b6d825e9c8ef9"
          }
        },
        "c1ab9962b87b4cea83c963442bb8f595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db601f520dc54dcbb659a06e83a985e5",
            "placeholder": "​",
            "style": "IPY_MODEL_cb71fa93e98d4c0a94277b0b98bea029",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fef93f42c8924bae80a5e608af9ef032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f3bb0060cb4417ad3e8c1124c29b63",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b519f3c42e6f41588bc80c361c2eb149",
            "value": 2
          }
        },
        "e6b6fb2862d548189e2a75b439b4a5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d9335b3c9c4f568da07cc67e1b22af",
            "placeholder": "​",
            "style": "IPY_MODEL_dfa3717389fe4b6a91dde66258f55173",
            "value": " 2/2 [00:03&lt;00:00,  1.69s/it]"
          }
        },
        "a4e0cc3aa50c41a58c4b6d825e9c8ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db601f520dc54dcbb659a06e83a985e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb71fa93e98d4c0a94277b0b98bea029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41f3bb0060cb4417ad3e8c1124c29b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b519f3c42e6f41588bc80c361c2eb149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2d9335b3c9c4f568da07cc67e1b22af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa3717389fe4b6a91dde66258f55173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7ba03d121374eada57252baa6f17a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dbc23c07ec944dd9514d34f05aed792",
              "IPY_MODEL_3191f01247214e2ba7e99b8aacaf479a",
              "IPY_MODEL_b75ce7203d604bd382616a55aee60481"
            ],
            "layout": "IPY_MODEL_b1f72a9a99b74ecc9c56ed493b6d5a34"
          }
        },
        "6dbc23c07ec944dd9514d34f05aed792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f7e8fe4fca4d2ba803a3de4c215228",
            "placeholder": "​",
            "style": "IPY_MODEL_e92e90797abd4ad3b63611480cedf58f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3191f01247214e2ba7e99b8aacaf479a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f939160b2546d588cc2215518c4737",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57c49da2e5014ffbb0f65fc27232a2d0",
            "value": 2
          }
        },
        "b75ce7203d604bd382616a55aee60481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c97b04aa2e419aa558fff0293404bc",
            "placeholder": "​",
            "style": "IPY_MODEL_e5216cce49c946189951c71991eac5a9",
            "value": " 2/2 [00:03&lt;00:00,  1.54s/it]"
          }
        },
        "b1f72a9a99b74ecc9c56ed493b6d5a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f7e8fe4fca4d2ba803a3de4c215228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92e90797abd4ad3b63611480cedf58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f939160b2546d588cc2215518c4737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c49da2e5014ffbb0f65fc27232a2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33c97b04aa2e419aa558fff0293404bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5216cce49c946189951c71991eac5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e1d62a1f0574493b95d04e99d0b19c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ccfad999c0b48a4ac8b5bc325a4250a",
              "IPY_MODEL_ede91c8a393a4a9f89771964a8f4a068",
              "IPY_MODEL_1cd07053bee04f188ff849ea936789b7"
            ],
            "layout": "IPY_MODEL_5a9060917a9946a6b994fbed1ed0e427"
          }
        },
        "4ccfad999c0b48a4ac8b5bc325a4250a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11092e75f2434155b2f0a4a29066d708",
            "placeholder": "​",
            "style": "IPY_MODEL_f5dfb1af7b0d4ad2a6b50ebc51485fb1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ede91c8a393a4a9f89771964a8f4a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813dc4aee6d04b478a0fff50d99ad114",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_433330b47da24fa0b636259213ea836c",
            "value": 3
          }
        },
        "1cd07053bee04f188ff849ea936789b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0285bad4bcb44d8a243c2a449187590",
            "placeholder": "​",
            "style": "IPY_MODEL_9d933693ab384f4bac1b3125a7c9324d",
            "value": " 3/3 [00:01&lt;00:00,  2.36it/s]"
          }
        },
        "5a9060917a9946a6b994fbed1ed0e427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11092e75f2434155b2f0a4a29066d708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5dfb1af7b0d4ad2a6b50ebc51485fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "813dc4aee6d04b478a0fff50d99ad114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433330b47da24fa0b636259213ea836c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0285bad4bcb44d8a243c2a449187590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d933693ab384f4bac1b3125a7c9324d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99dea34e9ce04297ad72e7faa7ad2491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_592b7e98e2af4245ab679ce00e0a6b60",
              "IPY_MODEL_6b608471493c43d1b043ad8f31e31c00",
              "IPY_MODEL_c96e7caf79f441c39fe152a218ce8d95"
            ],
            "layout": "IPY_MODEL_9a19d1a4d31d40a787c76457910ea595"
          }
        },
        "592b7e98e2af4245ab679ce00e0a6b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91321f1f53704257ae0060b9e24788d8",
            "placeholder": "​",
            "style": "IPY_MODEL_7a9e96a8527f408ba17ca5f102578217",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6b608471493c43d1b043ad8f31e31c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7932f978c3214fe3be5ac88b59e0eeb0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8051ef8cdfe4c5b9104b29228b55588",
            "value": 2
          }
        },
        "c96e7caf79f441c39fe152a218ce8d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124bf0d6b2224798a4646c853823ba02",
            "placeholder": "​",
            "style": "IPY_MODEL_df6d50a4f3b5465c9a7374acbf7b8753",
            "value": " 2/2 [00:03&lt;00:00,  1.45s/it]"
          }
        },
        "9a19d1a4d31d40a787c76457910ea595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91321f1f53704257ae0060b9e24788d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9e96a8527f408ba17ca5f102578217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7932f978c3214fe3be5ac88b59e0eeb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8051ef8cdfe4c5b9104b29228b55588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "124bf0d6b2224798a4646c853823ba02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6d50a4f3b5465c9a7374acbf7b8753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a2a6081479644008cf1827c49061b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd22d9a3095148498ebadcd7ba11ffbc",
              "IPY_MODEL_9533438097c24a7fa025be0ae14687d2",
              "IPY_MODEL_48c7b73ffaa14adb9832f22eb158ee57"
            ],
            "layout": "IPY_MODEL_02530c812e504b8492112e8b5dd35d4f"
          }
        },
        "dd22d9a3095148498ebadcd7ba11ffbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ec0b344030455493d25d6179c204e2",
            "placeholder": "​",
            "style": "IPY_MODEL_79ddd59d5d104cbab6a15922c6cbb18a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9533438097c24a7fa025be0ae14687d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d146140dc4640758301a8896f51280b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9152e0f812af4682ae8cf19b5c77eae2",
            "value": 2
          }
        },
        "48c7b73ffaa14adb9832f22eb158ee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97121e748ff04a468d127a3a5e12eb78",
            "placeholder": "​",
            "style": "IPY_MODEL_65b9eac11ab748f2af8f53805a268c34",
            "value": " 2/2 [01:20&lt;00:00, 34.17s/it]"
          }
        },
        "02530c812e504b8492112e8b5dd35d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ec0b344030455493d25d6179c204e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ddd59d5d104cbab6a15922c6cbb18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d146140dc4640758301a8896f51280b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9152e0f812af4682ae8cf19b5c77eae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97121e748ff04a468d127a3a5e12eb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b9eac11ab748f2af8f53805a268c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8903eaf897264d108d3bc3513fa0c6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caf428c827374d1fb5cc90a63a33570f",
              "IPY_MODEL_58a9c405e17c432d987e74dcc861fa37",
              "IPY_MODEL_1f0a6b67139c454bb1df73786ebc3e2e"
            ],
            "layout": "IPY_MODEL_4482e3069c3842ca8401d2937ba61a12"
          }
        },
        "caf428c827374d1fb5cc90a63a33570f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2592c50f256d43f994045b94a2e4a07a",
            "placeholder": "​",
            "style": "IPY_MODEL_90ae8a85b6554d1b9ceac2d1045664a5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "58a9c405e17c432d987e74dcc861fa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c10f6c3f67448b4945f1d8a1d31da5e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94604854dffe4efaad482448da5ecfcc",
            "value": 2
          }
        },
        "1f0a6b67139c454bb1df73786ebc3e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7835e9a6461442fca9e56a564fc92230",
            "placeholder": "​",
            "style": "IPY_MODEL_227dcc7bd83b42e4ad943a1fe551815d",
            "value": " 2/2 [00:03&lt;00:00,  1.42s/it]"
          }
        },
        "4482e3069c3842ca8401d2937ba61a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2592c50f256d43f994045b94a2e4a07a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ae8a85b6554d1b9ceac2d1045664a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c10f6c3f67448b4945f1d8a1d31da5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94604854dffe4efaad482448da5ecfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7835e9a6461442fca9e56a564fc92230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227dcc7bd83b42e4ad943a1fe551815d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cde185b5877e424385228c949d097ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c9c49315c9b48ec811b747803119358",
              "IPY_MODEL_e78dd31a7b5947bf9f7a3a4d38220356",
              "IPY_MODEL_f4a45f58da1b421fab0e4b328e01ad24"
            ],
            "layout": "IPY_MODEL_b36e09c015334f54848b8e3ab21ce37f"
          }
        },
        "9c9c49315c9b48ec811b747803119358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adc3b1db4964ee985d7aec44a83a6b4",
            "placeholder": "​",
            "style": "IPY_MODEL_ea60c4c31cc147c4bb40d3be2b4259a0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e78dd31a7b5947bf9f7a3a4d38220356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96aa1797494248408466b40bfa6220cb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_620d95fae2ba4722b6ba05581946d69d",
            "value": 2
          }
        },
        "f4a45f58da1b421fab0e4b328e01ad24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19113e0155c475f9ef331f233caf21c",
            "placeholder": "​",
            "style": "IPY_MODEL_1d709e95bd424c07af7b32a856a4bca8",
            "value": " 2/2 [00:38&lt;00:00, 16.31s/it]"
          }
        },
        "b36e09c015334f54848b8e3ab21ce37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3adc3b1db4964ee985d7aec44a83a6b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea60c4c31cc147c4bb40d3be2b4259a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96aa1797494248408466b40bfa6220cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620d95fae2ba4722b6ba05581946d69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f19113e0155c475f9ef331f233caf21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d709e95bd424c07af7b32a856a4bca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "793da6eb953d4da7acf7652fdeb20f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8164318b9348420fb8ce3ac41112b427",
              "IPY_MODEL_d707b4766ed3479a9e46c22330517eb7",
              "IPY_MODEL_101bef0b265d4e95a88652e455d8aca0"
            ],
            "layout": "IPY_MODEL_841cb760f44447c0a65807a449558046"
          }
        },
        "8164318b9348420fb8ce3ac41112b427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b003ddbfb6a64f92aa3cead023eafaba",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd29cbbd5a24b468682fafa86857697",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d707b4766ed3479a9e46c22330517eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2565cbde36364cbfb039d7a259809d91",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8382f63b0b834876b3f30a0cf977b30f",
            "value": 2
          }
        },
        "101bef0b265d4e95a88652e455d8aca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c2ba8e272cd4cafae3ec727837d043f",
            "placeholder": "​",
            "style": "IPY_MODEL_f3bb78afaad847b9acffafd104cd4b63",
            "value": " 2/2 [00:04&lt;00:00,  1.84s/it]"
          }
        },
        "841cb760f44447c0a65807a449558046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b003ddbfb6a64f92aa3cead023eafaba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd29cbbd5a24b468682fafa86857697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2565cbde36364cbfb039d7a259809d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8382f63b0b834876b3f30a0cf977b30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c2ba8e272cd4cafae3ec727837d043f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3bb78afaad847b9acffafd104cd4b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74d97730393401c90e88e6185d3777b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c2b3d47e32c4d5ab69dc90d4dbc69ad",
              "IPY_MODEL_50478117e61847b3ac4b6344f56c2448",
              "IPY_MODEL_bb0c710d6f3c4f12a0919db973470cf5"
            ],
            "layout": "IPY_MODEL_f7b4b08efe394dc2b39c85569f47fb8e"
          }
        },
        "4c2b3d47e32c4d5ab69dc90d4dbc69ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad4a2b14eff497f9f5233f048977f29",
            "placeholder": "​",
            "style": "IPY_MODEL_184ffd0feb0f4181974afb08d1c2d247",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "50478117e61847b3ac4b6344f56c2448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4a17971bf7f4fb9ba57d0236931eb6b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_123696086370456f90064f4f00385e3d",
            "value": 2
          }
        },
        "bb0c710d6f3c4f12a0919db973470cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4716812d074300a9ebd6c63e1df572",
            "placeholder": "​",
            "style": "IPY_MODEL_e050367e6e1e490baa97b4011c16cc1b",
            "value": " 2/2 [00:00&lt;00:00,  2.41it/s]"
          }
        },
        "f7b4b08efe394dc2b39c85569f47fb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad4a2b14eff497f9f5233f048977f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184ffd0feb0f4181974afb08d1c2d247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4a17971bf7f4fb9ba57d0236931eb6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "123696086370456f90064f4f00385e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d4716812d074300a9ebd6c63e1df572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e050367e6e1e490baa97b4011c16cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsrushton/VGG_Object_Detector/blob/main/Copy_of_GemmAA_2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rn86shck6Uh",
        "outputId": "39ab5956-f441-49ba-c5d2-a8a4c7350e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWEBlNyNkUl5"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/gemma-2-2b-it\" /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model from your local path\n",
        "model_path = \"/content/drive/MyDrive/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "3b848be7156e46c7a25929d448e35308",
            "c1ab9962b87b4cea83c963442bb8f595",
            "fef93f42c8924bae80a5e608af9ef032",
            "e6b6fb2862d548189e2a75b439b4a5d8",
            "a4e0cc3aa50c41a58c4b6d825e9c8ef9",
            "db601f520dc54dcbb659a06e83a985e5",
            "cb71fa93e98d4c0a94277b0b98bea029",
            "41f3bb0060cb4417ad3e8c1124c29b63",
            "b519f3c42e6f41588bc80c361c2eb149",
            "a2d9335b3c9c4f568da07cc67e1b22af",
            "dfa3717389fe4b6a91dde66258f55173"
          ]
        },
        "id": "LKDaxLAmlOff",
        "outputId": "862dcbda-f759-45f7-f708-2edf335c4d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b848be7156e46c7a25929d448e35308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gemma2ForCausalLM(\n",
              "  (model): Gemma2Model(\n",
              "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-25): 26 x Gemma2DecoderLayer(\n",
              "        (self_attn): Gemma2SdpaAttention(\n",
              "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
              "          (rotary_emb): Gemma2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Gemma2MLP(\n",
              "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/Othercomputers/My Computer (1)/Google Drive Sync/Shared Docs/Cleaned\"\n",
        "\n",
        "# Load and concatenate all text files in the directory\n",
        "texts = []\n",
        "for filename in os.listdir(data_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        with open(os.path.join(data_path, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            texts.append(file.read())\n",
        "\n",
        "# Combine all texts into one large string\n",
        "combined_text = \" \".join(texts)\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(combined_text, return_tensors=\"pt\", max_length=1024, truncation=True)"
      ],
      "metadata": {
        "id": "kAi4Ej1YlTMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "//Reg Mem\\\\"
      ],
      "metadata": {
        "id": "nZp-imn8tF7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs.input_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.inputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx]\n",
        "\n",
        "# Prepare the dataset and dataloader\n",
        "dataset = TextDataset(inputs)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Enable mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Fine-tuning loop\n",
        "model.train()\n",
        "for epoch in range(3):  # Adjust number of epochs\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast('cuda'):\n",
        "            outputs = model(input_ids=batch, labels=batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/MTLiens\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/MTLiens\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "2Q0THhevlUof",
        "outputId": "903f8ba2-d20b-4e4a-801c-7bf445c42fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-69c8c3731d06>:22: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-4-69c8c3731d06>:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "It is strongly recommended to train Gemma2 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 52.81 MiB is free. Process 26375 has 39.50 GiB memory in use. Of the allocated memory 38.47 GiB is allocated by PyTorch, and 544.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-69c8c3731d06>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             has_complex = self._init_group(\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n\u001b[1;32m    158\u001b[0m                 \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 state[\"exp_avg_sq\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 52.81 MiB is free. Process 26375 has 39.50 GiB memory in use. Of the allocated memory 38.47 GiB is allocated by PyTorch, and 544.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "//Low Mem\\\\"
      ],
      "metadata": {
        "id": "Km1DvQnptB_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs.input_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.inputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx]\n",
        "\n",
        "# Prepare the dataset and dataloader\n",
        "dataset = TextDataset(inputs)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Enable mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Accumulate gradients over 4 steps\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "# Fine-tuning loop with gradient accumulation\n",
        "model.train()\n",
        "for epoch in range(3):  # Adjust number of epochs\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(input_ids=batch, labels=batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        # Scale the loss and accumulate gradients\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Update weights every gradient_accumulation_steps\n",
        "        if (i + 1) % gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/MTLiens\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/MTLiens\")\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/MTLiens/pytorch_model.bin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y45PzYZftDjW",
        "outputId": "4058c71e-0ac4-45ea-addc-1c037e555178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1924855c1756>:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-17-1924855c1756>:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "It is strongly recommended to train Gemma2 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8589140772819519\n",
            "Loss: 0.8589140772819519\n",
            "Loss: 0.8589140772819519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTuXFQSzQpZ",
        "outputId": "e268990d-8ee8-4efc-b204-2b4e3780e07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/MTLiens/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/MTLiens/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/MTLiens/tokenizer.model',\n",
              " '/content/drive/MyDrive/MTLiens/added_tokens.json',\n",
              " '/content/drive/MyDrive/MTLiens/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GDNG4-PSyjRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the original model\n",
        "original_model_path = \"/content/drive/MyDrive/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(original_model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(original_model_path)\n",
        "\n",
        "# Load the fine-tuned model's weights\n",
        "fine_tuned_model_path = \"/content/drive/MyDrive/MTLiens\" # Update with your fine-tuned model path\n",
        "state_dict = torch.load(f\"{fine_tuned_model_path}/pytorch_model.bin\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/MTLiens/Refined\") # Update with desired save path\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/MTLiens/Refined\") # Update with desired save path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "d7ba03d121374eada57252baa6f17a62",
            "6dbc23c07ec944dd9514d34f05aed792",
            "3191f01247214e2ba7e99b8aacaf479a",
            "b75ce7203d604bd382616a55aee60481",
            "b1f72a9a99b74ecc9c56ed493b6d5a34",
            "69f7e8fe4fca4d2ba803a3de4c215228",
            "e92e90797abd4ad3b63611480cedf58f",
            "f1f939160b2546d588cc2215518c4737",
            "57c49da2e5014ffbb0f65fc27232a2d0",
            "33c97b04aa2e419aa558fff0293404bc",
            "e5216cce49c946189951c71991eac5a9"
          ]
        },
        "id": "IFARz7kV3r3F",
        "outputId": "f88656d7-df80-4141-ca36-c0b2d222c8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ba03d121374eada57252baa6f17a62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-4a95b06148a7>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(f\"{fine_tuned_model_path}/pytorch_model.bin\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/MTLiens/Refined/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/MTLiens/Refined/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/MTLiens/Refined/tokenizer.model',\n",
              " '/content/drive/MyDrive/MTLiens/Refined/added_tokens.json',\n",
              " '/content/drive/MyDrive/MTLiens/Refined/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "model_path = \"/content/drive/MyDrive/MTLiens/Refined\"\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "6e1d62a1f0574493b95d04e99d0b19c7",
            "4ccfad999c0b48a4ac8b5bc325a4250a",
            "ede91c8a393a4a9f89771964a8f4a068",
            "1cd07053bee04f188ff849ea936789b7",
            "5a9060917a9946a6b994fbed1ed0e427",
            "11092e75f2434155b2f0a4a29066d708",
            "f5dfb1af7b0d4ad2a6b50ebc51485fb1",
            "813dc4aee6d04b478a0fff50d99ad114",
            "433330b47da24fa0b636259213ea836c",
            "c0285bad4bcb44d8a243c2a449187590",
            "9d933693ab384f4bac1b3125a7c9324d"
          ]
        },
        "id": "2oZd4MfEyo6X",
        "outputId": "28d572ca-b213-4ad8-86ff-a5b586f3b6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e1d62a1f0574493b95d04e99d0b19c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gemma2ForCausalLM(\n",
              "  (model): Gemma2Model(\n",
              "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-25): 26 x Gemma2DecoderLayer(\n",
              "        (self_attn): Gemma2SdpaAttention(\n",
              "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
              "          (rotary_emb): Gemma2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Gemma2MLP(\n",
              "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text (prompt)\n",
        "input_text = \"What is the cure for alcoholism?\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "1dKptyVF1JdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "outputs = model.generate(\n",
        "    inputs['input_ids'],\n",
        "    max_length=500,  # Adjust max_length based on your needs\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,  # Adjust for more creative (higher) or deterministic (lower) output\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELsCYUB81WFe",
        "outputId": "c34b6459-c6c9-443f-97e2-90575e8dc821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the cure for alcoholism?\n",
            "\n",
            "There is no one-size-fits-all answer to this question.  Alcoholism is a complex medical condition that requires professional help and individualized treatment. However, here's a general overview of the path to recovery:\n",
            "\n",
            "**1. Recognizing the Problem:**\n",
            "\n",
            "* **Acknowledge the problem:** The first step is to admit that there's a problem with alcohol use. This can be difficult, but it's essential for starting the recovery process.\n",
            "* **Identify triggers:**  Understanding what situations or emotions lead to excessive drinking is crucial for managing triggers and avoiding relapse.\n",
            "* **Seek support:**  Talk to friends, family, or a therapist about your struggles. Having a support system can make a significant difference.\n",
            "\n",
            "**2. Seeking Professional Help:**\n",
            "\n",
            "* **Consult a doctor:** A medical professional can assess the severity of alcohol dependence and recommend appropriate treatment options.\n",
            "* **Consider rehab:**  Residential treatment programs offer a structured environment with intensive therapy, medical supervision, and a strong support network.\n",
            "* **Explore therapy options:**  Individual therapy, group therapy, and family therapy can help address underlying issues and develop coping mechanisms.\n",
            "* **Medication:**  Medications can be prescribed to manage withdrawal symptoms and reduce cravings.\n",
            "\n",
            "**3. Developing a Recovery Plan:**\n",
            "\n",
            "* **Set realistic goals:** Focus on small, achievable goals that build towards a healthier lifestyle.\n",
            "* **Build a support network:**  Connect with others who understand the challenges of recovery.\n",
            "* **Practice coping mechanisms:**  Develop healthy ways to deal with stress, anxiety, and cravings.\n",
            "* **Maintain a healthy lifestyle:**  Engage in regular exercise, eat a balanced diet, and prioritize sleep.\n",
            "\n",
            "**4. Ongoing Support and Monitoring:**\n",
            "\n",
            "* **Join a support group:**  Groups like Alcoholics Anonymous provide a safe and supportive environment for individuals in recovery.\n",
            "* **Regular checkups:**  Continue to see your doctor for regular health monitoring and medication management.\n",
            "* **Address relapse triggers:**  Be aware of situations that can trigger alcohol use and develop strategies to manage them.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "* **Recovery is a journey, not a destination:**  It's a process that requires ongoing effort and commitment.\n",
            "* **Relapse is possible:**  If you experience a relapse, don't be discouraged. It's an opportunity to learn and adjust your approach.\n",
            "* **There is hope\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text (prompt)\n",
        "input_text = \"What is the 7th step?\"\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generate text\n",
        "outputs = model.generate(\n",
        "    inputs['input_ids'],\n",
        "    max_length=500,  # Adjust max_length based on your needs\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,  # Adjust for more creative (higher) or deterministic (lower) output\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "82Ggd3NF1psh",
        "outputId": "8ca2ea18-5c0b-4631-e775-0b1fa09a7360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 39.56 GiB of which 22.81 MiB is free. Process 106027 has 39.53 GiB memory in use. Of the allocated memory 37.82 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f5464a07709b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Move model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Tokenize the input text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2903\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 )\n\u001b[0;32m-> 2905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                     )\n\u001b[0;32m-> 1160\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.20 GiB. GPU 0 has a total capacity of 39.56 GiB of which 22.81 MiB is free. Process 106027 has 39.53 GiB memory in use. Of the allocated memory 37.82 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "//Claude Iteration\\\\"
      ],
      "metadata": {
        "id": "rcfLsa--CO63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load the tokenizer and model from your local path\n",
        "model_path = \"/content/drive/MyDrive/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, attn_implementation='eager')\n",
        "\n",
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "data_path = \"/content/drive/Othercomputers/My Computer (1)/Google Drive Sync/Shared Docs/Cleaned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/gemma-2-2b-it\")\n",
        "\n",
        "# Load and concatenate all text files in the directory\n",
        "combined_text = \"\"\n",
        "file_count = 0\n",
        "for filename in os.listdir(data_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_count += 1\n",
        "        with open(os.path.join(data_path, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            file_content = file.read()\n",
        "            combined_text += file_content + \" \"\n",
        "        print(f\"Loaded file: {filename}, Content length: {len(file_content)}\")\n",
        "\n",
        "print(f\"\\nTotal files processed: {file_count}\")\n",
        "print(f\"Total characters in combined text: {len(combined_text)}\")\n",
        "\n",
        "# Print a sample of the combined text\n",
        "print(\"\\nSample of combined text (first 500 characters):\")\n",
        "print(combined_text[:500])\n",
        "\n",
        "# Tokenize the text with a sliding window\n",
        "max_length = 1024\n",
        "stride = 512\n",
        "tokenized_data = []\n",
        "\n",
        "for i in range(0, len(combined_text), stride):\n",
        "    chunk = combined_text[i:i+max_length]\n",
        "    tokens = tokenizer(chunk, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    tokenized_data.append(tokens.input_ids[0])\n",
        "\n",
        "print(f\"\\nNumber of chunks after tokenization: {len(tokenized_data)}\")\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenized_data):\n",
        "        self.tokenized_data = tokenized_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokenized_data[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Pad the batch to the maximum length in the batch\n",
        "    return pad_sequence(batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "dataset = TextDataset(tokenized_data)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "print(f\"First batch shape: {next(iter(dataloader)).shape}\")\n",
        "\n",
        "# Print a sample of tokenized and decoded text\n",
        "sample_tokens = tokenized_data[0]\n",
        "print(\"\\nSample of tokenized and decoded text:\")\n",
        "print(tokenizer.decode(sample_tokens))\n",
        "\n",
        "# Set up optimizer with Gemma-recommended parameters\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01)\n",
        "\n",
        "# Enable mixed precision training\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "# Accumulate gradients over 4 steps (adjust as needed based on your memory constraints)\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "# Learning rate scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "num_training_steps = len(dataloader) * 3  # 3 epochs, adjust as needed\n",
        "num_warmup_steps = num_training_steps // 10  # 10% of total steps for warmup\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Verify data loading\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "print(f\"First batch shape: {next(iter(dataloader)).shape}\")\n",
        "\n",
        "# Ensure model is in training mode and on correct device\n",
        "model.train()\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "\n",
        "# Fine-tuning loop with detailed logging\n",
        "for epoch in range(3):  # Consider increasing this\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        print(f\"Processing batch {i+1}\")\n",
        "        batch = batch.to(device)\n",
        "        print(f\"Batch shape: {batch.shape}, Device: {batch.device}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device_type='cuda'):\n",
        "            outputs = model(input_ids=batch, labels=batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        print(f\"Raw loss: {loss.item()}\")\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0:  # Print loss more frequently\n",
        "            print(f\"Epoch {epoch+1}, Step {i+1}, Avg Loss: {total_loss / 10:.4f}\")\n",
        "            total_loss = 0\n",
        "\n",
        "        # Break after a few batches for testing\n",
        "        if i == 20:\n",
        "            break\n",
        "\n",
        "    print(f\"Completed epoch {epoch+1}\")\n",
        "\n",
        "print(\"Training completed\")\n",
        "\n",
        "# Save the fine-tuned model weights\n",
        "fine_tuned_path = \"/content/drive/MyDrive/MTLiens/Refined\"\n",
        "torch.save(model.state_dict(), f\"{fine_tuned_path}/pytorch_model.bin\")\n",
        "tokenizer.save_pretrained(fine_tuned_path)\n",
        "\n",
        "print(\"Model saved. Now loading for inference...\")\n",
        "\n",
        "# Load the fine-tuned model for inference\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/gemma-2-2b-it\")  # Load original model architecture\n",
        "model.load_state_dict(torch.load(f\"{fine_tuned_path}/pytorch_model.bin\"))  # Load fine-tuned weights\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_path)\n",
        "\n",
        "print(\"Fine-tuned model loaded. Testing...\")\n",
        "\n",
        "# Test the model\n",
        "test_input = \"What is the 7th step?\"\n",
        "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(inputs['input_ids'], max_length=500)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "# Compare with original model\n",
        "original_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/gemma-2-2b-it\")\n",
        "original_model.to(device)\n",
        "outputs = original_model.generate(inputs['input_ids'], max_length=500)\n",
        "print(\"Original model output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "99dea34e9ce04297ad72e7faa7ad2491",
            "592b7e98e2af4245ab679ce00e0a6b60",
            "6b608471493c43d1b043ad8f31e31c00",
            "c96e7caf79f441c39fe152a218ce8d95",
            "9a19d1a4d31d40a787c76457910ea595",
            "91321f1f53704257ae0060b9e24788d8",
            "7a9e96a8527f408ba17ca5f102578217",
            "7932f978c3214fe3be5ac88b59e0eeb0",
            "f8051ef8cdfe4c5b9104b29228b55588",
            "124bf0d6b2224798a4646c853823ba02",
            "df6d50a4f3b5465c9a7374acbf7b8753"
          ]
        },
        "id": "BhssJL9iCRiF",
        "outputId": "a6dd6394-c7cd-4401-baad-ca854c492af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99dea34e9ce04297ad72e7faa7ad2491"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file: BigBook no stories no appendices.txt, Content length: 259323\n",
            "Loaded file: Clean_AsBillSeesIt.txt, Content length: 254165\n",
            "\n",
            "Total files processed: 2\n",
            "Total characters in combined text: 513490\n",
            "\n",
            "Sample of combined text (first 500 characters):\n",
            "Chapter 1\n",
            "    \n",
            "    BILL'S STORY\n",
            "    \n",
            "    WAR FEVER ran high in the New England town to which we new, young officers from Plattsburg were assigned, and we were flattered when the first citizens took us to their homes, making us feel heroic.  Here was love, applause, war; moments sublime with intervals hilarious.  I was part of life at last, and in the midst of the excitement I discovered liquor.  I forgot the strong warnings and the prejudices of my people concerning drink.  In time we sailed for\n",
            "\n",
            "Number of chunks after tokenization: 1003\n",
            "Dataset size: 1003\n",
            "First batch shape: torch.Size([2, 263])\n",
            "\n",
            "Sample of tokenized and decoded text:\n",
            "<bos>Chapter 1\n",
            "    \n",
            "    BILL'S STORY\n",
            "    \n",
            "    WAR FEVER ran high in the New England town to which we new, young officers from Plattsburg were assigned, and we were flattered when the first citizens took us to their homes, making us feel heroic.  Here was love, applause, war; moments sublime with intervals hilarious.  I was part of life at last, and in the midst of the excitement I discovered liquor.  I forgot the strong warnings and the prejudices of my people concerning drink.  In time we sailed for \"Over There.\"  I was very lonely and again turned to alcohol.\n",
            "    We landed in England.  I visited Winchester Cathedral.  Much moved, I wandered outside.  My attention was caught by a doggerel on an old tombstone:\n",
            "                    \"Here lies a Hampshire Grenadier\n",
            "                      Who caught his death\n",
            "                      Drinking cold small beer.\n",
            "                      A good soldier is ne'er forgot\n",
            "                      Whether he dieth by musket\n",
            "                                   Or by pot.\"\n",
            "    Ominous warn\n",
            "Dataset size: 1003\n",
            "First batch shape: torch.Size([2, 270])\n",
            "Model device: cuda:0\n",
            "Processing batch 1\n",
            "Batch shape: torch.Size([2, 221]), Device: cuda:0\n",
            "Raw loss: 3.9361984729766846\n",
            "Processing batch 2\n",
            "Batch shape: torch.Size([2, 238]), Device: cuda:0\n",
            "Raw loss: 4.109964847564697\n",
            "Processing batch 3\n",
            "Batch shape: torch.Size([2, 226]), Device: cuda:0\n",
            "Raw loss: 3.256101608276367\n",
            "Processing batch 4\n",
            "Batch shape: torch.Size([2, 252]), Device: cuda:0\n",
            "Raw loss: 4.67182731628418\n",
            "Processing batch 5\n",
            "Batch shape: torch.Size([2, 268]), Device: cuda:0\n",
            "Raw loss: 4.946300029754639\n",
            "Processing batch 6\n",
            "Batch shape: torch.Size([2, 249]), Device: cuda:0\n",
            "Raw loss: 3.1912682056427\n",
            "Processing batch 7\n",
            "Batch shape: torch.Size([2, 240]), Device: cuda:0\n",
            "Raw loss: 3.6935641765594482\n",
            "Processing batch 8\n",
            "Batch shape: torch.Size([2, 274]), Device: cuda:0\n",
            "Raw loss: 6.663818359375\n",
            "Processing batch 9\n",
            "Batch shape: torch.Size([2, 240]), Device: cuda:0\n",
            "Raw loss: 3.553694486618042\n",
            "Processing batch 10\n",
            "Batch shape: torch.Size([2, 248]), Device: cuda:0\n",
            "Raw loss: 6.685773849487305\n",
            "Epoch 1, Step 10, Avg Loss: 1.1177\n",
            "Processing batch 11\n",
            "Batch shape: torch.Size([2, 281]), Device: cuda:0\n",
            "Raw loss: 4.203315258026123\n",
            "Processing batch 12\n",
            "Batch shape: torch.Size([2, 255]), Device: cuda:0\n",
            "Raw loss: 5.150068283081055\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 74.81 MiB is free. Process 283492 has 39.48 GiB memory in use. Of the allocated memory 38.44 GiB is allocated by PyTorch, and 553.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-717d53a58df4>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"betas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             has_complex = self._init_group(\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n\u001b[1;32m    158\u001b[0m                 \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 state[\"exp_avg_sq\"] = torch.zeros_like(\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 74.81 MiB is free. Process 283492 has 39.48 GiB memory in use. Of the allocated memory 38.44 GiB is allocated by PyTorch, and 553.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "//Claude Low Mem\\\\ including fp16"
      ],
      "metadata": {
        "id": "OeMTWeHCPjLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Load the tokenizer and model from your local path\n",
        "model_path = \"/content/drive/MyDrive/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_path = \"/content/drive/Othercomputers/My Computer (1)/Google Drive Sync/Shared Docs/Cleaned\"\n",
        "\n",
        "# Load and concatenate all text files in the directory\n",
        "combined_text = \"\"\n",
        "file_count = 0\n",
        "for filename in os.listdir(data_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        file_count += 1\n",
        "        with open(os.path.join(data_path, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            file_content = file.read()\n",
        "            combined_text += file_content + \" \"\n",
        "        print(f\"Loaded file: {filename}, Content length: {len(file_content)}\")\n",
        "\n",
        "print(f\"\\nTotal files processed: {file_count}\")\n",
        "print(f\"Total characters in combined text: {len(combined_text)}\")\n",
        "\n",
        "# Print a sample of the combined text\n",
        "print(\"\\nSample of combined text (first 500 characters):\")\n",
        "print(combined_text[:500])\n",
        "\n",
        "# Tokenize the text with a sliding window\n",
        "max_length = 1024\n",
        "stride = 512\n",
        "tokenized_data = []\n",
        "\n",
        "for i in range(0, len(combined_text), stride):\n",
        "    chunk = combined_text[i:i+max_length]\n",
        "    tokens = tokenizer(chunk, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "    tokenized_data.append(tokens.input_ids[0])\n",
        "\n",
        "print(f\"\\nNumber of chunks after tokenization: {len(tokenized_data)}\")\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenized_data):\n",
        "        self.tokenized_data = tokenized_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokenized_data[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Pad the batch to the maximum length in the batch\n",
        "    return pad_sequence(batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "dataset = TextDataset(tokenized_data)\n",
        "\n",
        "# Reduce batch size\n",
        "batch_size = 1\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "print(f\"First batch shape: {next(iter(dataloader)).shape}\")\n",
        "\n",
        "# Print a sample of tokenized and decoded text\n",
        "sample_tokens = tokenized_data[0]\n",
        "print(\"\\nSample of tokenized and decoded text:\")\n",
        "print(tokenizer.decode(sample_tokens))\n",
        "\n",
        "# Load model with bfloat16 precision and gradient checkpointing\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    use_cache=False,\n",
        "    attn_implementation='eager'\n",
        ")\n",
        "model.gradient_checkpointing_enable()\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "\n",
        "# Optimizer setup\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler\n",
        "num_training_steps = len(dataloader) * 3  # 3 epochs\n",
        "num_warmup_steps = num_training_steps // 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
        "\n",
        "# Gradient accumulation steps\n",
        "gradient_accumulation_steps = 8\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "            outputs = model(input_ids=batch, labels=batch)\n",
        "            loss = outputs.loss / gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * gradient_accumulation_steps\n",
        "\n",
        "        if (i + 1) % (10 * gradient_accumulation_steps) == 0:\n",
        "            print(f\"Epoch {epoch+1}, Step {i+1}, Avg Loss: {total_loss / (10 * gradient_accumulation_steps):.4f}\")\n",
        "            total_loss = 0\n",
        "\n",
        "    print(f\"Completed epoch {epoch+1}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration/pytorch_model.bin\")\n",
        "\n",
        "print(\"Training completed and model saved.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a2a6081479644008cf1827c49061b2c",
            "dd22d9a3095148498ebadcd7ba11ffbc",
            "9533438097c24a7fa025be0ae14687d2",
            "48c7b73ffaa14adb9832f22eb158ee57",
            "02530c812e504b8492112e8b5dd35d4f",
            "31ec0b344030455493d25d6179c204e2",
            "79ddd59d5d104cbab6a15922c6cbb18a",
            "0d146140dc4640758301a8896f51280b",
            "9152e0f812af4682ae8cf19b5c77eae2",
            "97121e748ff04a468d127a3a5e12eb78",
            "65b9eac11ab748f2af8f53805a268c34"
          ]
        },
        "id": "Rx2s0_lCPnYZ",
        "outputId": "9ad15b30-83f1-4750-c67a-277bca302363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file: p3-ClaudeCleaned.txt, Content length: 4868\n",
            "Loaded file: p2-ClaudeCleaned.txt, Content length: 61802\n",
            "Loaded file: p5-Cleaned.txt, Content length: 53317\n",
            "Loaded file: p83_Cleaned.txt, Content length: 56537\n",
            "Loaded file: p-1_Claude.txt, Content length: 21015\n",
            "Loaded file: 12-Traditions.txt, Content length: 1540\n",
            "Loaded file: p4-ClaudeCleaned.txt, Content length: 21685\n",
            "Loaded file: DropTheRock_ClaudeCleanedManual.txt, Content length: 123227\n",
            "Loaded file: Clean_AsBillSeesIt_Corrected.txt, Content length: 251595\n",
            "Loaded file: BigBook no stories no appendices.txt, Content length: 259360\n",
            "Loaded file: 12-Steps.txt, Content length: 1231\n",
            "\n",
            "Total files processed: 11\n",
            "Total characters in combined text: 856188\n",
            "\n",
            "Sample of combined text (first 500 characters):\n",
            "Is A.A. for You?\n",
            "\n",
            "Only you can decide whether you want to give A.A. a try — whether you think it can help. The questions that follow below may help you make a decision.\n",
            "\n",
            "We who are in A.A. came because we finally gave up trying to control our drinking. We still hated to admit that we could never drink safely. Then we heard from other A.A. members that we had an illness. (Some of us thought so for years!) We found out that many people suffered from the same feelings of guilt and loneliness and ho\n",
            "\n",
            "Number of chunks after tokenization: 1673\n",
            "Dataset size: 1673\n",
            "First batch shape: torch.Size([1, 223])\n",
            "\n",
            "Sample of tokenized and decoded text:\n",
            "<bos>Is A.A. for You?\n",
            "\n",
            "Only you can decide whether you want to give A.A. a try — whether you think it can help. The questions that follow below may help you make a decision.\n",
            "\n",
            "We who are in A.A. came because we finally gave up trying to control our drinking. We still hated to admit that we could never drink safely. Then we heard from other A.A. members that we had an illness. (Some of us thought so for years!) We found out that many people suffered from the same feelings of guilt and loneliness and hopelessness that we did. We found out that we had these feelings because we had the disease of alcoholism.\n",
            "\n",
            "We decided to try to face up to what alcohol had done to us. Here are some of the questions we tried to answer honestly. If we answered \"Yes\" to four or more questions, we were in deep trouble with our drinking. See how you do. Remember, there is no disgrace in facing up to the fact that you have a problem.\n",
            "\n",
            "1. Have you ever decided to stop drinking for a week or so, but only lasted for a couple of days?\n",
            "Most of u\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a2a6081479644008cf1827c49061b2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 80, Avg Loss: 3.1942\n",
            "Epoch 1, Step 160, Avg Loss: 3.2093\n",
            "Epoch 1, Step 240, Avg Loss: 3.2125\n",
            "Epoch 1, Step 320, Avg Loss: 3.1365\n",
            "Epoch 1, Step 400, Avg Loss: 3.1198\n",
            "Epoch 1, Step 480, Avg Loss: 3.1672\n",
            "Epoch 1, Step 560, Avg Loss: 3.1001\n",
            "Epoch 1, Step 640, Avg Loss: 3.1073\n",
            "Epoch 1, Step 720, Avg Loss: 3.0575\n",
            "Epoch 1, Step 800, Avg Loss: 3.0187\n",
            "Epoch 1, Step 880, Avg Loss: 3.0054\n",
            "Epoch 1, Step 960, Avg Loss: 2.9338\n",
            "Epoch 1, Step 1040, Avg Loss: 2.9216\n",
            "Epoch 1, Step 1120, Avg Loss: 2.8796\n",
            "Epoch 1, Step 1200, Avg Loss: 2.9646\n",
            "Epoch 1, Step 1280, Avg Loss: 2.8337\n",
            "Epoch 1, Step 1360, Avg Loss: 2.8368\n",
            "Epoch 1, Step 1440, Avg Loss: 2.8865\n",
            "Epoch 1, Step 1520, Avg Loss: 2.8542\n",
            "Epoch 1, Step 1600, Avg Loss: 2.8830\n",
            "Completed epoch 1\n",
            "Epoch 2, Step 80, Avg Loss: 2.7552\n",
            "Epoch 2, Step 160, Avg Loss: 2.7280\n",
            "Epoch 2, Step 240, Avg Loss: 2.7097\n",
            "Epoch 2, Step 320, Avg Loss: 2.6916\n",
            "Epoch 2, Step 400, Avg Loss: 2.6530\n",
            "Epoch 2, Step 480, Avg Loss: 2.6336\n",
            "Epoch 2, Step 560, Avg Loss: 2.7216\n",
            "Epoch 2, Step 640, Avg Loss: 2.6833\n",
            "Epoch 2, Step 720, Avg Loss: 2.6746\n",
            "Epoch 2, Step 800, Avg Loss: 2.6221\n",
            "Epoch 2, Step 880, Avg Loss: 2.6217\n",
            "Epoch 2, Step 960, Avg Loss: 2.6126\n",
            "Epoch 2, Step 1040, Avg Loss: 2.5762\n",
            "Epoch 2, Step 1120, Avg Loss: 2.5872\n",
            "Epoch 2, Step 1200, Avg Loss: 2.5722\n",
            "Epoch 2, Step 1280, Avg Loss: 2.5464\n",
            "Epoch 2, Step 1360, Avg Loss: 2.6172\n",
            "Epoch 2, Step 1440, Avg Loss: 2.5292\n",
            "Epoch 2, Step 1520, Avg Loss: 2.5550\n",
            "Epoch 2, Step 1600, Avg Loss: 2.5297\n",
            "Completed epoch 2\n",
            "Epoch 3, Step 80, Avg Loss: 2.2764\n",
            "Epoch 3, Step 160, Avg Loss: 2.2322\n",
            "Epoch 3, Step 240, Avg Loss: 2.1993\n",
            "Epoch 3, Step 320, Avg Loss: 2.2661\n",
            "Epoch 3, Step 400, Avg Loss: 2.1292\n",
            "Epoch 3, Step 480, Avg Loss: 2.2060\n",
            "Epoch 3, Step 560, Avg Loss: 2.1198\n",
            "Epoch 3, Step 640, Avg Loss: 2.1034\n",
            "Epoch 3, Step 720, Avg Loss: 2.1407\n",
            "Epoch 3, Step 800, Avg Loss: 2.0556\n",
            "Epoch 3, Step 880, Avg Loss: 2.1019\n",
            "Epoch 3, Step 960, Avg Loss: 2.0692\n",
            "Epoch 3, Step 1040, Avg Loss: 1.9511\n",
            "Epoch 3, Step 1120, Avg Loss: 2.0407\n",
            "Epoch 3, Step 1200, Avg Loss: 2.0037\n",
            "Epoch 3, Step 1280, Avg Loss: 1.9718\n",
            "Epoch 3, Step 1360, Avg Loss: 2.0037\n",
            "Epoch 3, Step 1440, Avg Loss: 1.8865\n",
            "Epoch 3, Step 1520, Avg Loss: 1.9294\n",
            "Epoch 3, Step 1600, Avg Loss: 1.8653\n",
            "Completed epoch 3\n",
            "Training completed and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import os\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Load the tokenizer and model from your local path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load the fine-tuned model for inference\n",
        "\n",
        "fine_tuned_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "fine_tuned_model.to(device)\n",
        "\n",
        "# Test the fine-tuned model\n",
        "test_input = \"What is step 1, and how do i exercise it?\"\n",
        "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
        "outputs = fine_tuned_model.generate(inputs['input_ids'], max_length=500)\n",
        "print(\"Fine-tuned model output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "cde185b5877e424385228c949d097ec3",
            "9c9c49315c9b48ec811b747803119358",
            "e78dd31a7b5947bf9f7a3a4d38220356",
            "f4a45f58da1b421fab0e4b328e01ad24",
            "b36e09c015334f54848b8e3ab21ce37f",
            "3adc3b1db4964ee985d7aec44a83a6b4",
            "ea60c4c31cc147c4bb40d3be2b4259a0",
            "96aa1797494248408466b40bfa6220cb",
            "620d95fae2ba4722b6ba05581946d69d",
            "f19113e0155c475f9ef331f233caf21c",
            "1d709e95bd424c07af7b32a856a4bca8"
          ]
        },
        "id": "x2NtbvL4TZLE",
        "outputId": "3dde70ed-4b38-4e36-b55d-d4670649138e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde185b5877e424385228c949d097ec3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model output: What is step 1, and how do i exercise it?\n",
            "\n",
            "It is Step One of the Twelve Steps of Alcoholics Anonymous:\n",
            "\n",
            "**\"We admitted we were powerless over alcohol — that our lives had become unmanageable.\"**\n",
            "\n",
            "How do I exercise this step?\n",
            "\n",
            "The first step is the hardest. It requires a complete willingness to change and a willingness to admit that we cannot do it alone. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in denial. It requires a willingness to look at our lives and see that we have been living in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model from your local path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned model for inference\n",
        "fine_tuned_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/fine_tuned_gemma/o1-iteration/New-Data-Reiteration\")\n",
        "fine_tuned_model.to(device)\n",
        "\n",
        "# Test the fine-tuned model\n",
        "test_input = \"Respond in clear and concise language. What is Step Three, and how do i practice it?\"\n",
        "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generate text with repetition penalty and controlled creativity\n",
        "outputs = fine_tuned_model.generate(\n",
        "    inputs['input_ids'],\n",
        "    max_length=400,  # Adjust based on how long you'd like it to generate\n",
        "    temperature=0.2,  # Keep it minimally creative\n",
        "    top_k=20,  # Top-k sampling - next word pool\n",
        "    top_p=0.8,  # Nucleus sampling\n",
        "    repetition_penalty=1.2,  # Apply a penalty to discourage repetition\n",
        "    no_repeat_ngram_size=3,  # Ensure no 3-gram repetition\n",
        "    early_stopping=True,  # Stops the generation once it feels the output is repetitive or lower quality\n",
        "    do_sample=True  # Enables sampling to keep creativity\n",
        ")\n",
        "\n",
        "# Print the model's output\n",
        "print(\"Fine-tuned model output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "793da6eb953d4da7acf7652fdeb20f74",
            "8164318b9348420fb8ce3ac41112b427",
            "d707b4766ed3479a9e46c22330517eb7",
            "101bef0b265d4e95a88652e455d8aca0",
            "841cb760f44447c0a65807a449558046",
            "b003ddbfb6a64f92aa3cead023eafaba",
            "8bd29cbbd5a24b468682fafa86857697",
            "2565cbde36364cbfb039d7a259809d91",
            "8382f63b0b834876b3f30a0cf977b30f",
            "3c2ba8e272cd4cafae3ec727837d043f",
            "f3bb78afaad847b9acffafd104cd4b63"
          ]
        },
        "id": "6vTH7IxTVF19",
        "outputId": "904f3e44-981e-4045-845e-80ed19d78505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "793da6eb953d4da7acf7652fdeb20f74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model output: Respond in clear and concise language. What is Step Three, and how do i practice it?\n",
            "\n",
            "Twelve Steps are the foundation of recovery for members who identify as alcoholics or addicts. They represent a practical approach to living without addiction by providing tools that help individuals maintain sobriety (or abstinence) from alcohol and other addictive substances. The Twelve Steps offer guidance on developing healthy emotional habits and behaviors necessary for long-term stability in recovery. \n",
            "\n",
            "The Third Step says: \"We made direct amends to such people where we were wrong; ... We tried to carry this message to alcoholics, and to all who suffer from alcoholism.\" This means taking responsibility for our actions and apologizing when appropriate. It also involves sharing what we know about alcoholism with others so they can get sober themselves if they want to.\n",
            "\n",
            "\n",
            "What does practicing Step Three look like in daily life? Here's an example:\n",
            "You have been late getting to work several times recently because you got caught up talking with friends at lunch. Your boss has called you into his office twice to remind you that being punctual is important. You realize your lateness may be affecting your job performance. How would you apply the principles of Step Three to resolve this situation?\n",
            "\n",
            "Here’s one way to proceed:\n",
            "1. **Take Responsibility:** First, admit to yourself that you are responsible for showing up on time for work. No matter why you might be running behind — traffic jams, unexpected errands, family problems — those reasons don’t absolve you from doing your part to arrive promptly. If there was something preventing you from arriving on time, then take steps to correct these issues before they become habitual patterns.  If possible, let someone know ahead of time that you will be delayed. Be proactive rather than reactive. Don't wait until you are already late!\n",
            "2. **Make Amends:** Apologize to your boss for any inconvenience caused by your tardiness. Explain that you understand its importance and assure him/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with original model\n",
        "model_path = \"/content/drive/MyDrive/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "original_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "original_model.to(device)\n",
        "outputs = original_model.generate(inputs['input_ids'], max_length=500)\n",
        "print(\"Original model output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "8903eaf897264d108d3bc3513fa0c6d3",
            "caf428c827374d1fb5cc90a63a33570f",
            "58a9c405e17c432d987e74dcc861fa37",
            "1f0a6b67139c454bb1df73786ebc3e2e",
            "4482e3069c3842ca8401d2937ba61a12",
            "2592c50f256d43f994045b94a2e4a07a",
            "90ae8a85b6554d1b9ceac2d1045664a5",
            "2c10f6c3f67448b4945f1d8a1d31da5e",
            "94604854dffe4efaad482448da5ecfcc",
            "7835e9a6461442fca9e56a564fc92230",
            "227dcc7bd83b42e4ad943a1fe551815d"
          ]
        },
        "id": "-bbTp-xlSz4J",
        "outputId": "92408a23-37a9-459a-93c6-24db3282ce06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8903eaf897264d108d3bc3513fa0c6d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model output: How do i find a Higher Power in my life?\n",
            "\n",
            "It's a question that has been pondered by people for centuries.  There's no one right answer, as the concept of a Higher Power is deeply personal and can vary widely. \n",
            "\n",
            "Here are some ways people find their Higher Power:\n",
            "\n",
            "**1. Explore Different Spiritual Traditions:**\n",
            "* **Religion:**  Many religions offer a framework for understanding a Higher Power, such as God, Allah, Buddha, or the Tao.  \n",
            "* **Spirituality:**  Practices like meditation, yoga, and mindfulness can help you connect with a sense of the divine within yourself.\n",
            "* **Nature:**  Spending time in nature can be a source of awe and wonder, prompting a sense of connection to something larger than yourself.\n",
            "\n",
            "**2. Reflect on Your Values and Beliefs:**\n",
            "* **What do you believe in?** What gives your life meaning? \n",
            "* **What are your core values?**  Do they point towards a higher purpose or a sense of interconnectedness?\n",
            "* **What makes you feel most alive and fulfilled?**  These experiences can be clues to a Higher Power.\n",
            "\n",
            "**3. Seek Guidance and Support:**\n",
            "* **Talk to a spiritual leader or mentor:**  They can offer guidance and support on your spiritual journey.\n",
            "* **Join a community:**  Connecting with others who share your beliefs can provide a sense of belonging and support.\n",
            "* **Read spiritual texts:**  Explore different perspectives on the nature of a Higher Power.\n",
            "\n",
            "**4. Trust Your Intuition:**\n",
            "* **Pay attention to your inner voice:**  What does your heart tell you?\n",
            "* **Listen to your gut feelings:**  They can often guide you towards what is right and true for you.\n",
            "\n",
            "**5. Be Patient and Open-Minded:**\n",
            "* **Finding your Higher Power is a journey, not a destination.**  Be patient with yourself and open to new experiences.\n",
            "* **Don't be afraid to question and explore different ideas.**  The search for meaning is a lifelong process.\n",
            "\n",
            "**Remember:**\n",
            "* There is no right or wrong answer to the question of a Higher Power.\n",
            "* The most important thing is to find what resonates with you and brings you a sense of peace and purpose.\n",
            "* Your journey is unique, and your Higher Power may be something you discover on your own.\n",
            "\n",
            "\n",
            "It's important to note that this is a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "//Model Reducer\\\\ --- Reduced by only 20%"
      ],
      "metadata": {
        "id": "yhV2KvSAQp_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# Model and Tokenizer loading paths\n",
        "model_path = '/content/drive/MyDrive/fine_tuned_gemma/o1-iteration'\n",
        "save_path = '/content/drive/MyDrive/fine_tuned_gemma/pruned_quantized_model.pth'\n",
        "\n",
        "# Set the device to GPU if available, fallback to CPU if not\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the fine-tuned model on GPU for pruning\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, use_cache=False)\n",
        "\n",
        "# Move the model to GPU\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model loaded on device: {next(model.parameters()).device}\")\n",
        "\n",
        "# Apply light magnitude-based weight pruning to all Linear layers (10% pruning)\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "        # Prune the weights with the smallest magnitude, but only 10%\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.15)\n",
        "\n",
        "# Remove pruning re-parametrization and make pruning permanent\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "        prune.remove(module, 'weight')\n",
        "\n",
        "print(\"Light pruning complete (10%).\")\n",
        "\n",
        "# Move the model to CPU for dynamic quantization\n",
        "model.to(\"cpu\")\n",
        "\n",
        "# Apply dynamic quantization (quantizes Linear layers to qint8)\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8  # Quantize to qint8 for Linear layers\n",
        ")\n",
        "\n",
        "print(\"Dynamic quantization complete.\")\n",
        "\n",
        "# Save the pruned and quantized model using torch.save\n",
        "torch.save(quantized_model.state_dict(), save_path)\n",
        "print(f\"Pruned and quantized model saved to {save_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "b74d97730393401c90e88e6185d3777b",
            "4c2b3d47e32c4d5ab69dc90d4dbc69ad",
            "50478117e61847b3ac4b6344f56c2448",
            "bb0c710d6f3c4f12a0919db973470cf5",
            "f7b4b08efe394dc2b39c85569f47fb8e",
            "0ad4a2b14eff497f9f5233f048977f29",
            "184ffd0feb0f4181974afb08d1c2d247",
            "c4a17971bf7f4fb9ba57d0236931eb6b",
            "123696086370456f90064f4f00385e3d",
            "3d4716812d074300a9ebd6c63e1df572",
            "e050367e6e1e490baa97b4011c16cc1b"
          ]
        },
        "id": "nzhTlzgCUuHC",
        "outputId": "adda3f2a-1f62-4eea-d90c-bc1c2d16d8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b74d97730393401c90e88e6185d3777b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on device: cuda:0\n",
            "Light pruning complete (10%).\n",
            "Dynamic quantization complete.\n",
            "Pruned and quantized model saved to /content/drive/MyDrive/fine_tuned_gemma/pruned_quantized_model.pth\n",
            "Pruned and quantized model saved to /content/drive/MyDrive/fine_tuned_gemma/pruned_quantized_model.pth\n"
          ]
        }
      ]
    }
  ]
}