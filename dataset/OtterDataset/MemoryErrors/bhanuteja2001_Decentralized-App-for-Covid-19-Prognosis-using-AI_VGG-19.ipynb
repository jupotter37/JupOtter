{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79eb8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd92831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc3a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51952c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'G:\\\\PYTHON\\\\Final year project\\\\Dataset\\\\train'\n",
    "val_path = 'G:\\\\PYTHON\\\\Final year project\\\\Dataset\\\\val'\n",
    "test_path = 'G:\\\\PYTHON\\\\Final year project\\\\Dataset\\\\test'\n",
    "#test_path= test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf203b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to a size VGG-16 expects.\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE = 16  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_CLASSES = 2 # We are aware of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66645f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class --> ['covid', 'normal'] \n",
      " and the length is : 2\n"
     ]
    }
   ],
   "source": [
    "CLASSES = os.listdir(train_path)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(\"Class --> {} \\n and the length is : {}\".format(CLASSES, NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d43a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ed2455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6030 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import the images from the train dataset.\n",
    "# Make sure to provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    directory = train_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c08e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f96813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 860 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import the images from the test dataset.\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c9416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 8s 0us/step\n",
      "80150528/80134624 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG19(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b4c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a1febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "prediction = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef602289",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a372bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2ac4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensorboard = TensorBoard(log_dir=\"G:\\\\PYTHON\\\\Final year project\\\\Logs\\\\{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa1a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c095cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "377/377 [==============================] - 121s 293ms/step - loss: 0.4455 - accuracy: 0.8378 - val_loss: 0.5023 - val_accuracy: 0.7651\n",
      "Epoch 2/20\n",
      "377/377 [==============================] - 93s 246ms/step - loss: 0.2688 - accuracy: 0.8924 - val_loss: 0.5607 - val_accuracy: 0.7977\n",
      "Epoch 3/20\n",
      "377/377 [==============================] - 99s 262ms/step - loss: 0.2668 - accuracy: 0.8990 - val_loss: 0.6942 - val_accuracy: 0.7663\n",
      "Epoch 4/20\n",
      "377/377 [==============================] - 184s 487ms/step - loss: 0.2412 - accuracy: 0.9144 - val_loss: 0.3343 - val_accuracy: 0.8477\n",
      "Epoch 5/20\n",
      "377/377 [==============================] - 159s 423ms/step - loss: 0.2044 - accuracy: 0.9235 - val_loss: 0.3458 - val_accuracy: 0.8547\n",
      "Epoch 6/20\n",
      "377/377 [==============================] - 116s 308ms/step - loss: 0.2190 - accuracy: 0.9159 - val_loss: 0.5568 - val_accuracy: 0.7849\n",
      "Epoch 7/20\n",
      "377/377 [==============================] - 123s 326ms/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.3357 - val_accuracy: 0.8570\n",
      "Epoch 8/20\n",
      "377/377 [==============================] - 130s 345ms/step - loss: 0.1901 - accuracy: 0.9275 - val_loss: 0.9405 - val_accuracy: 0.7395\n",
      "Epoch 9/20\n",
      "377/377 [==============================] - 139s 368ms/step - loss: 0.3102 - accuracy: 0.9076 - val_loss: 0.3386 - val_accuracy: 0.8709\n",
      "Epoch 10/20\n",
      "377/377 [==============================] - 193s 511ms/step - loss: 0.2199 - accuracy: 0.9235 - val_loss: 0.3778 - val_accuracy: 0.8558\n",
      "Epoch 11/20\n",
      "377/377 [==============================] - 249s 660ms/step - loss: 0.1873 - accuracy: 0.9317 - val_loss: 0.3982 - val_accuracy: 0.8512\n",
      "Epoch 12/20\n",
      "377/377 [==============================] - 274s 727ms/step - loss: 0.1640 - accuracy: 0.9378 - val_loss: 0.3291 - val_accuracy: 0.8663\n",
      "Epoch 13/20\n",
      "377/377 [==============================] - 321s 851ms/step - loss: 0.1594 - accuracy: 0.9426 - val_loss: 0.3601 - val_accuracy: 0.8616\n",
      "Epoch 14/20\n",
      "377/377 [==============================] - 305s 807ms/step - loss: 0.1502 - accuracy: 0.9444 - val_loss: 0.9403 - val_accuracy: 0.7477\n",
      "Epoch 15/20\n",
      "377/377 [==============================] - 280s 743ms/step - loss: 0.1812 - accuracy: 0.9328 - val_loss: 0.3318 - val_accuracy: 0.8779\n",
      "Epoch 16/20\n",
      "377/377 [==============================] - 320s 849ms/step - loss: 0.2457 - accuracy: 0.9211 - val_loss: 0.3608 - val_accuracy: 0.8674\n",
      "Epoch 17/20\n",
      "329/377 [=========================>....] - ETA: 33s - loss: 0.1442 - accuracy: 0.9485"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[categorical_crossentropy/softmax_cross_entropy_with_logits/Shape_2/_6]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1372]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d7a10c17284a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-n1 -r1 '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"with tf.device('/GPU:0'):\\n    history = model.fit(\\n        training_set,\\n        validation_data=test_set,\\n        epochs=20,\\n        steps_per_epoch=len(training_set),\\n        validation_steps=len(test_set),\\n        callbacks=[Tensorboard]\\n    )\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2369\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2371\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2372\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m         \u001b[0mworst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[categorical_crossentropy/softmax_cross_entropy_with_logits/Shape_2/_6]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Charan Chandra\\anaconda3\\envs\\gputest\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.19 MiB for an array with shape (16, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1372]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 \n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        training_set,\n",
    "        validation_data=test_set,\n",
    "        epochs=20,\n",
    "        steps_per_epoch=len(training_set),\n",
    "        validation_steps=len(test_set),\n",
    "        callbacks=[Tensorboard]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcfe7a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2df580e79ce8efce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2df580e79ce8efce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb1afa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1726 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_set = validation_datagen.flow_from_directory(\n",
    "    directory = val_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56348a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/200 [===============>..............] - ETA: 18s - loss: 0.2966 - accuracy: 0.8969WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.2966 - accuracy: 0.8969\n",
      "loss: 0.30\n",
      "accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "validation_steps = 200\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(validation_set, steps = validation_steps)\n",
    "\n",
    "print(\"loss: {:.2f}\".format(loss0))\n",
    "print(\"accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4253a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1726 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate Validation set.\n",
    "validation_set2 = validation_datagen.flow_from_directory(\n",
    "    directory = val_path,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 1,\n",
    "    shuffle=False, \n",
    "    seed=42, \n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# validation_set2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd103187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 8s 145ms/step - loss: 0.3784 - accuracy: 0.8674\n",
      "loss: 0.38\n",
      "accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# just capture the loss and accuray into val variable... unlike in pervious code to capture into loss0 and accuracy0. Just to showcase alternate way.\n",
    "\n",
    "test = model.evaluate(test_set)\n",
    "\n",
    "print(\"loss: {:.2f}\".format(test[0]))\n",
    "print(\"accuracy: {:.2f}\".format(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca57002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdc131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "466bfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"G:\\\\PYTHON\\\\Final year project\\\\weights\\\\vgg_19_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
