{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccebc029-b2d0-4d2b-85b3-7f127deb0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import inspect\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import deepcopy\n",
    "from copy import copy\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0497828a-82d5-468c-aa94-d711445376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbfa15b-9844-4f77-8be6-2502cb7d6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../DSL')\n",
    "import solvers\n",
    "from solver_class import Solver\n",
    "import dsl\n",
    "from dsl import *\n",
    "from constants import *\n",
    "from fitness_scoring import *\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from visualization.visualization_utils import *\n",
    "from misc_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e01e5a4-fc29-4812-8f5e-065c755df81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "train_path = data_path / 'arc-agi_training_challenges.json'\n",
    "train_sols_path = data_path / 'arc-agi_training_solutions.json'\n",
    "eval_path = data_path / 'arc-agi_evaluation_challenges.json'\n",
    "eval_sols_path = data_path / 'arc-agi_evaluation_solutions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b3c7d0-4c83-44f2-8319-4a9d394c01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    train_tasks = json.load(f)\n",
    "with open(train_sols_path, 'r') as f:\n",
    "    train_sols = json.load(f)\n",
    "with open(eval_path, 'r') as f:\n",
    "    eval_tasks = json.load(f)\n",
    "with open(eval_sols_path, 'r') as f:\n",
    "    eval_sols = json.load(f)\n",
    "\n",
    "train_task_labels = sorted(train_tasks.keys())\n",
    "eval_task_labels = sorted(eval_tasks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e56531-5767-4c78-aae4-36475806394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast = lambda g: tuple(tuple(r) for r in g) # Converts grid to tuple format for DSL\n",
    "\n",
    "# Convert all train and eval examples to tuples for DSL\n",
    "for train_label in train_task_labels:\n",
    "    num_train = len(train_tasks[train_label]['train']) \n",
    "    num_test = len(train_tasks[train_label]['test'])\n",
    "    for i in range(num_train):\n",
    "        train_tasks[train_label]['train'][i]['input'] = ast(train_tasks[train_label]['train'][i]['input'])\n",
    "        train_tasks[train_label]['train'][i]['output'] = ast(train_tasks[train_label]['train'][i]['output'])\n",
    "    for i in range(num_test):\n",
    "        train_tasks[train_label]['test'][i]['input'] = ast(train_tasks[train_label]['test'][i]['input'])\n",
    "        train_sols[train_label][i] = ast(train_sols[train_label][i])\n",
    "for eval_label in eval_task_labels:\n",
    "    num_train = len(eval_tasks[eval_label]['train']) \n",
    "    num_test = len(eval_tasks[eval_label]['test'])\n",
    "    for i in range(num_train):\n",
    "        eval_tasks[eval_label]['train'][i]['input'] = ast(eval_tasks[eval_label]['train'][i]['input'])\n",
    "        eval_tasks[eval_label]['train'][i]['output'] = ast(eval_tasks[eval_label]['train'][i]['output'])\n",
    "    for i in range(num_test):\n",
    "        eval_tasks[eval_label]['test'][i]['input'] = ast(eval_tasks[eval_label]['test'][i]['input'])\n",
    "        eval_sols[eval_label][i] = ast(eval_sols[eval_label][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcd1319-f1c9-427e-988b-0208ff6e6e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449c307a-827e-4051-a4a1-72637a8ed814",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMITIVES = ['add', 'adjacent', 'apply', 'argmax', 'argmin', 'asindices', 'asobject', 'astuple', 'backdrop', 'bordering', 'both', 'bottomhalf', 'box', 'branch', 'canvas', 'cellwise', 'center', 'centerofmass', 'chain', 'cmirror', 'color', 'colorcount', 'colorfilter', 'combine', 'compose', 'compress', 'connect', 'contained', 'corners', 'cover', 'crement', 'crop', 'decrement', 'dedupe', 'delta', 'difference', 'divide', 'dmirror', 'dneighbors', 'double', 'downscale', 'either', 'equality', 'even', 'extract', 'fgpartition', 'fill', 'first', 'flip', 'fork', 'frontiers', 'gravitate', 'greater', 'halve', 'hconcat', 'height', 'hfrontier', 'hline', 'hmatching', 'hmirror', 'hperiod', 'hsplit', 'hupscale', 'identity', 'inbox', 'increment', 'index', 'ineighbors', 'initset', 'insert', 'intersection', 'interval', 'invert', 'last', 'lbind', 'leastcolor', 'leastcommon', 'lefthalf', 'leftmost', 'llcorner', 'lowermost', 'lrcorner', 'manhattan', 'mapply', 'matcher', 'maximum', 'merge', 'mfilter', 'minimum', 'mostcolor', 'mostcommon', 'move', 'mpapply', 'multiply', 'neighbors', 'normalize', 'numcolors', 'objects', 'occurrences', 'ofcolor', 'order', 'other', 'outbox', 'paint', 'pair', 'palette', 'papply', 'partition', 'portrait', 'position', 'positive', 'power', 'prapply', 'product', 'rapply', 'rbind', 'recolor', 'remove', 'repeat', 'replace', 'righthalf', 'rightmost', 'rot180', 'rot270', 'rot90', 'sfilter', 'shape', 'shift', 'shoot', 'sign', 'size', 'sizefilter', 'square', 'subgrid', 'subtract', 'switch', 'toindices', 'toivec', 'tojvec', 'toobject', 'tophalf', 'totuple', 'trim', 'ulcorner', 'underfill', 'underpaint', 'uppermost', 'upscale', 'urcorner', 'valmax', 'valmin', 'vconcat', 'vfrontier', 'vline', 'vmatching', 'vmirror', 'vperiod', 'vsplit', 'vupscale', 'width']\n",
    "COMMON_PRIMITIVES = ['compose', 'fork', 'lbind', 'rbind', 'fill', 'chain', 'objects', 'mapply', 'apply', 'ofcolor', 'astuple', 'paint', 'sfilter', 'matcher', 'branch', 'merge', 'combine', 'first', 'argmax', 'shift', 'canvas', 'mostcolor', 'palette', 'height', 'shape', 'width', 'remove', 'interval', 'difference', 'subgrid', 'colorfilter', 'size', 'replace', 'color', 'argmin', 'extract', 'leastcolor', 'decrement', 'increment', 'asobject', 'equality', 'asindices', 'add', 'hconcat', 'subtract', 'mfilter', 'initset', 'insert', 'normalize', 'vmirror']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3e0e9-21c6-4d88-bae7-e7c2a1f2b635",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967ff0c8-cbac-4560-a5f3-c6dc93fb19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "codegen_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\",\n",
    "                                                 padding_side='left', # For padding batches of input in decoder-only context\n",
    "                                                 clean_up_tokenization_spaces = True,\n",
    "                                                 ) \n",
    "codegen = AutoModelForCausalLM.from_pretrained(\"../CodeGen fine-tuning/outputs/v7/\")\n",
    "codegen = codegen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc6f885-a01b-4b52-926b-da3904059bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN = codegen_tokenizer.eos_token\n",
    "BOS_TOKEN = codegen_tokenizer.bos_token\n",
    "PAD_TOKEN = '[PAD]'\n",
    "codegen_tokenizer.add_special_tokens({'pad_token': PAD_TOKEN})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a4758-4fd5-4bd5-b720-3dcd32a60b87",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5b21a13-3bd0-4982-8ab1-dbdc81e7a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_safe_beam_generate(model,\n",
    "                              tokenizer,\n",
    "                              inputs,\n",
    "                              generate_args = {\n",
    "                                    'max_new_tokens': 256,\n",
    "                                    'num_beams': 8,\n",
    "                                    'num_return_sequences': 8,\n",
    "                                },\n",
    "                             ):\n",
    "    tokens = [tokenizer(prompt, padding = True, return_tensors = 'pt').to(DEVICE) for prompt in inputs]\n",
    "    results = []\n",
    "    for t in tokens:\n",
    "        outputs = []\n",
    "        while len(outputs) == 0:\n",
    "            try:\n",
    "                outputs = model.generate(**t,\n",
    "                         pad_token_id = tokenizer.pad_token_id,\n",
    "                        **generate_args,\n",
    "                        )\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                generate_args['num_beams'] = generate_args['num_beams']//2\n",
    "                generate_args['num_return_sequences'] = generate_args['num_return_sequences']//2\n",
    "                if generate_args['num_beams'] == 0:\n",
    "                    raise MemoryError('num_beams was reduced to 1, but still ran out of memory!')\n",
    "        results.extend(tokenizer.batch_decode(outputs, skip_special_tokens = True))\n",
    "        genargs_log.append((generate_args['max_new_tokens'], generate_args['num_beams']))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8116dc64-63e4-43ab-a1f4-74901a3c3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_candidates(candidates: list[str]) -> [int, list[str]]:\n",
    "    failed = []\n",
    "    cleaned = []\n",
    "    for candidate in candidates:\n",
    "        if \"return O\" not in candidate:\n",
    "            failed.append(candidate)\n",
    "        else:\n",
    "            cleaned.append(candidate.split(\"return O\")[0] + \"return O\")\n",
    "    return failed, cleaned            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df33d15-51c8-4e1c-8454-a0281436f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_candidates(candidates: list[str]) -> [int, list[Solver]]:\n",
    "    failed = []\n",
    "    compiled = []\n",
    "    for candidate in candidates:\n",
    "        try:\n",
    "            compiled.append(Solver(candidate))\n",
    "        except:\n",
    "            failed.append(candidate)\n",
    "    return failed, compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a9d81b-2f62-472e-af21-032b3eff0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_solutions(label, solvers) -> int:\n",
    "    saved_count = 0\n",
    "    solver_texts = set([solver.function_text.replace(solver.name, 'solve', 1) for solver in solvers])\n",
    "    existing_solvers = \"\"\n",
    "    try:\n",
    "        with open(f\"solvers generated/{label}.py\", \"r\") as f:\n",
    "            existing_solvers = f.read()\n",
    "    except:\n",
    "        pass # File didn't open, probably because it doesn't exist\n",
    "    for solver_text in solver_texts:\n",
    "        if solver_text not in existing_solvers:\n",
    "            with open(f\"solvers generated/{label}.py\", \"a\") as f:\n",
    "                f.write(solver_text + \"\\n\\n\\n\")\n",
    "                saved_count += 1\n",
    "    if saved_count > 0:\n",
    "        print(\"New solver found\")\n",
    "    return saved_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32084ce5-2152-4040-955c-897111b12cca",
   "metadata": {},
   "source": [
    "# Generate solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e811653f-52a6-44f7-820b-e3155d29eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_docstring(solver_text):\n",
    "    S = solver_text.split('    \"\"\"\\n', 2)\n",
    "    if len(S) == 1:\n",
    "        return S[0]\n",
    "    else:\n",
    "        return S[0] + S[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced39f89-4d78-45ba-9212-cf6ecc7f7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0d4d94-3b15-4bd8-9ac9-4c1f536efcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bb5f120c5f4efab4c79b0f4131c7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New solver found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m candidates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_new_tokens, num_beams \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m16\u001b[39m), (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m8\u001b[39m), (\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m2\u001b[39m)]:\n\u001b[0;32m---> 14\u001b[0m     candidates\u001b[38;5;241m.\u001b[39mextend(\u001b[43mmemory_safe_beam_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcodegen_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mgenerate_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_beams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_return_sequences\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m failed, cleaned \u001b[38;5;241m=\u001b[39m clean_candidates(candidates)\n\u001b[1;32m     25\u001b[0m results\u001b[38;5;241m.\u001b[39mextend([(\u001b[38;5;241m1.1\u001b[39m, F) \u001b[38;5;28;01mfor\u001b[39;00m F \u001b[38;5;129;01min\u001b[39;00m failed])\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mmemory_safe_beam_generate\u001b[0;34m(model, tokenizer, inputs, generate_args)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mOutOfMemoryError:\n\u001b[1;32m     21\u001b[0m         generate_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_beams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_beams\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/transformers/generation/utils.py:2063\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2056\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2057\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2058\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2059\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2060\u001b[0m     )\n\u001b[1;32m   2062\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2063\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2077\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2078\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2084\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2085\u001b[0m     )\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/transformers/generation/utils.py:3238\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 3238\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3241\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:667\u001b[0m, in \u001b[0;36mCodeGenForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    665\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 667\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# make sure sampling in fp16 works correctly and\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# compute loss in fp32 to match with mesh-tf version\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# https://github.com/EleutherAI/gpt-neo/blob/89ce74164da2fb16179106f54e2269b5da8db333/models/gpt2/gpt2.py#L179\u001b[39;00m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:536\u001b[0m, in \u001b[0;36mCodeGenModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    526\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    527\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m         output_attentions,\n\u001b[1;32m    534\u001b[0m     )\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/installs/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_results = {}\n",
    "NEW_SOLVERS_COUNT = 0\n",
    "genargs_log = []\n",
    "\n",
    "for i, label in enumerate(tqdm(eval_task_labels)):\n",
    "    pairs = eval_tasks[label]['train']\n",
    "    prompts = create_prompts_from_pairs(pairs, len(pairs))\n",
    "    results = []\n",
    "\n",
    "    tokens = [codegen_tokenizer(prompt, padding = True, return_tensors = 'pt').to(DEVICE) for prompt in prompts]\n",
    "\n",
    "    candidates = []\n",
    "    for max_new_tokens, num_beams in [(64, 32), (128, 16), (256, 8), (384, 4), (512, 4), (640, 4), (768, 4), (1024, 2)]:\n",
    "        candidates.extend(memory_safe_beam_generate(codegen,\n",
    "                                  codegen_tokenizer,\n",
    "                                  prompts,\n",
    "                                  generate_args = {\n",
    "                                        'max_new_tokens': max_new_tokens,\n",
    "                                        'num_beams': num_beams,\n",
    "                                        'num_return_sequences': num_beams,\n",
    "                                    },\n",
    "                                 ))\n",
    "\n",
    "    failed, cleaned = clean_candidates(candidates)\n",
    "    results.extend([(1.1, F) for F in failed])\n",
    "\n",
    "    failed, compiled = compile_candidates(cleaned)\n",
    "    results.extend([(1.1, F) for F in failed])\n",
    "\n",
    "    scored = score_solvers_vs_tasks(compiled, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "    results.extend(scored)\n",
    "\n",
    "    results = sorted(results, key = lambda x: x[0])\n",
    "    \n",
    "    full_results[label] = list(set([(score, remove_docstring(str(solver))) for score, solver in results]))\n",
    "\n",
    "    # Save any solvers that fully succeeded\n",
    "    idx = 0\n",
    "    to_save = []\n",
    "    while idx < len(results) and results[idx][0] == 0:\n",
    "        to_save.append(results[idx][1])\n",
    "        idx += 1\n",
    "    if len(to_save) > 0:\n",
    "        NEW_SOLVERS_COUNT += save_solutions(label, to_save)\n",
    "    \n",
    "    # Save every 10 tasks\n",
    "    if (i+1)%10 == 0:\n",
    "        with open('beam2.json', 'w') as f:\n",
    "            f.seek(0)\n",
    "            json.dump(full_results, f, indent = 4)\n",
    "\n",
    "\n",
    "with open('beam2.json', 'w') as f:\n",
    "    f.seek(0)\n",
    "    json.dump(full_results, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80469a5f-510b-4e89-8ce9-48272f7a6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(NEW_SOLVERS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf208e-1767-45db-90d8-edbe7d0a5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(genargs_log).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ba720-5684-470d-95a5-48e0d11a2fbf",
   "metadata": {},
   "source": [
    "# Scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4179241e-563f-44d7-8d95-39533eccd213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    1348\n",
       "64       9\n",
       "32       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(beam_log).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1811feb6-b5c5-4678-9035-286b13181196",
   "metadata": {},
   "source": [
    "NOTES:\n",
    " * Using top_p = 0.9, temp = 1.5 instead of top_k narrows results down to things that actually compile and speeds up computation. Generally top_p seems better than top_k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f9a419-f6e0-4a1e-b14a-2d00ddd53215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48f8583b\n"
     ]
    }
   ],
   "source": [
    "test_label = '48f8583b'\n",
    "label = test_label\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "586f1b04-90ab-4147-b852-2a128605d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = eval_tasks[label]['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "59391c12-43ab-4674-9973-7a744b7b4c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "05a05276-4018-49ce-9adb-7e8344fd0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SOLVERS_COUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b4cb49a6-c015-4560-9ac2-48ad1cf4daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = create_prompts_from_pairs(pairs, len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e36d7663-c342-4394-9eff-1477edef7d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "85295bc9-74d5-4788-9166-b1d9f4f33c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [codegen_tokenizer(prompt, padding = True, return_tensors = 'pt').to(DEVICE) for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bc8071c0-36e5-4a36-b205-72927aeef401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 seconds with 32 beams and 768 new tokens, no OOM\n",
    "# 15 seconds with 32 beams and 512 new tokens, no OOM\n",
    "# 192 seconds with 32 beams and 512 new tokens and low_memory = True\n",
    "# \n",
    "# Weirdly, temp 5.0 resulted in more compiled solvers and lower scores..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8040ed46-1758-463c-812a-f783895c3265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d44c5e29d2445fd9864d3729e691f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "configs = [(32, 512), (64, 256), (16, 1024)]\n",
    "full_results = {}\n",
    "\n",
    "for NUM_BEAMS, MAX_NEW_TOKENS in tqdm(configs):\n",
    "    generate_args = {\n",
    "        'max_new_tokens': MAX_NEW_TOKENS,\n",
    "        'num_beams': NUM_BEAMS,\n",
    "        'num_return_sequences': NUM_BEAMS,\n",
    "        'do_sample': True,\n",
    "        'temperature': 2.0,\n",
    "        #'low_memory': True # WAY TOO SLOW\n",
    "    }\n",
    "    results = []\n",
    "    candidates = []\n",
    "    for t in tokens:\n",
    "        outputs = []\n",
    "        try:\n",
    "            outputs = codegen.generate(**t,\n",
    "                     pad_token_id = codegen_tokenizer.pad_token_id,\n",
    "                    **generate_args,\n",
    "                    )\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(\"OOM\")\n",
    "        candidates.extend(codegen_tokenizer.batch_decode(outputs, skip_special_tokens = True))\n",
    "\n",
    "    failed, cleaned = clean_candidates(candidates)\n",
    "    results.extend([(1.1, F) for F in failed])\n",
    "\n",
    "    failed, compiled = compile_candidates(cleaned)\n",
    "    results.extend([(1.1, F) for F in failed])\n",
    "\n",
    "    scored = score_solvers_vs_tasks(compiled, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "    results.extend(scored)\n",
    "\n",
    "    full_results[(NUM_BEAMS, MAX_NEW_TOKENS)] = sorted(results, key = lambda x: x[0])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580c367-32f0-4de1-91c9-7e2488393cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a35786b0-679a-4622-8891-edb7292a22aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n",
      "0.276010101010101 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    717\n",
      "    177\n",
      "    717\n",
      "    OUTPUT:\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    717000000\n",
      "    177000000\n",
      "    717000000\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    \"\"\"\n",
      "    x1 = ofcolor(I, ONE)\n",
      "    x2 = shape(I)\n",
      "    x3 = multiply(x2, x2)\n",
      "    x4 = canvas(ZERO, x3)\n",
      "    x5 = rbind(multiply, x2)\n",
      "    x6 = apply(x5, x1)\n",
      "    x7 = asobject(I)\n",
      "    x8 = lbind(shift, x7)\n",
      "    x9 = mapply(x8, x6)\n",
      "    O = paint(x4, x9)\n",
      "    return O\n",
      "\n",
      "(64, 256)\n",
      "0.0 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    717\n",
      "    177\n",
      "    717\n",
      "    OUTPUT:\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    717000000\n",
      "    177000000\n",
      "    717000000\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    \"\"\"\n",
      "    x1 = leastcolor(I)\n",
      "    x2 = ofcolor(I, x1)\n",
      "    x3 = shape(I)\n",
      "    x4 = multiply(x3, x3)\n",
      "    x5 = canvas(ZERO, x4)\n",
      "    x6 = rbind(multiply, x3)\n",
      "    x7 = apply(x6, x2)\n",
      "    x8 = asobject(I)\n",
      "    x9 = lbind(shift, x8)\n",
      "    x10 = mapply(x9, x7)\n",
      "    O = paint(x5, x10)\n",
      "    return O\n",
      "\n",
      "(16, 1024)\n",
      "0.361025641025641 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    996\n",
      "    388\n",
      "    833\n",
      "    OUTPUT:\n",
      "    000000996\n",
      "    000000388\n",
      "    000000833\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    \"\"\"\n",
      "    x1 = shape(I)\n",
      "    x2 = multiply(x1, x1)\n",
      "    x3 = canvas(ZERO, x2)\n",
      "    x4 = mostcolor(I)\n",
      "    x5 = ofcolor(I, x4)\n",
      "    x6 = lbind(multiply, x1)\n",
      "    x7 = apply(x6, x5)\n",
      "    x8 = asobject(I)\n",
      "    x9 = lbind(shift, x8)\n",
      "    x10 = mapply(x9, x7)\n",
      "    O = paint(x3, x10)\n",
      "    return O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, results in full_results.items():\n",
    "    print(key)\n",
    "    print(results[0][0], results[0][1])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405b9be-8106-4084-8e82-464f1efda62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0461cd9-ff3d-410a-9bff-c89fe584678e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28bae4bf-0abe-4997-9e54-290c0fa7cc53",
   "metadata": {},
   "source": [
    "<code>generate_args = {\n",
    "        'max_new_tokens': MAX_NEW_TOKENS,\n",
    "        'num_beams': NUM_BEAMS,\n",
    "        'num_return_sequences': NUM_BEAMS,\n",
    "        #'do_sample': True,\n",
    "        #'temperature': 3.0,\n",
    "        #'low_memory': True # WAY TOO SLOW\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0a9f1ef9-5108-4b51-9f5d-bfc81e11595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n",
      "0.276010101010101 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    717\n",
      "    177\n",
      "    717\n",
      "    OUTPUT:\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    717000000\n",
      "    177000000\n",
      "    717000000\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    \"\"\"\n",
      "    x1 = ofcolor(I, ONE)\n",
      "    x2 = shape(I)\n",
      "    x3 = multiply(x2, x2)\n",
      "    x4 = canvas(ZERO, x3)\n",
      "    x5 = rbind(multiply, x2)\n",
      "    x6 = apply(x5, x1)\n",
      "    x7 = asobject(I)\n",
      "    x8 = lbind(shift, x7)\n",
      "    x9 = mapply(x8, x6)\n",
      "    O = paint(x4, x9)\n",
      "    return O\n",
      "\n",
      "(64, 256)\n",
      "0.0 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    717\n",
      "    177\n",
      "    717\n",
      "    OUTPUT:\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    717000000\n",
      "    177000000\n",
      "    717000000\n",
      "    000717000\n",
      "    000177000\n",
      "    000717000\n",
      "    \"\"\"\n",
      "    x1 = leastcolor(I)\n",
      "    x2 = ofcolor(I, x1)\n",
      "    x3 = shape(I)\n",
      "    x4 = multiply(x3, x3)\n",
      "    x5 = canvas(ZERO, x4)\n",
      "    x6 = rbind(multiply, x3)\n",
      "    x7 = apply(x6, x2)\n",
      "    x8 = asobject(I)\n",
      "    x9 = lbind(shift, x8)\n",
      "    x10 = mapply(x9, x7)\n",
      "    O = paint(x5, x10)\n",
      "    return O\n",
      "\n",
      "(16, 1024)\n",
      "0.361025641025641 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    996\n",
      "    388\n",
      "    833\n",
      "    OUTPUT:\n",
      "    000000996\n",
      "    000000388\n",
      "    000000833\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    \"\"\"\n",
      "    x1 = shape(I)\n",
      "    x2 = multiply(x1, x1)\n",
      "    x3 = canvas(ZERO, x2)\n",
      "    x4 = mostcolor(I)\n",
      "    x5 = ofcolor(I, x4)\n",
      "    x6 = lbind(multiply, x1)\n",
      "    x7 = apply(x6, x5)\n",
      "    x8 = asobject(I)\n",
      "    x9 = lbind(shift, x8)\n",
      "    x10 = mapply(x9, x7)\n",
      "    O = paint(x3, x10)\n",
      "    return O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, results in full_results.items():\n",
    "    print(key)\n",
    "    print(results[0][0], results[0][1])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735c462-bba2-42c3-886b-7001744d0e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5e533068-1e02-4c2a-a7c6-5ee837abd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.32 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "try:\n",
    "    outputs = codegen.generate(**tokens[0],\n",
    "                     pad_token_id = codegen_tokenizer.pad_token_id,\n",
    "                    **generate_args,\n",
    "                    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    print(\"OOM\")\n",
    "print(f\"{time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fde3afa7-cd2a-4dba-b157-251dee40e987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "candidates = codegen_tokenizer.batch_decode(outputs, skip_special_tokens = True)\n",
    "print(len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "13436df3-71d9-4b4f-bd58-a5f0749dd928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "failed1, cleaned = clean_candidates(candidates)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ab98e772-d3b3-476c-876b-a371ac013658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "failed2, compiled = compile_candidates(cleaned)\n",
    "print(len(compiled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a224d707-7f87-467a-b5f2-9ec302986131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[0.3239538982502369, 0.3391996891996892, 0.361025641025641, 0.361025641025641, 0.4003108003108003, 0.4186868686868687, 0.4585714285714286, 0.4593245640097597, 0.46058648192693497, 0.4626586983363246, 0.480519978106185, 0.480519978106185, 0.4814417895672325, 0.5378794364187622, 0.6142857142857142, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "scored = score_solvers_vs_tasks(compiled, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "scored = sorted(scored, key = lambda x: x[0])\n",
    "print(sum([score < 1.0 for score, _ in scored]))\n",
    "print([score for score, _ in scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "89973e86-bf31-47fd-8b66-c8bf02309fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.361025641025641 def solve(I):\n",
      "    \"\"\"\n",
      "    INPUT:\n",
      "    996\n",
      "    388\n",
      "    833\n",
      "    OUTPUT:\n",
      "    000000996\n",
      "    000000388\n",
      "    000000833\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    000000000\n",
      "    \"\"\"\n",
      "    x1 = shape(I)\n",
      "    x2 = multiply(x1, x1)\n",
      "    x3 = canvas(ZERO, x2)\n",
      "    x4 = mostcolor(I)\n",
      "    x5 = ofcolor(I, x4)\n",
      "    x6 = lbind(multiply, x1)\n",
      "    x7 = apply(x6, x5)\n",
      "    x8 = asobject(I)\n",
      "    x9 = lbind(shift, x8)\n",
      "    x10 = mapply(x9, x7)\n",
      "    O = paint(x3, x10)\n",
      "    return O\n"
     ]
    }
   ],
   "source": [
    "print(scored[0][0], scored[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff73042-05f2-4009-a0b0-c1a104d047da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
