{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f48cf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchsummary # 모델 구조 보기좋게 출력\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "from torchvision.utils import *\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b494e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device 세팅\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0529676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8980f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.00 GiB total capacity; 9.29 GiB already allocated; 0 bytes free; 9.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mtorchvision.models 에서 여러 모델 로드 가능\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mpretrained weight도 다운 가능\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m pretrained_weight \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mResNet50_Weights\u001b[38;5;241m.\u001b[39mIMAGENET1K_V2\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpretrained_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m torchsummary\u001b[38;5;241m.\u001b[39msummary(model, (\u001b[38;5;241m3\u001b[39m, size[\u001b[38;5;241m0\u001b[39m], size[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 639 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:985\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.00 GiB total capacity; 9.29 GiB already allocated; 0 bytes free; 9.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 모델 로드 및 출력\n",
    "\"\"\"\n",
    "torchvision.models 에서 여러 모델 로드 가능\n",
    "pretrained weight도 다운 가능\n",
    "\"\"\"\n",
    "pretrained_weight = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "model = models.resnet50(weights = pretrained_weight).to(device)\n",
    "torchsummary.summary(model, (3, size[0], size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bca69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "1a4fe7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size),\n",
    "])\n",
    "imageNetDataSet1 = torchvision.datasets.ImageNet(test_path, split = \"val\", transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8f471394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "imageNetDataSet2 = torchvision.datasets.ImageNet(test_path, split = \"val\", transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "29c53a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "d279e34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imageNetDataSet1[idx][1])\n",
    "imageNetDataSet1[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b66f1180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "image = imageNetDataSet2[idx][0].to(device)\n",
    "print(image.shape)\n",
    "image = image[np.newaxis, :, :, :]\n",
    "print(image.shape)\n",
    "# print(image.shape)\n",
    "# image = (image/255-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "937d3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "7c4a941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(134, device='cuda:0')"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "ee15689a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pathlib.Path('./train').mkdir(parents = True, exist_ok=True)\n",
    "pathlib.Path('./test').mkdir(parents = True, exist_ok=True)\n",
    "\n",
    "train_dataset = torchvision.datasets.STL10('/train', split='train', download=True, transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.STL10('/test', split='test', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "d7c59a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "4ae37b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 4, 7, 6, 4, 9, 1, 1, 8, 0, 6, 9, 5, 2, 8, 1, 3, 9, 8, 1, 0, 6, 0,\n",
      "        4, 5, 1, 9, 0, 9, 1, 1, 6, 2, 1, 9, 1, 8, 2, 4, 6, 6, 9, 5, 7, 4, 2, 9,\n",
      "        3, 2, 8, 9, 7, 2, 0, 1, 4, 7, 1, 2, 0, 2, 6, 0, 3, 0, 5, 5, 5, 5, 2, 3,\n",
      "        7, 0, 3, 1, 7, 7, 4, 5, 9, 3, 4, 9, 8, 6, 1, 7, 4, 7, 0, 5, 1, 1, 1, 2,\n",
      "        8, 7, 0, 5, 8, 8, 9, 6, 0, 3, 2, 1, 8, 5, 5, 5, 1, 9, 5, 5, 9, 3, 4, 8,\n",
      "        8, 7, 4, 0, 3, 3, 0, 0])\n",
      "tensor([8, 1, 2, 8, 3, 1, 5, 5, 8, 0, 0, 9, 2, 5, 1, 3, 4, 6, 2, 1, 9, 5, 8, 3,\n",
      "        5, 2, 0, 8, 7, 1, 2, 0, 0, 1, 4, 8, 7, 5, 1, 3, 3, 8, 5, 9, 2, 1, 5, 6,\n",
      "        0, 8, 1, 0, 0, 0, 7, 3, 0, 0, 1, 0, 7, 3, 7, 7, 6, 5, 7, 8, 2, 1, 1, 4,\n",
      "        9, 4, 2, 2, 6, 8, 4, 9, 6, 6, 5, 0, 7, 9, 2, 3, 5, 2, 9, 5, 9, 6, 4, 2,\n",
      "        7, 0, 5, 6, 6, 4, 9, 2, 3, 0, 3, 3, 2, 2, 4, 2, 7, 3, 9, 9, 0, 0, 2, 1,\n",
      "        8, 3, 0, 1, 4, 7, 7, 9])\n",
      "tensor([8, 3, 7, 9, 2, 2, 8, 8, 2, 9, 7, 2, 2, 5, 1, 6, 0, 4, 8, 6, 6, 1, 6, 4,\n",
      "        3, 0, 2, 5, 9, 3, 5, 7, 9, 4, 2, 7, 9, 9, 4, 5, 0, 3, 4, 9, 6, 1, 3, 5,\n",
      "        3, 8, 0, 0, 3, 3, 3, 7, 8, 6, 4, 2, 1, 0, 2, 7, 2, 5, 8, 2, 5, 2, 3, 1,\n",
      "        8, 3, 9, 3, 9, 4, 7, 1, 8, 6, 6, 3, 9, 0, 4, 1, 7, 3, 3, 1, 5, 9, 9, 2,\n",
      "        2, 7, 0, 2, 4, 9, 3, 6, 2, 5, 6, 7, 4, 1, 3, 1, 0, 1, 8, 4, 2, 4, 6, 9,\n",
      "        0, 6, 1, 3, 1, 8, 2, 8])\n",
      "tensor([7, 9, 2, 0, 9, 6, 1, 8, 0, 3, 4, 9, 6, 1, 4, 3, 3, 7, 7, 7, 4, 4, 7, 4,\n",
      "        9, 9, 8, 3, 9, 5, 5, 0, 9, 9, 1, 2, 6, 9, 3, 5, 0, 9, 0, 9, 5, 0, 3, 4,\n",
      "        0, 0, 6, 8, 8, 5, 4, 3, 4, 6, 7, 0, 3, 6, 8, 8, 9, 9, 4, 8, 8, 6, 1, 8,\n",
      "        3, 1, 4, 5, 7, 5, 4, 6, 6, 2, 1, 3, 0, 0, 2, 7, 2, 7, 5, 0, 6, 0, 9, 9,\n",
      "        8, 5, 6, 3, 4, 6, 1, 8, 8, 9, 3, 6, 3, 2, 9, 4, 9, 6, 6, 8, 4, 7, 9, 4,\n",
      "        7, 2, 8, 0, 9, 8, 5, 9])\n",
      "tensor([3, 4, 7, 6, 5, 0, 3, 4, 7, 2, 9, 5, 4, 4, 1, 9, 9, 7, 7, 3, 8, 3, 4, 3,\n",
      "        4, 2, 7, 2, 6, 6, 0, 8, 0, 2, 4, 9, 1, 3, 5, 8, 2, 5, 3, 4, 8, 2, 0, 0,\n",
      "        3, 2, 3, 5, 8, 6, 4, 9, 5, 2, 7, 2, 1, 0, 0, 6, 6, 8, 6, 9, 5, 5, 3, 9,\n",
      "        2, 8, 2, 4, 4, 2, 0, 1, 2, 4, 0, 9, 6, 5, 5, 5, 8, 8, 1, 1, 4, 6, 2, 0,\n",
      "        4, 5, 2, 8, 4, 7, 6, 9, 0, 7, 5, 9, 8, 8, 7, 9, 3, 9, 9, 8, 9, 2, 3, 0,\n",
      "        8, 4, 2, 1, 6, 5, 7, 7])\n",
      "tensor([5, 6, 2, 0, 2, 0, 2, 2, 3, 5, 5, 7, 6, 8, 1, 9, 1, 2, 6, 3, 9, 1, 0, 6,\n",
      "        5, 6, 6, 0, 9, 6, 6, 5, 0, 6, 5, 5, 0, 1, 4, 4, 0, 8, 4, 7, 5, 3, 2, 5,\n",
      "        8, 3, 7, 7, 5, 7, 8, 5, 3, 4, 3, 0, 4, 1, 4, 2, 3, 6, 3, 3, 9, 5, 9, 4,\n",
      "        8, 9, 1, 2, 7, 5, 6, 8, 8, 6, 5, 1, 7, 2, 7, 6, 9, 7, 4, 8, 2, 7, 0, 5,\n",
      "        3, 7, 4, 7, 5, 4, 3, 3, 9, 7, 8, 3, 3, 7, 7, 4, 5, 3, 2, 7, 8, 8, 3, 7,\n",
      "        0, 1, 9, 3, 1, 3, 1, 2])\n",
      "tensor([2, 9, 0, 1, 8, 2, 4, 7, 3, 6, 8, 7, 0, 4, 0, 9, 0, 3, 7, 2, 1, 7, 6, 2,\n",
      "        9, 1, 9, 3, 5, 0, 4, 5, 8, 5, 4, 1, 8, 8, 5, 7, 0, 4, 8, 0, 2, 1, 7, 7,\n",
      "        0, 0, 1, 8, 8, 4, 1, 1, 4, 5, 8, 9, 8, 3, 1, 0, 8, 3, 8, 1, 5, 2, 0, 7,\n",
      "        8, 0, 2, 5, 2, 7, 0, 7, 7, 3, 5, 5, 6, 3, 2, 1, 8, 4, 5, 7, 5, 9, 3, 6,\n",
      "        5, 3, 4, 3, 0, 8, 4, 4, 1, 4, 5, 9, 8, 1, 1, 9, 0, 1, 2, 6, 4, 5, 9, 3,\n",
      "        5, 9, 0, 2, 4, 3, 9, 8])\n",
      "tensor([4, 7, 6, 1, 5, 2, 9, 7, 4, 5, 5, 0, 2, 5, 7, 8, 1, 2, 8, 3, 5, 7, 1, 5,\n",
      "        0, 2, 2, 9, 7, 6, 6, 0, 4, 4, 5, 2, 3, 5, 9, 9, 1, 4, 5, 1, 3, 7, 4, 0,\n",
      "        1, 3, 2, 9, 0, 5, 3, 1, 0, 1, 2, 5, 2, 8, 2, 6, 1, 0, 1, 2, 2, 2, 1, 2,\n",
      "        8, 5, 8, 7, 2, 0, 5, 5, 2, 4, 0, 4, 9, 0, 9, 0, 5, 8, 4, 5, 9, 9, 2, 2,\n",
      "        8, 7, 9, 3, 9, 7, 2, 4, 0, 0, 3, 7, 8, 0, 7, 5, 1, 9, 1, 9, 3, 4, 9, 1,\n",
      "        6, 8, 3, 0, 4, 5, 8, 2])\n",
      "tensor([6, 4, 0, 5, 3, 6, 3, 1, 8, 3, 4, 5, 9, 6, 1, 2, 1, 3, 9, 0, 1, 2, 2, 7,\n",
      "        8, 6, 2, 0, 9, 5, 3, 8, 7, 6, 9, 8, 0, 1, 5, 4, 8, 9, 6, 7, 5, 0, 7, 0,\n",
      "        7, 4, 0, 5, 7, 1, 6, 3, 5, 9, 8, 1, 3, 7, 6, 5, 8, 1, 9, 0, 7, 0, 9, 9,\n",
      "        0, 3, 2, 7, 5, 7, 1, 7, 1, 9, 3, 4, 4, 8, 9, 5, 5, 9, 0, 4, 9, 4, 6, 1,\n",
      "        9, 6, 0, 9, 8, 7, 0, 8, 5, 6, 6, 2, 7, 8, 4, 5, 2, 6, 8, 1, 4, 5, 7, 9,\n",
      "        1, 6, 2, 3, 1, 8, 4, 1])\n",
      "tensor([2, 1, 6, 3, 1, 8, 5, 6, 5, 4, 2, 4, 7, 1, 9, 6, 5, 2, 2, 0, 2, 2, 6, 9,\n",
      "        6, 0, 3, 9, 0, 0, 4, 0, 1, 8, 1, 3, 7, 6, 2, 6, 8, 6, 4, 7, 0, 2, 7, 8,\n",
      "        7, 9, 1, 5, 2, 3, 0, 3, 6, 0, 4, 5, 0, 9, 8, 4, 4, 4, 4, 0, 0, 3, 0, 0,\n",
      "        0, 6, 8, 5, 4, 0, 3, 5, 7, 4, 3, 9, 5, 1, 0, 3, 2, 4, 6, 3, 3, 3, 1, 3,\n",
      "        8, 4, 0, 3, 9, 9, 1, 2, 6, 4, 7, 4, 1, 7, 5, 4, 4, 7, 4, 1, 8, 2, 1, 9,\n",
      "        9, 6, 9, 1, 1, 6, 3, 2])\n",
      "tensor([4, 3, 2, 5, 1, 9, 6, 4, 0, 5, 3, 9, 3, 1, 0, 6, 2, 8, 8, 9, 3, 5, 4, 5,\n",
      "        7, 0, 3, 3, 8, 9, 2, 8, 0, 8, 5, 7, 9, 3, 5, 5, 3, 1, 4, 8, 8, 1, 9, 2,\n",
      "        9, 2, 5, 9, 7, 7, 1, 5, 7, 3, 3, 5, 7, 9, 7, 1, 2, 7, 3, 2, 8, 7, 8, 8,\n",
      "        3, 1, 1, 6, 7, 5, 9, 2, 7, 2, 8, 6, 7, 3, 4, 3, 0, 6, 6, 3, 2, 4, 1, 4,\n",
      "        8, 9, 4, 9, 3, 3, 3, 4, 0, 3, 3, 4, 9, 2, 5, 4, 2, 0, 1, 0, 1, 0, 4, 0,\n",
      "        5, 1, 2, 9, 8, 7, 4, 4])\n",
      "tensor([9, 6, 2, 8, 0, 8, 0, 9, 4, 2, 5, 2, 6, 2, 7, 2, 7, 8, 4, 8, 3, 3, 5, 8,\n",
      "        2, 9, 3, 6, 1, 3, 9, 6, 0, 8, 2, 9, 2, 9, 3, 8, 9, 4, 5, 2, 2, 3, 6, 5,\n",
      "        2, 6, 8, 7, 8, 2, 5, 5, 0, 2, 5, 8, 0, 2, 6, 0, 1, 0, 2, 8, 5, 6, 2, 0,\n",
      "        9, 1, 8, 2, 8, 0, 9, 2, 1, 9, 8, 7, 6, 4, 5, 4, 2, 5, 1, 2, 4, 6, 9, 4,\n",
      "        8, 8, 2, 7, 3, 3, 3, 5, 2, 9, 0, 9, 5, 9, 3, 0, 7, 2, 2, 6, 7, 2, 3, 7,\n",
      "        1, 2, 6, 8, 4, 1, 1, 3])\n",
      "tensor([2, 3, 7, 2, 7, 8, 8, 9, 6, 3, 1, 8, 0, 8, 9, 7, 0, 1, 3, 9, 8, 5, 6, 3,\n",
      "        9, 1, 8, 6, 9, 1, 8, 6, 5, 6, 9, 4, 8, 0, 1, 3, 7, 6, 1, 3, 4, 1, 2, 0,\n",
      "        7, 3, 8, 5, 3, 4, 4, 5, 3, 4, 8, 9, 3, 1, 9, 1, 2, 8, 0, 3, 3, 1, 5, 8,\n",
      "        4, 9, 8, 4, 8, 0, 7, 1, 9, 4, 1, 1, 2, 8, 3, 6, 7, 7, 3, 7, 6, 2, 2, 5,\n",
      "        3, 6, 8, 6, 6, 9, 1, 0, 6, 7, 6, 2, 6, 2, 5, 6, 1, 9, 8, 1, 2, 7, 2, 6,\n",
      "        9, 3, 6, 8, 5, 8, 7, 5])\n",
      "tensor([9, 3, 9, 4, 9, 4, 5, 6, 9, 2, 9, 3, 5, 5, 7, 6, 5, 9, 1, 4, 5, 6, 9, 0,\n",
      "        6, 6, 1, 6, 5, 2, 4, 9, 9, 3, 5, 7, 7, 9, 6, 0, 4, 7, 8, 7, 5, 1, 3, 1,\n",
      "        4, 3, 8, 0, 1, 5, 9, 8, 6, 5, 7, 2, 1, 8, 3, 2, 1, 7, 3, 9, 4, 6, 4, 8,\n",
      "        5, 0, 2, 2, 0, 3, 5, 9, 7, 6, 4, 2, 1, 0, 1, 3, 4, 0, 6, 9, 5, 4, 1, 1,\n",
      "        2, 1, 1, 0, 2, 5, 3, 6, 3, 5, 0, 1, 3, 0, 1, 8, 9, 8, 2, 5, 4, 5, 5, 0,\n",
      "        9, 1, 0, 7, 2, 0, 8, 7])\n",
      "tensor([7, 0, 4, 3, 6, 1, 0, 5, 7, 5, 7, 4, 7, 5, 8, 6, 4, 1, 3, 3, 4, 5, 1, 1,\n",
      "        6, 5, 3, 2, 1, 4, 0, 6, 0, 7, 4, 3, 7, 4, 8, 8, 0, 8, 9, 9, 5, 1, 2, 0,\n",
      "        7, 9, 2, 4, 9, 6, 9, 0, 8, 2, 8, 8, 8, 1, 0, 0, 6, 4, 9, 5, 7, 9, 5, 2,\n",
      "        0, 9, 4, 1, 2, 5, 8, 7, 2, 9, 2, 0, 6, 2, 7, 6, 8, 8, 5, 4, 8, 5, 2, 7,\n",
      "        8, 3, 2, 8, 3, 6, 2, 9, 0, 5, 7, 5, 4, 0, 8, 0, 0, 6, 1, 2, 8, 0, 9, 7,\n",
      "        0, 7, 8, 6, 4, 0, 9, 3])\n",
      "tensor([7, 5, 7, 7, 0, 5, 3, 9, 8, 2, 3, 9, 5, 4, 1, 6, 4, 3, 9, 7, 5, 2, 4, 5,\n",
      "        4, 7, 5, 5, 5, 9, 4, 3, 6, 3, 8, 8, 5, 0, 1, 0, 5, 8, 1, 6, 3, 1, 9, 5,\n",
      "        9, 5, 5, 2, 1, 0, 0, 4, 7, 8, 4, 1, 7, 7, 9, 4, 3, 1, 5, 8, 0, 8, 1, 7,\n",
      "        1, 1, 4, 2, 2, 3, 7, 6, 7, 6, 4, 9, 9, 9, 1, 4, 4, 2, 8, 1, 4, 2, 3, 7,\n",
      "        4, 1, 6, 6, 2, 6, 9, 2, 9, 1, 4, 6, 5, 5, 2, 7, 0, 6, 7, 2, 6, 6, 7, 0,\n",
      "        4, 1, 4, 9, 0, 3, 3, 7])\n",
      "tensor([3, 6, 4, 8, 3, 6, 6, 4, 0, 8, 2, 4, 5, 7, 7, 3, 7, 1, 8, 6, 3, 2, 8, 3,\n",
      "        1, 4, 0, 3, 3, 5, 6, 1, 7, 2, 2, 7, 2, 8, 3, 0, 2, 1, 5, 1, 3, 0, 5, 1,\n",
      "        8, 0, 1, 0, 0, 9, 2, 5, 5, 7, 1, 0, 2, 6, 1, 9, 1, 1, 0, 4, 5, 0, 5, 5,\n",
      "        3, 7, 7, 5, 5, 0, 8, 9, 6, 1, 1, 1, 0, 9, 2, 6, 3, 4, 2, 4, 5, 4, 7, 6,\n",
      "        5, 6, 3, 1, 5, 9, 8, 7, 3, 6, 6, 0, 3, 2, 6, 4, 6, 7, 4, 0, 0, 5, 1, 0,\n",
      "        0, 9, 2, 2, 3, 3, 3, 8])\n",
      "tensor([7, 4, 7, 6, 2, 6, 1, 4, 7, 2, 6, 2, 1, 9, 9, 4, 9, 1, 7, 6, 7, 9, 8, 1,\n",
      "        2, 3, 3, 8, 6, 0, 2, 8, 9, 7, 5, 1, 8, 4, 4, 5, 4, 2, 2, 6, 4, 7, 5, 5,\n",
      "        6, 6, 7, 4, 6, 2, 6, 5, 2, 4, 4, 7, 9, 1, 9, 1, 5, 6, 0, 8, 9, 0, 6, 2,\n",
      "        5, 7, 8, 8, 9, 4, 1, 0, 0, 8, 8, 2, 3, 2, 4, 5, 0, 2, 1, 6, 9, 6, 3, 2,\n",
      "        6, 0, 4, 1, 5, 2, 8, 7, 7, 1, 2, 5, 3, 9, 2, 0, 9, 7, 7, 4, 9, 0, 2, 5,\n",
      "        4, 9, 9, 0, 7, 9, 0, 1])\n",
      "tensor([5, 1, 6, 0, 6, 0, 8, 9, 6, 8, 2, 6, 7, 5, 5, 8, 9, 0, 5, 0, 5, 2, 0, 1,\n",
      "        9, 8, 8, 6, 9, 7, 4, 9, 1, 1, 5, 1, 7, 2, 6, 4, 7, 7, 8, 1, 2, 8, 0, 9,\n",
      "        0, 2, 7, 6, 7, 6, 1, 1, 6, 4, 5, 7, 2, 3, 7, 8, 9, 3, 8, 2, 8, 1, 0, 4,\n",
      "        6, 5, 1, 4, 0, 3, 7, 9, 2, 7, 4, 0, 6, 7, 8, 1, 8, 4, 4, 7, 6, 2, 5, 4,\n",
      "        6, 5, 0, 1, 6, 4, 1, 0, 0, 8, 3, 4, 2, 0, 9, 3, 2, 7, 2, 4, 9, 7, 4, 9,\n",
      "        8, 3, 0, 6, 6, 0, 5, 9])\n",
      "tensor([8, 0, 2, 8, 0, 4, 5, 2, 4, 9, 0, 0, 0, 8, 0, 9, 0, 1, 2, 8, 1, 5, 9, 5,\n",
      "        3, 3, 3, 9, 8, 6, 6, 1, 4, 9, 8, 0, 6, 4, 5, 0, 9, 9, 8, 5, 1, 9, 3, 6,\n",
      "        6, 6, 4, 5, 4, 7, 9, 9, 6, 8, 3, 6, 6, 9, 8, 4, 8, 7, 6, 3, 6, 6, 1, 8,\n",
      "        3, 8, 3, 1, 2, 4, 9, 3, 6, 9, 0, 4, 3, 2, 3, 1, 7, 0, 9, 2, 5, 4, 7, 9,\n",
      "        6, 6, 6, 5, 2, 4, 7, 1, 9, 3, 3, 3, 5, 1, 6, 1, 7, 8, 0, 8, 7, 0, 4, 9,\n",
      "        8, 5, 7, 9, 9, 4, 7, 7])\n",
      "tensor([8, 6, 2, 3, 4, 9, 6, 8, 4, 0, 1, 9, 5, 6, 1, 3, 5, 3, 9, 5, 4, 1, 3, 7,\n",
      "        5, 9, 3, 2, 6, 6, 7, 9, 3, 4, 1, 7, 8, 7, 6, 7, 5, 4, 0, 8, 3, 8, 3, 5,\n",
      "        3, 6, 8, 0, 8, 9, 5, 9, 4, 0, 0, 8, 5, 2, 3, 7, 3, 9, 6, 0, 4, 5, 6, 7,\n",
      "        1, 7, 3, 4, 3, 6, 9, 7, 5, 7, 7, 6, 3, 9, 0, 7, 8, 3, 3, 4, 5, 4, 1, 1,\n",
      "        6, 0, 4, 7, 7, 0, 8, 6, 5, 3, 4, 1, 3, 3, 2, 8, 8, 5, 4, 3, 0, 2, 0, 5,\n",
      "        6, 2, 4, 7, 8, 1, 6, 4])\n",
      "tensor([4, 9, 0, 7, 7, 0, 8, 1, 4, 3, 1, 0, 9, 2, 5, 0, 9, 8, 5, 3, 6, 0, 1, 7,\n",
      "        5, 8, 5, 5, 3, 6, 1, 9, 7, 1, 4, 2, 1, 7, 8, 6, 6, 0, 7, 9, 1, 4, 8, 6,\n",
      "        2, 5, 5, 8, 8, 7, 5, 5, 1, 5, 0, 5, 5, 8, 6, 2, 9, 7, 4, 8, 1, 8, 5, 1,\n",
      "        1, 6, 8, 6, 4, 3, 6, 1, 2, 4, 1, 4, 1, 8, 2, 1, 8, 0, 3, 2, 0, 4, 6, 4,\n",
      "        7, 1, 1, 5, 7, 7, 4, 3, 8, 5, 6, 7, 1, 7, 5, 6, 6, 6, 3, 2, 3, 5, 8, 9,\n",
      "        6, 3, 3, 6, 4, 8, 3, 4])\n",
      "tensor([8, 9, 3, 3, 1, 2, 4, 5, 4, 8, 3, 3, 7, 6, 0, 3, 4, 2, 1, 3, 6, 6, 1, 5,\n",
      "        0, 7, 1, 0, 2, 6, 2, 8, 7, 0, 8, 1, 8, 3, 7, 3, 8, 1, 4, 7, 4, 3, 8, 8,\n",
      "        4, 1, 3, 4, 9, 5, 9, 0, 5, 9, 9, 6, 9, 6, 7, 9, 3, 0, 3, 5, 0, 9, 7, 2,\n",
      "        5, 7, 4, 8, 7, 2, 6, 0, 4, 7, 2, 5, 7, 6, 6, 2, 8, 9, 2, 6, 4, 0, 6, 4,\n",
      "        6, 1, 3, 9, 3, 9, 7, 0, 6, 3, 1, 4, 2, 7, 4, 1, 1, 8, 2, 2, 7, 3, 1, 2,\n",
      "        3, 2, 9, 9, 8, 5, 1, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 7, 1, 7, 9, 4, 5, 1, 9, 3, 2, 1, 0, 0, 8, 3, 1, 3, 9, 4, 6, 1, 8, 9,\n",
      "        7, 9, 1, 2, 4, 5, 4, 0, 8, 7, 6, 6, 9, 8, 2, 4, 1, 7, 6, 6, 9, 1, 5, 6,\n",
      "        9, 3, 1, 8, 3, 3, 7, 3, 9, 6, 1, 6, 8, 1, 6, 7, 7, 7, 1, 1, 9, 7, 9, 1,\n",
      "        3, 0, 9, 6, 6, 2, 1, 5, 6, 4, 5, 9, 3, 9, 4, 4, 0, 6, 1, 1, 4, 8, 6, 1,\n",
      "        9, 4, 1, 4, 2, 2, 8, 2, 1, 2, 2, 3, 4, 1, 2, 9, 2, 5, 8, 8, 3, 8, 3, 2,\n",
      "        2, 1, 8, 3, 7, 5, 0, 6])\n",
      "tensor([5, 7, 5, 7, 9, 3, 8, 2, 5, 1, 9, 3, 5, 6, 0, 6, 8, 4, 4, 3, 9, 9, 9, 3,\n",
      "        5, 0, 3, 3, 6, 8, 3, 7, 8, 0, 4, 7, 5, 8, 4, 1, 5, 5, 6, 5, 5, 4, 2, 3,\n",
      "        7, 0, 3, 4, 3, 6, 5, 9, 3, 7, 4, 7, 2, 8, 9, 8, 8, 9, 0, 9, 9, 2, 8, 2,\n",
      "        3, 3, 2, 6, 7, 6, 0, 2, 4, 6, 6, 2, 7, 6, 7, 6, 7, 9, 8, 8, 0, 5, 2, 1,\n",
      "        2, 0, 7, 0, 1, 7, 8, 5, 8, 7, 3, 1, 4, 0, 7, 3, 6, 4, 7, 6, 2, 1, 9, 2,\n",
      "        8, 9, 6, 3, 0, 4, 8, 5])\n",
      "tensor([8, 1, 9, 4, 3, 9, 6, 7, 4, 8, 0, 2, 4, 1, 0, 3, 1, 1, 7, 0, 5, 3, 2, 2,\n",
      "        9, 2, 7, 2, 5, 8, 3, 9, 4, 8, 6, 6, 8, 5, 6, 8, 7, 8, 5, 9, 6, 5, 3, 0,\n",
      "        2, 3, 1, 8, 8, 5, 5, 6, 8, 3, 8, 5, 0, 0, 3, 2, 7, 7, 4, 0, 8, 6, 5, 6,\n",
      "        8, 9, 8, 2, 1, 3, 8, 7, 9, 0, 6, 6, 6, 9, 8, 1, 9, 4, 8, 6, 6, 9, 5, 2,\n",
      "        5, 9, 8, 8, 7, 3, 9, 5, 6, 2, 0, 3, 7, 0, 6, 1, 4, 7, 1, 2, 1, 9, 9, 0,\n",
      "        6, 3, 4, 9, 7, 4, 3, 1])\n",
      "tensor([5, 8, 5, 6, 9, 8, 6, 9, 5, 7, 0, 9, 0, 2, 0, 4, 5, 5, 7, 2, 4, 9, 1, 8,\n",
      "        0, 2, 1, 7, 2, 0, 0, 2, 0, 4, 1, 7, 1, 9, 9, 6, 4, 3, 3, 4, 9, 8, 4, 9,\n",
      "        9, 7, 7, 5, 7, 1, 0, 8, 4, 1, 7, 2, 4, 7, 3, 5, 4, 2, 5, 5, 9, 5, 4, 6,\n",
      "        4, 1, 5, 3, 9, 2, 5, 8, 1, 8, 8, 6, 1, 1, 1, 6, 8, 0, 7, 1, 1, 3, 2, 0,\n",
      "        2, 4, 3, 7, 9, 8, 2, 6, 6, 0, 5, 5, 7, 7, 5, 8, 0, 8, 3, 6, 0, 3, 0, 1,\n",
      "        1, 3, 5, 8, 5, 1, 3, 6])\n",
      "tensor([8, 1, 6, 7, 8, 3, 5, 9, 1, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 0, 7, 3, 1, 4,\n",
      "        0, 8, 6, 7, 6, 5, 1, 1, 4, 3, 3, 4, 9, 6, 1, 1, 9, 0, 2, 5, 0, 9, 0, 6,\n",
      "        0, 1, 2, 6, 4, 2, 4, 6, 3, 1, 7, 0, 1, 0, 5, 1, 0, 3, 7, 9, 8, 4, 7, 9,\n",
      "        7, 1, 1, 8, 3, 2, 0, 0, 3, 1, 0, 0, 1, 4, 1, 2, 9, 2, 3, 4, 4, 8, 6, 0,\n",
      "        9, 7, 4, 7, 7, 2, 2, 4, 5, 1, 8, 9, 5, 6, 1, 2, 2, 4, 4, 2, 2, 8, 3, 9,\n",
      "        4, 2, 4, 3, 6, 3, 1, 0])\n",
      "tensor([6, 0, 7, 7, 5, 8, 8, 7, 1, 1, 8, 0, 7, 6, 6, 6, 7, 0, 2, 7, 6, 7, 2, 9,\n",
      "        1, 5, 8, 1, 0, 3, 5, 0, 9, 8, 7, 0, 1, 4, 8, 2, 5, 5, 9, 3, 7, 3, 7, 1,\n",
      "        0, 1, 3, 0, 8, 6, 0, 3, 7, 5, 9, 6, 5, 6, 7, 1, 0, 7, 7, 4, 0, 4, 6, 8,\n",
      "        8, 3, 1, 1, 5, 4, 2, 4, 0, 7, 2, 8, 5, 6, 5, 8, 6, 8, 4, 1, 2, 9, 9, 8,\n",
      "        2, 3, 0, 6, 4, 4, 1, 7, 2, 5, 6, 2, 0, 2, 7, 6, 6, 2, 6, 1, 2, 7, 5, 2,\n",
      "        8, 8, 7, 0, 3, 6, 1, 6])\n",
      "tensor([5, 9, 1, 8, 7, 2, 2, 3, 1, 5, 5, 8, 4, 4, 0, 4, 0, 7, 0, 1, 5, 9, 0, 1,\n",
      "        7, 2, 7, 5, 2, 1, 7, 1, 7, 7, 0, 7, 6, 5, 6, 9, 4, 7, 7, 3, 3, 9, 5, 3,\n",
      "        8, 5, 6, 1, 8, 2, 1, 6, 4, 6, 7, 1, 9, 6, 2, 2, 6, 6, 6, 1, 7, 0, 0, 5,\n",
      "        8, 9, 9, 0, 7, 0, 6, 5, 0, 7, 4, 3, 6, 0, 0, 3, 9, 1, 2, 6, 0, 1, 6, 2,\n",
      "        9, 6, 6, 4, 1, 7, 7, 7, 5, 7, 5, 8, 7, 1, 6, 9, 5, 8, 9, 7, 4, 7, 9, 6,\n",
      "        9, 6, 9, 4, 1, 8, 0, 7])\n",
      "tensor([5, 3, 0, 7, 8, 0, 7, 3, 7, 7, 5, 3, 3, 4, 6, 5, 9, 9, 9, 5, 2, 5, 2, 9,\n",
      "        9, 2, 4, 7, 0, 5, 7, 0, 3, 9, 4, 7, 6, 3, 4, 2, 2, 7, 2, 1, 4, 0, 0, 0,\n",
      "        1, 0, 4, 1, 9, 1, 6, 5, 5, 9, 6, 5, 2, 9, 0, 3, 8, 7, 7, 7, 7, 3, 4, 8,\n",
      "        1, 9, 8, 8, 2, 5, 7, 2, 2, 3, 7, 5, 5, 3, 9, 5, 3, 5, 0, 9, 2, 2, 1, 5,\n",
      "        8, 4, 7, 5, 8, 5, 1, 5, 9, 9, 8, 7, 5, 4, 0, 7, 0, 3, 4, 4, 7, 8, 0, 6,\n",
      "        6, 5, 3, 3, 7, 0, 5, 4])\n",
      "tensor([6, 6, 6, 1, 5, 6, 8, 7, 6, 7, 4, 2, 4, 5, 3, 8, 4, 7, 6, 9, 9, 4, 0, 5,\n",
      "        2, 7, 0, 6, 0, 7, 9, 8, 4, 5, 3, 4, 7, 0, 7, 6, 6, 0, 7, 4, 7, 0, 2, 8,\n",
      "        5, 4, 6, 4, 5, 0, 4, 7, 0, 9, 6, 2, 0, 2, 9, 0, 9, 9, 5, 6, 8, 3, 2, 6,\n",
      "        6, 8, 9, 7, 3, 4, 5, 4, 9, 2, 8, 9, 5, 7, 3, 4, 3, 6, 9, 3, 2, 4, 1, 0,\n",
      "        1, 0, 2, 6, 4, 4, 9, 7, 9, 3, 6, 0, 7, 7, 3, 3, 6, 6, 3, 6, 8, 6, 0, 0,\n",
      "        3, 3, 3, 4, 7, 6, 2, 9])\n",
      "tensor([6, 1, 1, 1, 8, 5, 4, 3, 8, 2, 9, 5, 3, 3, 6, 1, 3, 2, 5, 8, 6, 3, 8, 6,\n",
      "        4, 7, 4, 0, 9, 9, 0, 0, 1, 7, 3, 7, 8, 1, 1, 9, 3, 7, 7, 9, 5, 9, 8, 3,\n",
      "        7, 0, 4, 4, 8, 8, 2, 3, 3, 0, 9, 1, 3, 9, 7, 4, 1, 4, 3, 9, 3, 9, 0, 3,\n",
      "        1, 1, 8, 1, 3, 0, 1, 4, 3, 4, 7, 6, 8, 8, 2, 3, 3, 6, 6, 2, 4, 5, 5, 4,\n",
      "        5, 8, 0, 0, 5, 5, 9, 5, 0, 3, 8, 6, 4, 9, 4, 9, 3, 2, 5, 4, 5, 9, 4, 9,\n",
      "        6, 3, 6, 4, 4, 7, 1, 8])\n",
      "tensor([0, 9, 4, 0, 9, 7, 3, 9, 7, 0, 3, 5, 8, 0, 2, 1, 3, 3, 6, 4, 1, 6, 0, 0,\n",
      "        3, 8, 1, 9, 2, 1, 5, 0, 1, 9, 3, 3, 9, 1, 8, 5, 8, 5, 3, 6, 2, 3, 3, 4,\n",
      "        4, 0, 2, 2, 0, 5, 0, 5, 6, 1, 4, 9, 2, 2, 2, 7, 5, 4, 1, 1, 5, 6, 3, 5,\n",
      "        9, 3, 9, 5, 3, 8, 0, 6, 8, 8, 7, 1, 3, 7, 5, 5, 2, 2, 2, 2, 2, 6, 3, 0,\n",
      "        4, 1, 4, 4, 1, 0, 4, 0, 3, 8, 4, 1, 1, 0, 6, 8, 7, 9, 3, 3, 5, 6, 8, 5,\n",
      "        3, 4, 9, 8, 0, 3, 8, 4])\n",
      "tensor([8, 3, 4, 6, 2, 8, 9, 6, 5, 1, 6, 2, 6, 2, 5, 1, 8, 1, 1, 0, 2, 0, 1, 9,\n",
      "        2, 1, 5, 2, 8, 1, 1, 9, 9, 3, 6, 7, 3, 6, 4, 3, 6, 3, 4, 8, 0, 3, 6, 4,\n",
      "        8, 6, 5, 4, 1, 0, 2, 3, 2, 5, 4, 2, 2, 5, 4, 3, 9, 1, 5, 4, 1, 3, 6, 0,\n",
      "        6, 5, 8, 4, 1, 5, 3, 2, 7, 1, 7, 5, 9, 6, 7, 2, 2, 5, 8, 8, 3, 1, 0, 8,\n",
      "        8, 6, 9, 2, 7, 9, 2, 0, 3, 3, 7, 9, 2, 9, 1, 2, 6, 4, 6, 9, 5, 9, 1, 8,\n",
      "        7, 5, 9, 5, 6, 3, 3, 2])\n",
      "tensor([2, 0, 2, 2, 6, 8, 0, 0, 4, 3, 4, 0, 6, 2, 8, 6, 2, 8, 1, 6, 7, 3, 5, 6,\n",
      "        4, 1, 5, 9, 8, 9, 0, 8, 4, 0, 6, 4, 3, 7, 6, 3, 7, 1, 3, 8, 2, 7, 7, 2,\n",
      "        5, 6, 2, 6, 0, 8, 1, 1, 0, 8, 3, 8, 9, 5, 8, 0, 2, 3, 5, 1, 3, 8, 9, 5,\n",
      "        1, 6, 9, 7, 1, 2, 7, 3, 6, 4, 4, 0, 6, 2, 8, 9, 0, 3, 8, 0, 2, 5, 5, 0,\n",
      "        0, 7, 2, 4, 8, 4, 7, 0, 4, 0, 2, 0, 6, 5, 2, 2, 2, 4, 7, 4, 5, 3, 8, 2,\n",
      "        9, 4, 6, 8, 9, 4, 4, 4])\n",
      "tensor([4, 1, 7, 6, 0, 1, 1, 3, 8, 2, 4, 4, 0, 6, 4, 4, 0, 0, 9, 2, 0, 7, 2, 7,\n",
      "        1, 0, 6, 9, 2, 5, 7, 7, 9, 0, 2, 9, 7, 2, 1, 7, 7, 9, 1, 8, 2, 4, 0, 5,\n",
      "        3, 2, 8, 6, 3, 6, 6, 1, 8, 5, 5, 6, 5, 3, 7, 4, 3, 5, 0, 6, 5, 6, 2, 7,\n",
      "        4, 9, 1, 7, 1, 7, 8, 4, 1, 0, 4, 1, 7, 7, 0, 9, 6, 5, 1, 6, 1, 6, 8, 8,\n",
      "        6, 0, 9, 6, 5, 9, 9, 9, 1, 8, 7, 9, 3, 1, 5, 5, 3, 5, 1, 2, 0, 7, 8, 4,\n",
      "        6, 5, 7, 6, 8, 0, 1, 4])\n",
      "tensor([2, 2, 4, 8, 6, 0, 5, 2, 8, 4, 1, 3, 1, 9, 3, 7, 8, 9, 9, 4, 5, 7, 4, 1,\n",
      "        6, 3, 1, 1, 1, 6, 6, 7, 4, 8, 1, 5, 5, 5, 6, 9, 9, 1, 8, 8, 0, 4, 9, 2,\n",
      "        0, 6, 2, 0, 7, 4, 8, 2, 2, 3, 4, 1, 1, 8, 6, 3, 1, 8, 7, 0, 0, 7, 2, 4,\n",
      "        0, 7, 0, 0, 1, 4, 7, 0, 2, 7, 5, 4, 8, 9, 5, 2, 3, 7, 7, 5, 2, 7, 2, 9,\n",
      "        8, 7, 7, 3, 9, 5, 3, 5, 8, 7, 9, 3, 6, 2, 2, 4, 0, 8, 8, 9, 1, 0, 2, 6,\n",
      "        3, 2, 0, 2, 9, 8, 2, 6])\n",
      "tensor([0, 1, 2, 7, 6, 1, 9, 3, 7, 1, 2, 7, 1, 8, 8, 4, 8, 2, 4, 8, 9, 5, 7, 8,\n",
      "        8, 8, 3, 5, 9, 5, 8, 5, 4, 2, 2, 2, 7, 5, 8, 4, 2, 7, 7, 8, 7, 7, 3, 2,\n",
      "        8, 9, 7, 4, 8, 5, 1, 4, 0, 6, 6, 3, 7, 7, 9, 6, 4, 9, 0, 0, 1, 0, 6, 2,\n",
      "        9, 3, 2, 9, 9, 7, 1, 0, 2, 4, 8, 5, 9, 9, 4, 3, 8, 4, 3, 1, 5, 1, 0, 1,\n",
      "        0, 6, 9, 0, 4, 9, 8, 8, 2, 3, 6, 2, 4, 0, 2, 5, 4, 5, 5, 8, 4, 5, 4, 0,\n",
      "        2, 9, 4, 3, 2, 8, 8, 4])\n",
      "tensor([8, 6, 5, 0, 3, 1, 0, 7])\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "d25db44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "6ed1bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "192e7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "53fe31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "37039896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    test_dataloader=params[\"test_dataloader\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치를 초기화\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + back propagation 연산\n",
    "            outputs = model(inputs)\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # test accuracy 계산\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        accuracy = []\n",
    "        \n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 결과값 연산\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss = loss_function(outputs, labels).item()\n",
    "            accuracy.append(100 * correct/total)\n",
    "\n",
    "        # 학습 결과 출력\n",
    "        print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "73dc1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Train loss: 5.848760, Test loss: 5.452781, Accuracy: 17.93\n",
      "Epoch: 2/5, Train loss: 1.558341, Test loss: 0.827494, Accuracy: 69.75\n",
      "Epoch: 3/5, Train loss: 0.355515, Test loss: 0.433969, Accuracy: 83.19\n",
      "Epoch: 4/5, Train loss: 0.563165, Test loss: 0.397528, Accuracy: 84.99\n",
      "Epoch: 5/5, Train loss: 0.867846, Test loss: 0.428585, Accuracy: 85.62\n"
     ]
    }
   ],
   "source": [
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
