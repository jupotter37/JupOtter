{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:1848\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_meta_registrations.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     _add_op_to_registry,\n\u001b[0;32m     11\u001b[0m     _convert_out_params,\n\u001b[0;32m     12\u001b[0m     global_decomposition_table,\n\u001b[0;32m     13\u001b[0m     meta_table,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_decomp\\__init__.py:243\u001b[0m\n\u001b[0;32m    239\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_decomp\\decompositions.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, cast, Iterable, List, Optional, Tuple, Union\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_prims\\__init__.py:2608\u001b[0m\n\u001b[0;32m   2603\u001b[0m _full_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;124m    Creates a tensor filled with the given fill value, and with the specified shape, dtype, and device.\u001b[39m\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;66;03m# TODO: add layout\u001b[39;00m\n\u001b[1;32m-> 2608\u001b[0m full \u001b[38;5;241m=\u001b[39m _make_prim(\n\u001b[0;32m   2609\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull(SymInt[] shape, Scalar fill_value, *, ScalarType dtype, Device device, bool requires_grad) -> Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2610\u001b[0m     meta\u001b[38;5;241m=\u001b[39m_full_meta,\n\u001b[0;32m   2611\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39m_full_aten,\n\u001b[0;32m   2612\u001b[0m     return_type\u001b[38;5;241m=\u001b[39mRETURN_TYPE\u001b[38;5;241m.\u001b[39mNEW,\n\u001b[0;32m   2613\u001b[0m     doc\u001b[38;5;241m=\u001b[39m_full_doc,\n\u001b[0;32m   2614\u001b[0m )\n\u001b[0;32m   2617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_full_like_meta\u001b[39m(\n\u001b[0;32m   2618\u001b[0m     a: TensorLikeType,\n\u001b[0;32m   2619\u001b[0m     fill_value: NumberType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2623\u001b[0m     requires_grad: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorLikeType:\n\u001b[0;32m   2625\u001b[0m     strides \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcompute_elementwise_output_strides(a)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_prims\\__init__.py:303\u001b[0m, in \u001b[0;36m_make_prim\u001b[1;34m(schema, return_type, meta, impl_aten, doc, tags)\u001b[0m\n\u001b[0;32m    300\u001b[0m prim_autograd_impl\u001b[38;5;241m.\u001b[39mimpl(name, _autograd_impl)\n\u001b[0;32m    301\u001b[0m prim_meta_impl\u001b[38;5;241m.\u001b[39mimpl(name, meta)\n\u001b[1;32m--> 303\u001b[0m _prim_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprims, name)\n\u001b[0;32m    304\u001b[0m _prim \u001b[38;5;241m=\u001b[39m _prim_packet\u001b[38;5;241m.\u001b[39mdefault\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags:\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:834\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    829\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_OpNamespace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;66;03m# let the script frontend know that op is identical to the builtin op\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;66;03m# with qualified_op_name\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_builtins\u001b[38;5;241m.\u001b[39m_register_builtin(op, qualified_op_name)\n\u001b[0;32m    835\u001b[0m op\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m namespace_name\n\u001b[0;32m    836\u001b[0m opoverloadpacket \u001b[38;5;241m=\u001b[39m OpOverloadPacket(\n\u001b[0;32m    837\u001b[0m     qualified_op_name, op_name, op, overload_names\n\u001b[0;32m    838\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\jit\\_builtins.py:182\u001b[0m, in \u001b[0;36m_register_builtin\u001b[1;34m(fn, op)\u001b[0m\n\u001b[0;32m    177\u001b[0m         _builtin_table[\u001b[38;5;28mid\u001b[39m(builtin)] \u001b[38;5;241m=\u001b[39m aten_op\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_table\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_register_builtin\u001b[39m(fn, op):\n\u001b[0;32m    183\u001b[0m     _get_builtin_table()[\u001b[38;5;28mid\u001b[39m(fn)] \u001b[38;5;241m=\u001b[39m op\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_builtin\u001b[39m(fn):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Function to load and process the data\n",
    "def load_graph_data(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(data['network'].nonzero(), dtype=torch.long)\n",
    "    edge_attr = torch.ones(edge_index.shape[1], 9)\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_graph_data('acmv9.mat')\n",
    "test_data = load_graph_data('citationv1.mat')\n",
    "\n",
    "# Apply node-wise normalization\n",
    "transform = T.NormalizeFeatures()\n",
    "train_data = transform(train_data)\n",
    "test_data = transform(test_data)\n",
    "\n",
    "# Keep data on CPU\n",
    "train_data.x = train_data.x.cpu()\n",
    "train_data.edge_index = train_data.edge_index.cpu()\n",
    "train_data.edge_attr = train_data.edge_attr.cpu()\n",
    "train_data.y = train_data.y.cpu()\n",
    "\n",
    "test_data.x = test_data.x.cpu()\n",
    "test_data.edge_index = test_data.edge_index.cpu()\n",
    "test_data.edge_attr = test_data.edge_attr.cpu()\n",
    "test_data.y = test_data.y.cpu()\n",
    "\n",
    "# Custom sampler for batch training\n",
    "class GraphSampler:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = data.x.size(0)\n",
    "\n",
    "    def __iter__(self):\n",
    "        node_indices = torch.randperm(self.num_nodes)\n",
    "        for i in range(0, self.num_nodes, self.batch_size):\n",
    "            batch_indices = node_indices[i:i+self.batch_size]\n",
    "            edge_mask = (self.data.edge_index[0].unsqueeze(1) == batch_indices).any(1)\n",
    "            batch_edge_index = self.data.edge_index[:, edge_mask]\n",
    "            batch_edge_attr = self.data.edge_attr[edge_mask]\n",
    "            yield batch_indices, batch_edge_index, batch_edge_attr\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_nodes + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# Instantiate the pre-trained model from pretrain-gnns\n",
    "print(\"Loading pre-trained model...\")\n",
    "num_node_features = train_data.num_node_features\n",
    "num_classes = train_data.y.max().item() + 1\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gin', drop_ratio=0.5, JK=\"last\")\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop with mixed precision\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 25\n",
    "batch_size = 500 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    sampler = GraphSampler(train_data, batch_size)\n",
    "    for batch_indices, batch_edge_index, batch_edge_attr in tqdm(sampler, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            batch_x = train_data.x[batch_indices].to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            batch_y = train_data.y[batch_indices].to(device)\n",
    "            \n",
    "            output = model(batch_x, batch_edge_index, batch_edge_attr)\n",
    "            loss = criterion(output, batch_y)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(sampler):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampler = GraphSampler(test_data, batch_size)\n",
    "    for batch_indices, batch_edge_index, batch_edge_attr in tqdm(sampler, desc=\"Evaluation\"):\n",
    "        with autocast():\n",
    "            batch_x = test_data.x[batch_indices].to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            \n",
    "            output = model(batch_x, batch_edge_index, batch_edge_attr)\n",
    "        \n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(test_data.y[batch_indices].numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in the below cell-best code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/9360 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 2.51 GiB is free. Of the allocated memory 750.88 MiB is allocated by PyTorch, and 21.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m batch_edge_attr \u001b[38;5;241m=\u001b[39m batch_edge_attr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    105\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39my[batch_indices]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 107\u001b[0m node_representation \u001b[38;5;241m=\u001b[39m model(batch_x, batch_edge_index, batch_edge_attr, batch_indices)\n\u001b[0;32m    108\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier(node_representation)\n\u001b[0;32m    109\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:339\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch_indices)\u001b[0m\n\u001b[0;32m    337\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 339\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    341\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:261\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    258\u001b[0m edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer:\n\u001b[1;32m--> 261\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_node_embeddings(x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_attr\u001b[38;5;241m=\u001b[39medge_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 2.51 GiB is free. Of the allocated memory 750.88 MiB is allocated by PyTorch, and 21.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to load and process the data\n",
    "def load_graph_data(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(np.array(data['network'].nonzero()), dtype=torch.long)\n",
    "    edge_attr = torch.ones(edge_index.shape[1], 9)  # Create edge attributes\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_graph_data('acmv9.mat')\n",
    "test_data = load_graph_data('citationv1.mat')\n",
    "\n",
    "# Apply node-wise normalization\n",
    "transform = T.NormalizeFeatures()\n",
    "train_data = transform(train_data)\n",
    "test_data = transform(test_data)\n",
    "\n",
    "# Keep data on CPU\n",
    "train_data = train_data.to('cpu')\n",
    "test_data = test_data.to('cpu')\n",
    "\n",
    "# Custom sampler for batch training\n",
    "class GraphSampler:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = data.x.size(0)\n",
    "\n",
    "    def __iter__(self):\n",
    "        node_indices = torch.randperm(self.num_nodes)\n",
    "        for i in range(0, self.num_nodes, self.batch_size):\n",
    "            batch_indices = node_indices[i:i+self.batch_size]\n",
    "            edge_mask = (self.data.edge_index[0].unsqueeze(1) == batch_indices.unsqueeze(0)).any(1)\n",
    "            batch_edge_index = self.data.edge_index[:, edge_mask]\n",
    "            batch_edge_attr = self.data.edge_attr[edge_mask]\n",
    "            \n",
    "            # Remap node indices to ensure they are consecutive\n",
    "            node_map = {int(idx.item()): i for i, idx in enumerate(batch_indices)}\n",
    "            batch_edge_index = torch.tensor([[node_map.get(int(idx.item()), -1) for idx in batch_edge_index[0]],\n",
    "                                             [node_map.get(int(idx.item()), -1) for idx in batch_edge_index[1]]], \n",
    "                                            dtype=torch.long)\n",
    "            \n",
    "            # Remove any edges that point to nodes not in this batch\n",
    "            valid_edges = (batch_edge_index[0] != -1) & (batch_edge_index[1] != -1)\n",
    "            batch_edge_index = batch_edge_index[:, valid_edges]\n",
    "            batch_edge_attr = batch_edge_attr[valid_edges]\n",
    "            \n",
    "            # Ensure batch_edge_index is a 2D LongTensor\n",
    "            batch_edge_index = batch_edge_index.long()\n",
    "            \n",
    "            yield batch_indices, batch_edge_index, batch_edge_attr\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_nodes + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# Instantiate the pre-trained model\n",
    "print(\"Loading pre-trained model...\")\n",
    "num_node_features = train_data.num_node_features\n",
    "num_classes = train_data.y.max().item() + 1\n",
    "model = GNN(num_layer=5, emb_dim=300, JK=\"last\", drop_ratio=0.5, gnn_type='gin')\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Add a classification layer\n",
    "model.classifier = torch.nn.Linear(300, num_classes).to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop with mixed precision and gradient accumulation\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 20\n",
    "batch_size = 1  # Reduced batch size\n",
    "accumulation_steps = 1000  # Increased accumulation steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    sampler = GraphSampler(train_data, batch_size)\n",
    "    optimizer.zero_grad()  # Zero gradients at the beginning of each epoch\n",
    "    \n",
    "    for i, (batch_indices, batch_edge_index, batch_edge_attr) in enumerate(tqdm(sampler, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        with autocast():\n",
    "            batch_x = train_data.x.to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            batch_y = train_data.y[batch_indices].to(device)\n",
    "            \n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr, batch_indices)\n",
    "            output = model.classifier(node_representation)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss = loss / accumulation_steps  # Normalize the loss\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Clear unnecessary tensors from GPU\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, batch_y, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(sampler):.4f}')\n",
    "\n",
    "# Evaluation (keep this part as it is)\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampler = GraphSampler(test_data, batch_size)\n",
    "    for batch_indices, batch_edge_index, batch_edge_attr in tqdm(sampler, desc=\"Evaluation\"):\n",
    "        with autocast():\n",
    "            batch_x = test_data.x[batch_indices].to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            \n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr)\n",
    "            output = model.classifier(node_representation)\n",
    "        \n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(test_data.y[batch_indices].numpy())\n",
    "\n",
    "        # Clear unnecessary tensors from GPU\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another try for the above code to work with memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/9360 [00:00<?, ?it/s]c:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 1/20:   0%|          | 0/9360 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 2.51 GiB is free. Of the allocated memory 750.72 MiB is allocated by PyTorch, and 21.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m batch_edge_attr \u001b[38;5;241m=\u001b[39m batch_edge_attr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    104\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39my[batch_indices]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 106\u001b[0m node_representation \u001b[38;5;241m=\u001b[39m model(batch_x, batch_edge_index, batch_edge_attr, batch_indices)\n\u001b[0;32m    107\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier(node_representation[batch_indices])\n\u001b[0;32m    108\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:340\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch_indices)\u001b[0m\n\u001b[0;32m    338\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 340\u001b[0m     h \u001b[38;5;241m=\u001b[39m checkpoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer], h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:482\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    479\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    481\u001b[0m         )\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointFunction\u001b[38;5;241m.\u001b[39mapply(function, preserve, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    484\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[0;32m    485\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    486\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:261\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[0;32m    258\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 261\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m run_function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:262\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    259\u001b[0m edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer:\n\u001b[1;32m--> 262\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_node_embeddings(x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_attr\u001b[38;5;241m=\u001b[39medge_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 2.51 GiB is free. Of the allocated memory 750.72 MiB is allocated by PyTorch, and 21.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to load and process the data\n",
    "def load_graph_data(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(np.array(data['network'].nonzero()), dtype=torch.long)\n",
    "    edge_attr = torch.ones(edge_index.shape[1], 9)  # Create edge attributes\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_graph_data('acmv9.mat')\n",
    "test_data = load_graph_data('citationv1.mat')\n",
    "\n",
    "# Apply node-wise normalization\n",
    "transform = T.NormalizeFeatures()\n",
    "train_data = transform(train_data)\n",
    "test_data = transform(test_data)\n",
    "\n",
    "# Keep data on CPU\n",
    "train_data = train_data.to('cpu')\n",
    "test_data = test_data.to('cpu')\n",
    "\n",
    "# Custom sampler for batch training\n",
    "class GraphSampler:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = data.x.size(0)\n",
    "\n",
    "    def __iter__(self):\n",
    "        node_indices = torch.randperm(self.num_nodes)\n",
    "        for i in range(0, self.num_nodes, self.batch_size):\n",
    "            batch_indices = node_indices[i:i+self.batch_size]\n",
    "            edge_mask = (self.data.edge_index[0].unsqueeze(1) == batch_indices.unsqueeze(0)).any(1)\n",
    "            batch_edge_index = self.data.edge_index[:, edge_mask]\n",
    "            batch_edge_attr = self.data.edge_attr[edge_mask]\n",
    "            \n",
    "            # Remap node indices to ensure they are consecutive\n",
    "            node_map = {int(idx.item()): i for i, idx in enumerate(batch_indices)}\n",
    "            batch_edge_index = torch.tensor([[node_map.get(int(idx.item()), -1) for idx in batch_edge_index[0]],\n",
    "                                             [node_map.get(int(idx.item()), -1) for idx in batch_edge_index[1]]], \n",
    "                                            dtype=torch.long)\n",
    "            \n",
    "            # Remove any edges that point to nodes not in this batch\n",
    "            valid_edges = (batch_edge_index[0] != -1) & (batch_edge_index[1] != -1)\n",
    "            batch_edge_index = batch_edge_index[:, valid_edges]\n",
    "            batch_edge_attr = batch_edge_attr[valid_edges]\n",
    "            \n",
    "            # Ensure batch_edge_index is a 2D LongTensor\n",
    "            batch_edge_index = batch_edge_index.long()\n",
    "            \n",
    "            yield batch_indices, batch_edge_index, batch_edge_attr\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_nodes + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# Instantiate the pre-trained model\n",
    "print(\"Loading pre-trained model...\")\n",
    "num_node_features = train_data.num_node_features\n",
    "num_classes = train_data.y.max().item() + 1\n",
    "model = GNN(num_layer=5, emb_dim=300, JK=\"last\", drop_ratio=0.5, gnn_type='gin')\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Add a classification layer\n",
    "model.classifier = torch.nn.Linear(300, num_classes).to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  # Reduced learning rate\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 20\n",
    "batch_size = 1  # Keep batch size at 1\n",
    "accumulation_steps = 10000  # Increased accumulation steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    sampler = GraphSampler(train_data, batch_size)\n",
    "    optimizer.zero_grad()  # Zero gradients at the beginning of each epoch\n",
    "    \n",
    "    for i, (batch_indices, batch_edge_index, batch_edge_attr) in enumerate(tqdm(sampler, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        with autocast():\n",
    "            batch_x = train_data.x.to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            batch_y = train_data.y[batch_indices].to(device)\n",
    "            \n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr, batch_indices)\n",
    "            output = model.classifier(node_representation[batch_indices])\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss = loss / accumulation_steps  # Normalize the loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Clear unnecessary tensors from GPU\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, batch_y, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(sampler):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampler = GraphSampler(test_data, batch_size)\n",
    "    for batch_indices, batch_edge_index, batch_edge_attr in tqdm(sampler, desc=\"Evaluation\"):\n",
    "        with autocast():\n",
    "            batch_x = test_data.x.to(device)\n",
    "            batch_edge_index = batch_edge_index.to(device)\n",
    "            batch_edge_attr = batch_edge_attr.to(device)\n",
    "            \n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr)\n",
    "            output = model.classifier(node_representation[batch_indices])\n",
    "        \n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(test_data.y[batch_indices].numpy())\n",
    "\n",
    "        # Clear unnecessary tensors from GPU\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# another attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|| 293/293 [23:44<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:   2%|         | 7/293 [00:35<24:20,  5.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 111\u001b[0m\n\u001b[0;32m    108\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m--> 111\u001b[0m     node_representation \u001b[38;5;241m=\u001b[39m model(batch_x, batch_edge_index, batch_edge_attr, torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(batch_indices)))\n\u001b[0;32m    112\u001b[0m     output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier(node_representation)\n\u001b[0;32m    113\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def load_graph_data(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(np.array(data['network'].nonzero()), dtype=torch.long)\n",
    "    edge_attr = torch.ones(edge_index.shape[1], 9)\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_graph_data('acmv9.mat')\n",
    "test_data = load_graph_data('citationv1.mat')\n",
    "\n",
    "transform = T.NormalizeFeatures()\n",
    "train_data = transform(train_data)\n",
    "test_data = transform(test_data)\n",
    "\n",
    "class CPUOffloadGraphSampler:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = data.x.size(0)\n",
    "\n",
    "    def __iter__(self):\n",
    "        node_indices = torch.randperm(self.num_nodes)\n",
    "        for i in range(0, self.num_nodes, self.batch_size):\n",
    "            batch_indices = node_indices[i:i+self.batch_size]\n",
    "            edge_mask = (self.data.edge_index[0].unsqueeze(1) == batch_indices.unsqueeze(0)).any(1)\n",
    "            batch_edge_index = self.data.edge_index[:, edge_mask]\n",
    "            batch_edge_attr = self.data.edge_attr[edge_mask]\n",
    "            \n",
    "            node_map = {int(idx.item()): i for i, idx in enumerate(batch_indices)}\n",
    "            batch_edge_index = torch.tensor([[node_map.get(int(idx.item()), -1) for idx in batch_edge_index[0]],\n",
    "                                             [node_map.get(int(idx.item()), -1) for idx in batch_edge_index[1]]], \n",
    "                                            dtype=torch.long)\n",
    "            \n",
    "            valid_edges = (batch_edge_index[0] != -1) & (batch_edge_index[1] != -1)\n",
    "            batch_edge_index = batch_edge_index[:, valid_edges]\n",
    "            batch_edge_attr = batch_edge_attr[valid_edges]\n",
    "            \n",
    "            batch_x = self.data.x[batch_indices]\n",
    "            batch_y = self.data.y[batch_indices]\n",
    "            \n",
    "            yield batch_indices, batch_x, batch_edge_index, batch_edge_attr, batch_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_nodes + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "class MemoryEfficientGNN(GNN):\n",
    "    def forward(self, x, edge_index, edge_attr, batch_indices):\n",
    "        h_list = [x]\n",
    "        for layer in range(self.num_layer):\n",
    "            h = checkpoint(self.gnns[layer], h_list[layer], edge_index, edge_attr, use_reentrant=False)\n",
    "            if layer == self.num_layer - 1:\n",
    "                h = torch.nn.functional.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = torch.nn.functional.dropout(torch.nn.functional.relu(h), self.drop_ratio, training=self.training)\n",
    "            h_list.append(h)\n",
    "\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = sum(h_list[1:])\n",
    "\n",
    "        return node_representation[batch_indices]\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "num_node_features = train_data.num_node_features\n",
    "num_classes = train_data.y.max().item() + 1\n",
    "model = MemoryEfficientGNN(num_layer=5, emb_dim=300, JK=\"last\", drop_ratio=0.5, gnn_type='gin')\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "model.classifier = torch.nn.Linear(300, num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "accumulation_steps = 256\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    sampler = CPUOffloadGraphSampler(train_data, batch_size)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (batch_indices, batch_x, batch_edge_index, batch_edge_attr, batch_y) in enumerate(tqdm(sampler, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_edge_index = batch_edge_index.to(device)\n",
    "        batch_edge_attr = batch_edge_attr.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr, torch.arange(len(batch_indices)))\n",
    "            output = model.classifier(node_representation)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss = loss / accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, batch_y, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(sampler):.4f}')\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampler = CPUOffloadGraphSampler(test_data, batch_size)\n",
    "    for batch_indices, batch_x, batch_edge_index, batch_edge_attr, batch_y in tqdm(sampler, desc=\"Evaluation\"):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_edge_index = batch_edge_index.to(device)\n",
    "        batch_edge_attr = batch_edge_attr.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            node_representation = model(batch_x, batch_edge_index, batch_edge_attr, torch.arange(len(batch_indices)))\n",
    "            output = model.classifier(node_representation)\n",
    "        \n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch_y.numpy())\n",
    "\n",
    "        del batch_x, batch_edge_index, batch_edge_attr, node_representation, output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/10 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 31158 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m---> 66\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(train_data\u001b[38;5;241m.\u001b[39mx, train_data\u001b[38;5;241m.\u001b[39medge_index, train_data\u001b[38;5;241m.\u001b[39medge_attr)\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out[batch:batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1000\u001b[39m], train_data\u001b[38;5;241m.\u001b[39my[batch:batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m     69\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:278\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    276\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 278\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;66;03m#remove relu from the last layer\u001b[39;00m\n\u001b[0;32m    281\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:39\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#add self loops in the edge space\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m add_self_loops(edge_index, num_nodes \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#add features corresponding to self-loop edges.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     self_loop_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m9\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:471\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     loop_index \u001b[38;5;241m=\u001b[39m EdgeIndex(\n\u001b[0;32m    467\u001b[0m         torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    468\u001b[0m         sparse_size\u001b[38;5;241m=\u001b[39m(N, N),\n\u001b[0;32m    469\u001b[0m         is_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 471\u001b[0m full_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[1;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HANDLED_FUNCTIONS[func](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[1;34m(tensors, dim, out)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m Tensor\u001b[38;5;241m.\u001b[39m__torch_function__(torch\u001b[38;5;241m.\u001b[39mcat, (Tensor, ), (tensors, dim),\n\u001b[0;32m   1205\u001b[0m                                    \u001b[38;5;28mdict\u001b[39m(out\u001b[38;5;241m=\u001b[39mout))\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 31158 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to load and process the data\n",
    "def load_graph_data(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(data['network'].nonzero(), dtype=torch.long)\n",
    "    edge_attr = torch.ones(edge_index.shape[1], 1)  # Changed to 1-dimensional edge attributes\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_graph_data('acmv9.mat')\n",
    "test_data = load_graph_data('citationv1.mat')\n",
    "\n",
    "# Apply node-wise normalization\n",
    "transform = T.NormalizeFeatures()\n",
    "train_data = transform(train_data)\n",
    "test_data = transform(test_data)\n",
    "\n",
    "# Ensure edge_index is in the correct format (2, num_edges)\n",
    "train_data.edge_index = train_data.edge_index.t().contiguous()\n",
    "test_data.edge_index = test_data.edge_index.t().contiguous()\n",
    "\n",
    "# Move data to device\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Instantiate the pre-trained model from pretrain-gnns\n",
    "print(\"Loading pre-trained model...\")\n",
    "num_node_features = train_data.num_node_features\n",
    "num_classes = train_data.y.max().item() + 1\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gin', drop_ratio=0.5, JK=\"last\")\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop with mixed precision\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(range(0, train_data.num_nodes, 1000), desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            out = model(train_data.x, train_data.edge_index, train_data.edge_attr)\n",
    "            loss = criterion(out[batch:batch+1000], train_data.y[batch:batch+1000])\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(range(0, test_data.num_nodes, 1000), desc=\"Evaluation\"):\n",
    "        with autocast():\n",
    "            out = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
    "            predictions = torch.argmax(out[batch:batch+1000], dim=1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(test_data.y[batch:batch+1000].cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "x shape: torch.Size([9360, 6775]), edge_index shape: torch.Size([2, 31158]), edge_attr shape: torch.Size([3462, 9])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 235.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, edge_index shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, edge_attr shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_attr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x, edge_index, edge_attr)\n\u001b[0;32m     51\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     52\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:278\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    276\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 278\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;66;03m#remove relu from the last layer\u001b[39;00m\n\u001b[0;32m    281\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:51\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     47\u001b[0m edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# x = self.input_node_embeddings(x.to(torch.int64).view(-1,)) - modified\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_node_embeddings(x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr, edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_attr\u001b[38;5;241m=\u001b[39medge_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 70.87 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 235.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data preparation\n",
    "def custom_collate_fn(data_list):\n",
    "    batch = Data.from_data_list(data_list)\n",
    "    if 'edge_attr' in data_list[0]:\n",
    "        batch.edge_attr = torch.cat([data.edge_attr for data in data_list], dim=0)\n",
    "    return batch\n",
    "\n",
    "# Load and prepare datasets\n",
    "acm_data = scipy.io.loadmat('acmv9.mat')\n",
    "citation_data = scipy.io.loadmat('citationv1.mat')\n",
    "train_data = Data(\n",
    "    x=torch.tensor(acm_data['attrb'].todense(), dtype=torch.float32),\n",
    "    edge_index=torch.tensor(acm_data['network'].nonzero(), dtype=torch.long),\n",
    "    edge_attr=torch.tensor(acm_data['network'].data, dtype=torch.float32).view(-1, 9),\n",
    "    y=torch.tensor(acm_data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "# Model initialization\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gin')\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader([train_data], batch_size=1, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop with debugging\n",
    "model.train()\n",
    "for epoch in range(25):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            x, edge_index, edge_attr = batch.x.to(device), batch.edge_index.to(device), batch.edge_attr.to(device)\n",
    "            print(f\"x shape: {x.shape}, edge_index shape: {edge_index.shape}, edge_attr shape: {edge_attr.shape}\")\n",
    "            output = model(x, edge_index, edge_attr)\n",
    "            loss = criterion(output, batch.y.to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, edge_index, edge_attr, y = test_data.x.to(device), test_data.edge_index.to(device), test_data.edge_attr.to(device), test_data.y.to(device)\n",
    "    output = model(x, edge_index, edge_attr)\n",
    "    predictions = torch.argmax(output, dim=1)\n",
    "    accuracy = accuracy_score(y.cpu(), predictions.cpu())\n",
    "    micro_f1 = f1_score(y.cpu(), predictions.cpu(), average='micro')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Micro F1 Score: {micro_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n",
      "x shape: torch.Size([9360, 6775])\n",
      "edge_attr shape: torch.Size([31158])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 9 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m edge_attr\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x, edge_index, edge_attr)\n\u001b[0;32m     78\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:278\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    276\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 278\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;66;03m#remove relu from the last layer\u001b[39;00m\n\u001b[0;32m    281\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:45\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     43\u001b[0m self_loop_attr[:,\u001b[38;5;241m7\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# attribute for self-loop edge\u001b[39;00m\n\u001b[0;32m     44\u001b[0m self_loop_attr \u001b[38;5;241m=\u001b[39m self_loop_attr\u001b[38;5;241m.\u001b[39mto(edge_attr\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(edge_attr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m---> 45\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((edge_attr, self_loop_attr), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     47\u001b[0m edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# x = self.input_node_embeddings(x.to(torch.int64).view(-1,)) - modified\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 9 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#claude\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pretrain_gnns.bio.loader import BioDataset\n",
    "from pretrain_gnns.bio.dataloader import DataLoaderFinetune\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def custom_collate_fn(data_list):\n",
    "    batch = Data.from_data_list(data_list)\n",
    "    if 'edge_attr' in data_list[0]:\n",
    "        batch.edge_attr = torch.cat([data.edge_attr for data in data_list], dim=0)\n",
    "    return batch\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "# Loading the .mat files into the format compatible with the model\n",
    "acm_data = scipy.io.loadmat('acmv9.mat')\n",
    "citation_data = scipy.io.loadmat('citationv1.mat')\n",
    "\n",
    "# Create PyTorch Geometric data objects for training and testing\n",
    "train_data = Data(\n",
    "    x=torch.tensor(acm_data['attrb'].todense(), dtype=torch.float32),\n",
    "    edge_index=torch.tensor(acm_data['network'].nonzero(), dtype=torch.long),\n",
    "    edge_attr=torch.tensor(acm_data['network'].data, dtype=torch.float32),\n",
    "    y=torch.tensor(acm_data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "test_data = Data(\n",
    "    x=torch.tensor(citation_data['attrb'].todense(), dtype=torch.float32),\n",
    "    edge_index=torch.tensor(citation_data['network'].nonzero(), dtype=torch.long),\n",
    "    edge_attr=torch.tensor(citation_data['network'].data, dtype=torch.float32),\n",
    "    y=torch.tensor(citation_data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "# Load the pre-trained model\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gin') # Adjust parameters if needed\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up the DataLoader with the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    [train_data], # wrap the data in a list\n",
    "    batch_size=1, # since we are using a small dataset\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(25): # Assuming 25 epochs, adjust as needed\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            # Debug shapes before passing to the model\n",
    "            print(f\"x shape: {batch.x.shape}\")\n",
    "            print(f\"edge_attr shape: {batch.edge_attr.shape}\")\n",
    "\n",
    "            x, edge_index = batch.x.to(device), batch.edge_index.to(device)\n",
    "            edge_attr = batch.edge_attr.to(device) if batch.edge_attr is not None else None\n",
    "\n",
    "            # If edge_attr is 1D, uncomment the following line:\n",
    "            edge_attr = edge_attr.unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(x, edge_index, edge_attr)\n",
    "            loss = criterion(output, batch.y.to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in [test_data]: # wrap the test data in a list\n",
    "        x, edge_index = batch.x.to(device), batch.edge_index.to(device)\n",
    "        edge_attr = batch.edge_attr.to(device) if batch.edge_attr is not None else None\n",
    "\n",
    "        # If edge_attr is 1D, uncomment the following line:\n",
    "        # edge_attr = edge_attr.unsqueeze(1)\n",
    "\n",
    "        output = model(x, edge_index, edge_attr)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        accuracy = accuracy_score(batch.y.cpu(), predictions.cpu())\n",
    "        micro_f1 = f1_score(batch.y.cpu(), predictions.cpu(), average='micro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Micro F1 Score: {micro_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 31158 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m     x, edge_index \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     65\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x, edge_index, edge_attr)\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     69\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:278\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    276\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer):\n\u001b[1;32m--> 278\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;66;03m#remove relu from the last layer\u001b[39;00m\n\u001b[0;32m    281\u001b[0m         h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_ratio, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:39\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#add self loops in the edge space\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m add_self_loops(edge_index, num_nodes \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#add features corresponding to self-loop edges.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     self_loop_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m9\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:471\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     loop_index \u001b[38;5;241m=\u001b[39m EdgeIndex(\n\u001b[0;32m    467\u001b[0m         torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    468\u001b[0m         sparse_size\u001b[38;5;241m=\u001b[39m(N, N),\n\u001b[0;32m    469\u001b[0m         is_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 471\u001b[0m full_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[1;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HANDLED_FUNCTIONS[func](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch_geometric\\edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[1;34m(tensors, dim, out)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m Tensor\u001b[38;5;241m.\u001b[39m__torch_function__(torch\u001b[38;5;241m.\u001b[39mcat, (Tensor, ), (tensors, dim),\n\u001b[0;32m   1205\u001b[0m                                    \u001b[38;5;28mdict\u001b[39m(out\u001b[38;5;241m=\u001b[39mout))\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 31158 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#perplexity\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def custom_collate_fn(data_list):\n",
    "    batch = Data.from_data_list(data_list)\n",
    "    if 'edge_attr' in data_list:\n",
    "        batch.edge_attr = torch.cat([data.edge_attr for data in data_list], dim=0)\n",
    "    return batch\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "# Loading the .mat files into the format compatible with the model\n",
    "acm_data = scipy.io.loadmat('acmv9.mat')\n",
    "citation_data = scipy.io.loadmat('citationv1.mat')\n",
    "\n",
    "# Create PyTorch Geometric data objects for training and testing\n",
    "train_data = Data(\n",
    "    x=torch.tensor(acm_data['attrb'].todense(), dtype=torch.float32),\n",
    "    edge_index=torch.tensor(acm_data['network'].nonzero(), dtype=torch.long).t().contiguous(),\n",
    "    edge_attr=torch.tensor(acm_data['network'].data.reshape(-1, 1), dtype=torch.float32),\n",
    "    y=torch.tensor(acm_data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "test_data = Data(\n",
    "    x=torch.tensor(citation_data['attrb'].todense(), dtype=torch.float32),\n",
    "    edge_index=torch.tensor(citation_data['network'].nonzero(), dtype=torch.long).t().contiguous(),\n",
    "    edge_attr=torch.tensor(citation_data['network'].data.reshape(-1, 1), dtype=torch.float32),\n",
    "    y=torch.tensor(citation_data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "# Load the pre-trained model\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gin')\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_gin/supervised.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up the DataLoader with the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    [train_data],\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(25):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            x, edge_index = batch.x.to(device), batch.edge_index.to(device)\n",
    "            edge_attr = batch.edge_attr.to(device) if 'edge_attr' in batch else None\n",
    "            output = model(x, edge_index, edge_attr)\n",
    "            loss = criterion(output, batch.y.to(device))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
