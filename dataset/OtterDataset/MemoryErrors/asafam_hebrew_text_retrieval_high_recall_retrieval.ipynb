{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# High Recall Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jun 16 13:36:35 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:0E:00.0 Off |                    0 |\n",
            "| N/A   60C    P0            407W /  400W |   76877MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:13:00.0 Off |                    0 |\n",
            "| N/A   66C    P0            414W /  400W |   58285MiB /  81920MiB |    100%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:49:00.0 Off |                    0 |\n",
            "| N/A   33C    P0             62W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:4F:00.0 Off |                    0 |\n",
            "| N/A   35C    P0             63W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   4  NVIDIA A100-SXM4-80GB          Off |   00000000:91:00.0 Off |                    0 |\n",
            "| N/A   35C    P0             63W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   5  NVIDIA A100-SXM4-80GB          Off |   00000000:97:00.0 Off |                    0 |\n",
            "| N/A   32C    P0             63W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   6  NVIDIA A100-SXM4-80GB          Off |   00000000:CD:00.0 Off |                    0 |\n",
            "| N/A   48C    P0            178W /  400W |   26367MiB /  81920MiB |     59%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   7  NVIDIA A100-SXM4-80GB          Off |   00000000:D2:00.0 Off |                    0 |\n",
            "| N/A   38C    P0             66W /  400W |       3MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A   1197083      C   python                                      76868MiB |\n",
            "|    1   N/A  N/A   1174784      C   python                                      58276MiB |\n",
            "|    6   N/A  N/A   1187724      C   python                                      26358MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python version:\", sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "print(\"datasets version:\", datasets.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Ia1vEmbRIso"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.distributions import MultivariateNormal\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import logging\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_7n2dgYKG4s",
        "outputId": "5b42376e-2ba6-431e-d6c4-6c30d340bbf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder already exists at: /home/nlp/achimoa/projects/high-recall-retrieval\n",
            "Current Working Directory:  /home/nlp/achimoa/projects/high-recall-retrieval\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to the directory you want to set as the new working directory\n",
        "new_working_directory = \"/home/nlp/achimoa/projects/high-recall-retrieval\"\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(new_working_directory):\n",
        "    # Create the folder\n",
        "    os.makedirs(new_working_directory)\n",
        "    print(f\"Folder created at: {new_working_directory}\")\n",
        "else:\n",
        "    print(f\"Folder already exists at: {new_working_directory}\")\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(new_working_directory)\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvxwqrbZ-C14"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_logger(filename, id=None):\n",
        "    # Create a logger object\n",
        "    logger = logging.getLogger(id)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    # Create a file handler for writing logs to a file\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    file_handler = logging.FileHandler(filename)\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(file_formatter)\n",
        "\n",
        "    # Create a stream handler for writing logs to the console\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.DEBUG)\n",
        "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    console_handler.setFormatter(console_formatter)\n",
        "\n",
        "    # Add the handlers to the logger\n",
        "    logger.handlers = []\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    # Define a custom exception handler\n",
        "    def log_exception(exc_type, exc_value, exc_traceback):\n",
        "        logger.error(\"Unhandled exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
        "\n",
        "    # Set the custom exception handler as the global exception handler\n",
        "    sys.excepthook = log_exception\n",
        "\n",
        "    logger.info(f\"Logging to file {filename}\")\n",
        "\n",
        "    return logger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HdPwKqCFYfD-"
      },
      "outputs": [],
      "source": [
        "class SamplerEncoder(nn.Module):\n",
        "    def __init__(self, model_name=\"roberta-base\", latent_dim=8, regularization_factor= 1e-7, encode_hidden_state=False):\n",
        "        super(SamplerEncoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encode_hidden_state = encode_hidden_state\n",
        "        self.regularization_factor= regularization_factor\n",
        "\n",
        "        # Encoder - RoBERTa model\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Hidden dimensions of RoBERTa's output\n",
        "        hidden_dim = self.encoder.config.hidden_size\n",
        "\n",
        "        # Map encoder outputs to latent space\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        # self.decoder = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, encoder_hidden_dim)  # Reconstruct back to the encoder hidden state size\n",
        "        )\n",
        "\n",
        "        # self.decoder = nn.Linear(latent_dim, vocab_size * max_length)\n",
        "        # self.reshape_layer = nn.Unflatten(1, (max_length, vocab_size))\n",
        "        # self.output_layer = nn.Linear(vocab_size, hidden_dim)\n",
        "\n",
        "        # Projection layer to map hidden states to vocabulary size\n",
        "        # self.vocab_size = self.encoder.config.vocab_size\n",
        "        # self.hidden_to_vocab = nn.Linear(hidden_dim, self.vocab_size)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Encoding\n",
        "        encoded = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        if self.encode_hidden_state:\n",
        "            # last_hidden_state = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "            last_hidden_state = encoded.last_hidden_state\n",
        "            pooled_outputs = last_hidden_state[:, 0]  # Use the [CLS] token representation\n",
        "        else:\n",
        "            pooled_outputs = encoded.pooler_output\n",
        "        mu = self.fc_mu(pooled_outputs)\n",
        "        log_var = self.fc_var(pooled_outputs) + self.regularization_factor\n",
        "\n",
        "        # Sampling\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "\n",
        "        # Decoding\n",
        "        reconstructed = self.decoder(z)\n",
        "\n",
        "        # return logits, z, mu, log_var\n",
        "        return reconstructed, mu, log_var, pooled_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, model_name, max_length):\n",
        "        super().__init__()\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.reduction_layer = nn.Linear(self.model.config.hidden_size, max_length)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        reduced = self.reduction_layer(last_hidden_state)\n",
        "        return reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gyu-NUG_icn4"
      },
      "outputs": [],
      "source": [
        "class InfoNCELoss(nn.Module):\n",
        "    def __init__(self, temperature=0.1):\n",
        "        super(InfoNCELoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, features_query, features_original_positive, features_sampled_positives, features_negative=None):\n",
        "        # Normalize the features\n",
        "        features_query = F.normalize(features_query, p=2, dim=1)\n",
        "        features_original_positive = F.normalize(features_original_positive, p=2, dim=1)\n",
        "        features_sampled_positives = F.normalize(features_sampled_positives, p=2, dim=1)\n",
        "\n",
        "        # Concatenate original with sampled positive features\n",
        "        features_positive = torch.cat([features_original_positive, features_sampled_positives], dim=0)\n",
        "\n",
        "        # Concatenate the query feature such that it matches the positives dims\n",
        "        features_anchor = torch.cat([features_query, features_query], dim=0)\n",
        "\n",
        "        # Calculate dot product similarity\n",
        "        similarity_matrix = torch.matmul(features_anchor.float(), features_positive.float().T) / self.temperature\n",
        "\n",
        "        # Labels are the diagonal elements in the similarity matrix\n",
        "        labels = torch.arange(similarity_matrix.size(0), dtype=torch.long, device=features_query.device)\n",
        "\n",
        "        # Calculate cross-entropy loss\n",
        "        loss = F.cross_entropy(similarity_matrix, labels)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AszAFApxBe5F"
      },
      "outputs": [],
      "source": [
        "def tokenize(tokenizer, s, device, padding=\"max_length\", max_length=None, truncation=True, return_tensors=\"pt\"):\n",
        "    tokenizer_kwargs = {\n",
        "        \"padding\": padding,\n",
        "        \"truncation\": truncation,\n",
        "        \"return_tensors\": return_tensors\n",
        "    }\n",
        "    if max_length is not None:\n",
        "        tokenizer_kwargs[\"max_length\"] = max_length\n",
        "\n",
        "    inputs = tokenizer(s, **tokenizer_kwargs).to(device)\n",
        "    # inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def encode(encoder, tokenizer, s, device, padding=\"max_length\", truncation=True, return_tensors=\"pt\", pooling=None, return_scalars_vector=False):\n",
        "    # Tokenize and encode input sentences\n",
        "    inputs = tokenize(\n",
        "        tokenizer,\n",
        "        s,\n",
        "        device,\n",
        "        padding=padding,\n",
        "        max_length=128,\n",
        "        truncation=truncation,\n",
        "        return_tensors=return_tensors\n",
        "    )\n",
        "\n",
        "    # Forward pass for model1\n",
        "    outputs = encoder(**inputs)\n",
        "\n",
        "    # Pooling of the last hidden states\n",
        "    if pooling == 'max':\n",
        "        # max pooling\n",
        "        encoding = outputs.last_hidden_state.max(dim=1).values\n",
        "    elif pooling == 'mean':\n",
        "        # mean pooling\n",
        "        encoding = outputs.last_hidden_state.mean(dim=1)\n",
        "    else:\n",
        "        # pooler output\n",
        "        encoding = outputs.pooler_output\n",
        "\n",
        "    if return_scalars_vector:\n",
        "        encoding = [v.detach().cpu().numpy() for v in encoding]\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return encoding\n",
        "\n",
        "\n",
        "def sampler_encode(encoder, tokenizer, s, device, padding=\"max_length\", truncation=True, return_tensors=\"pt\"):\n",
        "    # Tokenize and encode input sentences\n",
        "    inputs = tokenize(\n",
        "        tokenizer,\n",
        "        s,\n",
        "        device,\n",
        "        padding=padding,\n",
        "        truncation=truncation,\n",
        "        return_tensors=return_tensors\n",
        "    )\n",
        "\n",
        "    # Forward pass for model1\n",
        "    reconstructed, mu, log_var, encoded = encoder(inputs['input_ids'], inputs['attention_mask'])\n",
        "\n",
        "    # return features, mu, log_var\n",
        "    return reconstructed, mu, log_var, encoded, inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kG94mfhBGPb2"
      },
      "outputs": [],
      "source": [
        "def compute_nll(mu, var, sentence):\n",
        "    \"\"\"\n",
        "    Compute the negative log-likelihood (NLL) of the sentences under\n",
        "    the multivariate normal distributions defined by mu and var.\n",
        "    \"\"\"\n",
        "    print(mu.size(), var.size(), sentence.size())\n",
        "    dist = MultivariateNormal(mu, torch.diag_embed(var))\n",
        "    nll = -dist.log_prob(sentence).mean()  # Compute the mean of negative log probabilities\n",
        "    return nll\n",
        "\n",
        "def nll_loss_fn(recon_x, target_ids, pad_token_id=1):\n",
        "    print(\"recon_x0\", recon_x.size())\n",
        "    recon_x = recon_x.view(-1).float()#, recon_x.size(-1))\n",
        "    print(\"recon_x\", recon_x.size())\n",
        "    print(\"target_ids0\", target_ids.size())\n",
        "    target_ids = target_ids.view(-1).long()#, target_ids.size(-1))\n",
        "    print(\"target_ids\", target_ids.size())\n",
        "\n",
        "    loss = nn.NLLLoss(ignore_index=pad_token_id)\n",
        "    return loss(recon_x, target_ids)\n",
        "\n",
        "\n",
        "def reconstruction_loss_fn(s, logits, tokenizer, device):\n",
        "    input_ids = tokenize(tokenizer=tokenizer, s=s, device=device)['input_ids']\n",
        "    input_ids_flat = input_ids.view(-1)\n",
        "    batch_size, sequence_length, vocab_size = logits.size()\n",
        "    logits_flat = logits.view(batch_size * sequence_length, vocab_size)\n",
        "    reconstruction_loss = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)(logits_flat, input_ids_flat)\n",
        "    return reconstruction_loss\n",
        "\n",
        "\n",
        "def kl_divergence_loss_fn(mu, log_var):\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return kl_loss\n",
        "\n",
        "\n",
        "def vae_loss_fn(anchor_sentences, positive_sentences, sampler_encoder, tokenizer, device, warm_up_epochs=5, epoch=0, alpha=1.0, beta=1.0):\n",
        "    reconstructed, mu, log_var, encoded, inputs = sampler_encode(sampler_encoder, tokenizer, anchor_sentences, device)\n",
        "    # reconstructed, mu, log_var, encoded = sampler_encode(sampler_encoder, tokenizer, positive_sentences, device)\n",
        "    # print(\"reconstructed = \", reconstructed.shape)\n",
        "    # print(\"encoded = \", encoded.shape)\n",
        "    # bce_loss = F.binary_cross_entropy(reconstructed, encoded, reduction='sum')\n",
        "    # bce_loss = nn.functional.mse_loss(reconstructed, encoded, reduction='sum')\n",
        "    nll_loss = nll_loss_fn(reconstructed, encoded, tokenizer.pad_token_id)\n",
        "    # print(\"-------------------\")\n",
        "    # print(\"log_var = \", log_var.shape)\n",
        "    # print(\"mu = \", mu.shape)\n",
        "    kl_loss = kl_divergence_loss_fn(mu=mu, log_var=log_var)\n",
        "\n",
        "    loss = nll_loss + kl_loss\n",
        "\n",
        "    return loss, dict(nll_loss=nll_loss, kl_loss=kl_loss)\n",
        "\n",
        "\n",
        "def vae_loss_fn_(s, logits, tokenizer, device, mu, log_var, warm_up_epochs=5, epoch=0, alpha=1.0, beta=1.0):\n",
        "    recon_loss = reconstruction_loss_fn(s, logits, tokenizer, device)\n",
        "    kl_loss = kl_divergence_loss_fn(mu, log_var)\n",
        "    warm_up_factor = min(1, epoch / warm_up_epochs) if warm_up_epochs > 0 else 1\n",
        "    loss = alpha * recon_loss + beta * warm_up_factor * kl_loss\n",
        "    return loss, dict(recon_loss=recon_loss, kl_loss=kl_loss)\n",
        "\n",
        "\n",
        "def vae_loss_fn2(query_sentences, positive_sentences, sampler_encoder, tokenizer, device, warm_up_epochs=5, epoch=0, alpha=1.0, beta=1.0):\n",
        "    # get reconstructions and latent variables\n",
        "    query_logits, query_mu, query_log_var = sampler_encode(sampler_encoder, tokenizer, query_sentences, device)\n",
        "    positive_logits, positive_mu, positive_log_var = sampler_encode(sampler_encoder, tokenizer, positive_sentences, device)\n",
        "\n",
        "    # Compute reconstruction loss for query and positive sentences\n",
        "    query_mu = query_mu.to(device)\n",
        "    query_log_var = query_log_var.to(device)\n",
        "\n",
        "    # mu = torch.rand((8, 768)).to(device)\n",
        "    # var = torch.rand((8, 768)).to(device)\n",
        "    # print(\"1\", mu.size(), var.size())\n",
        "    # MultivariateNormal(mu, torch.diag_embed(var))\n",
        "\n",
        "    # nll = compute_nll(query_mu, query_log_var, query_inputs['input_ids'])\n",
        "    # reconstruction_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "    # query_reconstruction_loss = reconstruction_loss_fn(query_logits.view(-1, query_logits.size(-1)), query_inputs['input_ids'].view(-1))\n",
        "    # positive_reconstruction_loss = reconstruction_loss_fn(positive_logits.view(-1, positive_logits.size(-1)), positive_inputs['input_ids'].view(-1))\n",
        "    # reconstruction_loss = query_reconstruction_loss + positive_reconstruction_loss\n",
        "\n",
        "    # Compute KL divergence loss for query and positive sentences\n",
        "    query_kl_loss = -0.5 * torch.sum(1 + query_log_var - query_mu.pow(2) - query_log_var.exp())\n",
        "    positive_kl_loss = -0.5 * torch.sum(1 + positive_log_var - positive_mu.pow(2) - positive_log_var.exp())\n",
        "    kl_loss = query_kl_loss + positive_kl_loss\n",
        "\n",
        "    # Total loss\n",
        "    # warm_up_factor = min(1, epoch / warm_up_epochs) if warm_up_epochs > 0 else 1\n",
        "    loss = kl_loss\n",
        "\n",
        "    # return loss, dict(reconstruction_loss=reconstruction_loss, kl_loss=kl_loss)\n",
        "    return loss, dict(nll=None, kl_loss=kl_loss)\n",
        "\n",
        "\n",
        "def info_nce_loss_fn(query, positive_key, negative_keys=None, sampled_positive_key=None, temperature=0.1, reduction='mean'):\n",
        "    query, positive_key, negative_keys, sampled_positive_key = normalize(query, positive_key, negative_keys, sampled_positive_key)\n",
        "\n",
        "    if negative_keys is not None:\n",
        "        pass\n",
        "\n",
        "    if sampled_positive_key is not None:\n",
        "      query = torch.cat((query, query), dim=0)\n",
        "      pos_keys = torch.cat((positive_key, sampled_positive_key), dim=0)\n",
        "      logits = query @ transpose(pos_keys)\n",
        "      labels = torch.arange(len(query), device=query.device)\n",
        "      p_loss = F.cross_entropy(logits / temperature, labels, reduction=reduction)\n",
        "\n",
        "    else:\n",
        "      # Cosine between all combinations\n",
        "      logits = query @ transpose(positive_key)\n",
        "      # Positive keys are the entries on the diagonal\n",
        "      labels = torch.arange(len(query), device=query.device)\n",
        "      p_loss = F.cross_entropy(logits / temperature, labels, reduction=reduction)\n",
        "\n",
        "    return p_loss\n",
        "\n",
        "\n",
        "def transpose(x):\n",
        "    return x.transpose(-2, -1)\n",
        "\n",
        "\n",
        "def normalize(*xs):\n",
        "    return [None if x is None else F.normalize(x, dim=-1) for x in xs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v7JLvrZF8KsL"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(dataset, batch_size, shuffle=True):\n",
        "    dataset2 = [{\n",
        "        'sentence': item['sentence'],\n",
        "        'good': random.choice(item['good']),\n",
        "        'bad': random.choice(item['bad']),\n",
        "    } for item in dataset]\n",
        "    # dataset2 = [dataset2[i] for i in range(4)]\n",
        "    dataloader = DataLoader(dataset2, batch_size=batch_size, shuffle=shuffle)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def compute_loss(\n",
        "        outputs_query,\n",
        "        outputs_sentence,\n",
        "        outputs_samples=None,\n",
        "        mu=None,\n",
        "        log_var=None,\n",
        "        should_compute_info_nce_loss=True,\n",
        "        should_compute_reconstruction_loss=True,\n",
        "        should_compute_kl_divergence_loss=True,\n",
        "    ):\n",
        "    # InfoNCE loss\n",
        "    # info_nce_fn = InfoNCELoss(temperature=0.5)\n",
        "    # info_nce_loss = info_nce_fn(\n",
        "    #     features_query=outputs_query,\n",
        "    #     features_original_positive=outputs_sentence,\n",
        "    #     features_sampled_positives=outputs_samples\n",
        "    # )\n",
        "    loss = None\n",
        "    losses = {}\n",
        "\n",
        "    # InfoNCE loss\n",
        "    if should_compute_info_nce_loss:\n",
        "        info_nce_loss = info_nce_loss_fn(query=outputs_query, positive_key=outputs_sentence, sampled_positive_key=outputs_samples)\n",
        "        loss = (loss + info_nce_loss) if loss else info_nce_loss\n",
        "        losses['info_nce_loss'] = info_nce_loss\n",
        "\n",
        "    # NLL loss\n",
        "    # nll_loss = F.cross_entropy(outputs_samples, outputs_sentence, reduction='sum')\n",
        "    # nll_loss = compute_nll(mu, log_var, outputs_sentence)\n",
        "    # nll_loss = compute_nll_loss(mu, log_var, outputs_query) ## ????\n",
        "\n",
        "    # Reconstruction loss for VAE\n",
        "    if should_compute_reconstruction_loss:\n",
        "        should_compute_reconstruction_loss = should_compute_reconstruction_loss and outputs_samples is not None\n",
        "        recon_loss = reconstruction_loss_fn(outputs_samples, outputs_sentence)\n",
        "        loss = (loss + recon_loss) if loss else recon_loss\n",
        "        losses['recon_loss'] = recon_loss\n",
        "\n",
        "    # KL divergence loss for VAE\n",
        "    if should_compute_kl_divergence_loss:\n",
        "        should_compute_kl_divergence_loss = should_compute_kl_divergence_loss and mu is not None and log_var is not None\n",
        "        kl_divergence_loss = kl_divergence_loss_fn(mu, log_var)\n",
        "        loss = (loss + kl_divergence_loss) if loss else kl_divergence_loss\n",
        "        losses['kl_loss'] = kl_divergence_loss\n",
        "\n",
        "    result = (loss, losses)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sCMYA_cy51hN"
      },
      "outputs": [],
      "source": [
        "def evaluate(data, sentence_encoder, query_encoder, tokenizer, device, log, batch_size=8):\n",
        "    all_queries = flatten_list([item['good'] for item in data])\n",
        "\n",
        "    all_queries_vectors = []\n",
        "    for i in tqdm(range(0, len(all_queries), batch_size), desc=\"Encoding all queries\"):\n",
        "        batch = all_queries[i:i+batch_size]\n",
        "        queries_batch = encode(encoder=query_encoder, tokenizer=tokenizer, s=batch, device=device, return_scalars_vector=True)\n",
        "        all_queries_vectors.extend(queries_batch)\n",
        "    queries = [dict(query=query, vector=vector) for query, vector in zip(all_queries, all_queries_vectors)]\n",
        "\n",
        "    queries_true = []\n",
        "    queries_pred = []\n",
        "    for i in tqdm(range(0, len(data), batch_size), desc=\"Predict matching queries\"):\n",
        "        batch = data[i:i+batch_size]\n",
        "        sentences_batch = [item for item in batch['sentence']]\n",
        "        sentences_vector = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=sentences_batch, device=device, return_scalars_vector=True)\n",
        "        sentences = [dict(vector=sentence_vector, sentence=sentence, good=good) for sentence_vector, sentence, good in zip(sentences_vector, sentences_batch, batch['good'])]\n",
        "        queries_true_batch = [item for item in batch['good']]\n",
        "        queries_pred_batch = predict_queries(sentences, queries)\n",
        "\n",
        "        queries_true.extend(queries_true_batch)\n",
        "        queries_pred.extend(queries_pred_batch)\n",
        "\n",
        "\n",
        "    precision, recall, f1 = compute_evaluation_metrics(queries_true, queries_pred)\n",
        "\n",
        "    log.info(f\"Precision: {precision} | Recall: {recall} | F1: {f1}\")\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "def compute_evaluation_metrics(queries_true, queries_pred):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "    for query_true, query_pred in zip(queries_true, queries_pred):\n",
        "        true_positives = list(set(query_true).intersection(set(query_pred)))\n",
        "        false_positives = set(query_pred) - set(query_true)\n",
        "        false_negative = set(query_true) - set(query_pred)\n",
        "\n",
        "        tp += len(true_positives)\n",
        "        fp += len(false_positives)\n",
        "        fn += len(false_negative)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = (2 * (precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "\n",
        "def flatten_list(list_of_lists):\n",
        "    flattened_list = [item for sublist in list_of_lists for item in sublist]\n",
        "    return flattened_list\n",
        "\n",
        "\n",
        "def predict_queries(sentences, queries):\n",
        "    similarity_matrix = np.zeros((len(sentences), len(queries)))\n",
        "\n",
        "    # Compute the similarity matrix\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for j, query in enumerate(queries):\n",
        "            sentence_vec = sentence['vector']\n",
        "            query_vec = query['vector']\n",
        "            similarity_matrix[i, j] = compute_similarity(sentence_vec, query_vec)\n",
        "\n",
        "    # Find the top k indices for each sentence based on the number of 'good' queries\n",
        "    queries_pred_batch = []\n",
        "    for i, item in enumerate(sentences):\n",
        "        k = len(item['good'])\n",
        "        top_k_indices = np.argsort(similarity_matrix[i])[-k:][::-1]\n",
        "        queries_pred_batch.append([queries[j]['query'] for j in top_k_indices])\n",
        "\n",
        "    return queries_pred_batch\n",
        "\n",
        "\n",
        "def compute_similarity(vec1, vec2):\n",
        "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "    return similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o_3-XMLpVkI8"
      },
      "outputs": [],
      "source": [
        "def train_vae(\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    tokenizer,\n",
        "    sampler_encoder,\n",
        "    num_epochs = 10,\n",
        "    lr = 0.25*1e-4,\n",
        "    weight_decay = 1e-6,\n",
        "    device = None,\n",
        "    print_interval = 1000,\n",
        "    should_grad_clipping = True,\n",
        "    checkpoints_base_path = \"checkpoints\",\n",
        "    log=None\n",
        "):\n",
        "    log.info(f\"Training VAE for {num_epochs} epochs\")\n",
        "    log.info(f\"Device: {device}\")\n",
        "    log.info(f\"Batch size: {train_dataloader.batch_size}\")\n",
        "    log.info(f\"Number of train iterations per epoch: {len(train_dataloader)}\")\n",
        "    log.info(f\"Learning rate: {lr}\")\n",
        "    log.info(f\"Weight decay: {weight_decay}\")\n",
        "\n",
        "    total_losses = {}\n",
        "    total_loss = 0\n",
        "    examples_processed = 0\n",
        "    best_loss = math.inf\n",
        "    timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
        "\n",
        "    optimizer_sampled = AdamW(sampler_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):  # num_epochs should be defined by you\n",
        "        epoch_start_time = time.time()\n",
        "        total_batch_time = 0\n",
        "\n",
        "        sampler_encoder.train()\n",
        "        sampler_encoder.to(device)\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            batch_start_time = time.time()\n",
        "            positive_batch = batch['sentence']\n",
        "            anchor_batch = batch['good']\n",
        "\n",
        "            # logits, mu, log_var, _ = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=positive_batch, device=device) if sampler_encoder else (None, None, None)\n",
        "            # loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "            # loss, losses = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var, should_compute_reconstruction_loss=should_compute_reconstruction_loss, should_compute_kl_divergence_loss=should_compute_kl_divergence_loss)\n",
        "            # loss, losses = vae_loss_fn_(s=positive_batch, logits=logits, tokenizer=tokenizer, device=device, mu=mu, log_var=log_var, epoch=epoch, warm_up_epochs=0)\n",
        "            # loss, losses = vae_loss_fn(query_sentences=query_batch, positive_sentences=positive_batch, sampler_encoder=sampler_encoder, tokenizer=tokenizer, device=device, epoch=epoch, warm_up_epochs=0)\n",
        "            loss, losses = vae_loss_fn(anchor_sentences=anchor_batch, positive_sentences=positive_batch, sampler_encoder=sampler_encoder, tokenizer=tokenizer, device=device, epoch=epoch, warm_up_epochs=0)\n",
        "            # Update running loss and example count\n",
        "            total_loss += loss.item()\n",
        "            for key in losses.keys():\n",
        "                loss_value = losses[key].item() if losses[key] else 0\n",
        "                total_losses[key] = (total_losses[key] + loss_value) if (key in total_losses) else loss_value\n",
        "            examples_processed += len(batch)\n",
        "\n",
        "            optimizer_sampled.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            if should_grad_clipping:\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(sampler_encoder.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Backpropagation for models\n",
        "            optimizer_sampled.step()\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_duration = batch_end_time - batch_start_time\n",
        "            total_batch_time += batch_duration\n",
        "\n",
        "            if batch_idx % print_interval == 0 and batch_idx > 0:\n",
        "                average_loss = total_loss / examples_processed\n",
        "                log.info(f\"Epoch: {epoch + 1} / {num_epochs}, Train Batch: {batch_idx}, Average Loss: {average_loss:.4f}, {', '.join([f'Average Loss {key}: {(value / examples_processed):.4f}' for key, value in total_losses.items()])}, Avg Iteration Time = {total_batch_time / print_interval:.4f} seconds\")\n",
        "\n",
        "                # Reset counters\n",
        "                total_loss = 0\n",
        "                total_losses = {}\n",
        "                examples_processed = 0\n",
        "                total_batch_time = 0\n",
        "\n",
        "        # validation\n",
        "        sampler_encoder.eval()\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            total_losses = {}\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in val_dataloader:\n",
        "                batch_start_time = time.time()\n",
        "                positive_batch = batch['sentence']\n",
        "                anchor_batch = batch['good']\n",
        "\n",
        "                # logits, mu, log_var = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=positive_batch, device=device) if sampler_encoder else (None, None, None)\n",
        "\n",
        "                # loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "                # loss, lossses = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var, should_compute_reconstruction_loss=should_compute_reconstruction_loss, should_compute_kl_divergence_loss=should_compute_kl_divergence_loss)\n",
        "                # loss, losses = vae_loss_fn_(s=positive_batch, logits=logits, tokenizer=tokenizer, device=device, mu=mu, log_var=log_var, epoch=epoch, warm_up_epochs=0)\n",
        "                loss, losses = vae_loss_fn(anchor_sentences=anchor_batch, positive_sentences=positive_batch, sampler_encoder=sampler_encoder, tokenizer=tokenizer, device=device, epoch=epoch, warm_up_epochs=0)\n",
        "\n",
        "                # Update running loss and example count\n",
        "                total_loss += loss.item()\n",
        "                for key in losses.keys():\n",
        "                    loss_value = losses[key].item() if losses[key] else 0\n",
        "                    total_losses[key] = (total_losses[key] + loss_value) if key in total_losses else loss_value\n",
        "\n",
        "            average_loss = total_loss / len(val_dataloader)\n",
        "            log.info(f\"Epoch: {epoch + 1} / {num_epochs}, Validation, Average Loss: {average_loss:.4f}, {', '.join([f'Average Loss {key}: {(value / len(val_dataloader)):.4f}' for key, value in total_losses.items()])}, Avg Iteration Time = {total_batch_time / print_interval:.4f} seconds\")\n",
        "\n",
        "            if average_loss < best_loss:\n",
        "                best_loss = average_loss\n",
        "                setup_config = \"vae\" if sampler_encoder else \"classic\"\n",
        "                checkpoints_path = os.path.join(checkpoints_base_path, f'loss{average_loss:.4f}_{setup_config}_epoch{epoch+1}_{timestamp}')\n",
        "                os.makedirs(checkpoints_path, exist_ok=True)\n",
        "                torch.save(\n",
        "                    {\n",
        "                        \"model_name\": sampler_encoder.encoder.config.name_or_path,\n",
        "                        \"latent_dim\": sampler_encoder.latent_dim,\n",
        "                        \"state_dict\": sampler_encoder.state_dict()\n",
        "                    },\n",
        "                    os.path.join(checkpoints_path, \"sampler_encoder.ckpt\")\n",
        "                )\n",
        "                log.info(f'Saved VAE model with loss {best_loss:.4f} at epoch {epoch} in folder {checkpoints_path}')\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        log.info(f\"Epoch {epoch} completed in {epoch_duration:.4f} seconds\")\n",
        "\n",
        "\n",
        "def try_train_vae(**kwargs):\n",
        "    try:\n",
        "        train_vae(**kwargs)\n",
        "    except Exception as e:\n",
        "        log = kwargs.get('log')\n",
        "        log.exception(e)\n",
        "\n",
        "\n",
        "def load_model(encoder, checkpoint_path, device):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    # Load the model configuration and state_dict\n",
        "    model_name = checkpoint[\"model_name\"]\n",
        "    # latent_dim = checkpoint[\"latent_dim\"]\n",
        "    state_dict = checkpoint[\"state_dict\"]\n",
        "\n",
        "    # Load the state_dict into the model\n",
        "    encoder.load_state_dict(state_dict)\n",
        "    encoder.to(device)\n",
        "    return encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15wyXFALBDMx"
      },
      "source": [
        "#### Train models util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_LbwIlxVq_A9"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "        validation_dataset,\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        tokenizer,\n",
        "        query_encoder,\n",
        "        sentence_encoder,\n",
        "        sampler_encoder = None,\n",
        "        num_epochs = 10,\n",
        "        lr = 0.25*1e-4,\n",
        "        weight_decay = 1e-6,\n",
        "        device = None,\n",
        "        print_interval = 1000,\n",
        "        should_grad_clipping = True,\n",
        "        checkpoints_base_path = \"checkpoints\",\n",
        "        should_compute_info_nce_loss=True,\n",
        "        should_compute_reconstruction_loss=True,\n",
        "        should_compute_kl_divergence_loss=True,\n",
        "        log=None\n",
        "):\n",
        "    # log = create_logger(id='train', filename=f'logs/train.log')\n",
        "    log.info(f\"Training for {num_epochs} epochs\")\n",
        "    log.info(f\"Device: {device}\")\n",
        "    log.info(f\"Batch size: {train_dataloader.batch_size}\")\n",
        "    log.info(f\"Number of train iterations per epoch: {len(train_dataloader)}\")\n",
        "    log.info(f\"Learning rate: {lr}\")\n",
        "    log.info(f\"Weight decay: {weight_decay}\")\n",
        "\n",
        "    total_losses = {}\n",
        "    total_loss = 0\n",
        "    examples_processed = 0\n",
        "    best_recall = 0.0\n",
        "    timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
        "\n",
        "    optimizer_query = AdamW(query_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    optimizer_sentence = AdamW(sentence_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    if sampler_encoder:\n",
        "        optimizer_sampled = AdamW(sampler_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):  # num_epochs should be defined by you\n",
        "        epoch_start_time = time.time()\n",
        "        total_batch_time = 0\n",
        "\n",
        "        query_encoder.train()\n",
        "        query_encoder.to(device)\n",
        "        sentence_encoder.train()\n",
        "        sentence_encoder.to(device)\n",
        "        if sampler_encoder:\n",
        "            sampler_encoder.train()\n",
        "            sampler_encoder.to(device)\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "            sentences_batch = batch['sentence']\n",
        "            abstracts_batch = batch['good']\n",
        "\n",
        "            outputs_abstract = encode(encoder=query_encoder, tokenizer=tokenizer, s=abstracts_batch, device=device)\n",
        "            outputs_sentence = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=sentences_batch, device=device)\n",
        "            outputs_samples, mu, log_var, _ = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=abstracts_batch, device=device) if sampler_encoder else (None, None, None, None)\n",
        "\n",
        "            # loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "            loss, losses = compute_loss(\n",
        "                outputs_query=outputs_abstract, \n",
        "                outputs_sentence=outputs_sentence, \n",
        "                outputs_samples=outputs_samples, \n",
        "                mu=mu, \n",
        "                log_var=log_var, \n",
        "                should_compute_info_nce_loss=should_compute_info_nce_loss,\n",
        "                should_compute_reconstruction_loss=should_compute_reconstruction_loss, \n",
        "                should_compute_kl_divergence_loss=should_compute_kl_divergence_loss\n",
        "            )\n",
        "\n",
        "            optimizer_query.zero_grad()\n",
        "            optimizer_sentence.zero_grad()\n",
        "            if sampler_encoder:\n",
        "                optimizer_sampled.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            if should_grad_clipping:\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(query_encoder.parameters(), max_norm=1.0)\n",
        "                torch.nn.utils.clip_grad_norm_(sentence_encoder.parameters(), max_norm=1.0)\n",
        "                if sampler_encoder:\n",
        "                    torch.nn.utils.clip_grad_norm_(sampler_encoder.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Backpropagation for models\n",
        "            optimizer_query.step()\n",
        "            optimizer_sentence.step()\n",
        "            if sampler_encoder:\n",
        "                optimizer_sampled.step()\n",
        "\n",
        "            # Update running loss and example count\n",
        "            total_loss += loss.item()\n",
        "            for key in losses.keys():\n",
        "                loss_value = losses[key].item() if losses[key] else 0\n",
        "                total_losses[key] = (total_losses[key] + loss_value) if key in total_losses else loss_value\n",
        "            examples_processed += len(batch)\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_duration = batch_end_time - batch_start_time\n",
        "            total_batch_time += batch_duration\n",
        "\n",
        "            if batch_idx % print_interval == 0 and batch_idx != 0:\n",
        "                average_loss = total_loss / examples_processed\n",
        "                log.info(f\"Epoch: {epoch + 1} / {num_epochs}, Train Batch: {batch_idx}, Average Loss: {average_loss:.4f}, {', '.join([f'Average Loss {key}: {(value / examples_processed):.4f}' for key, value in total_losses.items()])}, Avg Iteration Time = {total_batch_time / print_interval:.4f} seconds\")\n",
        "\n",
        "                # Reset counters\n",
        "                total_losses = {}\n",
        "                total_loss = 0\n",
        "                examples_processed = 0\n",
        "                total_batch_time = 0\n",
        "\n",
        "        # validation\n",
        "        query_encoder.eval()\n",
        "        sentence_encoder.eval()\n",
        "        if sampler_encoder:\n",
        "            sampler_encoder.eval()\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            total_losses = {}\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in val_dataloader:\n",
        "                batch_start_time = time.time()\n",
        "\n",
        "                outputs_query = encode(encoder=query_encoder, tokenizer=tokenizer, s=batch['good'], device=device)\n",
        "                outputs_sentence = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=batch['sentence'], device=device)\n",
        "                outputs_samples, mu, log_var, _ = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=batch['good'], device=device) if sampler_encoder else (None, None, None, None)\n",
        "\n",
        "                # loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "                loss, losses = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var, should_compute_reconstruction_loss=should_compute_reconstruction_loss, should_compute_kl_divergence_loss=should_compute_kl_divergence_loss)\n",
        "\n",
        "                # Update running loss and example count\n",
        "                total_loss += loss.item()\n",
        "                for key in losses.keys():\n",
        "                    loss_value = losses[key].item() if losses[key] else 0\n",
        "                    total_losses[key] = (total_losses[key] + loss_value) if key in total_losses else loss_value\n",
        "\n",
        "                batch_end_time = time.time()\n",
        "                batch_duration = batch_end_time - batch_start_time\n",
        "                total_batch_time += batch_duration\n",
        "\n",
        "            average_loss = total_loss / len(val_dataloader)\n",
        "            _, recall, _ = evaluate(data=validation_dataset, sentence_encoder=sentence_encoder, query_encoder=query_encoder, tokenizer=tokenizer, device=device, log=log)\n",
        "            log.info(f\"Epoch: {epoch + 1} / {num_epochs}, Validation, Average Loss: {average_loss:.4f}, {', '.join([f'Average Loss {key}: {(value / len(val_dataloader)):.4f}' for key, value in total_losses.items()])}, Recall: {recall:.4f}, Avg Iteration Time = {total_batch_time / print_interval:.4f} seconds\")\n",
        "\n",
        "            if recall > best_recall:\n",
        "                best_recall = recall\n",
        "                setup_config = \"vae\" if sampler_encoder else \"classic\"\n",
        "                checkpoints_path = os.path.join(checkpoints_base_path, f'recall{recall:.4f}_{setup_config}_epoch{epoch+1}_{timestamp}')\n",
        "                os.makedirs(checkpoints_path, exist_ok=True)\n",
        "                torch.save({\"model_name\": query_encoder.config.name_or_path, \"state_dict\": query_encoder.state_dict()}, os.path.join(checkpoints_path, \"query_encoder.ckpt\"))\n",
        "                torch.save({\"model_name\": sentence_encoder.config.name_or_path, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sentence_encoder.ckpt\"))\n",
        "                if sampler_encoder:\n",
        "                    torch.save({\"model_name\": sampler_encoder.encoder.config.name_or_path, \"latent_dim\": sampler_encoder.latent_dim, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sampler_encoder.ckpt\"))\n",
        "                log.info(f'Saved model with recall {recall:.4f} at epoch {epoch+1} in folder {checkpoints_path}')\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        log.info(f\"Epoch {epoch + 1} completed in {epoch_duration:.4f} seconds\")\n",
        "\n",
        "\n",
        "def try_train(**kwargs):\n",
        "    try:\n",
        "        train(**kwargs)\n",
        "    except Exception as e:\n",
        "        log = kwargs.get('log')\n",
        "        log.exception(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lkz5UVY9bWK"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "f0b84b44b40c43b382f0e2ec3b2909eb",
            "5d2666cf77e34757af4f8a8d700e09e8",
            "6f53055bc5524a66a6f019cb45629cb2",
            "cae0f4393d5f4076b61f61f60127c44b",
            "40656ab742454143a2d3142bcdb0f72f",
            "7ea7773040d84e31a871d1b06f9ba653",
            "4e8277b9f0a24a8d992d701bc387229d",
            "41b40a79e3264a13a72c986933341dac",
            "c181a2d8730a435d9e29b0ddd5560a78",
            "5a07729ba09248fc9b1548ece8226a46",
            "40e26a3401da4a2f85fdacafdd6e3b06",
            "e9e88fe1325549eab574eb464c233331",
            "42bb9aa98ade45bda30452891441b9bb",
            "9280f8f9ad5345779c4cf5ac47e08482",
            "7487d6b821f3495b93ce525487a81623",
            "afb2e4a5659946a08dbdb9754b14c539",
            "762742bec18243fb88f9ce4ac22b1dc5",
            "8af50f1921b94864a63e64c8ad4dea51",
            "a28e506a6e73430e84b2f9b485891fd7",
            "88230fdf4f454558ae5026684cda15c7",
            "fd44151f0f284958a0cc7e65168d9c46",
            "144085849b6047d38b6c1d801e349640",
            "1c702c866daa4ecfbcff7a5d1260492a",
            "712c01c09d74487088d6306ba34dcc55",
            "0210c55041684510b73bb026880ec52b",
            "627a0ffdec5f4d8ba5cc39843ab554c7",
            "2ae8fae5eba64f79a81186ecdfdd2931",
            "051524850dbd405285321482a5548af1",
            "e0fa41556d6a47f1a6a8a8caede84fe4",
            "0c58b8fdcce44b998739bbb283ce5df6",
            "818c2025435d49398df11561b3f1430e",
            "f5cb637ffe7043d48850f33031504c7a",
            "a062d049136443758552f2e0b624067f",
            "0ab6754e3044464bbc22478ecd655677",
            "5228b76b87a840c28950056d3a81de88",
            "76c47c7694b34adb88ae24a7e12f5ee1",
            "0d8c9ed8e89a4151bf7b9afed1b58827",
            "24f6ea6b263f4a46a2e34d985514815c",
            "5653f821a065400c88cd64cc9af80e59",
            "cc7f56aa8f6d4616a63f4fadc5be6893",
            "fccc724905a04a7e9a4f45ed395eade9",
            "48a71941aa5b473785c6de1c8eb6f09f",
            "23a6b01eba3145b597fe2135ae9fc135",
            "c268e03652d44434b97b31097c52bdb5",
            "6fbce80ca4ad4b22a06f3bddc52269aa",
            "7c1567f7574e4bdbbd389b37b94dd81d",
            "d6d1f02baf064ca1b1ee2d7640c45e25",
            "94ef15ed80dc4bbbbd492b586c052a5f",
            "20dab458e0e14dd6902c9e4f8d55affc",
            "957d73f59628450f90ade3ef9a9d1b7f",
            "61778a3de3f54c209fed5a58fd17ec37",
            "4560f59d76f544669b971ef3025a7c23",
            "e06ac6464466489ab13ea72037670ffe",
            "fd5a05cc0f1745ecaaaf6d815215bc89",
            "5650f6cbc51743d1a3817d2046fd770f",
            "2b637a518230469c94c8ecdfd0fbfa99",
            "f484d1cab9774086a8613eddcd4cbe7d",
            "f2e0930a322d4af8bc0855304952d8ce",
            "5f67607d38cf4dd59a66166a6eb7f2a8",
            "ce550e7ff64143659a56700612340f3e",
            "b9e3ce0023154062825db219c9f17650",
            "0b9e862a88064c07afc996af53574117",
            "6dc851c3c26543278251bc886983f243",
            "94af652ef542449494d30c1a1892455c",
            "5bb35a8e38764ae39d4898c6e8d922d3",
            "f6dec4914a7343499322d7f2ced36377",
            "4a1fc9fecfd9489e9dbbb66831ac8f27",
            "d3be9fc77dcf4ce6a1b9f4a64fe88ed3",
            "503b3ec5f1114c0a85090054ac965bb6",
            "331931afd31845b5a74a7fca366346b1",
            "6255307b6bf5432ca5150ceef2687bde",
            "f3de39376f324ae78c46116abf16057e",
            "f69af3a6ec7943bb81a2b76cf859f0b3",
            "1e0ebc40534d4551afc3ef20c3f6c38d",
            "a7108e66923546a6aa5ad3c13829367b",
            "a1b46a2b4ac244caacb55c219e655c73",
            "38a167153ad84ae5934a56b8ebd1b841"
          ]
        },
        "id": "U4ttt2pFRfWe",
        "outputId": "c5ed4186-a81a-48a3-a434-78d90911552c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nlp/achimoa/miniconda3/envs/biu/lib/python3.10/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'bad', 'good'],\n",
              "        num_rows: 157649\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'bad', 'good'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'bad', 'good'],\n",
              "        num_rows: 2955\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"biu-nlp/abstract-sim\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence:  Suburban development began in the early 20th century and increased with the advent of the automobile.\n",
            "Good abstracts:  ['Urban expansion in the early 1900s', 'Growth of suburban areas in the 1900s.', 'Increased accessibility of transportation', 'Development of suburban areas', 'The rise of the automobile', 'The introduction of a new technology enabled a shift in population density.', 'The population shifted to new locations as a result of the introduction of a new technology.', 'A shift in lifestyle led to changes in the landscape.']\n",
            "Bad abstracts:  ['Urban expansion in the late 1900s.', 'Decrease of suburban areas in the 1900s', 'Decreased accessibility of transportation', 'Decrease of suburban areas', 'The fall of the automobile.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Sentence: \", dataset['train']['sentence'][42])\n",
        "print(\"Good abstracts: \", dataset['train']['good'][42])\n",
        "print(\"Bad abstracts: \", dataset['train']['bad'][42])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57tCiIgV-MR2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpu = \":5\"\n",
        "device = torch.device(f\"cuda{gpu or ''}\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFCt9hRR6ErV"
      },
      "source": [
        "#### Train with Classic Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "batch_size = 64\n",
        "validation_batch_size = 1\n",
        "\n",
        "train_dataloader = get_dataloader(dataset['train'], batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = get_dataloader(dataset['validation'], batch_size=validation_batch_size, shuffle=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "base_checkpoint_path = None #'checkpoints/recall0.3000_classic_epoch1_20240523-023103'\n",
        "\n",
        "query_encoder = AutoModel.from_pretrained(model_name)\n",
        "query_checkpoint_path = os.path.join(base_checkpoint_path, 'query_encoder.ckpt') if base_checkpoint_path else None\n",
        "if query_checkpoint_path:\n",
        "    sampler_encoder = load_model(query_encoder, query_checkpoint_path, device=device)\n",
        "    \n",
        "sentence_encoder = AutoModel.from_pretrained(model_name)\n",
        "sentence_checkpoint_path = os.path.join(base_checkpoint_path, 'sentence_encoder.ckpt') if base_checkpoint_path else None\n",
        "if sentence_checkpoint_path:\n",
        "    sampler_encoder = load_model(sentence_encoder, sentence_checkpoint_path, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-27 15:11:04,020 - INFO - Logging to file logs/train_classic.log\n",
            "2024-05-27 15:11:04,020 - INFO - Training for 10 epochs\n",
            "2024-05-27 15:11:04,021 - INFO - Device: cuda:4\n",
            "2024-05-27 15:11:04,021 - INFO - Batch size: 64\n",
            "2024-05-27 15:11:04,022 - INFO - Number of train iterations per epoch: 2464\n",
            "2024-05-27 15:11:04,022 - INFO - Learning rate: 2.5e-05\n",
            "2024-05-27 15:11:04,023 - INFO - Weight decay: 1e-06\n",
            "2024-05-27 15:11:07,382 - INFO - Epoch: 1 / 10, Train Batch: 0, Average Loss: 1.3872, Average Loss info_nce_loss: 1.3872, Avg Iteration Time = 0.0015 seconds\n",
            "2024-05-27 15:20:44,114 - INFO - Epoch: 1 / 10, Train Batch: 1000, Average Loss: 0.3646, Average Loss info_nce_loss: 0.3646, Avg Iteration Time = 0.5763 seconds\n",
            "2024-05-27 15:30:20,598 - INFO - Epoch: 1 / 10, Train Batch: 2000, Average Loss: 0.1969, Average Loss info_nce_loss: 0.1969, Avg Iteration Time = 0.5761 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:52<00:00, 63.83it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:41<00:00,  1.31s/it]\n",
            "2024-05-27 15:50:34,223 - INFO - Precision: 0.43113483854224594 | Recall: 0.43049642764594825 | F1: 0.4308153965842996\n",
            "2024-05-27 15:50:34,244 - INFO - Epoch: 1 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4305, Avg Iteration Time = 0.3388 seconds\n",
            "2024-05-27 15:50:43,174 - INFO - Saved model with recall 0.4305 at epoch 1 in folder checkpoints/recall0.4305_classic_epoch1_20240527-151104\n",
            "2024-05-27 15:50:43,175 - INFO - Epoch 1 completed in 2378.0210 seconds\n",
            "2024-05-27 15:50:43,808 - INFO - Epoch: 2 / 10, Train Batch: 0, Average Loss: 0.0003, Average Loss info_nce_loss: 0.0003, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 16:00:20,401 - INFO - Epoch: 2 / 10, Train Batch: 1000, Average Loss: 0.1347, Average Loss info_nce_loss: 0.1347, Avg Iteration Time = 0.5762 seconds\n",
            "2024-05-27 16:09:57,044 - INFO - Epoch: 2 / 10, Train Batch: 2000, Average Loss: 0.1304, Average Loss info_nce_loss: 0.1304, Avg Iteration Time = 0.5763 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:52<00:00, 63.82it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:43<00:00,  1.32s/it]\n",
            "2024-05-27 16:30:12,572 - INFO - Precision: 0.4694748561885322 | Recall: 0.46829304408988265 | F1: 0.46888320545609546\n",
            "2024-05-27 16:30:12,594 - INFO - Epoch: 2 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4683, Avg Iteration Time = 0.3388 seconds\n",
            "2024-05-27 16:30:21,737 - INFO - Saved model with recall 0.4683 at epoch 2 in folder checkpoints/recall0.4683_classic_epoch2_20240527-151104\n",
            "2024-05-27 16:30:21,738 - INFO - Epoch 2 completed in 2378.5624 seconds\n",
            "2024-05-27 16:30:22,404 - INFO - Epoch: 3 / 10, Train Batch: 0, Average Loss: 0.0002, Average Loss info_nce_loss: 0.0002, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 16:39:59,592 - INFO - Epoch: 3 / 10, Train Batch: 1000, Average Loss: 0.0980, Average Loss info_nce_loss: 0.0980, Avg Iteration Time = 0.5766 seconds\n",
            "2024-05-27 16:49:36,403 - INFO - Epoch: 3 / 10, Train Batch: 2000, Average Loss: 0.0999, Average Loss info_nce_loss: 0.0999, Avg Iteration Time = 0.5764 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:53<00:00, 63.68it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:51<00:00,  1.33s/it]\n",
            "2024-05-27 17:10:01,526 - INFO - Precision: 0.48235730170496666 | Recall: 0.48176803761152037 | F1: 0.4820624895819829\n",
            "2024-05-27 17:10:01,550 - INFO - Epoch: 3 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4818, Avg Iteration Time = 0.3395 seconds\n",
            "2024-05-27 17:10:10,615 - INFO - Saved model with recall 0.4818 at epoch 3 in folder checkpoints/recall0.4818_classic_epoch3_20240527-151104\n",
            "2024-05-27 17:10:10,616 - INFO - Epoch 3 completed in 2388.8778 seconds\n",
            "2024-05-27 17:10:11,277 - INFO - Epoch: 4 / 10, Train Batch: 0, Average Loss: 0.0002, Average Loss info_nce_loss: 0.0002, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 17:19:48,371 - INFO - Epoch: 4 / 10, Train Batch: 1000, Average Loss: 0.0771, Average Loss info_nce_loss: 0.0771, Avg Iteration Time = 0.5767 seconds\n",
            "2024-05-27 17:29:25,103 - INFO - Epoch: 4 / 10, Train Batch: 2000, Average Loss: 0.0800, Average Loss info_nce_loss: 0.0800, Avg Iteration Time = 0.5763 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:53<00:00, 63.61it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:53<00:00,  1.33s/it]\n",
            "2024-05-27 17:49:51,673 - INFO - Precision: 0.4896188640071185 | Recall: 0.4888757265020546 | F1: 0.48924701305918317\n",
            "2024-05-27 17:49:51,695 - INFO - Epoch: 4 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4889, Avg Iteration Time = 0.3389 seconds\n",
            "2024-05-27 17:50:00,803 - INFO - Saved model with recall 0.4889 at epoch 4 in folder checkpoints/recall0.4889_classic_epoch4_20240527-151104\n",
            "2024-05-27 17:50:00,804 - INFO - Epoch 4 completed in 2390.1868 seconds\n",
            "2024-05-27 17:50:01,448 - INFO - Epoch: 5 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 17:59:38,135 - INFO - Epoch: 5 / 10, Train Batch: 1000, Average Loss: 0.0626, Average Loss info_nce_loss: 0.0626, Avg Iteration Time = 0.5763 seconds\n",
            "2024-05-27 18:09:14,615 - INFO - Epoch: 5 / 10, Train Batch: 2000, Average Loss: 0.0655, Average Loss info_nce_loss: 0.0655, Avg Iteration Time = 0.5761 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:53<00:00, 63.51it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:47<00:00,  1.32s/it]\n",
            "2024-05-27 18:29:35,318 - INFO - Precision: 0.4907136237256719 | Recall: 0.49002332210417204 | F1: 0.4903682299770319\n",
            "2024-05-27 18:29:35,340 - INFO - Epoch: 5 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4900, Avg Iteration Time = 0.3391 seconds\n",
            "2024-05-27 18:29:44,241 - INFO - Saved model with recall 0.4900 at epoch 5 in folder checkpoints/recall0.4900_classic_epoch5_20240527-151104\n",
            "2024-05-27 18:29:44,242 - INFO - Epoch 5 completed in 2383.4379 seconds\n",
            "2024-05-27 18:29:44,892 - INFO - Epoch: 6 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 18:39:21,702 - INFO - Epoch: 6 / 10, Train Batch: 1000, Average Loss: 0.0535, Average Loss info_nce_loss: 0.0535, Avg Iteration Time = 0.5764 seconds\n",
            "2024-05-27 18:48:58,812 - INFO - Epoch: 6 / 10, Train Batch: 2000, Average Loss: 0.0549, Average Loss info_nce_loss: 0.0549, Avg Iteration Time = 0.5768 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:54<00:00, 62.21it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:50<00:00,  1.33s/it]\n",
            "2024-05-27 19:09:24,190 - INFO - Precision: 0.48516760605161674 | Recall: 0.48435938251952765 | F1: 0.4847631574072359\n",
            "2024-05-27 19:09:24,301 - INFO - Epoch: 6 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4844, Avg Iteration Time = 0.3397 seconds\n",
            "2024-05-27 19:09:24,301 - INFO - Epoch 6 completed in 2380.0587 seconds\n",
            "2024-05-27 19:09:25,371 - INFO - Epoch: 7 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0010 seconds\n",
            "2024-05-27 19:19:04,881 - INFO - Epoch: 7 / 10, Train Batch: 1000, Average Loss: 0.0454, Average Loss info_nce_loss: 0.0454, Avg Iteration Time = 0.5791 seconds\n",
            "2024-05-27 19:28:41,574 - INFO - Epoch: 7 / 10, Train Batch: 2000, Average Loss: 0.0485, Average Loss info_nce_loss: 0.0485, Avg Iteration Time = 0.5764 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:52<00:00, 63.82it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:48<00:00,  1.33s/it]\n",
            "2024-05-27 19:49:04,632 - INFO - Precision: 0.4854347342672893 | Recall: 0.4848776515011291 | F1: 0.4851560329660154\n",
            "2024-05-27 19:49:04,655 - INFO - Epoch: 7 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4849, Avg Iteration Time = 0.3406 seconds\n",
            "2024-05-27 19:49:04,656 - INFO - Epoch 7 completed in 2380.3541 seconds\n",
            "2024-05-27 19:49:05,300 - INFO - Epoch: 8 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 19:58:42,027 - INFO - Epoch: 8 / 10, Train Batch: 1000, Average Loss: 0.0400, Average Loss info_nce_loss: 0.0400, Avg Iteration Time = 0.5764 seconds\n",
            "2024-05-27 20:08:18,794 - INFO - Epoch: 8 / 10, Train Batch: 2000, Average Loss: 0.0423, Average Loss info_nce_loss: 0.0423, Avg Iteration Time = 0.5764 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:54<00:00, 62.24it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:44<00:00,  1.32s/it]\n",
            "2024-05-27 20:28:37,665 - INFO - Precision: 0.4856211088052179 | Recall: 0.4850997667789583 | F1: 0.4853602977943219\n",
            "2024-05-27 20:28:37,688 - INFO - Epoch: 8 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4851, Avg Iteration Time = 0.3397 seconds\n",
            "2024-05-27 20:28:37,689 - INFO - Epoch 8 completed in 2373.0325 seconds\n",
            "2024-05-27 20:28:38,344 - INFO - Epoch: 9 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 20:38:15,036 - INFO - Epoch: 9 / 10, Train Batch: 1000, Average Loss: 0.0356, Average Loss info_nce_loss: 0.0356, Avg Iteration Time = 0.5764 seconds\n",
            "2024-05-27 20:47:51,719 - INFO - Epoch: 9 / 10, Train Batch: 2000, Average Loss: 0.0380, Average Loss info_nce_loss: 0.0380, Avg Iteration Time = 0.5764 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:54<00:00, 62.32it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:44<00:00,  1.32s/it]\n",
            "2024-05-27 21:08:11,077 - INFO - Precision: 0.4848788080942851 | Recall: 0.4843223633065561 | F1: 0.4846004259653672\n",
            "2024-05-27 21:08:11,102 - INFO - Epoch: 9 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4843, Avg Iteration Time = 0.3404 seconds\n",
            "2024-05-27 21:08:11,102 - INFO - Epoch 9 completed in 2373.4133 seconds\n",
            "2024-05-27 21:08:11,736 - INFO - Epoch: 10 / 10, Train Batch: 0, Average Loss: 0.0001, Average Loss info_nce_loss: 0.0001, Avg Iteration Time = 0.0006 seconds\n",
            "2024-05-27 21:17:48,602 - INFO - Epoch: 10 / 10, Train Batch: 1000, Average Loss: 0.0324, Average Loss info_nce_loss: 0.0324, Avg Iteration Time = 0.5765 seconds\n",
            "2024-05-27 21:27:25,313 - INFO - Epoch: 10 / 10, Train Batch: 2000, Average Loss: 0.0339, Average Loss info_nce_loss: 0.0339, Avg Iteration Time = 0.5764 seconds\n",
            "Encoding all queries: 100%|██████████| 3377/3377 [00:52<00:00, 64.05it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [13:48<00:00,  1.33s/it]\n",
            "2024-05-27 21:47:47,117 - INFO - Precision: 0.47750954870767975 | Recall: 0.4766964054344205 | F1: 0.4771026306039274\n",
            "2024-05-27 21:47:47,139 - INFO - Epoch: 10 / 10, Validation, Average Loss: 0.0000, Average Loss info_nce_loss: 0.0000, Recall: 0.4767, Avg Iteration Time = 0.3398 seconds\n",
            "2024-05-27 21:47:47,140 - INFO - Epoch 10 completed in 2376.0369 seconds\n"
          ]
        }
      ],
      "source": [
        "try_train(\n",
        "    validation_dataset=dataset['validation'],\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    tokenizer=tokenizer,\n",
        "    query_encoder=query_encoder,\n",
        "    sentence_encoder=sentence_encoder,\n",
        "    num_epochs=10,\n",
        "    lr=0.25*1e-4,\n",
        "    device=device,\n",
        "    should_grad_clipping=False,\n",
        "    should_compute_info_nce_loss=True,\n",
        "    should_compute_reconstruction_loss=False,\n",
        "    should_compute_kl_divergence_loss=False,\n",
        "    log=create_logger(id='train', filename=f'logs/train_classic.log')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsMJrQQdu_C"
      },
      "source": [
        "#### Train with VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "4e92cc2ce8b64f5cab9c5a75586a7757",
            "66e7474f692f4b1db2804df78cf2b3c1",
            "c590bb3e831f4e378e8dcc6bc0632eb5",
            "6109bc74d01d40d3bfcfb3523303d991",
            "93aa5cf3cd254bef860fb3046931136a",
            "96fe9374d0e542eb951beec5ea9d01f2",
            "47f036b7803c498ba7334acbf52b875e",
            "61d2322d4082436ab97b2fd922ee0849",
            "b2816d1d536647b4b1f44ffb400d8e2f",
            "4d2029cb296f4bdda8f88c0899493e10",
            "8eefef820f52407a90ec038d78da6f44",
            "f6550aa5fa204f4bb2cf71d4d8ba414d",
            "77da6b2bad3944a59344622c07315afe",
            "e09f7cbedb9f46f7922c236c867d052f",
            "b483065e64e84e3aabd4cfc687345772",
            "fdec75de59b14e9f8ed427b3e41be341",
            "75baade4202d42e8ab64f8ed89557d4d",
            "8bd666660a3743f59a1a5aa1cf970bcf",
            "f575378b3a174ec4a618ec7721468d9e",
            "051975af956a4900891b2202670bf222",
            "4655a2e241cc4f6e971e77a1ffb81211",
            "2a15a916e55a4b589ee97b7c7ecee823",
            "a9d04d3c82624bd588a0a54db0fcb626",
            "16a6480c1772489a839d714cfe3da99a",
            "41bca75562e8462286db769e42c2dcdd",
            "8a3c1a6bd9be49cd9917829ba8d9be26",
            "ca50236975b347eca2e8ceb83ad03ef5",
            "205f40180d56491db3f02be9ecae4bf1",
            "9068071e23d2400299aad1726da54804",
            "e561861ac57343b782a0ceae1f440570",
            "62167a67bb8844759b95221c03292902",
            "f30a3d06b6f84929a29379b4b35e0e0e",
            "2189b0b2f3be42a4bf75d206f448860b",
            "b2acb3a23d1644cf9b88a7dcabefa180",
            "4c6a54d1bb804a05ba512e964c55d28a",
            "6324b0b56e6346f8b22165459a83f3fb",
            "5a9b2002ec9748efbc080ba2bb7cc8a9",
            "70c66c31db8048458fe3e0ec28bfcd12",
            "ee26bc187e5b434baa9bc5d75f0a0c24",
            "f30089c691d4442dbf08060c211f8b37",
            "03232dd6540c49758834c34f05705b88",
            "ec312fd233a6487eabe16084cede56f8",
            "67bd505aa2454642afbae888791b00f4",
            "e5e0f1530fcd42c6b00fac0307fa4152",
            "01c6bbebe314425ab0a94427d2611ad5",
            "a7019e445fff4da497d3566bb97b08fe",
            "280ca4df585445e5beb1929d62d13bed",
            "999ca363e0074b8b9bcc4566d477ddba",
            "069de115e46741808d9785f597bb0b74",
            "93c1a4685187482aa8f3bcc49fd875a5",
            "705adb90225748e5824b8981bd27dcb6",
            "6921f61da02e436d8a4b0e4b4711c85b",
            "10e52ae17a5941c78c25fc21fef5ffdd",
            "361008d0f9d14cf79c721a7237e45126",
            "052af7ea60ee48ad900450552a865cb0",
            "a05f732614c14ac599874cebe21e9691",
            "800bcaeae660407882f0551de6052987",
            "5b4ff326aaf7418781400f5cec69ccc8",
            "39da96dee98a49929e42ef0f8e577761",
            "3d37ecf015af46a8a3798eb2cc4ac861",
            "edb778f661b04d929517016b397cfd0c",
            "af356a65548942358deeb41da43be38b",
            "0248529099b44eb3a35d50b585215313",
            "144ac59d998548ccb3c42ea20af3c5d4",
            "f0def0f2786c42899b41d03b42cc71a2",
            "d0f39b89555a48c095dd28224442f9fc"
          ]
        },
        "id": "lNPIF359QyRx",
        "outputId": "bf43587f-f2f3-41ed-fb27-a8d462764890"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "latent_dim = 8\n",
        "batch_size = 64\n",
        "validation_batch_size = 1\n",
        "\n",
        "train_dataloader = get_dataloader(dataset['train'], batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = get_dataloader(dataset['validation'], batch_size=validation_batch_size, shuffle=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "vocab_size = tokenizer.vocab_size\n",
        "max_length = tokenizer.model_max_length\n",
        "\n",
        "query_encoder = AutoModel.from_pretrained(model_name)\n",
        "sentence_encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "sampler_encoder = SamplerEncoder(model_name=model_name, latent_dim=latent_dim) #if not checkpoints_path else load_vae_model(sampler_encoder, checkpoints_path, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ny29BumuWSty",
        "outputId": "28519594-ed2f-417a-f005-84e4d51a687e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-16 14:37:51,490 - INFO - Logging to file logs/train_vae.log\n",
            "2024-06-16 14:37:51,491 - INFO - Training VAE for 10 epochs\n",
            "2024-06-16 14:37:51,543 - INFO - Device: cuda:5\n",
            "2024-06-16 14:37:51,597 - INFO - Batch size: 64\n",
            "2024-06-16 14:37:51,650 - INFO - Number of train iterations per epoch: 2464\n",
            "2024-06-16 14:37:51,694 - INFO - Learning rate: 2.5e-05\n",
            "2024-06-16 14:37:51,740 - INFO - Weight decay: 1e-06\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n",
            "recon_x0 torch.Size([64, 768])\n",
            "recon_x torch.Size([49152])\n",
            "target_ids0 torch.Size([64, 768])\n",
            "target_ids torch.Size([49152])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtry_train_vae\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_grad_clipping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_logger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_vae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/train_vae.log\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[25], line 128\u001b[0m, in \u001b[0;36mtry_train_vae\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_train_vae\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[43mtrain_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    130\u001b[0m         log \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[25], line 49\u001b[0m, in \u001b[0;36mtrain_vae\u001b[0;34m(train_dataloader, val_dataloader, tokenizer, sampler_encoder, num_epochs, lr, weight_decay, device, print_interval, should_grad_clipping, checkpoints_base_path, log)\u001b[0m\n\u001b[1;32m     47\u001b[0m loss, losses \u001b[38;5;241m=\u001b[39m vae_loss_fn(anchor_sentences\u001b[38;5;241m=\u001b[39manchor_batch, positive_sentences\u001b[38;5;241m=\u001b[39mpositive_batch, sampler_encoder\u001b[38;5;241m=\u001b[39msampler_encoder, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, device\u001b[38;5;241m=\u001b[39mdevice, epoch\u001b[38;5;241m=\u001b[39mepoch, warm_up_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Update running loss and example count\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     51\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m losses[key]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m losses[key] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "try_train_vae(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    tokenizer=tokenizer,\n",
        "    sampler_encoder=sampler_encoder,\n",
        "    num_epochs=10,\n",
        "    lr=0.25*1e-4,\n",
        "    device=device,\n",
        "    should_grad_clipping=False,\n",
        "    log=create_logger(id='train_vae', filename=f'logs/train_vae.log')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checkpoints_path = None\n",
        "# checkpoints_path = 'checkpoints/loss0.0011_vae_epoch10_20240527-220919/sampler_encoder.ckpt' #abstract vae\n",
        "checkpoints_path = 'checkpoints/loss0.0010_vae_epoch9_20240530-192302/sampler_encoder.ckpt' # description vae\n",
        "if checkpoints_path:\n",
        "    sampler_encoder = load_model(sampler_encoder, checkpoints_path, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXGFbMrE5yDG",
        "outputId": "ca8e10c5-6ee5-4941-9cc5-aceb09427fb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-31 06:48:45,838 - INFO - Logging to file logs/train_with_vae.log\n",
            "2024-05-31 06:48:45,839 - INFO - Training for 10 epochs\n",
            "2024-05-31 06:48:45,869 - INFO - Device: cuda:3\n",
            "2024-05-31 06:48:45,872 - INFO - Batch size: 64\n",
            "2024-05-31 06:48:45,876 - INFO - Number of train iterations per epoch: 2464\n",
            "2024-05-31 06:48:45,879 - INFO - Learning rate: 2.5e-05\n",
            "2024-05-31 06:48:45,883 - INFO - Weight decay: 1e-06\n",
            "2024-05-31 07:21:26,374 - INFO - Epoch: 1 / 10, Train Batch: 1000, Average Loss: 1.1632, Average Loss info_nce_loss: 1.1591, Average Loss kl_loss: 0.0041, Avg Iteration Time = 1.9599 seconds\n",
            "2024-05-31 07:52:20,727 - INFO - Epoch: 1 / 10, Train Batch: 2000, Average Loss: 1.0495, Average Loss info_nce_loss: 1.0494, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8540 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 64.24it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:49<00:00,  1.33s/it]\n",
            "2024-05-31 08:23:21,857 - INFO - Precision: 0.42188947778066044 | Recall: 0.42138970125495134 | F1: 0.42163944141941695\n",
            "2024-05-31 08:23:21,880 - INFO - Epoch: 1 / 10, Validation, Average Loss: 1.9496, Average Loss info_nce_loss: 1.9496, Average Loss kl_loss: 0.0000, Recall: 0.4214, Avg Iteration Time = 0.9787 seconds\n",
            "2024-05-31 08:23:42,879 - INFO - Saved model with recall 0.4214 at epoch 1 in folder checkpoints/recall0.4214_vae_epoch1_20240531-064845\n",
            "2024-05-31 08:23:42,880 - INFO - Epoch 1 completed in 5696.9462 seconds\n",
            "2024-05-31 08:54:33,791 - INFO - Epoch: 2 / 10, Train Batch: 1000, Average Loss: 2.9138, Average Loss info_nce_loss: 2.9135, Average Loss kl_loss: 0.0003, Avg Iteration Time = 1.8505 seconds\n",
            "2024-05-31 09:25:23,922 - INFO - Epoch: 2 / 10, Train Batch: 2000, Average Loss: 1.0139, Average Loss info_nce_loss: 1.0135, Average Loss kl_loss: 0.0004, Avg Iteration Time = 1.8497 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:53<00:00, 63.60it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [14:00<00:00,  1.34s/it]\n",
            "2024-05-31 09:56:37,988 - INFO - Precision: 0.4677987468021208 | Recall: 0.46707141006182207 | F1: 0.4674347954949615\n",
            "2024-05-31 09:56:38,017 - INFO - Epoch: 2 / 10, Validation, Average Loss: 1.9772, Average Loss info_nce_loss: 1.9772, Average Loss kl_loss: 0.0000, Recall: 0.4671, Avg Iteration Time = 0.9798 seconds\n",
            "2024-05-31 09:56:51,416 - INFO - Saved model with recall 0.4671 at epoch 2 in folder checkpoints/recall0.4671_vae_epoch2_20240531-064845\n",
            "2024-05-31 09:56:51,417 - INFO - Epoch 2 completed in 5588.5346 seconds\n",
            "2024-05-31 10:27:51,961 - INFO - Epoch: 3 / 10, Train Batch: 1000, Average Loss: 2.9309, Average Loss info_nce_loss: 2.9306, Average Loss kl_loss: 0.0003, Avg Iteration Time = 1.8601 seconds\n",
            "2024-05-31 10:59:39,691 - INFO - Epoch: 3 / 10, Train Batch: 2000, Average Loss: 0.9951, Average Loss info_nce_loss: 0.9948, Average Loss kl_loss: 0.0003, Avg Iteration Time = 1.9072 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 63.90it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:56<00:00,  1.34s/it]\n",
            "2024-05-31 11:30:47,840 - INFO - Precision: 0.4771302444634047 | Recall: 0.4761411172398475 | F1: 0.4766351676857513\n",
            "2024-05-31 11:30:47,935 - INFO - Epoch: 3 / 10, Validation, Average Loss: 1.9202, Average Loss info_nce_loss: 1.9202, Average Loss kl_loss: 0.0000, Recall: 0.4761, Avg Iteration Time = 0.9783 seconds\n",
            "2024-05-31 11:31:21,095 - INFO - Saved model with recall 0.4761 at epoch 3 in folder checkpoints/recall0.4761_vae_epoch3_20240531-064845\n",
            "2024-05-31 11:31:21,096 - INFO - Epoch 3 completed in 5669.6790 seconds\n",
            "2024-05-31 12:02:13,094 - INFO - Epoch: 4 / 10, Train Batch: 1000, Average Loss: 2.8570, Average Loss info_nce_loss: 2.8568, Average Loss kl_loss: 0.0002, Avg Iteration Time = 1.8515 seconds\n",
            "2024-05-31 12:36:53,276 - INFO - Epoch: 4 / 10, Train Batch: 2000, Average Loss: 0.9831, Average Loss info_nce_loss: 0.9828, Average Loss kl_loss: 0.0002, Avg Iteration Time = 2.0797 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 63.74it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:45<00:00,  1.32s/it]\n",
            "2024-05-31 13:07:58,516 - INFO - Precision: 0.4861960348341671 | Recall: 0.4856920741865028 | F1: 0.48594392384903146\n",
            "2024-05-31 13:07:58,539 - INFO - Epoch: 4 / 10, Validation, Average Loss: 1.8721, Average Loss info_nce_loss: 1.8721, Average Loss kl_loss: 0.0000, Recall: 0.4857, Avg Iteration Time = 0.9865 seconds\n",
            "2024-05-31 13:08:16,853 - INFO - Saved model with recall 0.4857 at epoch 4 in folder checkpoints/recall0.4857_vae_epoch4_20240531-064845\n",
            "2024-05-31 13:08:16,854 - INFO - Epoch 4 completed in 5815.7577 seconds\n",
            "2024-05-31 13:39:08,438 - INFO - Epoch: 5 / 10, Train Batch: 1000, Average Loss: 2.7965, Average Loss info_nce_loss: 2.7964, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8513 seconds\n",
            "2024-05-31 14:09:58,713 - INFO - Epoch: 5 / 10, Train Batch: 2000, Average Loss: 0.9746, Average Loss info_nce_loss: 0.9745, Average Loss kl_loss: 0.0002, Avg Iteration Time = 1.8501 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 63.83it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:56<00:00,  1.34s/it]\n",
            "2024-05-31 14:41:05,753 - INFO - Precision: 0.481378543635353 | Recall: 0.48087957650020363 | F1: 0.4811289307011371\n",
            "2024-05-31 14:41:05,782 - INFO - Epoch: 5 / 10, Validation, Average Loss: 1.8921, Average Loss info_nce_loss: 1.8920, Average Loss kl_loss: 0.0000, Recall: 0.4809, Avg Iteration Time = 0.9773 seconds\n",
            "2024-05-31 14:41:05,783 - INFO - Epoch 5 completed in 5568.9279 seconds\n",
            "2024-05-31 15:11:59,252 - INFO - Epoch: 6 / 10, Train Batch: 1000, Average Loss: 2.8149, Average Loss info_nce_loss: 2.8148, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8533 seconds\n",
            "2024-05-31 15:43:02,080 - INFO - Epoch: 6 / 10, Train Batch: 2000, Average Loss: 0.9678, Average Loss info_nce_loss: 0.9677, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8626 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:53<00:00, 63.46it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [14:08<00:00,  1.36s/it]\n",
            "2024-05-31 16:14:21,946 - INFO - Precision: 0.48930729031540715 | Recall: 0.48872764965016846 | F1: 0.4890172982183205\n",
            "2024-05-31 16:14:21,972 - INFO - Epoch: 6 / 10, Validation, Average Loss: 1.8322, Average Loss info_nce_loss: 1.8322, Average Loss kl_loss: 0.0000, Recall: 0.4887, Avg Iteration Time = 0.9775 seconds\n",
            "2024-05-31 16:14:35,402 - INFO - Saved model with recall 0.4887 at epoch 6 in folder checkpoints/recall0.4887_vae_epoch6_20240531-064845\n",
            "2024-05-31 16:14:35,403 - INFO - Epoch 6 completed in 5609.6196 seconds\n",
            "2024-05-31 16:45:27,188 - INFO - Epoch: 7 / 10, Train Batch: 1000, Average Loss: 2.7437, Average Loss info_nce_loss: 2.7437, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8516 seconds\n",
            "2024-05-31 17:16:25,932 - INFO - Epoch: 7 / 10, Train Batch: 2000, Average Loss: 0.9634, Average Loss info_nce_loss: 0.9633, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8586 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 64.31it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:28<00:00,  1.29s/it]\n",
            "2024-05-31 17:47:04,409 - INFO - Precision: 0.48335804299481094 | Recall: 0.4827675563617517 | F1: 0.4830626192284185\n",
            "2024-05-31 17:47:04,433 - INFO - Epoch: 7 / 10, Validation, Average Loss: 1.8180, Average Loss info_nce_loss: 1.8180, Average Loss kl_loss: 0.0000, Recall: 0.4828, Avg Iteration Time = 0.9767 seconds\n",
            "2024-05-31 17:47:04,434 - INFO - Epoch 7 completed in 5549.0309 seconds\n",
            "2024-05-31 18:20:06,077 - INFO - Epoch: 8 / 10, Train Batch: 1000, Average Loss: 2.7251, Average Loss info_nce_loss: 2.7250, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.9815 seconds\n",
            "2024-05-31 18:50:59,947 - INFO - Epoch: 8 / 10, Train Batch: 2000, Average Loss: 0.9602, Average Loss info_nce_loss: 0.9601, Average Loss kl_loss: 0.0000, Avg Iteration Time = 1.8537 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:53<00:00, 63.14it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:31<00:00,  1.30s/it]\n",
            "2024-05-31 19:21:42,293 - INFO - Precision: 0.49065697760640664 | Recall: 0.4899122644652575 | F1: 0.4902843382421043\n",
            "2024-05-31 19:21:42,317 - INFO - Epoch: 8 / 10, Validation, Average Loss: 1.7845, Average Loss info_nce_loss: 1.7845, Average Loss kl_loss: 0.0000, Recall: 0.4899, Avg Iteration Time = 0.9770 seconds\n",
            "2024-05-31 19:21:55,779 - INFO - Saved model with recall 0.4899 at epoch 8 in folder checkpoints/recall0.4899_vae_epoch8_20240531-064845\n",
            "2024-05-31 19:21:55,780 - INFO - Epoch 8 completed in 5691.3453 seconds\n",
            "2024-05-31 19:53:29,529 - INFO - Epoch: 9 / 10, Train Batch: 1000, Average Loss: 2.6851, Average Loss info_nce_loss: 2.6851, Average Loss kl_loss: 0.0001, Avg Iteration Time = 1.8936 seconds\n",
            "2024-05-31 20:24:29,120 - INFO - Epoch: 9 / 10, Train Batch: 2000, Average Loss: 0.9570, Average Loss info_nce_loss: 0.9570, Average Loss kl_loss: 0.0000, Avg Iteration Time = 1.8594 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:53<00:00, 63.00it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:30<00:00,  1.30s/it]\n",
            "2024-05-31 20:55:13,507 - INFO - Precision: 0.4857936654936099 | Recall: 0.4854699589086736 | F1: 0.48563175825803584\n",
            "2024-05-31 20:55:13,530 - INFO - Epoch: 9 / 10, Validation, Average Loss: 1.7479, Average Loss info_nce_loss: 1.7479, Average Loss kl_loss: 0.0000, Recall: 0.4855, Avg Iteration Time = 0.9800 seconds\n",
            "2024-05-31 20:55:13,531 - INFO - Epoch 9 completed in 5597.7501 seconds\n",
            "2024-05-31 21:26:04,536 - INFO - Epoch: 10 / 10, Train Batch: 1000, Average Loss: 2.6421, Average Loss info_nce_loss: 2.6420, Average Loss kl_loss: 0.0000, Avg Iteration Time = 1.8508 seconds\n",
            "2024-05-31 21:56:53,565 - INFO - Epoch: 10 / 10, Train Batch: 2000, Average Loss: 0.9545, Average Loss info_nce_loss: 0.9544, Average Loss kl_loss: 0.0000, Avg Iteration Time = 1.8489 seconds\n",
            "Encoding all queries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3377/3377 [00:52<00:00, 64.06it/s]\n",
            "Predict matching queries: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [13:30<00:00,  1.30s/it]\n",
            "2024-05-31 22:27:34,544 - INFO - Precision: 0.4850337111950804 | Recall: 0.48469255543627143 | F1: 0.48486307330531225\n",
            "2024-05-31 22:27:34,568 - INFO - Epoch: 10 / 10, Validation, Average Loss: 1.7215, Average Loss info_nce_loss: 1.7215, Average Loss kl_loss: 0.0000, Recall: 0.4847, Avg Iteration Time = 0.9777 seconds\n",
            "2024-05-31 22:27:34,568 - INFO - Epoch 10 completed in 5541.0364 seconds\n"
          ]
        }
      ],
      "source": [
        "try_train(\n",
        "    validation_dataset=dataset['validation'],\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    tokenizer=tokenizer,\n",
        "    query_encoder=query_encoder,\n",
        "    sentence_encoder=sentence_encoder,\n",
        "    sampler_encoder=sampler_encoder,\n",
        "    num_epochs=10,\n",
        "    lr=0.25*1e-4,\n",
        "    device=device,\n",
        "    should_grad_clipping=False,\n",
        "    should_compute_info_nce_loss=True,\n",
        "    should_compute_reconstruction_loss=False,\n",
        "    should_compute_kl_divergence_loss=True,\n",
        "    log=create_logger(id='train', filename=f'logs/train_with_vae.log'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon May 27 08:46:19 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:0E:00.0 Off |                    0 |\n",
            "| N/A   34C    P0             68W /  400W |    8900MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:13:00.0 Off |                    0 |\n",
            "| N/A   44C    P0            126W /  400W |   44585MiB /  81920MiB |     85%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:49:00.0 Off |                    0 |\n",
            "| N/A   29C    P0             61W /  400W |       5MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:4F:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             61W /  400W |       5MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   4  NVIDIA A100-SXM4-80GB          Off |   00000000:91:00.0 Off |                    0 |\n",
            "| N/A   38C    P0             69W /  400W |   80889MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   5  NVIDIA A100-SXM4-80GB          Off |   00000000:97:00.0 Off |                    0 |\n",
            "| N/A   42C    P0            214W /  400W |   49715MiB /  81920MiB |     78%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   6  NVIDIA A100-SXM4-80GB          Off |   00000000:CD:00.0 Off |                    0 |\n",
            "| N/A   39C    P0             87W /  400W |   20595MiB /  81920MiB |     96%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   7  NVIDIA A100-SXM4-80GB          Off |   00000000:D2:00.0 Off |                    0 |\n",
            "| N/A   42C    P0            332W /  400W |   19687MiB /  81920MiB |     95%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A   2240825      C   ...orge/envs/vec2text_inter/bin/python       7792MiB |\n",
            "|    0   N/A  N/A   2863096      C   ...imoa/miniconda3/envs/biu/bin/python       1092MiB |\n",
            "|    1   N/A  N/A   2702519      C   python                                      44574MiB |\n",
            "|    4   N/A  N/A   2863096      C   ...imoa/miniconda3/envs/biu/bin/python      80880MiB |\n",
            "|    5   N/A  N/A   2860995      C   python                                      49700MiB |\n",
            "|    6   N/A  N/A   2820256      C   ...zoh/miniconda3/envs/igcs/bin/python      20568MiB |\n",
            "|    7   N/A  N/A   2820257      C   ...zoh/miniconda3/envs/igcs/bin/python      19660MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "anchor_batch = dataset['train'][42]['good']\n",
        "sampler_encoder.to(device)\n",
        "x_recon, mu, log_var, encoded = sampler_encode(sampler_encoder, tokenizer, anchor_batch, device)\n",
        "x = encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2751.0098, device='cuda:0', grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = nn.functional.mse_loss(x_recon, x, reduction='sum') -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reconstructed =  torch.Size([8, 768])\n",
            "encoded =  torch.Size([8, 768])\n",
            "-------------------\n",
            "log_var =  torch.Size([8, 8])\n",
            "mu =  torch.Size([8, 8])\n"
          ]
        }
      ],
      "source": [
        "anchor_sentences = dataset['train'][42]['good']\n",
        "reconstructed, mu, log_var, encoded = sampler_encode(sampler_encoder, tokenizer, anchor_sentences, device)\n",
        "print(\"reconstructed = \", reconstructed.shape)\n",
        "print(\"encoded = \", encoded.shape)\n",
        "bce_loss = nn.functional.mse_loss(x_recon, x, reduction='sum')\n",
        "print(\"-------------------\")\n",
        "print(\"log_var = \", log_var.shape)\n",
        "print(\"mu = \", mu.shape)\n",
        "kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "loss = bce_loss + kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Internal IPv4 Address for dgx01: 127.0.1.1\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "\n",
        "try:\n",
        "    hostname = socket.gethostname()\n",
        "    ipv4_address = socket.gethostbyname(hostname)\n",
        "    print(f\"Internal IPv4 Address for {hostname}: {ipv4_address}\")\n",
        "except socket.gaierror:\n",
        "    print(\"There was an error resolving the hostname.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 <torch.utils.data.dataloader.DataLoader object at 0x7fdad20d0280>\n"
          ]
        }
      ],
      "source": [
        "for i, x in enumerate(train_dataloader):\n",
        "    print(i, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZe0avWXitzp",
        "outputId": "2ac39483-ce54-4081-fd37-e6de135d90c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding all queries: 100%|██████████| 3377/3377 [01:30<00:00, 37.49it/s]\n",
            "Predict matching queries: 100%|██████████| 625/625 [21:29<00:00,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.1934383688600556 | Recall: 0.19316625328545514 | F1: 0.19330221530710529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.1934383688600556, 0.19316625328545514, 0.19330221530710529)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(data=dataset['validation'], sentence_encoder=sentence_encoder, query_encoder=query_encoder, tokenizer=tokenizer, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0MIDOt36JIm"
      },
      "source": [
        "## Sandbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 4 has a total capacity of 79.14 GiB of which 104.75 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 77.56 GiB is allocated by PyTorch, and 1001.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m sentence_inputs \u001b[38;5;241m=\u001b[39m tokenizer(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# sentence_inputs = tokenizer(batch['sentence'], padding=True, max_length=128, truncation=True, add_special_tokens=True, return_tensors=\"pt\").to(device)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m sentence_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msentence_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msentence_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:270\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/biu/lib/python3.10/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 4 has a total capacity of 79.14 GiB of which 104.75 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 77.56 GiB is allocated by PyTorch, and 1001.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "batch_size = 64\n",
        "\n",
        "dataloader = get_dataloader(dataset['train'], batch_size=batch_size, shuffle=True)\n",
        "batch = next(iter(dataloader))\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "abstract_encoder = AutoModel.from_pretrained(model_name) \n",
        "abstract_encoder.to(device)\n",
        "abstract_encoder.train()\n",
        "\n",
        "sentence_encoder = AutoModel.from_pretrained(model_name)\n",
        "sentence_encoder.to(device)\n",
        "sentence_encoder.train()\n",
        "\n",
        "abstract_inputs = tokenizer(batch['good'], padding=\"max_length\", truncation=True, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "# abstract_inputs = tokenizer(batch['good'], padding=True, max_length=128, truncation=True, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "abstract_outputs = abstract_encoder(**abstract_inputs)\n",
        "\n",
        "sentence_inputs = tokenizer(batch['sentence'], padding=\"max_length\", truncation=True, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "# sentence_inputs = tokenizer(batch['sentence'], padding=True, max_length=128, truncation=True, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
        "sentence_outputs = sentence_encoder(**sentence_inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz4FIs8n6uu9",
        "outputId": "485714a3-2403-411b-cad2-042e456e8ea2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sentence_encoder' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m best_recall \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     17\u001b[0m optimizer_query \u001b[38;5;241m=\u001b[39m AdamW(query_encoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[0;32m---> 18\u001b[0m optimizer_sentence \u001b[38;5;241m=\u001b[39m AdamW(\u001b[43msentence_encoder\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     19\u001b[0m optimizer_sampled \u001b[38;5;241m=\u001b[39m AdamW(sampler_encoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# num_epochs should be defined by you\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sentence_encoder' is not defined"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "lr = 0.25*1e-4\n",
        "weight_decay = 1e-6\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print_interval = 1000\n",
        "should_grad_clipping = True\n",
        "timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
        "checkpoints_base_path = \"checkpoints\"\n",
        "\n",
        "total_loss = 0\n",
        "total_info_nce_loss = 0\n",
        "total_nll_loss = 0\n",
        "total_kl_loss = 0\n",
        "examples_processed = 0\n",
        "best_recall = 0.0\n",
        "\n",
        "optimizer_query = AdamW(query_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "optimizer_sentence = AdamW(sentence_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "optimizer_sampled = AdamW(sampler_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "for epoch in range(num_epochs):  # num_epochs should be defined by you\n",
        "    query_encoder.train()\n",
        "    sentence_encoder.train()\n",
        "    sampler_encoder.train()\n",
        "\n",
        "    query_encoder.to(device)\n",
        "    sentence_encoder.to(device)\n",
        "    sampler_encoder.to(device)\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        sentences_batch = batch['sentence']\n",
        "        positives_batch = batch['good']\n",
        "\n",
        "        outputs_query = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=sentences_batch, device=device)\n",
        "        outputs_sentence = encode(encoder=query_encoder, tokenizer=tokenizer, s=positives_batch, device=device)\n",
        "        outputs_samples, mu, log_var = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=positives_batch, device=device)\n",
        "\n",
        "        loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "\n",
        "        optimizer_query.zero_grad()\n",
        "        optimizer_sentence.zero_grad()\n",
        "        optimizer_sampled.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if should_grad_clipping:\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(query_encoder.parameters(), max_norm=1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(sentence_encoder.parameters(), max_norm=1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(sampler_encoder.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Backpropagation for models\n",
        "        optimizer_query.step()\n",
        "        optimizer_sentence.step()\n",
        "        optimizer_sampled.step()\n",
        "\n",
        "        # Update running loss and example count\n",
        "        total_loss += loss.item()\n",
        "        total_info_nce_loss += info_nce_loss.item()\n",
        "        total_nll_loss += nll_loss.item()\n",
        "        total_kl_loss += kl_divergence_loss.item()\n",
        "        examples_processed += len(batch)\n",
        "\n",
        "        if batch_idx % print_interval == 0:\n",
        "            average_loss = total_loss / examples_processed\n",
        "            average_info_nce_loss = total_info_nce_loss / examples_processed\n",
        "            average_nll_loss = total_nll_loss / examples_processed\n",
        "            average_kl_loss = total_kl_loss / len(val_dataloader)\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Average Loss: {average_loss:.4f}, Average InfoNCE Loss: {average_info_nce_loss:.4f}, Average NLL Loss: {average_nll_loss:.4f}, Average KL Divergence Loss: {average_kl_loss:.4f}\")\n",
        "\n",
        "            # Reset counters\n",
        "            total_loss = 0\n",
        "            total_info_nce_loss = 0\n",
        "            total_nll_loss = 0\n",
        "            examples_processed = 0\n",
        "\n",
        "    # validation\n",
        "    query_encoder.eval()\n",
        "    sentence_encoder.eval()\n",
        "    sampler_encoder.eval()\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        total_loss = 0\n",
        "        total_info_nce_loss = 0\n",
        "        total_nll_loss = 0\n",
        "        total_kl_loss = 0\n",
        "\n",
        "        for batch in val_dataloader:\n",
        "            # Validation step\n",
        "            outputs_query = encode(encoder=query_encoder, tokenizer=tokenizer, s=batch['sentence'], device=device)\n",
        "            outputs_sentence = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=batch['good'], device=device)\n",
        "            outputs_samples, mu, log_var = sampler_encode(encoder=sampler_encoder, tokenizer=tokenizer, s=batch['good'], device=device)\n",
        "\n",
        "            loss, info_nce_loss, nll_loss, kl_divergence_loss = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=mu, log_var=log_var)\n",
        "\n",
        "            # Update running loss and example count\n",
        "            total_loss += loss.item()\n",
        "            total_info_nce_loss += info_nce_loss.item()\n",
        "            total_nll_loss += nll_loss.item()\n",
        "            total_kl_loss += kl_divergence_loss.item()\n",
        "\n",
        "        average_loss = total_loss / len(val_dataloader)\n",
        "        average_info_nce_loss = total_info_nce_loss / len(val_dataloader)\n",
        "        average_nll_loss = total_nll_loss / len(val_dataloader)\n",
        "        average_kl_loss = total_kl_loss / len(val_dataloader)\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Average Validation Loss: {average_loss:.4f}, Average Validation InfoNCE Loss: {average_info_nce_loss:.4f}, Average Validation NLL Loss: {average_nll_loss:.4f}, Average Validation KL Divergence Loss: {average_kl_loss:.4f}\")\n",
        "\n",
        "        _, recall, _ = evaluate(data=dataset['validation'], sentence_encoder=sentence_encoder, query_encoder=query_encoder, tokenizer=tokenizer, device=device)\n",
        "        if recall > best_recall:\n",
        "            best_recall = recall\n",
        "            os.makedirs(checkpoints_base_path, exist_ok=True)\n",
        "            checkpoints_path = os.path.join(checkpoints_base_path, f'recall{recall:.4f}_epoch{epoch+1}_{timestamp}')\n",
        "            torch.save({\"model_name\": query_encoder.config.name_or_path, \"state_dict\": query_encoder.state_dict()}, os.path.join(checkpoints_path, \"query_encoder.ckpt\"))\n",
        "            torch.save({\"model_name\": sentence_encoder.config.name_or_path, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sentence_encoder.ckpt\"))\n",
        "            torch.save({\"model_name\": sampler_encoder.encoder.config.name_or_path, \"latent_dim\": sampler_encoder.latent_dim, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sampler_encoder.ckpt\"))\n",
        "            print(f'Saved model with recall {recall:.4f} at epoch {epoch+1} in folder {checkpoints_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzd22jAAxBNB",
        "outputId": "a6676337-e324-44c6-b4e6-74581233c33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recall > best_recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0djeKdw6ga",
        "outputId": "9bfd115c-0518-4fd9-8163-b2d75ed006af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model with recall 0.0002 at epoch 1 in folder checkpoints/recall0.0002_epoch1_20240225-132429\n"
          ]
        }
      ],
      "source": [
        "if recall > best_recall or True:\n",
        "        best_recall = recall\n",
        "        checkpoints_path = os.path.join(checkpoints_base_path, f'recall{recall:.4f}_epoch{epoch+1}_{timestamp}')\n",
        "        os.makedirs(checkpoints_path, exist_ok=True)\n",
        "        torch.save({\"model_name\": query_encoder.config.name_or_path, \"state_dict\": query_encoder.state_dict()}, os.path.join(checkpoints_path, \"query_enoder.ckpt\"))\n",
        "        torch.save({\"model_name\": sentence_encoder.config.name_or_path, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sentence_encoder.ckpt\"))\n",
        "        torch.save({\"model_name\": sampler_encoder.encoder.config.name_or_path, \"latent_dim\": sampler_encoder.latent_dim, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sampler_encoder.ckpt\"))\n",
        "        print(f'Saved model with recall {recall:.4f} at epoch {epoch+1} in folder {checkpoints_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov-Wo804-Jcx",
        "outputId": "a11a3cfa-ab09-429d-fcda-af6a1c6fa848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.00018508236165093466 | Recall: 0.00018509606485766112 | F1: 0.00018508921300066633\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.00018508236165093466, 0.00018509606485766112, 0.00018508921300066633)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(data=dataset['validation'], sentence_encoder=sentence_encoder, query_encoder=query_encoder, tokenizer=tokenizer, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKF-DnM0eZ00"
      },
      "source": [
        "#### Train classic setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT9WIrufJTv-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 4\n",
        "lr = 0.25*1e-4\n",
        "weight_decay = 1e-6\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print_interval = 1000\n",
        "should_grad_clipping = True\n",
        "timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
        "checkpoints_base_path = \"checkpoints\"\n",
        "\n",
        "total_loss = 0\n",
        "total_info_nce_loss = 0\n",
        "total_nll_loss = 0\n",
        "total_kl_loss = 0\n",
        "examples_processed = 0\n",
        "best_recall = 0.0\n",
        "\n",
        "optimizer_query = AdamW(query_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "optimizer_sentence = AdamW(sentence_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "for epoch in range(num_epochs):  # num_epochs should be defined by you\n",
        "    query_encoder.train()\n",
        "    sentence_encoder.train()\n",
        "\n",
        "    query_encoder.to(device)\n",
        "    sentence_encoder.to(device)\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        sentences_batch = batch['sentence']\n",
        "        positives_batch = batch['good']\n",
        "\n",
        "        outputs_query = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=sentences_batch, device=device)\n",
        "        outputs_sentence = encode(encoder=query_encoder, tokenizer=tokenizer, s=positives_batch, device=device)\n",
        "\n",
        "        loss, info_nce_loss, nll_loss, _ = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=None, log_var=None)\n",
        "\n",
        "        optimizer_query.zero_grad()\n",
        "        optimizer_sentence.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if should_grad_clipping:\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(query_encoder.parameters(), max_norm=1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(sentence_encoder.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Backpropagation for models\n",
        "        optimizer_query.step()\n",
        "        optimizer_sentence.step()\n",
        "\n",
        "        # Update running loss and example count\n",
        "        total_loss += loss.item()\n",
        "        total_info_nce_loss += info_nce_loss.item()\n",
        "        total_nll_loss += nll_loss.item()\n",
        "        total_kl_loss += kl_divergence_loss.item() if (mu and log_var) else 0\n",
        "        examples_processed += len(batch)\n",
        "\n",
        "        if batch_idx % print_interval == 0:\n",
        "            average_loss = total_loss / examples_processed\n",
        "            average_info_nce_loss = total_info_nce_loss / examples_processed\n",
        "            average_nll_loss = total_nll_loss / examples_processed\n",
        "            average_kl_loss = total_kl_loss / len(val_dataloader)\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Average Loss: {average_loss:.4f}, Average InfoNCE Loss: {average_info_nce_loss:.4f}, Average NLL Loss: {average_nll_loss:.4f}, Average KL Divergence Loss: {average_kl_loss:.4f}\")\n",
        "\n",
        "            # Reset counters\n",
        "            total_loss = 0\n",
        "            total_info_nce_loss = 0\n",
        "            total_nll_loss = 0\n",
        "            examples_processed = 0\n",
        "\n",
        "    # validation\n",
        "    query_encoder.eval()\n",
        "    sentence_encoder.eval()\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        total_loss = 0\n",
        "        total_info_nce_loss = 0\n",
        "        total_nll_loss = 0\n",
        "        total_kl_loss = 0\n",
        "\n",
        "        for batch in val_dataloader:\n",
        "            # Validation step\n",
        "            outputs_query = encode(encoder=query_encoder, tokenizer=tokenizer, s=batch['sentence'], device=device)\n",
        "            outputs_sentence = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=batch['good'], device=device)\n",
        "\n",
        "            loss, info_nce_loss, nll_loss, _ = compute_loss(outputs_query=outputs_query, outputs_sentence=outputs_sentence, outputs_samples=outputs_samples, mu=None, log_var=None)\n",
        "\n",
        "            # Update running loss and example count\n",
        "            total_loss += loss.item()\n",
        "            total_info_nce_loss += info_nce_loss.item()\n",
        "            total_nll_loss += nll_loss.item()\n",
        "            total_kl_loss += 0\n",
        "\n",
        "        average_loss = total_loss / len(val_dataloader)\n",
        "        average_info_nce_loss = total_info_nce_loss / len(val_dataloader)\n",
        "        average_nll_loss = total_nll_loss / len(val_dataloader)\n",
        "        average_kl_loss = total_kl_loss / len(val_dataloader)\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Average Validation Loss: {average_loss:.4f}, Average Validation InfoNCE Loss: {average_info_nce_loss:.4f}, Average Validation NLL Loss: {average_nll_loss:.4f}, Average Validation KL Divergence Loss: {average_kl_loss:.4f}\")\n",
        "\n",
        "        _, recall, _ = evaluate(data=dataset['validation'], sentence_encoder=sentence_encoder, query_encoder=query_encoder, tokenizer=tokenizer, device=device)\n",
        "        if recall > best_recall:\n",
        "            best_recall = recall\n",
        "            checkpoints_path = os.path.join(checkpoints_base_path, f'recall{recall:.4f}_epoch{epoch+1}_{timestamp}')\n",
        "            torch.save({\"model_name\": query_encoder.config.name_or_path, \"state_dict\": query_encoder.state_dict()}, os.path.join(checkpoints_path, \"query_enoder.ckpt\"))\n",
        "            torch.save({\"model_name\": sentence_encoder.config.name_or_path, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sentence_encoder.ckpt\"))\n",
        "            torch.save({\"model_name\": sampler_encoder.encoder.config.name_or_path, \"latent_dim\": sampler_encoder.latent_dim, \"state_dict\": sentence_encoder.state_dict()}, os.path.join(checkpoints_path, \"sampler_encoder.ckpt\"))\n",
        "            print(f'Saved model with recall {recall:.4f} at epoch {epoch+1} in folder {checkpoints_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4hgVJn5-2km"
      },
      "outputs": [],
      "source": [
        "lr = 0.25*1e-4\n",
        "weight_decay = 1e-6\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer_query = AdamW(query_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "optimizer_sentence = AdamW(sentence_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "optimizer_sampled = AdamW(sampler_encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "        # Move batch to GPU\n",
        "        # batch = {k: v.to(device) for k, v in batch.items() if k in ['sentence', 'good']}\n",
        "        outputs_query = encode(encoder=query_encoder, tokenizer=tokenizer, s=batch['sentence'], device=device)\n",
        "        outputs_sentence = encode(encoder=sentence_encoder, tokenizer=tokenizer, s=batch['good'], device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD06P3CT-JzU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "15wyXFALBDMx",
        "SYgN1kuWA6w5",
        "TFCt9hRR6ErV"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01c6bbebe314425ab0a94427d2611ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7019e445fff4da497d3566bb97b08fe",
              "IPY_MODEL_280ca4df585445e5beb1929d62d13bed",
              "IPY_MODEL_999ca363e0074b8b9bcc4566d477ddba"
            ],
            "layout": "IPY_MODEL_069de115e46741808d9785f597bb0b74"
          }
        },
        "0210c55041684510b73bb026880ec52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c58b8fdcce44b998739bbb283ce5df6",
            "max": 3609781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_818c2025435d49398df11561b3f1430e",
            "value": 3609781
          }
        },
        "0248529099b44eb3a35d50b585215313": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03232dd6540c49758834c34f05705b88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051524850dbd405285321482a5548af1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051975af956a4900891b2202670bf222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "052af7ea60ee48ad900450552a865cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069de115e46741808d9785f597bb0b74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab6754e3044464bbc22478ecd655677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5228b76b87a840c28950056d3a81de88",
              "IPY_MODEL_76c47c7694b34adb88ae24a7e12f5ee1",
              "IPY_MODEL_0d8c9ed8e89a4151bf7b9afed1b58827"
            ],
            "layout": "IPY_MODEL_24f6ea6b263f4a46a2e34d985514815c"
          }
        },
        "0b9e862a88064c07afc996af53574117": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c58b8fdcce44b998739bbb283ce5df6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8c9ed8e89a4151bf7b9afed1b58827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a6b01eba3145b597fe2135ae9fc135",
            "placeholder": "​",
            "style": "IPY_MODEL_c268e03652d44434b97b31097c52bdb5",
            "value": " 2.30M/2.30M [00:00&lt;00:00, 6.57MB/s]"
          }
        },
        "10e52ae17a5941c78c25fc21fef5ffdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "144085849b6047d38b6c1d801e349640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144ac59d998548ccb3c42ea20af3c5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16a6480c1772489a839d714cfe3da99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205f40180d56491db3f02be9ecae4bf1",
            "placeholder": "​",
            "style": "IPY_MODEL_9068071e23d2400299aad1726da54804",
            "value": "vocab.json: 100%"
          }
        },
        "1c702c866daa4ecfbcff7a5d1260492a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_712c01c09d74487088d6306ba34dcc55",
              "IPY_MODEL_0210c55041684510b73bb026880ec52b",
              "IPY_MODEL_627a0ffdec5f4d8ba5cc39843ab554c7"
            ],
            "layout": "IPY_MODEL_2ae8fae5eba64f79a81186ecdfdd2931"
          }
        },
        "1e0ebc40534d4551afc3ef20c3f6c38d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "205f40180d56491db3f02be9ecae4bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20dab458e0e14dd6902c9e4f8d55affc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2189b0b2f3be42a4bf75d206f448860b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a6b01eba3145b597fe2135ae9fc135": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f6ea6b263f4a46a2e34d985514815c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280ca4df585445e5beb1929d62d13bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6921f61da02e436d8a4b0e4b4711c85b",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10e52ae17a5941c78c25fc21fef5ffdd",
            "value": 1355863
          }
        },
        "2a15a916e55a4b589ee97b7c7ecee823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ae8fae5eba64f79a81186ecdfdd2931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b637a518230469c94c8ecdfd0fbfa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f484d1cab9774086a8613eddcd4cbe7d",
              "IPY_MODEL_f2e0930a322d4af8bc0855304952d8ce",
              "IPY_MODEL_5f67607d38cf4dd59a66166a6eb7f2a8"
            ],
            "layout": "IPY_MODEL_ce550e7ff64143659a56700612340f3e"
          }
        },
        "331931afd31845b5a74a7fca366346b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b46a2b4ac244caacb55c219e655c73",
            "placeholder": "​",
            "style": "IPY_MODEL_38a167153ad84ae5934a56b8ebd1b841",
            "value": " 2955/0 [00:00&lt;00:00, 56836.25 examples/s]"
          }
        },
        "361008d0f9d14cf79c721a7237e45126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a167153ad84ae5934a56b8ebd1b841": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39da96dee98a49929e42ef0f8e577761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0def0f2786c42899b41d03b42cc71a2",
            "placeholder": "​",
            "style": "IPY_MODEL_d0f39b89555a48c095dd28224442f9fc",
            "value": " 499M/499M [00:29&lt;00:00, 18.8MB/s]"
          }
        },
        "3d37ecf015af46a8a3798eb2cc4ac861": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40656ab742454143a2d3142bcdb0f72f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e26a3401da4a2f85fdacafdd6e3b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41b40a79e3264a13a72c986933341dac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bca75562e8462286db769e42c2dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e561861ac57343b782a0ceae1f440570",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62167a67bb8844759b95221c03292902",
            "value": 898823
          }
        },
        "42bb9aa98ade45bda30452891441b9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762742bec18243fb88f9ce4ac22b1dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_8af50f1921b94864a63e64c8ad4dea51",
            "value": "Downloading data: 100%"
          }
        },
        "4560f59d76f544669b971ef3025a7c23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4655a2e241cc4f6e971e77a1ffb81211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f036b7803c498ba7334acbf52b875e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a71941aa5b473785c6de1c8eb6f09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a1fc9fecfd9489e9dbbb66831ac8f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3be9fc77dcf4ce6a1b9f4a64fe88ed3",
              "IPY_MODEL_503b3ec5f1114c0a85090054ac965bb6",
              "IPY_MODEL_331931afd31845b5a74a7fca366346b1"
            ],
            "layout": "IPY_MODEL_6255307b6bf5432ca5150ceef2687bde"
          }
        },
        "4c6a54d1bb804a05ba512e964c55d28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee26bc187e5b434baa9bc5d75f0a0c24",
            "placeholder": "​",
            "style": "IPY_MODEL_f30089c691d4442dbf08060c211f8b37",
            "value": "merges.txt: 100%"
          }
        },
        "4d2029cb296f4bdda8f88c0899493e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8277b9f0a24a8d992d701bc387229d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e92cc2ce8b64f5cab9c5a75586a7757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66e7474f692f4b1db2804df78cf2b3c1",
              "IPY_MODEL_c590bb3e831f4e378e8dcc6bc0632eb5",
              "IPY_MODEL_6109bc74d01d40d3bfcfb3523303d991"
            ],
            "layout": "IPY_MODEL_93aa5cf3cd254bef860fb3046931136a"
          }
        },
        "503b3ec5f1114c0a85090054ac965bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e0ebc40534d4551afc3ef20c3f6c38d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7108e66923546a6aa5ad3c13829367b",
            "value": 1
          }
        },
        "5228b76b87a840c28950056d3a81de88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5653f821a065400c88cd64cc9af80e59",
            "placeholder": "​",
            "style": "IPY_MODEL_cc7f56aa8f6d4616a63f4fadc5be6893",
            "value": "Downloading data: 100%"
          }
        },
        "5650f6cbc51743d1a3817d2046fd770f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5653f821a065400c88cd64cc9af80e59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a07729ba09248fc9b1548ece8226a46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a9b2002ec9748efbc080ba2bb7cc8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67bd505aa2454642afbae888791b00f4",
            "placeholder": "​",
            "style": "IPY_MODEL_e5e0f1530fcd42c6b00fac0307fa4152",
            "value": " 456k/456k [00:00&lt;00:00, 38.1MB/s]"
          }
        },
        "5b4ff326aaf7418781400f5cec69ccc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0248529099b44eb3a35d50b585215313",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_144ac59d998548ccb3c42ea20af3c5d4",
            "value": 498818054
          }
        },
        "5bb35a8e38764ae39d4898c6e8d922d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d2666cf77e34757af4f8a8d700e09e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea7773040d84e31a871d1b06f9ba653",
            "placeholder": "​",
            "style": "IPY_MODEL_4e8277b9f0a24a8d992d701bc387229d",
            "value": "Downloading readme: 100%"
          }
        },
        "5f67607d38cf4dd59a66166a6eb7f2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb35a8e38764ae39d4898c6e8d922d3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6dec4914a7343499322d7f2ced36377",
            "value": " 5000/0 [00:00&lt;00:00, 57767.85 examples/s]"
          }
        },
        "6109bc74d01d40d3bfcfb3523303d991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2029cb296f4bdda8f88c0899493e10",
            "placeholder": "​",
            "style": "IPY_MODEL_8eefef820f52407a90ec038d78da6f44",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.26kB/s]"
          }
        },
        "61778a3de3f54c209fed5a58fd17ec37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d2322d4082436ab97b2fd922ee0849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62167a67bb8844759b95221c03292902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6255307b6bf5432ca5150ceef2687bde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627a0ffdec5f4d8ba5cc39843ab554c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5cb637ffe7043d48850f33031504c7a",
            "placeholder": "​",
            "style": "IPY_MODEL_a062d049136443758552f2e0b624067f",
            "value": " 3.61M/3.61M [00:01&lt;00:00, 3.49MB/s]"
          }
        },
        "6324b0b56e6346f8b22165459a83f3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03232dd6540c49758834c34f05705b88",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec312fd233a6487eabe16084cede56f8",
            "value": 456318
          }
        },
        "66e7474f692f4b1db2804df78cf2b3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fe9374d0e542eb951beec5ea9d01f2",
            "placeholder": "​",
            "style": "IPY_MODEL_47f036b7803c498ba7334acbf52b875e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "67bd505aa2454642afbae888791b00f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6921f61da02e436d8a4b0e4b4711c85b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc851c3c26543278251bc886983f243": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6f53055bc5524a66a6f019cb45629cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b40a79e3264a13a72c986933341dac",
            "max": 89,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c181a2d8730a435d9e29b0ddd5560a78",
            "value": 89
          }
        },
        "6fbce80ca4ad4b22a06f3bddc52269aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1567f7574e4bdbbd389b37b94dd81d",
              "IPY_MODEL_d6d1f02baf064ca1b1ee2d7640c45e25",
              "IPY_MODEL_94ef15ed80dc4bbbbd492b586c052a5f"
            ],
            "layout": "IPY_MODEL_20dab458e0e14dd6902c9e4f8d55affc"
          }
        },
        "705adb90225748e5824b8981bd27dcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c66c31db8048458fe3e0ec28bfcd12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712c01c09d74487088d6306ba34dcc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051524850dbd405285321482a5548af1",
            "placeholder": "​",
            "style": "IPY_MODEL_e0fa41556d6a47f1a6a8a8caede84fe4",
            "value": "Downloading data: 100%"
          }
        },
        "7487d6b821f3495b93ce525487a81623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd44151f0f284958a0cc7e65168d9c46",
            "placeholder": "​",
            "style": "IPY_MODEL_144085849b6047d38b6c1d801e349640",
            "value": " 114M/114M [00:28&lt;00:00, 4.96MB/s]"
          }
        },
        "75baade4202d42e8ab64f8ed89557d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762742bec18243fb88f9ce4ac22b1dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c47c7694b34adb88ae24a7e12f5ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fccc724905a04a7e9a4f45ed395eade9",
            "max": 2298584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48a71941aa5b473785c6de1c8eb6f09f",
            "value": 2298584
          }
        },
        "77da6b2bad3944a59344622c07315afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75baade4202d42e8ab64f8ed89557d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd666660a3743f59a1a5aa1cf970bcf",
            "value": "config.json: 100%"
          }
        },
        "7c1567f7574e4bdbbd389b37b94dd81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957d73f59628450f90ade3ef9a9d1b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_61778a3de3f54c209fed5a58fd17ec37",
            "value": "Generating train split: "
          }
        },
        "7ea7773040d84e31a871d1b06f9ba653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800bcaeae660407882f0551de6052987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edb778f661b04d929517016b397cfd0c",
            "placeholder": "​",
            "style": "IPY_MODEL_af356a65548942358deeb41da43be38b",
            "value": "model.safetensors: 100%"
          }
        },
        "818c2025435d49398df11561b3f1430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88230fdf4f454558ae5026684cda15c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a3c1a6bd9be49cd9917829ba8d9be26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f30a3d06b6f84929a29379b4b35e0e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_2189b0b2f3be42a4bf75d206f448860b",
            "value": " 899k/899k [00:00&lt;00:00, 3.58MB/s]"
          }
        },
        "8af50f1921b94864a63e64c8ad4dea51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd666660a3743f59a1a5aa1cf970bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eefef820f52407a90ec038d78da6f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9068071e23d2400299aad1726da54804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9280f8f9ad5345779c4cf5ac47e08482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a28e506a6e73430e84b2f9b485891fd7",
            "max": 113868578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88230fdf4f454558ae5026684cda15c7",
            "value": 113868578
          }
        },
        "93aa5cf3cd254bef860fb3046931136a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c1a4685187482aa8f3bcc49fd875a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94af652ef542449494d30c1a1892455c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94ef15ed80dc4bbbbd492b586c052a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5a05cc0f1745ecaaaf6d815215bc89",
            "placeholder": "​",
            "style": "IPY_MODEL_5650f6cbc51743d1a3817d2046fd770f",
            "value": " 157649/0 [00:03&lt;00:00, 44167.98 examples/s]"
          }
        },
        "957d73f59628450f90ade3ef9a9d1b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96fe9374d0e542eb951beec5ea9d01f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999ca363e0074b8b9bcc4566d477ddba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361008d0f9d14cf79c721a7237e45126",
            "placeholder": "​",
            "style": "IPY_MODEL_052af7ea60ee48ad900450552a865cb0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.80MB/s]"
          }
        },
        "a05f732614c14ac599874cebe21e9691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_800bcaeae660407882f0551de6052987",
              "IPY_MODEL_5b4ff326aaf7418781400f5cec69ccc8",
              "IPY_MODEL_39da96dee98a49929e42ef0f8e577761"
            ],
            "layout": "IPY_MODEL_3d37ecf015af46a8a3798eb2cc4ac861"
          }
        },
        "a062d049136443758552f2e0b624067f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b46a2b4ac244caacb55c219e655c73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28e506a6e73430e84b2f9b485891fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7019e445fff4da497d3566bb97b08fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c1a4685187482aa8f3bcc49fd875a5",
            "placeholder": "​",
            "style": "IPY_MODEL_705adb90225748e5824b8981bd27dcb6",
            "value": "tokenizer.json: 100%"
          }
        },
        "a7108e66923546a6aa5ad3c13829367b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9d04d3c82624bd588a0a54db0fcb626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a6480c1772489a839d714cfe3da99a",
              "IPY_MODEL_41bca75562e8462286db769e42c2dcdd",
              "IPY_MODEL_8a3c1a6bd9be49cd9917829ba8d9be26"
            ],
            "layout": "IPY_MODEL_ca50236975b347eca2e8ceb83ad03ef5"
          }
        },
        "af356a65548942358deeb41da43be38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb2e4a5659946a08dbdb9754b14c539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2816d1d536647b4b1f44ffb400d8e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2acb3a23d1644cf9b88a7dcabefa180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c6a54d1bb804a05ba512e964c55d28a",
              "IPY_MODEL_6324b0b56e6346f8b22165459a83f3fb",
              "IPY_MODEL_5a9b2002ec9748efbc080ba2bb7cc8a9"
            ],
            "layout": "IPY_MODEL_70c66c31db8048458fe3e0ec28bfcd12"
          }
        },
        "b483065e64e84e3aabd4cfc687345772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4655a2e241cc4f6e971e77a1ffb81211",
            "placeholder": "​",
            "style": "IPY_MODEL_2a15a916e55a4b589ee97b7c7ecee823",
            "value": " 481/481 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "b9e3ce0023154062825db219c9f17650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c181a2d8730a435d9e29b0ddd5560a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c268e03652d44434b97b31097c52bdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c590bb3e831f4e378e8dcc6bc0632eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d2322d4082436ab97b2fd922ee0849",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2816d1d536647b4b1f44ffb400d8e2f",
            "value": 25
          }
        },
        "ca50236975b347eca2e8ceb83ad03ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae0f4393d5f4076b61f61f60127c44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a07729ba09248fc9b1548ece8226a46",
            "placeholder": "​",
            "style": "IPY_MODEL_40e26a3401da4a2f85fdacafdd6e3b06",
            "value": " 89.0/89.0 [00:00&lt;00:00, 7.83kB/s]"
          }
        },
        "cc7f56aa8f6d4616a63f4fadc5be6893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce550e7ff64143659a56700612340f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f39b89555a48c095dd28224442f9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3be9fc77dcf4ce6a1b9f4a64fe88ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3de39376f324ae78c46116abf16057e",
            "placeholder": "​",
            "style": "IPY_MODEL_f69af3a6ec7943bb81a2b76cf859f0b3",
            "value": "Generating test split: "
          }
        },
        "d6d1f02baf064ca1b1ee2d7640c45e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4560f59d76f544669b971ef3025a7c23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e06ac6464466489ab13ea72037670ffe",
            "value": 1
          }
        },
        "e06ac6464466489ab13ea72037670ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e09f7cbedb9f46f7922c236c867d052f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f575378b3a174ec4a618ec7721468d9e",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_051975af956a4900891b2202670bf222",
            "value": 481
          }
        },
        "e0fa41556d6a47f1a6a8a8caede84fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e561861ac57343b782a0ceae1f440570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e0f1530fcd42c6b00fac0307fa4152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9e88fe1325549eab574eb464c233331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42bb9aa98ade45bda30452891441b9bb",
              "IPY_MODEL_9280f8f9ad5345779c4cf5ac47e08482",
              "IPY_MODEL_7487d6b821f3495b93ce525487a81623"
            ],
            "layout": "IPY_MODEL_afb2e4a5659946a08dbdb9754b14c539"
          }
        },
        "ec312fd233a6487eabe16084cede56f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edb778f661b04d929517016b397cfd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee26bc187e5b434baa9bc5d75f0a0c24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b84b44b40c43b382f0e2ec3b2909eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d2666cf77e34757af4f8a8d700e09e8",
              "IPY_MODEL_6f53055bc5524a66a6f019cb45629cb2",
              "IPY_MODEL_cae0f4393d5f4076b61f61f60127c44b"
            ],
            "layout": "IPY_MODEL_40656ab742454143a2d3142bcdb0f72f"
          }
        },
        "f0def0f2786c42899b41d03b42cc71a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e0930a322d4af8bc0855304952d8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc851c3c26543278251bc886983f243",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94af652ef542449494d30c1a1892455c",
            "value": 1
          }
        },
        "f30089c691d4442dbf08060c211f8b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f30a3d06b6f84929a29379b4b35e0e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3de39376f324ae78c46116abf16057e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f484d1cab9774086a8613eddcd4cbe7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e3ce0023154062825db219c9f17650",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9e862a88064c07afc996af53574117",
            "value": "Generating validation split: "
          }
        },
        "f575378b3a174ec4a618ec7721468d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5cb637ffe7043d48850f33031504c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6550aa5fa204f4bb2cf71d4d8ba414d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77da6b2bad3944a59344622c07315afe",
              "IPY_MODEL_e09f7cbedb9f46f7922c236c867d052f",
              "IPY_MODEL_b483065e64e84e3aabd4cfc687345772"
            ],
            "layout": "IPY_MODEL_fdec75de59b14e9f8ed427b3e41be341"
          }
        },
        "f69af3a6ec7943bb81a2b76cf859f0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6dec4914a7343499322d7f2ced36377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fccc724905a04a7e9a4f45ed395eade9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd44151f0f284958a0cc7e65168d9c46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5a05cc0f1745ecaaaf6d815215bc89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdec75de59b14e9f8ed427b3e41be341": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
