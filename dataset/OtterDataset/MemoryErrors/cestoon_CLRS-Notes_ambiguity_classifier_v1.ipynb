{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMln0gwEWdKeb5ultdbJ9u5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8ab73553a0045269c46fdd81068c63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5af3438c2de34dedb46528cd43736872",
              "IPY_MODEL_9f4023354dae43ff8f43445fa5cea5b2",
              "IPY_MODEL_4ac7c4cb7170413eaef5ee12876200b3"
            ],
            "layout": "IPY_MODEL_61d74c58eb4e40ffb98ab0ef40bfc8b2"
          }
        },
        "5af3438c2de34dedb46528cd43736872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d426cf2c8b4b739fdce57c3f4f6c57",
            "placeholder": "​",
            "style": "IPY_MODEL_8330eb1394e445da9d5cb2992c707119",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9f4023354dae43ff8f43445fa5cea5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7cd910b9a34f639cc2f49a4fe1ee58",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe94dfc68c0469ca178a54d2bc7ab43",
            "value": 3
          }
        },
        "4ac7c4cb7170413eaef5ee12876200b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42804929450a493c8ffea9d89af61daa",
            "placeholder": "​",
            "style": "IPY_MODEL_ffcd83afdc114012842bf9a90f5c5dfd",
            "value": " 3/3 [01:02&lt;00:00, 20.11s/it]"
          }
        },
        "61d74c58eb4e40ffb98ab0ef40bfc8b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d426cf2c8b4b739fdce57c3f4f6c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8330eb1394e445da9d5cb2992c707119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7cd910b9a34f639cc2f49a4fe1ee58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe94dfc68c0469ca178a54d2bc7ab43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42804929450a493c8ffea9d89af61daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcd83afdc114012842bf9a90f5c5dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cestoon/CLRS-Notes/blob/main/ambiguity_classifier_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] accelerate -U"
      ],
      "metadata": {
        "id": "RBiDaQIIAOb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dkpro-cassis"
      ],
      "metadata": {
        "id": "e0z56XmNrisd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d709d4-f7ba-4ac1-a8d3-c4863cde68b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dkpro-cassis\n",
            "  Downloading dkpro-cassis-0.9.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml~=4.9.1 in /usr/local/lib/python3.10/dist-packages (from dkpro-cassis) (4.9.4)\n",
            "Requirement already satisfied: attrs<24,>=21.2 in /usr/local/lib/python3.10/dist-packages (from dkpro-cassis) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers==2.4.* in /usr/local/lib/python3.10/dist-packages (from dkpro-cassis) (2.4.0)\n",
            "Collecting toposort==1.7 (from dkpro-cassis)\n",
            "  Downloading toposort-1.7-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting more-itertools<9,>=8.12 (from dkpro-cassis)\n",
            "  Downloading more_itertools-8.14.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation==2.1.* (from dkpro-cassis)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting importlib_resources==5.4.* (from dkpro-cassis)\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.*->dkpro-cassis) (24.0)\n",
            "Building wheels for collected packages: dkpro-cassis\n",
            "  Building wheel for dkpro-cassis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dkpro-cassis: filename=dkpro_cassis-0.9.1-py3-none-any.whl size=78088 sha256=bf5a69d03c5f34ce5e76724e155d75aaf9ca1ea0a89f83c6e0e2580a3f460fe1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/4b/9e/6cea69983b5694b5b0f961dfa5d5bc096ed985b9f1c0540766\n",
            "Successfully built dkpro-cassis\n",
            "Installing collected packages: toposort, more-itertools, importlib_resources, deprecation, dkpro-cassis\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 10.1.0\n",
            "    Uninstalling more-itertools-10.1.0:\n",
            "      Successfully uninstalled more-itertools-10.1.0\n",
            "  Attempting uninstall: importlib_resources\n",
            "    Found existing installation: importlib_resources 6.4.0\n",
            "    Uninstalling importlib_resources-6.4.0:\n",
            "      Successfully uninstalled importlib_resources-6.4.0\n",
            "Successfully installed deprecation-2.1.0 dkpro-cassis-0.9.1 importlib_resources-5.4.0 more-itertools-8.14.0 toposort-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhJnx-ftX4Tb",
        "outputId": "4d714e00-57fe-4ef3-9dfb-9221151e0333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data extraction\n",
        "Starting from this part, we perform data extraction"
      ],
      "metadata": {
        "id": "Ogz6wdp4Ez32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # pwd\n",
        "\n",
        "# import zipfile\n",
        "\n",
        "# zip_file_path = \"/content/sentences_annotation_v213138974997607738687.zip\"  # Replace this with the path to your zip file\n",
        "# extract_to_path = \"/content/extracted/\"  # Replace this with the directory where you want to extract the contents\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_to_path)"
      ],
      "metadata": {
        "id": "RIDDmdOgZKkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_file_path = \"/content/extracted/annotation/1_Hospital_Workflow.txt/admin.zip\"  # Replace this with the path to your zip file\n",
        "# extract_to_path = \"/content/extracted_data/01_Hospital\"  # Replace this with the directory where you want to extract the contents\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_to_path)"
      ],
      "metadata": {
        "id": "SR4k4jcqaJ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_file_path = \"/content/data.zip\"  # Replace this with the path to your zip file\n",
        "# extract_to_path = \"/content/data\"  # Replace this with the directory where you want to extract the contents\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_to_path)"
      ],
      "metadata": {
        "id": "Rw3YnfYA1bDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cassis import *\n",
        "\n",
        "with open('/content/extracted_data/01_Hospital/TypeSystem.xml', 'rb') as f:\n",
        "    typesystem = load_typesystem(f)\n",
        "\n",
        "with open('/content/extracted_data/01_Hospital/admin.xmi', 'rb') as f:\n",
        "   cas = load_cas_from_xmi(f, typesystem=typesystem)\n"
      ],
      "metadata": {
        "id": "kW7yXyJMbBxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 选择并打印注释\n",
        "for sentence in cas.select('de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence'):\n",
        "    sentence_text = sentence.get_covered_text()\n",
        "    reason = None\n",
        "    ambiguity_type = []\n",
        "    ambiguity_num = None\n",
        "\n",
        "    # 提取 Reason\n",
        "    reasons = cas.select_covered('webanno.custom.Reason', sentence)\n",
        "    if reasons:\n",
        "        reason = reasons[0].reason  # 获取 reason 的值\n",
        "\n",
        "    # 提取 Ambiguity_Type\n",
        "    ambiguity_types = cas.select_covered('webanno.custom.AmbiguityTag', sentence)\n",
        "    if ambiguity_types:\n",
        "        ambiguity_type = ambiguity_types[0].TS.elements  # 获取 TS 数组的元素\n",
        "\n",
        "    # 提取 Ambiguity_Num\n",
        "    ambiguity_nums = cas.select_covered('webanno.custom.Tag', sentence)\n",
        "    if ambiguity_nums:\n",
        "        ambiguity_num = ambiguity_nums[0].Num  # 获取 Num 的值\n",
        "\n",
        "    # 打印提取的信息\n",
        "    print(f'Sentence: {sentence_text}')\n",
        "    print(f'Reason: {reason}')\n",
        "    print(f'Ambiguity_Type: {ambiguity_type}')\n",
        "    print(f'Ambiguity_Num: {ambiguity_num}')\n",
        "    print('---')\n"
      ],
      "metadata": {
        "id": "8d0Xj557i2AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from cassis import *\n",
        "\n",
        "# 定义数据目录和类型系统文件路径\n",
        "data_dir = '/content/data/export2'\n",
        "typesystem_path = '/content/data/TypeSystem.xml'\n",
        "\n",
        "# 加载类型系统\n",
        "with open(typesystem_path, 'rb') as f:\n",
        "    typesystem = load_typesystem(f)\n",
        "\n",
        "# 初始化一个空的列表来存储数据\n",
        "data = []\n",
        "\n",
        "# 遍历目录中的所有 XMI 文件\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith('.xmi'):\n",
        "        file_path = os.path.join(data_dir, filename)\n",
        "\n",
        "        # 加载 XMI 文件\n",
        "        with open(file_path, 'rb') as f:\n",
        "            cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
        "\n",
        "        # 提取每个句子的相关信息\n",
        "        for sentence in cas.select('de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence'):\n",
        "            sentence_text = sentence.get_covered_text()\n",
        "            reason = \"\"\n",
        "            ambiguity_type = ['T1_false', 'T2_false', 'T3_false', 'T4_false']\n",
        "            ambiguity_num = 0\n",
        "\n",
        "            try:\n",
        "                # 提取 Reason\n",
        "                reasons = cas.select_covered('webanno.custom.Reason', sentence)\n",
        "                if reasons:\n",
        "                    reason = reasons[0].reason\n",
        "\n",
        "                # 提取 Ambiguity_Type\n",
        "                ambiguity_types = cas.select_covered('webanno.custom.AmbiguityTag', sentence)\n",
        "                if ambiguity_types:\n",
        "                    ambiguity_type = ambiguity_types[0].TS.elements\n",
        "\n",
        "                # 提取 Ambiguity_Num\n",
        "                ambiguity_nums = cas.select_covered('webanno.custom.Tag', sentence)\n",
        "                if ambiguity_nums:\n",
        "                    ambiguity_num = ambiguity_nums[0].Num\n",
        "\n",
        "            except AttributeError as e:\n",
        "                print(f\"Error processing sentence: {sentence_text}\")\n",
        "                print(e)\n",
        "\n",
        "            # 将数据添加到列表\n",
        "            data.append({\n",
        "                'filename': filename,\n",
        "                'sentence': sentence_text,\n",
        "                'reason': reason,\n",
        "                'T1': ambiguity_type[0],\n",
        "                'T2': ambiguity_type[1],\n",
        "                'T3': ambiguity_type[2],\n",
        "                'T4': ambiguity_type[3],\n",
        "                'ambiguity_num': ambiguity_num\n",
        "            })\n",
        "\n",
        "# 将数据转换为 DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# 将 DataFrame 保存到 CSV 文件中（可选）\n",
        "df.to_csv('/content/sentence_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoWIXVS24BcB",
        "outputId": "0821b6b3-0712-4ea4-f5da-7a0ddb043454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing sentence: The SoW is then evaluated before sending it to the customer.\n",
            "'NoneType' object has no attribute 'elements'\n",
            "Error processing sentence: Once the adjustment is done, the SoW can be sent for internal evaluation again.\n",
            "'NoneType' object has no attribute 'elements'\n",
            "Error processing sentence: If there is no team member available to the Resp. department must make dissemination and handover to sub.\n",
            "'NoneType' object has no attribute 'elements'\n",
            "         filename                                           sentence  \\\n",
            "0     7_admin.xmi  The customer makes an order on Wolt’s website ...   \n",
            "1     7_admin.xmi  When Wolt receives the order, it is then regis...   \n",
            "2     7_admin.xmi  If the order is accepted, the restaurant begin...   \n",
            "3     7_admin.xmi  Additionally, if delivery option is chosen and...   \n",
            "4     7_admin.xmi  It is determined by range from the customer an...   \n",
            "..            ...                                                ...   \n",
            "355  13_admin.xmi  If the client accepts it, a notification is se...   \n",
            "356  13_admin.xmi  If the translator declines the request, the ag...   \n",
            "357  13_admin.xmi  Once the translator is done with the translati...   \n",
            "358  13_admin.xmi  The agent will then check the translated work ...   \n",
            "359  13_admin.xmi  If deemed satisfactory the agent will close th...   \n",
            "\n",
            "                                                reason        T1        T2  \\\n",
            "0    This sentence clearly describes the initial ac...  T1_false  T2_false   \n",
            "1    lack of detail about specific criteria for rej...  T1_false  T2_false   \n",
            "2              A straightforward conditional statement  T1_false  T2_false   \n",
            "3    complexity in conditional steps for T1. Wolt's...   T1_true  T2_false   \n",
            "4    how range determination affects courier alloca...   T1_true  T2_false   \n",
            "..                                                 ...       ...       ...   \n",
            "355  Provides clear conditional pathways depending ...  T1_false  T2_false   \n",
            "356  Specifies the next step if the initial transla...  T1_false  T2_false   \n",
            "357  Describes a clear end-of-task action by the tr...  T1_false  T2_false   \n",
            "358  The term \"up-to-standard\" is vague and lacks a...  T1_false  T2_false   \n",
            "359  Outlines the final actions clearly if the work...  T1_false  T2_false   \n",
            "\n",
            "           T3        T4  ambiguity_num  \n",
            "0    T3_false  T4_false              0  \n",
            "1     T3_true  T4_false              1  \n",
            "2    T3_false  T4_false              0  \n",
            "3     T3_true  T4_false              2  \n",
            "4     T3_true  T4_false              2  \n",
            "..        ...       ...            ...  \n",
            "355  T3_false  T4_false              0  \n",
            "356  T3_false  T4_false              0  \n",
            "357  T3_false  T4_false              0  \n",
            "358   T3_true  T4_false              1  \n",
            "359  T3_false  T4_false              0  \n",
            "\n",
            "[360 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "Starting from this part, we proceed with model training. First train an ordinary Bayesian Classifier. Then use llama13B"
      ],
      "metadata": {
        "id": "SLyFdrocE_Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayesian Classifier\n",
        "1. **Data Loading and Preparation**: Load the CSV file into a DataFrame and prepare the feature (`X`) and label (`y`) variables.\n",
        "2. **TF-IDF Vectorization**: Use `TfidfVectorizer` to convert sentences into numerical features.\n",
        "3. **K-Fold Cross-Validation**: Split the data into training and validation sets using K-Fold cross-validation.\n",
        "4. **Model Initialization and Training**: Initialize and train a `MultinomialNB` (Naive Bayes) model.\n",
        "5. **Model Evaluation**: Predict the labels for the validation set and print the classification report and confusion matrix for evaluation.\n",
        "\n",
        "This script provides a basic implementation of a Naive Bayesian Classifier for your task, offering a simple comparison against the more complex LLaMA model. Adjust the vectorizer parameters and model hyperparameters as needed to optimize performance."
      ],
      "metadata": {
        "id": "5BNgbK-YFeAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv('/content/sentence_data.csv')\n",
        "\n",
        "# preprae data\n",
        "X = df['sentence']\n",
        "y = df[['T1', 'T2', 'T3', 'T4']]\n",
        "\n",
        "# transfer type label into binary\n",
        "y = y.applymap(lambda x: 1 if x.endswith(\"_true\") else 0)\n",
        "\n",
        "# initialize vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# cross verification\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # transfer data\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "    # initial model\n",
        "    model = OneVsRestClassifier(MultinomialNB())\n",
        "\n",
        "    # train model\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # predict\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "\n",
        "    # evaulate model\n",
        "    for i, label in enumerate(y.columns):\n",
        "        print(f\"Classification Report for {label}\")\n",
        "        unique_labels = sorted(set(y_val.iloc[:, i]) | set(y_pred[:, i]))\n",
        "        print(classification_report(y_val.iloc[:, i], y_pred[:, i], target_names=[f'not_{label}', label] if len(unique_labels) > 1 else [label]))\n",
        "\n",
        "    print(\"Confusion Matrix\")\n",
        "    for i, label in enumerate(y.columns):\n",
        "        print(f\"Confusion Matrix for {label}\")\n",
        "        print(confusion_matrix(y_val.iloc[:, i], y_pred[:, i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D_wr03hFQCL",
        "outputId": "65bb001a-dae2-4fca-f761-5c7410b5ce33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for T1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T1       0.85      1.00      0.92        61\n",
            "          T1       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.85        72\n",
            "   macro avg       0.42      0.50      0.46        72\n",
            "weighted avg       0.72      0.85      0.78        72\n",
            "\n",
            "Classification Report for T2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T2       0.94      1.00      0.97        68\n",
            "          T2       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.94        72\n",
            "   macro avg       0.47      0.50      0.49        72\n",
            "weighted avg       0.89      0.94      0.92        72\n",
            "\n",
            "Classification Report for T3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T3       0.78      1.00      0.88        56\n",
            "          T3       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.78        72\n",
            "   macro avg       0.39      0.50      0.44        72\n",
            "weighted avg       0.60      0.78      0.68        72\n",
            "\n",
            "Classification Report for T4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T4       0.99      1.00      0.99        71\n",
            "          T4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        72\n",
            "   macro avg       0.49      0.50      0.50        72\n",
            "weighted avg       0.97      0.99      0.98        72\n",
            "\n",
            "Confusion Matrix\n",
            "Confusion Matrix for T1\n",
            "[[61  0]\n",
            " [11  0]]\n",
            "Confusion Matrix for T2\n",
            "[[68  0]\n",
            " [ 4  0]]\n",
            "Confusion Matrix for T3\n",
            "[[56  0]\n",
            " [16  0]]\n",
            "Confusion Matrix for T4\n",
            "[[71  0]\n",
            " [ 1  0]]\n",
            "Classification Report for T1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T1       0.83      1.00      0.91        60\n",
            "          T1       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.83        72\n",
            "   macro avg       0.42      0.50      0.45        72\n",
            "weighted avg       0.69      0.83      0.76        72\n",
            "\n",
            "Classification Report for T2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T2       0.99      1.00      0.99        71\n",
            "          T2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        72\n",
            "   macro avg       0.49      0.50      0.50        72\n",
            "weighted avg       0.97      0.99      0.98        72\n",
            "\n",
            "Classification Report for T3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T3       0.88      1.00      0.93        63\n",
            "          T3       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.88        72\n",
            "   macro avg       0.44      0.50      0.47        72\n",
            "weighted avg       0.77      0.88      0.82        72\n",
            "\n",
            "Classification Report for T4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T4       0.97      1.00      0.99        70\n",
            "          T4       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.97        72\n",
            "   macro avg       0.49      0.50      0.49        72\n",
            "weighted avg       0.95      0.97      0.96        72\n",
            "\n",
            "Confusion Matrix\n",
            "Confusion Matrix for T1\n",
            "[[60  0]\n",
            " [12  0]]\n",
            "Confusion Matrix for T2\n",
            "[[71  0]\n",
            " [ 1  0]]\n",
            "Confusion Matrix for T3\n",
            "[[63  0]\n",
            " [ 9  0]]\n",
            "Confusion Matrix for T4\n",
            "[[70  0]\n",
            " [ 2  0]]\n",
            "Classification Report for T1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T1       0.75      1.00      0.86        54\n",
            "          T1       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.75        72\n",
            "   macro avg       0.38      0.50      0.43        72\n",
            "weighted avg       0.56      0.75      0.64        72\n",
            "\n",
            "Classification Report for T2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T2       0.90      1.00      0.95        65\n",
            "          T2       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.90        72\n",
            "   macro avg       0.45      0.50      0.47        72\n",
            "weighted avg       0.82      0.90      0.86        72\n",
            "\n",
            "Classification Report for T3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T3       0.76      1.00      0.87        55\n",
            "          T3       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.76        72\n",
            "   macro avg       0.38      0.50      0.43        72\n",
            "weighted avg       0.58      0.76      0.66        72\n",
            "\n",
            "Classification Report for T4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T4       0.99      1.00      0.99        71\n",
            "          T4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        72\n",
            "   macro avg       0.49      0.50      0.50        72\n",
            "weighted avg       0.97      0.99      0.98        72\n",
            "\n",
            "Confusion Matrix\n",
            "Confusion Matrix for T1\n",
            "[[54  0]\n",
            " [18  0]]\n",
            "Confusion Matrix for T2\n",
            "[[65  0]\n",
            " [ 7  0]]\n",
            "Confusion Matrix for T3\n",
            "[[55  0]\n",
            " [17  0]]\n",
            "Confusion Matrix for T4\n",
            "[[71  0]\n",
            " [ 1  0]]\n",
            "Classification Report for T1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T1       0.76      1.00      0.87        55\n",
            "          T1       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.76        72\n",
            "   macro avg       0.38      0.50      0.43        72\n",
            "weighted avg       0.58      0.76      0.66        72\n",
            "\n",
            "Classification Report for T2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T2       0.92      1.00      0.96        66\n",
            "          T2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.92        72\n",
            "   macro avg       0.46      0.50      0.48        72\n",
            "weighted avg       0.84      0.92      0.88        72\n",
            "\n",
            "Classification Report for T3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T3       0.78      1.00      0.88        56\n",
            "          T3       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.78        72\n",
            "   macro avg       0.39      0.50      0.44        72\n",
            "weighted avg       0.60      0.78      0.68        72\n",
            "\n",
            "Classification Report for T4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          T4       1.00      1.00      1.00        72\n",
            "\n",
            "    accuracy                           1.00        72\n",
            "   macro avg       1.00      1.00      1.00        72\n",
            "weighted avg       1.00      1.00      1.00        72\n",
            "\n",
            "Confusion Matrix\n",
            "Confusion Matrix for T1\n",
            "[[55  0]\n",
            " [17  0]]\n",
            "Confusion Matrix for T2\n",
            "[[66  0]\n",
            " [ 6  0]]\n",
            "Confusion Matrix for T3\n",
            "[[56  0]\n",
            " [16  0]]\n",
            "Confusion Matrix for T4\n",
            "[[72]]\n",
            "Classification Report for T1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T1       0.86      1.00      0.93        62\n",
            "          T1       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.86        72\n",
            "   macro avg       0.43      0.50      0.46        72\n",
            "weighted avg       0.74      0.86      0.80        72\n",
            "\n",
            "Classification Report for T2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T2       0.93      1.00      0.96        67\n",
            "          T2       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.47      0.50      0.48        72\n",
            "weighted avg       0.87      0.93      0.90        72\n",
            "\n",
            "Classification Report for T3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      not_T3       0.85      1.00      0.92        61\n",
            "          T3       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.85        72\n",
            "   macro avg       0.42      0.50      0.46        72\n",
            "weighted avg       0.72      0.85      0.78        72\n",
            "\n",
            "Classification Report for T4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          T4       1.00      1.00      1.00        72\n",
            "\n",
            "    accuracy                           1.00        72\n",
            "   macro avg       1.00      1.00      1.00        72\n",
            "weighted avg       1.00      1.00      1.00        72\n",
            "\n",
            "Confusion Matrix\n",
            "Confusion Matrix for T1\n",
            "[[62  0]\n",
            " [10  0]]\n",
            "Confusion Matrix for T2\n",
            "[[67  0]\n",
            " [ 5  0]]\n",
            "Confusion Matrix for T3\n",
            "[[61  0]\n",
            " [11  0]]\n",
            "Confusion Matrix for T4\n",
            "[[72]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available. Using GPU...\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available. Using CPU...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLzWogkr9ez6",
        "outputId": "ee35b838-6a31-452a-e681-86012a5102fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Using GPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kigHm1K5rgXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "b8ab73553a0045269c46fdd81068c63a",
            "5af3438c2de34dedb46528cd43736872",
            "9f4023354dae43ff8f43445fa5cea5b2",
            "4ac7c4cb7170413eaef5ee12876200b3",
            "61d74c58eb4e40ffb98ab0ef40bfc8b2",
            "99d426cf2c8b4b739fdce57c3f4f6c57",
            "8330eb1394e445da9d5cb2992c707119",
            "bd7cd910b9a34f639cc2f49a4fe1ee58",
            "ffe94dfc68c0469ca178a54d2bc7ab43",
            "42804929450a493c8ffea9d89af61daa",
            "ffcd83afdc114012842bf9a90f5c5dfd"
          ]
        },
        "outputId": "afdf11ca-e2e1-478a-d0bc-d7c9f9fdb82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8ab73553a0045269c46fdd81068c63a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-13b-hf and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32001, 5120)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "# from transformers import pipeline\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# !pip install transformers\n",
        "model_name = \"meta-llama/Llama-2-13b-hf\"\n",
        "api_token = \"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\"\n",
        "\n",
        "# model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=api_token)\n",
        "# Add a padding token if not already present\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=api_token)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, use_auth_token=api_token)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_name, use_auth_token=api_token, num_labels=4)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/sentence_data.csv')\n",
        "\n",
        "# Prepare the dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# Create a function to encode the dataset\n",
        "def encode_data(df):\n",
        "    encodings = tokenizer(list(df['sentence']), truncation=True, padding=True, max_length=512)\n",
        "    labels = df[['T1', 'T2', 'T3', 'T4']].apply(\n",
        "        lambda x: [1 if val.endswith('_true') else 0 for val in x], axis=1).tolist()\n",
        "    return encodings, labels\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",  # Use eval_strategy instead of evaluation_strategy\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, val_index in kf.split(df):\n",
        "    train_df, val_df = df.iloc[train_index], df.iloc[val_index]\n",
        "\n",
        "    # Encode data\n",
        "    train_encodings, train_labels = encode_data(train_df)\n",
        "    val_encodings, val_labels = encode_data(val_df)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Dataset(train_encodings, train_labels)\n",
        "    val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "    # Define the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    predictions = trainer.predict(val_dataset)\n",
        "    preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "    labels = torch.tensor(val_labels)\n",
        "\n",
        "    print(\"Classification Report\")\n",
        "    for i, label in enumerate(['T1', 'T2', 'T3', 'T4']):\n",
        "        print(f\"Classification Report for {label}\")\n",
        "        print(classification_report(labels[:, i], preds[:, i], target_names=[f'not_{label}', label]))\n",
        "\n",
        "    print(\"Confusion Matrix\")\n",
        "    for i, label in enumerate(['T1', 'T2', 'T3', 'T4']):\n",
        "        print(f\"Confusion Matrix for {label}\")\n",
        "        print(confusion_matrix(labels[:, i], preds[:, i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "jkE3pnyx9kie",
        "outputId": "d38009c6-f9d9-4591-fef9-24caf2d7a3b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 16.81 MiB is free. Process 800323 has 39.54 GiB memory in use. Of the allocated memory 39.13 GiB is allocated by PyTorch, and 792.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-606f4c616bfa>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Define the Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     trainer = Trainer(\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantization_method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBITS_AND_BYTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         ):\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m                 )\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 16.81 MiB is free. Process 800323 has 39.54 GiB memory in use. Of the allocated memory 39.13 GiB is allocated by PyTorch, and 792.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # try 70B\n",
        "# import torch\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# # Load the data\n",
        "# df = pd.read_csv('/mnt/data/sentence_data.csv')\n",
        "\n",
        "# # Prepare the dataset\n",
        "# class Dataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self, encodings, labels):\n",
        "#         self.encodings = encodings\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "#         item['labels'] = torch.tensor(self.labels[idx])\n",
        "#         return item\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "# # Define the model and tokenizer\n",
        "# model_name = \"meta-llama/Llama-2-70b-hf\"\n",
        "# api_token = \"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\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=api_token)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_name, use_auth_token=api_token, num_labels=4)\n",
        "\n",
        "# # Create a function to encode the dataset\n",
        "# def encode_data(df):\n",
        "#     encodings = tokenizer(list(df['sentence']), truncation=True, padding=True, max_length=512)\n",
        "#     labels = df[['T1', 'T2', 'T3', 'T4']].apply(lambda x: [1 if val == 'true' else 0 for val in x], axis=1).tolist()\n",
        "#     return encodings, labels\n",
        "\n",
        "# # Initialize KFold\n",
        "# kf = KFold(n_splits=5)\n",
        "\n",
        "# # Training arguments\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir='./results',\n",
        "#     num_train_epochs=3,\n",
        "#     per_device_train_batch_size=1,  # Reduce batch size if needed due to large model size\n",
        "#     per_device_eval_batch_size=1,\n",
        "#     warmup_steps=500,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_dir='./logs',\n",
        "#     logging_steps=10,\n",
        "#     evaluation_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\"\n",
        "# )\n",
        "\n",
        "# # Cross-validation\n",
        "# for train_index, val_index in kf.split(df):\n",
        "#     train_df, val_df = df.iloc[train_index], df.iloc[val_index]\n",
        "\n",
        "#     # Encode data\n",
        "#     train_encodings, train_labels = encode_data(train_df)\n",
        "#     val_encodings, val_labels = encode_data(val_df)\n",
        "\n",
        "#     # Create datasets\n",
        "#     train_dataset = Dataset(train_encodings, train_labels)\n",
        "#     val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "#     # Define the Trainer\n",
        "#     trainer = Trainer(\n",
        "#         model=model,\n",
        "#         args=training_args,\n",
        "#         train_dataset=train_dataset,\n",
        "#         eval_dataset=val_dataset\n",
        "#     )\n",
        "\n",
        "#     # Train the model\n",
        "#     trainer.train()\n",
        "\n",
        "#     # Evaluate the model\n",
        "#     predictions = trainer.predict(val_dataset)\n",
        "#     preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "#     labels = torch.tensor(val_labels)\n",
        "\n",
        "#     print(\"Classification Report\")\n",
        "#     print(classification_report(labels, preds, target_names=['T1', 'T2', 'T3', 'T4']))\n",
        "\n",
        "#     print(\"Confusion Matrix\")\n",
        "#     print(confusion_matrix(labels.argmax(axis=1), preds.argmax(axis=1)))\n"
      ],
      "metadata": {
        "id": "JEPeiL4vBd5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}