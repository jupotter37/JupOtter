{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PyTorch version: 2.0.0+cu118\n",
      "Torchvision version: 0.15.1+cu118\n",
      "CUDA is available: True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# from torch.utils.data.dataset import Datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "input_ch = 4 # 3 or 4\n",
    "weight_decay = 1e-5\n",
    "max_epochs = 100\n",
    "val_interval = 1\n",
    "batch_size = 32\n",
    "num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "data_dir = Path('/dlab/ldrive/CBT/USLJ-DSDE_DATA-I10008/shihch3/projects/HPA_single_data')\n",
    "checkpoint_dir = data_dir.joinpath('checkpoints', timestamp)\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_dir = data_dir.joinpath('log', timestamp)\n",
    "writer = SummaryWriter(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds size: 19626\n",
      "val_ds size: 2180\n"
     ]
    }
   ],
   "source": [
    "from HPASCDataset import HPASCDataset\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((2048, 2048)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "    ])  \n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor()])\n",
    "\n",
    "datadir= Path('/dlab/ldrive/CBT/USLJ-DSDE_DATA-I10008/BenchmarkDatasets/hpa-single-cell-image-classification')\n",
    "train_dataset_dir = datadir.joinpath('train')\n",
    "train_csv = datadir.joinpath('train.csv')\n",
    "\n",
    "HPA_dataset = HPASCDataset(\n",
    "                    input_csv = train_csv, \n",
    "                    root = train_dataset_dir, \n",
    "                    split = 'train', \n",
    "                    transform = transform,\n",
    "                    input_ch = input_ch, \n",
    "                    n_class = 19, \n",
    "                    # debug_size = 100,\n",
    "                    )\n",
    "\n",
    "torch.manual_seed(1947)\n",
    "train_ds, val_ds = random_split(HPA_dataset, [0.9, 0.1])\n",
    "print(\"train_ds size:\", len(train_ds))\n",
    "print(\"val_ds size:\", len(val_ds))\n",
    "train_loader = DataLoader(train_ds, batch_size = batch_size, shuffle = True, \n",
    "                        num_workers = num_workers)\n",
    "val_loader = DataLoader(val_ds, batch_size = batch_size, shuffle = True, \n",
    "                        num_workers = num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = next(dataiter)\n",
    "# images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(images[0]))\n",
    "# print(images[0].shape)\n",
    "# print(images[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "# print(' '.join(f'{labels[j]}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation device: cuda:3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Computation device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs: [3, 0, 1, 2]\n",
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(4, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=4145296, out_features=120, bias=True)\n",
      "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (fc3): Linear(in_features=84, out_features=19, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_ch, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 509 * 509, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 19)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:02, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/153, train_loss: 0.6970, step time: 21.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:07, 67.61s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.98 GiB (GPU 3; 31.75 GiB total capacity; 24.12 GiB already allocated; 1.42 GiB free; 25.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdsdegpu01/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdsdegpu01/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdsdegpu01/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdsdegpu01/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdsdegpu01/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/script/resnet_multicls.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/runtime_env/miniconda3/envs/mspytorch/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/runtime_env/miniconda3/envs/mspytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 3; 31.75 GiB total capacity; 24.12 GiB already allocated; 1.42 GiB free; 25.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "min_val_loss = 0.0\n",
    "\n",
    "for epoch in range(max_epochs):  # loop over the dataset multiple times\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    epoch_loss = 0.0\n",
    "    step = 0\n",
    "    for i, batch_data  in tqdm(enumerate(train_loader, 0)):\n",
    "        step_start = time.time()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = batch_data \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "        step += 1\n",
    "        batch_calculation = 5\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    writer.add_scalar('Loss/train', epoch_loss, epoch+1)\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:  # print every 2000 mini-batches\n",
    "        epoch_val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_step = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = val_data\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                val_step += 1\n",
    "        \n",
    "        epoch_val_loss /= val_step\n",
    "        writer.add_scalar('Loss/valid', epoch_val_loss, epoch+1)\n",
    "        \n",
    "        if min_val_loss > epoch_val_loss and epoch > 0: \n",
    "            print(f'Validation Loss Decreased({min_val_loss:.6f}--->{epoch_val_loss:.6f}) \\t Saving The Model')\n",
    "            min_val_loss = epoch_val_loss\n",
    "            best_metric_epoch = epoch + 1\n",
    "            print(f'Best Metric Epoch: {best_metric_epoch}')\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), checkpoint_dir.joinpath('best_checkpoint.pth'))\n",
    "            \n",
    "        else:\n",
    "            min_val_loss = epoch_val_loss\n",
    "            print(min_val_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
