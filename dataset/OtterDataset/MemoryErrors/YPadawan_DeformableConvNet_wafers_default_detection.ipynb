{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f93e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import deep learning\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b6dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"./Wafer_Map_Datasets.npz\")\n",
    "print(data.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e264b59",
   "metadata": {},
   "source": [
    "Le fichier *Wafer Map Datasets* contient deux sous-fichiers:\n",
    "   - **arr_0**: Fichier contenant les données représentant les wafers et leur défauts. Ce fichier contient à peu près 38000 images de format 52*52. Chaque élément de la matrice peut prendre 3 valeurs potentielles: 0 si c'est un point blanc, 1 si c'est une zone qui a passé le test éléctrique, et 2 si la zone n'a pas passée le test électrique.\n",
    "   - **arr_1**: Contient les labels pour chacune des images. Chaque élément est un vecteur binaire de dimension 8. Chaque élément du vecteur correspond à un défaut basic unique. Si le défaut est présent sur l'image, alors la valeur est de 1, sinon elle est de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5e7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[\"arr_0\"]\n",
    "label = data[\"arr_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066fecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38015"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"arr_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e6bb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38015"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdcc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab1d9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train[1])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8105292",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = torch.from_numpy(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4b1932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 52])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39cc794e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8153154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(label[1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0bc20",
   "metadata": {},
   "source": [
    "## Creating the dataset and dataloader for waferdataset on pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824fb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c179d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaferDefaultDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir, train, test_size=0.2):\n",
    "        \"\"\"\n",
    "        dataset_dir : 'str', path to the directory of the wafer default dataset\n",
    "        train: 'bool' a boolean used for splitting the of train and test datasets, if true it will return the\n",
    "                training set, if False, it will return the test set\n",
    "        test_size: 'float' a float between 0 and 1 (default 0.2) for splitting the dataset between train and test sets\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = np.load(dataset_dir)\n",
    "        self.fullsize = len(self.data[\"arr_1\"])\n",
    "        self.train = train # boolean used to split a train set from a test set\n",
    "        self.split_idx = int(self.fullsize * (1-test_size))\n",
    "        \n",
    "        if self.train:\n",
    "            \n",
    "            self.datasamples = self.data[\"arr_0\"][:self.split_idx]\n",
    "            self.labels = self.data[\"arr_1\"][:self.split_idx]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.datasamples = self.data[\"arr_0\"][self.split_idx:]\n",
    "            self.labels = self.data[\"arr_1\"][self.split_idx:]\n",
    "            \n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.datasamples[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return torch.from_numpy(sample.astype('float32')).unsqueeze(0), torch.from_numpy(label.astype('float32')).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384379d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = WaferDefaultDataset(\"./Wafer_Map_Datasets.npz\", True)\n",
    "test_data = WaferDefaultDataset(\"./Wafer_Map_Datasets.npz\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2841bbd",
   "metadata": {},
   "source": [
    "### Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3962c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=1024, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d58751",
   "metadata": {},
   "source": [
    "# Développement du réseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6433ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import deform_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f192e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefConvNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 kernel_size, defconv=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Creating Deformable Convolutional Network\n",
    "        if defconv: \n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, \n",
    "                          out_channels=out_channels, \n",
    "                          kernel_size=kernel_size),\n",
    "                deform_conv2d(),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, \n",
    "                          out_channels=out_channels, \n",
    "                          kernel_size=kernel_size),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d33d5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DCNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.module1 = DefConvNetBlock(1, 32, kernel_size=5)\n",
    "        self.module2 = DefConvNetBlock(32, 64, kernel_size=3)\n",
    "        self.module3 = DefConvNetBlock(64, 128, kernel_size=3)\n",
    "        self.module4 = DefConvNetBlock(128, 128, kernel_size=3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(42*42*128, 128)\n",
    "        self.fc2 = nn.Linear(128, 8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.module1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.module2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.module3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.module4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # creating output\n",
    "        output = torch.sigmoid(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3ef360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DCNet()\n",
    "model2 = DCNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63144965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x72fbc8ee3920>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51de9e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCNet(\n",
       "  (module1): DefConvNetBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module2): DefConvNetBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module3): DefConvNetBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (module4): DefConvNetBlock(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=225792, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb7beafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 48, 48]             832\n",
      "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
      "   DefConvNetBlock-3           [-1, 32, 48, 48]               0\n",
      "            Conv2d-4           [-1, 64, 46, 46]          18,496\n",
      "       BatchNorm2d-5           [-1, 64, 46, 46]             128\n",
      "   DefConvNetBlock-6           [-1, 64, 46, 46]               0\n",
      "            Conv2d-7          [-1, 128, 44, 44]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 44, 44]             256\n",
      "   DefConvNetBlock-9          [-1, 128, 44, 44]               0\n",
      "           Conv2d-10          [-1, 128, 42, 42]         147,584\n",
      "      BatchNorm2d-11          [-1, 128, 42, 42]             256\n",
      "  DefConvNetBlock-12          [-1, 128, 42, 42]               0\n",
      "           Linear-13                  [-1, 128]      28,901,504\n",
      "           Linear-14                    [-1, 8]           1,032\n",
      "================================================================\n",
      "Total params: 29,144,008\n",
      "Trainable params: 29,144,008\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 15.63\n",
      "Params size (MB): 111.18\n",
      "Estimated Total Size (MB): 126.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model2, input_size=(1, 52, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca8db2",
   "metadata": {},
   "source": [
    "### Defining hyperparameters for the model according to the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45da219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 1024\n",
    "decay = 1e-6\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate, weight_decay=decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4ca8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 4800\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c60cab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b9d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df634f",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ca287b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "model.train level\n",
      "model.train() over\n",
      "30412\n",
      "inside the loop!\n",
      "forward pass\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 400.94 MiB is free. Including non-PyTorch memory, this process has 4.69 GiB memory in use. Of the allocated memory 4.47 GiB is allocated by PyTorch, and 90.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward pass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mDCNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule3(x)\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m---> 27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mDefConvNetBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MSIAM_courses/.venv310/lib/python3.10/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 882.00 MiB. GPU 0 has a total capacity of 5.79 GiB of which 400.94 MiB is free. Including non-PyTorch memory, this process has 4.69 GiB memory in use. Of the allocated memory 4.47 GiB is allocated by PyTorch, and 90.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"model.train level\")\n",
    "    model2.train()\n",
    "    print(\"model.train() over\")\n",
    "    size = len(train_dataloader.dataset)\n",
    "    print(size)\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        print(\"inside the loop!\")\n",
    "        inputs, labels = data[0].to(device), data[1].squeeze(1).to(device)\n",
    "             \n",
    "        # Forward pass\n",
    "        print(\"forward pass\")\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        print(\"backward pass\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            loss, current = loss.item(), i * batch_size + len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "#     print(\"before model.eval()\")    \n",
    "#     model2.eval()\n",
    "#     print(\"after model.eval()\")\n",
    "#     size = len(test_dataloader.dataset)\n",
    "#     num_batches = len(test_dataloader)\n",
    "#     test_loss, correct = 0, 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         print(\"at test level\")\n",
    "#         for X, y in test_dataloader:\n",
    "#             y = y.squeeze(1)\n",
    "#             pred = model2(X)\n",
    "#             test_loss += criterion(pred, y).item()\n",
    "#             pred = pred > 0.8\n",
    "#             correct += (pred == y).type(torch.float).sum().item()\n",
    "#     test_loss /= num_batches\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cfb4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch._C._cuda_clearCublasWorkspaces()\n",
    "torch._dynamo.reset()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59ede3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model2\n",
    "del criterion\n",
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0a36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a84d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abb569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
