{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip -q PPM-100"
      ],
      "metadata": {
        "id": "B6vnFq5E_ZqC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import math\n",
        "from PIL import Image\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "rV_oKHbUAW83"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aLstUsj9ne4H"
      },
      "outputs": [],
      "source": [
        "# Data loading\n",
        "fg_path = 'PPM-100/image/'\n",
        "\n",
        "# path to provided alpha mattes\n",
        "a_path = 'PPM-100/matte/'\n",
        "\n",
        "# Path to background images (MSCOCO)\n",
        "bg_path = 'PPM-100/background/'\n",
        "\n",
        "# Path to folder where you want the composited images to go\n",
        "out_path = 'merged/'\n",
        "\n",
        "def composite4(fg, bg, a, w, h):\n",
        "    fg = np.array(fg, np.float32)\n",
        "    bg = np.array(bg[0:h, 0:w], np.float32)\n",
        "    alpha = np.zeros((h, w, 1), np.float32)\n",
        "    alpha[:, :, 0] = a / 255.\n",
        "    comp = alpha * fg + (1 - alpha) * bg\n",
        "    comp = comp.astype(np.uint8)\n",
        "    print(a.shape)\n",
        "    return comp\n",
        "\n",
        "\n",
        "def process(im_name, bg_name, fcount, bcount):\n",
        "    im = cv.imread(fg_path + im_name)\n",
        "    a = cv.imread(a_path + im_name, 0)\n",
        "    h, w = im.shape[:2]\n",
        "    bg = cv.imread(bg_path + bg_name)\n",
        "    bh, bw = bg.shape[:2]\n",
        "    if not (bh < h or bw < w):\n",
        "        left = int((bw - w) / 2)\n",
        "        top = int((bh - h) / 2)\n",
        "        right = int((bw + w) / 2)\n",
        "        lower = int((bh + h) / 2)\n",
        "        cropped = bg[top:lower, left:right, :]\n",
        "        out = composite4(im, cropped, a, w, h)\n",
        "        filename = out_path + str(fcount) + '_' + str(bcount) + '.png'\n",
        "        cv.imwrite(filename, out)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('PPM-100/background.txt') as f:\n",
        "    bg_files = f.read().splitlines()\n",
        "with open('PPM-100/image.txt') as f:\n",
        "    fg_files = f.read().splitlines()"
      ],
      "metadata": {
        "id": "_eW510pG3Zez"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('PPM-100/background.txt') as f:\n",
        "    bg_files = f.read().splitlines()\n",
        "with open('PPM-100/image.txt') as f:\n",
        "    fg_files = f.read().splitlines()\n",
        "\n",
        "num_bgs = 20\n",
        "\n",
        "num_samples = len(fg_files) * num_bgs\n",
        "\n",
        "print(bg_files)\n",
        "print(fg_files)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "bcount = 0\n",
        "for fcount in tqdm(range(len(fg_files))):\n",
        "    im_name = fg_files[fcount]\n",
        "    bcount = 0\n",
        "    for i in range(num_bgs):\n",
        "        bg_name = bg_files[bcount]\n",
        "        process(im_name, bg_name, fcount, bcount)\n",
        "        bcount += 1\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print('elapsed: {} seconds'.format(elapsed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "LYb5Uq-5FYeN",
        "outputId": "bf61febf-deb6-4d3f-8dda-ce3668c13c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['al-ghazali-3KmWk2WC_Z0-unsplash.jpg', 'alina-grubnyak-8yT8YL-x8CQ-unsplash.jpg', 'annie-spratt-_iH19KS6e2c-unsplash.jpg', 'hieu-vu-minh-He8-FZl-o10-unsplash.jpg', 'house-method-CqVHT8g45R8-unsplash.jpg', 'israa-hilles-xP0gM0Dh-MY-unsplash.jpg', 'jason-goodman-nF0nQuqBsrI-unsplash.jpg', 'jorgen-haland-8UE83jPlNXg-unsplash.jpg', 'jose-losada-Sm8TAus1pGs-unsplash.jpg', 'kevin-wolf-3AbwSH1y9dc-unsplash.jpg', 'lexie-barnhorn-rWjd8kNuT7Q-unsplash.jpg', 'lukasz-szmigiel-jFCViYFYcus-unsplash.jpg', 'luke-stackpoole-x2qSNIEZuEE-unsplash.jpg', 'mathias-adam-JKHUw0Xujf8-unsplash.jpg', 'michal-pechardo-bpt7mjgrBRQ-unsplash.jpg', 'mickey-o-neil-xL66l--msXU-unsplash.jpg', 'mike-benna-SBiVq9eWEtQ-unsplash.jpg', 'nolan-issac-K5sjajgbTFw-unsplash.jpg', 'ricardo-frantz-sC-BXbi9ajw-unsplash.jpg', 'rune-enstad-UXFJ-6Zj27M-unsplash.jpg']\n",
            "['13179159164_1a4ae8d085_o.jpg', '14299313536_ea3e61076c_o.jpg', '14429083354_23c8fddff5_o.jpg', '14559969490_d33552a324_o.jpg', '14561870264_b21b665f1f_o.jpg', '14996438642_58c976f957_o.jpg', '15372445161_8f9a002163_o.jpg', '15484589590_aa8c549b09_o.jpg', '16033420983_bf2714ea70_o.jpg', '16617208122_d49f100f58_o.jpg', '16731963546_3148ea2b33_o.jpg', '16756405415_234c47784a_o.jpg', '17012922300_f46d4cace9_o.jpg', '17464489461_0e158881db_o.jpg', '17692337940_44dfe102df_o.jpg', '17876927642_a73799528c_o.jpg', '18426592324_902aace2eb_o.jpg', '19045402063_8d68cda3e2_o.jpg', '19551619800_2c7ac67584_o.jpg', '1991971655_d7182c30e6_o.jpg', '2133184216_18d38525a2_o.jpg', '21440655004_9042e41252_o.jpg', '22037305096_d4f7a80070_o.jpg', '2251211039_514e0d6381_o.jpg', '2286375093_90e0f3bd5c_o.jpg', '23182124263_f73a7659f1_o.jpg', '2399432208_47d240db23_o.jpg', '24179781765_21532649fd_o.jpg', '2597446670_7603493d92_o.jpg', '26843142809_f237ef41de_o.jpg', '2712595293_2a811baf51_o.jpg', '27128793201_8b80f08b59_o.jpg', '27378578609_9fb95e6d18_o.jpg', '27438080369_61ae60ab4a_o.jpg', '27755397158_5f9af325ab_5k.jpg', '28068209155_efecedf6ee_o.jpg', '29556012541_3942bae649_o.jpg', '3104502752_cb935c1f0b_o.jpg', '31137397232_5fbec8697b_o.jpg', '31727147035_ef01d2496d_o.jpg', '32552705987_fbc78cd29e_o.jpg', '32602381061_7fe6c8e201_o.jpg', '32680360593_196431a953_o.jpg', '3284532104_aaf266bfb3_o.jpg', '33417724542_f25ee4ced7_o.jpg', '34504878700_d626a8a3c6_o.jpg', '34763377415_22eae5b6bc_o.jpg', '35290106894_9725c465a6_o.jpg', '35463429630_eed47d744a_o.jpg', '35998070871_36c398b9c6_o.jpg', '36959512493_b6c1cc8e4e_o.jpg', '40582488762_3ff469cfd2_o.jpg', '4065842143_71bd1d0b2f_o.jpg', '4082044950_d82c95164b_o.jpg', '41151764511_4c31d91009_o.jpg', '4262720719_98b283b577_o.jpg', '4519591952_a28ec51c93_o.jpg', '45694792702_d9488ff191_o.jpg', '4695247296_a73cc1feef_o.jpg', '48020524488_499f7403f3_o.jpg', '48035016352_7cda75fccd_o.jpg', '4814717217_51bd4859dc_o.jpg', '48624730818_67ff3c2811_o.jpg', '48625101712_675622d1f4_o.jpg', '49020513826_d8fffe604d_o.jpg', '49158639747_c516378273_o.jpg', '49570726843_7e8c5d61e7_o.jpg', '49740440761_f9ffe43f60_o.jpg', '50048955706_7d520d5a19_o.jpg', '50131649212_e89fcd353b_o.jpg', '50238484256_6c8d245d7a_o.jpg', '50412671508_364056eabb_o.jpg', '506937171_b73ff1c24b_o.jpg', '5475151559_0245f5ca69_o.jpg', '5568806374_e947232b97_o.jpg', '5588687863_a7160d7922_o.jpg', '5588688353_3426d4b5d9_o.jpg', '5605413616_a369eeb580_o.jpg', '5606410404_3ebf4b1d58_o.jpg', '562923769_48519f411e_o.jpg', '5856163574_fd870a0e1d_o.jpg', '5972392747_8c19036ff0_o.jpg', '6146816_556eaff97f_o.jpg', '6542415853_7f81703517_o.jpg', '7014439975_7ba69c1abe_o.jpg', '7050227021_4898a00341_o.jpg', '7085121445_1165c4a561_o.jpg', '7199196364_b799dd85a7_o.jpg', '7563506064_09918edbde_o.jpg', '7672088804_38b388f59e_o.jpg', '7933140068_61793b7f1e_o.jpg', '8038262829_c8e4aef99c_o.jpg', '8079007331_4f6a2caaea_o.jpg', '8196666445_52d7c14300_o.jpg', '8505149244_f85e4aa75d_o.jpg', '8611028976_bd1f1bd214_o.jpg', '8646915801_429929b96a_o.jpg', '8881079923_af57ddb8df_o.jpg', '9588042894_3311442be9_o.jpg', '9646653607_63bcb2f669_o.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3229, 4843)\n",
            "(3229, 4843)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-ea5a22a7a6d6>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mbcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-c550d85ed196>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(im_name, bg_name, fcount, bcount)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mbh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbh\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbw\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "for fcount in tqdm(range(len(fg_files))):\n",
        "  im_name = fg_files[fcount]\n",
        "  a = cv.imread(a_path + im_name, 0)\n",
        "  blurred_image = cv.GaussianBlur(a, (15, 15), 0)\n",
        "  # cv2_imshow(blurred_image)\n",
        "\n",
        "  # cv.waitKey(0)\n",
        "  cv.imwrite('blurred_matte/'+im_name, blurred_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX-CRqmGjSDu",
        "outputId": "15378862-7439-4985-b976-0ca23397d814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 20.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Unpooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unpooling, self).__init__()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs[:, 1]\n",
        "        bool_mask = inputs[:, 0] >= inputs[:, 1]\n",
        "        mask = bool_mask.float()\n",
        "        x = mask * x\n",
        "        return x"
      ],
      "metadata": {
        "id": "rk_-GFtsIqcz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1_1 = nn.Conv2d(4, 64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Decoder\n",
        "        self.unpool = Unpooling()\n",
        "\n",
        "        self.deconv6 = nn.Conv2d(512, 512, kernel_size=1, padding='same')\n",
        "        self.bn6 = nn.BatchNorm2d(512)\n",
        "        self.upsample6 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv5 = nn.Conv2d(512, 512, kernel_size=1, padding='same')\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.upsample5 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv4 = nn.Conv2d(512, 256, kernel_size=5, padding='same')\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv3 = nn.Conv2d(256, 128, kernel_size=5, padding='same')\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv2 = nn.Conv2d(128, 64, kernel_size=5, padding='same')\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv1 = nn.Conv2d(64, 64, kernel_size=5, padding='same')\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        self.deconv0 = nn.Conv2d(64, 1, kernel_size=5, padding='same')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        orig_1 = x\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        orig_2 = x\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        orig_3 = x\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        orig_4 = x\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        orig_5 = x\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        Decoder\n",
        "        x = F.relu(self.deconv6(x))\n",
        "        x = self.bn6(x)\n",
        "        x = self.upsample6(x)\n",
        "        x = torch.cat((orig_5, x), dim=1)\n",
        "        x = self.unpool(x)\n",
        "\n",
        "        x = F.relu(self.deconv5(x))\n",
        "        x = self.bn5(x)\n",
        "        x = self.upsample5(x)\n",
        "        x = torch.cat((orig_4, x), dim=1)\n",
        "        x = self.unpool(x)\n",
        "\n",
        "        x = F.relu(self.deconv4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.upsample4(x)\n",
        "        x = torch.cat((orig_3, x), dim=1)\n",
        "        x = self.unpool(x)\n",
        "\n",
        "        x = F.relu(self.deconv3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = self.upsample3(x)\n",
        "        x = torch.cat((orig_2, x), dim=1)\n",
        "        x = self.unpool(x)\n",
        "\n",
        "        x = F.relu(self.deconv2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = self.upsample2(x)\n",
        "        x = torch.cat((orig_1, x), dim=1)\n",
        "        x = self.unpool(x)\n",
        "\n",
        "        x = F.relu(self.deconv1(x))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = F.sigmoid(self.deconv0(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example of creating a model instance and printing the architecture\n",
        "model = EncoderDecoder()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5z07jDj4849",
        "outputId": "ee291825-5ff5-45a8-d479-1190670bde5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderDecoder(\n",
            "  (conv1_1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (unpool): Unpooling()\n",
            "  (deconv3): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (upsample3): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (deconv2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (upsample2): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (deconv1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (upsample1): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (deconv0): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1e-6\n",
        "epsilon_sqr = epsilon ** 2\n",
        "def alpha_pred_loss(y_true, y_pred):\n",
        "  num_pixels = y_true.shape[0] * y_true.shape[1]\n",
        "  diff = y_true - y_pred\n",
        "  return torch.sum(torch.sqrt(torch.square(diff) + epsilon_sqr)) / (num_pixels + epsilon)"
      ],
      "metadata": {
        "id": "VBIHJvFcY1u7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EncoderDecoder().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using the GPU!\")\n",
        "else:\n",
        "  print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kBE9xkCt1uK",
        "outputId": "0c76dd94-af13-4dc4-a5fa-1747765759ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, n_iters=90):\n",
        "\n",
        "\n",
        "  for i in range(n_iters):\n",
        "    im_name = fg_files[i]\n",
        "    bmat = cv.imread(\"PPM-100/blurred_matte/\" + im_name, 0)\n",
        "    img = cv.imread(\"PPM-100/image/\" + im_name)\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    bmat_tensor = torch.from_numpy(bmat).float()/255.0\n",
        "    bmat_tensor = bmat_tensor.unsqueeze(dim=2).cuda()\n",
        "    img_tensor = torch.from_numpy(img).float() / 255.0\n",
        "    img_tensor = img_tensor.cuda()\n",
        "    x = torch.cat((bmat_tensor, img_tensor), dim=2)\n",
        "    y_true = cv.imread(a_path + im_name, 0)\n",
        "    y_true = torch.from_numpy(y_true).float() / 255.0\n",
        "    y_true = y_true.cuda()\n",
        "\n",
        "    # print(bmat_tensor.dtype)\n",
        "    # print(img_tensor.dtype)\n",
        "    # print(x.shape)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(x.permute(2, 0, 1).unsqueeze(0))\n",
        "\n",
        "    loss = alpha_pred_loss(y_true, y_pred)\n",
        "    print(\"Iteration: {}, loss = {}\".format(i, loss))\n",
        "\n",
        "    # Backward pass: compute gradient and do optimizer step\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "fONLcsZ8sQYl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model.to(device), optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cwIX_L1t3PsM",
        "outputId": "c7df3201-c920-4428-c10e-bd54a0ef4da3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 14.75 GiB of which 487.06 MiB is free. Process 2690 has 14.27 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 141.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-45a71a19c25b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-fca86257e353>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, n_iters)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_pred_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b3a6562168b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0morig_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 14.75 GiB of which 487.06 MiB is free. Process 2690 has 14.27 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 141.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5Q7BcQB3Vkz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}