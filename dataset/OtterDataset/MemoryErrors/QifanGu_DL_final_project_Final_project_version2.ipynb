{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df440ab893604e89ad9431d74d20a865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc913aefe3ba496b949e924c1f52be87",
              "IPY_MODEL_a3212745ba664ad08500c93f49ea30a7",
              "IPY_MODEL_5bbf7579be354e36a435f1ba3da0e147"
            ],
            "layout": "IPY_MODEL_e246c4b20658483187b0cc6b0e24b26f"
          }
        },
        "cc913aefe3ba496b949e924c1f52be87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b97df07f46054b5b97e1fe6ab99ca2f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c7004115554d46f5abcca9d782027e99",
            "value": "Downloading data files: 100%"
          }
        },
        "a3212745ba664ad08500c93f49ea30a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66b6795cbd04a25ba866b594a3aa4a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fc060a156f24d87aefee9bc059ab298",
            "value": 1
          }
        },
        "5bbf7579be354e36a435f1ba3da0e147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c427f0fc08534b8f90640cab925908e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4f01c5e1cce64ca49f2ba9f44ad0bbaa",
            "value": " 1/1 [00:00&lt;00:00, 86.59it/s]"
          }
        },
        "e246c4b20658483187b0cc6b0e24b26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97df07f46054b5b97e1fe6ab99ca2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7004115554d46f5abcca9d782027e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d66b6795cbd04a25ba866b594a3aa4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc060a156f24d87aefee9bc059ab298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c427f0fc08534b8f90640cab925908e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f01c5e1cce64ca49f2ba9f44ad0bbaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ef5d19ccc594be091647c0eae6c8aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adb8262f1cef43d8b28d408416fdba9a",
              "IPY_MODEL_05ee53ef4227427e8e8ff4362f8a5bad",
              "IPY_MODEL_46201e7494934137a565ad7552a4f01d"
            ],
            "layout": "IPY_MODEL_cbe1fded29324a759af425cee7f818a4"
          }
        },
        "adb8262f1cef43d8b28d408416fdba9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aec20b126b24ea0bd61cd5524286c6d",
            "placeholder": "​",
            "style": "IPY_MODEL_b6aa4b0d9db44954a9de0016175305b3",
            "value": "Extracting data files: 100%"
          }
        },
        "05ee53ef4227427e8e8ff4362f8a5bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea772afbc214a49a62646cbacae02d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53da15accca24ae685b7c0d9c1f6e934",
            "value": 1
          }
        },
        "46201e7494934137a565ad7552a4f01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41bf50ae2f6f4877bab98fa71a3e9972",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd98c371c724cb1ad37e243bc9637b3",
            "value": " 1/1 [00:00&lt;00:00, 53.51it/s]"
          }
        },
        "cbe1fded29324a759af425cee7f818a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aec20b126b24ea0bd61cd5524286c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6aa4b0d9db44954a9de0016175305b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eea772afbc214a49a62646cbacae02d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53da15accca24ae685b7c0d9c1f6e934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41bf50ae2f6f4877bab98fa71a3e9972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd98c371c724cb1ad37e243bc9637b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfff42f13a0f4801b115644df488a423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab480191d084c239cc6d1f342000344",
              "IPY_MODEL_af079d5c14884b37b1aa7bcc858cd8dd",
              "IPY_MODEL_f8a169b8c5ff44ce9c7cd0beb830c482"
            ],
            "layout": "IPY_MODEL_cb4467bfcd364b238dba068aece6dfdc"
          }
        },
        "6ab480191d084c239cc6d1f342000344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e988acd89d4951859d12de265ea117",
            "placeholder": "​",
            "style": "IPY_MODEL_9221f9b7c35c40fc9dbacfa5c4838a55",
            "value": "Generating train split: "
          }
        },
        "af079d5c14884b37b1aa7bcc858cd8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e9ff20510049caa375ef2b49846f9e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aa340b8ad4449a184934529488ca1f1",
            "value": 1
          }
        },
        "f8a169b8c5ff44ce9c7cd0beb830c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89eef40d9d20445cac5498f2eceecce7",
            "placeholder": "​",
            "style": "IPY_MODEL_ccbb7ed85af24a2788b780ab3df26445",
            "value": " 50000/0 [00:00&lt;00:00, 385394.66 examples/s]"
          }
        },
        "cb4467bfcd364b238dba068aece6dfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e988acd89d4951859d12de265ea117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9221f9b7c35c40fc9dbacfa5c4838a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e9ff20510049caa375ef2b49846f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7aa340b8ad4449a184934529488ca1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89eef40d9d20445cac5498f2eceecce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbb7ed85af24a2788b780ab3df26445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee91dd6498ed4d8984cf0b278970a9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e83e9ff5a0c440a90e2d7b00834e697",
              "IPY_MODEL_9551f07cff8e45abab0025e2be92044b",
              "IPY_MODEL_e6e3b54ba7d84ed88917b1b85817bf89"
            ],
            "layout": "IPY_MODEL_f80eb2ecb5294fda9e823fdd9ec87436"
          }
        },
        "0e83e9ff5a0c440a90e2d7b00834e697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b02266e191c4d4699946ac25ccf7066",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7fa171da3a4f90b0933c3e1c82be0c",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "9551f07cff8e45abab0025e2be92044b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c812b1f2e2040faabacf39f94b1ed6b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e669e45e02249858a47a9000cd53425",
            "value": 1
          }
        },
        "e6e3b54ba7d84ed88917b1b85817bf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_831296dba8104b2589b516565720f80d",
            "placeholder": "​",
            "style": "IPY_MODEL_92d7b006705840fe81642c182d51a4f5",
            "value": " 1/1 [00:01&lt;00:00,  1.96s/it]"
          }
        },
        "f80eb2ecb5294fda9e823fdd9ec87436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b02266e191c4d4699946ac25ccf7066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7fa171da3a4f90b0933c3e1c82be0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c812b1f2e2040faabacf39f94b1ed6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e669e45e02249858a47a9000cd53425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "831296dba8104b2589b516565720f80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d7b006705840fe81642c182d51a4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c72c3910cd946519aa9eb50909f4c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8d076ba513f43a4b0ec7af1b8a4ad65",
              "IPY_MODEL_a4c33f53ef59428997d2cb31460f2711",
              "IPY_MODEL_0e8dd7565c604b2fb745fabf8a160f89"
            ],
            "layout": "IPY_MODEL_773a26ff679944969edac4dfe9f7cb59"
          }
        },
        "f8d076ba513f43a4b0ec7af1b8a4ad65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab27af1b9cbf45b4b9bc10829a6b09cf",
            "placeholder": "​",
            "style": "IPY_MODEL_1ef69f5d95b7473d8f412de1b1ae3957",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "a4c33f53ef59428997d2cb31460f2711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc53b69b1a4b40c09c652434825aeb0e",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5effd5c2c574045a59d085e5f20a678",
            "value": 50
          }
        },
        "0e8dd7565c604b2fb745fabf8a160f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4460348b3f134e6a801c08d54927e4bd",
            "placeholder": "​",
            "style": "IPY_MODEL_db853a7126244ea98b3df821dcd00368",
            "value": " 50/50 [00:00&lt;00:00, 315.10ba/s]"
          }
        },
        "773a26ff679944969edac4dfe9f7cb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab27af1b9cbf45b4b9bc10829a6b09cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef69f5d95b7473d8f412de1b1ae3957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc53b69b1a4b40c09c652434825aeb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5effd5c2c574045a59d085e5f20a678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4460348b3f134e6a801c08d54927e4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db853a7126244ea98b3df821dcd00368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46c6e9c183394999ad750334df32924a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0242dede85741e6add3d98b1a442c68",
              "IPY_MODEL_8a0f3efc8e2149e7936eb9a22d4f1077",
              "IPY_MODEL_4224aa2c05d64981aa3f1007da06feeb"
            ],
            "layout": "IPY_MODEL_9c013cd30a4e40858d9d0264c0b9d991"
          }
        },
        "d0242dede85741e6add3d98b1a442c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13cf6578cf2c43fca0c6feb8e58644f9",
            "placeholder": "​",
            "style": "IPY_MODEL_87b5139f35c54792b248205156953bd2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8a0f3efc8e2149e7936eb9a22d4f1077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bac21ee43215479d86f6a71cce147632",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc348e5896014d4684b753621ac3b430",
            "value": 2
          }
        },
        "4224aa2c05d64981aa3f1007da06feeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6a6111d426418a80b476e687e129f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b9bf0e3670534841bb51a92a82215d56",
            "value": " 2/2 [00:02&lt;00:00,  1.19s/it]"
          }
        },
        "9c013cd30a4e40858d9d0264c0b9d991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13cf6578cf2c43fca0c6feb8e58644f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b5139f35c54792b248205156953bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bac21ee43215479d86f6a71cce147632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc348e5896014d4684b753621ac3b430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6a6111d426418a80b476e687e129f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bf0e3670534841bb51a92a82215d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnMm6l_w4pCZ",
        "outputId": "aee4b771-076e-468d-8275-d13266975404"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip install"
      ],
      "metadata": {
        "id": "P34E6EQCvxZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3EPOKSFrXQj",
        "outputId": "9556b5c2-88b6-4bc0-f506-8f4cfcc31c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuGEa7FMr3N1",
        "outputId": "5e38b790-a8f1-430a-ed91-27a9e8ec4251"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export LAMINI_API_KEY= \"d64c4c724cb846b28865dbaa92411304\""
      ],
      "metadata": {
        "id": "Vv2mMzqMsTl9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade lamini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjZhBzHOsX3V",
        "outputId": "55390e11-9dac-44a3-ca14-7213e6d27cbe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lamini\n",
            "  Downloading lamini-1.0.3-47-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m41.0/50.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic==1.10.* in /usr/local/lib/python3.10/dist-packages (from lamini) (1.10.13)\n",
            "Collecting lamini-configuration[yaml] (from lamini)\n",
            "  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lamini) (1.23.5)\n",
            "Collecting jsonlines (from lamini)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (1.5.3)\n",
            "Collecting faiss-cpu (from lamini)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob (from lamini)\n",
            "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.*->lamini) (4.5.0)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->lamini)\n",
            "  Downloading azure_core-1.29.5-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (41.0.7)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob->lamini)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lamini) (23.1.0)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
            "Collecting typing-extensions>=4.2.0 (from pydantic==1.10.*->lamini)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.21)\n",
            "Installing collected packages: faiss-cpu, typing-extensions, lamini-configuration, jsonlines, isodate, azure-core, azure-storage-blob, lamini\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-core-1.29.5 azure-storage-blob-12.19.0 faiss-cpu-1.7.4 isodate-0.6.1 jsonlines-4.0.0 lamini-1.0.3 lamini-configuration-0.8.3 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkRsNcTWsbCy",
        "outputId": "9a103a37-ff44-44e4-b95d-c09a32aee864"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zstandard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uICgbSxds_35",
        "outputId": "bdb0b894-888c-4ce9-fe16-b8624a142559"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zstandard\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard\n",
            "Successfully installed zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3C1_sJQRWAm",
        "outputId": "dce72797-d9f2-466a-93f3-6d09d0285c3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch,accelerate]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-U46KqHPkOJ",
        "outputId": "6406abfa-485a-4a31-ac56-68924a8d109a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[accelerate,torch] in /usr/local/lib/python3.10/dist-packages (4.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (4.66.1)\n",
            "Collecting accelerate>=0.21.0 (from transformers[accelerate,torch])\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[accelerate,torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[accelerate,torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[accelerate,torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[accelerate,torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[accelerate,torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[accelerate,torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[accelerate,torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[accelerate,torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[accelerate,torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqMyj8UxP1Dd",
        "outputId": "fbb007c7-d753-4f3a-d287-93e73fa7bf9c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import lamini and huggingface login"
      ],
      "metadata": {
        "id": "ZH_jOvDMv53T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0RiaV7msPsd",
        "outputId": "c210e79f-91f8-4ce7-dc1c-f1d96f1fc0fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lamini\n",
        "lamini.api_key = \"d64c4c724cb846b28865dbaa92411304\"\n",
        "\n",
        "\n",
        "llm = lamini.LlamaV2Runner()\n",
        "print(llm(\"How are you?\"))"
      ],
      "metadata": {
        "id": "n848N7vrsnFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791f862c-e8b9-4680-cff8-7519d1b67a84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  I'm just an AI, I don't have feelings or emotions like humans do, so I don't have a physical state of being such as \"good\" or \"bad.\" I'm here to help answer your questions and provide information to the best of my ability, so please feel free to ask me anything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama import BasicModelRunner\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from pprint import pprint\n",
        "import jsonlines\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import config\n",
        "import os\n",
        "import yaml\n",
        "import logging\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import TrainingArguments\n",
        "from llama import BasicModelRunner\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None"
      ],
      "metadata": {
        "id": "Q_nGCyVatE_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "40b70f2d-b260-4cf2-a8e7-8f67e335da7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-195a85d58773>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicModelRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# simple observe the outcome of the original model we will use."
      ],
      "metadata": {
        "id": "XdcEaMb2wlgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
        "non_finetuned_output = non_finetuned(\"Which letter corresponds to the graph of $y = |f(x)|$?\")\n",
        "non_finetuned_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "DHi6hapiuaRI",
        "outputId": "f77eca61-3884-4f97-9fb5-ff54b0fd626b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nI\\'m trying to find the graph of $y = |f(x)|$ where $f(x) = \\\\sin(x)$.\\n\\nI\\'ve tried to find the graph of $y = \\\\sin(x)$ and then find the absolute value of it, but I\\'m not sure how to do that.\\n\\nComment: What is the domain of $f$?\\n\\nComment: @JMoravitz The domain of $f$ is $\\\\mathbb{R}$.\\n\\nComment: @JMoravitz I\\'m not sure what you mean by \"the domain of $f$ is $\\\\mathbb{R}$\".\\n\\nComment: @JMoravitz I\\'m not sure what you mean by \"the domain of $f$ is $\\\\mathbb{R}$\".\\n\\nComment: @JMoravitz I\\'m not sure what you mean by \"the domain of $f$ is $\\\\mathbb{R}$\".\\n\\nComment: @JMoravitz I\\'m not sure what you mean by \"the domain of $f$ is $\\\\mathbb{R}$\".\\n\\nComment: @JMoravitz I\\'m not sure what you mean by \"the domain of $f'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "non_finetuned_output = non_finetuned(\"Which letter corresponds to the graph of $y = |f(x)|$?\")\n",
        "pprint(non_finetuned_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP6KxuzJvjUa",
        "outputId": "998801bc-dc53-4d26-e7c0-d9951c561df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n'\n",
            " '\\n'\n",
            " 'The graph of $y = |f(x)|$ is shown below:\\n'\n",
            " '\\n'\n",
            " '$$\\\\begin{array}{ccc}\\n'\n",
            " '\\\\text{Graph of } y = |f(x)| & \\\\text{Domain of } f(x) & \\\\text{Range of } '\n",
            " 'f(x) \\\\\\\\\\n'\n",
            " '\\\\hline\\n'\n",
            " '\\\\begin{array}{c}\\n'\n",
            " '\\\\text{Positive values of } y \\\\\\\\\\n'\n",
            " '\\\\text{for } x \\\\in \\\\mathbb{R}\\n'\n",
            " '\\\\end{array} & \\\\begin{array}{c}\\n'\n",
            " '\\\\text{All real numbers} \\\\\\\\\\n'\n",
            " '\\\\text{including zero}\\n'\n",
            " '\\\\end{array} & \\\\begin{array}{c}\\n'\n",
            " '\\\\text{All real numbers} \\\\\\\\\\n'\n",
            " '\\\\text{including zero}\\n'\n",
            " '\\\\end{array} \\\\\\\\\\n'\n",
            " '\\\\end{array}$$\\n'\n",
            " '\\n'\n",
            " 'Which letter corresponds to the graph of $y = |f(x)|$?\\n'\n",
            " '\\n'\n",
            " 'A) The graph of $y = f(x)$\\n'\n",
            " 'B) The graph of $y = -f(x)$\\n'\n",
            " 'C) The graph of $y = f(x)$ with a positive sign\\n'\n",
            " 'D) The graph of $y = f(x)$ with a negative sign\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load the dataset and observe the dataset"
      ],
      "metadata": {
        "id": "ep633LdGwwgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_dataset = load_dataset(\"meta-math/MetaMathQA\", split = \"train\", streaming = True)"
      ],
      "metadata": {
        "id": "qC0r3n24vqXd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "print(\"Instruciton-tuned dataset:\")\n",
        "top_n = list(itertools.islice(pretrained_dataset, n))\n",
        "for i in top_n:\n",
        "  pprint(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaXs5evmvsUW",
        "outputId": "e4cd2911-f800-4e58-c8b2-64bbe78f5cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruciton-tuned dataset:\n",
            "{'query': 'Which letter corresponds to the graph of $y = |f(x)|$?',\n",
            " 'response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected '\n",
            "             'across the x-axis for all values of $x$ where $f(x) < 0$.\\n'\n",
            "             'Therefore, the correct letter that corresponds to the graph of '\n",
            "             '$y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: '\n",
            "             '\\\\text{D}',\n",
            " 'type': 'MATH_Rephrased'}\n",
            "{'query': 'The coffee shop sold 8 more than four times the number of lattes as '\n",
            "          'it did teas. If 6 teas were sold how many lattes did the coffee '\n",
            "          'shop sell?',\n",
            " 'response': 'If the coffee shop sold 6 teas, then the number of lattes sold '\n",
            "             'is 8 more than four times the number of teas.\\n'\n",
            "             'Four times the number of teas is 4 * 6 = 24.\\n'\n",
            "             'So, the number of lattes sold is 24 + 8 = 32.\\n'\n",
            "             '#### 32\\n'\n",
            "             'The answer is: 32',\n",
            " 'type': 'GSM_AnsAug'}\n",
            "{'query': 'A store is comparing their profits throughout the year. They had '\n",
            "          'profits of $1,500 in the first quarter of the year, $3,000 in the '\n",
            "          'third quarter, and $2,000 in the fourth quarter. If their annual '\n",
            "          'profits are $8,000, how much profit, in dollars, did they make in '\n",
            "          'the second quarter?',\n",
            " 'response': 'The annual profit is $8,000.\\n'\n",
            "             'The sum of the profits in the first, third, and fourth quarters '\n",
            "             'is $1,500 + $3,000 + $2,000 = $6,500.\\n'\n",
            "             'Therefore, the profit in the second quarter is $8,000 - $6,500 = '\n",
            "             '$1,500.\\n'\n",
            "             '#### 1500\\n'\n",
            "             'The answer is: 1500',\n",
            " 'type': 'GSM_AnsAug'}\n",
            "{'query': 'In a class of $40$ students, $18$ said they liked apple pie, X said '\n",
            "          'they liked chocolate cake, and $12$ said they did not like either. '\n",
            "          '5 students in the class liked both. What is the value of unknown '\n",
            "          'variable X?',\n",
            " 'response': 'To solve this problem, we need to determine the value of x, '\n",
            "             'which represents the number of students who said they liked '\n",
            "             'chocolate cake.\\n'\n",
            "             'We know that 18 students liked apple pie, 12 students did not '\n",
            "             'like either, and 5 students liked both.\\n'\n",
            "             \"Let's set up the equation using the principle of \"\n",
            "             'inclusion-exclusion:\\n'\n",
            "             'Number of students who liked apple pie + Number of students who '\n",
            "             'liked chocolate cake - Number of students who liked both + '\n",
            "             'Number of students who liked neither = Total number of students\\n'\n",
            "             '18 + x - 5 + 12 = 40\\n'\n",
            "             \"Let's simplify and solve for x:\\n\"\n",
            "             '18 + x - 5 + 12 = 40\\n'\n",
            "             '25 + x = 40\\n'\n",
            "             'To isolate x, we subtract 25 from both sides of the equation:\\n'\n",
            "             '25 + x - 25 = 40 - 25\\n'\n",
            "             'x = 15\\n'\n",
            "             'The value of x is 15.\\n'\n",
            "             'The answer is: 15',\n",
            " 'type': 'MATH_SV'}\n",
            "{'query': 'With Janice needing to watch a movie in 2 hours, she has several '\n",
            "          'tasks to complete before she can leave. These tasks include '\n",
            "          'finishing her homework (which takes 30 minutes), cleaning her room '\n",
            "          '(which takes half as long as her homework), walking the dog (which '\n",
            "          'takes 5 minutes more than doing homework), and taking out the trash '\n",
            "          '(which takes 1/6 of the time it takes her to do homework). What is '\n",
            "          'the remaining time in minutes that Janice has before the movie '\n",
            "          'starts?',\n",
            " 'response': 'Finishing her homework takes 30 minutes.\\n'\n",
            "             'Cleaning her room takes half as long as her homework, so it '\n",
            "             'takes 30/2 = 15 minutes.\\n'\n",
            "             'Walking the dog takes 5 minutes more than doing homework, so it '\n",
            "             'takes 30 + 5 = 35 minutes.\\n'\n",
            "             'Taking out the trash takes 1/6 of the time it takes her to do '\n",
            "             'homework, so it takes 30/6 = 5 minutes.\\n'\n",
            "             'The total time for all the tasks is 30 + 15 + 35 + 5 = 85 '\n",
            "             'minutes.\\n'\n",
            "             'Janice has 2 hours, which is 2 * 60 = 120 minutes.\\n'\n",
            "             'So the remaining time Janice has before the movie starts is 120 '\n",
            "             '- 85 = 35 minutes.\\n'\n",
            "             '#### 35\\n'\n",
            "             'The answer is: 35',\n",
            " 'type': 'GSM_Rephrased'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "82wxwug-w72H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter the data by type\n",
        "pretrained_dataset_math_re = []\n",
        "\n",
        "for i in pretrained_dataset:\n",
        "    if i['type'] == 'MATH_Rephrased':\n",
        "        pretrained_dataset_math_re.append(i)"
      ],
      "metadata": {
        "id": "Z2rEtHwNxT3Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "print(\"Instruciton-tuned dataset:\")\n",
        "top_n = list(itertools.islice(pretrained_dataset_math_re, n))\n",
        "for i in top_n:\n",
        "  pprint(i)"
      ],
      "metadata": {
        "id": "PWgKQ81TzDB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408213e5-4772-4dc4-9c64-4367b58f2967"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruciton-tuned dataset:\n",
            "{'query': 'Which letter corresponds to the graph of $y = |f(x)|$?',\n",
            " 'response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected '\n",
            "             'across the x-axis for all values of $x$ where $f(x) < 0$.\\n'\n",
            "             'Therefore, the correct letter that corresponds to the graph of '\n",
            "             '$y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: '\n",
            "             '\\\\text{D}',\n",
            " 'type': 'MATH_Rephrased'}\n",
            "{'query': 'What is the value of the ceiling function applied to -2.4?',\n",
            " 'response': 'The ceiling function rounds a number up to the nearest integer.\\n'\n",
            "             'For -2.4, the nearest integer greater than -2.4 is -2.\\n'\n",
            "             'Therefore, the value of the ceiling function applied to -2.4 is '\n",
            "             '$\\\\boxed{-2}$.The answer is: -2',\n",
            " 'type': 'MATH_Rephrased'}\n",
            "{'query': 'If $a$ is a constant and $9x^2 + 24x + a$ is a perfect square '\n",
            "          'binomial, what is the value of $a$?',\n",
            " 'response': 'A perfect square binomial can be written in the form $(mx + '\n",
            "             'n)^2$,\\n'\n",
            "             'where $m$ and $n$ are constants.\\n'\n",
            "             'If $9x^2 + 24x + a$ is a perfect square binomial, it must be of '\n",
            "             'the form $(3x + n)^2$ for some constant $n$.\\n'\n",
            "             'Expanding $(3x + n)^2$, we get $9x^2 + 6nx + n^2$.\\n'\n",
            "             'Comparing this with $9x^2 + 24x + a$, we see that $6n = 24$ and '\n",
            "             '$n^2 = a$.\\n'\n",
            "             'Solving $6n = 24$, we find that $n = 4$.\\n'\n",
            "             'Therefore, $n^2 = a = \\\\boxed{16}$.\\n'\n",
            "             'The answer is: 16',\n",
            " 'type': 'MATH_Rephrased'}\n",
            "{'query': 'What is the simplified form of $(5^7 + 3^6)(1^5 - (-1)^4)^{10}$?',\n",
            " 'response': 'First, we simplify the expression inside the parentheses:\\n'\n",
            "             '$(1^5 - (-1)^4)^{10} = (1 - 1)^{10} = 0^{10} = 0$.\\n'\n",
            "             '\\n'\n",
            "             'Now, we can simplify the entire expression:\\n'\n",
            "             '$(5^7 + 3^6)(1^5 - (-1)^4)^{10} = (5^7 + 3^6)(0)^{10} = 0$.\\n'\n",
            "             '\\n'\n",
            "             'Therefore, the simplified form of the expression is '\n",
            "             '$\\\\boxed{0}$.The answer is: 0',\n",
            " 'type': 'MATH_Rephrased'}\n",
            "{'query': 'Determine the value of $\\\\displaystyle\\\\frac{235^2-221^2}{14}$.',\n",
            " 'response': 'We can factor the numerator as a difference of squares: '\n",
            "             '$\\\\displaystyle 235^2-221^2=(235+221)(235-221)$.\\n'\n",
            "             'So, $\\\\displaystyle '\n",
            "             '\\\\frac{235^2-221^2}{14}=\\\\frac{(235+221)(235-221)}{14}$.\\n'\n",
            "             'Simplifying the numerator, we have $\\\\displaystyle '\n",
            "             '\\\\frac{456(14)}{14}$.\\n'\n",
            "             \"The $\\\\displaystyle 14$'s cancel out, leaving us with \"\n",
            "             '$\\\\displaystyle \\\\boxed{456}$.\\n'\n",
            "             'The answer is: 456',\n",
            " 'type': 'MATH_Rephrased'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = '''\n",
        "\n",
        "\"Below is an instruction that describes a task. \" \"Write a response that appropriately completes the request.\\n\\n\" \"### Instruction:\\n{instruction}\\n\\n### Response: Let's think step by step.\"\n",
        "\n",
        "'''\n",
        "\n",
        "processed_data = []\n",
        "for j in pretrained_dataset_math_re:\n",
        "  processed_prompt = prompt_template.format(instruction = j['query'])\n",
        "  processed_data.append({\"Instruction\": processed_prompt,\"Response\":j[\"response\"]})"
      ],
      "metadata": {
        "id": "MNNYaCGB6UIE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(processed_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc05wyZJ8VgK",
        "outputId": "86b94f9d-a71e-4b7a-ab50-51ac06ad557d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Instruction': '\\n'\n",
            "                '\\n'\n",
            "                '\"Below is an instruction that describes a task. \" \"Write a '\n",
            "                'response that appropriately completes the request.\\n'\n",
            "                '\\n'\n",
            "                '\" \"### Instruction:\\n'\n",
            "                'Which letter corresponds to the graph of $y = |f(x)|$?\\n'\n",
            "                '\\n'\n",
            "                '### Response: Let\\'s think step by step.\"\\n'\n",
            "                '\\n',\n",
            " 'Response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected '\n",
            "             'across the x-axis for all values of $x$ where $f(x) < 0$.\\n'\n",
            "             'Therefore, the correct letter that corresponds to the graph of '\n",
            "             '$y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: '\n",
            "             '\\\\text{D}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(f'math_rephrased_processed.jsonl','w') as writer:\n",
        "  writer.write_all(processed_data)"
      ],
      "metadata": {
        "id": "LDHBQKlz8wku"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload to hugging face\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"math_rephrased_processed_dataset\"\n",
        "dataset = load_dataset('json', data_files='math_rephrased_processed.jsonl', split='train')\n",
        "dataset.push_to_hub(dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "df440ab893604e89ad9431d74d20a865",
            "cc913aefe3ba496b949e924c1f52be87",
            "a3212745ba664ad08500c93f49ea30a7",
            "5bbf7579be354e36a435f1ba3da0e147",
            "e246c4b20658483187b0cc6b0e24b26f",
            "b97df07f46054b5b97e1fe6ab99ca2f7",
            "c7004115554d46f5abcca9d782027e99",
            "d66b6795cbd04a25ba866b594a3aa4a2",
            "1fc060a156f24d87aefee9bc059ab298",
            "c427f0fc08534b8f90640cab925908e6",
            "4f01c5e1cce64ca49f2ba9f44ad0bbaa",
            "4ef5d19ccc594be091647c0eae6c8aaa",
            "adb8262f1cef43d8b28d408416fdba9a",
            "05ee53ef4227427e8e8ff4362f8a5bad",
            "46201e7494934137a565ad7552a4f01d",
            "cbe1fded29324a759af425cee7f818a4",
            "8aec20b126b24ea0bd61cd5524286c6d",
            "b6aa4b0d9db44954a9de0016175305b3",
            "eea772afbc214a49a62646cbacae02d6",
            "53da15accca24ae685b7c0d9c1f6e934",
            "41bf50ae2f6f4877bab98fa71a3e9972",
            "2cd98c371c724cb1ad37e243bc9637b3",
            "dfff42f13a0f4801b115644df488a423",
            "6ab480191d084c239cc6d1f342000344",
            "af079d5c14884b37b1aa7bcc858cd8dd",
            "f8a169b8c5ff44ce9c7cd0beb830c482",
            "cb4467bfcd364b238dba068aece6dfdc",
            "58e988acd89d4951859d12de265ea117",
            "9221f9b7c35c40fc9dbacfa5c4838a55",
            "79e9ff20510049caa375ef2b49846f9e",
            "7aa340b8ad4449a184934529488ca1f1",
            "89eef40d9d20445cac5498f2eceecce7",
            "ccbb7ed85af24a2788b780ab3df26445",
            "ee91dd6498ed4d8984cf0b278970a9fc",
            "0e83e9ff5a0c440a90e2d7b00834e697",
            "9551f07cff8e45abab0025e2be92044b",
            "e6e3b54ba7d84ed88917b1b85817bf89",
            "f80eb2ecb5294fda9e823fdd9ec87436",
            "5b02266e191c4d4699946ac25ccf7066",
            "ea7fa171da3a4f90b0933c3e1c82be0c",
            "4c812b1f2e2040faabacf39f94b1ed6b",
            "6e669e45e02249858a47a9000cd53425",
            "831296dba8104b2589b516565720f80d",
            "92d7b006705840fe81642c182d51a4f5",
            "2c72c3910cd946519aa9eb50909f4c77",
            "f8d076ba513f43a4b0ec7af1b8a4ad65",
            "a4c33f53ef59428997d2cb31460f2711",
            "0e8dd7565c604b2fb745fabf8a160f89",
            "773a26ff679944969edac4dfe9f7cb59",
            "ab27af1b9cbf45b4b9bc10829a6b09cf",
            "1ef69f5d95b7473d8f412de1b1ae3957",
            "fc53b69b1a4b40c09c652434825aeb0e",
            "b5effd5c2c574045a59d085e5f20a678",
            "4460348b3f134e6a801c08d54927e4bd",
            "db853a7126244ea98b3df821dcd00368"
          ]
        },
        "id": "3eV17hRo9PTJ",
        "outputId": "a5e9ddfc-d25e-4e2d-9216-edbf2a65833b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df440ab893604e89ad9431d74d20a865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ef5d19ccc594be091647c0eae6c8aaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfff42f13a0f4801b115644df488a423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee91dd6498ed4d8984cf0b278970a9fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/50 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c72c3910cd946519aa9eb50909f4c77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data set if needed\n",
        "from datasets import load_dataset\n",
        "dataset_path_hf = \"MarkGu/math_rephrased_processed_dataset\"\n",
        "processed_data_df = load_dataset(dataset_path_hf)\n",
        "print(processed_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Vrc0IcPK-DpG",
        "outputId": "79a6da85-60aa-4de9-aac1-898e6602d165"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-86e8ff90170e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data set if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_path_hf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MarkGu/math_rephrased_processed_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprocessed_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_hf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you load dataset again\n",
        "data_list = []\n",
        "\n",
        "for split_name, split_dataset in processed_data_df.items():\n",
        "    for example in split_dataset:\n",
        "        data_dict = dict(example)\n",
        "        data_list.append(data_dict)\n",
        "\n",
        "processed_data = data_list"
      ],
      "metadata": {
        "id": "8sjBWcPWTFGx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(processed_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LF0x8uTtNY",
        "outputId": "a0caaeea-9148-41ef-c53b-468585c45b8a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Instruction': '\\n'\n",
            "                '\\n'\n",
            "                '\"Below is an instruction that describes a task. \" \"Write a '\n",
            "                'response that appropriately completes the request.\\n'\n",
            "                '\\n'\n",
            "                '\" \"### Instruction:\\n'\n",
            "                'Which letter corresponds to the graph of $y = |f(x)|$?\\n'\n",
            "                '\\n'\n",
            "                '### Response: Let\\'s think step by step.\"\\n'\n",
            "                '\\n',\n",
            " 'Response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected '\n",
            "             'across the x-axis for all values of $x$ where $f(x) < 0$.\\n'\n",
            "             'Therefore, the correct letter that corresponds to the graph of '\n",
            "             '$y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: '\n",
            "             '\\\\text{D}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run model"
      ],
      "metadata": {
        "id": "8r4r_jnHCmML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  input_ids = tokenizer.encode(\n",
        "      text,\n",
        "      return_tensors='pt',\n",
        "      truncation=True,\n",
        "      max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "      input_ids=input_ids.to(device),\n",
        "      max_length=max_output_tokens,\n",
        "      # num_return_sequences=1,\n",
        "      # no_repeat_ngram_size=2,\n",
        "      # top_p=0.9,\n",
        "      # top_k=50\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "vDLU7xqN-ShC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "46c6e9c183394999ad750334df32924a",
            "d0242dede85741e6add3d98b1a442c68",
            "8a0f3efc8e2149e7936eb9a22d4f1077",
            "4224aa2c05d64981aa3f1007da06feeb",
            "9c013cd30a4e40858d9d0264c0b9d991",
            "13cf6578cf2c43fca0c6feb8e58644f9",
            "87b5139f35c54792b248205156953bd2",
            "bac21ee43215479d86f6a71cce147632",
            "cc348e5896014d4684b753621ac3b430",
            "5e6a6111d426418a80b476e687e129f1",
            "b9bf0e3670534841bb51a92a82215d56"
          ]
        },
        "id": "0ECztqC-Dg7X",
        "outputId": "0729571f-cc16-41e0-c615-a9032ca5b852"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46c6e9c183394999ad750334df32924a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the use of inference function\n",
        "test_sample = processed_data[0]['Instruction']\n",
        "generated_text = inference(test_sample, base_model, tokenizer)\n",
        "print(\"Instruction:\\n\",test_sample)\n",
        "print(\"The right answer:\\n\",processed_data[0]['Response'])\n",
        "print(\"\\nGenerated text:\")\n",
        "pprint(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg6pugLSDhie",
        "outputId": "08f8c61e-253a-467c-b381-c7209809cb3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            " \n",
            "\n",
            "\"Below is an instruction that describes a task. \" \"Write a response that appropriately completes the request.\n",
            "\n",
            "\" \"### Instruction:\n",
            "Which letter corresponds to the graph of $y = |f(x)|$?\n",
            "\n",
            "### Response: Let's think step by step.\"\n",
            "\n",
            "\n",
            "The right answer:\n",
            " The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected across the x-axis for all values of $x$ where $f(x) < 0$.\n",
            "Therefore, the correct letter that corresponds to the graph of $y = |f(x)|$ is the letter $\\boxed{\\text{D}}$.The answer is: \\text{D}\n",
            "\n",
            "Generated text:\n",
            "'\\n\\n\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare and begin training"
      ],
      "metadata": {
        "id": "p41lGnq1L8GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset to train and test\n",
        "test_size = int(len(processed_data) * 0.1)\n",
        "train_size = len(processed_data) - test_size\n",
        "\n",
        "train_dataset = processed_data[:test_size]\n",
        "test_dataset = processed_data[train_size:]\n",
        "print(\"Whole dataset length: \",len(processed_data))\n",
        "print(\"Training dataset length: \", len(train_dataset))\n",
        "print(\"Testing dataset length: \", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuhZD2vLKz5j",
        "outputId": "848af32f-aefe-40ab-dca0-986084f3f177"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole dataset length:  50000\n",
            "Training dataset length:  5000\n",
            "Testing dataset length:  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_config ={\n",
        "    \"model\":{\n",
        "        \"pretrained_name\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "        \"max_length\" : 1024\n",
        "    },\n",
        "    \"datasets\":{\n",
        "        \"use_hf\": True,\n",
        "        \"path\":\"MarkGu/math_rephrased_processed_dataset\"\n",
        "    },\n",
        "    \"verbose\": True\n",
        "}"
      ],
      "metadata": {
        "id": "JmaVH59fVZSf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define max data point\n",
        "max_steps = 5000"
      ],
      "metadata": {
        "id": "Ysc_BwkWFd7u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the output output_dir name\n",
        "trained_model_mame = f\"math_rephrase_docs_{max_steps}_steps\"\n",
        "output_dir = trained_model_mame"
      ],
      "metadata": {
        "id": "DpZH_lUEMaIo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "  # Learning rate\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs = 1,\n",
        "\n",
        "  # Max steps to train for (each step is a batch of data)\n",
        "  # Overrides num train epochs, if not -1\n",
        "  max_steps=max_steps,\n",
        "\n",
        "  # Batch size for training\n",
        "  per_device_train_batch_size=1,\n",
        "\n",
        "  # Directory to save model checkpoints\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # Other arguments\n",
        "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
        "  disable_tqdm=False,# Disable progress bars\n",
        "  eval_steps=120,# Number of update steps between two evaluations\n",
        "  save_steps=120,# After # steps model is saved\n",
        "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
        "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
        "  evaluation_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=1,\n",
        "  optim=\"adafactor\",\n",
        "  gradient_accumulation_steps = 32,\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # Parameters for early stopping\n",
        "  load_best_model_at_end=True,\n",
        "  save_total_limit=1,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False\n",
        ")"
      ],
      "metadata": {
        "id": "oAzXBuEUNByC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print memory use of the model\n",
        "model_flops = (\n",
        "  base_model.floating_point_ops(\n",
        "      {\n",
        "         \"input_ids\": torch.zeros(\n",
        "             (1, training_config[\"model\"][\"max_length\"])\n",
        "         )\n",
        "      }\n",
        "  )\n",
        "  * training_args.gradient_accumulation_steps\n",
        ")\n",
        "\n",
        "print(base_model)\n",
        "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9,\"GB\")\n",
        "print(\"Flops\",model_flops / 1e9,\"GFLOPs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSWqbjPtNels",
        "outputId": "2b76be9d-36c2-47e6-cfe3-2b96bff93d78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
            "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
            "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
            "          (act_fn): SiLUActivation()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n",
            "Memory footprint 27.087888384 GB\n",
            "Flops 324764.153413632 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "WbfG4Y-FZ6ac"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Jw1qgX2WUHXg",
        "outputId": "adf71565-d373-4495-d724-c8d8ec1d9fa0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-14471979741e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantization_method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBITS_AND_BYTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         ):\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2269\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 )\n\u001b[0;32m-> 2271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 24.12 MiB is free. Process 160180 has 15.75 GiB memory in use. Of the allocated memory 14.89 GiB is allocated by PyTorch, and 5.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(processed_data[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5v7hyyxihCj",
        "outputId": "6948678e-ebd5-404f-abc4-ff4d16043075"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Instruction': '\\n'\n",
            "                 '\\n'\n",
            "                 '\"Below is an instruction that describes a task. \" \"Write a '\n",
            "                 'response that appropriately completes the request.\\n'\n",
            "                 '\\n'\n",
            "                 '\" \"### Instruction:\\n'\n",
            "                 'Which letter corresponds to the graph of $y = |f(x)|$?\\n'\n",
            "                 '\\n'\n",
            "                 '### Response: Let\\'s think step by step.\"\\n'\n",
            "                 '\\n',\n",
            "  'Response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected '\n",
            "              'across the x-axis for all values of $x$ where $f(x) < 0$.\\n'\n",
            "              'Therefore, the correct letter that corresponds to the graph of '\n",
            "              '$y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: '\n",
            "              '\\\\text{D}'},\n",
            " {'Instruction': '\\n'\n",
            "                 '\\n'\n",
            "                 '\"Below is an instruction that describes a task. \" \"Write a '\n",
            "                 'response that appropriately completes the request.\\n'\n",
            "                 '\\n'\n",
            "                 '\" \"### Instruction:\\n'\n",
            "                 'What is the value of the ceiling function applied to -2.4?\\n'\n",
            "                 '\\n'\n",
            "                 '### Response: Let\\'s think step by step.\"\\n'\n",
            "                 '\\n',\n",
            "  'Response': 'The ceiling function rounds a number up to the nearest '\n",
            "              'integer.\\n'\n",
            "              'For -2.4, the nearest integer greater than -2.4 is -2.\\n'\n",
            "              'Therefore, the value of the ceiling function applied to -2.4 is '\n",
            "              '$\\\\boxed{-2}$.The answer is: -2'},\n",
            " {'Instruction': '\\n'\n",
            "                 '\\n'\n",
            "                 '\"Below is an instruction that describes a task. \" \"Write a '\n",
            "                 'response that appropriately completes the request.\\n'\n",
            "                 '\\n'\n",
            "                 '\" \"### Instruction:\\n'\n",
            "                 'If $a$ is a constant and $9x^2 + 24x + a$ is a perfect '\n",
            "                 'square binomial, what is the value of $a$?\\n'\n",
            "                 '\\n'\n",
            "                 '### Response: Let\\'s think step by step.\"\\n'\n",
            "                 '\\n',\n",
            "  'Response': 'A perfect square binomial can be written in the form $(mx + '\n",
            "              'n)^2$,\\n'\n",
            "              'where $m$ and $n$ are constants.\\n'\n",
            "              'If $9x^2 + 24x + a$ is a perfect square binomial, it must be of '\n",
            "              'the form $(3x + n)^2$ for some constant $n$.\\n'\n",
            "              'Expanding $(3x + n)^2$, we get $9x^2 + 6nx + n^2$.\\n'\n",
            "              'Comparing this with $9x^2 + 24x + a$, we see that $6n = 24$ and '\n",
            "              '$n^2 = a$.\\n'\n",
            "              'Solving $6n = 24$, we find that $n = 4$.\\n'\n",
            "              'Therefore, $n^2 = a = \\\\boxed{16}$.\\n'\n",
            "              'The answer is: 16'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lamini import BasicModelRunner as BasicModelRunner_lamini\n",
        "model = BasicModelRunner_lamini(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "model.load_data_from_jsonlines(\"math_rephrased_processed.jsonl\",input_key='Instruction',output_key = 'Response')\n",
        "model.train(is_public=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS8NfkV7ezNG",
        "outputId": "0c424b86-1c07-4bb4-8a3f-e7c30587be3d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training job submitted! Check status of job 4432 here: https://app.lamini.ai/train/4432\n",
            "Finetuning process completed, model name is: e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from lamini"
      ],
      "metadata": {
        "id": "QwySXkg716wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import push_to_hub\n",
        "\n",
        "model_path = \"my_lamini_math_model\"\n",
        "username = \"your_hugging_face_username\"\n",
        "repository_name = \"your_repository_name\"\n",
        "\n",
        "push_to_hub(model_path, username, repository_name)"
      ],
      "metadata": {
        "id": "pPqWJSI71UIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluation"
      ],
      "metadata": {
        "id": "Kr275qPkzKPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama import LLMEngine\n",
        "\n",
        "llm = LLMEngine(\n",
        "    id=\"4432\",\n",
        "    model_name=\"e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd\",\n",
        "    config={\n",
        "        \"production\": {\n",
        "            \"key\": \"d64c4c724cb846b28865dbaa92411304\",\n",
        "        }\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "ONGdKY-S0G-4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = 4432\n",
        "Path = f\"https://api.lamini.ai/v2/lamini/train/math/{job_id}/eval\""
      ],
      "metadata": {
        "id": "kVOEm5Bcyx4m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --location --request GET \"https://api.lamini.ai/v2/lamini/train/jobs/4432/eval\" \\\n",
        "--header 'Authorization: Bearer d64c4c724cb846b28865dbaa92411304' \\\n",
        "--header 'Content-Type: application/json' -o lamini_math.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq5aEeGhzJtm",
        "outputId": "975c5abb-55cf-4291-b9b5-988bf7d6c4be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12781  100 12781    0     0   6685      0  0:00:01  0:00:01 --:--:--  6684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = \"lamini_math.json\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "nAm4LUXsBFVX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(current_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IrjUUBABjEB",
        "outputId": "af058cfc-9e52-4cc9-b5ac-d86170923a26"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "for i in range(5):\n",
        "  print(data['eval_results'][i]['input'])\n",
        "  pprint(data['eval_results'][i]['outputs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ4h_QIsB_78",
        "outputId": "05880e4d-90cd-4388-ec27-3d790e921836"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the value of $88 \\div (4 \\div 2)$?\n",
            "[{'model_name': 'e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd',\n",
            "  'output': ' First, we divide $88$ by $4$ to get $22$.\\n'\n",
            "            'Then, we divide $22$ by $2$ to get $11$.\\n'\n",
            "            'Finally, we divide $11$ by $4$ to get $\\\\boxed{2.75}$.\\n'\n",
            "            'The answer is: 2.75'},\n",
            " {'model_name': 'Base model (meta-llama/Llama-2-7b-chat-hf)',\n",
            "  'output': '\\n'\n",
            "            '\\n'\n",
            "            'What is the value of $88 \\\\div (4 \\\\div 2)$?\\n'\n",
            "            '\\n'\n",
            "            'To perform the division, we need to follow the standard '\n",
            "            'procedure:\\n'\n",
            "            '\\n'\n",
            "            '1. Divide the dividend (88) by the divisor (4): 88 ÷ 4 = 22\\n'\n",
            "            '2. Divide the result (22) by the divisor (2): 22 ÷ 2 = 11\\n'\n",
            "            '\\n'\n",
            "            'Therefore, the value of $88 \\\\div (4 \\\\div 2)$ is 11.'}]\n",
            "At a party with 23 attendees, each person shakes hands with at least two other people. What is the minimum number of handshakes that could occur?\n",
            "[{'model_name': 'e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd',\n",
            "  'output': ' Each handshake requires three people, so the minimum number of '\n",
            "            'handshakes is 23 x 3 = 69.\\n'\n",
            "            'Therefore, the minimum number of handshakes that could occur at '\n",
            "            'the party is 69.\\n'\n",
            "            'The answer is: 69'},\n",
            " {'model_name': 'Base model (meta-llama/Llama-2-7b-chat-hf)',\n",
            "  'output': '\\n'\n",
            "            '\\n'\n",
            "            'Answer: 46\\n'\n",
            "            '\\n'\n",
            "            'Explanation:\\n'\n",
            "            '\\n'\n",
            "            'Each person shakes hands with at least two other people, so the '\n",
            "            'total number of handshakes is at least 2 x 22 = 44. However, '\n",
            "            'since there are 23 attendees, the minimum number of handshakes '\n",
            "            'that could occur is 23 x 2 = 46.'}]\n",
            "The larger sphere has a radius of 6 units and the smaller sphere has a radius of 3 units. What is the volume, in cubic units, of the region between the larger sphere and the smaller sphere? Express your answer in terms of π.\n",
            "[{'model_name': 'e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd',\n",
            "  'output': ' The radius of the larger sphere is 6 units, and the radius of '\n",
            "            'the smaller sphere is 3 units.\\n'\n",
            "            'The distance between the centers of the two spheres is $6-3=3$ '\n",
            "            'units.\\n'\n",
            "            'The volume of a sphere with radius $r$ is $\\\\frac{4}{3}\\\\pi '\n",
            "            'r^3$.\\n'\n",
            "            'The volume of the region between the larger sphere and the '\n",
            "            'smaller sphere is the volume of the sphere that lies inside the '\n",
            "            'smaller sphere minus the volume of the sphere that lies outside '\n",
            "            'the smaller sphere.\\n'\n",
            "            'We can calculate these volumes using the formulae for the volumes '\n",
            "            'of spheres.\\n'\n",
            "            'The volume of the sphere that lies inside the smaller sphere is '\n",
            "            '$\\\\frac{4}{3}\\\\pi (6)^3 = 72\\\\pi$.\\n'\n",
            "            'The volume of the sphere that lies outside the smaller sphere is '\n",
            "            '$\\\\frac{4}{3}\\\\pi (3)^3 = 27\\\\pi$.\\n'\n",
            "            'Therefore, the volume of the region between the larger sphere and '\n",
            "            'the smaller sphere is $72\\\\pi - 27\\\\pi = \\\\boxed{45\\\\pi}$.\\n'\n",
            "            'The answer is: 45\\\\pi'},\n",
            " {'model_name': 'Base model (meta-llama/Llama-2-7b-chat-hf)',\n",
            "  'output': '\\n'\n",
            "            '\\n'\n",
            "            'Answer:\\n'\n",
            "            'The volume of the region between the larger sphere and the '\n",
            "            'smaller sphere can be calculated using the formula:\\n'\n",
            "            '\\n'\n",
            "            'V = (4/3)π(r1^3 - r2^3)\\n'\n",
            "            '\\n'\n",
            "            'where r1 is the radius of the larger sphere and r2 is the radius '\n",
            "            'of the smaller sphere.\\n'\n",
            "            '\\n'\n",
            "            'In this case, the radius of the larger sphere is 6 units, and the '\n",
            "            'radius of the smaller sphere is 3 units. So, we can plug these '\n",
            "            'values into the formula:\\n'\n",
            "            '\\n'\n",
            "            'V = (4/3)π(6^3 - 3^3)\\n'\n",
            "            '= (4/3)π(216 - 27)\\n'\n",
            "            '= (4/3)π189\\n'\n",
            "            '= 129π\\n'\n",
            "            '\\n'\n",
            "            'Therefore, the volume of the region between the larger sphere and '\n",
            "            'the smaller sphere is 129π cubic units.'}]\n",
            "If a regular polygon has a total of nine diagonals, what is the number of sides it has?\n",
            "[{'model_name': 'e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd',\n",
            "  'output': ' Each vertex of a polygon can be connected to every other vertex '\n",
            "            'except for the three vertices adjacent to it through two possible '\n",
            "            'diagonals.\\n'\n",
            "            'Since there are nine diagonals in total, the polygon has 9/2 = '\n",
            "            '4.5 sides.\\n'\n",
            "            'However, we cannot have a polygon with 4.5 sides, so the answer '\n",
            "            'is nine.\\n'\n",
            "            'The answer is: 9'},\n",
            " {'model_name': 'Base model (meta-llama/Llama-2-7b-chat-hf)',\n",
            "  'output': '\\n'\n",
            "            '\\n'\n",
            "            'Answer:\\n'\n",
            "            'A regular polygon with nine diagonals must have 9 sides.\\n'\n",
            "            '\\n'\n",
            "            'Explanation:\\n'\n",
            "            'A diagonal of a polygon is a line that connects two non-adjacent '\n",
            "            'vertices of the polygon. Since a regular polygon has all its '\n",
            "            'sides of equal length, the length of each diagonal is equal to '\n",
            "            'half the perimeter of the polygon.\\n'\n",
            "            '\\n'\n",
            "            'In a regular polygon with nine diagonals, the sum of the lengths '\n",
            "            'of all nine diagonals is equal to the perimeter of the polygon. '\n",
            "            'Therefore, the number of sides of the polygon is:\\n'\n",
            "            '\\n'\n",
            "            'Perimeter of polygon = 9 diagonals x length of each diagonal\\n'\n",
            "            '= 9 x (half the perimeter of the polygon)\\n'\n",
            "            '= 9 x (9 x side length)\\n'\n",
            "            '= 81 x side length\\n'\n",
            "            '\\n'\n",
            "            'So, the number of sides of a regular polygon with nine diagonals '\n",
            "            'is 81.'}]\n",
            "What is the square of the difference between the solutions $d$ and $e$ of the equation $3x^2 + 10x - 25 = 0$?\n",
            "[{'model_name': 'e62aa22bb8f467a12ee15beb7cdfde4da1793243bdd3d3d364b9e709c3f307fd',\n",
            "  'output': ' The solution to the equation $3x^2 + 10x - 25 = 0$ is $x = -5$.\\n'\n",
            "            'The difference between the solutions $d$ and $e$ is $d - e = 0$, '\n",
            "            'so $d = e$.\\n'\n",
            "            'The square of the difference is $(e - d)^2 = e^2 - 2d + d^2 = e^2 '\n",
            "            '- 2d + d^2 = 0$, so $e^2 - 2d + d^2 = 0$.\\n'\n",
            "            'Factoring, we have $(e - d)(e + d) = 0$, so $e - d = 0$ or $e + d '\n",
            "            '= 0$.\\n'\n",
            "            'Since $e > d$, we have $e - d = 0$ and $e + d = 0$.\\n'\n",
            "            'This means $e = d$ and $e^2 - 2d + d^2 = 0$.\\n'\n",
            "            'Substituting $e = d$, we have $d^2 - 2d + d^2 = 0$.\\n'\n",
            "            'Factoring, we have $(d - d)(d + d) = 0$, so $d'},\n",
            " {'model_name': 'Base model (meta-llama/Llama-2-7b-chat-hf)',\n",
            "  'output': '\\n'\n",
            "            '\\n'\n",
            "            'The solutions of the equation $3x^2 + 10x - 25 = 0$ are $d = -5$ '\n",
            "            'and $e = -3$. To find the square of the difference between these '\n",
            "            'solutions, we need to subtract $d$ from $e$.\\n'\n",
            "            '\\n'\n",
            "            '$$(e - d)^2 = (e + 3 - d)^2 = 9 + 6 = 15$$\\n'\n",
            "            '\\n'\n",
            "            'So, the square of the difference between the solutions $d$ and '\n",
            "            '$e$ is $15$.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arc evalution\n",
        "!python lm-evaluation-harness/main.py --model hf-causual --model_args pretrained=lamini/lamini_docs--tasks arc_easy -- device cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsAd5S5mDazy",
        "outputId": "1ac82bf8-c1b7-48a1-a47f-ed886d414fb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/lm-evaluation-harness/main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ]
}