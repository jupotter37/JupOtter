{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0174a131-88ce-4e0a-96ef-17cced1e81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4666631-f363-4c7a-b2fc-929db91d6f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fc8290fd9a4abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T16:07:19.154730Z",
     "start_time": "2024-05-17T16:07:16.336087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshehremen/miniconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import transformers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852132a0-88e6-4dd5-8747-d474e30f683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde828fd-f9dc-40ec-8547-41fcd3b26ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x733eea181ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(13)\n",
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1abeb65-7489-42cc-8d99-3a68acf1b188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71705c3-c98a-491d-bafe-9803f1bb1804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a22442-53d0-47cf-a456-1e18f5292578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T15:53:38.091237Z",
     "start_time": "2024-05-17T15:53:38.061261Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ebfda3-a603-413d-afe8-c8d8b0118799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_hallucination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Херманус Питер (Дик) Логгере (нидерл. Hermanus...</td>\n",
       "      <td>В каком городе проходил чемпионат мира по хокк...</td>\n",
       "      <td>В Хилверсюме.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ходуткинские горячие источники (Худутские горя...</td>\n",
       "      <td>Как называется район в который входят источники?</td>\n",
       "      <td>Елизовским районом</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Чёрная вдова (лат. Latrodectus mactans) — вид ...</td>\n",
       "      <td>Для кого опасны пауки-бокоходы?</td>\n",
       "      <td>Для рыб.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Рысь — река в России, протекает по территориям...</td>\n",
       "      <td>Какова длина реки Рысь?</td>\n",
       "      <td>5 км.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>И́се (яп. 伊勢市), ранее Удзиямада — город в Япон...</td>\n",
       "      <td>Что такое Исе?</td>\n",
       "      <td>Исе — это небольшой город в Японии, который не...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>Восемь незарегистрированных правителей (яп. 欠史...</td>\n",
       "      <td>Что связывают с императорским домом?</td>\n",
       "      <td>ни одна легенда не связывает их с Японией</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>«Гастингс» (англ. Hastings) — название военной...</td>\n",
       "      <td>Какой род войск проводил военную операцию под ...</td>\n",
       "      <td>Танковые войска.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>Bacillus cereus (лат.) — вид грамположительных...</td>\n",
       "      <td>У кого вызывает токсикоз?</td>\n",
       "      <td>У растений.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>Стеклова́та — волокнистый минеральный теплоизо...</td>\n",
       "      <td>Какой способностью обладает стекловата?</td>\n",
       "      <td>Стекловата обладает способностью проводить эле...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>Земляные работы, переработка грунта — работы, ...</td>\n",
       "      <td>Что такое рыхлый слой, располагающийся между п...</td>\n",
       "      <td>Грунт</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      line_id                                            summary  \\\n",
       "0           0  Херманус Питер (Дик) Логгере (нидерл. Hermanus...   \n",
       "1           1  Ходуткинские горячие источники (Худутские горя...   \n",
       "2           2  Чёрная вдова (лат. Latrodectus mactans) — вид ...   \n",
       "3           3  Рысь — река в России, протекает по территориям...   \n",
       "4           4  И́се (яп. 伊勢市), ранее Удзиямада — город в Япон...   \n",
       "...       ...                                                ...   \n",
       "1045     1045  Восемь незарегистрированных правителей (яп. 欠史...   \n",
       "1046     1046  «Гастингс» (англ. Hastings) — название военной...   \n",
       "1047     1047  Bacillus cereus (лат.) — вид грамположительных...   \n",
       "1048     1048  Стеклова́та — волокнистый минеральный теплоизо...   \n",
       "1049     1049  Земляные работы, переработка грунта — работы, ...   \n",
       "\n",
       "                                               question  \\\n",
       "0     В каком городе проходил чемпионат мира по хокк...   \n",
       "1      Как называется район в который входят источники?   \n",
       "2                       Для кого опасны пауки-бокоходы?   \n",
       "3                               Какова длина реки Рысь?   \n",
       "4                                        Что такое Исе?   \n",
       "...                                                 ...   \n",
       "1045               Что связывают с императорским домом?   \n",
       "1046  Какой род войск проводил военную операцию под ...   \n",
       "1047                          У кого вызывает токсикоз?   \n",
       "1048            Какой способностью обладает стекловата?   \n",
       "1049  Что такое рыхлый слой, располагающийся между п...   \n",
       "\n",
       "                                                 answer  is_hallucination  \n",
       "0                                         В Хилверсюме.                 1  \n",
       "1                                    Елизовским районом                 0  \n",
       "2                                              Для рыб.                 1  \n",
       "3                                                 5 км.                 1  \n",
       "4     Исе — это небольшой город в Японии, который не...                 1  \n",
       "...                                                 ...               ...  \n",
       "1045          ни одна легенда не связывает их с Японией                 0  \n",
       "1046                                   Танковые войска.                 1  \n",
       "1047                                        У растений.                 1  \n",
       "1048  Стекловата обладает способностью проводить эле...                 1  \n",
       "1049                                              Грунт                 0  \n",
       "\n",
       "[1050 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74454aba-2c5e-4ca1-8360-72763d9e2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['summary'] + \" \" + train_df['question'] + \" \" + train_df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "291c1ce1-5a88-4d24-a0f4-b3db1771ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshehremen/miniconda3/envs/dev/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#bert_name = 'bert-base-uncased'\n",
    "#bert_name = 'imvladikon/charbert-bert-wiki'\n",
    "bert_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
    "#model = BertForSequenceClassification.from_pretrained(bert_name, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa716076-a53d-4616-84d3-5ad40ae8bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, #[\"text\"], \n",
    "            padding='max_length', \n",
    "            max_length = 512, \n",
    "            truncation=True) #,\n",
    "            #return_tensors=\"pt\"\n",
    "    #return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "train_df['input_ids'] = train_df['text'].apply(tokenize_function)\n",
    "train_df['inputC'] = train_df['summary'].apply(tokenize_function)\n",
    "train_df['inputQ'] = train_df['question'].apply(tokenize_function)\n",
    "train_df['inputA'] = train_df['answer'].apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa739898-8b5d-4a44-b433-0ce637247dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe, proc):\n",
    "    ids_shu = list(dataframe['line_id'])\n",
    "    random.shuffle(ids_shu)\n",
    "    test  = ids_shu[:proc]\n",
    "    train_df = dataframe[~dataframe['line_id'].isin(test)]\n",
    "    test_df = dataframe[dataframe['line_id'].isin(test)]\n",
    "    return train_df, test_df\n",
    "\n",
    "posdf = train_df[train_df['is_hallucination'] == 1]\n",
    "negdf = train_df[train_df['is_hallucination'] == 0]\n",
    "\n",
    "train_pos, test_pos = split_dataframe(posdf, 100)\n",
    "train_neg, test_neg = split_dataframe(negdf, 100)\n",
    "#train_df[train_df['is_hallucination'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e510232c-08a5-4071-84cc-ec4dd74c4f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 100, 418, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos),len(test_pos),len(train_neg),len(test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a413952-ff85-4f6a-9e5e-44f26b547975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T15:53:38.091237Z",
     "start_time": "2024-05-17T15:53:38.061261Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_dataset = Dataset.from_pandas( pd.concat([train_pos, train_neg]).sample(frac=1) [['text', 'is_hallucination']] ) \n",
    "    val_dataset   = Dataset.from_pandas( pd.concat([test_pos, test_neg]).sample(frac=1) [['text', 'is_hallucination']] ) \n",
    "    train_dataset = train_dataset.rename_column(\"is_hallucination\", \"labels\")\n",
    "    val_dataset   = val_dataset.rename_column(\"is_hallucination\", \"labels\")\n",
    "    \n",
    "    if False:\n",
    "        train_dataset = Dataset.from_pandas(train_df[['text', 'is_hallucination']])\n",
    "        train_dataset = train_dataset.rename_column(\"is_hallucination\", \"labels\")\n",
    "        \n",
    "        train_test_split = train_dataset.train_test_split(test_size=0.2)\n",
    "        train_dataset = train_test_split['train']\n",
    "        val_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d60f98-4f36-4575-b278-372590eebb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1a14ef2fd8602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T15:53:39.195739Z",
     "start_time": "2024-05-17T15:53:38.091975Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f9e959-07f8-497f-a4a5-acd2377d40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassHall(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, activationfunc):\n",
    "        super().__init__()\n",
    "        self.BERTC = transformers.BertModel.from_pretrained(bert_name).to(device)\n",
    "        self.BERTQ = transformers.BertModel.from_pretrained(bert_name).to(device)\n",
    "        self.BERTA = transformers.BertModel.from_pretrained(bert_name).to(device)\n",
    "        #self.linear1 = torch.nn.Linear(768, hidden_size)\n",
    "        #self.act1 = activationfunc()\n",
    "        #self.linear2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.linear2 = torch.nn.Linear(768*3, output_size)\n",
    "        \n",
    "        self.act2 = torch.nn.Softmax(dim = 1) # activationfunc()\n",
    "        self.tofit = [False, False, False]\n",
    "        \n",
    "    def forward(self, inputC, inputQ, inputA,\n",
    "                      attentionC, attentionQ, attentionA):\n",
    "        #print(x)\n",
    "        #batches, x2, target, view = x\n",
    "        #h = self.BERTencoder( x, return_dict=False)[1]# self.BERTencoder(x)\n",
    "\n",
    "        hC = self.BERTC (input_ids=inputC,\n",
    "                         attention_mask=attentionC,\n",
    "                         return_dict=False)[1]\n",
    "        if not self.tofit[0]:\n",
    "            hC = hC.detach()\n",
    "        hQ = self.BERTQ (input_ids=inputQ,\n",
    "                         attention_mask=attentionQ,\n",
    "                         return_dict=False)[1]\n",
    "        if not self.tofit[0]:\n",
    "            hQ = hQ.detach()\n",
    "        hA = self.BERTA (input_ids=inputA,\n",
    "                         attention_mask=attentionA,\n",
    "                         return_dict=False)[1]\n",
    "        if not self.tofit[0]:\n",
    "            hA = hA.detach()\n",
    "        h = torch.cat([hC, hQ, hA], dim = 1)\n",
    "        #h = self.linear1(h)\n",
    "        #h = self.act1(h)\n",
    "        \n",
    "        h = self.linear2(h)\n",
    "        h = self.act2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38d4e5ab-92c4-4a8c-a4fd-4c9348efba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arshehremen/miniconda3/envs/dev/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ClassHall(256, 2, torch.nn.Tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f650ad9d-f801-4788-b448-adc42e4c3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "getlr = 2e-5\n",
    "weight_decay=0.01\n",
    "criterion   = torch.nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "optimizer   = torch.optim.AdamW(model.parameters(), lr= getlr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceac3708-330a-4bb2-94ba-b0e662c0a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_pos),len(test_pos),len(train_neg),len(test_neg)\n",
    "\n",
    "neg_value = [-1.0, 0.0][1] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a054a4bc-73ce-4f36-8c04-f314b3e37330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                  | 1/432 [00:00<02:16,  3.16it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 11.76 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 11.73 GiB memory in use. Of the allocated memory 11.03 GiB is allocated by PyTorch, and 413.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#groupatt    +=[ pos_att, neg_att ]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#auggroups = [made_aug(onegroup)  for onegroup in  groupetensor]\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#groupetensor = groupetensor + auggroups\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#line_tensor = torch.tensor(groupetensor).to(device) # torch.cat([onegroup for onegroup in groupetensor]).to(device)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#attention = torch.tensor(groupatt).to(device)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m fit_target \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mtensor(groupetarget)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#torch.cat([onegroup.reshape([1,*onegroup.shape ]) for onegroup in groupetarget]).float().to(device)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m output \u001b[38;5;241m=\u001b[39m model( \u001b[38;5;241m*\u001b[39mgroupetensor ,\u001b[38;5;241m*\u001b[39mgroupatt  ) \u001b[38;5;66;03m# line_tensor, attention ) #[:, -1, :]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, fit_target)\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36mClassHall.forward\u001b[0;34m(self, inputC, inputQ, inputA, attentionC, attentionQ, attentionA)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtofit[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     31\u001b[0m     hQ \u001b[38;5;241m=\u001b[39m hQ\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 32\u001b[0m hA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBERTA (input_ids\u001b[38;5;241m=\u001b[39minputA,\n\u001b[1;32m     33\u001b[0m                  attention_mask\u001b[38;5;241m=\u001b[39mattentionA,\n\u001b[1;32m     34\u001b[0m                  return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtofit[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     36\u001b[0m     hA \u001b[38;5;241m=\u001b[39m hA\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1014\u001b[0m     embedding_output,\n\u001b[1;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1016\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1017\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1018\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1019\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1020\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1021\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1022\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m    430\u001b[0m         head_mask,\n\u001b[1;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    433\u001b[0m         past_key_value,\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:349\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    346\u001b[0m         relative_position_scores_key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhrd,lrd->bhlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    347\u001b[0m         attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m relative_position_scores_query \u001b[38;5;241m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 349\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 11.76 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 11.73 GiB memory in use. Of the allocated memory 11.03 GiB is allocated by PyTorch, and 413.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "max_len = max(len(train_pos), len(train_neg))\n",
    "batch_size = 1\n",
    "\n",
    "#it_pos = list(train_pos['input_ids'])\n",
    "#it_neg = list(train_neg['input_ids'])\n",
    "it_posC = list(train_pos['inputC'])\n",
    "it_posQ = list(train_pos['inputQ'])\n",
    "it_posA = list(train_pos['inputA'])\n",
    "it_negC = list(train_neg['inputC'])\n",
    "it_negQ = list(train_neg['inputQ'])\n",
    "it_negA = list(train_neg['inputA'])\n",
    "model.train()\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.tofit = [False, False, False]\n",
    "    model.tofit[epoch] = True\n",
    "    for i in tqdm(range(max_len// batch_size)):\n",
    "        groupetensor = []\n",
    "        groupetarget = []\n",
    "        groupatt = []\n",
    "        for it in range(batch_size):\n",
    "            assert batch_size == 1\n",
    "            iterid = i*batch_size + it\n",
    "            for party_list in [[it_posC, it_negC], \n",
    "                               [it_posQ, it_negQ], \n",
    "                               [it_posA, it_negA] ]:\n",
    "                one_ids = torch.tensor([it_list[ iterid % len(it_list) ] ['input_ids']      for it_list  in party_list]).to(device)\n",
    "                one_att = torch.tensor([it_list[ iterid % len(it_list) ] ['attention_mask'] for it_list  in party_list]).to(device)\n",
    "                groupetensor += [one_ids]\n",
    "                groupatt    += [one_att]\n",
    "            #groupetensor+=[ pos_ids, neg_ids ]\n",
    "            groupetarget+=[ [neg_value,1.0],[1.0,neg_value]   ]\n",
    "            #groupatt    +=[ pos_att, neg_att ]\n",
    "        #auggroups = [made_aug(onegroup)  for onegroup in  groupetensor]\n",
    "        #groupetensor = groupetensor + auggroups\n",
    "        #line_tensor = torch.cat([torch.cat(onegroup).reshape([1,*torch.cat(onegroup).shape ]) for onegroup in groupetensor]).to(device)\n",
    "        #fit_target  = torch.cat([torch.cat(onegroup).reshape([1,*torch.cat(onegroup).shape ]) for onegroup in groupetarget]).to(device)\n",
    "        #line_tensor = torch.tensor(groupetensor).to(device) # torch.cat([onegroup for onegroup in groupetensor]).to(device)\n",
    "        #attention = torch.tensor(groupatt).to(device)\n",
    "        fit_target =  torch.tensor(groupetarget).to(device) #torch.cat([onegroup.reshape([1,*onegroup.shape ]) for onegroup in groupetarget]).float().to(device)\n",
    "        output = model( *groupetensor ,*groupatt  ) # line_tensor, attention ) #[:, -1, :]\n",
    "        loss = criterion(output, fit_target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "941008b3-10e4-439b-947e-90cc66552e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(train_pos),len(test_pos),len(train_neg),len(test_neg)\n",
    "it_pos = list(test_pos['input_ids'])\n",
    "it_neg = list(test_neg['input_ids'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tp = 0\n",
    "fn = 0\n",
    "for pos_ids in it_pos:\n",
    "    line_tensor = torch.tensor(pos_ids['input_ids'])\n",
    "    line_tensor = line_tensor.reshape(1, *line_tensor.shape ).to(device)\n",
    "    \n",
    "    attention = torch.tensor(pos_ids['attention_mask'])\n",
    "    attention = attention.reshape(1, *attention.shape ).to(device)\n",
    "    output = model(line_tensor, attention)\n",
    "    right_now = (output.argmax(dim = 1).detach().cpu() == torch.tensor([[neg_value,1.0]]).argmax(dim=1)).item()\n",
    "    tp += right_now\n",
    "    fn += 1-right_now\n",
    "\n",
    "tn = 0\n",
    "fp = 0\n",
    "for neg_ids in it_neg:\n",
    "    line_tensor = torch.tensor(neg_ids['input_ids'])\n",
    "    line_tensor = line_tensor.reshape(1, *line_tensor.shape ).to(device)\n",
    "    attention = torch.tensor(neg_ids['attention_mask'])\n",
    "    attention = attention.reshape(1, *attention.shape ).to(device)\n",
    "    output = model(line_tensor,attention)\n",
    "    right_now = (output.argmax(dim = 1).detach().cpu() == torch.tensor([[1.0,neg_value]]).argmax(dim=1)).item()\n",
    "    tn += right_now\n",
    "    fp += 1-right_now\n",
    "\n",
    "rec = tp/(tp+fn)\n",
    "pre = tp/(tp+fp)\n",
    "f1 = 2*(pre*rec)/(pre+rec)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eaf7ce6-86ec-44a7-b151-8879f89b0831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 0, 0, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp,fn,tn,fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fea508d-5a1e-43e8-8d1e-3ec615c34d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '0.85_f1_rubert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f57b044a-647d-445c-b722-ba22b547dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '0.76f1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918cd58b-2cc1-46b4-8b35-035d29729635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('0.98f1.pt'))\n",
    "#model.load_state_dict(torch.load('0.76f1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
