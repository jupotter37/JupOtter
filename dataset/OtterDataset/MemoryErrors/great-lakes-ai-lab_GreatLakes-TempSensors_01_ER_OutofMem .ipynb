{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.captureWarnings(False)\n",
    "\n",
    "import deepsensor.torch\n",
    "from deepsensor.data import DataProcessor, TaskLoader\n",
    "from deepsensor.model import ConvNP\n",
    "from deepsensor.train import Trainer\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "from deepsensor.train import set_gpu_default_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_rmse(model, val_tasks):\n",
    "    errors = []\n",
    "    target_var_ID = task_loader.target_var_IDs[0][0]  # assume 1st target set and 1D\n",
    "    for task in np.random.choice(val_tasks, 50, replace = False):\n",
    "#         print(\"im in for loop\")\n",
    "        mean = data_processor.map_array(model.mean(task), target_var_ID, unnorm=True)\n",
    "#         print(\"mean calc\")\n",
    "        true = data_processor.map_array(task[\"Y_t\"][0], target_var_ID, unnorm=True)\n",
    "#         print(\"true calc\")\n",
    "        errors.extend(np.abs(mean - true))\n",
    "    return np.sqrt(np.mean(np.concatenate(errors) ** 2))\n",
    "def gen_tasks(dates, progress=True):\n",
    "    tasks = []\n",
    "    for date in notebook.tqdm(dates, disable=not progress):\n",
    "#         N_c = np.random.randint(0, 500)\n",
    "        task = task_loader(date, context_sampling=[\"all\"], target_sampling=\"all\")\n",
    "        tasks.append(task)\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat15 ='/nfs/turbo/seas-dannes/SST-sensor-placement-input/GLSEA3_NETCDF/GLSEA3_2015.nc'\n",
    "dat14 ='/nfs/turbo/seas-dannes/SST-sensor-placement-input/GLSEA3_NETCDF/GLSEA3_2014.nc'\n",
    "dat16 ='/nfs/turbo/seas-dannes/SST-sensor-placement-input/GLSEA3_NETCDF/GLSEA3_2016.nc'\n",
    "\n",
    "dat = xr.open_mfdataset([dat14, dat15, dat16],\n",
    "                                concat_dim='time',\n",
    "                                combine='nested',\n",
    "                                chunks={'lat': 'auto', 'lon': 'auto'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdat = dat.where(np.isnan(dat.sst) == False, -0.009)\n",
    "climatology = mdat.groupby('time.dayofyear').mean('time')\n",
    "anomalies = mdat.groupby('time.dayofyear') - climatology\n",
    "data_processor = DataProcessor(x1_name=\"lat\", x2_name=\"lon\")\n",
    "anom_ds = data_processor(anomalies)\n",
    "task_loader = TaskLoader(\n",
    "    context = anom_ds,\n",
    "    target = anom_ds, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = []\n",
    "for date in pd.date_range('2015-01-02T12:00:00.000000000', '2015-12-31T12:00:00.000000000')[::5]:\n",
    "#     N_context = np.random.randint(0, 100)\n",
    "    task = task_loader(date, context_sampling=\"all\", target_sampling=\"all\")\n",
    "    train_tasks.append(task)\n",
    "val_tasks = []\n",
    "for date in pd.date_range('2016-01-01T12:00:00.000000000', '2016-12-31T12:00:00.000000000'):\n",
    "    N_context = np.random.randint(0, 100)\n",
    "    task = task_loader(date, context_sampling=\"all\", target_sampling=\"all\")\n",
    "    val_tasks.append(task)\n",
    "set_gpu_default_device()\n",
    "model = ConvNP(data_processor, task_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_rmses = []\n",
    "train_range = pd.date_range('2015-01-02T12:00:00.000000000', '2015-12-31T12:00:00.000000000')\n",
    "val_range = pd.date_range('2016-01-01T12:00:00.000000000', '2016-12-31T12:00:00.000000000')\n",
    "val_rmse_best = np.inf\n",
    "trainer = Trainer(model, lr=5e-5)\n",
    "for epoch in range(10):\n",
    "#     print(\"step1\")\n",
    "    train_tasks = gen_tasks(pd.date_range(train_range[0], train_range[1])[::5], progress=False)\n",
    "\n",
    "    batch_losses = trainer(train_tasks)\n",
    "#     print(\"step3\")\n",
    "    losses.append(np.mean(batch_losses))\n",
    "    val_rmses.append(compute_val_rmse(model, val_tasks))\n",
    "    if val_rmses[-1] < val_rmse_best:\n",
    "        val_rmse_best = val_rmses[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the cell that generated \"OutOfMemoryError: CUDA out of memory. Tried to allocate 5.25 GiB. GPU\" with 1gpu, and 15.75GiB wth 4 sgpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task = task_loader(\"2016-07-19T12:00:00.000000000\", [\"all\"], seed_override=42)\n",
    "pred = model.predict(test_task, X_t=anomalies, n_samples=3, ar_sample=True, ar_subsample_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepsensor_env_gpu)",
   "language": "python",
   "name": "deepsensor_env_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
