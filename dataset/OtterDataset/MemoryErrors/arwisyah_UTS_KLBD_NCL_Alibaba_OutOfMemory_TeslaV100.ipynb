{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVYAeuIpLAhl",
        "outputId": "d571c3da-ad94-4033-fec2-917efd5e6453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NCL'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 38 (delta 17), reused 18 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (38/38), 278.65 KiB | 1.51 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RUCAIBox/NCL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd NCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkLH2IPTMUDn",
        "outputId": "e50b5b9b-a3bd-415e-e573-49a0f37bc339"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "dPk_46udjxpP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/alibaba.zip dataset/\n",
        "!unzip dataset/alibaba.zip -d dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v0dlC3ukk9c",
        "outputId": "08350d14-d2ab-4ad1-9726-3777d277f7cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/alibaba.zip\n",
            "   creating: dataset/alibaba/\n",
            "  inflating: dataset/alibaba/alibaba.inter  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recbole"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt_Uc3KHUkMc",
        "outputId": "12b17600-a205-4ebd-ec9a-69f32fbcbc8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recbole\n",
            "  Downloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.11.3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (4.66.1)\n",
            "Collecting colorlog==4.7.2 (from recbole)\n",
            "  Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
            "Collecting colorama==0.4.4 (from recbole)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (6.0.1)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.14.1)\n",
            "Collecting thop>=0.1.1.post2207130030 (from recbole)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from recbole) (0.9.0)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (5.15.0)\n",
            "Collecting texttable>=0.9.0 (from recbole)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2023.3.post1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (2.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->recbole) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->recbole) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->recbole) (3.2.2)\n",
            "Installing collected packages: texttable, colorlog, colorama, thop, recbole\n",
            "Successfully installed colorama-0.4.4 colorlog-4.7.2 recbole-1.2.0 texttable-1.7.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clG6o1ntVfye",
        "outputId": "9f6e0307-6c78-4f61-9986-2ebc78c95a09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset alibaba"
      ],
      "metadata": {
        "id": "7x6kSYnxQ0HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae9a1a8-6a49-44f4-b183-2ed9d5a2aa67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NCL/main.py:65: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if args.config is not '':\n",
            "2023-11-01 15:51:53.182703: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-01 15:51:53.182773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-01 15:51:53.182813: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-01 15:51:53.194076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-01 15:51:54.745578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "command line args [--dataset alibaba] will not be used in RecBole\n",
            "01 Nov 15:51    INFO  \n",
            "\u001b[1;35mGeneral Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
            "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
            "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
            "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m dataset/alibaba\u001b[0m\n",
            "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
            "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\n",
            "\u001b[1;35mTraining Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
            "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
            "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
            "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
            "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
            "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
            "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
            "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
            "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mEvaluation Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
            "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'NDCG']\u001b[0m\n",
            "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10, 20, 50]\u001b[0m\n",
            "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m NDCG@10\u001b[0m\n",
            "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096000\u001b[0m\n",
            "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mDataset Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
            "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
            "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
            "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
            "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
            "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
            "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
            "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
            "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id']}\u001b[0m\n",
            "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
            "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
            "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
            "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
            "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
            "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
            "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
            "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
            "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\n",
            "\u001b[1;35mOther Hyper Parameters: \n",
            "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
            "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
            "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
            "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m64\u001b[0m\n",
            "\u001b[1;36mn_layers\u001b[0m = \u001b[1;33m3\u001b[0m\n",
            "\u001b[1;36mreg_weight\u001b[0m = \u001b[1;33m0.0001\u001b[0m\n",
            "\u001b[1;36mssl_temp\u001b[0m = \u001b[1;33m0.1\u001b[0m\n",
            "\u001b[1;36mssl_reg\u001b[0m = \u001b[1;33m1e-09\u001b[0m\n",
            "\u001b[1;36mhyper_layers\u001b[0m = \u001b[1;33m1\u001b[0m\n",
            "\u001b[1;36malpha\u001b[0m = \u001b[1;33m1\u001b[0m\n",
            "\u001b[1;36mproto_reg\u001b[0m = \u001b[1;33m1e-10\u001b[0m\n",
            "\u001b[1;36mnum_clusters\u001b[0m = \u001b[1;33m10000\u001b[0m\n",
            "\u001b[1;36mm_step\u001b[0m = \u001b[1;33m1\u001b[0m\n",
            "\u001b[1;36mwarm_up_step\u001b[0m = \u001b[1;33m20\u001b[0m\n",
            "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
            "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36mkg_reverse_r\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mentity_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
            "\u001b[1;36mrelation_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
            "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.GENERAL\u001b[0m\n",
            "\u001b[1;36meval_setting\u001b[0m = \u001b[1;33m{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}\u001b[0m\n",
            "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.PAIRWISE\u001b[0m\n",
            "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
            "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
            "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
            "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
            "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
            "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0m01 Nov 15:52    INFO  \u001b[1;35malibaba\u001b[0m\n",
            "\u001b[1;34mThe number of users\u001b[0m: 300001\n",
            "\u001b[1;34mAverage actions of users\u001b[0m: 5.359376666666667\n",
            "\u001b[1;34mThe number of items\u001b[0m: 81615\n",
            "\u001b[1;34mAverage actions of items\u001b[0m: 19.700210748155953\n",
            "\u001b[1;34mThe number of inters\u001b[0m: 1607813\n",
            "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.99343336543267%\n",
            "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id']\u001b[0m\n",
            "\u001b[0m01 Nov 15:52    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
            "\u001b[0m01 Nov 15:52    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096000]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
            "\u001b[0m/content/NCL/ncl.py:119: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  i = torch.LongTensor([row, col])\n",
            "\u001b[0m/content/NCL/ncl.py:121: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n",
            "  SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))\n",
            "\u001b[0m01 Nov 15:52    INFO  NCL(\n",
            "  (user_embedding): Embedding(300001, 64)\n",
            "  (item_embedding): Embedding(81615, 64)\n",
            "  (mf_loss): BPRLoss()\n",
            "  (reg_loss): EmbLoss()\n",
            ")\u001b[1;34m\n",
            "Trainable parameters\u001b[0m: 24423424\u001b[0m\n",
            "\u001b[0m01 Nov 15:52    INFO  Running E-step ! \u001b[0m\n",
            "\u001b[0mWARNING clustering 300001 points to 10000 centroids: please provide at least 390000 training points\n",
            "WARNING clustering 81615 points to 10000 centroids: please provide at least 390000 training points\n",
            "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                          | 0/250 [00:00<?, ?it/s]\u001b[0m\u001b[0m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m  File \"/content/NCL/main.py\", line 68, in <module>\n",
            "\u001b[0m    \u001b[0mrun_single_model(args)\u001b[0m\n",
            "\u001b[0m  File \"/content/NCL/main.py\", line 41, in run_single_model\n",
            "\u001b[0m    \u001b[0mbest_valid_score, best_valid_result = trainer.fit(\u001b[0m\n",
            "\u001b[0m  File \"/content/NCL/trainer.py\", line 47, in fit\n",
            "\u001b[0m    \u001b[0mtrain_loss = self._train_epoch(train_data, epoch_idx, show_progress=show_progress)\u001b[0m\n",
            "\u001b[0m  File \"/content/NCL/trainer.py\", line 133, in _train_epoch\n",
            "\u001b[0m    \u001b[0mlosses = loss_func(interaction)\u001b[0m\n",
            "\u001b[0m  File \"/content/NCL/ncl.py\", line 222, in calculate_loss\n",
            "\u001b[0m    \u001b[0mssl_loss = self.ssl_layer_loss(context_embedding, center_embedding, user, pos_item)\u001b[0m\n",
            "\u001b[0m  File \"/content/NCL/ncl.py\", line 189, in ssl_layer_loss\n",
            "\u001b[0m    \u001b[0mttl_score_user = torch.exp(ttl_score_user / self.ssl_temp).sum(dim=1)\u001b[0m\n",
            "\u001b[0mtorch.cuda\u001b[0m.\u001b[0mOutOfMemoryError\u001b[0m: \u001b[0mCUDA out of memory. Tried to allocate 4.58 GiB. GPU 0 has a total capacty of 15.77 GiB of which 4.16 GiB is free. Process 22321 has 11.61 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, and 50.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Alibaba.zip /content/NCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjDOPVplFxvF",
        "outputId": "7574ed71-d21d-44fc-ffdf-283b5856a1ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/NCL/ (stored 0%)\n",
            "  adding: content/NCL/.git/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/HEAD (deflated 25%)\n",
            "  adding: content/NCL/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/refs/heads/master (deflated 25%)\n",
            "  adding: content/NCL/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/NCL/.git/logs/refs/remotes/origin/HEAD (deflated 25%)\n",
            "  adding: content/NCL/.git/HEAD (stored 0%)\n",
            "  adding: content/NCL/.git/config (deflated 30%)\n",
            "  adding: content/NCL/.git/info/ (stored 0%)\n",
            "  adding: content/NCL/.git/info/exclude (deflated 28%)\n",
            "  adding: content/NCL/.git/objects/ (stored 0%)\n",
            "  adding: content/NCL/.git/objects/info/ (stored 0%)\n",
            "  adding: content/NCL/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/NCL/.git/objects/pack/pack-3a467bd8e7f2e21d3ff119cee96d7c2f3e0fda34.idx (deflated 42%)\n",
            "  adding: content/NCL/.git/objects/pack/pack-3a467bd8e7f2e21d3ff119cee96d7c2f3e0fda34.pack (deflated 0%)\n",
            "  adding: content/NCL/.git/index (deflated 43%)\n",
            "  adding: content/NCL/.git/refs/ (stored 0%)\n",
            "  adding: content/NCL/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/NCL/.git/refs/heads/master (stored 0%)\n",
            "  adding: content/NCL/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/NCL/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/NCL/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/NCL/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/NCL/.git/hooks/ (stored 0%)\n",
            "  adding: content/NCL/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/NCL/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/NCL/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/NCL/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/NCL/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/NCL/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/NCL/.git/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/NCL/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/NCL/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/NCL/.git/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/NCL/.git/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/NCL/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/NCL/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/NCL/.git/branches/ (stored 0%)\n",
            "  adding: content/NCL/.git/packed-refs (deflated 9%)\n",
            "  adding: content/NCL/.git/description (deflated 14%)\n",
            "  adding: content/NCL/dataset/ (stored 0%)\n",
            "  adding: content/NCL/dataset/alibaba.zip (stored 0%)\n",
            "  adding: content/NCL/dataset/alibaba/ (stored 0%)\n",
            "  adding: content/NCL/dataset/alibaba/alibaba.inter (deflated 67%)\n",
            "  adding: content/NCL/asset/ (stored 0%)\n",
            "  adding: content/NCL/asset/intro.png (deflated 4%)\n",
            "  adding: content/NCL/README.md (deflated 51%)\n",
            "  adding: content/NCL/trainer.py (deflated 72%)\n",
            "  adding: content/NCL/properties/ (stored 0%)\n",
            "  adding: content/NCL/properties/amazon-books.yaml (deflated 40%)\n",
            "  adding: content/NCL/properties/gowalla-merged.yaml (deflated 35%)\n",
            "  adding: content/NCL/properties/alibaba.yaml (deflated 35%)\n",
            "  adding: content/NCL/properties/ml-1m.yaml (deflated 39%)\n",
            "  adding: content/NCL/properties/overall.yaml (deflated 23%)\n",
            "  adding: content/NCL/properties/NCL.yaml (deflated 27%)\n",
            "  adding: content/NCL/properties/yelp.yaml (deflated 38%)\n",
            "  adding: content/NCL/main.py (deflated 64%)\n",
            "  adding: content/NCL/ncl.py (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/NCL_Alibaba.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7a6OjTmxGQZ9",
        "outputId": "b4e31bfa-ebd0-4bbd-af10-0d72bd7d3a60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_adef5bc6-53d3-48fb-864c-06c03aae3ba8\", \"NCL_Amazon.zip\", 14141660)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}