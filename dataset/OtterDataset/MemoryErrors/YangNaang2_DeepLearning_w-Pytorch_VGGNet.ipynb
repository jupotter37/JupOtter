{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox77b6U3Q89d"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as Datasets\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG 모델 정의\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self, features, output_dim):\n",
        "    super().__init__()\n",
        "    self.features = features\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(512*7*7, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096, output_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    h = x.view(x.shape[0], -1)\n",
        "    x = self.classifier(h)\n",
        "    return x, h"
      ],
      "metadata": {
        "id": "msox8iXiSht3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 유형 정의\n",
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "metadata": {
        "id": "8GHe4kjTXsKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG 계층 정의 VGG11사용 예정\n",
        "def get_vgg_layers(config, batch_norm):\n",
        "  layers = []\n",
        "  in_channels = 3\n",
        "\n",
        "  for c in config: #vgg11_config값들 가져와\n",
        "    assert c =='M' or isinstance(c, int)\n",
        "    if c == 'M': #불러온 값이 m이면 maxpooling 진행\n",
        "      layers += [nn.MaxPool2d(kernel_size=2)]\n",
        "    else: #불러온 값이 숫자면 conv2d 진행\n",
        "      conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
        "      if batch_norm: #배치 정규화 진행할건지\n",
        "        layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
        "      else:\n",
        "        layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "      in_channels = c\n",
        "\n",
        "  return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "xSam_sbLJvvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 계층 생성\n",
        "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)"
      ],
      "metadata": {
        "id": "MhyCcRHxSG0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG11 계층 확인\n",
        "print(vgg11_layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWa8XFdoXcql",
        "outputId": "e2b22e6e-9adf-4f0b-bf89-25ac4835b179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (27): ReLU(inplace=True)\n",
            "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG11 전체에 대한 네트워크\n",
        "OUTPUT_DIM = 2\n",
        "model = VGG(vgg11_layers, OUTPUT_DIM)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLWvYh4zYa6D",
        "outputId": "4988cdda-a502-4f03-c76b-4a476addfc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG11 사전 훈련된 모델 사용\n",
        "import torchvision.models as models\n",
        "pretrained_model = models.vgg11_bn(pretrained=True)\n",
        "print(pretrained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj0sXUSsZBWG",
        "outputId": "29c984d1-ca6b-4fc2-c303-8ff94768b3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n",
            "100%|██████████| 507M/507M [00:13<00:00, 40.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 데이터 전처리\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "04kZqB5jadtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file_uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "UXTu6J9-ch5n",
        "outputId": "4bec3228-315e-4eb7-ef7a-6f152c21af89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3792a802-d71f-4bb1-8c28-d8aedff6e67b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3792a802-d71f-4bb1-8c28-d8aedff6e67b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving catanddog.zip to catanddog.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip catanddog.zip -d catanddog/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jYKp49QenWU",
        "outputId": "69ef093e-c1ee-4d40-f2e0-1a85db501ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  catanddog.zip\n",
            "   creating: catanddog/test/\n",
            "   creating: catanddog/test/Cat/\n",
            "  inflating: catanddog/test/Cat/8104.jpg  \n",
            "  inflating: catanddog/test/Cat/8105.jpg  \n",
            "  inflating: catanddog/test/Cat/8106.jpg  \n",
            "  inflating: catanddog/test/Cat/cat.12426.jpg  \n",
            "  inflating: catanddog/test/Cat/cat.12495.jpg  \n",
            "  inflating: catanddog/test/Cat/cat.12496.jpg  \n",
            "   creating: catanddog/test/Dog/\n",
            "  inflating: catanddog/test/Dog/dog.116.jpg  \n",
            "  inflating: catanddog/test/Dog/dog.212.jpg  \n",
            "  inflating: catanddog/test/Dog/dog.213.jpg  \n",
            "  inflating: catanddog/test/Dog/dog.214.jpg  \n",
            "  inflating: catanddog/test/Dog/dog.215.jpg  \n",
            "  inflating: catanddog/test/Dog/dog.224.jpg  \n",
            "   creating: catanddog/train/\n",
            "   creating: catanddog/train/Cat/\n",
            "  inflating: catanddog/train/Cat/0.jpg  \n",
            "  inflating: catanddog/train/Cat/1.jpg  \n",
            "  inflating: catanddog/train/Cat/10.jpg  \n",
            "  inflating: catanddog/train/Cat/11.jpg  \n",
            "  inflating: catanddog/train/Cat/12.jpg  \n",
            "  inflating: catanddog/train/Cat/13.jpg  \n",
            "  inflating: catanddog/train/Cat/14.jpg  \n",
            "  inflating: catanddog/train/Cat/15.jpg  \n",
            "  inflating: catanddog/train/Cat/16.jpg  \n",
            "  inflating: catanddog/train/Cat/17.jpg  \n",
            "  inflating: catanddog/train/Cat/18.jpg  \n",
            "  inflating: catanddog/train/Cat/19.jpg  \n",
            "  inflating: catanddog/train/Cat/2.jpg  \n",
            "  inflating: catanddog/train/Cat/20.jpg  \n",
            "  inflating: catanddog/train/Cat/21.jpg  \n",
            "  inflating: catanddog/train/Cat/22.jpg  \n",
            "  inflating: catanddog/train/Cat/23.jpg  \n",
            "  inflating: catanddog/train/Cat/24.jpg  \n",
            "  inflating: catanddog/train/Cat/25.jpg  \n",
            "  inflating: catanddog/train/Cat/26.jpg  \n",
            "  inflating: catanddog/train/Cat/27.jpg  \n",
            "  inflating: catanddog/train/Cat/28.jpg  \n",
            "  inflating: catanddog/train/Cat/29.jpg  \n",
            "  inflating: catanddog/train/Cat/3.jpg  \n",
            "  inflating: catanddog/train/Cat/30.jpg  \n",
            "  inflating: catanddog/train/Cat/31.jpg  \n",
            "  inflating: catanddog/train/Cat/32.jpg  \n",
            "  inflating: catanddog/train/Cat/33.jpg  \n",
            "  inflating: catanddog/train/Cat/34.jpg  \n",
            "  inflating: catanddog/train/Cat/35.jpg  \n",
            "  inflating: catanddog/train/Cat/36.jpg  \n",
            "  inflating: catanddog/train/Cat/37.jpg  \n",
            "  inflating: catanddog/train/Cat/38.jpg  \n",
            "  inflating: catanddog/train/Cat/39.jpg  \n",
            "  inflating: catanddog/train/Cat/4.jpg  \n",
            "  inflating: catanddog/train/Cat/40.jpg  \n",
            "  inflating: catanddog/train/Cat/41.jpg  \n",
            "  inflating: catanddog/train/Cat/42.jpg  \n",
            "  inflating: catanddog/train/Cat/43.jpg  \n",
            "  inflating: catanddog/train/Cat/44.jpg  \n",
            "  inflating: catanddog/train/Cat/45.jpg  \n",
            "  inflating: catanddog/train/Cat/46.jpg  \n",
            "  inflating: catanddog/train/Cat/47.jpg  \n",
            "  inflating: catanddog/train/Cat/48.jpg  \n",
            "  inflating: catanddog/train/Cat/49.jpg  \n",
            "  inflating: catanddog/train/Cat/5.jpg  \n",
            "  inflating: catanddog/train/Cat/50.jpg  \n",
            "  inflating: catanddog/train/Cat/51.jpg  \n",
            "  inflating: catanddog/train/Cat/52.jpg  \n",
            "  inflating: catanddog/train/Cat/53.jpg  \n",
            "  inflating: catanddog/train/Cat/54.jpg  \n",
            "  inflating: catanddog/train/Cat/55.jpg  \n",
            "  inflating: catanddog/train/Cat/56.jpg  \n",
            "  inflating: catanddog/train/Cat/57.jpg  \n",
            "  inflating: catanddog/train/Cat/58.jpg  \n",
            "  inflating: catanddog/train/Cat/59.jpg  \n",
            "  inflating: catanddog/train/Cat/6.jpg  \n",
            "  inflating: catanddog/train/Cat/60.jpg  \n",
            "  inflating: catanddog/train/Cat/61.jpg  \n",
            "  inflating: catanddog/train/Cat/62.jpg  \n",
            "  inflating: catanddog/train/Cat/7.jpg  \n",
            "  inflating: catanddog/train/Cat/7539.jpg  \n",
            "  inflating: catanddog/train/Cat/7540.jpg  \n",
            "  inflating: catanddog/train/Cat/7541.jpg  \n",
            "  inflating: catanddog/train/Cat/7542.jpg  \n",
            "  inflating: catanddog/train/Cat/7543.jpg  \n",
            "  inflating: catanddog/train/Cat/7544.jpg  \n",
            "  inflating: catanddog/train/Cat/7545.jpg  \n",
            "  inflating: catanddog/train/Cat/7546.jpg  \n",
            "  inflating: catanddog/train/Cat/7547.jpg  \n",
            "  inflating: catanddog/train/Cat/7548.jpg  \n",
            "  inflating: catanddog/train/Cat/7549.jpg  \n",
            "  inflating: catanddog/train/Cat/7550.jpg  \n",
            "  inflating: catanddog/train/Cat/7551.jpg  \n",
            "  inflating: catanddog/train/Cat/7552.jpg  \n",
            "  inflating: catanddog/train/Cat/7553.jpg  \n",
            "  inflating: catanddog/train/Cat/7554.jpg  \n",
            "  inflating: catanddog/train/Cat/7555.jpg  \n",
            "  inflating: catanddog/train/Cat/7556.jpg  \n",
            "  inflating: catanddog/train/Cat/7557.jpg  \n",
            "  inflating: catanddog/train/Cat/7558.jpg  \n",
            "  inflating: catanddog/train/Cat/7559.jpg  \n",
            "  inflating: catanddog/train/Cat/7560.jpg  \n",
            "  inflating: catanddog/train/Cat/7561.jpg  \n",
            "  inflating: catanddog/train/Cat/7562.jpg  \n",
            "  inflating: catanddog/train/Cat/7563.jpg  \n",
            "  inflating: catanddog/train/Cat/7564.jpg  \n",
            "  inflating: catanddog/train/Cat/7565.jpg  \n",
            "  inflating: catanddog/train/Cat/7566.jpg  \n",
            "  inflating: catanddog/train/Cat/7567.jpg  \n",
            "  inflating: catanddog/train/Cat/7568.jpg  \n",
            "  inflating: catanddog/train/Cat/7569.jpg  \n",
            "  inflating: catanddog/train/Cat/7570.jpg  \n",
            "  inflating: catanddog/train/Cat/7571.jpg  \n",
            "  inflating: catanddog/train/Cat/7572.jpg  \n",
            "  inflating: catanddog/train/Cat/7573.jpg  \n",
            "  inflating: catanddog/train/Cat/7574.jpg  \n",
            "  inflating: catanddog/train/Cat/7575.jpg  \n",
            "  inflating: catanddog/train/Cat/7576.jpg  \n",
            "  inflating: catanddog/train/Cat/7577.jpg  \n",
            "  inflating: catanddog/train/Cat/7578.jpg  \n",
            "  inflating: catanddog/train/Cat/7579.jpg  \n",
            "  inflating: catanddog/train/Cat/7580.jpg  \n",
            "  inflating: catanddog/train/Cat/7581.jpg  \n",
            "  inflating: catanddog/train/Cat/7582.jpg  \n",
            "  inflating: catanddog/train/Cat/7583.jpg  \n",
            "  inflating: catanddog/train/Cat/7584.jpg  \n",
            "  inflating: catanddog/train/Cat/7585.jpg  \n",
            "  inflating: catanddog/train/Cat/7586.jpg  \n",
            "  inflating: catanddog/train/Cat/7587.jpg  \n",
            "  inflating: catanddog/train/Cat/7588.jpg  \n",
            "  inflating: catanddog/train/Cat/7589.jpg  \n",
            "  inflating: catanddog/train/Cat/7590.jpg  \n",
            "  inflating: catanddog/train/Cat/7591.jpg  \n",
            "  inflating: catanddog/train/Cat/7592.jpg  \n",
            "  inflating: catanddog/train/Cat/7593.jpg  \n",
            "  inflating: catanddog/train/Cat/7594.jpg  \n",
            "  inflating: catanddog/train/Cat/7595.jpg  \n",
            "  inflating: catanddog/train/Cat/7596.jpg  \n",
            "  inflating: catanddog/train/Cat/7597.jpg  \n",
            "  inflating: catanddog/train/Cat/7598.jpg  \n",
            "  inflating: catanddog/train/Cat/7599.jpg  \n",
            "  inflating: catanddog/train/Cat/7600.jpg  \n",
            "  inflating: catanddog/train/Cat/7601.jpg  \n",
            "  inflating: catanddog/train/Cat/7602.jpg  \n",
            "  inflating: catanddog/train/Cat/7603.jpg  \n",
            "  inflating: catanddog/train/Cat/7604.jpg  \n",
            "  inflating: catanddog/train/Cat/7605.jpg  \n",
            "  inflating: catanddog/train/Cat/7606.jpg  \n",
            "  inflating: catanddog/train/Cat/7607.jpg  \n",
            "  inflating: catanddog/train/Cat/7608.jpg  \n",
            "  inflating: catanddog/train/Cat/7609.jpg  \n",
            "  inflating: catanddog/train/Cat/7610.jpg  \n",
            "  inflating: catanddog/train/Cat/7611.jpg  \n",
            "  inflating: catanddog/train/Cat/7612.jpg  \n",
            "  inflating: catanddog/train/Cat/7613.jpg  \n",
            "  inflating: catanddog/train/Cat/7614.jpg  \n",
            "  inflating: catanddog/train/Cat/7615.jpg  \n",
            "  inflating: catanddog/train/Cat/7616.jpg  \n",
            "  inflating: catanddog/train/Cat/7617.jpg  \n",
            "  inflating: catanddog/train/Cat/7618.jpg  \n",
            "  inflating: catanddog/train/Cat/7619.jpg  \n",
            "  inflating: catanddog/train/Cat/7620.jpg  \n",
            "  inflating: catanddog/train/Cat/7621.jpg  \n",
            "  inflating: catanddog/train/Cat/7622.jpg  \n",
            "  inflating: catanddog/train/Cat/7623.jpg  \n",
            "  inflating: catanddog/train/Cat/7624.jpg  \n",
            "  inflating: catanddog/train/Cat/7625.jpg  \n",
            "  inflating: catanddog/train/Cat/7626.jpg  \n",
            "  inflating: catanddog/train/Cat/7627.jpg  \n",
            "  inflating: catanddog/train/Cat/7628.jpg  \n",
            "  inflating: catanddog/train/Cat/7629.jpg  \n",
            "  inflating: catanddog/train/Cat/7630.jpg  \n",
            "  inflating: catanddog/train/Cat/7631.jpg  \n",
            "  inflating: catanddog/train/Cat/7632.jpg  \n",
            "  inflating: catanddog/train/Cat/7633.jpg  \n",
            "  inflating: catanddog/train/Cat/7634.jpg  \n",
            "  inflating: catanddog/train/Cat/7635.jpg  \n",
            "  inflating: catanddog/train/Cat/7636.jpg  \n",
            "  inflating: catanddog/train/Cat/7637.jpg  \n",
            "  inflating: catanddog/train/Cat/7638.jpg  \n",
            "  inflating: catanddog/train/Cat/7639.jpg  \n",
            "  inflating: catanddog/train/Cat/7640.jpg  \n",
            "  inflating: catanddog/train/Cat/7641.jpg  \n",
            "  inflating: catanddog/train/Cat/7642.jpg  \n",
            "  inflating: catanddog/train/Cat/7643.jpg  \n",
            "  inflating: catanddog/train/Cat/7644.jpg  \n",
            "  inflating: catanddog/train/Cat/7645.jpg  \n",
            "  inflating: catanddog/train/Cat/7646.jpg  \n",
            "  inflating: catanddog/train/Cat/7647.jpg  \n",
            "  inflating: catanddog/train/Cat/7648.jpg  \n",
            "  inflating: catanddog/train/Cat/7649.jpg  \n",
            "  inflating: catanddog/train/Cat/7650.jpg  \n",
            "  inflating: catanddog/train/Cat/7651.jpg  \n",
            "  inflating: catanddog/train/Cat/7652.jpg  \n",
            "  inflating: catanddog/train/Cat/7653.jpg  \n",
            "  inflating: catanddog/train/Cat/7654.jpg  \n",
            "  inflating: catanddog/train/Cat/7655.jpg  \n",
            "  inflating: catanddog/train/Cat/7656.jpg  \n",
            "  inflating: catanddog/train/Cat/7657.jpg  \n",
            "  inflating: catanddog/train/Cat/8.jpg  \n",
            "  inflating: catanddog/train/Cat/9.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12360.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12361.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12362.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12363.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12364.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12365.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12366.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12367.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12368.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12369.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12370.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12371.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12372.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12373.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12374.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12375.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12376.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12377.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12378.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12379.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12380.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12381.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12382.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12383.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12384.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12385.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12386.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12387.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12388.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12389.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12390.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12391.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12392.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12393.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12394.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12395.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12396.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12397.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12398.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12399.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12400.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12401.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12402.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12403.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12404.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12405.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12406.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.12407.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8940.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8941.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8942.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8943.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8944.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8945.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8946.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8947.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8948.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8949.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8950.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8951.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8952.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8953.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8954.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8955.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8956.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8957.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8958.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8959.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8960.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8961.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8962.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8963.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8964.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8965.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8966.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8967.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8968.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8969.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8970.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8971.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8972.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8973.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8974.jpg  \n",
            "  inflating: catanddog/train/Cat/cat.8975.jpg  \n",
            "   creating: catanddog/train/Dog/\n",
            "  inflating: catanddog/train/Dog/0.jpg  \n",
            "  inflating: catanddog/train/Dog/1.jpg  \n",
            "  inflating: catanddog/train/Dog/10.jpg  \n",
            "  inflating: catanddog/train/Dog/1000.jpg  \n",
            "  inflating: catanddog/train/Dog/1001.jpg  \n",
            "  inflating: catanddog/train/Dog/1002.jpg  \n",
            "  inflating: catanddog/train/Dog/1003.jpg  \n",
            "  inflating: catanddog/train/Dog/1004.jpg  \n",
            "  inflating: catanddog/train/Dog/1005.jpg  \n",
            "  inflating: catanddog/train/Dog/1006.jpg  \n",
            "  inflating: catanddog/train/Dog/1007.jpg  \n",
            "  inflating: catanddog/train/Dog/1008.jpg  \n",
            "  inflating: catanddog/train/Dog/1009.jpg  \n",
            "  inflating: catanddog/train/Dog/1010.jpg  \n",
            "  inflating: catanddog/train/Dog/1011.jpg  \n",
            "  inflating: catanddog/train/Dog/1012.jpg  \n",
            "  inflating: catanddog/train/Dog/1013.jpg  \n",
            "  inflating: catanddog/train/Dog/1014.jpg  \n",
            "  inflating: catanddog/train/Dog/1015.jpg  \n",
            "  inflating: catanddog/train/Dog/1016.jpg  \n",
            "  inflating: catanddog/train/Dog/1017.jpg  \n",
            "  inflating: catanddog/train/Dog/1018.jpg  \n",
            "  inflating: catanddog/train/Dog/1019.jpg  \n",
            "  inflating: catanddog/train/Dog/1020.jpg  \n",
            "  inflating: catanddog/train/Dog/1021.jpg  \n",
            "  inflating: catanddog/train/Dog/1022.jpg  \n",
            "  inflating: catanddog/train/Dog/1023.jpg  \n",
            "  inflating: catanddog/train/Dog/1024.jpg  \n",
            "  inflating: catanddog/train/Dog/1025.jpg  \n",
            "  inflating: catanddog/train/Dog/1026.jpg  \n",
            "  inflating: catanddog/train/Dog/1027.jpg  \n",
            "  inflating: catanddog/train/Dog/1028.jpg  \n",
            "  inflating: catanddog/train/Dog/1029.jpg  \n",
            "  inflating: catanddog/train/Dog/1030.jpg  \n",
            "  inflating: catanddog/train/Dog/1031.jpg  \n",
            "  inflating: catanddog/train/Dog/1032.jpg  \n",
            "  inflating: catanddog/train/Dog/1033.jpg  \n",
            "  inflating: catanddog/train/Dog/1034.jpg  \n",
            "  inflating: catanddog/train/Dog/1035.jpg  \n",
            "  inflating: catanddog/train/Dog/1036.jpg  \n",
            "  inflating: catanddog/train/Dog/1037.jpg  \n",
            "  inflating: catanddog/train/Dog/1038.jpg  \n",
            "  inflating: catanddog/train/Dog/1039.jpg  \n",
            "  inflating: catanddog/train/Dog/1040.jpg  \n",
            "  inflating: catanddog/train/Dog/1041.jpg  \n",
            "  inflating: catanddog/train/Dog/1042.jpg  \n",
            "  inflating: catanddog/train/Dog/1043.jpg  \n",
            "  inflating: catanddog/train/Dog/1044.jpg  \n",
            "  inflating: catanddog/train/Dog/1045.jpg  \n",
            "  inflating: catanddog/train/Dog/1046.jpg  \n",
            "  inflating: catanddog/train/Dog/1047.jpg  \n",
            "  inflating: catanddog/train/Dog/1048.jpg  \n",
            "  inflating: catanddog/train/Dog/1049.jpg  \n",
            "  inflating: catanddog/train/Dog/1050.jpg  \n",
            "  inflating: catanddog/train/Dog/1051.jpg  \n",
            "  inflating: catanddog/train/Dog/1052.jpg  \n",
            "  inflating: catanddog/train/Dog/1053.jpg  \n",
            "  inflating: catanddog/train/Dog/1054.jpg  \n",
            "  inflating: catanddog/train/Dog/1055.jpg  \n",
            "  inflating: catanddog/train/Dog/1056.jpg  \n",
            "  inflating: catanddog/train/Dog/1057.jpg  \n",
            "  inflating: catanddog/train/Dog/1058.jpg  \n",
            "  inflating: catanddog/train/Dog/1059.jpg  \n",
            "  inflating: catanddog/train/Dog/1060.jpg  \n",
            "  inflating: catanddog/train/Dog/1061.jpg  \n",
            "  inflating: catanddog/train/Dog/1062.jpg  \n",
            "  inflating: catanddog/train/Dog/1063.jpg  \n",
            "  inflating: catanddog/train/Dog/1064.jpg  \n",
            "  inflating: catanddog/train/Dog/1065.jpg  \n",
            "  inflating: catanddog/train/Dog/1066.jpg  \n",
            "  inflating: catanddog/train/Dog/1067.jpg  \n",
            "  inflating: catanddog/train/Dog/1068.jpg  \n",
            "  inflating: catanddog/train/Dog/1069.jpg  \n",
            "  inflating: catanddog/train/Dog/1070.jpg  \n",
            "  inflating: catanddog/train/Dog/11.jpg  \n",
            "  inflating: catanddog/train/Dog/12.jpg  \n",
            "  inflating: catanddog/train/Dog/13.jpg  \n",
            "  inflating: catanddog/train/Dog/14.jpg  \n",
            "  inflating: catanddog/train/Dog/15.jpg  \n",
            "  inflating: catanddog/train/Dog/16.jpg  \n",
            "  inflating: catanddog/train/Dog/17.jpg  \n",
            "  inflating: catanddog/train/Dog/18.jpg  \n",
            "  inflating: catanddog/train/Dog/19.jpg  \n",
            "  inflating: catanddog/train/Dog/2.jpg  \n",
            "  inflating: catanddog/train/Dog/20.jpg  \n",
            "  inflating: catanddog/train/Dog/21.jpg  \n",
            "  inflating: catanddog/train/Dog/22.jpg  \n",
            "  inflating: catanddog/train/Dog/23.jpg  \n",
            "  inflating: catanddog/train/Dog/24.jpg  \n",
            "  inflating: catanddog/train/Dog/25.jpg  \n",
            "  inflating: catanddog/train/Dog/26.jpg  \n",
            "  inflating: catanddog/train/Dog/27.jpg  \n",
            "  inflating: catanddog/train/Dog/28.jpg  \n",
            "  inflating: catanddog/train/Dog/29.jpg  \n",
            "  inflating: catanddog/train/Dog/3.jpg  \n",
            "  inflating: catanddog/train/Dog/30.jpg  \n",
            "  inflating: catanddog/train/Dog/31.jpg  \n",
            "  inflating: catanddog/train/Dog/32.jpg  \n",
            "  inflating: catanddog/train/Dog/33.jpg  \n",
            "  inflating: catanddog/train/Dog/34.jpg  \n",
            "  inflating: catanddog/train/Dog/35.jpg  \n",
            "  inflating: catanddog/train/Dog/36.jpg  \n",
            "  inflating: catanddog/train/Dog/37.jpg  \n",
            "  inflating: catanddog/train/Dog/38.jpg  \n",
            "  inflating: catanddog/train/Dog/39.jpg  \n",
            "  inflating: catanddog/train/Dog/4.jpg  \n",
            "  inflating: catanddog/train/Dog/40.jpg  \n",
            "  inflating: catanddog/train/Dog/41.jpg  \n",
            "  inflating: catanddog/train/Dog/42.jpg  \n",
            "  inflating: catanddog/train/Dog/43.jpg  \n",
            "  inflating: catanddog/train/Dog/44.jpg  \n",
            "  inflating: catanddog/train/Dog/45.jpg  \n",
            "  inflating: catanddog/train/Dog/46.jpg  \n",
            "  inflating: catanddog/train/Dog/47.jpg  \n",
            "  inflating: catanddog/train/Dog/48.jpg  \n",
            "  inflating: catanddog/train/Dog/49.jpg  \n",
            "  inflating: catanddog/train/Dog/5.jpg  \n",
            "  inflating: catanddog/train/Dog/50.jpg  \n",
            "  inflating: catanddog/train/Dog/51.jpg  \n",
            "  inflating: catanddog/train/Dog/52.jpg  \n",
            "  inflating: catanddog/train/Dog/53.jpg  \n",
            "  inflating: catanddog/train/Dog/54.jpg  \n",
            "  inflating: catanddog/train/Dog/55.jpg  \n",
            "  inflating: catanddog/train/Dog/56.jpg  \n",
            "  inflating: catanddog/train/Dog/57.jpg  \n",
            "  inflating: catanddog/train/Dog/58.jpg  \n",
            "  inflating: catanddog/train/Dog/59.jpg  \n",
            "  inflating: catanddog/train/Dog/6.jpg  \n",
            "  inflating: catanddog/train/Dog/60.jpg  \n",
            "  inflating: catanddog/train/Dog/61.jpg  \n",
            "  inflating: catanddog/train/Dog/62.jpg  \n",
            "  inflating: catanddog/train/Dog/7.jpg  \n",
            "  inflating: catanddog/train/Dog/8.jpg  \n",
            "  inflating: catanddog/train/Dog/9.jpg  \n",
            "  inflating: catanddog/train/Dog/931.jpg  \n",
            "  inflating: catanddog/train/Dog/932.jpg  \n",
            "  inflating: catanddog/train/Dog/933.jpg  \n",
            "  inflating: catanddog/train/Dog/934.jpg  \n",
            "  inflating: catanddog/train/Dog/935.jpg  \n",
            "  inflating: catanddog/train/Dog/936.jpg  \n",
            "  inflating: catanddog/train/Dog/937.jpg  \n",
            "  inflating: catanddog/train/Dog/938.jpg  \n",
            "  inflating: catanddog/train/Dog/939.jpg  \n",
            "  inflating: catanddog/train/Dog/940.jpg  \n",
            "  inflating: catanddog/train/Dog/941.jpg  \n",
            "  inflating: catanddog/train/Dog/942.jpg  \n",
            "  inflating: catanddog/train/Dog/943.jpg  \n",
            "  inflating: catanddog/train/Dog/944.jpg  \n",
            "  inflating: catanddog/train/Dog/945.jpg  \n",
            "  inflating: catanddog/train/Dog/946.jpg  \n",
            "  inflating: catanddog/train/Dog/947.jpg  \n",
            "  inflating: catanddog/train/Dog/948.jpg  \n",
            "  inflating: catanddog/train/Dog/949.jpg  \n",
            "  inflating: catanddog/train/Dog/950.jpg  \n",
            "  inflating: catanddog/train/Dog/951.jpg  \n",
            "  inflating: catanddog/train/Dog/952.jpg  \n",
            "  inflating: catanddog/train/Dog/953.jpg  \n",
            "  inflating: catanddog/train/Dog/954.jpg  \n",
            "  inflating: catanddog/train/Dog/955.jpg  \n",
            "  inflating: catanddog/train/Dog/956.jpg  \n",
            "  inflating: catanddog/train/Dog/957.jpg  \n",
            "  inflating: catanddog/train/Dog/958.jpg  \n",
            "  inflating: catanddog/train/Dog/959.jpg  \n",
            "  inflating: catanddog/train/Dog/960.jpg  \n",
            "  inflating: catanddog/train/Dog/961.jpg  \n",
            "  inflating: catanddog/train/Dog/962.jpg  \n",
            "  inflating: catanddog/train/Dog/963.jpg  \n",
            "  inflating: catanddog/train/Dog/964.jpg  \n",
            "  inflating: catanddog/train/Dog/965.jpg  \n",
            "  inflating: catanddog/train/Dog/966.jpg  \n",
            "  inflating: catanddog/train/Dog/967.jpg  \n",
            "  inflating: catanddog/train/Dog/968.jpg  \n",
            "  inflating: catanddog/train/Dog/969.jpg  \n",
            "  inflating: catanddog/train/Dog/970.jpg  \n",
            "  inflating: catanddog/train/Dog/971.jpg  \n",
            "  inflating: catanddog/train/Dog/972.jpg  \n",
            "  inflating: catanddog/train/Dog/973.jpg  \n",
            "  inflating: catanddog/train/Dog/974.jpg  \n",
            "  inflating: catanddog/train/Dog/975.jpg  \n",
            "  inflating: catanddog/train/Dog/976.jpg  \n",
            "  inflating: catanddog/train/Dog/977.jpg  \n",
            "  inflating: catanddog/train/Dog/978.jpg  \n",
            "  inflating: catanddog/train/Dog/979.jpg  \n",
            "  inflating: catanddog/train/Dog/980.jpg  \n",
            "  inflating: catanddog/train/Dog/981.jpg  \n",
            "  inflating: catanddog/train/Dog/982.jpg  \n",
            "  inflating: catanddog/train/Dog/983.jpg  \n",
            "  inflating: catanddog/train/Dog/984.jpg  \n",
            "  inflating: catanddog/train/Dog/985.jpg  \n",
            "  inflating: catanddog/train/Dog/986.jpg  \n",
            "  inflating: catanddog/train/Dog/987.jpg  \n",
            "  inflating: catanddog/train/Dog/988.jpg  \n",
            "  inflating: catanddog/train/Dog/989.jpg  \n",
            "  inflating: catanddog/train/Dog/990.jpg  \n",
            "  inflating: catanddog/train/Dog/991.jpg  \n",
            "  inflating: catanddog/train/Dog/992.jpg  \n",
            "  inflating: catanddog/train/Dog/993.jpg  \n",
            "  inflating: catanddog/train/Dog/994.jpg  \n",
            "  inflating: catanddog/train/Dog/995.jpg  \n",
            "  inflating: catanddog/train/Dog/996.jpg  \n",
            "  inflating: catanddog/train/Dog/997.jpg  \n",
            "  inflating: catanddog/train/Dog/998.jpg  \n",
            "  inflating: catanddog/train/Dog/999.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10024.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10025.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10026.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10027.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10028.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10029.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10030.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10031.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10032.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10033.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10034.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10035.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10036.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10037.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10038.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10039.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10040.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10041.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10042.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10043.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10044.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10045.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10046.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10047.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10048.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10049.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10050.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10051.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10052.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10053.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10054.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10055.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10056.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10057.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10058.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10059.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10060.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10061.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10062.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10063.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10064.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10065.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10066.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10067.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10068.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10069.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10070.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10071.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10072.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10073.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10074.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10075.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10076.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10077.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10078.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10079.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10080.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10081.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10082.jpg  \n",
            "  inflating: catanddog/train/Dog/dog.10083.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imageFolder를 이용하여 데이터셋 불러오기\n",
        "train_path = 'catanddog/train'\n",
        "test_path =  'catanddog/test'\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    train_path,\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "    test_path,\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "print(len(train_dataset)), print(len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq-nJLXNbq0W",
        "outputId": "3a7ab7a1-8d76-414f-e20f-6dcf03ac7cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "529\n",
            "12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련과 검증 데이터 분할\n",
        "VALID_RATIO = 0.9\n",
        "n_train_examples = int(len(train_dataset) * VALID_RATIO)\n",
        "n_valid_examples = len(train_dataset) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(train_dataset, [n_train_examples, n_valid_examples])"
      ],
      "metadata": {
        "id": "L7MmydneteFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#검증 데이터 전처리\n",
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ],
      "metadata": {
        "id": "Rw1w4o70uFyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련, 검증, 테스트 데이터셋 수 확인\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dja9mjUHvRKH",
        "outputId": "9fa0f3b8-dfdf-4baa-9b0c-01f252b71602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 476\n",
            "Number of validation examples: 53\n",
            "Number of testing examples: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#메모리로 데이터 불러오기\n",
        "BATCH_SIZE = 128\n",
        "train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
        "valid_iterator = data.DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
        "test_iterator = data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "xVHy93LswBsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저와 손실 함수 정의\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "mLIwRq0awOjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 정확도 측정 함수\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "65ZiYPb4wbAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습 함수 정의\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "  for(x, y) in iterator:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y_pred, _ = model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "    acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "lZGZ3Kiiwun9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 성능 측정 함수\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for(x, y) in iterator:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred, _ = model(x)\n",
        "      loss = criterion(y_pred, y)\n",
        "      acc = calculate_accuracy(y_pred, y)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "l0xqxxGZyTi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 시간 측정 함수\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "mDKlgIR9y0le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "3pukH9G80sLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습\n",
        "EPOCHS = 1\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.monotonic()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "  end_time = time.monotonic()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Valid. Loss: {valid_loss:.3f} | Valid.Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "rlGVL18uzAgA",
        "outputId": "17241e0a-23e8-43f5-982a-d9acdca6d482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacity of 14.75 GiB of which 717.06 MiB is free. Process 9932 has 14.04 GiB memory in use. Of the allocated memory 13.37 GiB is allocated by PyTorch, and 548.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-712aa6f2910c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5ff89c208795>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5849ac6ec0df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacity of 14.75 GiB of which 717.06 MiB is free. Process 9932 has 14.04 GiB memory in use. Of the allocated memory 13.37 GiB is allocated by PyTorch, and 548.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "메모리 부족으로 학습이 안되었지만 책 내용대로 되었다 가정하고 진행"
      ],
      "metadata": {
        "id": "4exbxW8L3FYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터셋을 이용한 모델 성능 측정\n",
        "model.load_state_dict(torch.load('saved_weights.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "cEWi3yqi0d4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터셋을 이용한 모델의 예측 확인 함수\n",
        "def get_predictions(model, iterator):\n",
        "  model.eval()\n",
        "  images=[]\n",
        "  labels=[]\n",
        "  probs=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for (x, y) in iterator:\n",
        "      x = x.to(device)\n",
        "      y_pred, _ = model(x)\n",
        "      y_prob = F.softmax(y_pred, dim=-1)\n",
        "      top_pred = y_prob.argmax(1, keepdim=True)\n",
        "      images.append(x.cpu())\n",
        "      labels.append(y.cpu())\n",
        "      probs.append(y_prob.cpu())\n",
        "\n",
        "  images = torch.cat(images, dim=0)\n",
        "  labels = torch.cat(labels, dim=0)\n",
        "  probs = torch.cat(probs, dim=0)\n",
        "\n",
        "  return images, labels, probs"
      ],
      "metadata": {
        "id": "RjXUJKj2-LhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 중에서 정확하게 예측한 것들 추출\n",
        "images, labels, probs = get_predictions(model, test_iterator)\n",
        "pred_labels = torch.argmax(probs, 1)\n",
        "corrects = torch.eq(labels, pred_labels)\n",
        "correct_examples=[]\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
        "  if correct:\n",
        "    correct_examples.append((image, label, prob))\n",
        "\n",
        "correct_examples.sort(reserve=True, ket=lambda x: torch.max(x[2], dim=0).values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "YbAOvAfhAaCO",
        "outputId": "56938f4b-08f2-4080-b0bd-4a886dd37889"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_predictions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b0b975f55106>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#예측 중에서 정확하게 예측한 것들 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 출력을 위한 전처리\n",
        "def normalize_image(image):\n",
        "  image_min = image.min()\n",
        "  image_max = image.max()\n",
        "  image.clamp_(min=image_min, max=image_max)\n",
        "  image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "  return image"
      ],
      "metadata": {
        "id": "AjIPdJ8qIRk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델이 정확하게 예측한 이미지 출력 함수\n",
        "def plot_most_correct(correct, classes, n_images, normalize=True):\n",
        "  rows = int(np.sqrt(n_images))\n",
        "  cols = int(np.sqrt(n_images))\n",
        "  fig = plt.figure(figsize=(25, 20))\n",
        "  for i in range(rows*cols):\n",
        "    ax = fig.add_subplot(rows, cols, i+1)\n",
        "    image, true_label, probs = correct[i]\n",
        "    image = image.permute(1,2,0)\n",
        "    true_prob = probs[true_label]\n",
        "    correct_prob, correct_label = torch.max(probs, dim=0)\n",
        "    true_class = classes[true_label]\n",
        "    correct_class = classes[correct_label]\n",
        "\n",
        "    if normalize:\n",
        "      image = normalize_image(image)\n",
        "\n",
        "    ax.imshow(image.numpy())\n",
        "    ax.seet_title(f'true label: {true_class} ({true_prob:.2f}) \\n' \\\n",
        "                  f'pred label: {correct_class} ({correct_prob:.3f})')\n",
        "    ax.axis('off')\n",
        "\n",
        "  fig.subplots_adjust(hspace=0.4)"
      ],
      "metadata": {
        "id": "3CsGmzX7IrPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 결과 이미지 출력\n",
        "classes = test_dataset.classes\n",
        "N_IMAGES = 5\n",
        "plot_most_correct(correct_examples, classes, N_IMAGES)"
      ],
      "metadata": {
        "id": "FZwb6UVLKMX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGwK7OYvKssM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}