{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PFJmrpevWEf"
   },
   "source": [
    "# TransE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfSjZAj6wR6f",
    "outputId": "9019e5d5-0b28-467f-fe2a-28a15c4ae8fb"
   },
   "outputs": [],
   "source": [
    "!pip install pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xBWw3RBQvWEh"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from pydantic_settings import BaseSettings\n",
    "from typing import Optional, Literal, Tuple, Dict, List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIp-U3BevWEi"
   },
   "source": [
    "## Config Class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rhu8wT1jvWEi"
   },
   "outputs": [],
   "source": [
    "class DatasetConf(BaseSettings):\n",
    "    \"\"\"\n",
    "    Related configuration information of the data set\n",
    "    \"\"\"\n",
    "    dataset_name: str = Field(title='The name of the data set for easy viewing when printing')\n",
    "    base_dir: str = Field(title='Directory of the dataset')\n",
    "    entity2id_path: str = Field(default='entity2id.txt', title='entity2id')\n",
    "    relation2id_path: str = Field(default='relation2id.txt', title='relation2id')\n",
    "    train_path: str = Field(default='train.txt', title='training set')\n",
    "    valid_path: str = Field(default='valid.txt', title='valid set')\n",
    "    test_path: str = Field(default='test.txt', title='testing set')\n",
    "\n",
    "\n",
    "class HyperParam(BaseModel):\n",
    "    \"\"\"\n",
    "    hyperparameters\n",
    "    \"\"\"\n",
    "    batch_size: int = 128\n",
    "    valid_batch_size: int = 64\n",
    "    learning_rate: float = 0.001\n",
    "    epoch_size: int = 500\n",
    "    embed_dim: int = 50\n",
    "    norm: int = 1\n",
    "    margin: int = 2.0\n",
    "    valid_freq: int = Field(title='During the training process, perform valid every few times to verify whether the model is saved.')\n",
    "\n",
    "\n",
    "class TrainConf(BaseModel):\n",
    "    \"\"\"\n",
    "    Some configurations for training\n",
    "    \"\"\"\n",
    "    checkpoint_path: str = Field(title='Path to save the model')\n",
    "    metric_result_path: str = Field(title='The metric output location of running test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ekrn4LifvWEi"
   },
   "source": [
    "## Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cr8Y_PP7vWEj"
   },
   "outputs": [],
   "source": [
    "EntityMapping = Dict[str, int]\n",
    "RelMapping = Dict[str, int]\n",
    "Triple = List[int]\n",
    "\n",
    "def create_mapping(dataset_conf: DatasetConf) -> Tuple[EntityMapping, RelMapping]:\n",
    "    \"\"\"\n",
    "    create mapping of `entity2id` and `relation2id`\n",
    "    \"\"\"\n",
    "    # 读取 entity2id\n",
    "    entity2id = dict()\n",
    "    with open(dataset_conf.base_dir + dataset_conf.entity2id_path) as f:\n",
    "        for line in f:\n",
    "            entity, entity_id = line.split('\\t')\n",
    "            entity = entity.strip()\n",
    "            entity_id = int(entity_id.strip())\n",
    "            entity2id[entity] = entity_id\n",
    "    # 读取 relation2id\n",
    "    rel2id = dict()\n",
    "    with open(dataset_conf.base_dir + dataset_conf.relation2id_path) as f:\n",
    "        for line in f:\n",
    "            rel, rel_id = line.split()\n",
    "            rel = rel.strip()\n",
    "            rel_id = int(rel_id.strip())\n",
    "            rel2id[rel] = rel_id\n",
    "    return entity2id, rel2id\n",
    "\n",
    "\n",
    "class KRLDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset_conf: DatasetConf,\n",
    "                 mode: Literal['train', 'valid', 'test'],\n",
    "                 entity2id: Dict[str, int],\n",
    "                 rel2id: Dict[str, int]) -> None:\n",
    "        super().__init__()\n",
    "        self.conf = dataset_conf\n",
    "        self.mode = mode\n",
    "        self.triples = []\n",
    "        self.entity2id = entity2id\n",
    "        self.rel2id = rel2id\n",
    "        self._read_triples()\n",
    "\n",
    "    def _split_and_to_id(self, line: str) -> Triple:\n",
    "        \"\"\"Split a row of data in the data set file and convert entity and rel into id\n",
    "\n",
    "        :param line: A row of data in the dataset\n",
    "        :return: [head_id, rel_id, tail_id]\n",
    "        \"\"\"\n",
    "        head, tail, rel = line.split()\n",
    "        head_id = self.entity2id[head.strip()]\n",
    "        rel_id = self.rel2id[rel.strip()]\n",
    "        tail_id = self.entity2id[tail.strip()]\n",
    "        return (head_id, rel_id, tail_id)\n",
    "\n",
    "    def _read_triples(self):\n",
    "        data_path = {\n",
    "            'train': self.conf.train_path,\n",
    "            'valid': self.conf.valid_path,\n",
    "            'test': self.conf.test_path\n",
    "        }.get(self.mode)\n",
    "        with open(self.conf.base_dir + data_path) as f:\n",
    "            self.triples = [self._split_and_to_id(line) for line in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples.\"\"\"\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, index) -> Triple:\n",
    "        \"\"\"Returns (head id, relation id, tail id).\"\"\"\n",
    "        triple = self.triples[index]\n",
    "        return triple[0], triple[1], triple[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-4P33sWvWEj"
   },
   "source": [
    "## Negative Sampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l3P0M88GvWEj"
   },
   "outputs": [],
   "source": [
    "class NegativeSampler(ABC):\n",
    "    def __init__(self, dataset: KRLDataset, device: torch.device):\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "\n",
    "    @abstractmethod\n",
    "    def neg_sample(self, heads, rels, tails):\n",
    "        \"\"\"Perform negative sampling\n",
    "\n",
    "        :param heads: tensor consisting of batch_size head idx, size: [batch_size]\n",
    "        :param rels: size [batch_size]\n",
    "        :param tails: size [batch_size]\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BP51nRTAvWEk"
   },
   "outputs": [],
   "source": [
    "class RandomNegativeSampler(NegativeSampler):\n",
    "    \"\"\"\n",
    "    Randomly replace head or tail to implement sampling\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: KRLDataset, device: torch.device):\n",
    "        super().__init__(dataset, device)\n",
    "\n",
    "    def neg_sample(self, heads, rels, tails):\n",
    "        ent_num = len(self.dataset.entity2id)\n",
    "        head_or_tail = torch.randint(high=2, size=heads.size(), device=self.device)\n",
    "        random_entities = torch.randint(high=ent_num, size=heads.size(), device=self.device)\n",
    "        corupted_heads = torch.where(head_or_tail == 1, random_entities, heads)\n",
    "        corupted_tails = torch.where(head_or_tail == 0, random_entities, tails)\n",
    "        return torch.stack([corupted_heads, rels, corupted_tails], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScltT0sYvWEk"
   },
   "source": [
    "## Model\n",
    "\n",
    "Defining the TransE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ybmN5eqsvWEk"
   },
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ent_num: int,\n",
    "        rel_num: int,\n",
    "        device: torch.device,\n",
    "        norm: int,\n",
    "        embed_dim: int,\n",
    "        margin: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ent_num = ent_num\n",
    "        self.rel_num = rel_num\n",
    "        self.device = device\n",
    "        self.norm = norm\n",
    "        self.embed_dim = embed_dim\n",
    "        self.margin = margin\n",
    "\n",
    "        # Initialize ent_embedding\n",
    "        self.ent_embedding = nn.Embedding(self.ent_num, self.embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.ent_embedding.weight.data)\n",
    "        #uniform_range = 6 / np.sqrt(self.embed_dim)\n",
    "        #self.ent_embedding.weight.data.uniform_(-uniform_range, uniform_range)\n",
    "\n",
    "        # Initialize rel_embedding\n",
    "        self.rel_embedding = nn.Embedding(self.rel_num, self.embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.rel_embedding.weight.data)\n",
    "        #uniform_range = 6 / np.sqrt(self.embed_dim)\n",
    "        #self.rel_embedding.weight.data.uniform_(-uniform_range, uniform_range)\n",
    "\n",
    "        self.criterion = nn.MarginRankingLoss(margin=self.margin)\n",
    "\n",
    "    def _distance(self, triples):\n",
    "        \"\"\"Calculate the distance of a batch's triplet\n",
    "\n",
    "        :param triples: triples of a batch，size: [batch, 3]\n",
    "        :return: size: [batch,]\n",
    "        \"\"\"\n",
    "        heads = triples[:, 0]\n",
    "        rels = triples[:, 1]\n",
    "        tails = triples[:, 2]\n",
    "        h_embs = self.ent_embedding(heads)  # h_embs: [batch, embed_dim]\n",
    "        r_embs = self.rel_embedding(rels)\n",
    "        t_embs = self.ent_embedding(tails)\n",
    "        dist = h_embs + r_embs - t_embs  # [batch, embed_dim]\n",
    "        return torch.norm(dist, p=self.norm, dim=1)\n",
    "\n",
    "    def loss(self, pos_distances, neg_distances):\n",
    "        \"\"\"Calculate the loss of TransE training\n",
    "\n",
    "        :param pos_distances: [batch, ]\n",
    "        :param neg_distances: [batch, ]\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        ones = torch.tensor([-1], dtype=torch.long, device=self.device)\n",
    "        return self.criterion(pos_distances, neg_distances, ones)\n",
    "\n",
    "    def forward(self, pos_triples: torch.Tensor, neg_triples: torch.Tensor):\n",
    "        \"\"\"Return model losses based on the input.\n",
    "\n",
    "        :param pos_triples: triplets of positives in Bx3 shape (B - batch, 3 - head, relation and tail)\n",
    "        :param neg_triples: triplets of negatives in Bx3 shape (B - batch, 3 - head, relation and tail)\n",
    "        :return: tuple of the model loss, positive triplets loss component, negative triples loss component\n",
    "        \"\"\"\n",
    "        assert pos_triples.size()[1] == 3\n",
    "        assert neg_triples.size()[1] == 3\n",
    "\n",
    "        pos_distances = self._distance(pos_triples)\n",
    "        neg_distances = self._distance(neg_triples)\n",
    "        loss = self.loss(pos_distances, neg_distances)\n",
    "        return loss, pos_distances, neg_distances\n",
    "\n",
    "    def predict(self, triples: torch.Tensor):\n",
    "        \"\"\"Calculated dissimilarity score for given triplets.\n",
    "\n",
    "        :param triplets: triplets in Bx3 shape (B - batch, 3 - head, relation and tail)\n",
    "        :return: dissimilarity score for given triplets\n",
    "        \"\"\"\n",
    "        return self._distance(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8YWXnjGvWEl"
   },
   "source": [
    "## Metric\n",
    "\n",
    "Calculate the metric for measuring the effect of link prediction, i.e. MRR and hits@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fNPmx2JKvWEl"
   },
   "outputs": [],
   "source": [
    "# metric\n",
    "\n",
    "def cal_hits_at_k(\n",
    "    predictions: torch.Tensor,\n",
    "    ground_truth_idx: torch.Tensor,\n",
    "    device: torch.device,\n",
    "    k: int\n",
    ") -> float:\n",
    "    \"\"\"Calculates number of hits@k.\n",
    "\n",
    "    :param predictions: BxN tensor of prediction values where B is batch size and N number of classes. Predictions\n",
    "    must be sorted in class ids order\n",
    "    :param ground_truth_idx: Bx1 tensor with index of ground truth class\n",
    "    :param k: number of top K results to be considered as hits\n",
    "    :return: Hits@K scoreH\n",
    "    \"\"\"\n",
    "    assert predictions.size()[0] == ground_truth_idx.size()[0]  # has the same batch_size\n",
    "\n",
    "    zero_tensor = torch.tensor([0], device=device)\n",
    "    one_tensor = torch.tensor([1], device=device)\n",
    "    _, indices = predictions.topk(k, largest=False)  # indices: [batch_size, k]\n",
    "    where_flags = indices == ground_truth_idx  # where_flags: [batch_size, k], type: bool\n",
    "    hits = torch.where(where_flags, one_tensor, zero_tensor).sum().item()\n",
    "    return hits\n",
    "\n",
    "def cal_mrr(predictions: torch.Tensor, ground_truth_idx: torch.Tensor) -> float:\n",
    "    \"\"\"Calculates mean reciprocal rank (MRR) for given predictions and ground truth values.\n",
    "\n",
    "    :param predictions: BxN tensor of prediction values where B is batch size and N number of classes. Predictions\n",
    "    must be sorted in class ids order\n",
    "    :param ground_truth_idx: Bx1 tensor with index of ground truth class\n",
    "    :return: Mean reciprocal rank score\n",
    "    \"\"\"\n",
    "    assert predictions.size(0) == ground_truth_idx.size(0)\n",
    "\n",
    "    indices = predictions.argsort()\n",
    "    return (1.0 / (indices == ground_truth_idx).nonzero()[:, 1].float().add(1.0)).sum().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOyxp4eLvWEl"
   },
   "source": [
    "## Inference Operation\n",
    "\n",
    "Run the inference process for the model, i.e., iterate through the validation or test set and compute the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tNtFE25cvWEl"
   },
   "outputs": [],
   "source": [
    "def run_testing(\n",
    "    model: TransE,\n",
    "    dataloader: DataLoader,\n",
    "    ent_num: int,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Run test programs against Trans models\n",
    "\n",
    "    :param model: TransE model\n",
    "    :param ent_num: Number of entities in the dataset\n",
    "    :return: _description_\n",
    "    \"\"\"\n",
    "    hits_at_1 = 0.0\n",
    "    hits_at_3 = 0.0\n",
    "    hits_at_10 = 0.0\n",
    "    mrr = 0.0\n",
    "    examples_count = 0\n",
    "\n",
    "    # entity_ids = [[0, 1, 2, ..., ent_num]], shape: [1, ent_num]\n",
    "    entitiy_ids = torch.arange(0, ent_num, device=device).unsqueeze(0)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # batch: [3, batch_size]\n",
    "        heads, rels, tails = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        batch_size = heads.size()[0]\n",
    "        all_entities = entitiy_ids.repeat(batch_size, 1)  # all_entities: [batch_size, ent_num]\n",
    "        # heads: [batch_size,] -> [batch_size, 1] -> [batch_size, ent_num]\n",
    "        heads_expanded = heads.reshape(-1, 1).repeat(1, ent_num)  # _expanded: [batch_size, ent_num]\n",
    "        rels_expanded = rels.reshape(-1, 1).repeat(1, ent_num)\n",
    "        tails_expanded = tails.reshape(-1, 1).repeat(1, ent_num)\n",
    "        # check all possible tails\n",
    "        triplets = torch.stack([heads_expanded, rels_expanded, all_entities], dim=2).reshape(-1, 3)  # triplets: [batch_size * ent_num, 3]\n",
    "        tails_predictions = model.predict(triplets).reshape(batch_size, -1)  # tails_prediction: [batch_size, ent_num]\n",
    "        # check all possible heads\n",
    "        triplets = torch.stack([all_entities, rels_expanded, tails_expanded], dim=2).reshape(-1, 3)\n",
    "        heads_predictions = model.predict(triplets).reshape(batch_size, -1)  # heads_prediction: [batch_size, ent_num]\n",
    "\n",
    "        # Concept preditions\n",
    "        predictions = torch.cat([tails_predictions, heads_predictions], dim=0)  # predictions: [batch_size * 2, ent_num]\n",
    "        ground_truth_entity_id = torch.cat([tails.reshape(-1, 1), heads.reshape(-1, 1)], dim=0)  # [batch_size * 2, 1]\n",
    "        # calculate metrics\n",
    "        hits_at_1 += cal_hits_at_k(predictions, ground_truth_entity_id, device=device, k=1)\n",
    "        hits_at_3 += cal_hits_at_k(predictions, ground_truth_entity_id, device=device, k=3)\n",
    "        hits_at_10 += cal_hits_at_k(predictions, ground_truth_entity_id, device=device, k=10)\n",
    "        mrr += cal_mrr(predictions, ground_truth_entity_id)\n",
    "\n",
    "        examples_count += predictions.size()[0]\n",
    "\n",
    "    hits_at_1_score = hits_at_1 / examples_count * 100\n",
    "    hits_at_3_score = hits_at_3 / examples_count * 100\n",
    "    hits_at_10_score = hits_at_10 / examples_count * 100\n",
    "    mrr_score = mrr / examples_count * 100\n",
    "\n",
    "    return hits_at_1_score, hits_at_3_score, hits_at_10_score, mrr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2m4EPwavWEl"
   },
   "source": [
    "## Checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i0X_BpztvWEl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_state_dict\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CheckpointFormat(BaseModel):\n",
    "    model_state_dict: dict\n",
    "    optim_state_dict: dict\n",
    "    epoch_id: int\n",
    "    best_score: float\n",
    "\n",
    "\n",
    "def save_checkpoint(model: TransE,\n",
    "                    optimzer: torch.optim.Optimizer,\n",
    "                    epoch_id: int,\n",
    "                    best_score: float,\n",
    "                    train_conf: TrainConf):\n",
    "    ckpt = CheckpointFormat(\n",
    "        model_state_dict=model.state_dict(),\n",
    "        optim_state_dict=optimzer.state_dict(),\n",
    "        epoch_id=epoch_id,\n",
    "        best_score=best_score\n",
    "    )\n",
    "    torch.save(ckpt.dict(), train_conf.checkpoint_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(train_conf: TrainConf) -> CheckpointFormat:\n",
    "    ckpt = torch.load(train_conf.checkpoint_path)\n",
    "    return CheckpointFormat.parse_obj(ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Effgd0lNvWEl"
   },
   "source": [
    "## Training Operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pj74PCdjvWEl"
   },
   "outputs": [],
   "source": [
    "def run_training(model: TransE,\n",
    "                 train_conf: TrainConf,\n",
    "                 params: HyperParam,\n",
    "                 device: torch.device,\n",
    "                 dataset_conf: DatasetConf,\n",
    "                 entity2id: Dict[str, int],\n",
    "                 rel2id: Dict[str, int]):\n",
    "    # Prepare dataset\n",
    "    train_dataset = KRLDataset(dataset_conf, 'train', entity2id, rel2id)\n",
    "    valid_dataset = KRLDataset(dataset_conf, 'valid', entity2id, rel2id)\n",
    "    # dataset -> dataloader\n",
    "    train_dataloder = DataLoader(train_dataset, params.batch_size)\n",
    "    valid_dataloder = DataLoader(valid_dataset, params.valid_batch_size)\n",
    "    # negative sampler\n",
    "    train_neg_sampler = RandomNegativeSampler(train_dataset, device)\n",
    "    valid_neg_sampler = RandomNegativeSampler(valid_dataset, device)\n",
    "    # Tools to prepare for training\n",
    "    optimzer = torch.optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "    min_valid_loss = 10000.0\n",
    "    best_score = 0.0\n",
    "    # training loop\n",
    "    for epoch_id in range(1, params.epoch_size + 1):\n",
    "        print(\"Starting epoch: \", epoch_id)\n",
    "        loss_sum = 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_dataloder):\n",
    "            # Get training data for a batch\n",
    "            pos_heads, pos_rels, pos_tails = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "            pos_triples = torch.stack([pos_heads, pos_rels, pos_tails], dim=1)  # pos_triples: [batch_size, 3]\n",
    "            neg_triples = train_neg_sampler.neg_sample(pos_heads, pos_rels, pos_tails)  # neg_triples: [batch_size, 3]\n",
    "            optimzer.zero_grad()\n",
    "            # Calculate loss\n",
    "            loss, pos_dist, neg_dist = model(pos_triples, neg_triples)\n",
    "            loss.backward()\n",
    "            loss_sum += loss.cpu().item()\n",
    "            # update model\n",
    "            optimzer.step()\n",
    "\n",
    "        if epoch_id % params.valid_freq == 0:\n",
    "            model.eval()\n",
    "            _, _, hits_at_10, _ = run_testing(model, valid_dataloder, len(valid_dataset.entity2id), device)\n",
    "            score = hits_at_10\n",
    "            print('valid hits@10:', score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                print('best score of valid: ', best_score)\n",
    "                save_checkpoint(model, optimzer, epoch_id, best_score, train_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QMR9yyUbvWEm"
   },
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "def main(dataset_conf: DatasetConf,\n",
    "         params: HyperParam,\n",
    "         train_conf: TrainConf,\n",
    "         device: torch.device):\n",
    "    entity2id, rel2id = create_mapping(dataset_conf)\n",
    "    device = get_device()\n",
    "    ent_num = len(entity2id)\n",
    "    rel_num = len(rel2id)\n",
    "    model = TransE(ent_num, rel_num, device,\n",
    "                   norm=params.norm,\n",
    "                   embed_dim=params.embed_dim,\n",
    "                   margin=params.margin)\n",
    "    model = model.to(device)\n",
    "    run_training(model, train_conf, params, device, dataset_conf, entity2id, rel2id)\n",
    "\n",
    "    # Testing the best checkpoint on test dataset\n",
    "    ckpt = load_checkpoint(train_conf)\n",
    "    model.load_state_dict(ckpt.model_state_dict)\n",
    "    model = model.to(device)\n",
    "    test_dataset = KRLDataset(dataset_conf, 'test', entity2id, rel2id)\n",
    "    test_dataloder = DataLoader(test_dataset, params.valid_batch_size)\n",
    "    hits_at_1, hits_at_3, hits_at_10, mrr = run_testing(model, test_dataloder, ent_num, device)\n",
    "\n",
    "    # write results\n",
    "    with open(train_conf.metric_result_path, 'w') as f:\n",
    "         f.write(f'dataset: {dataset_conf.dataset_name}\\n')\n",
    "         f.write(f'Hits@1: {hits_at_1}\\n')\n",
    "         f.write(f'Hits@3: {hits_at_3}\\n')\n",
    "         f.write(f'Hits@10: {hits_at_10}\\n')\n",
    "         f.write(f'MRR: {mrr}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICIvF6n8vWEm"
   },
   "source": [
    "## Begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TLpeZVcbvWEm"
   },
   "outputs": [],
   "source": [
    "fb15k_dataset_conf = DatasetConf(\n",
    "    dataset_name='RoG',\n",
    "    base_dir='RoG/'   # 수정 필요\n",
    ")\n",
    "\n",
    "fb15k_hyper_params = HyperParam(\n",
    "    valid_freq=5,\n",
    "    batch_size=512,\n",
    "    valid_batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    epoch_size=500,\n",
    "    embed_dim=64,\n",
    "    norm=1,\n",
    "    margin=2.0\n",
    ")\n",
    "\n",
    "fb15k_train_conf = TrainConf(\n",
    "    checkpoint_path='RoG/transe_fb15k.ckpt',  # 수정 필요\n",
    "    metric_result_path='RoG/transe_fb15k_metrics.txt'   # 수정 필요\n",
    ")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "e2PINSGzvWEm",
    "outputId": "057b58a6-f4ef-4ac9-f3f6-60c5c19cfae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  1\n",
      "Starting epoch:  2\n",
      "Starting epoch:  3\n",
      "Starting epoch:  4\n",
      "Starting epoch:  5\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 11.00 GiB (GPU 0; 23.69 GiB total capacity; 16.51 GiB already allocated; 6.72 GiB free; 16.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfb15k_dataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfb15k_hyper_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfb15k_train_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset_conf, params, train_conf, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m TransE(ent_num, rel_num, device,\n\u001b[1;32m     14\u001b[0m                norm\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m     15\u001b[0m                embed_dim\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[1;32m     16\u001b[0m                margin\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mmargin)\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity2id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel2id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Testing the best checkpoint on test dataset\u001b[39;00m\n\u001b[1;32m     21\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m load_checkpoint(train_conf)\n",
      "Cell \u001b[0;32mIn[12], line 41\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, train_conf, params, device, dataset_conf, entity2id, rel2id)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch_id \u001b[38;5;241m%\u001b[39m params\u001b[38;5;241m.\u001b[39mvalid_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 41\u001b[0m     _, _, hits_at_10, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_testing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity2id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     score \u001b[38;5;241m=\u001b[39m hits_at_10\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid hits@10:\u001b[39m\u001b[38;5;124m'\u001b[39m, score)\n",
      "Cell \u001b[0;32mIn[10], line 32\u001b[0m, in \u001b[0;36mrun_testing\u001b[0;34m(model, dataloader, ent_num, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# check all possible tails\u001b[39;00m\n\u001b[1;32m     31\u001b[0m triplets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([heads_expanded, rels_expanded, all_entities], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# triplets: [batch_size * ent_num, 3]\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m tails_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriplets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# tails_prediction: [batch_size, ent_num]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# check all possible heads\u001b[39;00m\n\u001b[1;32m     34\u001b[0m triplets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([all_entities, rels_expanded, tails_expanded], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 79\u001b[0m, in \u001b[0;36mTransE.predict\u001b[0;34m(self, triples)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, triples: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculated dissimilarity score for given triplets.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    :param triplets: triplets in Bx3 shape (B - batch, 3 - head, relation and tail)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    :return: dissimilarity score for given triplets\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36mTransE._distance\u001b[0;34m(self, triples)\u001b[0m\n\u001b[1;32m     41\u001b[0m tails \u001b[38;5;241m=\u001b[39m triples[:, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     42\u001b[0m h_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_embedding(heads)  \u001b[38;5;66;03m# h_embs: [batch, embed_dim]\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m r_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m t_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_embedding(tails)\n\u001b[1;32m     45\u001b[0m dist \u001b[38;5;241m=\u001b[39m h_embs \u001b[38;5;241m+\u001b[39m r_embs \u001b[38;5;241m-\u001b[39m t_embs  \u001b[38;5;66;03m# [batch, embed_dim]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.00 GiB (GPU 0; 23.69 GiB total capacity; 16.51 GiB already allocated; 6.72 GiB free; 16.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "main(fb15k_dataset_conf, fb15k_hyper_params, fb15k_train_conf, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iymyQt29vWEm"
   },
   "outputs": [],
   "source": [
    "ckpt = torch.load(fb15k_train_conf.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmyr_El5vWEm",
    "outputId": "549331cf-b8ec-4a02-d379-7db3b0feff27"
   },
   "outputs": [],
   "source": [
    "ckpt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0418effca45178467ac68c18e34d93809a092be692e0a4443d8690099b71f4bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
