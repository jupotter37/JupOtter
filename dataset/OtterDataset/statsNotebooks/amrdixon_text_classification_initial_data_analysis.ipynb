{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In 2018, the e-commerce site Rakuten ran a public data challenge that asked data scientists to develop a model to classify products given a text description of that product. This notebook begins to address this challenge through some initial data and problem exploration. Included in this work is the initial data analysis and discussion of performance metrics.\n",
    "\n",
    "While this work is derived from many sources, many of the methods and approaches were inspired by the scikit learn tutorial on working with text data: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "The training data, data used to train the machine leaning model, consists of 800,000 records. Each record has only two fields: a description of the product and the product's category. The fields are both strings. The following subsections take a closer look at the labels (product category) and features (product description). Minor cleaning checked that there were no invalid (np.nan or None) values in either the description or category fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  800000\n",
      "Number of columns:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cat_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Replacement Viewsonic VG710 LCD Monitor 48Watt...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...</td>\n",
       "      <td>3292&gt;1370&gt;4767&gt;3975&gt;1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonjour</td>\n",
       "      <td>2296&gt;3597&gt;2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Pack 6V 12Ah  Eaton POWERRITE PRO II 2400 ...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generations Small Side Table White</td>\n",
       "      <td>4015&gt;3636&gt;1319&gt;1409&gt;3606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                  cat_full\n",
       "0  Replacement Viewsonic VG710 LCD Monitor 48Watt...             3292>114>1231\n",
       "1  HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...  3292>1370>4767>3975>1420\n",
       "2                                            Bonjour            2296>3597>2989\n",
       "3  Two Pack 6V 12Ah  Eaton POWERRITE PRO II 2400 ...             3292>114>1231\n",
       "4                 Generations Small Side Table White  4015>3636>1319>1409>3606"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv('https://github.com/up-lab/rakuten-data-challenge/raw/master/rdc-catalog-train.tsv', header=None, names=['description', 'cat_full'], sep='\\t', )\n",
    "\n",
    "#print some basic information about data\n",
    "print('Number of rows: ', train_data.shape[0])\n",
    "print('Number of columns: ', train_data.shape[1])\n",
    "\n",
    "#look at the data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cat_1'] = train_data['cat_full'].apply(lambda x: x.split('>')[0])\n",
    "train_data['cat_2'] = train_data['cat_full'].apply(lambda x: x.split('>')[1] if (len(x.split('>'))>1) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before cleaning:  800000\n",
      "Number of rows after cleaning:  800000\n"
     ]
    }
   ],
   "source": [
    "#basic cleaning, remove any rows that don't have values in the decsription or cat_1 fields (leaving those with\n",
    "#missing cat_2 for now)\n",
    "print('Number of rows before cleaning: ', train_data.shape[0])\n",
    "train_data.dropna(subset=['description','cat_1'], inplace=True)\n",
    "print('Number of rows after cleaning: ', train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a function to perform all the actions shown above for better repetition (and use in other notebooks)\n",
    "def import_format_data(this_url):\n",
    "    \"\"\"\n",
    "    Loads data from provided url into Pandas dataframe,\n",
    "    breaks out columns for different category levels and\n",
    "    does basic data cleaning. Basic data cleaning here involves\n",
    "    dropping rows with empty description or first level category labels.\n",
    "    Note that it does not drop rows with empty fields for categories\n",
    "    after the first level as the number of levels assigned is variable.\n",
    "    \n",
    "    args:\n",
    "    this_url (str): URL of dataset\n",
    "    \n",
    "    returns:\n",
    "    pandas df of processed data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    this_data = pd.read_csv(this_url, header=0, names=['description', 'cat_full'], sep='\\t')\n",
    "    this_data['cat_1'] = this_data['cat_full'].apply(lambda x: x.split('>')[0])\n",
    "    this_data['cat_2'] = this_data['cat_full'].apply(lambda x: x.split('>')[1] if (len(x.split('>'))>1) else np.nan)\n",
    "    this_data.dropna(subset=['description','cat_1'], inplace=True)\n",
    "    \n",
    "    return this_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels\n",
    "\n",
    "The category field is ultimately the labels. The categories are hierarchical with each level separated by a \">\" character. Not all labels consist of the same number of levels. Number of category levels range from 1 to 8 with a mean of 4. To simplify this work, we will focus on classification of the first two levels only and leave further classification to future work. There are 14 unique first level categories and 109 unique second level categories. Further there are 109 unique first+second level categories, meaning there are no shared second level categories with first level categories (e.g. if A>1 and B>2 are categories, \"1\" always mapped back to \"A\" and 2 always mapped back to \"B\").\n",
    "\n",
    "Finally, we take a look at how balanced the data is for the first level category. It is not a very balanced dataset, with 2/14 of the first level categories composing more than 50% of the dataset. This may have implications on certain classifier performance, perhaps showing overwhelming preference to classifying those more prevalent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of categories:  1\n",
      "Maximum number of categories:  8\n",
      "Mean number of categories:  4.0131475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the distribution for teh category mappings\n",
    "num_categories = train_data['cat_full'].apply(lambda x: len(x.split('>')))\n",
    "print('Minimum number of categories: ', min(num_categories))\n",
    "print('Maximum number of categories: ', max(num_categories))\n",
    "print('Mean number of categories: ', np.mean(num_categories))\n",
    "\n",
    "\n",
    "plt.hist(num_categories, align='left', bins=[x for x in range(max(num_categories))])\n",
    "plt.xlabel('Number of category levels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of first level distinct categories:  14\n",
      "Number of second level distinct categories:  109\n",
      "Number of first+second level distinct categories:  109\n"
     ]
    }
   ],
   "source": [
    "#look at numer of categories\n",
    "print('Number of first level distinct categories: ', len(train_data['cat_1'].unique()))\n",
    "print('Number of second level distinct categories: ', len(train_data['cat_2'].unique()))\n",
    "#double checking there are no second level category mappings that are shared between first levels\n",
    "#(e.g. 1>a and 2>a)\n",
    "print('Number of first+second level distinct categories: ', len(train_data.groupby(['cat_1', 'cat_2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_1\n",
       "1208    0.001288\n",
       "1395    0.023559\n",
       "1608    0.106942\n",
       "2075    0.025108\n",
       "2199    0.120892\n",
       "2296    0.035515\n",
       "3093    0.006372\n",
       "3292    0.251181\n",
       "3625    0.036946\n",
       "3730    0.010141\n",
       "4015    0.335369\n",
       "4238    0.029411\n",
       "4564    0.007060\n",
       "92      0.010215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at how balanaced the training set is\n",
    "train_data.groupby('cat_1').apply(len)/len(train_data['cat_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "\n",
    "The description field will provide the basis for the feature(s) in our machine learning model. Each description is a short collection of \"words\" any about the product. Words here are actually tokens, defined by the scikit learn toolkit tokenizer, which is basically smaller groups of characters identifiable meaning (usually words). The entry descriptions' length range from 0 to 52 words with a mean of 10.6 and a standard deviation of 4.7. This led to the decision to use a bag of words model, a model whereby words and their frequency are the system's features. There are often few enough words in the descriptions, that the machine learning model will likely be classifying categories from previously encountered words.\n",
    "\n",
    "\n",
    "The scikit learn tokenizer is used convert the description text into tokens. We first apply this to a small sample set to gain a better understanding of how the tokenizer constructs the features. We see that the tokenizer works by breaking up all the tokens in all n training data points into m tokens. Then, it constructs an nxm matrix which is the count of every possible token in each training data point. You can normalize beyond simple word counts to account for super common words among and within different entries using TF-IDF (term frequency times inverse document frequency). Each of the n training points is so short however, that it's unclear how helpful this normalization would be and is thus left to future work.\n",
    "\n",
    "After gaining some understanding of how the tokenizer functions, we broadened the analysis to look at the entire tokenized training set. Without any further data processing, the training set contains 427,297 total tokens. Looking at the token frequency across the training set, we see that tokens had a mean count of ~20 tokens with a standard deviation of ~510 tokens, meaning some high frequency words are much higher frequency than others and skewing that standard deviation pretty high. There are a couple potential data processing measures we could take here such as:\n",
    "\n",
    "- Removing stop words: By removing common words in the English language, such as \"the\", we may be able to reduce and enrich the feature space.\n",
    "- Using n-grams: Small groups of tokens, rather than single tokens, may contain more context. For example, we show that \"black\" is a high frequency word. But using pairs of words like \"black beans\" and \"black notebook\" we may give the features more context.\n",
    "- Stemming/Lemmatizing: Grouping words together with similar meanings would help reduce the size of and enrich the feature space. An example of stemming/lemmatizing would be mapping \"battery\" and \"batteries\" to the same token.\n",
    "- Translation: A peek at the tokens below reveals that there are some entries with non-English words. Performing a translation operation to English such that all entries are the same language would help build a better training set.\n",
    "\n",
    "The analysis below explores removing stop words and using n-grams. While we believe stemming/lemmatizing and translation would be good data processing steps, we are leaving this to future work.\n",
    "\n",
    "Finally, we did detect 11 test data entries where the tokenizer identified 0 tokens. 10/11 of those entries map to the same category so you could consider a \"no data is data\" approach, but I hypothesize it will more likely lead to overfitting and would best be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description Length Statistics: \n",
      "Min:  0\n",
      "Max:  52\n",
      "Mean:  10.60846875\n",
      "Std. Dev.:  4.682643167087735\n"
     ]
    }
   ],
   "source": [
    "#Stats of number of \"words\" in each description field\n",
    "word_counter = CountVectorizer()\n",
    "word_counter.fit(train_data['description'])\n",
    "train_x = word_counter.transform(train_data['description'])\n",
    "\n",
    "num_words_per_record = train_x.sum(axis=1)\n",
    "print('Description Length Statistics: ')\n",
    "print('Min: ', np.min(num_words_per_record))\n",
    "print('Max: ', np.max(num_words_per_record))\n",
    "print('Mean: ', np.mean(num_words_per_record))\n",
    "print('Std. Dev.: ', np.std(num_words_per_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample String: \n",
      "0    Replacement Viewsonic VG710 LCD Monitor 48Watt...\n",
      "1    HP COMPAQ Pavilion DV6-1410EZ 4400mAh 48Wh 6 C...\n",
      "Name: description, dtype: object\n",
      "\n",
      "Features: \n",
      "['10', '12v', '1410ez', '4400mah', '48watt', '48wh', '4a', '8v', 'ac', 'adapter', 'battery', 'black', 'cell', 'compaq', 'compatible', 'dv6', 'hp', 'ion', 'lcd', 'li', 'monitor', 'pavilion', 'replacement', 'vg710', 'viewsonic']\n",
      "\n",
      "Number of Occurences: \n",
      "0    [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...\n",
      "1    [1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, ...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#looking at the feature (bag of words of description field) for TWO descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "print('Sample String: ')\n",
    "sample_data = train_data.iloc[0:2]['description']\n",
    "print(sample_data)\n",
    "\n",
    "#create a dictionary from the whole trainign set\n",
    "vectorizer.fit_transform(sample_data)\n",
    "vocab_full =  vectorizer.get_feature_names()\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_full)\n",
    "bow_counts = sample_data.apply(lambda x: vectorizer.fit_transform([x]))\n",
    "\n",
    "print('')\n",
    "print('Features: ')\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print('')\n",
    "print('Number of Occurences: ')\n",
    "print(bow_counts.apply(lambda x: x.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  427297\n",
      " \n",
      "Highest frequency words: \n",
      "[('for', 165031), ('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('in', 53520), ('skin', 50501), ('and', 46959), ('decal', 43758)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('µdimm', 1), ('â³', 1), ('çelebration', 1), ('égales', 1), ('élan', 1), ('épais', 1), ('étagère', 1), ('üsküdar', 1), ('œme', 1), ('ﾠb', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  19.861536589304396\n",
      "Standard Deviation:  509.9616573544085\n",
      "Min:  1 , Number of occurences:  290634\n",
      "Max:  165031\n"
     ]
    }
   ],
   "source": [
    "#Broadening analysis to whole training set\n",
    "\n",
    "def quick_feature_analysis(feature=train_data['description'], tok_kwargs={}):\n",
    "    vectorizer = CountVectorizer(**tok_kwargs)\n",
    "    vectorizer.fit(feature)\n",
    "    train_x = vectorizer.transform(feature)\n",
    "    print('Number of features: ', train_x.shape[1])\n",
    "\n",
    "    #What are some high frequency words?\n",
    "    top_i = 10\n",
    "\n",
    "    total_occurences = zip(vectorizer.get_feature_names(), train_x.sum(axis=0).tolist()[0])\n",
    "    total_occurences_sorted = sorted(total_occurences, key=lambda x: -x[1])\n",
    "    print(' ')\n",
    "    print('Highest frequency words: ')\n",
    "    print(total_occurences_sorted[0:top_i])\n",
    "\n",
    "    print(' ')\n",
    "    print('Lowest frequency words: ')\n",
    "    print(total_occurences_sorted[-top_i:])\n",
    "\n",
    "    print(' ')\n",
    "    print('Basic Statistics of Word Frequencies: ')\n",
    "    word_freq = train_x.sum(axis=0).tolist()[0]\n",
    "    print('Mean: ', np.mean(word_freq))\n",
    "    print('Standard Deviation: ', np.std(word_freq))\n",
    "    print('Min: ', np.min(word_freq), ', Number of occurences: ', len(np.argwhere(word_freq==np.min(word_freq))))\n",
    "    print('Max: ', np.max(word_freq))\n",
    "    \n",
    "quick_feature_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  427019\n",
      " \n",
      "Highest frequency words: \n",
      "[('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('skin', 50501), ('decal', 43758), ('protective', 43434), ('filter', 40792), ('vinyl', 39550)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('µdimm', 1), ('â³', 1), ('çelebration', 1), ('égales', 1), ('élan', 1), ('épais', 1), ('étagère', 1), ('üsküdar', 1), ('œme', 1), ('ﾠb', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  18.557822954013755\n",
      "Standard Deviation:  417.8405487963014\n",
      "Min:  1 , Number of occurences:  290622\n",
      "Max:  91313\n"
     ]
    }
   ],
   "source": [
    "#What if we removed stop words?\n",
    "quick_feature_analysis(tok_kwargs={'stop_words':'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  2480461\n",
      " \n",
      "Highest frequency words: \n",
      "[('for', 165031), ('replacement', 91313), ('pack', 74865), ('black', 64110), ('battery', 55975), ('cover', 55047), ('in', 53520), ('skin', 50501), ('and', 46959), ('decal', 43758)]\n",
      " \n",
      "Lowest frequency words: \n",
      "[('œme salon', 1), ('šâ žâ', 1), ('šã premium', 1), ('šã pãƒæ', 1), ('šã re', 1), ('šã â³', 1), ('šã â¾ãƒæ', 1), ('žâ ãƒæ', 1), ('ﾠb', 1), ('ﾠb battery', 1)]\n",
      " \n",
      "Basic Statistics of Word Frequencies: \n",
      "Mean:  6.520385121959184\n",
      "Standard Deviation:  227.16310240064493\n",
      "Min:  1 , Number of occurences:  1792252\n",
      "Max:  165031\n"
     ]
    }
   ],
   "source": [
    "#What if we used n-grams?\n",
    "quick_feature_analysis(tok_kwargs={'ngram_range': (1,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with no decscription:  11\n",
      " \n",
      "Entries with empty features: \n",
      "       description         cat_full cat_1 cat_2\n",
      "58845        3 & 4    2296>3597>689  2296  3597\n",
      "161182     1-2-3-4    2296>3597>689  2296  3597\n",
      "240920           R   2296>3706>2852  2296  3706\n",
      "249402         3.0   2296>3597>2002  2296  3597\n",
      "485492         S'u    2296>3597>689  2296  3597\n",
      "528822         2.0    2296>3597>689  2296  3597\n",
      "587832     4, 5, 6   2296>2435>1941  2296  2435\n",
      "593957           S   2296>3706>1175  2296  3706\n",
      "615731         $O$    2296>3597>689  2296  3597\n",
      "707056          N+  3292>49>189>398  3292    49\n",
      "713429       X O K   2296>3597>3083  2296  3597\n"
     ]
    }
   ],
   "source": [
    "print('Number of entries with no decscription: ', len(np.argwhere(num_words_per_record==0)))\n",
    "\n",
    "print(' ')\n",
    "print('Entries with empty features: ')\n",
    "print(train_data.iloc[[i for i in np.argwhere(num_words_per_record==0)[:,0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data contains 200,000 entries with the same fields as the training data. We've loaded the dataset and performed the same preprocessing here, but have intentionally limited exploration to avoid overfitting. A quick look at the first category label distribution shows that while it also seems to be unbalanced, it appears to be unbalanced in the same manner as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cat_full</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;3813</td>\n",
       "      <td>1608</td>\n",
       "      <td>2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "      <td>2199</td>\n",
       "      <td>4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "      <td>2199</td>\n",
       "      <td>4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "      <td>1608</td>\n",
       "      <td>4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "      <td>3292</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description             cat_full  \\\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>3813   \n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12   \n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12   \n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221   \n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231   \n",
       "\n",
       "  cat_1 cat_2  \n",
       "0  1608  2320  \n",
       "1  2199  4592  \n",
       "2  2199  4592  \n",
       "3  1608  4269  \n",
       "4  3292   114  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = import_format_data('https://github.com/up-lab/rakuten-data-challenge/raw/master/rdc-catalog-test.tsv')\n",
    "print('Number of rows: ', test_data.shape[0])\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_1\n",
       "1208    0.000605\n",
       "1395    0.020385\n",
       "1608    0.105870\n",
       "2075    0.023325\n",
       "2199    0.127690\n",
       "2296    0.041095\n",
       "3093    0.006155\n",
       "3292    0.250175\n",
       "3625    0.039045\n",
       "3730    0.010055\n",
       "4015    0.330875\n",
       "4238    0.028400\n",
       "4564    0.005855\n",
       "92      0.010470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at how balanaced the test set is\n",
    "test_data.groupby('cat_1').apply(len)/len(test_data['cat_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straightforward metric is of course accuracy. Accuracy simply tells us the percentage that the classifier predicts the correct label.\n",
    "\n",
    "An evaluation tool we will look at here is a confusion matrix (at least for the first level of categorization). The confusion matrix is a grid showing number/percentage of each predicted labels vs the actual labels. This may be advantageous for debugging purposes (e.g. are there two classes that are often confused for one another?).\n",
    "\n",
    "Other performance metrics should be considered depending on system design intentions. If this is a human-in-the-loop system and the accuracy is only ok, I would recommend another performance metric here that measures how well the classifier understands its' ability to predict the output. In other words, how accurate is the classifiers' prediction probability? One example of this type of metric would be the Brier score. In this system, if the prediction probabilities are determined to be reliable, a confidence threshold could be set and all predictions whose probability is below that threshold would be flagged for human validation and feedback. This type of metric was not evaluated here but is strongly recommended after further use case review with stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for accuracy\n",
    "def display_performance(classifier, test_x, test_y, train_x=[], train_y=[]):\n",
    "    \"\"\"\n",
    "    Prints accuracy and confusion matrix for specified classifier and test set.\n",
    "    Displays the confusion matrix. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if (train_x.shape[0]>0) & (train_y.shape[0]>0):\n",
    "        train_accuracy = classifier.score(train_x, train_y)\n",
    "        print('Overall Training Set Accuracy: ', train_accuracy)\n",
    "        cv_scores = cross_val_score(classifier, train_x, train_y, cv=5)\n",
    "        print('Cross-validated Training Set Accuracy: {:.2f} +/- {:.2f}'.format(np.mean(cv_scores), np.std(cv_scores)))\n",
    "    \n",
    "    accuracy = classifier.score(test_x, test_y)\n",
    "    \n",
    "    print('Test Set Accuracy: ', accuracy)\n",
    "    \n",
    "    predictions = classifier.predict(test_x)\n",
    "    num_labels = len(classifier.classes_)\n",
    "    cf_matrix = np.zeros((num_labels, num_labels))\n",
    "    labels = np.unique(test_y)\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        label_actual = test_y[i]\n",
    "        label_actual_idx = np.argwhere(labels==label_actual)[0]\n",
    "        predict_label_idx = np.argwhere(labels==prediction)[0]\n",
    "        cf_matrix[label_actual_idx, predict_label_idx] += 1\n",
    "        cf_matrix_norm = normalize(cf_matrix, axis=1, norm='l1')\n",
    "\n",
    "    sns.heatmap(cf_matrix_norm, xticklabels=labels, yticklabels=labels, cmap=\"YlGnBu\")\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "censusbureau",
   "language": "python",
   "name": "censusbureau"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
