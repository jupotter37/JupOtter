{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5d8bb",
   "metadata": {},
   "source": [
    "##  Assignment 37 - 13 March 2023 : Divya Pardeshi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733c2d9",
   "metadata": {},
   "source": [
    "__Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2883d",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e76625",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means among multiple groups. However, ANOVA comes with certain assumptions that must be met for the results to be valid and reliable. Violations of these assumptions can lead to incorrect conclusions. The main assumptions for using ANOVA are:\n",
    "\n",
    "1. **Normality**: The residuals (differences between observed values and group means) should follow a normal distribution. This assumption is particularly important when the sample sizes are small. Violations of normality might lead to biased results.\n",
    "\n",
    "2. **Homogeneity of Variance (Homoscedasticity)**: The variances of the residuals should be roughly equal across all groups. Homoscedasticity ensures that the groups have similar variability. Violations can lead to an inflated Type I error rate.\n",
    "\n",
    "3. **Independence**: The observations within each group should be independent of each other. This means that the values within one group should not be influenced by the values in other groups. Violations of independence can distort the standard error estimates and lead to inaccurate p-values.\n",
    "\n",
    "Examples of Violations:\n",
    "\n",
    "1. **Normality Violation**: If the residuals are not normally distributed, the ANOVA results might be unreliable. For example, if the residuals are skewed or have heavy tails, the p-values for group differences may not accurately reflect the true significance.\n",
    "\n",
    "2. **Homoscedasticity Violation**: If the variances of the residuals are not equal across groups, the assumptions underlying the F-test may not hold. For instance, if one group has much larger variances than the others, it might dominate the F-test and lead to incorrect conclusions.\n",
    "\n",
    "3. **Independence Violation**: If observations are not independent within groups, it can lead to biased standard error estimates and artificially low p-values. For instance, if repeated measurements are taken from the same subjects, the independence assumption might be violated.\n",
    "\n",
    "It's important to assess these assumptions before interpreting ANOVA results. Various graphical methods (such as residual plots, normality plots, and box plots) can be used to check for violations. If assumptions are severely violated, alternative analysis methods or transformations might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09bc2a",
   "metadata": {},
   "source": [
    "__Q2. What are the three types of ANOVA, and in what situations would each be used?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ecc1c",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffd0c0",
   "metadata": {},
   "source": [
    "There are three main types of Analysis of Variance (ANOVA), each designed for different situations and experimental designs:\n",
    "\n",
    "1. **One-Way ANOVA**:\n",
    "   - **Design**: Used when there is a single categorical independent variable with three or more levels (groups).\n",
    "   - **Example**: Comparing the effect of different teaching methods (A, B, C) on student test scores.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - **Design**: Used when there are two categorical independent variables, also known as factors, and their interaction, which leads to multiple combinations or cells.\n",
    "   - **Example**: Investigating the effects of both gender (male, female) and treatment (A, B) on a response variable like blood pressure.\n",
    "\n",
    "3. **Repeated Measures ANOVA** (or Within-Subjects ANOVA):\n",
    "   - **Design**: Used when the same subjects are measured under different conditions, resulting in related samples or repeated measurements.\n",
    "   - **Example**: Examining the effects of three different diets (A, B, C) on the weight of the same group of individuals measured over time.\n",
    "\n",
    "Each type of ANOVA addresses different research questions and experimental designs. It's important to choose the appropriate type of ANOVA based on the structure of your data and research objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc15ce",
   "metadata": {},
   "source": [
    "__Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7eb093",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54db6a6",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variability observed in the data into different sources of variability. This decomposition helps to understand the relative contributions of different factors or sources to the observed variation. In ANOVA, the total variance of the dependent variable is divided into several components:\n",
    "\n",
    "1. **Between-Group Variance (Treatment Variance)**: This is the variance between different groups or levels of the independent variable. It measures how much the group means differ from each other.\n",
    "\n",
    "2. **Within-Group Variance (Error Variance)**: This is the variance within each group. It measures the variability of the individual data points around their respective group means.\n",
    "\n",
    "3. **Total Variance**: This is the overall variability in the data. It's the sum of the between-group variance and the within-group variance.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. **Identifying Sources of Variation**: By partitioning variance, ANOVA helps us identify whether the observed differences between group means are significant and whether they can be attributed to the factors under study (such as treatments or conditions).\n",
    "\n",
    "2. **Assessing Significance**: ANOVA provides a framework for assessing the significance of differences between group means. It does so by comparing the between-group variance to the within-group variance.\n",
    "\n",
    "3. **Hypothesis Testing**: The partitioning of variance forms the basis for the F-test used in ANOVA. The F-statistic quantifies the ratio of between-group variance to within-group variance, helping us determine whether the group means are significantly different.\n",
    "\n",
    "4. **Interpreting Results**: By understanding how much of the total variance is explained by the factors being studied and how much is due to random variability, researchers can better interpret the practical significance of their findings.\n",
    "\n",
    "5. **Designing Experiments**: Partitioning variance helps researchers design experiments by considering the factors that contribute most to the overall variability. This can guide decisions about sample sizes, treatment conditions, and control measures.\n",
    "\n",
    "Overall, the partitioning of variance in ANOVA provides a structured and quantitative way to analyze and interpret the differences among groups, helping researchers draw meaningful conclusions from their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59208754",
   "metadata": {},
   "source": [
    "__Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdab7c",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fe43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of Tips dataset:\n",
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "\n",
      "===================================================================\n",
      "\n",
      "Values for Total Bill vs Day:\n",
      "SSE: 643.9414\n",
      "SSR: 18614.5227\n",
      "SST: 19258.4641\n",
      "\n",
      "===================================================================\n",
      "\n",
      "             df        sum_sq     mean_sq         F    PR(>F)\n",
      "day         3.0    643.941362  214.647121  2.767479  0.042454\n",
      "Residual  240.0  18614.522721   77.560511       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Loading Tips dataset from seaborn\n",
    "df_tips = sns.load_dataset('tips')\n",
    "print('Top 5 rows of Tips dataset:')\n",
    "print(df_tips.head())\n",
    "print('\\n===================================================================\\n')\n",
    "\n",
    "# Fit the one-way ANOVA model (total_bill vs Day)\n",
    "model = ols('total_bill ~ day', data=df_tips).fit()\n",
    "\n",
    "# Calculate the sum of squares for the model\n",
    "print('Values for Total Bill vs Day:')\n",
    "SSE = model.ess\n",
    "SSR = model.ssr\n",
    "SST = SSE + SSR\n",
    "\n",
    "print('SSE:', round(SSE, 4))\n",
    "print('SSR:', round(SSR, 4))\n",
    "print('SST:', round(SST, 4))\n",
    "\n",
    "print('\\n===================================================================\\n')\n",
    "# Print the ANOVA table\n",
    "print(anova_lm(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2b999",
   "metadata": {},
   "source": [
    "__Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407c923",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5e2959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of Tips dataset:\n",
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "\n",
      "==============================================================\n",
      "\n",
      "Main effects:\n",
      "C(day)     165.305544\n",
      "C(time)    612.986863\n",
      "Name: sum_sq, dtype: float64\n",
      "\n",
      "==============================\n",
      "\n",
      "Interaction effect:\n",
      "C(day):C(time)    94.67622\n",
      "Name: sum_sq, dtype: float64\n",
      "\n",
      "==============================\n",
      "\n",
      "ANOVA Table:\n",
      "                      sum_sq     df         F    PR(>F)\n",
      "C(day)            165.305544    3.0  0.712428  0.491495\n",
      "C(time)           612.986863    1.0  7.925488  0.005283\n",
      "C(day):C(time)     94.676220    3.0  0.408032  0.747369\n",
      "Residual        18407.808794  238.0       NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swati\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\swati\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\swati\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the Tips dataset from Seaborn\n",
    "df_tips = sns.load_dataset('tips')\n",
    "print('Top 5 rows of Tips dataset:')\n",
    "print(df_tips.head())\n",
    "print('\\n==============================================================\\n')\n",
    "\n",
    "# Define the model formula\n",
    "model_formula = \"total_bill ~ C(day) + C(time) + C(day):C(time)\"\n",
    "\n",
    "# Fit the model using OLS regression\n",
    "model = ols(model_formula, df_tips).fit()\n",
    "\n",
    "# Calculate the main effects and interaction effects\n",
    "main_effects = sm.stats.anova_lm(model, typ=2)['sum_sq'][:2]\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=2)['sum_sq'][2:3]\n",
    "\n",
    "# Print the results\n",
    "print(\"Main effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\n==============================\\n\")\n",
    "print(\"Interaction effect:\")\n",
    "print(interaction_effect)\n",
    "print(\"\\n==============================\\n\")\n",
    "print(\"ANOVA Table:\")\n",
    "print(sm.stats.anova_lm(model, typ=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453168d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>total_bill</td>    <th>  R-squared:         </th> <td>   0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 25 Aug 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0551</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:03</td>     <th>  Log-Likelihood:    </th> <td> -873.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   1759.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   238</td>      <th>  BIC:               </th> <td>   1780.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   17.6648</td> <td>    1.126</td> <td>   15.688</td> <td> 0.000</td> <td>   15.447</td> <td>   19.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Fri]</th>                   <td>   -4.8190</td> <td>    3.510</td> <td>   -1.373</td> <td> 0.171</td> <td>  -11.733</td> <td>    2.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Sat]</th>                   <td>    0.8307</td> <td>    4.422</td> <td>    0.188</td> <td> 0.851</td> <td>   -7.881</td> <td>    9.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Sun]</th>                   <td>    1.3150</td> <td>    4.426</td> <td>    0.297</td> <td> 0.767</td> <td>   -7.404</td> <td>   10.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(time)[T.Dinner]</th>               <td>    1.1152</td> <td>    8.866</td> <td>    0.126</td> <td> 0.900</td> <td>  -16.351</td> <td>   18.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Fri]:C(time)[T.Dinner]</th> <td>    5.7024</td> <td>    9.803</td> <td>    0.582</td> <td> 0.561</td> <td>  -13.610</td> <td>   25.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Sat]:C(time)[T.Dinner]</th> <td>    0.8307</td> <td>    4.422</td> <td>    0.188</td> <td> 0.851</td> <td>   -7.881</td> <td>    9.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(day)[T.Sun]:C(time)[T.Dinner]</th> <td>    1.3150</td> <td>    4.426</td> <td>    0.297</td> <td> 0.767</td> <td>   -7.404</td> <td>   10.034</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45.019</td> <th>  Durbin-Watson:     </th> <td>   1.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  66.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.107</td> <th>  Prob(JB):          </th> <td>4.35e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.265</td> <th>  Cond. No.          </th> <td>4.94e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.19e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             total_bill   R-squared:                       0.044\n",
       "Model:                            OLS   Adj. R-squared:                  0.024\n",
       "Method:                 Least Squares   F-statistic:                     2.200\n",
       "Date:                Fri, 25 Aug 2023   Prob (F-statistic):             0.0551\n",
       "Time:                        23:28:03   Log-Likelihood:                -873.67\n",
       "No. Observations:                 244   AIC:                             1759.\n",
       "Df Residuals:                     238   BIC:                             1780.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          17.6648      1.126     15.688      0.000      15.447      19.883\n",
       "C(day)[T.Fri]                      -4.8190      3.510     -1.373      0.171     -11.733       2.095\n",
       "C(day)[T.Sat]                       0.8307      4.422      0.188      0.851      -7.881       9.543\n",
       "C(day)[T.Sun]                       1.3150      4.426      0.297      0.767      -7.404      10.034\n",
       "C(time)[T.Dinner]                   1.1152      8.866      0.126      0.900     -16.351      18.582\n",
       "C(day)[T.Fri]:C(time)[T.Dinner]     5.7024      9.803      0.582      0.561     -13.610      25.015\n",
       "C(day)[T.Sat]:C(time)[T.Dinner]     0.8307      4.422      0.188      0.851      -7.881       9.543\n",
       "C(day)[T.Sun]:C(time)[T.Dinner]     1.3150      4.426      0.297      0.767      -7.404      10.034\n",
       "==============================================================================\n",
       "Omnibus:                       45.019   Durbin-Watson:                   1.932\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               66.138\n",
       "Skew:                           1.107   Prob(JB):                     4.35e-15\n",
       "Kurtosis:                       4.265   Cond. No.                     4.94e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.19e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d84f5b",
   "metadata": {},
   "source": [
    "__Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6dd700",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8bf16",
   "metadata": {},
   "source": [
    "In the context of a one-way ANOVA, the F-statistic and the associated p-value provide important information about the differences between the groups being compared. Let's break down the interpretation of the results:\n",
    "\n",
    "1. **F-Statistic**: The F-statistic is a measure of the variability between group means relative to the variability within the groups. It quantifies whether the observed differences in means are greater than what would be expected due to random chance alone.\n",
    "\n",
    "2. **P-Value**: The p-value associated with the F-statistic indicates the probability of observing such extreme or more extreme results if the null hypothesis is true. In this case, the null hypothesis usually states that there are no significant differences between the group means.\n",
    "\n",
    "As per given information:\n",
    "- F-Statistic: 5.23\n",
    "- P-Value: 0.02\n",
    "\n",
    "Interpretation:\n",
    "- The p-value (0.02) is less than the common significance level of 0.05. This suggests that the observed differences between the groups' means are statistically significant.\n",
    "\n",
    "- Since the p-value is below the significance level, you would reject the null hypothesis. This means that there are likely significant differences between at least two of the groups.\n",
    "\n",
    "- The F-statistic of 5.23 indicates that the variability between group means is larger than the variability within the groups. This further supports the idea that the groups are not all the same.\n",
    "\n",
    "- In practical terms, you would conclude that there is evidence to suggest that at least one group mean is different from the others. However, the ANOVA itself does not tell you which specific groups are different from each other.\n",
    "\n",
    "To determine which specific groups differ from each other, you might perform post-hoc tests or pairwise comparisons (e.g., Tukey's HSD test, Bonferroni correction) to identify which pairs of groups have significantly different means.\n",
    "\n",
    "In summary, an F-statistic of 5.23 with a p-value of 0.02 suggests that there are significant differences between the groups, and you would reject the null hypothesis of equal group means. Further analyses would be needed to determine exactly which groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb240e5",
   "metadata": {},
   "source": [
    "__Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51351568",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add5ead",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity and accuracy of your analysis. There are several methods you can use to handle missing data, each with its own implications. Let's explore how to handle missing data and the potential consequences of using different methods:\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**:\n",
    "   - This method involves removing entire cases (subjects) with missing data from the analysis.\n",
    "   - Pros: Simple to implement, retains only complete cases for analysis.\n",
    "   - Cons: Reduces sample size, may lead to biased results if missingness is related to the outcome or other variables.\n",
    "\n",
    "2. **Pairwise Deletion**:\n",
    "   - This method retains cases with available data for each specific comparison.\n",
    "   - Pros: Retains more data than listwise deletion, doesn't require removing entire cases.\n",
    "   - Cons: May lead to biased results, as different analyses will use different subsets of data.\n",
    "\n",
    "3. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean of the available data for that variable.\n",
    "   - Pros: Simple to implement, retains all cases.\n",
    "   - Cons: Distorts variance and covariance estimates, potentially affects statistical significance and confidence intervals.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Missing values are replaced with the last observed value for that subject.\n",
    "   - Pros: Preserves temporal order, appropriate for some longitudinal studies.\n",
    "   - Cons: May not accurately represent missing values, assumes a constant pattern.\n",
    "\n",
    "5. **Linear Interpolation**:\n",
    "   - Missing values are estimated based on linear interpolation between neighboring time points.\n",
    "   - Pros: Preserves temporal order, can be useful for time series data.\n",
    "   - Cons: Assumes linear relationships, may not work well for nonlinear data.\n",
    "\n",
    "6. **Multiple Imputation**:\n",
    "   - Generates multiple complete datasets by imputing missing values using statistical methods. Analysis is performed on each dataset, and results are pooled.\n",
    "   - Pros: Handles missing data more rigorously, provides estimates of uncertainty.\n",
    "   - Cons: More complex to implement, may require assumptions about missing data mechanism.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data include:\n",
    "\n",
    "- **Bias**: Some methods may introduce bias by inflating or deflating the estimates of effects. For example, mean imputation tends to underestimate variability.\n",
    "\n",
    "- **Inaccurate Standard Errors**: Incorrectly handling missing data can lead to incorrect standard errors and p-values, affecting the validity of inferential statistics.\n",
    "\n",
    "- **Misinterpretation**: Using listwise or pairwise deletion can lead to incorrect conclusions about the relationships between variables.\n",
    "\n",
    "- **Efficiency**: Some methods may be more efficient than others in terms of retaining information and maintaining statistical power.\n",
    "\n",
    "It's important to choose a method that aligns with your data characteristics and research questions while considering the potential consequences of the chosen method. Multiple imputation is generally considered a robust approach that addresses many of the issues associated with missing data, but it may require more advanced statistical knowledge and software. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e21e36",
   "metadata": {},
   "source": [
    "__Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48845aad",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ead2f",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after conducting an ANOVA to make pairwise comparisons between group means when a significant difference has been detected in the overall ANOVA. These tests help identify which specific groups differ from each other. There are several common post-hoc tests, each designed to address different levels of control over Type I error rates (familywise error rate) and assumptions about the data. Let's look at a few common post-hoc tests and when to use them:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test**:\n",
    "   - Controls the familywise error rate, making it suitable for situations where multiple pairwise comparisons are conducted.\n",
    "   - Assumes homogeneity of variances across groups.\n",
    "   - Example: You conducted a one-way ANOVA to compare the effects of different teaching methods on test scores among multiple groups. Tukey's HSD can be used to identify which specific pairs of teaching methods have significantly different effects.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - Controls the familywise error rate by dividing the desired significance level (e.g., 0.05) by the number of comparisons.\n",
    "   - More conservative than Tukey's HSD.\n",
    "   - Suitable for cases where a large number of pairwise comparisons are conducted.\n",
    "   - Example: You're analyzing differences in customer satisfaction scores among different product categories. Since you're conducting numerous pairwise comparisons, Bonferroni correction can help manage the increased risk of Type I error.\n",
    "\n",
    "3. **Dunnett's Test**:\n",
    "   - Used when one group (control) is compared against multiple other groups.\n",
    "   - Controls the familywise error rate specifically for the control-to-other-group comparisons.\n",
    "   - Example: You're comparing the effectiveness of a new drug to a control group and want to determine which doses of the new drug are significantly different from the control.\n",
    "\n",
    "4. **Scheffe's Test**:\n",
    "   - Offers greater control over Type I error rates but is more conservative than other tests.\n",
    "   - Suitable for situations with unequal sample sizes and unequal variances.\n",
    "   - Example: You're conducting a multi-factorial ANOVA with unequal group sizes and want to make pairwise comparisons that have a high level of control over Type I errors.\n",
    "\n",
    "5. **Games-Howell Test**:\n",
    "   - Suitable when the assumption of homogeneity of variances is violated.\n",
    "   - Allows for unequal variances across groups.\n",
    "   - Example: You're analyzing data on reaction times among different groups but find that the assumption of equal variances is not met. The Games-Howell test can be used for pairwise comparisons.\n",
    "\n",
    "The need for a post-hoc test arises when you've performed an ANOVA and found a significant overall effect. However, the ANOVA doesn't indicate which specific groups are different from each other. In such cases, post-hoc tests provide a systematic way to identify these differences while managing the risk of Type I errors. The choice of post-hoc test depends on the research question, the assumptions of the data, and the level of control over error rates desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27bfe0",
   "metadata": {},
   "source": [
    "__Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c973ab2",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d9f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results:\n",
      "F-statistic: 57.06379442059458\n",
      "p-value: 4.5619061215783055e-19\n",
      "We reject the null hypothesis.\n",
      "Conclusion: The mean weight loss is different for at least one diet.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate simulated data assuming normal distribution with the same variance\n",
    "np.random.seed(1)\n",
    "diet_A = np.random.normal(5, 1, 50)\n",
    "diet_B = np.random.normal(4, 1, 50)\n",
    "diet_C = np.random.normal(3, 1, 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Define hypotheses\n",
    "null_hypothesis = \"The mean weight loss is the same for all three diets.\"\n",
    "alternate_hypothesis = \"The mean weight loss is different for at least one diet.\"\n",
    "\n",
    "# Print ANOVA results\n",
    "print(\"One-Way ANOVA Results:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results based on the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis.\")\n",
    "    print(\"Conclusion:\", alternate_hypothesis)\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis.\")\n",
    "    print(\"Conclusion:\", null_hypothesis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755ee52",
   "metadata": {},
   "source": [
    "__Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0cb69",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138219c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data:\n",
      "  Software   Experience       Time\n",
      "0        A       Novice  12.828739\n",
      "1        A  Experienced  16.994691\n",
      "2        A       Novice  15.565957\n",
      "3        A  Experienced  11.987411\n",
      "4        A       Novice  13.842799\n",
      "\n",
      "=============================================\n",
      "\n",
      "ANOVA Table:\n",
      "                               sum_sq    df          F    PR(>F)\n",
      "C(Software)                204.881181   2.0  11.507860  0.000069\n",
      "C(Experience)                0.246230   1.0   0.027661  0.868530\n",
      "C(Software):C(Experience)    0.455966   2.0   0.025611  0.974726\n",
      "Residual                   480.696856  54.0        NaN       NaN\n",
      "\n",
      "=============================================\n",
      "\n",
      "Interpretation:\n",
      "There is a significant effect of C(Software).\n",
      "There is no significant effect of C(Experience).\n",
      "There is no significant effect of C(Software):C(Experience).\n",
      "There is no significant effect of Residual.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Create simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 20),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 30),\n",
    "    'Time': np.concatenate([time_novice, time_expert])\n",
    "})\n",
    "\n",
    "# Display the simulated data\n",
    "print('Simulated Data:')\n",
    "print(data.head())\n",
    "print('\\n=============================================\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Print ANOVA table\n",
    "print(\"ANOVA Table:\")\n",
    "print(anova_table)\n",
    "print('\\n=============================================\\n')\n",
    "\n",
    "# Interpret the results\n",
    "print(\"Interpretation:\")\n",
    "for factor in anova_table.index:\n",
    "    p_value = anova_table.loc[factor, 'PR(>F)']\n",
    "    if p_value < alpha:\n",
    "        print(f\"There is a significant effect of {factor}.\")\n",
    "    else:\n",
    "        print(f\"There is no significant effect of {factor}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d92396",
   "metadata": {},
   "source": [
    "__Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0de1b0",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b90015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data:\n",
      "     Group     Scores\n",
      "0  Control  64.143694\n",
      "1  Control  84.973454\n",
      "2  Control  77.829785\n",
      "3  Control  59.937053\n",
      "4  Control  69.213997\n",
      "\n",
      "=============================================\n",
      "\n",
      "Two-sample t-test results:\n",
      "T-statistic: -2.315158728279605\n",
      "P-value: 0.022690065589586535\n",
      "\n",
      "=============================================\n",
      "\n",
      "Post-hoc Tukey's HSD test results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   5.2768 0.0227 0.7537 9.7998   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate test scores for control and experimental groups\n",
    "control_scores = np.random.normal(loc=75, scale=10, size=50)\n",
    "experimental_scores = np.random.normal(loc=80, scale=10, size=50)\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'Group': np.repeat(['Control', 'Experimental'], 50),\n",
    "    'Scores': np.concatenate([control_scores, experimental_scores])\n",
    "})\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print('Simulated Data:')\n",
    "print(data.head())\n",
    "print('\\n=============================================\\n')\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Print t-test results\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print('\\n=============================================\\n')\n",
    "\n",
    "# Perform a post-hoc Tukey's HSD test\n",
    "posthoc = pairwise_tukeyhsd(data['Scores'], data['Group'])\n",
    "\n",
    "# Print post-hoc test results\n",
    "print(\"Post-hoc Tukey's HSD test results:\")\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cc0f2",
   "metadata": {},
   "source": [
    "#### Conclusion from Tukey's HSD Test:\n",
    "\n",
    "* The adjusted p-value (0.0227) is less than the significance level (0.05).\n",
    "* The mean difference of approximately 5.2768 indicates a statistically significant difference in test scores.\n",
    "* The \"True\" value under the \"reject\" column suggests that the means are significantly different between the Control and Experimental groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d160a",
   "metadata": {},
   "source": [
    "#### Overall Conclusion:\n",
    "\n",
    "The new teaching method (Experimental group) has led to a statistically significant improvement in student test scores compared to the traditional teaching method (Control group).\n",
    "In summary, the t-test and Tukey's HSD test results provide strong evidence that the new teaching method has a positive impact on student test scores compared to the traditional method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9e4d0",
   "metadata": {},
   "source": [
    "__Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7773eca",
   "metadata": {},
   "source": [
    "__Ans.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd1c87",
   "metadata": {},
   "source": [
    "Assume significance value of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1c91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "================================================\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n================================================\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06252d5f",
   "metadata": {},
   "source": [
    "#### Conclusion: \n",
    "\n",
    "1. In Repeated Measure ANOVA test we got p_value (Pr>F) as 0.0000 which is less than 0.05 .Reject the Null Hypothesis .Which means atleast one of the mean of groups is different.\n",
    "\n",
    "2. In Tukey's Post Hoc Test we get following interpretation :\n",
    "    * No significant difference between sales of Store A and Store B. Store B earns 21.24 dollars more than store A(becuse reject=False for this)\n",
    "    * Significant difference between sales of Store A and Store C . Store C has approx 207.8 dollars lesser compared to store A (reject=True)\n",
    "    * Siginficant difference between sales of Store B and Store C . Store C has approx 229.0 dollars lesser compared to store B (reject=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f4f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
