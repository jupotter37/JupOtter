{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continual Learning Model - Dynamic Layer Expansion - Episodic Replay with Random Sampling - Memory Partitioning & Data Augmentation - Class Incremental - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "process = psutil.Process()\n",
    "start_memory = process.memory_info().rss / 1024 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation function\n",
    "def prepare_dataset():\n",
    "    # Load MNIST dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='/Users/guptaabhinav/Documents/All Documentation/Education/Postgrad - USC - Coursework/USC Semester-3/Deep Learning/Project/data', train=True, download=False, transform=transform)\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='/Users/guptaabhinav/Documents/All Documentation/Education/Postgrad - USC - Coursework/USC Semester-3/Deep Learning/Project/data', train=False, download=False, transform=transform)\n",
    "    \n",
    "    # Split dataset into 5 tasks (0-1, 2-3, 4-5, 6-7, 8-9)\n",
    "    tasks = []\n",
    "    for i in range(0, 10, 2):\n",
    "        train_idx = torch.where((train_dataset.targets == i) | \n",
    "                              (train_dataset.targets == i+1))[0]\n",
    "        test_idx = torch.where((test_dataset.targets == i) | \n",
    "                              (test_dataset.targets == i+1))[0]\n",
    "        \n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        test_subset = Subset(test_dataset, test_idx)\n",
    "        tasks.append((train_subset, test_subset))\n",
    "    \n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, initial_channels, kernel_size=3, padding=1, expansion_factor=0.5):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.current_channels = initial_channels\n",
    "        self.expansion_factor = expansion_factor\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Main convolution layer\n",
    "        self.conv = nn.Conv2d(in_channels, initial_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(initial_channels)\n",
    "        self.expansion_layers = nn.ModuleList()\n",
    "        \n",
    "    def expand(self, task_id):\n",
    "        \"\"\"Add new channels for new task\"\"\"\n",
    "        expansion_size = int(self.current_channels * self.expansion_factor)\n",
    "        new_conv = nn.Conv2d(\n",
    "            self.in_channels, \n",
    "            expansion_size, \n",
    "            kernel_size=self.kernel_size, \n",
    "            padding=self.padding\n",
    "        ).to(self.conv.weight.device)\n",
    "        new_bn = nn.BatchNorm2d(expansion_size).to(self.conv.weight.device)\n",
    "        \n",
    "        # Initialize with similar statistics\n",
    "        nn.init.kaiming_normal_(new_conv.weight)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight.data *= 0.1\n",
    "        \n",
    "        self.expansion_layers.append((new_conv, new_bn, task_id))\n",
    "        self.current_channels += expansion_size\n",
    "        return self.current_channels\n",
    "        \n",
    "    def forward(self, x, task_id=None):\n",
    "        main_out = F.relu(self.bn(self.conv(x)))\n",
    "        \n",
    "        expansion_outputs = []\n",
    "        for conv, bn, layer_task_id in self.expansion_layers:\n",
    "            if task_id is None or layer_task_id <= task_id:\n",
    "                exp_out = F.relu(bn(conv(x)))\n",
    "                expansion_outputs.append(exp_out)\n",
    "        \n",
    "        if expansion_outputs:\n",
    "            return torch.cat([main_out] + expansion_outputs, dim=1)\n",
    "        return main_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicIncrementalCNN(nn.Module):\n",
    "    def __init__(self, num_tasks=5, classes_per_task=2, expansion_threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "        self.classes_per_task = classes_per_task\n",
    "        self.total_classes = num_tasks * classes_per_task\n",
    "        self.expansion_threshold = expansion_threshold\n",
    "        self.task_performance = defaultdict(list)\n",
    "        \n",
    "        # Dynamic feature extractor matching your architecture\n",
    "        self.features = nn.ModuleList([\n",
    "            DynamicBlock(1, 32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            DynamicBlock(32, 64),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        ])\n",
    "        \n",
    "        # Dynamic classifier\n",
    "        self.current_hidden_size = 512\n",
    "        self.classifier = nn.ModuleList([\n",
    "            nn.Linear(64 * 7 * 7, self.current_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.current_hidden_size, self.total_classes)\n",
    "        ])\n",
    "        \n",
    "    def should_expand(self, task_id, current_performance):\n",
    "        \"\"\"Determine if network should expand based on performance\"\"\"\n",
    "        if not self.task_performance[task_id]:\n",
    "            return False\n",
    "        \n",
    "        avg_prev_performance = np.mean(self.task_performance[task_id][-5:])\n",
    "        return current_performance < avg_prev_performance * self.expansion_threshold\n",
    "    \n",
    "    def expand_network(self, task_id):\n",
    "        \"\"\"Expand network capacity for new task\"\"\"\n",
    "        # Expand convolutional blocks\n",
    "        new_channels = 0\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, DynamicBlock):\n",
    "                new_channels = layer.expand(task_id)\n",
    "        \n",
    "        # Update classifier input size if needed\n",
    "        if new_channels:\n",
    "            old_fc = self.classifier[0]\n",
    "            new_in_features = new_channels * 7 * 7\n",
    "            new_hidden_size = int(self.current_hidden_size * 1.2)  # Grow hidden layer\n",
    "            \n",
    "            # Create new classifier layers\n",
    "            new_fc1 = nn.Linear(new_in_features, new_hidden_size).to(old_fc.weight.device)\n",
    "            new_fc2 = nn.Linear(new_hidden_size, self.total_classes).to(self.classifier[3].weight.device)\n",
    "            \n",
    "            # Initialize and copy weights\n",
    "            with torch.no_grad():\n",
    "                # Copy weights for the first layer\n",
    "                new_fc1.weight.data[:old_fc.out_features, :old_fc.in_features] = old_fc.weight.data\n",
    "                new_fc1.bias.data[:old_fc.out_features] = old_fc.bias.data\n",
    "                \n",
    "                # Copy weights for the output layer\n",
    "                new_fc2.weight.data[:, :self.classifier[3].in_features] = self.classifier[3].weight.data\n",
    "                new_fc2.bias.data = self.classifier[3].bias.data\n",
    "            \n",
    "            # Update classifier\n",
    "            self.classifier[0] = new_fc1\n",
    "            self.classifier[3] = new_fc2\n",
    "            self.current_hidden_size = new_hidden_size\n",
    "    \n",
    "    def forward(self, x, task_id=None):\n",
    "        # Forward through dynamic feature extractor\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, DynamicBlock):\n",
    "                x = layer(x, task_id)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        # Flatten and forward through classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier[0](x)\n",
    "        x = self.classifier[1](x)\n",
    "        x = self.classifier[2](x)\n",
    "        x = self.classifier[3](x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def update_task_performance(self, task_id, performance):\n",
    "        \"\"\"Track task performance for expansion decisions\"\"\"\n",
    "        self.task_performance[task_id].append(performance)\n",
    "        if len(self.task_performance[task_id]) > 10:\n",
    "            self.task_performance[task_id].pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedMemoryItem:\n",
    "    def __init__(self, image, label, task_id):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.task_id = task_id\n",
    "\n",
    "class HybridEpisodicBuffer:\n",
    "    def __init__(self, samples_per_class=50, n_classes=10, device='mps'):\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.n_classes = n_classes\n",
    "        self.device = device\n",
    "        self.memory = defaultdict(list)\n",
    "        \n",
    "        # Define augmentation transforms\n",
    "        self.augmentation_transforms = transforms.Compose([\n",
    "            transforms.RandomAffine(\n",
    "                degrees=20,\n",
    "                translate=(0.15, 0.15),\n",
    "                scale=(0.85, 1.15),\n",
    "                fill=0\n",
    "            ),\n",
    "            transforms.RandomRotation(\n",
    "                degrees=20,\n",
    "                fill=0\n",
    "            ),\n",
    "            transforms.RandomPerspective(\n",
    "                distortion_scale=0.1,\n",
    "                p=0.3,\n",
    "                fill=0\n",
    "            ),\n",
    "            transforms.GaussianBlur(\n",
    "                kernel_size=3,\n",
    "                sigma=(0.1, 0.2)\n",
    "            ),\n",
    "        ])\n",
    "    \n",
    "    def add_sample(self, image, label, task_id):\n",
    "        \"\"\"Add a new sample to the memory buffer\"\"\"\n",
    "        if len(self.memory[label.item()]) >= self.samples_per_class:\n",
    "            # Remove oldest sample if buffer is full for this class\n",
    "            self.memory[label.item()].pop(0)\n",
    "        \n",
    "        # Store the sample\n",
    "        self.memory[label.item()].append(\n",
    "            AugmentedMemoryItem(image.cpu(), label.cpu(), task_id)\n",
    "        )\n",
    "    \n",
    "    def get_memory_samples(self, n_samples=32, augment=True):\n",
    "        \"\"\"Get random samples from memory with augmentation\"\"\"\n",
    "        if len(self.memory) == 0:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Randomly select classes that are in memory\n",
    "        available_classes = list(self.memory.keys())\n",
    "        samples_per_class = n_samples // len(available_classes)\n",
    "        remaining_samples = n_samples % len(available_classes)\n",
    "        \n",
    "        memory_images = []\n",
    "        memory_labels = []\n",
    "        memory_task_ids = []\n",
    "        \n",
    "        # Distribute samples across classes\n",
    "        for class_idx in available_classes:\n",
    "            class_samples = random.sample(\n",
    "                self.memory[class_idx],\n",
    "                min(samples_per_class + (1 if remaining_samples > 0 else 0),\n",
    "                    len(self.memory[class_idx]))\n",
    "            )\n",
    "            if remaining_samples > 0:\n",
    "                remaining_samples -= 1\n",
    "            \n",
    "            for sample in class_samples:\n",
    "                image = sample.image\n",
    "                if augment:\n",
    "                    # Apply augmentation with 50% probability\n",
    "                    if random.random() < 0.5:\n",
    "                        image = self.augment_sample(image)\n",
    "                \n",
    "                memory_images.append(image)\n",
    "                memory_labels.append(sample.label)\n",
    "                memory_task_ids.append(sample.task_id)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        memory_images = torch.stack(memory_images).to(self.device)\n",
    "        memory_labels = torch.tensor(memory_labels).to(self.device)\n",
    "        memory_task_ids = torch.tensor(memory_task_ids).to(self.device)\n",
    "        \n",
    "        return memory_images, memory_labels, memory_task_ids\n",
    "    \n",
    "    def augment_sample(self, image):\n",
    "        \"\"\"Apply augmentation to a single image\"\"\"\n",
    "        # Convert to PIL image for transforms\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = transforms.ToPILImage()(image.squeeze())\n",
    "        augmented = self.augmentation_transforms(image)\n",
    "        # Convert back to tensor\n",
    "        return transforms.ToTensor()(augmented)\n",
    "\n",
    "class DynamicContinualLearningModel(DynamicIncrementalCNN):\n",
    "    def __init__(self, num_tasks=5, classes_per_task=2, memory_samples_per_class=50):\n",
    "        super().__init__(num_tasks, classes_per_task)\n",
    "        self.episodic_memory = HybridEpisodicBuffer(\n",
    "            samples_per_class=memory_samples_per_class,\n",
    "            n_classes=num_tasks * classes_per_task\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_task_with_dynamic_expansion(model, train_loader, task_id, device, \n",
    "                                    epochs=7, replay_batch_size=32, augment_ratio=2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            task_targets = targets % 2 + (task_id * 2)\n",
    "            \n",
    "            # Generate augmented samples\n",
    "            augmented_inputs = []\n",
    "            augmented_targets = []\n",
    "            \n",
    "            for _ in range(augment_ratio - 1):\n",
    "                aug_inputs = torch.stack([\n",
    "                    model.episodic_memory.augment_sample(img) \n",
    "                    for img in inputs\n",
    "                ]).to(device)\n",
    "                augmented_inputs.append(aug_inputs)\n",
    "                augmented_targets.append(task_targets)\n",
    "            \n",
    "            # Get replay samples\n",
    "            memory_inputs, memory_labels, _ = model.episodic_memory.get_memory_samples(\n",
    "                n_samples=replay_batch_size,\n",
    "                augment=True\n",
    "            )\n",
    "            \n",
    "            # Combine all samples\n",
    "            batch_inputs = [inputs] + augmented_inputs\n",
    "            batch_targets = [task_targets] + augmented_targets\n",
    "            \n",
    "            if memory_inputs is not None:\n",
    "                batch_inputs.append(memory_inputs)\n",
    "                batch_targets.append(memory_labels)\n",
    "            \n",
    "            combined_inputs = torch.cat(batch_inputs)\n",
    "            combined_targets = torch.cat(batch_targets)\n",
    "            \n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_inputs, task_id)\n",
    "            loss = criterion(outputs, combined_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Store samples in memory\n",
    "            for img, lbl in zip(inputs, targets):\n",
    "                model.episodic_memory.add_sample(img, lbl, task_id)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            task_outputs = outputs[:len(inputs)]\n",
    "            _, predicted = task_outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == task_targets).sum().item()\n",
    "        \n",
    "        epoch_acc = 100 * correct / total\n",
    "        model.update_task_performance(task_id, epoch_acc)\n",
    "        \n",
    "        # Check if network should expand\n",
    "        if model.should_expand(task_id, epoch_acc):\n",
    "            print(f\"\\nExpanding network for task {task_id + 1} at epoch {epoch + 1}\")\n",
    "            model.expand_network(task_id)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.3f}, '\n",
    "              f'Accuracy: {epoch_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Task 1\n",
      "Epoch 1, Loss: 0.096, Accuracy: 99.21%\n",
      "Epoch 2, Loss: 0.029, Accuracy: 99.83%\n",
      "Epoch 3, Loss: 0.022, Accuracy: 99.92%\n",
      "Epoch 4, Loss: 0.017, Accuracy: 99.94%\n",
      "Epoch 5, Loss: 0.017, Accuracy: 99.91%\n",
      "Epoch 6, Loss: 0.018, Accuracy: 99.90%\n",
      "Epoch 7, Loss: 0.012, Accuracy: 99.99%\n",
      "\n",
      "Training Task 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_subset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m train_task_with_dynamic_expansion(model, train_loader, task_id, device)\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mtrain_task_with_dynamic_expansion\u001b[0;34m(model, train_loader, task_id, device, epochs, replay_batch_size, augment_ratio)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Store samples in memory\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, lbl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, targets):\n\u001b[0;32m---> 54\u001b[0m     model\u001b[38;5;241m.\u001b[39mepisodic_memory\u001b[38;5;241m.\u001b[39madd_sample(img, lbl, task_id)\n\u001b[1;32m     56\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m, in \u001b[0;36mHybridEpisodicBuffer.add_sample\u001b[0;34m(self, image, label, task_id)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, label, task_id):\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a new sample to the memory buffer\"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory[label\u001b[38;5;241m.\u001b[39mitem()]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples_per_class:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# Remove oldest sample if buffer is full for this class\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory[label\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Store the sample\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tasks = prepare_dataset()\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicContinualLearningModel(\n",
    "    num_tasks=5, \n",
    "    classes_per_task=2, \n",
    "    memory_samples_per_class=100\n",
    ").to(device)\n",
    "\n",
    "# Train with dynamic expansion\n",
    "for task_id, (train_subset, _) in enumerate(tasks):\n",
    "    print(f'\\nTraining Task {task_id + 1}')\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    train_task_with_dynamic_expansion(model, train_loader, task_id, device)\n",
    "    # train_task_with_enhanced_expansion(model, train_loader, task_id, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task-Agnostic Evaluation Results\n",
      "==================================================\n",
      "Overall Accuracy: 95.40%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_task_agnostic(model, tasks, device, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate model performance without any knowledge of task boundaries or class associations.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    task_predictions = defaultdict(list)\n",
    "    task_targets = defaultdict(list)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for task_id, (_, test_subset) in enumerate(tasks):\n",
    "            test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "            \n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                \n",
    "                # Store predictions and targets for both overall and per-task analysis\n",
    "                predictions = predicted.cpu().numpy()\n",
    "                targets_np = targets.cpu().numpy()\n",
    "                \n",
    "                all_predictions.extend(predictions)\n",
    "                all_targets.extend(targets_np)\n",
    "                task_predictions[task_id].extend(predictions)\n",
    "                task_targets[task_id].extend(targets_np)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = np.mean(all_predictions == all_targets) * 100\n",
    "    \n",
    "    print(\"\\nTask-Agnostic Evaluation Results\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Overall Accuracy: {metrics:.2f}%\")\n",
    "\n",
    "evaluate_task_agnostic(model, tasks, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
    "end_memory = process.memory_info().rss / 1024 ** 2  # Memory in MB\n",
    "print(f\"Memory Usage: {end_memory - start_memory:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
