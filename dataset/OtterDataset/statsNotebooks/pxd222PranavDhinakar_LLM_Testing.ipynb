{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/pranavdhinakar/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "\n",
    "def ensure_nltk_resources():\n",
    "  required_resources = ['punkt', 'brown', 'punkt_tab']\n",
    "  for resource in required_resources:\n",
    "    try:\n",
    "      if resource == 'punkt_tab':\n",
    "        nltk.data.find(f'tokenizers/{resource}/english/')\n",
    "      else:\n",
    "        nltk.data.find(f'tokenizers/{resource}')\n",
    "    except LookupError:\n",
    "      nltk.download(resource, download_dir='C://Users//caden/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C://Users//caden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to C://Users//caden/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C://Users//caden/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "ensure_nltk_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentences from the Brown corpus:\n",
      "1. The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "2. The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\n",
      "3. The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. .\n",
      "4. `` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\n",
      "5. The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' .\n",
      "6. It recommended that Fulton legislators act `` to have these laws studied and revised to the end of modernizing and improving them '' .\n",
      "7. The grand jury commented on a number of other topics , among them the Atlanta and Fulton County purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best interest of both governments '' .\n",
      "8. Merger proposed\n",
      "9. However , the jury said it believes `` these two offices should be combined to achieve greater efficiency and reduce the cost of administration '' .\n",
      "10. The City Purchasing Department , the jury said , `` is lacking in experienced clerical personnel as a result of city personnel policies '' .\n",
      "\n",
      "Categories in the Brown corpus:\n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "\n",
      "Sample words from different categories:\n",
      "\n",
      "Adventure:\n",
      "Dan Morgan told himself he would forget Ann Turner . He was well rid of her . He certainly didn't\n",
      "\n",
      "Belles_lettres:\n",
      "Northern liberals are the chief supporters of civil rights and of integration . They have also led the nation in\n",
      "\n",
      "Editorial:\n",
      "Assembly session brought much good The General Assembly , which adjourns today , has performed in an atmosphere of crisis\n",
      "\n",
      "Fiction:\n",
      "Thirty-three Scotty did not go back to school . His parents talked seriously and lengthily to their own doctor and\n",
      "\n",
      "Government:\n",
      "The Office of Business Economics ( OBE ) of the U.S. Department of Commerce provides basic measures of the national\n"
     ]
    }
   ],
   "source": [
    "# Get the first 10 sentences from the Brown corpus\n",
    "sentences = brown.sents()[:10]\n",
    "\n",
    "print(\"Sample sentences from the Brown corpus:\")\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {' '.join(sentence)}\")\n",
    "\n",
    "print(\"\\nCategories in the Brown corpus:\")\n",
    "print(brown.categories())\n",
    "\n",
    "print(\"\\nSample words from different categories:\")\n",
    "for category in brown.categories()[:5]:  # First 5 categories\n",
    "    print(f\"\\n{category.capitalize()}:\")\n",
    "    print(' '.join(brown.words(categories=category)[:20]))  # First 20 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Model Process Example\n",
    "\n",
    "Let's use a bigram (2-gram) model to process the first sentence from the Brown corpus and demonstrate how it predicts new tokens.\n",
    "\n",
    "Sentence: \"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced no evidence that any irregularities took place .\"\n",
    "\n",
    "## 1. Tokenization\n",
    "\n",
    "First, we tokenize the sentence:\n",
    "\n",
    "[\"The\", \"Fulton\", \"County\", \"Grand\", \"Jury\", \"said\", \"Friday\", \"an\", \"investigation\", \"of\", \"Atlanta's\", \"recent\", \"primary\", \"election\", \"produced\", \"no\", \"evidence\", \"that\", \"any\", \"irregularities\", \"took\", \"place\", \".\"]\n",
    "\n",
    "## 2. Creating Bigrams\n",
    "\n",
    "We create bigrams from this sequence:\n",
    "\n",
    "(\"The\", \"Fulton\"), (\"Fulton\", \"County\"), (\"County\", \"Grand\"), ..., (\"took\", \"place\"), (\"place\", \".\")\n",
    "\n",
    "## 3. Counting Bigrams\n",
    "\n",
    "We count the occurrences of each bigram in our corpus. Let's assume we've processed the entire corpus and have these counts (simplified for this example):\n",
    "\n",
    "- Count(\"The\", \"Fulton\") = 10\n",
    "- Count(\"Fulton\", \"County\") = 15\n",
    "- ...\n",
    "- Count(\"The\") = 1000 (total occurrences of \"The\" as the first word in any bigram)\n",
    "\n",
    "## 4. Calculating Probabilities\n",
    "\n",
    "For each bigram, we calculate the probability:\n",
    "\n",
    "$P(w_2|w_1) = \\frac{Count(w_1, w_2)}{Count(w_1)}$\n",
    "\n",
    "For example:\n",
    "$P(\\text{\"Fulton\"}|\\text{\"The\"}) = \\frac{Count(\\text{\"The\", \"Fulton\"})}{Count(\\text{\"The\"})} = \\frac{10}{1000} = 0.01$\n",
    "\n",
    "## 5. Predicting Next Token\n",
    "\n",
    "To predict the next token after \"The\", we would:\n",
    "\n",
    "1. Find all bigrams starting with \"The\"\n",
    "2. Calculate their probabilities\n",
    "3. Choose the one with the highest probability\n",
    "\n",
    "Let's say we have these bigrams and probabilities:\n",
    "\n",
    "- $P(\\text{\"Fulton\"}|\\text{\"The\"}) = 0.01$\n",
    "- $P(\\text{\"Grand\"}|\\text{\"The\"}) = 0.02$\n",
    "- $P(\\text{\"investigation\"}|\\text{\"The\"}) = 0.03$\n",
    "\n",
    "The model would predict \"investigation\" as the next token after \"The\", as it has the highest probability.\n",
    "\n",
    "## 6. Generating Text\n",
    "\n",
    "To generate text, we would:\n",
    "\n",
    "1. Start with a token (e.g., \"The\")\n",
    "2. Predict the next token based on probabilities\n",
    "3. Add the predicted token to our sequence\n",
    "4. Repeat steps 2-3, using the last token as the new starting point\n",
    "\n",
    "For example:\n",
    "\"The\" → \"investigation\" → \"of\" → \"Atlanta's\" → ...\n",
    "\n",
    "## 7. Handling Unseen Bigrams\n",
    "\n",
    "If we encounter a bigram that wasn't in our training data, we need a smoothing technique. A simple method is add-one (Laplace) smoothing:\n",
    "\n",
    "$P(w_2|w_1) = \\frac{Count(w_1, w_2) + 1}{Count(w_1) + V}$\n",
    "\n",
    "Where $V$ is the size of our vocabulary.\n",
    "\n",
    "This ensures that even unseen bigrams have a small, non-zero probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/pranavdhinakar/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from model_builder import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the NGram model\n",
    "n = 2  # for bigram model\n",
    "ngram_model = NGram(n)\n",
    "\n",
    "# Prepare the corpus\n",
    "corpus = brown.words()[:10000]  # Using first 10000 words from Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Model training complete.\n",
      "Vocabulary size: 2475\n",
      "First 10 words in vocabulary: ['6', 'privilege', 'scattered', 'firmer', 'h.', 'pressure', 'disappointment', 'criticized', 'each', 'franker']\n",
      "Shape of counts array: (2475, 2475)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "ngram_model.train(corpus)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Print some information about the trained model\n",
    "print(f\"Vocabulary size: {len(ngram_model.vocab)}\")\n",
    "print(f\"First 10 words in vocabulary: {ngram_model.vocab[:10]}\")\n",
    "print(f\"Shape of counts array: {ngram_model.counts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(man|the) = 0.000178\n",
      "Either 'the' or 'woman' is not in the vocabulary.\n",
      "P(child|the) = 0.000356\n",
      "P(court|the) = 0.000533\n",
      "P(judge|the) = 0.000178\n",
      "P(man|a) = 0.000194\n",
      "Either 'a' or 'woman' is not in the vocabulary.\n",
      "P(child|a) = 0.000194\n",
      "P(court|a) = 0.000194\n",
      "P(judge|a) = 0.000194\n",
      "P(man|to) = 0.000192\n",
      "Either 'to' or 'woman' is not in the vocabulary.\n",
      "P(child|to) = 0.000192\n",
      "P(court|to) = 0.000192\n",
      "P(judge|to) = 0.000192\n",
      "\n",
      "Most probable word after 'the': 'state' with P(state|the) = 0.003378\n",
      "\n",
      "Vocabulary size: 2475\n",
      "First 10 words in vocabulary: ['6', 'privilege', 'scattered', 'firmer', 'h.', 'pressure', 'disappointment', 'criticized', 'each', 'franker']\n",
      "'the' in vocabulary: True\n"
     ]
    }
   ],
   "source": [
    "# Test words\n",
    "test_contexts = ['the', 'a', 'to']\n",
    "test_words = ['man', 'woman', 'child', 'court', 'judge']\n",
    "\n",
    "# Calculate and print probabilities\n",
    "for context in test_contexts:\n",
    "    for word in test_words:\n",
    "        try:\n",
    "            if context in ngram_model.vocab and word in ngram_model.vocab:\n",
    "                prob = ngram_model.prob([context], word)\n",
    "                print(f\"P({word}|{context}) = {prob:.6f}\")\n",
    "            else:\n",
    "                print(f\"Either '{context}' or '{word}' is not in the vocabulary.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating P({word}|{context}): {str(e)}\")\n",
    "\n",
    "# Find the most probable word after 'the'\n",
    "if 'the' in ngram_model.vocab:\n",
    "    try:\n",
    "        most_probable = max(ngram_model.vocab, key=lambda w: ngram_model.prob(['the'], w))\n",
    "        prob = ngram_model.prob(['the'], most_probable)\n",
    "        print(f\"\\nMost probable word after 'the': '{most_probable}' with P({most_probable}|the) = {prob:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding most probable word after 'the': {str(e)}\")\n",
    "else:\n",
    "    print(\"'the' is not in the vocabulary.\")\n",
    "\n",
    "# Print some vocabulary information\n",
    "print(\"\\nVocabulary size:\", len(ngram_model.vocab))\n",
    "print(\"First 10 words in vocabulary:\", ngram_model.vocab[:10])\n",
    "print(\"'the' in vocabulary:\", 'the' in ngram_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/pranavdhinakar/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/pranavdhinakar/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# CSDS497 Programming Exercise 1\n",
    "\n",
    "## Setup and Imports\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown, gutenberg\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your NGram class here\n",
    "from model_builder import NGram\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "## 1. Different runs of your code (n=2)\n",
    "\n",
    "# Training data\n",
    "#train_data = brown.words()[:50000]  # Use first 50,000 words for training\n",
    "#test_data = brown.words()[50000:60000]  # Use next 10,000 words for testing\n",
    "train_data = brown.words()[:5000]# Use first 5,000 words for training\n",
    "test_data = brown.words()[5000:5500]# Use next 500 words for testing\n",
    "\n",
    "\n",
    "# Train the model\n",
    "bigram_model = NGram(2)\n",
    "bigram_model.train(train_data)\n",
    "\n",
    "\n",
    "\n",
    "## 2. Test with different source\n",
    "\n",
    "#gutenberg_data = gutenberg.words()[:10000]  # Use first 10,000 words from Gutenberg corpus\n",
    "gutenberg_data = gutenberg.words()[:1000]  # Use first 1,000 words from Gutenberg corpus\n",
    "\n",
    "\n",
    "# Test the model on Gutenberg data\n",
    "# (We'll implement testing here)\n",
    "\n",
    "## 3. Compare n-gram models (n=1,2,3)\n",
    "\n",
    "# Train and test models for n=1,2,3\n",
    "# (We'll implement this comparison here)\n",
    "\n",
    "## 4. Compare models with and without smoothing\n",
    "\n",
    "# Implement versions of NGram with and without smoothing\n",
    "# Test on vocabulary from lexicon and vocabulary not from lexicon\n",
    "# (We'll implement this comparison here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bigram model...\n",
      "\n",
      "Testing on Brown corpus test data...\n",
      "Perplexity: 2356.02\n",
      "\n",
      "Example probabilities from test data:\n",
      "Format: P(next_word|context) = probability\n",
      "--------------------------------------------------\n",
      "P(evidence|said) = 0.000326\n",
      "P(not|did) = 0.000990\n",
      "P(Cook|of) = 0.000313\n",
      "P(of|precincts) = 0.000330\n",
      "P(.|them) = 0.000330\n",
      "\n",
      "Testing on Gutenberg corpus...\n",
      "Perplexity: 2734.81\n",
      "\n",
      "Example probabilities from Gutenberg data:\n",
      "Format: P(next_word|context) = probability\n",
      "--------------------------------------------------\n",
      "P(Emma|[) = 0.000330\n",
      "P(mildness|the) = 0.000298\n",
      "P(father|her) = 0.000330\n",
      "P(last|the) = 0.000597\n",
      "P(her|for) = 0.000325\n",
      "\n",
      "Dataset Statistics:\n",
      "Training data size: 5000 words\n",
      "Test data size: 500 words\n",
      "Gutenberg test data size: 1000 words\n",
      "Vocabulary size: 1513 words\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(model: NGram, test_data: List[str]) -> float:\n",
    "    log_likelihood = 0\n",
    "    N = len(test_data)\n",
    "    \n",
    "    for i in range(N - model.n + 1):\n",
    "        context = test_data[i:i+model.n-1]\n",
    "        word = test_data[i+model.n-1]\n",
    "        prob = model.prob(context, word)\n",
    "        log_likelihood += np.log2(prob)\n",
    "    \n",
    "    perplexity = 2 ** (-1/N * log_likelihood)\n",
    "    return perplexity\n",
    "\n",
    "def test_model(model: NGram, test_data: List[str]) -> Tuple[float, List[Tuple[str, str, float]]]:\n",
    "    perplexity = calculate_perplexity(model, test_data)\n",
    "    \n",
    "    # Get some example probabilities\n",
    "    examples = []\n",
    "    # Adjust sampling interval based on dataset size\n",
    "    sample_interval = max(1, len(test_data) // 5)  # Get about 5 examples\n",
    "    \n",
    "    for i in range(0, len(test_data) - model.n + 1, sample_interval):\n",
    "        context = test_data[i:i+model.n-1]\n",
    "        word = test_data[i+model.n-1]\n",
    "        prob = model.prob(context, word)\n",
    "        examples.append((\" \".join(context), word, prob))\n",
    "    \n",
    "    return perplexity, examples\n",
    "\n",
    "# Test the bigram model\n",
    "print(\"Training bigram model...\")\n",
    "bigram_model = NGram(2)\n",
    "bigram_model.train(train_data)\n",
    "\n",
    "print(\"\\nTesting on Brown corpus test data...\")\n",
    "perplexity, examples = test_model(bigram_model, test_data)\n",
    "\n",
    "print(f\"Perplexity: {perplexity:.2f}\")\n",
    "print(\"\\nExample probabilities from test data:\")\n",
    "print(\"Format: P(next_word|context) = probability\")\n",
    "print(\"-\" * 50)\n",
    "for context, word, prob in examples:\n",
    "    print(f\"P({word}|{context}) = {prob:.6f}\")\n",
    "\n",
    "print(\"\\nTesting on Gutenberg corpus...\")\n",
    "gutenberg_perplexity, gutenberg_examples = test_model(bigram_model, gutenberg_data)\n",
    "\n",
    "print(f\"Perplexity: {gutenberg_perplexity:.2f}\")\n",
    "print(\"\\nExample probabilities from Gutenberg data:\")\n",
    "print(\"Format: P(next_word|context) = probability\")\n",
    "print(\"-\" * 50)\n",
    "for context, word, prob in gutenberg_examples:\n",
    "    print(f\"P({word}|{context}) = {prob:.6f}\")\n",
    "\n",
    "# Print some statistics about the data\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Training data size: {len(train_data)} words\")\n",
    "print(f\"Test data size: {len(test_data)} words\")\n",
    "print(f\"Gutenberg test data size: {len(gutenberg_data)} words\")\n",
    "print(f\"Vocabulary size: {len(bigram_model.vocab)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive NGram Analysis\n",
    "import pandas as pd\n",
    "\n",
    "def run_experiment(train_size: int, test_size: int, n: int) -> dict:\n",
    "    # Get data\n",
    "    train_data = brown.words()[:train_size]\n",
    "    test_brown = brown.words()[train_size:train_size+test_size]\n",
    "    test_gutenberg = gutenberg.words()[:test_size]\n",
    "    \n",
    "    # Train model\n",
    "    model = NGram(n)\n",
    "    model.train(train_data)\n",
    "    \n",
    "    # Test on both corpora\n",
    "    brown_perp, brown_examples = test_model(model, test_brown)\n",
    "    gut_perp, gut_examples = test_model(model, test_gutenberg)\n",
    "    \n",
    "    return {\n",
    "        'n': n,\n",
    "        'train_size': train_size,\n",
    "        'test_size': test_size,\n",
    "        'vocab_size': len(model.vocab),\n",
    "        'brown_perplexity': brown_perp,\n",
    "        'gutenberg_perplexity': gut_perp,\n",
    "        'example_prob_brown': brown_examples[0][2] if brown_examples else None,\n",
    "        'example_prob_gutenberg': gut_examples[0][2] if gut_examples else None\n",
    "    }\n",
    "\n",
    "# Run experiments with different configurations\n",
    "experiments = []\n",
    "for train_size in [5000, 10000]:  # Try different training sizes\n",
    "    for n in [1, 2, 3]:  # Try different n-gram sizes\n",
    "        result = run_experiment(train_size, 500, n)\n",
    "        experiments.append(result)\n",
    "\n",
    "# Create a DataFrame and display results\n",
    "results_df = pd.DataFrame(experiments)\n",
    "print(\"\\nExperiment Results:\")\n",
    "print(results_df.to_string(float_format=lambda x: '{:.2f}'.format(x)))\n",
    "\n",
    "# Plot perplexity comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for train_size in [5000, 10000]:\n",
    "    mask = results_df['train_size'] == train_size\n",
    "    plt.plot(results_df[mask]['n'], \n",
    "             results_df[mask]['brown_perplexity'], \n",
    "             label=f'Brown (train={train_size})',\n",
    "             marker='o')\n",
    "    plt.plot(results_df[mask]['n'], \n",
    "             results_df[mask]['gutenberg_perplexity'], \n",
    "             label=f'Gutenberg (train={train_size})',\n",
    "             marker='s')\n",
    "\n",
    "plt.xlabel('n-gram size')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity vs n-gram size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print analysis\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"1. Effect of n-gram size:\")\n",
    "for n in [1, 2, 3]:\n",
    "    mask = results_df['n'] == n\n",
    "    avg_brown = results_df[mask]['brown_perplexity'].mean()\n",
    "    avg_gut = results_df[mask]['gutenberg_perplexity'].mean()\n",
    "    print(f\"  n={n}:\")\n",
    "    print(f\"    Average Brown perplexity: {avg_brown:.2f}\")\n",
    "    print(f\"    Average Gutenberg perplexity: {avg_gut:.2f}\")\n",
    "\n",
    "print(\"\\n2. Effect of training size:\")\n",
    "for size in [5000, 10000]:\n",
    "    mask = results_df['train_size'] == size\n",
    "    avg_brown = results_df[mask]['brown_perplexity'].mean()\n",
    "    avg_gut = results_df[mask]['gutenberg_perplexity'].mean()\n",
    "    print(f\"  Training size={size}:\")\n",
    "    print(f\"    Average Brown perplexity: {avg_brown:.2f}\")\n",
    "    print(f\"    Average Gutenberg perplexity: {avg_gut:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
