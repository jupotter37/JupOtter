{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this unit we will discuss an important part of data analysis, fitting distributions to data. In the process we will cover:\n",
    "\n",
    "* How to fit a distribution to data using `scipy`\n",
    "* Different distributions that may fit data\n",
    "* How to evaluate the fit of a distribution to data at a basic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as stat\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_frame(sub, xaxis_label, yaxis_label, font_size = 15, padding = -0.02):\n",
    "    \"\"\"Formats frame, axes, and ticks for matplotlib made graphic with half frame.\"\"\"\n",
    "\n",
    "    # Format graph frame and tick marks\n",
    "    sub.yaxis.set_ticks_position('left')\n",
    "    sub.xaxis.set_ticks_position('bottom')\n",
    "    sub.tick_params(axis = 'both', which = 'major', length = 7, width = 2, direction = 'out', pad = 10,\n",
    "                    labelsize = font_size)\n",
    "    sub.tick_params(axis = 'both', which = 'minor', length = 5, width = 2, direction = 'out', labelsize = 10)\n",
    "    for axis in ['bottom','left']:\n",
    "        sub.spines[axis].set_linewidth(2)\n",
    "        sub.spines[axis].set_position((\"axes\", padding))\n",
    "    for axis in ['top','right']:\n",
    "        sub.spines[axis].set_visible(False)\n",
    "\n",
    "    # Format axes\n",
    "    sub.set_xlabel(xaxis_label, fontsize = 1.6 * font_size)\n",
    "    sub.set_ylabel(yaxis_label, fontsize = 1.6 * font_size)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting data to statistical models\n",
    "\n",
    "When doing science, one wants to develop a parsimonious description of data or of a system. For example, it is much more parsimonious to describe some data as being drawn from a Gaussian distribution with $\\mu = 0$ and $\\sigma = 1$ than storing all the data. \n",
    "\n",
    "Once we know what disctribution may reproduce the properties of the data, we can test that hypothesis. However, first we must determine the parameters values for the distribution.  \n",
    "\n",
    "\n",
    "## GPAs of applicants to Chemical Engineering Graduate Program\n",
    "\n",
    "In order to explore this type of statistical analysis with Python, we will study the undergraduate GPA of the applicants to the Chemical Engineering Graduate Program in 2014.\n",
    "\n",
    "### Import the data\n",
    "\n",
    "If you look at the contents of the file, this is what you see:\n",
    "\n",
    "`GPA UG,GPA UG Max`\n",
    "\n",
    "`9.1,10`\n",
    "\n",
    "`\"3.61, 3.65 (updated)\",4`\n",
    "\n",
    "`3.27,4`\n",
    "\n",
    "`3.966,4`\n",
    "\n",
    "These data have lots of mistakes. For simplicity, we are only going to consider here data that has no issues and for which the maximum GPA is 4.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/Day3-Visualization-and-Functions/gpa_data.csv\", \"r\") as data_file:\n",
    "    all_lines = data_file.readlines()\n",
    "\n",
    "gpa_list = []\n",
    "for line in all_lines[1:]:      # Ignore first line with field names\n",
    "    gpa_list.append( line.strip().split(\",\") )\n",
    "    \n",
    "print(len(gpa_list), gpa_list[:3])\n",
    "    \n",
    "gpa = []\n",
    "for x in gpa_list:\n",
    "    try:\n",
    "        if (float(x[1]) == 4.):  # consider only cases for which maximum GPA is 4.0\n",
    "            try:\n",
    "                gpa.append(float(x[0]))\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(gpa), gpa[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.stats as stat\n",
    "#import numpy as np\n",
    "\n",
    "mode = float(stat.mode(gpa)[0])\n",
    "print(\"The mode of the sample is {0:4.2f}\".format(mode))\n",
    "\n",
    "first_quartile = stat.scoreatpercentile(gpa, 25)\n",
    "print(\"The first quartile of the sample is {0:4.2f}\".format(first_quartile))\n",
    "\n",
    "median = stat.scoreatpercentile(gpa, 50)\n",
    "print(\"The median of the sample is {0:4.2f}\".format(median))\n",
    "\n",
    "third_quartile = stat.scoreatpercentile(gpa, 75)\n",
    "print(\"The third quartile of the sample is {0:4.2f}\".format(third_quartile))\n",
    "\n",
    "skew = stat.skew(gpa)\n",
    "print(\"The skewness of the sample is {0:5.3f}\".format(skew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 9) )\n",
    "sub1 = fig.add_subplot(2,1,1)\n",
    "my_font_size = 15\n",
    "\n",
    "half_frame(sub1, \"\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram\n",
    "#\n",
    "sub1.hist(gpa, 25, normed = 1, rwidth = 0.75, color = \"g\", alpha = 0.5, histtype = \"bar\", \n",
    "          label = \"data\", cumulative = False)\n",
    "\n",
    "sub1.vlines([first_quartile, median, third_quartile], ymin = 0, ymax = 1.8, lw = 3, color = \"red\", \n",
    "            label = \"quartiles\")\n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "# Plot cumulative probability\n",
    "#\n",
    "sub2 = fig.add_subplot(2,1,2)\n",
    "half_frame(sub2, \"GPA\", \"Cumulative probability\", font_size = my_font_size)\n",
    "sub2.hist(gpa, 25, normed = 1, rwidth = 0.75, color = \"g\", alpha = 0.5, histtype = \"bar\", \n",
    "          label = \"data\", cumulative = True)\n",
    "sub2.vlines([first_quartile, median, third_quartile], ymin = 0, ymax = 1., lw = 3, color = \"red\", \n",
    "            label = \"quartiles\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to be sort of Bell shaped but the median does not coincide with the mode... we could use the sample mean and sample standard deviation to generate a Gaussian distribution and compare it to our data. \n",
    "\n",
    "\n",
    "\n",
    "## Aside: Pre-defined distributions\n",
    "\n",
    "The `stats` library of `Scipy` gives us access to lots of modules for well-known distributions.  These include, **but are not at all limited to**,  the binomial, the Poisson, and the Gaussian.\n",
    "\n",
    "**Binomial distributions** occurs as the result of the repetition of independent trials. Flipping a coin several times.  Throwing one or more dice.\n",
    "\n",
    "A fair coin has 50% chance of landing on heads and a 50% chance of landing on tails. The binomial distribution with p = 0.5 and n = 50 specifies the probability of tossing k heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.05\n",
    "n = 50\n",
    "\n",
    "# We can use the properties of the binomial function to define the plot ranges \n",
    "x = np.arange(stat.binom.ppf(0.0001, n, p), stat.binom.ppf(0.9999, n, p))\n",
    "rv = stat.binom(n, p)\n",
    "\n",
    "fig = plt.figure( figsize = (6, 4.5) )\n",
    "sub1 = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(sub1, \"k\", \"Probability mass\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram\n",
    "sub1.vlines(x, 0, rv.pmf(x), color = \"g\", linewidth = 20, alpha = 0.5, label = \"Binomial\")\n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = 1.5 * my_font_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (8, 4.5) )\n",
    "sub1 = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(sub1, \"GPA\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram\n",
    "#\n",
    "sub1.hist(gpa, 30, normed = 1, rwidth = 0.75, color = \"g\", alpha = 0.5, histtype = \"bar\", \n",
    "          label = \"data\", cumulative = False)\n",
    "\n",
    "# Gaussian null model: Use the sample's mean and st_dev \n",
    "#\n",
    "mu = np.mean(gpa)\n",
    "sigma = np.std(gpa)\n",
    "print('Sample mean: {0:6.3f}\\nSample std. dev: {1:6.3f}'.format(mu, sigma))\n",
    "\n",
    "x3 = np.linspace(stat.norm.ppf(0.0001, loc = mu, scale = sigma),\n",
    "                 stat.norm.ppf(0.9999, loc = mu, scale = sigma), \n",
    "                 100)\n",
    "rv3 = stat.norm(loc = mu, scale = sigma)\n",
    "sub1.plot(x3, rv3.pdf(x3), color = \"b\", lw = 2, label= \"Gaussian\")\n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That does not look too good.  However, maybe we are being negatively biased by the fluctuations in the data... We could plot the cumulative distribution, which will smooth out the fluctuations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (8, 4.5) )\n",
    "sub1 = fig.add_subplot(1,1,1)\n",
    "my_font_size = 15\n",
    "half_frame(sub1, \"GPA\", \"Cumulative probability\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram, notice how we change the flag value for 'cumulative'\n",
    "#\n",
    "sub1.hist(gpa, 30, normed = 1, rwidth = 0.75, color = \"g\", alpha = 0.5, histtype = \"bar\", \n",
    "          label = \"data\", cumulative = True) \n",
    "\n",
    "## Gaussian null model: Use the sample's mean and st_dev \n",
    "#\n",
    "mu = np.mean(gpa)\n",
    "sigma = np.std(gpa)\n",
    "print('Sample mean: {0:6.3f}\\nSample std. dev: {1:6.3f}'.format(mu, sigma))\n",
    "\n",
    "x3 = np.linspace(stat.norm.ppf(0.0001, loc = mu, scale = sigma), \n",
    "                 stat.norm.ppf(0.9999, loc = mu, scale = sigma), \n",
    "                 100)\n",
    "sub1.plot(x3, stat.norm.cdf(x3, loc = mu, scale = sigma), color = \"b\", lw = 2, label= \"Gaussian\") # Notice we are plotting the cdf now\n",
    "\n",
    "sub1.set_xlim([2.5, 4.5])\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not look too bad, especially around the 3.5 to 3.8 range of GPA values.  But is it good enough? Is this the right description of the data? \n",
    "\n",
    "One thing we are not considering in our analysis is the fact that our data does not include values larger than 4. The distribution is truncated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated sample cumulative probability\n",
    "gpa.sort()\n",
    "cumulative = []\n",
    "for i, value in enumerate(gpa):\n",
    "    cumulative.append((i+1) / len(gpa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat.truncnorm requires as input the bounds a, b, and loc and scale\n",
    "\n",
    "popt, pcov = curve_fit(stat.truncnorm.cdf, gpa, cumulative, p0 = [-100, 0.8, 3.7, 0.3])\n",
    "\n",
    "a_model = popt[0]\n",
    "b_model = popt[1]\n",
    "mu_model = popt[2]\n",
    "sig_model = popt[3]\n",
    "print('Fitted mu: {0:6.3f}\\nFitted sigma: {1:6.3f}'.format(mu_model, sig_model))\n",
    "print(a_model, b_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well! That is unwelcome!  Why is that?\n",
    "\n",
    "Let's think about it. The value of `a` and `b` actually has to be scaled by $\\mu$ and $\\sigma$, so the four parameters are **not** independent.  The lack of independence makes the calculation of the covariance problematic.\n",
    "\n",
    "How can we solve this problem? \n",
    "\n",
    "We should start by noting that `a` and `b` are not really parameters. The value of `b` is determined by the maximum GPA (4.0) and the values of $\\mu$ and $\\sigma$. The value of `a` does not really matter as long as it is far enough from `b`.\n",
    "\n",
    "We can define a new function that incorporates this knowledge!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal(x, mu, sigma):\n",
    "    a = -100\n",
    "    b = (4.0 - mu) / sigma\n",
    "    \n",
    "    return stat.truncnorm.cdf(x, a, b, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(truncated_normal, gpa, cumulative, p0 = [3.7, 0.3])\n",
    "\n",
    "mu_model = popt[0]\n",
    "sig_model = popt[1]\n",
    "a_model = -100\n",
    "b_model = (4.0 - mu_model) / sig_model\n",
    "\n",
    "print('Fitted mu: {0:6.3f}\\nFitted sigma: {1:6.3f}'.format(mu_model, sig_model))\n",
    "print(a_model, b_model)\n",
    "print(pcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem solved!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (12, 4.5) )\n",
    "sub1 = fig.add_subplot(1,2,2)\n",
    "sub2 = fig.add_subplot(1,2,1)\n",
    "my_font_size = 15\n",
    "half_frame(sub1, \"GPA\", \"Cumulative probability\", font_size = my_font_size)\n",
    "half_frame(sub2, \"GPA\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "# \n",
    "# Cumulative\n",
    "#\n",
    "sub1.plot(gpa, cumulative, \"go\", label= \"Data\")\n",
    "sub1.set_xlim([2.5, 4.2])\n",
    "\n",
    "## Gaussian null model: Use the sample's mean and st_dev \n",
    "mu = np.mean(gpa)\n",
    "sigma = np.std(gpa)\n",
    "print('Sample mean: {0:6.3f}\\nSample std. dev: {1:6.3f}'.format(mu, sigma))\n",
    "\n",
    "x3 = np.linspace(stat.norm.ppf(0.0001, loc = mu, scale = sigma), \n",
    "                 4., \n",
    "                 100)\n",
    "sub1.plot(x3, stat.norm.cdf(x3, mu, sigma), color = \"b\", lw = 2, label= \"Gaussian\") \n",
    "\n",
    "## Fitted model\n",
    "print('Fitted mu: {0:6.3f}\\nFitted sigma: {1:6.3f}'.format(mu_model, sig_model))\n",
    "sub1.plot(x3, stat.truncnorm.cdf(x3, a_model, b_model, loc = mu_model, scale = sig_model), \n",
    "          color = \"orange\", lw = 2, label= \"Truncated Gaussian\") \n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "#\n",
    "# Density\n",
    "#\n",
    "sub2.hist(gpa, 20, normed = 1, rwidth = 0.75, color = \"g\", alpha = 0.5, histtype = \"bar\", \n",
    "          label = \"Data\", cumulative = False) \n",
    "\n",
    "sub2.plot(x3, stat.norm.pdf(x3, mu_model, sig_model), color = \"b\", lw = 2, label= \"Gaussian\") \n",
    "\n",
    "sub2.plot(x3, stat.truncnorm.pdf(x3, a_model, b_model, loc = mu_model, scale = sig_model), \n",
    "          color = \"orange\", lw = 2, label= \"Gaussian\") \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These fits look really good. However, they do not tell us whether they provide an adequate representation of the data.  To answer that question we need to determine whether the data is statistically compatible with distributions generated using the truncated Gaussian distribution with the fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test 1 sample\n",
    "\n",
    "popmean = stat.truncnorm.stats(a_model, b_model, mu_model, sig_model, moments = 'm')\n",
    "t_data, p = stat.ttest_1samp(gpa, popmean)\n",
    "print('t-test 1 sample for model: \\tt = {0:6.6f} \\tp = {1:6.6f}'.format(t_data, p))\n",
    "\n",
    "# KS test\n",
    "D_data, p = stat.kstest(gpa, stat.truncnorm.cdf, args = (a_model, b_model, mu_model, sig_model))\n",
    "print('KS 1 sample test for model: \\tD = {0:6.6f} \\tp = {1:6.6f}'.format(D_data, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful. Our null hypthesis passed with flying colors!  But did it?\n",
    "\n",
    "Was what we did even correct?\n",
    "\n",
    "Let us explore this with a simple computational experiment.  We will generate a number of synthetic data sets drawn from the fitted truncated Gaussian and what these statistical test tell us when we do the test against the generated parameter values vs when we perform a fit to estimate the parameter values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data set and make fit\n",
    "\n",
    "print('Input mu: {0:6.3f}\\nInput sigma: {1:6.3f}'.format(mu_model, sig_model))\n",
    "print()\n",
    "\n",
    "xv = stat.truncnorm.rvs(a_model, b_model, loc = mu_model, scale = sig_model, size = len(gpa))\n",
    "xv.sort()\n",
    "cumulative = []\n",
    "for i, value in enumerate(xv):\n",
    "        cumulative.append((i+1) / len(xv))\n",
    "\n",
    "popt, pcov = curve_fit(truncated_normal, xv, cumulative, p0 = [3.7, 0.3])\n",
    "\n",
    "mu_fit = popt[0]\n",
    "sig_fit = popt[1]\n",
    "a_fit = -100\n",
    "b_fit = (4.0 - mu_fit) / sig_fit\n",
    "print('Fitted mu: {0:6.3f}\\nFitted sigma: {1:6.3f}'.format(mu_fit, sig_fit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test 1 sample\n",
    "\n",
    "popmean = stat.truncnorm.stats(a_model, b_model, mu_model, sig_model, moments = 'm')\n",
    "t, p = stat.ttest_1samp(xv, popmean)\n",
    "print('t-test 1 sample for model: \\tt = {0:6.6f} \\tp = {1:6.6f}'.format(t, p))\n",
    "popmean = stat.truncnorm.stats(a_fit, b_fit, mu_fit, sig_fit, moments = 'm')\n",
    "t, p = stat.ttest_1samp(xv, popmean)\n",
    "print('t-test 1 sample for fit: \\tt = {0:6.6f} \\tp = {1:6.6f}'.format(t, p))\n",
    "\n",
    "print()\n",
    "\n",
    "# KS test\n",
    "D, p = stat.kstest(xv, stat.truncnorm.cdf, args = (a_model, b_model, mu_model, sig_model))\n",
    "print('KS 1 sample test for model: \\tD = {0:6.6f} \\tp = {1:6.6f}'.format(D, p))\n",
    "D, p = stat.kstest(xv, stat.truncnorm.cdf, args = (a_fit, b_fit, mu_fit, sig_fit))\n",
    "print('KS 1 sample test for fit: \\tD = {0:6.6f} \\tp = {1:6.6f}'.format(D, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t and D statistics systematically take lower values when compared to the fitted parameters.  That means that the `p-value` we are calculating may be an over-estimate...\n",
    "\n",
    "## Monte Carlo methods\n",
    "\n",
    "So called Monte Carlo methods, make use of computers to simulate stochastic processes. We will use such stochastic simulations now to investigate this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "N_repetitions = 1000\n",
    "D_statistic = []\n",
    "t_statistic = []\n",
    "D_statistic_fit = []\n",
    "t_statistic_fit = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(D_statistic), min(D_statistic))\n",
    "print(max(D_statistic_fit), min(D_statistic_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (6, 9) )\n",
    "my_font_size = 15\n",
    "\n",
    "sub1 = fig.add_subplot(2,1,1)\n",
    "sub2 = fig.add_subplot(2,1,2)\n",
    "\n",
    "half_frame(sub1, \"t statistic\", \"Probability density\", font_size = my_font_size)\n",
    "half_frame(sub2, \"D statistic\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "sub1.hist([t_statistic, t_statistic_fit], bins = 21, normed = 1, color = ['r', 'cyan'], histtype = 'bar',\n",
    "         label = ['To model', 'To fit'], cumulative = False)\n",
    "\n",
    "sub2.hist([D_statistic, D_statistic_fit], bins = 10, normed = 1, color = ['r', 'cyan'], histtype = 'bar',\n",
    "         cumulative = False)\n",
    "\n",
    "popt, pcov = curve_fit(truncated_normal, xv, cumulative, p0 = [3.7, 0.3])\n",
    "\n",
    "mu_fit = popt[0]\n",
    "sig_fit = popt[1]\n",
    "a_fit = -100\n",
    "b_fit = (4.0 - mu_fit) / sig_fit\n",
    "\n",
    "#\n",
    "# Plot Student's t distribution for validation\n",
    "#\n",
    "xt = np.linspace(-3, 3, 50)\n",
    "df = len(gpa) - 1\n",
    "sub1.plot(xt, stat.t.pdf(xt, df), lw = 3)\n",
    "sub1.vlines(t_data, 0, 1.4, lw = 3, color = 'darkblue')\n",
    "\n",
    "#\n",
    "# Plot KS distribution for validation\n",
    "#\n",
    "xD = np.linspace(0, 0.15, 50)\n",
    "sub2.plot(xD, stat.ksone.pdf(xD, len(gpa)), lw = 3)\n",
    "sub2.vlines(D_data, 0, 60, lw = 3, color = 'darkblue')\n",
    "\n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots make it clear that we still cannot reject the null hypothesis when we do things correctly.  However, they also demonstrate that the thoughtless use of the standard statistical tests could have led us to the wrong conclusion in other situations."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
