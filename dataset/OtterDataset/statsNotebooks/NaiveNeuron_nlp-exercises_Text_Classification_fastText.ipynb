{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_fastText.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG3Y3QNaklub"
      },
      "source": [
        "# Text Classification with fastText\n",
        "\n",
        "This quick tutorial introduces the task of text classification using the [fastText](https://fasttext.cc/) library and tries to show what the full pipeline looks like from the beginning (obtaining the dataset and preparing the train/valid split) to the end (predicting labels for unseen input data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DdFjtLj1qis"
      },
      "source": [
        "## The Cooking StackExchange tags dataset\n",
        "\n",
        "We'll use a dataset of a few thousand questions asked on [Cooking StackExchange](https://cooking.stackexchange.com/) which have various tags assigned to them and which already exists in the fastText format -- basically a text file where each line contains one text document that is to be classified. Note that the lines start with `__label__` tags which denote the \"ground truth\" label for that particular text document.\n",
        "\n",
        "\n",
        "`__label__<X> __label__<Y> ... <Text>`\n",
        "\n",
        "\n",
        "For example:\n",
        "\n",
        "`__label__chocolate American equivalent for British chocolate terms`\n",
        "\n",
        "--------------------------\n",
        "\n",
        "In the next few cells we'll download the dataset and take a closer look at what the data looks like (using the [`head`](https://linux.101hacks.com/unix/head/) command) and some further statistics about the dataset (using the [`wc`](https://www.tecmint.com/wc-command-examples/) -- command).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODjsAxt1ono"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FmlmQB42tfL"
      },
      "source": [
        "!head cooking.stackexchange.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyPeaPL03bTw"
      },
      "source": [
        "!wc cooking.stackexchange.txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IWotaq83op6"
      },
      "source": [
        "We've got roughly 15k samples in our dataset. Let's split it into a training set of roughly 12k samples and testing set of 3k samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR_Yj97c3fD3"
      },
      "source": [
        "!head -n 12404 cooking.stackexchange.txt > cooking.train\n",
        "!tail -n 3000 cooking.stackexchange.txt > cooking.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4QTcoLc4U1E"
      },
      "source": [
        "## Installation of fastText\n",
        "\n",
        "Installing fastText is realtively easy on any Unix-like system -- running the following cell should be enough to build the `fasttext` binary, which is all we need in this tutorial. \n",
        "\n",
        "Note that fastText also has [Python bindings](https://pypi.org/project/fasttext/) which allow you to use it directly from Python code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFTFf8_C4SVp"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!make\n",
        "!cp fasttext ../\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMM0RoLK6BBM"
      },
      "source": [
        "## Training and testing a fastText model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMi85o9H858P"
      },
      "source": [
        "The actual model fastText implements is rather simple as we can see in the image below -- the negative log-likelihood the model tries to minimize in training is \n",
        "\n",
        "$$ - \\frac{1}{N} \\sum_{n=1}^{N} y_n \\log(f(BAd_n)) $$\n",
        "\n",
        "where \n",
        "- $d_n$ is the representation of the $n$-th document (denoted `hidden` in the image below)\n",
        "- $A$ is the \"document\" embedding matrix \n",
        "- $B$ is the linear projection from \"document\" embeddings to output classes\n",
        "- $f$ is the `softmax` non-linearity function\n",
        "- $y_n$ is the label of the $n$-th document\n",
        "\n",
        "You can find more details on the model in section 2 the introductory paper: [Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759). \n",
        "\n",
        "Note that the document representation $d_n$ (again, denoted `hidden` in the image below) is computed as the average of the embedding of all document features: words, word ngrams or character ngrams -- more on that later.\n",
        "\n",
        "\n",
        "![The actual model architecture of fastText classification](https://cdn-images-1.medium.com/max/800/1*AgrrRZ9DpUVb3srTWs0gzA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr70hgu38eCY"
      },
      "source": [
        "In the following cell we run the `supervised` command which trains a fastText model using the data in `./cooking.train` and saves the model to `./cooking_model1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhi9ln0x4ues"
      },
      "source": [
        "!./fasttext supervised -input ./cooking.train -output ./cooking_model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjF9yEkc-XOw"
      },
      "source": [
        "Now let's see how the model does on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xEv2S4846Ky"
      },
      "source": [
        "!./fasttext test cooking_model1.bin ./cooking.valid 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T6yt2RR62rH"
      },
      "source": [
        "Looking at the results, they do not look very stellar, as both the $P@3$ and $R@3$ can be values from 0 to 1. But what do those $P@3$ and $R@3$ actually represent?\n",
        "\n",
        "The short answer is that they are the average [precision](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) and [recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall) averaged over all test examples. Plus, the $@3$ tell us that we only consider the top 3 most probable labels predicted by the system. \n",
        "\n",
        "That probably did not help too much, so let's try to illustrate what that would mean using the following example:\n",
        "\n",
        "`__label__storage-method __label__equipment __label__bread __label__food-safety What's the purpose of a bread box?`\n",
        "\n",
        "As we can see, our data shows that for \"*What's the purpose of a bread box?*\" the model is supposed to predict the following labels with high probability: \n",
        "\n",
        "- `storage-method`\n",
        "- `equipment`\n",
        "- `bread`\n",
        "- `food-safety`\n",
        "\n",
        "Suppose, however, that our model predicts the following labels as the top 3 most probable:\n",
        "\n",
        "- `bread`\n",
        "- `equipment`\n",
        "- `box`\n",
        "\n",
        "Since two labels (`bread` and `equipment`) out of three were found in the top 3 most probable predictions of the model, the $P@3$ in this particular example would be $P@3 = \\frac{2}{3} = 0.66 $. We can interpret that as the model *precisely predicting* $\\frac{2}{3}$ of the top 3 predictions it provided.\n",
        "\n",
        "Furthermore, since two labels (again `bread` and `equipment`) out of all 4 that were denoted in the data as correct (or relevant) could be found in the top 3 most probable predictions of the model, the $R@3$ would be $R@3 = \\frac{2}{4} = 0.5 $. That in turn can be interpreted as the model being able to *recall* $\\frac{2}{4}$ of the correct (or relevant) labels in its top 3 most probable predictions.\n",
        "\n",
        "As we can see, the reported performance and recall of our models will strongly depend on how many of the top most probable predictions should be considered. Also, we need to consider our final use case when deciding which of these to optimize for -- in the Cooking StackExchange example we may be more interested in recall than in precision.\n",
        "\n",
        "--------------------------------\n",
        "\n",
        "Armed with this understanding of the metrics we can try to improve, let's see what options does fastText allow us to set and see if we can get the model to perform better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKko9217kBR"
      },
      "source": [
        "!./fasttext supervised"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g1jFzxw__WR"
      },
      "source": [
        "There are a couple of interesting options we'll dive a bit deeper into:\n",
        "\n",
        "#### Character ngrams (`minx` and `maxn`)\n",
        "\n",
        "One of the interesting things fastText is capable of doing is incorporating character level information when preparing word vectors. You can find all the glory details in the [Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606) paper, but the basic idea is as follows:\n",
        "\n",
        "Given the word `banana` and $n=3$, fastText would generate the following ngrams:\n",
        "\n",
        "- `<ba`\n",
        "- `ban`\n",
        "- `ana`\n",
        "- `nan`\n",
        "- `ana`\n",
        "- `na>`\n",
        "\n",
        "where the `<` and `>` represent the beginning and end of the word, respectively. That is quite useful because if we also had the word *ban* as part of the vocabulary, it would be represented as `<ban>` which makes it distinguishable from `ban` we extracted from banana.\n",
        "\n",
        "Note that we are still talking about bag of words model and thus only the presence of a respective ngram matters. Still, thanks to this nice setup we are pretty much by default able to model prefixes and suffixes. That is of huge practical value, since even if we now encountered say the word `bananoid`  which was not present in training data, thanks to the aforementioned character ngrams we are able to assign it at least some representation, rather than calling it an unknown word and replacing its occurences with `UNK`, which is what the standard approach would be.\n",
        "\n",
        "In fastText the length of ngrams can be set via the `-minn` and `-maxn` flags, which control the minimum and maximum length of ngrams fastText considers. By default these are set to 0, which basically turns this feature off.\n",
        "\n",
        "Let's see if our `bananoid` example would actually work by saving the word vectors fastText produces during training and trying to find out which words are the closest neighbors of `bananoid` in the learned vector space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkFo6EpeDKr"
      },
      "source": [
        "!./fasttext supervised -minn 3 -maxn 5 -input ./cooking.train -output ./cooking_model1 -saveOutput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw6DBJi4eGhc"
      },
      "source": [
        "!echo \"bananoid\" | ./fasttext nn ./cooking_model1.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR4-fH5GORH0"
      },
      "source": [
        "Although it is obvious that our training data leave a lot to be desired, seeing `bananoid` close to `bananas`, `bananas?` and `banana?` seems to suggest that the ngrams do indeed have the potential to help with out of vocabulary words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFrjqHMZdPhi"
      },
      "source": [
        "#### Word ngrams\n",
        "\n",
        "Similarly to character ngrams, fastText can also generate ngrams from words in the document. This can be set using the `-wordNgrams` flag which is set to 1 by default: only unigrams (single words) are considered. When we set it to say 2, the sentece `smash all potatoes` would be represented as\n",
        "\n",
        "- `<smash>`\n",
        "- `<all>`\n",
        "- `<potatoes>`\n",
        "- `<smash all>`\n",
        "- `<all potatoes`\n",
        "\n",
        "-----------------\n",
        "\n",
        "Using these and some of the other available options, let us train a new version of the model and see how it performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFF_zi5a6P9_"
      },
      "source": [
        "!./fasttext supervised -minCount 2 -wordNgrams 3 -minn 3 -maxn 8 -lr 0.7 -dim 100 -epoch 25 -input ./cooking.train -output cooking_model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-nbgTW14YR"
      },
      "source": [
        "!ls -alh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bSihncU6dm8"
      },
      "source": [
        "!./fasttext test cooking_model2.bin ./cooking.valid 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bzAvHmafXvd"
      },
      "source": [
        "Looks a bit better, right?\n",
        "\n",
        "Still, looking at just the summary statistics is not really that much fun -- that usually comes from trying the model out on some real-world data. We can easily do that with fastText by running something like the command in the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "godG5jDhf0tE"
      },
      "source": [
        "!echo \"Does it make sense to cook smashed potatoes?\" | ./fasttext predict-prob ./cooking_model2.bin -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gIhCAvzgK3r"
      },
      "source": [
        "Alternatively we can also ask for more than just the most probable label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yl7hOlqgRLE"
      },
      "source": [
        "!echo \"Does it make sense to cook smashed potatoes?\" | ./fasttext predict-prob ./cooking_model2.bin - 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2j07FbWgh0N"
      },
      "source": [
        "Or ask for as many predictions as possible (`-1`) but only taking into account those that have probability higher than `0.02`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0NdM7SqgexL"
      },
      "source": [
        "!echo \"Does it make sense to cook smashed potatoes?\" | ./fasttext predict-prob ./cooking_model2.bin - -1 0.02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6GEl-hx_Hw6"
      },
      "source": [
        "## Your tasks\n",
        "\n",
        "1. See if you can improve the model further -- try to optimize both Precision and Recall at 3 predictions. If you won't be able to take it anymore, feel free to use the [`autotune`](https://fasttext.cc/docs/en/autotune.html) capability of the new version of fastText we are using.\n",
        "\n",
        "2. Try to see if some pre-processing (lowercasing, removing stop words, punctuation, ...) would be helpful here (the `bananoid` example does really suggest so). Note that fastText splits tokens on whitespace it finds in the input data, so it is not uncommon to find out that it learned word vectors for words like `banana?` among others. If you are looking for an industry-grade tokenizer, take a look at [BlingFire](https://github.com/Microsoft/BlingFire).\n",
        "\n",
        "3. See if you can use some of the same ideas on a different _Amazon Sentiment Analysis dataset_ ([train](https://storage.googleapis.com/amazonreviews/train.ft.txt.bz2), [test](https://storage.googleapis.com/amazonreviews/test.ft.txt.bz2) splits) and get the testing precision/recall over 0.95! Note that since you'll only have two classes, looking at $P@3$ and $R@3$ does not make too much sense. Thus, it would be advisable to use the following command to test your model on the validation split: `!./fasttext test-label model.bin ./data.valid`. It will (among other things) print out the metrics per each class, which is very useful in binary classification.\n",
        "\n",
        "**Bonus**: the choice of checking both Precision and Recall at 3 is rather arbitrary. Analyze the training data and find out what number would really make sense, based on the number of labels the considered documents usually have.\n",
        "\n",
        "**Bonus 2**: the resulting model is rather large -- looking at `!ls -alh` shows that the first model we trained is over 1.5GB in size. That may be a bit too much for practical usage, and so we usually end up using a process called \"quantization\" to make it a bit smaller. Try to follow the [quantization autotuning docs](https://fasttext.cc/docs/en/autotune.html#constrain-model-size) and see how much can you decrease the size of your best model while still keeping its accuracy.  _Note: FastText's quanization approach is described in the [FastText.zip: Compressing text classification models](https://arxiv.org/pdf/1612.03651) -- it's pretty nice and I encourage you to give it a read!_\n",
        "\n",
        "\n",
        "For a more in-depth walkthrough of fastText's internals please reffer to [FastText: Under the Hood](https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3)"
      ]
    }
  ]
}