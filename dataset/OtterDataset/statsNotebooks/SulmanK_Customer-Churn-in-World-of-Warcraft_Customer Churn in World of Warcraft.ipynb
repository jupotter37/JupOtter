{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WoW Logo](assets/World_of_Warcraft_logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* Complete Exploratory Data Analysis.\n",
    "* Complete Survival Analysis.\n",
    "* Predict if a user will churn in a six-month period using classification algorithms.\n",
    "\n",
    "## Background Information\n",
    "* World of Warcraft is a massively multiplayer online video game released on November 23, 2004. Before this era, MMORPG’s catered to a small segment of video gamers. But with the massive success of WoW, various video game companies decided to invest resources into developing large-scale titles. Video games were sought out as movie-like experiences, where you follow a single protagonist. However, WoW did not follow a single protagonist, but all the users playing the video game. Not only was the main objective different from single-player games, but the pricing model. Traditional games followed a single upfront fee. In addition to the single upfront fee, WoW had a monthly subscription to play the game. With customer subscriptions in mind, we can apply the use of churn prediction to not only predict whether a customer will unsubscribe from the service but explore the user’s playing behavior to obtain more insight into user playing patterns. The churn problem is somewhat complex due to the nature of not having a one size fits all solution – as different services define churn in a variety of ways.\n",
    "\n",
    "## Process:\n",
    "* Exploratory Data Analysis conducted utilizing various python packages (Numpy, Matplotlib, Pandas, and Plotly).'\n",
    "* Survival Analysis (Lifelines)\n",
    "    * Kaplan Meier Estimator\n",
    "* Binary Classification Algorithms (Sci-Kit Learn)\n",
    "    * Logistic Regression\n",
    "    * Support Vector Machines\n",
    "    * K-nearest neighbors\n",
    "    * Random Forests\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents:\n",
    "* Part I: Exploratory Data Analysis\n",
    "    * EDA\n",
    "* Part II: Churn Prediction\n",
    "    * Survival Analysis\n",
    "    * Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.plotting import rmst_plot\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by reading in the CSV file containing the data, and examining the data contents such as the number of features and the number of samples. It seems there are 7 column entries (features) and 10826734 row entries (number of samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10826734 entries, 0 to 10826733\n",
      "Data columns (total 7 columns):\n",
      "char          int64\n",
      " level        int64\n",
      " race         object\n",
      " charclass    object\n",
      " zone         object\n",
      " guild        int64\n",
      " timestamp    object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 578.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>level</th>\n",
       "      <th>race</th>\n",
       "      <th>charclass</th>\n",
       "      <th>zone</th>\n",
       "      <th>guild</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59425</td>\n",
       "      <td>1</td>\n",
       "      <td>Orc</td>\n",
       "      <td>Rogue</td>\n",
       "      <td>Orgrimmar</td>\n",
       "      <td>165</td>\n",
       "      <td>01/01/08 00:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>65494</td>\n",
       "      <td>9</td>\n",
       "      <td>Orc</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>Durotar</td>\n",
       "      <td>-1</td>\n",
       "      <td>01/01/08 00:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>65325</td>\n",
       "      <td>14</td>\n",
       "      <td>Orc</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>Ghostlands</td>\n",
       "      <td>-1</td>\n",
       "      <td>01/01/08 00:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>65490</td>\n",
       "      <td>18</td>\n",
       "      <td>Orc</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>Ghostlands</td>\n",
       "      <td>-1</td>\n",
       "      <td>01/01/08 00:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2288</td>\n",
       "      <td>60</td>\n",
       "      <td>Orc</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>Hellfire Peninsula</td>\n",
       "      <td>-1</td>\n",
       "      <td>01/01/08 00:02:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    char   level  race  charclass                zone   guild  \\\n",
       "0  59425       1   Orc      Rogue           Orgrimmar     165   \n",
       "1  65494       9   Orc     Hunter             Durotar      -1   \n",
       "2  65325      14   Orc    Warrior          Ghostlands      -1   \n",
       "3  65490      18   Orc     Hunter          Ghostlands      -1   \n",
       "4   2288      60   Orc     Hunter  Hellfire Peninsula      -1   \n",
       "\n",
       "           timestamp  \n",
       "0  01/01/08 00:02:04  \n",
       "1  01/01/08 00:02:04  \n",
       "2  01/01/08 00:02:04  \n",
       "3  01/01/08 00:02:04  \n",
       "4  01/01/08 00:02:09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------- Pandas Dataframe\n",
    "## Read in CSV\n",
    "avatar_history = pd.read_csv('data/wowah_data.csv')\n",
    "\n",
    "## Examine data contents\n",
    "avatar_history.info()\n",
    "avatar_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* char = the character id\n",
    "* level = level of the character\n",
    "* race = race of the character\n",
    "* charclass = class of the character\n",
    "* zone = location at which the character is\n",
    "* guild = guild id of the character\n",
    "* timestamp = date and time at which the entry took place\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted whitespace in column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['char', 'level', 'race', 'charclass', 'zone', 'guild', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip whitespace in feature names\n",
    "avatar_history.rename(columns = lambda x: x.strip(), inplace = True)\n",
    "avatar_history.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the date from the time from the timestamp feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_transform(x):\n",
    "    \"Function to split the date and time\"\n",
    "    y = x.split()[0]\n",
    "    return y[:-2] + '20' + y[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new features date and time using the function above\n",
    "avatar_history['date'] = avatar_history['timestamp'].apply(time_transform)\n",
    "avatar_history['time'] = avatar_history['timestamp'].apply(lambda x: x.split()[1][:-4] + '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamps feature was converted into a DateTime object, allowing us to extract the month, day, and time of each entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime features \n",
    "avatar_history['timestamp'] = pd.to_datetime(avatar_history['timestamp'])\n",
    "avatar_history['Month'] = avatar_history['timestamp'].dt.month\n",
    "avatar_history['Day'] = avatar_history['timestamp'].dt.dayofyear\n",
    "avatar_history['Weekday'] = avatar_history['timestamp'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique entries for each feature is organized in Table 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of feature description\n",
    "## Find the number of unique entries for each feature\n",
    "number_of_characters = avatar_history['char'].nunique()\n",
    "number_of_levels = avatar_history['level'].nunique()\n",
    "number_of_races = avatar_history['race'].nunique()\n",
    "number_of_classes = avatar_history['charclass'].nunique()\n",
    "number_of_zones = avatar_history['zone'].nunique()\n",
    "number_of_guilds = avatar_history['guild'].nunique()\n",
    "number_of_timestamps = avatar_history['timestamp'].nunique()\n",
    "\n",
    "## Append and print the unique entries for each feature\n",
    "data = []\n",
    "for x in avatar_history.columns:\n",
    "    print(\"The number of unique \" + str(x) + \" is \" + str(avatar_history[x].nunique()) + \".\")\n",
    "    data.append(avatar_history[x].nunique())\n",
    "\n",
    "## Create table using plotly \n",
    "### Create an array and transpose values to make it a two-column format\n",
    "data = np.array(data)\n",
    "data = data.transpose()\n",
    "\n",
    "### Create plotly table object\n",
    "feature_information = go.Figure(data = [go.Table(\n",
    "    header = dict(values = ['Unique Characters', 'Unique Levels',\n",
    "                            'Unique Races', 'Unique Classes',\n",
    "                            'Unique Zones', 'Unique Guilds',\n",
    "                            'Unique Timestamps'],\n",
    "                  line_color = 'darkslategray',\n",
    "                  fill_color = 'lightskyblue',\n",
    "                  align = 'left'),\n",
    "    cells = dict(values = data,\n",
    "                 line_color = 'darkslategray',\n",
    "                 fill_color = 'lightcyan',\n",
    "                 align = 'left'))\n",
    "])\n",
    "\n",
    "feature_information.update_layout(width = 800, height = 300, title = 'Table 1: Feature description')\n",
    "feature_information.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most players are level 1 with 11598 out of 37354 character entries. This can be explained by the use of alternate characters, which are used as mules in major towns to sell and trade items between others. Also, with such a right-skewed distribution it may be informative for game developers to put more effort into the level 1 – 30 zones. There appears to be a steady decrease from 1 to 60 until 70, which was the max level before the WOTLK expansion. Finally, a peak at 80, which is the latest max level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the Distribution of Levels\n",
    "## Create data segment - get the latest snapshot of levels\n",
    "level_dist = avatar_history.groupby('char')['level'].max()\n",
    "\n",
    "## Figure parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3})\n",
    "\n",
    "ax = sns.distplot(level_dist, kde_kws = {\"color\": \"green\", \"lw\": 4, \"label\": \"KDE\"},\n",
    "                  hist_kws = {\"linewidth\": 6,\n",
    "                              \"alpha\": 1, \"color\": \"pink\",\n",
    "                              'label': 'Histogram'})\n",
    "\n",
    "plt.xlabel('Levels', fontsize = 24)\n",
    "plt.ylabel('Frequency', fontsize = 24)\n",
    "plt.title('Distribution of Levels', fontsize = 24)\n",
    "number_of_ticks = [1, 10, 20, 30, 40, 50, 60, 70, 80]\n",
    "plt.xticks(number_of_ticks, fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "## Add annotations for statistics\n",
    "plt.text(80, 0.175, 'Min: ' + str(round(level_dist.value_counts().min(),1)) , size = 18, color = 'black')\n",
    "plt.text(80, 0.185, 'Mean: ' + str(round(level_dist.value_counts().mean(),1)) , size = 18, color = 'black')\n",
    "plt.text(80, 0.195, 'Max: ' + str(round(level_dist.value_counts().max(),1)) , size = 18, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureDistribution_DF(feature):\n",
    "    \"\"\"Acquires a sorted dataframe of a selected featue which is categorized by char ID\"\"\"\n",
    "    feature_dist = avatar_history.groupby('char')[feature].max().value_counts()\n",
    "    sorted_feature_dist = pd.DataFrame(feature_dist)\n",
    "    sorted_feature_dist.columns = ['Count']\n",
    "    sorted_feature_dist.index.names = [feature]\n",
    "    return sorted_feature_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zones which occupy WoW are not for individual levels but comprises level intervals. The top three level intervals are 0-9, 10 – 19, and 70-79. Such that having insight into how the population is divided in these intervals, further supports our initial reasoning to provide more development time in these early-level zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the level intervals \n",
    "## Discretize the levels into intervals\n",
    "bins = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80])\n",
    "\n",
    "## Apply the bins and create a new feature level_intervals\n",
    "avatar_history['level_interval'] = np.digitize(avatar_history['level'],bins)\n",
    "\n",
    "mapped_levels = {1: '0-9', 2: '10-19',\n",
    "     3: '20-29', 4: '30-39',\n",
    "     5: '40-49', 6: '50-59',\n",
    "     7: '60-69', 8: '70-79',\n",
    "     9: '80'}\n",
    "\n",
    "avatar_history['level_interval'] = avatar_history['level_interval'].map(mapped_levels)\n",
    "\n",
    "## Create a sorted dataframe of the level_interval feature\n",
    "sorted_level_interval_dist = featureDistribution_DF('level_interval')\n",
    "\n",
    "## Plot parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\n",
    "\n",
    "ax = sns.barplot(x = sorted_level_interval_dist['Count'],\n",
    "                 y = sorted_level_interval_dist.index, \n",
    "                 edgecolor = 'pink')\n",
    "\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Level Ranges', fontsize = 24)\n",
    "plt.title('Distribution of Level Ranges', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\n",
    "color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When players create their characters, they have a choice in selecting the race and class. Having data on their selections provides developers with insight to properly manage what classes should be monitored more and helps the game balance team to decide on why these certain classes or races are picked – Are they strong, weak, or people enjoy the themes of the classes. Should we spend more time on their race-specific starting zones due to their selection? The player base selects Blood Elves, Warriors, and Orc Warriors, as their popular choices in races, classes, and race-class combinations, respectively.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the race distribution\n",
    "sorted_race_dist = featureDistribution_DF('race')\n",
    "\n",
    "## Plot parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "textprops = dict(size = 22 )\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ffb3cc']\n",
    "\n",
    "plt.pie(sorted_race_dist['Count'], labels = sorted_race_dist.index,\n",
    "        autopct = '%1.1f%%', startangle = 90, textprops = textprops, colors = colors)\n",
    "\n",
    "plt.title('Distribution of Races', fontsize = 24)\n",
    "plt.axis('equal') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class distribution\n",
    "sorted_class_dist = featureDistribution_DF('charclass')\n",
    "\n",
    "## Plot Parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\n",
    "ax = sns.barplot( x = sorted_class_dist['Count'],\n",
    "                  y = sorted_class_dist.index, edgecolor = 'pink')\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Classes', fontsize = 24)\n",
    "plt.title('Distribution of Classes', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\n",
    "color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race + Class Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the popular class / race combinations\n",
    "## Create dataframes for the race and class combinations\n",
    "race_class_dist = avatar_history.groupby('char')['race', 'charclass'].max()\n",
    "tmp_df = pd.DataFrame(race_class_dist)\n",
    "tmp_df.columns = ['Race', 'Class']\n",
    "tmp_df.index.names = ['charID']\n",
    "\n",
    "race_class_df = pd.DataFrame(tmp_df['Class'].values.astype(str),\n",
    "             tmp_df['Race'].values.astype(str), columns = ['Class'])\n",
    "\n",
    "race_class_df.index.names = ['Race']\n",
    "\n",
    "## Apply a whitespace to combine both race and class features\n",
    "race_class_df['Class']= race_class_df['Class'].apply(lambda x: \"{}{}\".format(' ', x))\n",
    "\n",
    "## Create the new race+class feature\n",
    "race_class_df['race+class'] = race_class_df.index.str.cat(race_class_df.values)\n",
    "\n",
    "## Sort by frequency \n",
    "ah_pop = race_class_df.assign(freq = race_class_df.groupby('race+class')['race+class'].transform('count'))\\\n",
    "  .sort_values(by = ['freq','race+class'],ascending = [False,True]).loc[:,['race+class']]\n",
    "\n",
    "## Plot parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3}, palette = 'bright')\n",
    "ax = sns.countplot( y = ah_pop['race+class'], palette = 'bright', edgecolor = 'pink' )\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Races and Classes', fontsize = 24)\n",
    "plt.title('Distribution of Race and Class Combinations', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 14)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width(), i.get_y() + 0.9, \\\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', fontsize = 16,\n",
    "color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying population bottlenecks is important for optimizing server stability, but investigating which zones are populated is crucial in delegating resources into what aspects of the game players are enjoying. The game is divided into Player vs Environment and Player vs Player content. The top two zones are hubs where players can trade items or sign up for quests. The third is a major PvE raid dungeon where players embark on a quest to clear the opposing forces.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 Popular Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 20 popular zones\n",
    "## Sort by frequent zones\n",
    "ah_zf = avatar_history.assign(freq = avatar_history.groupby('zone')['zone'].transform('count'))\\\n",
    "  .sort_values(by = ['freq','zone'],ascending = [False , True]).loc[:,['zone']]\n",
    "\n",
    "## Create dataframe for top 20 popular zones\n",
    "zone_dist = ah_zf['zone'].value_counts()\n",
    "sorted_zone_dist = pd.DataFrame(zone_dist)\n",
    "sorted_zone_dist.columns = ['Count']\n",
    "sorted_zone_dist.index.names = ['zone']\n",
    "\n",
    "## Plot the expected variance\n",
    "plt.figure(figsize = (20, 10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 2})\n",
    "ax = sns.barplot( x = sorted_zone_dist['Count'][0:20],\n",
    "                  y = sorted_zone_dist.index[0:20], palette = 'bright', edgecolor = 'pink')\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Zones', fontsize = 24)\n",
    "plt.title('Top 20 Popular Zones', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches[0:20]:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches[0:20]:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width(), i.get_y() + 0.6, \\\n",
    "            str(round((i.get_width() / total) *100, 2)) + '%', fontsize = 16,\n",
    "color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guild Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 500 guilds created - The largest guild has a population of 1796 members, and the average guild has 73 members. Similar to the class distribution in earlier, guilds follow the same breakdown. Higher-level content requires an abundant amount of people requiring 25 or more and use guilds as a way to gather people. Not only are guilds used for completing WoW activities, but many users have it function as a social community to keep in touch with their online friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guild distribution and guild-class Distribution\n",
    "## Select entries that are in a guild\n",
    "in_a_guild = avatar_history[avatar_history['guild'] != -1]\n",
    "\n",
    "## Group playerbase by character char id, guild, and class\n",
    "tmp = in_a_guild.groupby(['char'])['guild','charclass'].max()\n",
    "\n",
    "## Find guild indices with 10 or more players\n",
    "guild_list = tmp['guild'].value_counts()[tmp['guild'].value_counts() >= 10].index\n",
    "\n",
    "## Create guild_class dataframe\n",
    "data =  {'guild_id': tmp['guild'].values ,\n",
    "         'class': tmp['charclass'].values,\n",
    "        }\n",
    "\n",
    "guild_class_df = pd.DataFrame(data)\n",
    "\n",
    "## Apply those guild_list indices to our dataframe\n",
    "guild_class_df = guild_class_df[guild_class_df['guild_id'].isin(guild_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the guild population distribution\n",
    "## Plot parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3},  palette = 'bright')\n",
    "ax = sns.distplot(guild_class_df['guild_id'], kde_kws = {\"color\": \"green\", \"lw\": 4, \"label\": \"KDE\"},\n",
    "                  hist_kws = {\"linewidth\": 6,\n",
    "                              \"alpha\": 1, \"color\": \"pink\",\n",
    "                              'label': 'Histogram'})\n",
    "\n",
    "plt.xlabel('Guild IDs', fontsize = 24)\n",
    "plt.ylabel('Frequency', fontsize = 24)\n",
    "plt.title('Guild Populations', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "# Add annotations for statistics\n",
    "plt.text(501, 0.00702,\n",
    "         'Min: ' + str(round(guild_class_df['guild_id'].value_counts().min(),1)),\n",
    "         size = 18, color = 'black')\n",
    "plt.text(501, 0.0073,\n",
    "         'Mean: ' + str(round(guild_class_df['guild_id'].value_counts().mean(),1)),\n",
    "         size = 18, color = 'black')\n",
    "plt.text(501, 0.0076,\n",
    "         'Max: ' + str(round(guild_class_df['guild_id'].value_counts().max(),1)),\n",
    "         size = 18, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class distribution in guilds\n",
    "## Plot parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 3},  palette = 'bright')\n",
    "\n",
    "ax = sns.barplot(y = ['Warrior', 'Hunter',\n",
    "                      'Rogue', 'Mage',\n",
    "                      'Warlock', 'Paladin',\n",
    "                      'Shaman', 'Priest',\n",
    "                      'Druid', 'Death Knight'],\n",
    "                 x = guild_class_df['class'].value_counts()\n",
    "                )\n",
    "\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Classes', fontsize = 24)\n",
    "plt.title('Class distribution in guilds', fontsize = 24)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width() + .3, i.get_y() + .50, \\\n",
    "            str(round((i.get_width() / total) * 100, 2)) + '%', fontsize = 16,\n",
    "color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a steady equilibrium of players between 70-79 having the highest frequency because the max level before November was 70. The max level was increased to 80 in November. Similar fluctuations are observed within the other leveling intervals between January and September, but a sharp peak in the 0-9 interval arises during October. A possible reason is the arrival of new players who are awaiting the expansion release in November.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Active Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_transform(x):\n",
    "    \"Function to split the date and time\"\n",
    "    y = x.split()[0]\n",
    "    return y[:-2] + '20' + y[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new features date and time using the function above\n",
    "avatar_history['date'] = avatar_history['timestamp'].apply(time_transform)\n",
    "avatar_history['time'] = avatar_history['timestamp'].apply(lambda x: x.split()[1][:-4] + '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily active users\n",
    "## Create pivot table to aggregate the number of users in each specific level interval.\n",
    "dau_pvt = avatar_history.pivot_table(index = 'date',\n",
    "                            columns = ['level_interval'],\n",
    "                            values = 'char',\n",
    "                            aggfunc = lambda x: x.value_counts().count()).fillna(0).astype(int)\n",
    "dau_pvt.reset_index(inplace=True)\n",
    "\n",
    "## Variables to extract all dates and account for missing dates in the pivot table\n",
    "all_dates = pd.Series(pd.date_range('01/01/08', freq = 'D', periods = 365))\n",
    "all_dates = all_dates.dt.strftime('%m/%d/%Y')\n",
    "missing_dates = list(set(all_dates) - set(dau_pvt.index.unique()))\n",
    "add_df = pd.DataFrame(columns = ['date'])\n",
    "add_df['date'] = missing_dates\n",
    "dau_pvt['date'] = pd.to_datetime(dau_pvt['date'])\n",
    "dau_pvt.sort_values(by=['date'], inplace = True)\n",
    "dau_pvt.reset_index(drop = True, inplace = True)\n",
    "dau_pvt['date'] = dau_pvt['date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "## Plotly go object to plot the graph.\n",
    "fig = go.Figure()\n",
    "\n",
    "## Set colors of curves\n",
    "colormap = ['purple', 'orange',\n",
    "            'green', 'blue',\n",
    "            'teal', 'red',\n",
    "            'black', 'pink',\n",
    "            'yellow']\n",
    "\n",
    "## Set leveling intervals of curves\n",
    "columns = [ '0-9', '10-19',\n",
    "           '20-29', '30-39',\n",
    "           '40-49', '50-59',\n",
    "           '60-69', '70-79',\n",
    "           '80']\n",
    "\n",
    "## Plot each leveling curve with a respective color\n",
    "for color, column in zip(colormap, columns):\n",
    "    fig.add_trace(go.Scatter(\n",
    "                    x = dau_pvt['date'],\n",
    "                    y = dau_pvt[column],\n",
    "                    name = column,\n",
    "                    line_color = color,\n",
    "                    hoverinfo = 'name+x+y',\n",
    "                    opacity = 0.8))\n",
    "fig.update_layout(title_text = \"Daily User Activity over one-year\", \n",
    "                 xaxis = dict(\n",
    "                     tickmode = 'array',\n",
    "                     ## Place tick labels and locations\n",
    "                     ticktext = ['Jan', 'Feb',\n",
    "                                 'Mar', 'Apr',\n",
    "                                 'May', 'Jun',\n",
    "                                 'Jul', 'Aug',\n",
    "                                 'Sep', 'Oct',\n",
    "                                 'Nov', 'Dec'],\n",
    "                     \n",
    "                     tickvals = [1, 31,\n",
    "                                 60, 91,\n",
    "                                 121, 152,\n",
    "                                 182, 213,\n",
    "                                 244, 274,\n",
    "                                 304, 335]\n",
    "                 ),\n",
    "                  xaxis_rangeslider_visible = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Active Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot monthly active users\n",
    "## Create pivot table to aggregate the number of users in each specific level interval.\n",
    "mau_pvt = avatar_history.pivot_table(index = 'date',\n",
    "                            columns = ['level_interval'],\n",
    "                            values = 'char',\n",
    "                            aggfunc = lambda x: x.value_counts().count()).fillna(0).astype(int)\n",
    "\n",
    "mau_pvt.reset_index(inplace = True)\n",
    "\n",
    "## Variables to extract all dates and account for missing dates in the pivot table\n",
    "all_dates = pd.Series(pd.date_range('01/01/08', freq = 'D', periods = 365))\n",
    "all_dates = all_dates.dt.strftime('%m/%d/%Y')\n",
    "missing_dates = list(set(all_dates) - set(mau_pvt.index.unique()))\n",
    "add_df = pd.DataFrame(columns=['date'])\n",
    "add_df['date'] = missing_dates\n",
    "mau_pvt['date'] = pd.to_datetime(mau_pvt['date'])\n",
    "mau_pvt.sort_values(by = ['date'], inplace = True)\n",
    "mau_pvt.reset_index(drop = True, inplace = True)\n",
    "mau_pvt['date'] = mau_pvt['date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "## Map the months\n",
    "mau_pvt['date'] = (pd.to_datetime(mau_pvt['date']))\n",
    "\n",
    "d = {1: 'January', 2: 'February',\n",
    "     3: 'March', 4: 'April',\n",
    "     5: 'May', 6: 'June',\n",
    "     7: 'July', 8: 'August',\n",
    "     9: 'September', 10: 'October',\n",
    "     11: 'November', 12: 'December'}\n",
    "\n",
    "## Create the months dataframe for MAU\n",
    "mau_pvt['Month'] = mau_pvt['date'].dt.month.map(d)\n",
    "\n",
    "## Create label list for months\n",
    "yourlabels_list = [ 'January', 'February',\n",
    "                   'March',  'April',\n",
    "                   'May', 'June',\n",
    "                   'July',  'August',\n",
    "                   'September',  'October',\n",
    "                   'November',  'December']\n",
    "\n",
    "sum_months = mau_pvt.groupby('Month').sum()\n",
    "sorted_sum_month = pd.DataFrame(sum_months)\n",
    "\n",
    "sorted_sum_month.columns = [ '0-9', '10-19',\n",
    "                            '20-29', '30-39',\n",
    "                            '40-49', '50-59',\n",
    "                            '60-69',  '70-79',\n",
    "                            '80']\n",
    "\n",
    "sorted_sum_month.index.names = ['Month']\n",
    "sorted_sum_month = sorted_sum_month.reindex(yourlabels_list)\n",
    "\n",
    "## Plotly go object to plot the graph.\n",
    "fig = go.Figure()\n",
    "\n",
    "## Set colors for each curve\n",
    "colormap = ['purple', 'orange',\n",
    "            'green', 'blue',\n",
    "            'teal', 'red',\n",
    "            'black', 'pink',\n",
    "            'yellow']\n",
    "\n",
    "## Set leveling intervals of curves\n",
    "columns = [ '0-9', '10-19',\n",
    "           '20-29', '30-39',\n",
    "           '40-49', '50-59',\n",
    "           '60-69', '70-79',\n",
    "           '80']\n",
    "\n",
    "## Plot each leveling curve with a respective color\n",
    "for color, column in zip(colormap, columns):\n",
    "    fig.add_trace(go.Scatter(\n",
    "                    x = sorted_sum_month.index,\n",
    "                    y = sorted_sum_month[column],\n",
    "                    name = column,\n",
    "                    line_color = color,\n",
    "                    hoverinfo = 'name+x+y',\n",
    "                    opacity = 0.8))\n",
    "fig.update_layout(title_text = \"Monthly User Activity over one-year\", \n",
    "                 xaxis = dict(\n",
    "                     tickmode = 'array',              \n",
    "                     \n",
    "                 ),\n",
    "                  xaxis_rangeslider_visible = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observing the HAU, there is a steady decrease until 7:00 am and then elevates during the afternoon because teenagers arrive from school. Then, a steady increase in the evening from 5:00 pm until 12:00 pm because adults arrive from work. The highest frequency of users is during the evening hours. The average user plays for 1 hour daily, and the 95% percentile of players play for 4 hours daily. Having this knowledge allows us to properly address times in which the servers need to be taken down for maintenance, and how to pace future content updates for the average user’s playtime - do not want to release content which the average user cannot finish. Most users are recorded playing on Sunday, and the other days of the week are in similar in frequency. We’d expect most players to play on the weekend to account for not having work obligations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot hourly user activity\n",
    "## Create daily session dataframes\n",
    "tmp = avatar_history.groupby(by = ['date', 'time'])['char'].nunique().to_frame('char').reset_index()\n",
    "day_activity_mean = round(tmp.groupby(['time'], as_index = False)['char'].mean())\n",
    "day_activity_max = round(tmp.groupby(['time'], as_index = False)['char'].max())\n",
    "\n",
    "## Plotly go object to graph plot.\n",
    "fig = go.Figure()\n",
    "\n",
    "## Mean\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = day_activity_mean['time'],\n",
    "    y = day_activity_mean['char'],\n",
    "    name = 'Average',\n",
    "    line_color = 'red',\n",
    "    hoverinfo = 'name+x+y',\n",
    "    opacity = 0.8))\n",
    "\n",
    "## Max \n",
    "fig.add_trace(go.Scatter(\n",
    "    x = day_activity_max['time'],\n",
    "    y = day_activity_max['char'],\n",
    "    name = 'Max',\n",
    "    line_color = 'purple',\n",
    "    hoverinfo = 'name+x+y',\n",
    "    opacity = 0.8))\n",
    "\n",
    "fig.update_layout(title_text = \"Hourly User Activity over one-year\", \n",
    "                  xaxis = dict(\n",
    "                      tickvals = [0, 6, 12, 18, 24, 30,\n",
    "                                  36, 42, 48, 54, 60,\n",
    "                                  66, 72, 78, 84, 90,\n",
    "                                  96, 102, 108, 114, 120,\n",
    "                                  126, 132, 138, 144],\n",
    "                  ),\n",
    "                  xaxis_rangeslider_visible = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Average hours played\n",
    "# Group playerbase by character ID for average hours\n",
    "tmp = avatar_history.groupby(by = ['char'])['Day'].nunique()\n",
    "\n",
    "# Group playerbase by character ID for the number of unique days they have played\n",
    "total_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\n",
    "\n",
    "# Create dataframe for average_hours\n",
    "data =  {'char_id': tmp.index,\n",
    "         'total_timestamps': total_timestamps.values,\n",
    "         'unique_days': tmp.values\n",
    "        }\n",
    "\n",
    "average_hours_df = pd.DataFrame(data = data)\n",
    "\n",
    "# Create average_hour feature\n",
    "average_hours_df['Average_Hour'] = average_hours_df['total_timestamps'] * 10 / (60 * average_hours_df['unique_days'])\n",
    "\n",
    "# Plot the Average hours played\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "x = ['95% Percentile', '75% Percentile',\n",
    "     'Mean',  '50% Percentile',\n",
    "     '25% Percentile']\n",
    "\n",
    "y = [average_hours_df['Average_Hour'].quantile(0.95),\n",
    "     average_hours_df['Average_Hour'].quantile(0.75),\n",
    "     average_hours_df['Average_Hour'].mean(),\n",
    "     average_hours_df['Average_Hour'].quantile(0.50),\n",
    "     average_hours_df['Average_Hour'].quantile(0.25)]\n",
    "\n",
    "def absolute_value(val):\n",
    "    a  = str(round(val / 100 * 6.971746263215458, 3)) + \" hrs\"\n",
    "    return a\n",
    "\n",
    "# Create pie chart\n",
    "textprops = dict(size = 20 )\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ffb3cc']\n",
    "plt.pie(y, labels = x,\n",
    "        autopct = absolute_value, startangle = 180, textprops = textprops, colors = colors)\n",
    "plt.axis('equal') \n",
    "plt.tight_layout()\n",
    "plt.title('Daily Playtime', fontsize = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Frequency on Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot user frequency on weekdays\n",
    "## Create dataframe for most frequent day of the week\n",
    "tmp = avatar_history.groupby(by =['char'])['Weekday'].max().value_counts()\n",
    "\n",
    "data =  {'weekday': tmp.index,\n",
    "         'count': tmp.values\n",
    "        }\n",
    "\n",
    "weekdays_df = pd.DataFrame(data = data)\n",
    "\n",
    "## Map weekday\n",
    "d = {0: 'Monday', 1: 'Tuesday',\n",
    "     2: 'Wednesday', 3: 'Thursday',\n",
    "     4: 'Friday', 5: 'Saturday',\n",
    "     6: 'Sunday'}\n",
    "\n",
    "weekdays_df['weekday'] = weekdays_df['weekday'].map(d)\n",
    "tmp = weekdays_df\n",
    "\n",
    "## Plot the expected variance\n",
    "plt.figure(figsize = (20, 10))\n",
    "sns.set(style = \"whitegrid\", rc = {\"lines.linewidth\": 2})\n",
    "\n",
    "order = ['Monday', 'Tuesday', \n",
    "         'Wednesday', 'Thursday',\n",
    "         'Friday', 'Saturday',\n",
    "         'Sunday']\n",
    "\n",
    "ax = sns.barplot(y = weekdays_df['weekday'], x = weekdays_df['count'],\n",
    "                 order = order,  palette = 'bright',\n",
    "                 edgecolor = 'pink')\n",
    "\n",
    "plt.xlabel('Count', fontsize = 24)\n",
    "plt.ylabel('Weekdays', fontsize = 24)\n",
    "plt.title('Distribution of Weekdays', fontsize = 24)\n",
    "plt.xticks( fontsize = 16)\n",
    "plt.yticks( fontsize = 16)\n",
    "\n",
    "'''Annotates a plot with percentages vertical layout.'''\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width(), i.get_y() + 0.5, \\\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', fontsize = 16,\n",
    "color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of survival analysis is to provide an accurate experimental analysis when the collected data has not been completed. It was inspired for applications concerning clinical trials in the diagnosis of illnesses, and how to properly classify patients if they do not exhibit symptoms during the lifetime of the study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before KM survival analysis, the data was filtered discard users who are on a trial period and have not subscribed yet (< 30 days). Also, various churn periods were assigned to a user if they did not play in 2, 3, 4, or 6-month periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Feature creation\n",
    "### Earliest day and latest day of the year played\n",
    "tmp_day_earliest = avatar_history.groupby('char')['Day'].min()\n",
    "tmp_day_latest = avatar_history.groupby('char')['Day'].max()\n",
    "\n",
    "### Earliest month and Latest month of year played \n",
    "tmp_month_earliest = avatar_history.groupby('char')['Month'].min()\n",
    "tmp_month_latest = avatar_history.groupby('char')['Month'].max()\n",
    "\n",
    "### Unique amount of days played\n",
    "tmp_days = avatar_history.groupby('char')['Day'].nunique()\n",
    "\n",
    "### Are they in a guild or not\n",
    "tmp_guild = avatar_history.groupby('char')['guild'].max()\n",
    "\n",
    "### Max level\n",
    "tmp_level = avatar_history.groupby('char')['level_interval'].max()\n",
    "\n",
    "### Need this for the number of unique days played\n",
    "tmp_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\n",
    "\n",
    "# Create dataframe\n",
    "data =  {'Char_ID': tmp_month_latest.index,\n",
    "         'Unique_Days': tmp_days.values,\n",
    "         'Total_Timestamps': tmp_timestamps.values,\n",
    "         'Earliest_Month_Played': tmp_month_earliest.values,\n",
    "         'Latest_Month_Played': tmp_month_latest.values,\n",
    "         'Earliest_Day_Played': tmp_day_earliest.values,\n",
    "         'Latest_Day_Played': tmp_day_latest.values,\n",
    "         'Guild': tmp_guild.values,\n",
    "         'Max_Level': tmp_level.values\n",
    "        }\n",
    "\n",
    "sa_total = pd.DataFrame(data)\n",
    "\n",
    "### Difference in latest day played and earliest day played and absolute value to find the total subscribed time.\n",
    "sa_total['Difference'] = (sa_total['Latest_Day_Played'] - sa_total['Earliest_Day_Played']).abs()\n",
    "\n",
    "### Filter out the data whom have lower than 30 days of played time (free-trial accounts)\n",
    "sa_total = sa_total.loc[(sa_total['Difference'] > 30)]\n",
    "sa_total['Guild'] = sa_total['Guild'].apply(lambda x: 0 if x == -1 else 1)\n",
    "\n",
    "### Create average_hour feature\n",
    "sa_total['Average_Hour'] = sa_total['Total_Timestamps'] * 10 / (60 * sa_total['Unique_Days'])\n",
    "\n",
    "### Create playing density\n",
    "sa_total['Average_Playing_Density'] = sa_total['Unique_Days']/ (((sa_total['Latest_Month_Played'] - sa_total['Earliest_Month_Played'] + 1).abs())/12 * 366)\n",
    "\n",
    "### Classify churn as someone who hasn't logged in various periods, 2, 3, 4, 6\n",
    "#### 2 month period\n",
    "sa_total['Churn2'] = (sa_total['Latest_Month_Played'] >= 11 )\n",
    "sa_total['Churn2'] = sa_total['Churn2'].apply(lambda x: 0 if x == True else 1)\n",
    "\n",
    "#### 3 month period\n",
    "sa_total['Churn3'] = (sa_total['Latest_Month_Played'] >= 10)\n",
    "sa_total['Churn3'] = sa_total['Churn3'].apply(lambda x: 0 if x == True else 1)\n",
    "\n",
    "#### 4 month period\n",
    "sa_total['Churn4'] = (sa_total['Latest_Month_Played'] >= 9)\n",
    "sa_total['Churn4'] = sa_total['Churn4'].apply(lambda x: 0 if x == True else 1)\n",
    "\n",
    "#### 6 month period\n",
    "sa_total['Churn6'] = (sa_total['Latest_Month_Played'] >= 7)\n",
    "sa_total['Churn6'] = sa_total['Churn6'].apply(lambda x: 0 if x == True else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to be heavily right-censored and does converge to a constant instead of reaching to 0. The 2-month and 3-month churn periods provide more accurate results due to less censoring than the other survival curves. The 2-month churn period has a 70% probability of not churning for ~215 days, and the 3-month period has a 60% probability of not churning for ~245 days. These results display promising insights into how addictive this game is as the population will be healthy across ~200 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plot Parameters\n",
    "sns.set_context(\"talk\")\n",
    "ax = plt.subplot()\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Churn Periods', fontsize = 24)\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\n",
    "\n",
    "### Plotting KM curves with various churn periods\n",
    "churn_list = ['Churn2', 'Churn3', 'Churn4', 'Churn6']\n",
    "churn_labels = ['2-month churn period', '3-month churn period', '4-month churn period', '6-month churn period']\n",
    "colormap = ['red', 'blue', 'green', 'orange']\n",
    "for churn, label, color in zip(churn_list, churn_labels, colormap):\n",
    "    kmf.fit(sa_total['Difference'], sa_total[churn], label = label)\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color)\n",
    "    \n",
    "### Plotting Annotations\n",
    "plt.vlines(303, ymin= 0.40, ymax= 0.46, linestyle = 'dotted', color = 'red')\n",
    "plt.vlines(273, ymin= 0.40, ymax= 0.59, linestyle = 'dotted', color = 'blue')\n",
    "plt.vlines(243, ymin= 0.40, ymax= 0.67, linestyle = 'dotted', color = 'green')\n",
    "plt.vlines(177, ymin= 0.40, ymax= 0.81, linestyle = 'dotted', color = 'orange')\n",
    "plt.text(276, 0.40, '30 days', color = 'red')\n",
    "plt.text(246, 0.40, '30 days', color = 'blue')\n",
    "plt.text(186, 0.40, '60 days', color = 'green', fontsize = 38)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guilds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who are not in a guild have a 1.33x higher churn ratio because being in a social network - can interact and group with your guildmates when playing the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plotting parameters\n",
    "sns.set_context(\"talk\")\n",
    "ax = plt.subplot()\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Guild', fontsize = 24)\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\n",
    "\n",
    "### Plotting KM curves if they are in a guild or not\n",
    "T_0 = sa_total[sa_total['Guild'] == 0]['Difference']\n",
    "C_0 = sa_total[sa_total['Guild'] == 0]['Churn2']\n",
    "T_1 = sa_total[sa_total['Guild'] == 1]['Difference']\n",
    "C_1 = sa_total[sa_total['Guild'] == 1]['Churn2']\n",
    "\n",
    "time_limit = 303\n",
    "labels = ['Guild', 'No Guild']\n",
    "colormap = ['red', 'blue']\n",
    "duration = [T_0, T_1]\n",
    "event = [C_0, C_1]\n",
    "position = [(100, 0.4), (180, 0.6)]\n",
    "\n",
    "for T, C, label, label_position, color in zip(duration, event, labels, position, colormap):\n",
    "    kmf.fit(T, C, label = label)\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color)\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\n",
    "          t = time_limit, ax = ax,\n",
    "          label = '_nolegend_', text_position = label_position)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Guild Churn Ratio: \" + str((242.407/182.265)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant overlap between curves. Therefore, let’s compare each curve with the 70-79 range to compare the churn ratios. The churn ratios are listed in Table 2. An interesting detail is the survival analysis curve for the 10-19 interval has a higher churn ratio than the other intervals. A possible solution is updating the 10-19 range content to compensate for this higher churn ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plotting parameters\n",
    "sns.set_context(\"talk\")\n",
    "ax = plt.subplot()\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Levels', fontsize = 24)\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.ylabel(\"Probability a Player is Still Active\", fontsize = 18)\n",
    "\n",
    "### Plotting KM curves if they are in a guild or not\n",
    "T_09 = sa_total[sa_total['Max_Level'] == '0-9']['Difference']\n",
    "C_09 = sa_total[sa_total['Max_Level'] == '0-9']['Churn2']\n",
    "T_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Difference']\n",
    "C_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Churn2']\n",
    "T_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Difference']\n",
    "C_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Churn2']\n",
    "T_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Difference']\n",
    "C_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Churn2']\n",
    "T_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Difference']\n",
    "C_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Churn2']\n",
    "T_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Difference']\n",
    "C_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Churn2']\n",
    "T_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Difference']\n",
    "C_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Churn2']\n",
    "T_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Difference']\n",
    "C_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Churn2']\n",
    "\n",
    "time_limit = 303\n",
    "\n",
    "labels = ['0-9', '10-19',\n",
    "          '20-29', '30-39',\n",
    "          '40-49', '50-59',\n",
    "          '60-69', '70-79']\n",
    "\n",
    "colormap = ['red', 'blue',\n",
    "            'magenta', 'orange',\n",
    "            'teal', 'purple',\n",
    "            'green', 'pink']\n",
    "\n",
    "duration = [T_09, T_1019, T_2029, T_3039, T_4049, T_5059, T_6069, T_7079] \n",
    "event = [C_09, C_1019, C_2029, C_3039, C_4049, C_5059, C_6069, C_7079]\n",
    "\n",
    "for T, C, label, color in zip(duration, event, labels, colormap):\n",
    "    kmf.fit(T, C, label = label)\n",
    "    kmf.plot(figsize = (18,9), ax = ax, color = color, ci_show = True )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plot parameters\n",
    "sns.set_context(\"talk\")\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(figsize = (20, 10), nrows=2,\n",
    "                                                                 ncols=4, sharex=True,\n",
    "                                                                 sharey=True)\n",
    "fig.suptitle('Kaplan-Meier Estimate of Customer Retention by Levels')\n",
    "\n",
    "# Plotting KM curves at various levels\n",
    "T_09 = sa_total[sa_total['Max_Level'] == '0-9']['Difference']\n",
    "C_09 = sa_total[sa_total['Max_Level'] == '0-9']['Churn2']\n",
    "T_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Difference']\n",
    "C_1019 = sa_total[sa_total['Max_Level'] == '10-19']['Churn2']\n",
    "T_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Difference']\n",
    "C_2029 = sa_total[sa_total['Max_Level'] == '20-29']['Churn2']\n",
    "T_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Difference']\n",
    "C_3039 = sa_total[sa_total['Max_Level'] == '30-39']['Churn2']\n",
    "T_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Difference']\n",
    "C_4049 = sa_total[sa_total['Max_Level'] == '40-49']['Churn2']\n",
    "T_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Difference']\n",
    "C_5059 = sa_total[sa_total['Max_Level'] == '50-59']['Churn2']\n",
    "T_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Difference']\n",
    "C_6069 = sa_total[sa_total['Max_Level'] == '60-69']['Churn2']\n",
    "T_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Difference']\n",
    "C_7079 = sa_total[sa_total['Max_Level'] == '70-79']['Churn2']\n",
    "\n",
    "time_limit = 303\n",
    "\n",
    "labels = ['0-9', '10-19',\n",
    "          '20-29', '30-39',\n",
    "          '40-49', '50-59',\n",
    "          '60-69', '70-79']\n",
    "\n",
    "colormap = ['red', 'blue',\n",
    "            'magenta', 'orange',\n",
    "            'teal', 'purple',\n",
    "            'green', 'pink']\n",
    "position = [(100, 0.4), (180, 0.6)]\n",
    "\n",
    "duration = [T_09, T_1019, T_2029, T_3039, T_4049, T_5059, T_6069] \n",
    "event = [C_09, C_1019, C_2029, C_3039, C_4049, C_5059, C_6069]\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7]\n",
    "\n",
    "for T, C, label, color, ax in zip(duration, event, labels, colormap, axes):\n",
    "    # Plot 70-79 KM curve\n",
    "    kmf.fit(T_7079, C_7079, label = '70-79')\n",
    "    kmf.plot(figsize = (40,20), ax = ax, color = 'black', ci_show=True )\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\n",
    "          t = time_limit, ax = ax,\n",
    "          label = '_nolegend_', text_position = (125, 0.92), fontsize = 10)\n",
    "    # Plot level interval KM curve\n",
    "    kmf.fit(T, C, label = label)\n",
    "    kmf.plot(figsize = (40,20), ax = ax, color = color, ci_show=True )\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\n",
    "          t = time_limit, ax = ax,\n",
    "          label = '_nolegend_', text_position = (0, 0.25), fontsize = 10)\n",
    "    \n",
    "    # Set plot parameters\n",
    "    ax.set_title(label, y = 1.05, fontsize = 16)\n",
    "    ax.set_xlabel('Duration (Days)', fontsize = 16)\n",
    "    ax.set_ylabel(\"Probability a Player is Still Active\", fontsize = 14)\n",
    "    ax.legend(bbox_to_anchor = [0.55, 0.27])\n",
    "    ax8.axis('off')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of churn ratios with various leveling intervals\n",
    "## Create an array and transpose values to make it a two-column format\n",
    "churn_values = [round(262.447 / 189.470, 3), round(262.447 / 170.453, 3),\n",
    "        round(262.447 / 191.560, 3), round(262.447 / 207.947, 3),\n",
    "        round(262.447 / 212.784, 3), round(262.447 / 235.308, 3),\n",
    "        round(262.447 / 228.042, 3)]\n",
    "churn_values = np.array(churn_values)\n",
    "\n",
    "## Create level intervals label\n",
    "level_intervals = ['0-9', '10-19',\n",
    "                            '20-29', '30-39',\n",
    "                            '40-49', '50-59',\n",
    "                            '60-69']\n",
    "    \n",
    "## Create plotly table object\n",
    "level_churn = go.Figure(data = [go.Table(\n",
    "    header = dict(values = ['Level Interval', 'Churn Ratio'],\n",
    "                  line_color = 'darkslategray',\n",
    "                  fill_color = 'lightskyblue',\n",
    "                  align = 'left'),\n",
    "    cells = dict(values = [level_intervals, churn_values],\n",
    "                 line_color = 'darkslategray',\n",
    "                 fill_color = 'lightcyan',\n",
    "                 align = 'left'))\n",
    "])\n",
    "\n",
    "level_churn.update_layout(width = 800, height = 500,\n",
    "                          title = 'Table 2: Churn Ratios with Level Intervals')\n",
    "level_churn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Playing Hours and Average Playing Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The churn ratios are 1.076x, and 1.1713x with users who have more than two average hours played. The churn ratio is 1.2723x with users who have greater than or equal to a 0.5 average playing density. An explanation for this observed behavior is players with more average hours played or average playing densities would exhibit lower churn ratios because they are spending more time playing the game and less likely to unsubscribe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plot Parameters\n",
    "ax = plt.subplot()\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Average Hours Played', fontsize = 24)\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "### Plot KM survival curves \n",
    "T_0 = sa_total[sa_total['Average_Hour'] < 1]['Difference']\n",
    "C_0 = sa_total[sa_total['Average_Hour'] < 1]['Churn2']\n",
    "T_1 = sa_total[(sa_total['Average_Hour'] >= 1) & (sa_total['Average_Hour'] < 2) ]['Difference']\n",
    "C_1 = sa_total[(sa_total['Average_Hour'] >= 1) & (sa_total['Average_Hour'] < 2)]['Churn2']\n",
    "T_2 = sa_total[(sa_total['Average_Hour'] >= 2) ]['Difference']\n",
    "C_2 = sa_total[(sa_total['Average_Hour'] >= 2) ]['Churn2']\n",
    "time_limit = 303\n",
    "labels = ['Average Hour < 1', '1 ≤ Average Hour < 2 ', 'Average Hour > 2']\n",
    "colormap = ['red', 'blue', 'green']\n",
    "position = [(130, 0.40), (200, 0.55), (140, 0.73)]\n",
    "duration = [T_0, T_1, T_2] \n",
    "event = [C_0, C_1, C_2]\n",
    "\n",
    "for T, C, label, color, label_position in zip(duration, event, labels, colormap, position):\n",
    "    # Plot level interval KM curve\n",
    "    kmf.fit(T, C, label = label)\n",
    "    kmf.plot(figsize = (18, 9), ax = ax, color = color)\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\n",
    "          t = time_limit, ax = ax,\n",
    "          label = '_nolegend_', text_position = label_position, fontsize = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Analysis\n",
    "## Kaplan-Meier Analysis\n",
    "### KMF\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "### Plot Parameters\n",
    "sns.set_context(\"talk\")\n",
    "ax = plt.subplot()\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.title('Kaplan-Meier Estimate of Customer Retention by Average Playing Densities', fontsize = 24)\n",
    "plt.xlabel('Duration (Days)', fontsize = 18)\n",
    "plt.ylabel(\"Probability a Player is Still Active\")\n",
    "\n",
    "### Plot KM survival curves \n",
    "T_1 = sa_total[sa_total['Average_Playing_Density'] < 0.5]['Difference']\n",
    "C_1 = sa_total[sa_total['Average_Playing_Density'] < 0.5]['Churn2']\n",
    "T_1 = sa_total[(sa_total['Average_Playing_Density'] >= 0.5) ]['Difference']\n",
    "C_1 = sa_total[(sa_total['Average_Playing_Density'] >= 0.5) ]['Churn2']\n",
    "\n",
    "time_limit = 303\n",
    "labels = ['Average Playing Density < 0.5', 'Average Playing Density ≥ 0.5 ']\n",
    "colormap = ['red', 'blue']\n",
    "position = [(130, 0.40), (200, 0.65)]\n",
    "duration = [T_0, T_1] \n",
    "event = [C_0, C_1]\n",
    "\n",
    "for T, C, label, color, label_position in zip(duration, event, labels, colormap, position):\n",
    "    # Plot level interval KM curve\n",
    "    kmf.fit(T, C, label = label)\n",
    "    kmf.plot(figsize = (18, 9), ax = ax, color = color)\n",
    "    rmst_plot(figsize = (18,9), model = kmf,\n",
    "          t = time_limit, ax = ax,\n",
    "          label = '_nolegend_', text_position = label_position, fontsize = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Playing Hours Churn Ratio: \", str(241.081 / 223.894))\n",
    "print(\"Average Playing Hours Churn Ratio: \", str(241.081 / 205.822))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification is a problem involving the assignment of a sample to one of two categories by measuring a series of attributes. The semantics include learning a function that minimizes the misclassification probability of labeling a sample as a 0 or 1. The main metric selected is the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate and false-positive rate. The true positive rate is defined as the recall and is presented in Equation 1. The false-positive rate is presented in Equation 2. The ROC curve plots the TPR vs FPR by varying classification thresholds – lowering the classification threshold results in a higher positive rate. Using the ROC curve, we'll measure the area under the curve (AUC) because it provides an aggregate measure of performance across all possible classification thresholds. Two reasons for using AUC: \n",
    "\n",
    "* AUC is scale-invariant - it measures how well predictions are ranked.  \n",
    "\n",
    "* AUC is classification-threshold-invariant - it measures the quality of the model’s predictions without selecting a classification threshold. \n",
    "\n",
    "In our problem, misclassification of false positives (labeling someone who has quit the game as playing) is more important because it affects the projected finances of the game as the model is predicting a user is playing but is not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (1) and Equation (2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TPR = \\frac{TP}{TP + FN}$$                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ FPR = \\frac{FP}{FP + TN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are split into an 80/20 ratio between the training and test samples, respectively. There was k-fold cross-validation performed on the training set for hyperparameter tuning. In k-fold cross-validation, the data is evenly split into k non-overlapping pieces and each piece contains a validation set as displayed in the figure below. Then, average the selected scoring metric across the k trials. Cross-validation was used to test the generalizability of the model. As CV checks in how it is performing on new unseen data with a limited amount of training samples. Since the problem is binary classification, stratification can be used to make sure the same number of proportion of classes are in the validation and training folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![10-fold](assets/kfold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two techniques were compared for feature selection: univariate feature selection and recursive feature elimination. Univariate feature selection works best when you have an abundant number of features and want to select which features are significant using a statistical test. Recursive feature elimination is utilized for identifying which features are increasing your performance metric. Recursive feature selection works by eliminating the least important features. It continues recursively until the specified number of features is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to apply ML\n",
    "## Group playerbase by character ID for average hours\n",
    "tmp = avatar_history.groupby(by = ['char'])['Day'].nunique()\n",
    "tmp_guild = avatar_history.groupby('char')['guild'].max()\n",
    "tmp_max_level = avatar_history.groupby('char')['level'].max()\n",
    "tmp_max_month = avatar_history.groupby('char')['Month'].max()\n",
    "tmp_min_month = avatar_history.groupby('char')['Month'].min()\n",
    "\n",
    "## Group playerbase by character ID for the number of unique days they have played\n",
    "total_timestamps = avatar_history.groupby(by = ['char'])['Day'].count()\n",
    "\n",
    "## Create dataframe for average_hours\n",
    "data =  {'char_id': tmp.index,\n",
    "         'guild': tmp_guild.values,\n",
    "         'total_timestamps': total_timestamps.values,\n",
    "         'unique_days': tmp.values,\n",
    "         'max_level': tmp_max_level.values,\n",
    "         'min_month': tmp_min_month.values,\n",
    "         'max_month': tmp_max_month.values,\n",
    "        }\n",
    "\n",
    "average_hours_df = pd.DataFrame(data = data)\n",
    "\n",
    "## Create average_hour feature\n",
    "average_hours_df['Average_Hour'] = average_hours_df['total_timestamps'] * 10 / (60 * average_hours_df['unique_days'])\n",
    "\n",
    "## Create playing density\n",
    "average_hours_df['Average_Playing_density'] = average_hours_df['unique_days'] / (((average_hours_df['max_month'] - average_hours_df['min_month'] + 1).abs()) / 12 * 366)\n",
    "\n",
    "## Are they in a guild or not\n",
    "average_hours_df['guild'] = average_hours_df['guild'].apply(lambda x: 0 if x == -1 else 1)\n",
    "\n",
    "## Playing for 6 months and longer (y output)\n",
    "average_hours_df['Playing_after_6_months'] = (average_hours_df['max_month'] - average_hours_df['min_month'] +1).abs().apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "## Create train and testing sets, and include stratification (0.80 / 0/20)\n",
    "X = average_hours_df[['guild', 'max_level', 'Average_Hour', 'Average_Playing_density']]\n",
    "y = average_hours_df['Playing_after_6_months']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10, stratify = y)\n",
    "\n",
    "## Scale the data\n",
    "col_names = ['guild','max_level', 'Average_Hour', 'Average_Playing_density']\n",
    "features = X_train[col_names]\n",
    "features_test = X_test[col_names]\n",
    "ct = ColumnTransformer([\n",
    "        ('somename', StandardScaler(), ['max_level', 'Average_Hour', 'Average_Playing_density'])\n",
    "    ], remainder = 'passthrough')\n",
    "X_train_scaled = ct.fit_transform(features)\n",
    "X_test_scaled = ct.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_hours_df.to_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters were tuned to find the best ROC AUC score for logistic regression using an exhaustive grid search (10-fold cv). The optimal hyperparameters are listed below. \n",
    "\n",
    "* Penalty: L1 \n",
    "\n",
    "* Regularization: C = 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True]\n",
      "Best Penalty: l2\n",
      "Best C: 25\n",
      "{'C': 25, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Pipeline\n",
    "## Instantiate logistic regression model\n",
    "clf_LR = LogisticRegression(random_state = 0, solver = 'liblinear')\n",
    "\n",
    "## First step of pipeline recursive feature elimination with cross validation (10-fold)\n",
    "rfecv = RFECV(estimator = clf_LR, \n",
    "              step = 1, \n",
    "              cv = StratifiedKFold(10), \n",
    "              scoring = 'roc_auc')\n",
    "\n",
    "## Second step of pipeline grid search using cross validation (10-fold)\n",
    "CV_rfc = GridSearchCV(clf_LR, \n",
    "                      param_grid = {'penalty': ['l2', 'l1'],\n",
    "                                    'C': [0.001,.009,0.01,.09,.5, 0.8, 1,5,10,25]},\n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\n",
    "\n",
    "## Instantiate Pipeline\n",
    "pipeline = Pipeline([('feature_sele', rfecv),('clf_LR_cv', CV_rfc)])\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Assign model predictions\n",
    "y_pred_acc = pipeline.predict(X_test_scaled)\n",
    "\n",
    "## Best parameters and features for the model\n",
    "print(rfecv.get_support()) \n",
    "print('Best Penalty:', CV_rfc.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', CV_rfc.best_estimator_.get_params()['C'])\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean:0.85324450970565\n",
      "Accuracy Score : 0.8451345201445589\n",
      "Precision Score : 0.6926751592356688\n",
      "Recall Score : 0.5301645338208409\n",
      "F1 Score : 0.6006213324128409\n",
      "ROC Score : 0.8502737526693237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5444,  386],\n",
       "       [ 771,  870]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Logistic Regression parameters \n",
    "## Create the model instance\n",
    "clf_LR = LogisticRegression(random_state = 0, solver = 'liblinear',\n",
    "                            C = 25, penalty = 'l2')\n",
    "\n",
    "## Get the ROC by k-fold cross validation on the training set\n",
    "cv_scores = cross_val_score(clf_LR, X_train_scaled,\n",
    "                            y_train, cv = StratifiedKFold(10),\n",
    "                            scoring = 'roc_auc')\n",
    "\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "## Fit the model\n",
    "clf_LR.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the model predictions\n",
    "y_pred_acc = clf_LR.predict(X_test_scaled)\n",
    "\n",
    "# Classification metrics\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_LR.predict_proba(X_test_scaled)[:,1])))\n",
    "\n",
    "# Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test,y_pred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters were tuned to find the best ROC AUC score for the support vector machine using an exhaustive grid search (10-fold cv). The optimal hyperparameters are listed below. \n",
    "\n",
    "* Kernel: Linear \n",
    "\n",
    "* Regularization: C = 0.009 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a119d7a7fcfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m## Instantiate Pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'feature_sele'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfecv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clf_SVM_cv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCV_rfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m## Assign model predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Pipeline\n",
    "## Instantiate Support Vector Machine Pipeline\n",
    "\n",
    "clf_SVM = svm.SVC(kernel = 'linear')\n",
    "\n",
    "## First step of pipeline recursive feature elimination with cross validation (10-fold)\n",
    "rfecv = RFECV(estimator = clf_SVM, \n",
    "              step = 1, \n",
    "              cv = StratifiedKFold(10), \n",
    "              scoring = 'roc_auc')\n",
    "\n",
    "## Second step of pipeline grid search using cross validation (10-fold)\n",
    "CV_rfc = GridSearchCV(clf_SVM, \n",
    "                      param_grid = \n",
    "                      {\n",
    "                          'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "                          'C': [0.001,.009,0.01,.09,.5, 0.8, 1,5,10,25]      \n",
    "                      },\n",
    "                      \n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\n",
    "\n",
    "## Instantiate Pipeline\n",
    "pipeline = Pipeline([('feature_sele', rfecv),('clf_SVM_cv', CV_rfc)])\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Assign model predictions\n",
    "y_pred_acc = pipeline.predict(X_test_scaled)\n",
    "\n",
    "## Best parameters and features for the model\n",
    "print(rfecv.get_support()) \n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean:0.8456118782603654\n",
      "Accuracy Scoree : 0.6233333333333333\n",
      "Recall Score : : 0.8298755186721992\n",
      "Precision Score : 0.6233333333333333\n",
      "Recall Score : 0.5697745277269958\n",
      "F1 Score : 0.5953517987901942\n",
      "ROC Score : 0.8416722849201894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5265,  565],\n",
       "       [ 706,  935]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best SVM parameters \n",
    "## Set new features\n",
    "X_train_SVM = np.column_stack((X_train_scaled[:,:2],\n",
    "                               X_train_scaled[:,:][0:, -1].reshape(29883, 1)))\n",
    "\n",
    "X_test_SVM = np.column_stack((X_test_scaled[:,:2],\n",
    "                              X_test_scaled[:,:][0:, -1].reshape(7471, 1)))\n",
    "\n",
    "## Create the model instance\n",
    "clf_SVM = svm.SVC(kernel = 'linear', C = 0.009)\n",
    "\n",
    "## Get the ROC by k-fold cross validation on the training set\n",
    "cv_scores = cross_val_score(clf_SVM, X_train_SVM,\n",
    "                            y_train, cv = StratifiedKFold(10),\n",
    "                            scoring = 'roc_auc')\n",
    "\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "## Fit the model\n",
    "clf_SVM.fit(X_train_SVM, y_train)\n",
    "\n",
    "## Get the model predictions\n",
    "y_pred_acc = clf_SVM.predict(X_test_SVM)\n",
    "\n",
    "## Classification metrics\n",
    "print('Accuracy Scoree : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "print('Recall Score : : ' + str(accuracy_score(y_test, y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_SVM.decision_function(X_test_SVM))))\n",
    "\n",
    "#Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test, y_pred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters were tuned to find the best ROC AUC score for the KNN classifier using an exhaustive grid search (10-fold cv). The optimal hyperparameters are listed below. \n",
    "\n",
    "* n_neighbors: 24 \n",
    "\n",
    "* leaf_size: 2 \n",
    "\n",
    "* metric (p): 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Pipeline\n",
    "## Instantiate K-Nearest Neighbors Pipeline\n",
    "clf_KNN = KNeighborsClassifier()\n",
    "\n",
    "## Set parameters for grid search\n",
    "leaf_size = list(range(1, 50))\n",
    "n_neighbors = list(range(1, 30))\n",
    "p = [1,2]\n",
    "hyperparameters = dict(leaf_size = leaf_size, n_neighbors = n_neighbors,\n",
    "                       p = p)\n",
    "\n",
    "### First step of pipeline\n",
    "CV_rfc = GridSearchCV(clf_KNN, \n",
    "                      param_grid = hyperparameters,\n",
    "                      cv = StratifiedKFold(10), scoring = 'roc_auc')\n",
    "\n",
    "## Instantiate Pipeline\n",
    "pipeline = Pipeline([(('clf_KNN_cv', CV_rfc))])\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Best parameters and features for the model\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean:0.9406726549238076\n",
      "Accuracy Score : 0.8816758131441574\n",
      "Precision Score : 0.7531772575250836\n",
      "Recall Score : 0.6861669713589275\n",
      "F1 Score : 0.7181122448979591\n",
      "ROC Score : 0.9359318931789699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5461,  369],\n",
       "       [ 515, 1126]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best KNN parameters \n",
    "## Create the model instance\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors = 24, leaf_size = 2,\n",
    "                               p = 1)\n",
    "\n",
    "cv_scores = cross_val_score(clf_KNN, X_train_scaled,\n",
    "                            y_train, cv = StratifiedKFold(10),\n",
    "                            scoring = 'roc_auc')\n",
    "\n",
    "## Get the ROC by k-fold cross validation on the training set\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "## Fit the model\n",
    "clf_KNN.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Get the model predictions\n",
    "y_pred_acc = clf_KNN.predict(X_test_scaled)\n",
    "\n",
    "## Classification metrics\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1])))\n",
    "\n",
    "# Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test,y_pred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters were tuned to find the best ROC AUC score for the KNN classifier using a randomized search (10-fold cv) [10]. The optimal hyperparameters are listed below. \n",
    "\n",
    "* n_estimators: 300 \n",
    "\n",
    "* Criterion: entropy \n",
    "\n",
    "* max_features: 4 \n",
    "\n",
    "* max_depth: None \n",
    "\n",
    "* min_samples_split: 15 \n",
    "\n",
    "* Bootstrap: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6052f67eb017>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m## Instantiate Pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clf_RF_cv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCV_rfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m## Best parameters and features for the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "## Instantiate Random Forest Pipeline\n",
    "clf_RF = RandomForestClassifier()\n",
    "\n",
    "# Randomized grid search of parameters\n",
    "grid_param = {\n",
    "    'n_estimators': [100, 300, 500, 800, 1000, 1200],\n",
    "    'max_features': [1, 2, 3, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split' : [2, 5, 10, 15, 20],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "CV_rfc = clf_RF = RandomizedSearchCV(clf_RF, grid_param,\n",
    "                                     random_state = 0, cv = StratifiedKFold(10))\n",
    "\n",
    "## Instantiate Pipeline\n",
    "pipeline = Pipeline([('clf_RF_cv',CV_rfc)])\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Best parameters and features for the model\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean :0.9406726549238076\n",
      "Accuracy Score : 0.9186186588140811\n",
      "Precision Score : 0.8058022498519835\n",
      "Recall Score : 0.8293723339427178\n",
      "F1 Score : 0.8174174174174175\n",
      "ROC Score : 0.9666548030057397\n"
     ]
    }
   ],
   "source": [
    "# Best RF parameters \n",
    "\n",
    "## Create the model instance\n",
    "clf_RF = RandomForestClassifier(n_estimators = 300, min_samples_split = 15,\n",
    "                                max_depth = None, criterion = 'entropy',\n",
    "                                bootstrap = True, random_state = 10)\n",
    "\n",
    "cv_scores = cross_val_score(clf_KNN, X_train_scaled,\n",
    "                            y_train, cv = StratifiedKFold(10),\n",
    "                            scoring = 'roc_auc')\n",
    "\n",
    "## Get the ROC score by k-fold cross validation on the training set\n",
    "print('cv_scores mean :{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "## Fit the model\n",
    "clf_RF.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Get the model predictions\n",
    "y_pred_acc = clf_RF.predict(X_test_scaled)\n",
    "\n",
    "## Classification metrics\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\n",
    "print('ROC Score : ' + str(roc_auc_score(y_test, clf_RF.predict_proba(X_test_scaled)[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of each model is listed from best to worst: RF > KN > LR > SVM and are presented in Table 3. The results are not a surprise as ensemble methods tend to do very well. And being the data is somewhat linearly separable, Logistic Regression and Support Vector Machine with a linear kernel would perform similarly. Overall, the ROC AUC scores are very promising, and the models have fit this dataset well. However, more investigation needs to be conducted to see if our models fit certain behaviors better (people who have higher average playing densities and average hours played).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reciever Operating Characteristics\n",
    "## Plot parameters\n",
    "sns.set_context(\"talk\")\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(figsize = (20, 10), nrows=2, ncols=2, sharex=True, sharey=True)\n",
    "fig.suptitle('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.subplots_adjust(\n",
    "wspace = 0.2,  # the amount of width reserved for space between subplots,\n",
    "       # expressed as a fraction of the average axis width\n",
    "hspace = 0.3 , # the amount of height reserved for space between subplots,\n",
    "              # expressed as a fraction of the average axis height)\n",
    ") \n",
    "\n",
    "## Plotting ROC curves with various algorithms\n",
    "fper_LR, tper_LR, thresholds_LR = roc_curve(y_test, clf_LR.predict_proba(X_test_scaled)[:,1]) \n",
    "\n",
    "fper_SVM, tper_SVM, thresholds_SVM = roc_curve(y_test, clf_SVM.decision_function(X_test_SVM)) \n",
    "\n",
    "fper_KNN, tper_KNN, thresholds_KNN = roc_curve(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1]) \n",
    "\n",
    "fper_RF, tper_RF, thresholds_RF = roc_curve(y_test, clf_RF.predict_proba(X_test_scaled)[:,1]) \n",
    "\n",
    "titles = ['LR', 'SVM',\n",
    "          'KNN', 'RF',\n",
    "]\n",
    "\n",
    "colormap = ['red', 'blue',\n",
    "            'magenta', 'orange',\n",
    "           ]\n",
    "position = [(100, 0.4), (180, 0.6)]\n",
    "\n",
    "fpr = [fper_LR, fper_SVM, fper_KNN, fper_RF] \n",
    "tpr = [tper_LR, tper_SVM, tper_KNN, tper_RF]\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4]\n",
    "roc_scores = [str('AUC: ') + str(round(roc_auc_score(y_test, clf_LR.predict_proba(X_test_scaled)[:,1]), 4)),\n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_SVM.decision_function(X_test_SVM)), 4)),\n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_KNN.predict_proba(X_test_scaled)[:,1]), 4)), \n",
    "              str('AUC: ') + str(round(roc_auc_score(y_test, clf_RF.predict_proba(X_test_scaled)[:,1]), 4))\n",
    "             ]\n",
    "for fp, tp, label, title, color, ax in zip(fpr, tpr, roc_scores, titles, colormap, axes):\n",
    "    ax.plot(fp, tp, color= color, label= label)\n",
    "    ax.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    # Set plot parameters\n",
    "    ax.set_title(title, y = 1.05, fontsize = 16)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize = 14, labelpad = 10)\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize = 14, labelpad = 15)\n",
    "    ax.legend(bbox_to_anchor = [1, 0.27])\n",
    "\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Table of the ROC AUC scores of various machine learning algorithms\n",
    "## Create an array and transpose values to make it a two-column format\n",
    "accuracy_values = [0.8451, 0.6384,\n",
    "        0.8814, 0.9171]\n",
    "accuracy_values = np.array(accuracy_values)\n",
    "\n",
    "\n",
    "roc_values_train = [0.8532, 0.8454,\n",
    "        0.9407, 0.9254]\n",
    "\n",
    "roc_values_test = [0.8503, 0.8417,\n",
    "        0.9366, 0.9665]\n",
    "\n",
    "roc_values_test = np.array(roc_values_test)\n",
    "\n",
    "method = ['Logistic Regression', 'Support Vector Machine',\n",
    "                            'K-Nearest Neighbors', 'Random Forest',]\n",
    "\n",
    "## Create plotly table object\n",
    "roc_auc = go.Figure(data = [go.Table(\n",
    "    header = dict(values = [['Method'], ['Accuracy'], ['ROC_AUC', ['10-fold CV']], ['', ['Testing']]],\n",
    "                  line_color = 'darkslategray',\n",
    "                  fill_color = 'lightskyblue',\n",
    "                  align = 'left'),\n",
    "    cells = dict(values = [method, accuracy_values, roc_values_train, roc_values_test],\n",
    "                 line_color = 'darkslategray',\n",
    "                 fill_color = 'lightcyan',\n",
    "                 align = 'left'))\n",
    "])\n",
    "\n",
    "roc_auc.update_layout(width = 800, height = 500,\n",
    "                      title = 'Table 3: ROC AUC scores with various machine learning algorithms.')\n",
    "roc_auc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is an algorithm to classify or to group objects based on attributes or features into K number of groups [11]. The grouping is done by minimizing the sum of the square of distances between data and the corresponding cluster centroids.  Generally, used as an unsupervised learning technique to find patterns amongst unstructured data or data without labels, K-means can be used for supervised learning problems such as classification. However, k-means does not compute probabilities in classifying labels. Therefore, the ROC AUC cannot be computed, but the accuracy can be used instead. \n",
    "\n",
    "A general rule of thumb is to select the number of components that accounts for at least 85% or 95% of the variance, which are two or three components, respectively. The accuracies of the models are listed in Table 4. Overall, all methods performed similarly with an accuracy ~ 81% and is a good baseline for future models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter3d_cluster(df, x, y, z, code, title):\n",
    "    \"\"\"Function to create 3D scatterplots for clustering diagrams\"\"\"\n",
    "    scatter  =  px.scatter_3d(df, x = x, y = y, z = z, color  =  code,  \n",
    "                            color_discrete_sequence = px.colors.qualitative.Light24)\n",
    "    \n",
    "    scatter.update_layout(title  =  title, title_font  =  dict(size  =  30),\n",
    "                          scene  =  dict(\n",
    "                              xaxis  =  dict(\n",
    "                                  backgroundcolor = \"rgb(200, 200, 230)\",\n",
    "                                  gridcolor = \"white\",\n",
    "                                  showbackground = True,\n",
    "                                  zerolinecolor = \"white\",\n",
    "                                  nticks = 10, ticks = 'outside',\n",
    "                                  tick0 = 0, tickwidth  =  4,\n",
    "                                  title_font  =  dict(size  =  16)),\n",
    "                              yaxis  =  dict(\n",
    "                                  backgroundcolor = \"rgb(230, 200,230)\",\n",
    "                                  gridcolor = \"white\",\n",
    "                                  showbackground = True,\n",
    "                                  zerolinecolor = \"white\",\n",
    "                                  nticks = 10, ticks = 'outside',\n",
    "                                  tick0 = 0, tickwidth  =  4,\n",
    "                                  title_font  =  dict(size  =  16)),\n",
    "                              zaxis  =  dict(\n",
    "                                  backgroundcolor = \"rgb(230, 230,200)\",\n",
    "                                  gridcolor = \"white\",\n",
    "                                  showbackground = True,\n",
    "                                  zerolinecolor = \"white\",\n",
    "                                  nticks = 10, ticks = 'outside',\n",
    "                                  tick0 = 0, tickwidth  =  4,\n",
    "                                  title_font  =  dict(size  =  16),\n",
    "                              ),\n",
    "                          ),\n",
    "                          width  =  700\n",
    "                         )\n",
    "    return scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on training set\n",
    "number_cluster = 2\n",
    "kmeans = KMeans(n_clusters = number_cluster, init = 'k-means++', random_state = 10).fit(X_train_scaled)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3D Plot of Training Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "df_X_train_std = pd.DataFrame(X_train_scaled)\n",
    "df_X_train_std['Cluster'] = pd.Series(labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['Cluster'].map(cluster_label_names)  \n",
    "df_X_train_std.columns = [ 'Max_Level', \"Average_Hour\",\n",
    "                          \"Average_Playing_density\", 'guild', 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Average_Hour',\n",
    "                  y = 'Average_Playing_density', z = 'Max_Level', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the accuracy of the training set\n",
    "y_train_df = pd.Series(y_train)\n",
    "y_train_df = y_train_df.reset_index()\n",
    "df_X_train_std['Actual_Labels'] = pd.Series(y_train_df['Playing_after_6_months'], index = y_train_df.index)\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "acc_train = df_X_train_std['Actual_Labels'].eq(df_X_train_std['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of training set\n",
    "print(\"Accuracy : \" + str(acc_train[1]/(acc_train[0] + acc_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on testing set\n",
    "predict_labels = kmeans.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Plot of testing Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "df_X_test_std = pd.DataFrame(X_test_scaled)\n",
    "df_X_test_std['Cluster'] = pd.Series(predict_labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['Cluster'].map(cluster_label_names)  \n",
    "df_X_test_std.columns = [ 'Max_Level', \"Average_Hour\",\n",
    "                          \"Average_Playing_density\", 'guild', 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Average_Hour',\n",
    "                  y = 'Average_Playing_density', z = 'Max_Level', code = 'Cluster_Labels', \n",
    "                  title =  'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the testing set\n",
    "y_test_df = pd.Series(y_test)\n",
    "y_test_df = y_test_df.reset_index()\n",
    "df_X_test_std['Actual_Labels'] = pd.Series(y_test_df['Playing_after_6_months'], index = y_test_df.index)\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "acc_test = df_X_test_std['Actual_Labels'].eq(df_X_test_std['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of testing set\n",
    "print(\"Accuracy : \" + str(acc_test[1]/(acc_test[0] + acc_test[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting PCA variance \n",
    "## Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(X_train_scaled)\n",
    "pca_variance_components = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "## Plotting the Cumulative Summation of the Explained Variance\n",
    "### Plot Parameters\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(pca_variance_components)\n",
    "plt.xlabel('Number of Components', fontsize = 24)\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.ylabel('Variance (%)', fontsize = 24) \n",
    "plt.title('Variance of Principle Components', fontsize = 24)\n",
    "\n",
    "### Color markers and annotate text\n",
    "s = ['o', 'o', 'o', 'o']\n",
    "col = ['blue','red','green', 'black']\n",
    "x = np.array([0, 1, 2, 3])\n",
    "y = pca_variance_components\n",
    "\n",
    "for _s, c, _x, _y in zip(s, col, x, y):\n",
    "    plt.scatter(_x, _y, marker = _s, c = c)\n",
    "\n",
    "### Annotate text\n",
    "plt.text(-0.05, pca_variance_components[0] + 0.015,\n",
    "         str(round(pca_variance_components[0], 3)), size = 14, color = 'blue', weight = 'semibold')\n",
    "\n",
    "plt.text(0.95, pca_variance_components[1] + 0.008,\n",
    "         str(round(pca_variance_components[1], 3)), size = 14, color = 'red', weight = 'semibold')\n",
    "\n",
    "plt.text(1.95, pca_variance_components[2] + 0.008,\n",
    "         str(round(pca_variance_components[2], 3)), size = 14, color = 'green', weight = 'semibold')\n",
    "\n",
    "plt.text(2.96, pca_variance_components[3] + 0.005,\n",
    "         str(round(pca_variance_components[3], 3)), size = 14, color = 'black', weight = 'semibold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA - Two Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variance of two PCA components\n",
    "## Set PCA parameters\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "## Fit and transform\n",
    "principalComponents = pca.fit(X_train_scaled)\n",
    "features = range(pca.n_components_)\n",
    "principalComponents_variance = principalComponents.explained_variance_ratio_\n",
    "\n",
    "## Plot the expected variance\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.set(style = \"white\", rc = {\"lines.linewidth\": 3})\n",
    "ax = sns.barplot(x = np.array(features), y = principalComponents.explained_variance_ratio_,\n",
    "                 palette = \"bright\")\n",
    "\n",
    "plt.xlabel('PCA features', fontsize = 24)\n",
    "plt.ylabel('Variance %', fontsize = 24)\n",
    "plt.title('PCA Variance', fontsize = 24)\n",
    "plt.xticks(features, fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "## Annotate plot\n",
    "### Function to add labels to bar chart\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.3f}\".format(y_value)\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            fontsize = '16',            # Font size\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values.\n",
    "\n",
    "### Call the function above\n",
    "add_value_labels(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of PCA components\n",
    "pca = PCA(n_components = 2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_Fit_Transform(df):\n",
    "    \"\"\"Function to fit and transform the dataframe and rename the PCA components\"\"\"\n",
    "    PCA_DF = pca.fit_transform(df)\n",
    "    PCA_DF = pd.DataFrame(PCA_DF)\n",
    "    \n",
    "    # Rename PCA column names\n",
    "    x = (np.array(PCA_DF.columns)+1)\n",
    "    columns = []\n",
    "    for i in x:\n",
    "        columns.append('PCA' + ' ' + str(i))\n",
    "    PCA_DF.columns = columns\n",
    "    \n",
    "    return PCA_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_Transform(df):\n",
    "    \"\"\"Function to transform the dataframe and rename the PCA components\"\"\"\n",
    "    PCA_DF = pca.transform(df)\n",
    "    PCA_DF = pd.DataFrame(PCA_DF)\n",
    "    \n",
    "    # Rename PCA column names\n",
    "    x = (np.array(PCA_DF.columns)+1)\n",
    "    columns = []\n",
    "    for i in x:\n",
    "        columns.append('PCA' + ' ' + str(i))\n",
    "    PCA_DF.columns = columns\n",
    "    \n",
    "    return PCA_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataframes using PCA\n",
    "PCA_components_train = pca_Fit_Transform(X_train_scaled)\n",
    "PCA_components_test = pca_Transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter2d_cluster(df, x, y,  code, title):\n",
    "    \"\"\"Function to create 2d scatterplots for clustering diagrams\"\"\"\n",
    "    scatter = px.scatter(df, x = x, y = y, color = code,\n",
    "                         color_discrete_sequence = px.colors.qualitative.Light24)\n",
    "    \n",
    "    scatter.update_xaxes(showline = True, linewidth = 1, linecolor = 'black', \n",
    "                          mirror = True, gridcolor = 'LightPink', automargin = True, \n",
    "                          zeroline = True, zerolinewidth = 2, zerolinecolor = 'LightPink', \n",
    "                          ticks = \"outside\", tickwidth = 2, tickcolor = 'black', ticklen = 10,\n",
    "                          title_font = dict(size = 18))\n",
    "    scatter.update_yaxes(showline = True, linewidth = 2, linecolor = 'black', \n",
    "                          mirror = True, gridcolor = 'LightPink',\n",
    "                          zeroline = True, zerolinewidth = 1, zerolinecolor = 'LightPink', \n",
    "                          ticks = \"outside\", tickwidth = 2, tickcolor = 'black', ticklen = 10,\n",
    "                          title_font = dict(size = 18))\n",
    "    \n",
    "    \n",
    "    scatter.update_layout(title = title, title_font = dict(size = 24), \n",
    "                          legend = dict(\n",
    "                              x = 1,\n",
    "                              y = 1,\n",
    "                              traceorder = \"normal\",\n",
    "                              font = dict(\n",
    "                                  family = \"sans-serif\",\n",
    "                                  size = 14,\n",
    "                                  color = \"black\"\n",
    "                              ),\n",
    "                              bgcolor = \"#e5ecf6\",\n",
    "                              bordercolor = \"Black\",\n",
    "                              borderwidth = 2\n",
    "                          )\n",
    "                         )\n",
    "    return scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on training set\n",
    "number_cluster = 2\n",
    "kmeans = KMeans(n_clusters = number_cluster, init = 'k-means++', random_state = 10).fit(PCA_components_train)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Plot of Training Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "PCA_components_train['Cluster'] = pd.Series(labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "PCA_components_train['Cluster_Labels'] = PCA_components_train['Cluster'].map(cluster_label_names)  \n",
    "PCA_components_train.columns = [ 'PCA_1', \"PCA_2\",\n",
    "                         'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter2d_cluster(df = PCA_components_train , x = 'PCA_1',\n",
    "                  y = 'PCA_2', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the training set\n",
    "y_train_df = pd.Series(y_train)\n",
    "y_train_df = y_train_df.reset_index()\n",
    "PCA_components_train['Actual_Labels'] = pd.Series(y_train_df['Playing_after_6_months'], index = y_train_df.index)\n",
    "PCA_components_train['Cluster_Labels'] = PCA_components_train['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "PCA_acc_train = PCA_components_train['Actual_Labels'].eq(PCA_components_train['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the training set\n",
    "print(\"Accuracy : \" + str(PCA_acc_train[1]/(PCA_acc_train[0] + PCA_acc_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on testing set\n",
    "predict_labels = kmeans.predict(PCA_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Plot of testing Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "PCA_components_test['Cluster'] = pd.Series(predict_labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "PCA_components_test['Cluster_Labels'] = PCA_components_test['Cluster'].map(cluster_label_names)  \n",
    "PCA_components_test.columns = [ 'PCA_1', \"PCA_2\",\n",
    "                         'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter2d_cluster(df = PCA_components_test , x = 'PCA_1',\n",
    "                  y = 'PCA_2', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the testing set\n",
    "y_test_df = pd.Series(y_test)\n",
    "y_test_df = y_test_df.reset_index()\n",
    "PCA_components_test['Actual_Labels'] = pd.Series(y_test_df['Playing_after_6_months'], index = y_test_df.index)\n",
    "PCA_components_test['Cluster_Labels'] = PCA_components_test['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "PCA_acc_test = PCA_components_test['Actual_Labels'].eq(PCA_components_test['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the testing set\n",
    "print(\"Accuracy : \" + str(PCA_acc_test[1]/(PCA_acc_test[0] + PCA_acc_test[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA- Three Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframes using PCA\n",
    "PCA_components_train = pca_Fit_Transform(X_train_scaled)\n",
    "PCA_components_test = pca_Transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variance of three PCA components\n",
    "## Set PCA parameters\n",
    "pca = PCA(n_components = 3)\n",
    "\n",
    "## Fit and transform\n",
    "principalComponents = pca.fit(X_train_scaled)\n",
    "features = range(pca.n_components_)\n",
    "principalComponents_variance = principalComponents.explained_variance_ratio_\n",
    "\n",
    "## Plot the expected variance\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.set(style = \"white\", rc = {\"lines.linewidth\": 3})\n",
    "ax = sns.barplot(x = np.array(features), y = principalComponents.explained_variance_ratio_,\n",
    "                 palette = \"bright\")\n",
    "\n",
    "plt.xlabel('PCA features', fontsize = 24)\n",
    "plt.ylabel('Variance %', fontsize = 24)\n",
    "plt.title('PCA Variance', fontsize = 24)\n",
    "plt.xticks(features, fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "\n",
    "# Function to add labels to bar chart\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.3f}\".format(y_value)\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            fontsize = '16',            # Font size\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values.\n",
    "\n",
    "# Call the function above\n",
    "add_value_labels(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of PCA components\n",
    "pca = PCA(n_components = 3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_components_train = pca_Fit_Transform(X_train_scaled)\n",
    "PCA_components_test = pca_Transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on training set\n",
    "number_cluster = 2\n",
    "kmeans = KMeans(n_clusters = number_cluster, init = 'k-means++', random_state = 10).fit(PCA_components_train)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3D Plot of Training Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "PCA_components_train['Cluster'] = pd.Series(labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "PCA_components_train['Cluster_Labels'] = PCA_components_train['Cluster'].map(cluster_label_names)  \n",
    "PCA_components_train.columns = [ 'PCA_1', \"PCA_2\", \"PCA_3\", \n",
    "                         'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = PCA_components_train , x = 'PCA_1',\n",
    "                  y = 'PCA_2', z = 'PCA_3', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the training set\n",
    "y_train_df = pd.Series(y_train)\n",
    "y_train_df = y_train_df.reset_index()\n",
    "PCA_components_train['Actual_Labels'] = pd.Series(y_train_df['Playing_after_6_months'], index = y_train_df.index)\n",
    "PCA_components_train['Cluster_Labels'] = PCA_components_train['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "PCA_acc_train = PCA_components_train['Actual_Labels'].eq(PCA_components_train['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the training set\n",
    "print(\"Accuracy : \" + str(PCA_acc_train[1]/(PCA_acc_train[0] + PCA_acc_train[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering on testing set\n",
    "predict_labels = kmeans.predict(PCA_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Plot of testing Data\n",
    "## Create and modify dataframe for the cluster column\n",
    "PCA_components_test['Cluster'] = pd.Series(predict_labels)\n",
    "\n",
    "## Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Subscribed\", 1: \"Churned\"}\n",
    "PCA_components_test['Cluster_Labels'] = PCA_components_test['Cluster'].map(cluster_label_names)  \n",
    "PCA_components_test.columns = [ 'PCA_1', \"PCA_2\", \"PCA_3\", \n",
    "                         'Cluster', 'Cluster_Labels']\n",
    "\n",
    "## Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = PCA_components_test , x = 'PCA_1',\n",
    "                  y = 'PCA_2', z = 'PCA_3', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Customer Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the testing set\n",
    "y_test_df = pd.Series(y_test)\n",
    "y_test_df = y_test_df.reset_index()\n",
    "PCA_components_test['Actual_Labels'] = pd.Series(y_test_df['Playing_after_6_months'], index = y_test_df.index)\n",
    "PCA_components_test['Cluster_Labels'] = PCA_components_test['Cluster_Labels'].map({'Subscribed': 0, 'Churned': 1})\n",
    "PCA_acc_test = PCA_components_test['Actual_Labels'].eq(PCA_components_test['Cluster_Labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of the testing set\n",
    "print(\"Accuracy : \" + str(PCA_acc_test[1]/(PCA_acc_test[0] + PCA_acc_test[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of accuracies of k-means clustering with and without PCA\n",
    "## Create an array and transpose values to make it a two-column format\n",
    "acc_values_train = [0.817253, 0.817253,\n",
    "        0.817221]\n",
    "\n",
    "acc_values_test = [0.816758, 0.816891,\n",
    "        0.816891]\n",
    "acc_values_test = np.array(acc_values_test)\n",
    "\n",
    "## Create table columns\n",
    "method = ['K-Means Clustering', 'PCA 2D + K-Means Clustering',\n",
    "                            'PCA 3D + K-Means Clustering',]\n",
    "    \n",
    "## Create plotly table object\n",
    "accuracy = go.Figure(data = [go.Table(\n",
    "    header = dict(values = [['Method'],['Accuracy', ['Training']], ['', ['Testing']]],\n",
    "                  line_color = 'darkslategray',\n",
    "                  fill_color = 'lightskyblue',\n",
    "                  align = 'left'),\n",
    "    cells = dict(values = [method, acc_values_train, acc_values_test],\n",
    "                 line_color = 'darkslategray',\n",
    "                 fill_color = 'lightcyan',\n",
    "                 align = 'left'))\n",
    "])\n",
    "\n",
    "accuracy.update_layout(width = 800, height = 500,\n",
    "                       title = 'Table 4: Accuracy of k-means clustering with and without using PCA.')\n",
    "accuracy.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival analysis establishes a healthy financial model for Blizzard. With lifetimes of ~215 days until churn, it allows for Blizzard to make a hefty sum of money before a person will unsubscribe. There is still unpredictability due to how censored the data is – many entries have not churned in the one-year period and cannot judge past the 365-day duration. The survival curves for each feature exhibit expected behavior such as having higher average playing hours, average playing density or being in a guild results in a lower churn ratio. Lastly, the binary classification performed in the best performing algorithm having a 96% ROC AUC score in predicting whether a customer will churn in six months. \n",
    "\n",
    "Possible future work includes:\n",
    "\n",
    "(1) Examine a three-year period to have more accurate analyses for survival analysis and six-month churn prediction.  \n",
    "\n",
    "(2) Study the performance of our algorithms with different playing patterns – does the data fit well for players who exhibit more playing time? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yeng-Ting Lee, Kuan-Ta Chen, Yun-Maw Cheng, and Chin-Laung Lei, \"World of Warcraft Avatar History Dataset,\" In Proceedings of ACM Multimedia Systems 2011, Feb 2011. \n",
    "* M. Oneil, \"myles-oneill/WoWAH-parser\", GitHub, 2020. [Online]. Available: https://github.com/myles-oneill/WoWAH-parser. [Accessed: 18- Mar- 2020]. \n",
    "\n",
    "*  L. Zhao et al., \"On the restricted mean survival time curve in survival analysis\", Biometrics, vol. 72, no. 1, pp. 215-221, 2015. Available: 10.1111/biom.12384. \n",
    "\n",
    "*  P. Royston and M. Parmar, \"Restricted mean survival time: an alternative to the hazard ratio for the design and analysis of randomized trials with a time-to-event outcome\", BMC Medical Research Methodology, vol. 13, no. 1, 2013. Available: 10.1186/1471-2288-13-152. \n",
    "\n",
    "*  \"Classification: ROC Curve and AUC |  Machine Learning Crash Course\", Google Developers, 2020. [Online]. Available: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc. [Accessed: 31- Mar- 2020]. \n",
    "\n",
    "* P. Burman, \"A Comparative Study of Ordinary Cross-Validation, v-Fold Cross-Validation and the Repeated Learning-Testing Methods\", Biometrika, vol. 76, no. 3, p. 503, 1989. Available: 10.2307/2336116. \n",
    "\n",
    "* C. Peng, K. Lee and G. Ingersoll, \"An Introduction to Logistic Regression Analysis and Reporting\", The Journal of Educational Research, vol. 96, no. 1, pp. 3-14, 2002. Available: 10.1080/00220670209598786. \n",
    "\n",
    "* S. Salcedo-Sanz, J. Rojo-Álvarez, M. Martínez-Ramón and G. Camps-Valls, \"Support vector machines in engineering: an overview\", Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 4, no. 3, pp. 234-267, 2014. Available: 10.1002/widm.1125. \n",
    "\n",
    "* Cunningham, Padraig & Delany, Sarah. (2007). k-Nearest neighbour classifiers. Mult Classif Syst. \n",
    "\n",
    "* L. Breiman, \"Random Forests\", Machine Learning, vol. 45, no. 3, pp. 261-277, 2001. Available: 10.1023/a:1017934522171. \n",
    "\n",
    "* P. Probst, M. Wright and A. Boulesteix, \"Hyperparameters and tuning strategies for random forest\", Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 9, no. 3, 2019. Available: 10.1002/widm.1301. \n",
    "\n",
    "* A. Tharwat, \"Principal component analysis - a tutorial\", International Journal of Applied Pattern Recognition, vol. 3, no. 3, p. 197, 2016. Available: 10.1504/ijapr.2016.079733. \n",
    "\n",
    "* \"Survey Report on K-Means Clustering Algorithm\", International Journal of Modern Trends in Engineering & Research, vol. 4, no. 4, pp. 218-221, 2017. Available: 10.21884/ijmter.2017.4143.lgjzd. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
