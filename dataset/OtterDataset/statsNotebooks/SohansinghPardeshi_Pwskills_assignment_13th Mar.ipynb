{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assmption in ANOVA:\n",
    "1. Normality of sampling distribution of mean -: The distribtuion of sampling mean is normally distributed\n",
    "2. Absence of outliers\n",
    "3. Homogenity of variance -: Each one of the popuation has the same variance\n",
    "4. Samples are independent and random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of ANOVA :\n",
    "1. One-Way ANOVA is used when there is only one  factor with two or more  independent levels (groups).\n",
    "2. Two-Way ANOVA (factorial anova ): Two-Way ANOVA is used when there are atlest two factors simultaneously influencing the dependent variable. All factors can have two or more levels. Levels can be either independent or dependent. \n",
    "3. Repeated Measure ANOVA : One factor with atleast two levels and levels are dependent . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variance observed in the data into different components that can be attributed to specific sources of variation. Understanding this concept is crucial because it allows researchers to assess the contributions of different factors to the overall variability in the data and to determine whether the observed differences among groups are statistically significant.\n",
    "\n",
    "In ANOVA, the total variability in the data is divided into two main components:\n",
    "\n",
    "1. Between-Group Variance (Systematic Variance): This component represents the variability in the dependent variable that can be attributed to the differences between the group means. It measures the effect of the independent variable(s) on the dependent variable. If this component is large relative to the within-group variance, it suggests that the groups are different from each other in a meaningful way.\n",
    "\n",
    "2. Within-Group Variance (Error Variance): This component represents the variability in the dependent variable within each group. It is also known as error variance because it includes random fluctuations and measurement error that are not accounted for by the independent variable(s). It reflects the inherent variability within each group.\n",
    "\n",
    "The partitioning of variance is achieved by calculating various sums of squares:\n",
    "\n",
    "- Total Sum of Squares (SST): This is the total variability in the data, computed as the sum of squared differences between each data point and the overall mean of all data points.\n",
    "\n",
    "- Between-Group Sum of Squares (SSB): This represents the variability attributed to differences between the group means. It is calculated as the sum of squared differences between each group mean and the overall mean.\n",
    "\n",
    "- Within-Group Sum of Squares (SSW): This represents the variability within each group. It is calculated as the sum of squared differences between each data point and its respective group mean.\n",
    "\n",
    "Once the sums of squares are calculated, degrees of freedom are also determined, and the Mean Squares (MS) are calculated by dividing the sums of squares by their respective degrees of freedom. Then, F-ratio is computed by dividing the Mean Square for Between-Groups by the Mean Square for Within-Groups. The F-ratio is used to test whether the group means are significantly different from each other.\n",
    "\n",
    "The importance of understanding the partitioning of variance in ANOVA lies in its ability to:\n",
    "\n",
    "1. Assess the significance of the effects of different factors: By comparing the Between-Group Variance to the Within-Group Variance using the F-ratio, ANOVA determines if the differences between the group means are statistically significant.\n",
    "\n",
    "2. Identify the relative importance of factors: Partitioning the variance helps researchers understand how much of the variability in the dependent variable can be attributed to the independent variable(s) being studied.\n",
    "\n",
    "3. Interpret the results: Understanding the contributions of different sources of variation helps in interpreting the outcomes of ANOVA and drawing meaningful conclusions from the data.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA is a fundamental concept that aids in understanding the relationships between the independent and dependent variables, identifying significant differences among groups, and making valid inferences from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can use the scipy.stats module, which provides functions to perform ANOVA calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference between groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data for three groups (replace these with your own data)\n",
    "group1 = np.array([10, 15, 20, 25, 30])\n",
    "group2 = np.array([5, 10, 15, 20, 25])\n",
    "group3 = np.array([20, 25, 30, 35, 40])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "statistic, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference between groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effects:\n",
      "Group[T.B]        -5.0\n",
      "Group[T.C]        10.0\n",
      "Treatment[T.Y]     5.0\n",
      "Treatment[T.Z]    10.0\n",
      "dtype: float64\n",
      "\n",
      "Interaction Effect:\n",
      "-6.401761139798435e-15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data as a pandas DataFrame (replace these with your own data)\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Treatment': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'Values': [10, 15, 20, 5, 10, 15, 20, 25, 30]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Values ~ Group + Treatment + Group:Treatment', data=data).fit()\n",
    "\n",
    "# Get the main effects\n",
    "main_effects = model.params[['Group[T.B]', 'Group[T.C]', 'Treatment[T.Y]', 'Treatment[T.Z]']]\n",
    "\n",
    "# Get the interaction effect\n",
    "interaction_effect = model.params['Group[T.B]:Treatment[T.Y]']\n",
    "\n",
    "print(\"Main Effects:\")\n",
    "print(main_effects)\n",
    "\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences between the means of two or more groups. The p-value associated with the F-statistic helps determine the statistical significance of the observed differences. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "\n",
    "Interpreting the results:\n",
    "\n",
    "1. F-Statistic: The F-statistic is a measure of the variation between the sample means relative to the variation within the samples. A larger F-statistic suggests that the variation between the group means is more significant compared to the variation within the groups. In your case, the F-statistic is 5.23.\n",
    "\n",
    "2. P-Value: The p-value is the probability of obtaining results as extreme as the observed ones, assuming that there are no real differences between the groups (null hypothesis). A small p-value (typically less than the chosen significance level, commonly 0.05) indicates that there is strong evidence against the null hypothesis, suggesting that the observed differences between the groups are unlikely to have occurred by chance. In your case, the p-value is 0.02.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Based on the results you provided:\n",
    "\n",
    "1. Since the p-value (0.02) is less than the typical significance level of 0.05, we reject the null hypothesis. This means that there is a statistically significant difference between the means of the groups.\n",
    "\n",
    "2. The F-statistic (5.23) being greater than 1 suggests that the variation between the group means is larger than the variation within the groups, further supporting the idea that the groups are different.\n",
    "\n",
    "Overall, the results suggest that there are significant differences between the groups based on the variable being analyzed. However, to understand the nature of these differences and which specific groups are different from each other, additional post-hoc tests or pairwise comparisons would be needed. These tests can help identify which group means are significantly different from one another.\n",
    "\n",
    "Keep in mind that statistical significance does not necessarily imply practical or meaningful significance. It's essential to consider the context and practical implications of the results when drawing conclusions from an ANOVA analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity and accuracy of the analysis. Missing data can arise due to various reasons, such as participants dropping out of the study, technical errors, or incomplete responses. There are several methods to handle missing data in repeated measures ANOVA, and the choice of method can impact the results and conclusions. Here are some common approaches:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "This method involves excluding any participant with missing data on any variable used in the analysis. While it is straightforward to implement, it may lead to a loss of statistical power if a significant number of cases are excluded. It can also introduce bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "Mean Imputation:\n",
    "Missing values in each group or condition are replaced with the mean of the available data for that group. While this approach preserves the sample size, it can underestimate the variance and produce biased estimates of the treatment effects, especially when data are not MCAR.\n",
    "\n",
    "Last Observation Carried Forward (LOCF):\n",
    "Missing values are replaced with the last observed value for that participant. This approach can introduce bias if there is a trend in the data, as it assumes that the missing values are similar to the last observed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity and accuracy of the analysis. Missing data can arise due to various reasons, such as participants dropping out of the study, technical errors, or incomplete responses. There are several methods to handle missing data in repeated measures ANOVA, and the choice of method can impact the results and conclusions. Here are some common approaches:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "This method involves excluding any participant with missing data on any variable used in the analysis. While it is straightforward to implement, it may lead to a loss of statistical power if a significant number of cases are excluded. It can also introduce bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "Mean Imputation:\n",
    "Missing values in each group or condition are replaced with the mean of the available data for that group. While this approach preserves the sample size, it can underestimate the variance and produce biased estimates of the treatment effects, especially when data are not MCAR.\n",
    "\n",
    "Last Observation Carried Forward (LOCF):\n",
    "Missing values are replaced with the last observed value for that participant. This approach can introduce bias if there is a trend in the data, as it assumes that the missing values are similar to the last observed value.\n",
    "\n",
    "Potential consequences of using different methods:\n",
    "\n",
    "Complete Case Analysis: This method may lead to biased results if the missing data are not MCAR. It can reduce the sample size and statistical power of the analysis.\n",
    "\n",
    "Mean Imputation: This method can produce biased estimates and artificially reduce the variance in the data, leading to an inflated Type I error rate.\n",
    "\n",
    "LOCF: This approach can lead to biased estimates, especially if there is a trend in the data or the missing data are not MCAR.\n",
    "\n",
    "Multiple Imputation: Multiple imputation generally provides more accurate and unbiased estimates compared to single imputation methods. However, it requires more complex analysis and may not fully address the effects of non-ignorable missing data.\n",
    "\n",
    "MLE: MLE is a powerful approach that accounts for the uncertainty associated with missing data. It can produce more accurate estimates, assuming the missing data mechanism is correctly modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "After conducting an ANOVA and finding a significant overall effect (i.e., rejecting the null hypothesis that all group means are equal), post-hoc tests are used to determine which specific group means differ significantly from each other. There are several post-hoc tests available, and the choice of the appropriate test depends on the study design and assumptions. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) Test:\n",
    "   Tukey's HSD test is used when the sample sizes are equal and the groups have equal variances. It controls the family-wise error rate, making it suitable for situations where multiple pairwise comparisons are being performed.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "   The Bonferroni correction adjusts the significance level for each individual comparison to maintain a desired overall level of significance. It is conservative but appropriate when performing a large number of comparisons.\n",
    "\n",
    "3. Scheffe's Test:\n",
    "   Scheffe's test is more conservative and can be used for unequal sample sizes and unequal variances. It is appropriate when the assumptions of equal sample sizes and equal variances are violated.\n",
    "\n",
    "4. Sidak Correction:\n",
    "   The Sidak correction is another method to adjust the significance level for multiple comparisons. It is less conservative than Bonferroni but still controls the family-wise error rate.\n",
    "\n",
    "5. Dunn's Test (or Dunn's Multiple Comparison Test):\n",
    "   Dunn's test is a non-parametric alternative to Tukey's HSD for situations where the assumptions of normality and equal variances are not met.\n",
    "\n",
    "6. Games-Howell Test:\n",
    "   The Games-Howell test is a robust post-hoc test used when the assumption of equal variances is violated, and sample sizes may be unequal.\n",
    "\n",
    "Example of when a post-hoc test might be necessary:\n",
    "\n",
    "Let's say a researcher conducted a study to compare the effectiveness of three different treatments (A, B, and C) on reducing anxiety levels in participants. After running a one-way ANOVA, they obtained a significant result, indicating that at least one of the treatments has a different effect on anxiety levels. However, the researcher is not sure which specific treatments differ significantly from each other.\n",
    "\n",
    "In this scenario, a post-hoc test like Tukey's HSD, Bonferroni, or Games-Howell could be used to perform pairwise comparisons between the treatment groups and identify which treatments have significantly different effects on anxiety levels. The post-hoc test would help the researcher draw more specific conclusions about the effectiveness of each treatment and determine if there are any meaningful differences between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference between the mean weight loss of the diets.\n",
      "\n",
      "F-Statistic: 633.3100407055613\n",
      "p-value: 5.602349701095334e-73\n",
      "3.057620651649394\n",
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "# Sample weight loss data for each diet (replace these with your own data)\n",
    "diet_A = np.array([5.1, 4.8, 5.2, 4.9, 5.5, 5.3, 4.7, 5.0, 5.4, 5.6,\n",
    "                   5.1, 4.8, 5.2, 4.9, 5.5, 5.3, 4.7, 5.0, 5.4, 5.6,\n",
    "                   5.1, 4.8, 5.2, 4.9, 5.5, 5.3, 4.7, 5.0, 5.4, 5.6,\n",
    "                   5.1, 4.8, 5.2, 4.9, 5.5, 5.3, 4.7, 5.0, 5.4, 5.6,\n",
    "                   5.1, 4.8, 5.2, 4.9, 5.5, 5.3, 4.7, 5.0, 5.4, 5.6])\n",
    "diet_B = np.array([4.5, 4.2, 4.6, 4.3, 4.7, 4.8, 4.2, 4.4, 4.5, 4.3,\n",
    "                   4.5, 4.2, 4.6, 4.3, 4.7, 4.8, 4.2, 4.4, 4.5, 4.3,\n",
    "                   4.5, 4.2, 4.6, 4.3, 4.7, 4.8, 4.2, 4.4, 4.5, 4.3,\n",
    "                   4.5, 4.2, 4.6, 4.3, 4.7, 4.8, 4.2, 4.4, 4.5, 4.3,\n",
    "                   4.5, 4.2, 4.6, 4.3, 4.7, 4.8, 4.2, 4.4, 4.5, 4.3])\n",
    "diet_C = np.array([6.0, 5.8, 6.2, 6.1, 5.9, 6.3, 6.0, 5.8, 6.2, 6.1,\n",
    "                   6.0, 5.8, 6.2, 6.1, 5.9, 6.3, 6.0, 5.8, 6.2, 6.1,\n",
    "                   6.0, 5.8, 6.2, 6.1, 5.9, 6.3, 6.0, 5.8, 6.2, 6.1,\n",
    "                   6.0, 5.8, 6.2, 6.1, 5.9, 6.3, 6.0, 5.8, 6.2, 6.1,\n",
    "                   6.0, 5.8, 6.2, 6.1, 5.9, 6.3, 6.0, 5.8, 6.2, 6.1])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference between the mean weight loss of the diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between the mean weight loss of the diets.\")\n",
    "\n",
    "print(\"\\nF-Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "f_table = stat.f.ppf(0.95,2,147)\n",
    "print(f_table)\n",
    "\n",
    "\n",
    "if f_table > statistic  :\n",
    "    print(\"accept null hypothesis\")\n",
    "else:\n",
    "    print(\"reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df      sum_sq    mean_sq         F    PR(>F)\n",
      "C(Software)                 2.0    9.411111   4.705556  0.330585  0.721723\n",
      "C(Experience)               1.0    0.532964   0.532964  0.037443  0.848194\n",
      "C(Software):C(Experience)   2.0   19.405924   9.702962  0.681674  0.515295\n",
      "Residual                   24.0  341.616667  14.234028       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data as a pandas DataFrame (replace these with your own data)\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A'],\n",
    "    'Experience': ['Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Experienced', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Novice', 'Novice', 'Experienced', 'Novice', 'Experienced', 'Experienced'],\n",
    "    'Time': [12, 15, 13, 18, 19, 17, 14, 16, 13, 20, 22, 19, 17, 16, 18, 21, 20, 19, 14, 12, 11, 17, 16, 18, 15, 14, 13, 23, 25, 22]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference in test scores between the two groups.\n",
      "\n",
      "t-statistic: -3.2112255699432195\n",
      "p-value: 0.0026899259927753803\n",
      "\n",
      "Tukey's HSD Test Results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental     5.35 0.0027 1.9773 8.7227   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data (replace these with your own data)\n",
    "control_group = [78, 85, 79, 90, 70, 88, 82, 75, 80, 81, 72, 74, 76, 77, 84, 87, 86, 73, 80, 89]\n",
    "experimental_group = [85, 88, 92, 78, 86, 79, 90, 93, 82, 91, 84, 87, 80, 83, 85, 89, 91, 86, 81, 83]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Interpret the results of the t-test\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "print(\"\\nt-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc Tukey's HSD test (if results are significant)\n",
    "if p_value < alpha:\n",
    "    # Combine data from both groups and create a corresponding group label\n",
    "    data = pd.DataFrame({'Test_Score': control_group + experimental_group,\n",
    "                         'Group': ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)})\n",
    "\n",
    "    # Perform Tukey's HSD test\n",
    "    tukey_result = pairwise_tukeyhsd(data['Test_Score'], data['Group'])\n",
    "\n",
    "    # Print the results of Tukey's HSD test\n",
    "    print(\"\\nTukey's HSD Test Results:\")\n",
    "    print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. There is a significant difference in daily sales between the three stores.\n",
      "\n",
      "F-statistic: 14.06060606060606\n",
      "p-value: 5.114811158531271e-06\n",
      "\n",
      "Tukey's HSD Test Results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B    -10.0 0.0255 -18.993  -1.007   True\n",
      "     A      C    -20.0    0.0 -28.993 -11.007   True\n",
      "     B      C    -10.0 0.0255 -18.993  -1.007   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data (replace these with your own data)\n",
    "store_A_sales = np.array([100, 105, 110, 115, 120, 125, 130, 135, 140, 145,\n",
    "                          100, 105, 110, 115, 120, 125, 130, 135, 140, 145,\n",
    "                          100, 105, 110, 115, 120, 125, 130, 135, 140, 145])\n",
    "store_B_sales = np.array([90, 95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
    "                          90, 95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
    "                          90, 95, 100, 105, 110, 115, 120, 125, 130, 135])\n",
    "store_C_sales = np.array([80, 85, 90, 95, 100, 105, 110, 115, 120, 125,\n",
    "                          80, 85, 90, 95, 100, 105, 110, 115, 120, 125,\n",
    "                          80, 85, 90, 95, 100, 105, 110, 115, 120, 125])\n",
    "\n",
    "# Combine data from all three stores and create corresponding group labels\n",
    "data = pd.DataFrame({'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales]),\n",
    "                     'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Interpret the results of the one-way ANOVA\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference in daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in daily sales between the three stores.\")\n",
    "\n",
    "print(\"\\nF-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc Tukey's HSD test (if results are significant)\n",
    "if p_value < alpha:\n",
    "    # Perform Tukey's HSD test\n",
    "    tukey_result = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "    # Print the results of Tukey's HSD test\n",
    "    print(\"\\nTukey's HSD Test Results:\")\n",
    "    print(tukey_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
