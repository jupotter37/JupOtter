{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f2a152-11c1-40ca-a46a-bdcbf612708f",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "ANOVA, or Analysis of Variance is a parametric statistical technique that helps in finding out if there is a significant difference between the mean of three or more groups. It checks the impact of various factors by comparing groups (samples) based on their respective mean. \n",
    "\n",
    "Assumptions for ANOVA:\n",
    "1. The dependent variable is approximately normally distributed within each group. This assumption is more critical for smaller sample sizes.\n",
    "2. The samples are selected at random and should be independent of one another.\n",
    "3. All groups have equal standard deviations.\n",
    "4. Each data point should belong to one and only one group. There should be no overlap or sharing of data points between groups.\n",
    "\n",
    "Violations of the assumptions underlying ANOVA (Analysis of Variance) can impact the validity of the results. Here are some examples of violations that could affect the validity of ANOVA results:\n",
    "\n",
    "1. Homogeneity: When the variances of the groups being compared are not equal. Violation of homogeneity of variances can lead to inaccurate F-test results and affect the validity of the overall ANOVA analysis. It may inflate the Type I error rate and decrease the power of the test.\n",
    "2. Normality: When the residuals (the differences between observed and predicted values) from each group do not follow a normal distribution. Departure from normality can lead to biased estimates of group means and affect the precision and accuracy of ANOVA results. It may also influence the Type I error rate and confidence intervals.\n",
    "3. Independence: When observations within groups are not independent, such as in repeated measures designs or clustered data. Violating the independence assumption can lead to incorrect standard errors, inflated Type I error rates, and biased F-test results. It may also affect the interpretation of group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc584fc7-f410-4e06-88d3-44e2b0a33e89",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "There are three main types of ANOVA, each suitable for different experimental designs and research questions:\n",
    "\n",
    "1. One-Way ANOVA:\n",
    "\n",
    "- One-way ANOVA is used when there is one independent variable (factor) with three or more levels (groups). It determines whether there are statistically significant differences in the means of the dependent variable across the different levels of the independent variable.\n",
    "\n",
    "- Example: Comparing the effectiveness of three different teaching methods (levels of the independent variable) on student test scores (dependent variable).\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "\n",
    "- Two-way ANOVA is used when there are two independent variables (factors) and one dependent variable. It examines the main effects of each independent variable as well as their interaction effect.\n",
    "- Example: Investigating the effects of both gender and treatment type (two independent variables) on patient recovery time (dependent variable).\n",
    "\n",
    "3. Repeated Measures ANOVA:\n",
    "\n",
    "- Repeated Measures ANOVA is used when the same subjects are measured under different conditions or at different time points. It assesses within-subject differences across the repeated measures.\n",
    "- Example: Analyzing the effect of a training program on participants' performance by measuring their scores before training, immediately after training, and one month after training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ebf51-ee31-4584-a443-c44cd867bfbe",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the decomposition of the total variability observed in the data into different components that can be attributed to specific sources, such as between-group differences and within-group variation. \n",
    "\n",
    "- By partitioning the total variance into between-group variance and within-group variance, ANOVA helps researchers understand the relative contribution of different factors or groups to the overall variability in the data. This insight can inform decisions about which factors are most influential and merit further investigation.\n",
    "- ANOVA compares the magnitude of between-group variance to within-group variance to determine whether the observed differences among groups are statistically significant. By understanding how the total variance is partitioned, researchers can assess the significance of group differences and make valid inferences about the effects of independent variables on the dependent variable.\n",
    "- ANOVA provides valuable information about the sources of variability in the data, which enhances the interpretation of hypothesis tests. For example, if a significant difference is found between groups, understanding the partitioning of variance can help identify which specific groups or factors are driving the observed differences.\n",
    "- Partitioning the variance allows researchers to identify areas of interest for further analysis or research. For example, if a large proportion of the total variance is explained by between-group differences, it may indicate that the independent variable(s) under investigation have a substantial impact on the dependent variable, warranting further exploration or experimental manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d8db0-2117-4a5e-a95c-b414b0e58f5e",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a2d70b-3074-4772-ad46-08228e79968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of iris dataset\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "Value of sepal length vs species\n",
      "SSR: 38.9562\n",
      "SSE: 63.21213333333335\n",
      "SST: 102.16833333333335\n",
      "             df     sum_sq    mean_sq           F        PR(>F)\n",
      "species     2.0  63.212133  31.606067  119.264502  1.669669e-31\n",
      "Residual  147.0  38.956200   0.265008         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.anova  import anova_lm\n",
    "\n",
    "#loading Iris dataset\n",
    "\n",
    "df_iris = sns.load_dataset('iris')\n",
    "print('Top 5 rows of iris dataset')\n",
    "print(df_iris.head())\n",
    "\n",
    "#fitting the anova model\n",
    "model = ols('sepal_length ~ species', data = df_iris).fit()\n",
    "\n",
    "#calculating SST, SSE and SSR\n",
    "print('Value of sepal length vs species')\n",
    "SSR = model.ssr\n",
    "SSE = model.ess\n",
    "SST = SSR + SSE\n",
    "\n",
    "print('SSR:', SSR)\n",
    "print('SSE:', SSE)\n",
    "print('SST:', SST)\n",
    "\n",
    "print(anova_lm(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bb9c1-c157-403c-8d54-9009b9ce17c8",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8c51ff2-ad24-41bb-acb1-9e7d6d7838d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of the Iris dataset\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Main effects\n",
      "                       sum_sq    df             F        PR(>F)\n",
      "C(species)       6.909412e-12   2.0  3.292629e-11  9.999954e-01\n",
      "C(petal_length)  3.550098e+02  42.0  8.056061e+01  1.889577e-36\n",
      "\n",
      "------------\n",
      "\n",
      "Interaction effects\n",
      "                               sum_sq    df         F        PR(>F)\n",
      "C(species):C(petal_length)  84.879528  84.0  9.630644  2.764512e-20\n",
      "\n",
      "------------\n",
      "\n",
      "                                  sum_sq     df             F        PR(>F)\n",
      "C(species)                  6.909412e-12    2.0  3.292629e-11  9.999954e-01\n",
      "C(petal_length)             3.550098e+02   42.0  8.056061e+01  1.889577e-36\n",
      "C(species):C(petal_length)  8.487953e+01   84.0  9.630644e+00  2.764512e-20\n",
      "Residual                    1.070209e+01  102.0           NaN           NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 42, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 84, but rank is 39\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 42, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 84, but rank is 39\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 42, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 84, but rank is 39\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "df = sns.load_dataset('iris')\n",
    "print('Top 5 rows of the Iris dataset')\n",
    "print(df.head())\n",
    "print('\\n-------------------------------------\\n')\n",
    "\n",
    "model = ols(' sepal_length ~ C(species) + C(petal_length) + C(species):C(petal_length)', data=df).fit()\n",
    "\n",
    "main_effects = anova_lm(model, typ=2)[:2]\n",
    "interaction_eff = anova_lm(model,typ=2)[2:3]\n",
    "\n",
    "print('Main effects')\n",
    "print(main_effects)\n",
    "print('\\n------------\\n')\n",
    "print('Interaction effects')\n",
    "print(interaction_eff)\n",
    "print('\\n------------\\n')\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7bc85-44a9-42cf-b0cf-11e40e8bd79c",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Based on the provided F-statistic of 5.23 and a p-value of 0.02, the F-statistic suggests that there is some evidence of differences between the group means. The p-value of 0.02 indicates that the probability of observing the data if there were no differences between the group means is 0.02, which is less than the typical significance level of 0.05. Therefore, we would reject the null hypothesis and conclude that there are statistically significant differences between at least two of the groups. \n",
    "\n",
    "In summary, the results suggest that there are significant differences between the groups, but further post-hoc tests or additional analysis may be needed to determine which specific groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74cfad-604d-413c-bcec-876dcb9167f4",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "\n",
    "In repeated measures ANOVA, missing data can arise due to various reasons such as participant dropout, technical errors, or incomplete responses. Handling missing data appropriately is crucial to ensure the validity and reliability of the analysis. Here are some common methods for handling missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (CCA):\n",
    "- In CCA, any case with missing data in any variable is excluded from the analysis.\n",
    "- It's straightforward and easy to implement.\n",
    "- This method can lead to biased estimates if missingness is related to the outcome or other variables in the analysis. It can also reduce statistical power if a large portion of the data is missing.\n",
    "\n",
    "2. Mean Imputation:\n",
    "\n",
    "- Mean imputation involves replacing missing values with the mean of the observed values for that variable.\n",
    "- It preserves the sample size and can provide unbiased estimates if data are missing completely at random (MCAR).\n",
    "- It can underestimate the standard errors, leading to inflated Type I error rates. It also assumes that the missing data have the same mean as the observed data, which may not always be true.\n",
    "\n",
    "3. Last Observation Carried Forward (LOCF):\n",
    "\n",
    "- OCF involves using the last observed value for a participant to replace missing values in subsequent time points.\n",
    "- It's simple and maintains the time sequence of the data.\n",
    "- It can lead to biased estimates if missingness is related to changes over time or if there's a trend in the data. It may also overestimate treatment effects, especially in longitudinal studies with dropout.\n",
    "\n",
    "4. Multiple Imputation:\n",
    "\n",
    "- Multiple imputation generates several plausible values for each missing observation, based on the observed data and the estimated uncertainty.\n",
    "- It provides more accurate estimates compared to single imputation methods and properly accounts for uncertainty due to missing data.\n",
    "- It's computationally intensive and may require additional assumptions about the missing data mechanism. It can also be challenging to implement correctly.\n",
    "\n",
    "5. Model-Based Imputation:\n",
    "\n",
    "- Model-based imputation involves using regression or other statistical models to predict missing values based on observed data.\n",
    "- It can provide more accurate imputations by incorporating information from other variables.\n",
    "- It relies on the assumption that the model used for imputation accurately represents the relationship between variables, which may not always be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9b0b3-7234-4cd5-9d28-ba623f6b1ffc",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "After conducting an Analysis of Variance (ANOVA) and finding a significant difference between groups, it's common to perform post-hoc tests to determine which specific groups differ from each other. There are several post-hoc tests available, each with its own assumptions and appropriate use cases. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "- Use when you have equal group sizes and homogeneity of variances.\n",
    "- It's conservative, meaning it controls the family-wise error rate.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "\n",
    "- Use when you have unequal group sizes or violations of homogeneity of variances.\n",
    "- It's more conservative than Tukey's HSD and controls the family-wise error rate by adjusting the significance threshold for multiple comparisons.\n",
    "\n",
    "3. Scheffe's test: \n",
    "\n",
    "- This test also controls the family-wise error rate but is more conservative than Tukey's HSD test. \n",
    "- It is often used when the number of groups is large, and when there is no prior knowledge about which groups differ.\n",
    "\n",
    "4. Duncan's New Multiple Range Test:\n",
    "\n",
    "- Use when you have unequal group sizes and homogeneity of variances.\n",
    "- It's less conservative than Tukey's HSD but still controls the Type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8507b-d343-4399-818a-037828527641",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352996f4-f361-433a-aac4-1d10bfc5916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic =  140.82403794251056\n",
      "P_value =  6.893019806567957e-35\n",
      "We reject the null hypothesis\n",
      "The mean weight loss is not same of the three diets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "diet_a = np.random.normal(5,1,50)\n",
    "diet_b = np.random.normal(4,1,50)\n",
    "diet_c = np.random.normal(2,1,50)\n",
    "\n",
    "f_statistic, p_value = f_oneway(diet_a,diet_b,diet_c)\n",
    "\n",
    "null_hypo = \"The mean weight loss is same for all the three diets\"\n",
    "alternate_hypo = \"The mean weight loss is not same of the three diets\"\n",
    "\n",
    "print('F-statistic = ', f_statistic)\n",
    "print('P_value = ', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value<alpha:\n",
    "    print('We reject the null hypothesis')\n",
    "    print(alternate_hypo)\n",
    "else:\n",
    "    print('We failed to reject the null hypothesis')\n",
    "    print(null_hypo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dff624-87b7-4d4e-878c-7009e511231d",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e02cac-ae60-48c4-a0df-075864ec4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "-----------------------\n",
      "\n",
      "                             df      sum_sq  ...          F        PR(>F)\n",
      "C(Software)                 2.0  204.881181  ...  18.135666  8.460472e-07\n",
      "C(Experience)               1.0  165.079097  ...  29.224933  1.375177e-06\n",
      "C(Software):C(Experience)   2.0   17.481552  ...   1.547431  2.217544e-01\n",
      "Residual                   56.0  316.319953  ...        NaN           NaN\n",
      "\n",
      "[4 rows x 5 columns]\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Conclusion: There is significant main effect of Software\n",
      "Conclusion: There is significant main effect of Experience\n",
      "Conclusion: There is no significant main effect of Software and Experience\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "time_novice = np.random.normal(15, 2, 30)\n",
    "time_expert = np.random.normal(10, 2, 30)\n",
    "\n",
    "df = pd.DataFrame({'Software':['A']*20 + ['B']*20 + ['C']*20,\n",
    "                 'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "                  'Time': list(time_novice)+list(time_expert)})\n",
    "print('Dataset:')\n",
    "print(df.head())\n",
    "print('\\n-----------------------\\n')\n",
    "\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software): C(Experience)', data = df).fit()\n",
    "\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "print(table)\n",
    "print('\\n-----------------------\\n')\n",
    "if table['PR(>F)'][0]< alpha:\n",
    "    print('Conclusion: There is significant main effect of Software')\n",
    "else:\n",
    "    print('Conclusion: There is no significant main effect of Software')\n",
    "\n",
    "if table['PR(>F)'][1]< alpha:\n",
    "    print('Conclusion: There is significant main effect of Experience')\n",
    "else:\n",
    "    print('Conclusion: There is no significant main effect of Experience')\n",
    "\n",
    "if table['PR(>F)'][2]< alpha:\n",
    "    print('Conclusion: There is significant main effect of Software and Experience')\n",
    "else:\n",
    "    print('Conclusion: There is no significant main effect of Software and Experience')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd0185-f4b5-484e-bd40-428612d27cdb",
   "metadata": {},
   "source": [
    "Here are the interpretations of the three conclusions:\n",
    "\"There is a significant main effect of software\": This means that the software programs used by the employees have a significant impact on the outcome variable (e.g., completion time), independent of the experience level of the employees. This suggests that the choice of software program is an important factor that should be considered carefully when completing this task.\n",
    "\n",
    "\"There is a significant main effect of experience\": This means that the experience level of the employees has a significant impact on the outcome variable, independent of the software program used. Specifically, this suggests that experienced employees may complete the task faster than novices, or vice versa. This finding can be helpful for the company to identify the best employees for a given task and to provide appropriate training for new employees.\n",
    "\n",
    "\"There is NO significant interaction effect between software and experience\": This means that the effect of software on the outcome variable does not depend on the experience level of the employees, and vice versa. This suggests that the software programs perform similarly for both novices and experienced employees. This finding can be helpful for the company to decide which software program to use, as they do not need to consider the experience level of the employees when making the choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2d02a-030b-48e7-97fc-ca79ce71b573",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9e121c-4814-43c7-95f3-9639581920bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   test_score Teaching_method\n",
      "0   70.079124         Control\n",
      "1   70.780965         Control\n",
      "2   68.814563         Control\n",
      "3   69.387097         Control\n",
      "4   66.185102         Control\n",
      "\n",
      "-------------\n",
      "\n",
      "Statistic -1.5847354411553825\n",
      "P_value 0.11624822250929473\n",
      "We failed to reject the null hypothesis\n",
      "There is no significant difference in test scores between two groups\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(45)\n",
    "\n",
    "test_score_control = np.random.normal(70,3,50)\n",
    "test_score_experimental = np.random.normal(70,3,50)\n",
    "\n",
    "df = pd.DataFrame({'test_score': list(test_score_control)+list(test_score_experimental),\n",
    "                  'Teaching_method': ['Control']*50 + ['experimental']*50})\n",
    "print('Dataset:')\n",
    "print(df.head())\n",
    "print('\\n-------------\\n')\n",
    "\n",
    "null_hypo = 'There is no significant difference in test scores between two groups'\n",
    "alternate_hypo = 'There is significant difference in test scores between two groups'\n",
    "\n",
    "statistic, p_value = stats.ttest_ind(test_score_control, test_score_experimental, equal_var=True)\n",
    "\n",
    "print('Statistic', statistic)\n",
    "print('P_value', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value<alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "    print(alternate_hypo)\n",
    "else:\n",
    "    print('We failed to reject the null hypothesis')\n",
    "    print(null_hypo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e756d-04c0-432d-b5db-218f8a814287",
   "metadata": {},
   "source": [
    "Tukey's HSD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4667abff-b27c-4c96-97c3-ff382f843b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj   lower  upper  reject\n",
      "----------------------------------------------------------\n",
      "Control experimental   0.8829 0.1162 -0.2227 1.9886  False\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey_result =  pairwise_tukeyhsd(df['test_score'], df['Teaching_method'], 0.05)\n",
    "print(tukey_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082562f6-fa44-4572-b51e-90590924a0b5",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f832338-675a-4ffc-98d6-886723697203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "================================================\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n================================================\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba17a86-41a4-4282-b028-941148d5f4b9",
   "metadata": {},
   "source": [
    "Interpretation of above\n",
    "In Repeated Measure ANOVA test we got p_value (Pr>F) as 0.0000 which is less than 0.05 .Reject the Null Hypothesis .Which means atleast one of the mean of groups is different.\n",
    "\n",
    "In Tukey's Post Hoc Test we get following interpretation :\n",
    "\n",
    "No significant difference between sales of Store A and Store B. Store B earns 21.24 dollars more than store A(becuse reject=False for this)\n",
    "Significant difference between sales of Store A and Store C . Store C has approx 207.8 dollars lesser compared to store A (reject=True)\n",
    "Siginficant difference between sales of Store B and Store C . Store C has approx 229.0 dollars lesser compared to store B (reject=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74449791-0d6a-4a2e-b0b9-7982b6a3e454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
