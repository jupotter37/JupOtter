{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 7: Hypothesis and Inference\n",
    "Notes on \"Data Science from Scratch\" by Joel Grus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statistical Hypothesis Testing\n",
    "Example hypotheses:\n",
    "- \"this coin is fair\"\n",
    "- \"data scientists prefer Python to R\"\n",
    "- \"people are more likely to navigate away from the page without ever reading the content if we pop up an irritating interstitial advertisement with a tiny, hard-to-find close button\"\n",
    "\n",
    "Let's define:\n",
    "- $H_0$: **null hypothesis** that represents the \"default\" position\n",
    "- $H_1$: **alternative hypothesis** that we'll compare $H_0$ with\n",
    "\n",
    "We'll use statistics to decide whether we can reject the null hypothesis ($H_0$) or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example: Flipping a Coin\n",
    "\"1.\" **Identify a question or problem**: We have a coin and want to test whether it's fair.\n",
    "    - $p$: probability that the coin lands on heads\n",
    "    - $H_0$: the coin **is** fair ($\\,p = 0.5$)\n",
    "    - $H_1$: the coin **is not** fair ($\\,p \\ne 0.5$)\n",
    "    \n",
    "    \n",
    "\"2.\" **Collect relevant data on the topic**: We flip the coin some number $n$ times and count the number of heads $X$.\n",
    "    - If we assume that each flip of the coin has only two possible outcomes, that the probability of getting heads is the same for each flip, and that the flips are independent of each other, then we can treat each coin flip as a *Bernoulli trial*.\n",
    "    - Thus, $X$ is a binomial random variable.\n",
    "    - Thus, we can approximate $X$ using the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(n, p):\n",
    "    \"\"\"finds mu and sigma corresponding to a Binomial(n, p)\"\"\"\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_cdf(x, mu=0, sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "# the normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "# it's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo, mu=0, sigma=1):\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
    "    \"\"\"find approximate inverse using binary search\"\"\"\n",
    "    \n",
    "    # if not standard, compute standard and rescale\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
    "    \n",
    "    low_z, low_p = -10.0, 0           # normal_cdf(-10) is (very close to) 0\n",
    "    hi_z, hi_p   =  10.0, 1           # normal_cdf(10) is (very close to) 1\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2    # consider the midpoint\n",
    "        mid_p = normal_cdf(mid_z)     # and the cdf's value there\n",
    "        if mid_p < p:\n",
    "            # midpoint is still too low, search above it\n",
    "            low_z, low_p = mid_z, mid_p\n",
    "        elif mid_p > p:\n",
    "            # midpoint is still too high, search below it\n",
    "            hi_z, hi_p = mid_z, mid_p\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return mid_z\n",
    "\n",
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds\n",
    "    that contain the specified probability\"\"\"\n",
    "    tail_probability = (1 - probability) / 2\n",
    "    \n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "    \n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"3.\" **Analyze the data (perform tests)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_0 = 500.0\n",
      "sigma_0 = 15.811388300841896\n"
     ]
    }
   ],
   "source": [
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "print(\"mu_0 =\", mu_0)\n",
    "print(\"sigma_0 =\", sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469.01026640487555, 530.9897335951244)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8865480012953671"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% bounds based on assumption p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "# actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "\n",
    "# a type 2 error means we fail to reject th enull hypothesis\n",
    "# which will happen when X is still in our original interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526.0073585242053"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "hi\n",
    "# is < 531, since we need more probability in the upper tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363794803307173"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p-values* way:\n",
    "- choose bounds based on some probability cutoff\n",
    "- compute the probability - assuming $H_0$ is true - that we would see a vlue at least as extreme as the one actually observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598857"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is what's greater than x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is what's less than x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)\n",
    "    \n",
    "two_sided_p_value(529.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: A *continuity correction* was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simulation to check that this is a sensible estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06133\n"
     ]
    }
   ],
   "source": [
    "extreme_value_count = 0\n",
    "for _ in range(100000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0   # count number of heads\n",
    "                    for _ in range(1000))               # in 1000 flips\n",
    "    \n",
    "    if num_heads >= 530 or num_heads <= 470:            # and count how often\n",
    "        extreme_value_count += 1                        # the number is 'extreme'\n",
    "\n",
    "print(extreme_value_count / 100000)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"4.\" **Form a conclusion**: Should we reject the hypothesis that the coin is fair (that $p = 0.5$)?\n",
    "    - Don't reject the null hypothesis\n",
    "    - Reject the null\n",
    "    - Don't reject the null\n",
    "    - Reject the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046345287837786575"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(531.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06062885772582083"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below\n",
    "\n",
    "upper_p_value(524.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(526.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "We formed a hypothesis about the value of the head probability $p$, which is a parameter of the unknown \"heads\" distribution, and tested it. Now we construct a *confidence interval* around the observed value of the parameter.\n",
    "\n",
    "**Example**: If we observe 525 heads out of 1000 coin flips, we can estimate $p = 0.525$.*How confident can we be of this estimate?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015791611697353755"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This is not entirely justified, but people seem to do it anyway.\"\n",
    "\n",
    "**Note**: If you were to repeat the experiment many times, 95% of the time the \"true\" parameter (which is the same every time) would lie within th eobserved confidence interval (which might be different every time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 540 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    \"\"\"flip a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    return [np.random.random() < 0.5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment):\n",
    "    \"\"\"using the 5% significance levels\"\"\"\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "np.random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment\n",
    "                     for experiment in experiments\n",
    "                     if reject_fairness(experiment)])\n",
    "\n",
    "print(num_rejections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Running an A/B Test\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "N_A &= \\textrm{number of people who see ad A}\\\\\n",
    "n_A &= \\textrm{number of people who click on ad A}\\\\\n",
    "p_A &= \\textrm{probability that someone clicks ad A}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Assumptions**:\n",
    "- $N_A$ is large $\\rightarrow n_A / N_A$ is approximately a normal random variable with mean $p_A$ and standard deviation $\\sigma_A = \\sqrt{p_A(1 - p_A) / N_A}$\n",
    "- normals are independent $\\rightarrow$ their difference should also be normal with mean $p_B - p_A$ and standard deviation $\\sqrt{\\sigma_A^2 + \\sigma_B^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimated_parameters(N, n):\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1 - p) / N)\n",
    "    return p, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a_b_test_statistic(N_A, n_A, N_b, n_b):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
    "two_sided_p_value(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = a_b_test_statistic(1000, 200, 1000, 150)\n",
    "two_sided_p_value(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference\n",
    "Until now we made probability statements about our *tests*.  \n",
    "Now we will make probability statements about the *parameters* themselves and not about the *tests*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def B(alpha, beta):\n",
    "    \"\"\"a normalizing constant so that the total probability is 1\"\"\"\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x, alpha, beta):\n",
    "    if x < 0 or x > 1:        # no weight outside of [0, 1]\n",
    "        return 0\n",
    "    return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Further Exploration\n",
    "- Free Intro Stats Textbooks:\n",
    "    - [OpenIntro Statistics](https://www.openintro.org/stat/textbook.php?stat_book=os)\n",
    "    - [OpenStax Introductory Statistics](https://openstax.org/details/introductory-statistics)\n",
    "- [Data Analysis and Statistical Inference](https://www.coursera.org/course/statistics) on Coursera\n",
    "- Maybe there are better books these days, but this is a classic reference: https://www.amazon.com/Statistical-Inference-George-Casella/dp/0534243126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
