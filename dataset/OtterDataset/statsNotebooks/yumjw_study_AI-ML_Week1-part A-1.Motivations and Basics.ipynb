{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 스터디 1주차\n",
    "#### 2020.01.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Motivations and Basics\n",
    "* Motivate the study on\n",
    "    * Machine learning, AI, Data-mining\n",
    "    * Overview of the field\n",
    "<br><br>\n",
    "* Short questions and answers on a story\n",
    "    * What consists of machine learning?\n",
    "    * MLE\n",
    "    * MAP\n",
    "<br><br>\n",
    "* Some basics\n",
    "    * Probability\n",
    "    * Distribution\n",
    "    * And some rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Motivations\n",
    "### Keywords\n",
    "Many floating keywords : Data-mining, Knowledge discovery, Machine Learning, AL...<br>\n",
    "Related Majority : Computer Science, Statistics, Math, Business...\n",
    "\n",
    "### Data\n",
    "Text, Image, Network Data, Time Series Data, and Big Data\n",
    "\n",
    "### Machine Learning\n",
    "Machine learning is an application of artificial intelligence(AI) that provides systems **the ability to automatically learn and improve from experience without being explicitly programmed.** Machine learning focuses on the development of computer programs that can access data and use it learn for themselves<br><br>\n",
    "They are used in everywhere, document classification, stock market prediction, SNS analysis, spam mail filtering etc.\n",
    "\n",
    "### Types of Machine Learning\n",
    "#### 1. Supervised Learning\n",
    "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function **from labeled training data** consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples.<br><br>\n",
    "ex) classification, regression<br>\n",
    "* Hit or Miss: Something has **either disease or not.**\n",
    "* Ranking: Someone received **either A+, B, C, or F**\n",
    "* Types: An article is **either positive or negative**\n",
    "* Value prediction: The price of this artifact is X\n",
    "\n",
    "#### 2. Unsupervised Learning\n",
    "Unsupervised learning is a type of self-organized Hebbian learning that helps find previously unknown patterns in data set **without pre-existing labels.** It is also known as self-organization and allows modeling probability densities of given inputs. It is one of the main three categories of machine learning, along with supervised and reinforcement learning. Semi-supervised learning is a hybridization of supervised and unsupervised techniques. <br><br>\n",
    "ex) clustering, filtering<br>\n",
    "* Finding the representative topic words from text data\n",
    "* Finding the latent image from facial data\n",
    "* Completing the incomplete matrix of product review scores\n",
    "* Filtering the noise from the trajectory data\n",
    "\n",
    "#### 3. Reinforcement Learning\n",
    "Reinforcement learning (RL) is an area of machine learning concerned with **how software agents ought to take actions in an environment in order to maximize some notion of cumulative reward.** Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.<br>\n",
    "Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).<br><br>\n",
    "ex) AlphaGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 MLE\n",
    "### Thumbtack Question\n",
    "There is a gambling site with a game of flipping a thumbtack. Nail is up, and you betted on nails up you get your money in double. Same is true with the nail's down. A billionaire wants to enter the gambling with scientific and engineering supports. He is paying you a big chunk of money. He asks you **\"I have a thumbtack, if I flip it, what’s the probability that it will fall with the nails up?\"**<br><br>\n",
    "억만장자의 의뢰를 받았으니 압정이 앞면이 나올 확률을 계산해봅시다. 먼저 데이터가 필요하므로 압정던지기를 5번 시행합니다. 그 결과, 앞면이 3번 뒷면이 2번 나왔습니다. 그래서 우리는 억만장자에게 \"압정을 던질 때 앞면이 나올 확률은 ${3\\over5}$입니다.\"라고 자신만만하게 이야기합니다. 억만장자는 답변에 만족하지 못하고 의뢰비 지급을 거부합니다. **어떻게 하면 수학적인 근거를 들어 이를 증명할 수 있을까요?**\n",
    "\n",
    "### Binomial Distribution\n",
    "압정던지기를 수학적으로 증명하기 위해서는 먼저 이항분포에 대해 알아볼 필요가 있습니다. **우리는 압정던지기가 이항분포를 따른다고 가정할 것입니다.** 이항 분포는 연속된 n번의 독립적 시행에서 각 시행이 확률 p를 가질 때의 이산 확률 분포입니다. 이러한 시행은 베르누이 시행이라고 불리기도 합니다. n=1일 때 이항 분포는 베르누이 분포입니다.<br><br>\n",
    "먼저 이항분포를 가정하기 전에 압정을 던지는 행위는 모두 **독립사건**임을 확인할 필요가 있습니다. 통계학에서 Identically Independent Distributed라고 불리는 이 가정은 분포를 사용하는 모수적 방법에서 상당히 중요하고 또 자주 쓰이는 가정이기 때문에 알아둘 필요가 있습니다. 상식적으로 생각해도 압정 던지기는 던질 때마다 모두 독립사건이 됩니다.<br><br>\n",
    "다시 이항분포로 돌아와서 일반적으로 확률변수 X가 매개변수 n과 p를 가지는 이항분포를 따르면, $B(n,p)$라고 씁니다. n번 시행 중에 x번 성공할 확률은 확률 질량 함수를 통해 구할 수 있습니다. 확률 질량 함수는 아래와 같습니다.<br><br>\n",
    "$$P(X=x)={n!\\over k!(n-k)!}p^k(1-p)^{n-k}$$\n",
    "<br><br>\n",
    "이제 위의 압정던지기를 이항분포에 적용해보겠습니다. 앞면의 사건은 $H$로 뒷면의 사건은 $T$로 표시합니다. 5번의 시행에서 앞면이 3번, 뒷면이 2번 나왔으므로 이를 $a_H=3$, $a_T=2$로 표현하겠습니다.<br>\n",
    "앞면의 사건과 뒷면의 사건의 확률은 각각 다음과 같이 표현 가능합니다.\n",
    "<br><br>\n",
    "$$P(H)=\\theta$$<br>\n",
    "$$P(T)=1-\\theta$$\n",
    "<br><br>\n",
    "우리는 총 5번의 시행을 했고 그 결과는 D={H,H,H,T,T}입니다. (순서는 상관이 없습니다.) D라는 결과가 나올 확률은 다음과 같습니다.\n",
    "<br><br>\n",
    "$$P(D|\\theta)=\\theta^3(1-\\theta)^2$$\n",
    "<br><br>\n",
    "즉, 다음과 같이 일반화가 가능합니다. <br>D가 $a_H$개의 앞면과 $a_T$개의 뒷면으로 이루어진 시행들의 집합일 때, D가 나타날 확률은 다음과 같습니다.\n",
    "<br><br>\n",
    "$$P(D|\\theta)=\\theta^{a_H}(1-\\theta)^{a_T}$$\n",
    "\n",
    "### Maximum Likelihood Estimation\n",
    "지금까지 우리는 압정던지기의 시행이 이항분포를 따른다고 가정하고, 시행결과의 확률식을 구해보았습니다. 정확한 분포를 구할 수 있다면 우리는 어떤 상황에서도 압정던지기의 결과를 합리적으로 예측할 수 있을 것입니다. **압정던지기의 정확한 분포를 어떻게 구할 수  있을까요?**<br>\n",
    "* Finding out a better distribution of the observation\n",
    "    * Can be done, but you need more rational.\n",
    "* Finding out the best candidate of $\\theta$\n",
    "    * What’s the condition to make $\\theta$ most plausible?\n",
    "    \n",
    "물론 정확한 분포를 구할 수 있으면 좋겠지만, 아무것도 없는 상태에서 분포를 추정하는 것은 쉬운 일이 아닙니다. 따라서 우리는 보통 어떤 분포를 가정하고 **그 분포의 적절한 매개변수를 찾는 일** 에 집중합니다. 이 경우에도 이항분포를 가정했으므로 우리는 시행의 결과로부터 **적절한 $\\theta$를 찾는 것**을 목적으로 하면 됩니다.<br><br>\n",
    "적절한 $\\theta$란 **관찰값이 일어날 확률을 최대로 하는 값**을 말합니다. 즉 다양한 $\\theta$를 통해 관찰값이 일어날 확률을 구하고, 이를 나열했을 때 가장 큰 값을 취할 수 있는 $\\theta$를 찾으면 됩니다. 이를 식으로 표현하면 다음과 같습니다.\n",
    "<br><br>\n",
    "$$\\hat{\\theta}=argmax_\\theta P(D|\\theta)$$\n",
    "\n",
    "### MLE Calculation\n",
    "위의 수식을 풀어내면 최적의 $\\theta$를 구할 수 있습니다. 즉, **압정던지기를 시행했을 때 윗면이 나올 확률**을 추정할 수 있습니다.<br>\n",
    "최댓값을 구하기 위해서 수식을 미분하여 0이 되도록 만들어야 하는데, 위의 목적함수는 제곱의 형태로 되어있어 미분이 어렵습니다. 미분을 용이하게 만들어주기 위해 **자연로그를 취해줍니다.** 자연로그는 단조증가함수이므로 최댓값에는 변화가 없습니다.\n",
    "<br><br>\n",
    "$$\\hat{\\theta}=argmax_\\theta P(D|\\theta)=argmax_\\theta \\theta^{a_H}(1-\\theta)^{a_T}$$\n",
    "<br>\n",
    "$$\\hat{\\theta}=argmax_\\theta lnP(D|\\theta)=argmax_\\theta ln(\\theta^{a_H}(1-\\theta)^{a_T})$$\n",
    "<br><br>\n",
    "미분을 하고 0으로 만들어줍니다.\n",
    "<br><br>\n",
    "$${d\\over d\\theta}(a_Hln\\theta+a_Tln(1-\\theta))=0$$\n",
    "<br><br>\n",
    "$${a_H\\over\\theta}-{a_T\\over(1-\\theta)}=0$$\n",
    "<br><br>\n",
    "$$\\theta={a_H\\over a_H+a_T}$$\n",
    "<br><br>\n",
    "따라서, 이항분포의 최적의 매개변수는 다음과 같습니다.\n",
    "<br><br>\n",
    "$$\\hat{\\theta}={a_H\\over a_H+a_T}$$\n",
    "\n",
    "### Thumbtack Question(answer)\n",
    "자 이제 MLE를 통해 최적의 매개변수를 구했습니다. $a_H=3$, $a_T=2$를 위의 식에 대입하면\n",
    "<br><br>\n",
    "$$\\hat{\\theta}={3\\over5}$$\n",
    "<br>\n",
    "라는 결과를 도출할 수 있습니다.<br><br>\n",
    "이는 처음에 우리가 직관적으로 도출했던 결과와 일치합니다. 이를 MLE를 통해 수학적으로(통계적으로) 증명할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 MAP\n",
    "### Incorporating Prior Knowledge(Bayes' theorem)\n",
    "우리는 MLE를 통해 억만장자에게 자신있게 이야기할 수 있습니다. 압정이 윗면이 나올 확률이 0.6이므로 윗면에 베팅하셔야합니다!<br><br>\n",
    "그 때, Bayes라는 사람이 와서 이야기합니다. **\"상식적으로 앞면이 나올 확률이 50%라고 생각하시지 않나요?\"** 생각해보니 무한히 압정을 던지면 앞면과 뒷면이 동일한 확률로 나올 것 같습니다. **그렇다면 우리가 알고 있는 이 사전확률을 추정에 사용할 수 있을까요?**<br><br>\n",
    "베이즈 정리에 의해 사전확률로 사후확률을 예측할 수 있습니다. 조건부확률을 다루는 베이즈정리는 통계학에서 굉장히 자주 사용되는 이론입니다. 전통적인 확률이론이 연역적 추론에 기반한다면, 베이즈 정리는 확률임에도 경험에 의한 귀납적인 추론을 사용합니다. 베이즈정리는 아래와 같은 식으로 표현 가능합니다.<br><br>\n",
    "$$P(A|B)={P(A\\cap B)\\over P(B)}={P(B|A)P(A)\\over P(B)}$$\n",
    "<br><br>\n",
    "이제 이 베이즈 정리를 이용해 MAP 추정을 해보겠습니다.\n",
    "\n",
    "### MAP(Maximum A Posterior)\n",
    "베이즈 정리는 사전확률로 사후확률을 예측하는 정리입니다. 각각의 값을 하나하나 살펴보겠습니다. 일단 식은 다음과 같이 정리됩니다.\n",
    "<br><br>\n",
    "$$Posterior={Likelihood * Prior Knowledge\\over Normalizing Constant}$$\n",
    "<br><br>\n",
    "$$P(\\theta|D)={P(D|\\theta) * P(\\theta)\\over P(D)}$$\n",
    "<br>\n",
    "* Posterior(사후확률): $P(\\theta|D)$\n",
    "* Likelihood(우도) : $P(D|\\theta)$\n",
    "* Prior Knowledge(사전확률) : $P(\\theta)$\n",
    "* Constant(관측값의 확률) : $P(D)$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$P(D)$는 상수이기 때문에 비례표현을 통해 지워줍니다.\n",
    "<br>\n",
    "<br>\n",
    "$$P(\\theta|D)\\propto P(D|\\theta) * P(\\theta)$$\n",
    "<br>\n",
    "$$ , \\ such \\ that \\ P(D|\\theta)=\\theta^{a_H}(1-\\theta)^{a_T}$$\n",
    "<br>\n",
    "<br>\n",
    "우리는 압정던지기가 이항분포를 따른다고 가정했기 때문에 Likelihood, 즉 $P(D|\\theta)$를 계산할 수 있습니다. 따라서 $P(\\theta)$만 알면 사후확률을 구할 수 있습니다.\n",
    "<br><br>\n",
    "$\\theta$는 확률이기 때문에 **Beta Distribution**을 통해 $P(\\theta)$를 구해보겠습니다. $\\theta$가 베타분포를 따르면 다음과 같은 식이 성립합니다.\n",
    "<br><br>\n",
    "$$P(\\theta)={\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\over B(\\alpha, \\beta)}$$\n",
    "<br>\n",
    "$$ , \\ such \\ that \\ B(\\alpha, \\beta)={\\Gamma(\\alpha)\\Gamma(\\beta)\\over \\Gamma(\\alpha+\\beta)}$$\n",
    "<br><br>\n",
    "이제 사후확률을 구하기 위한 준비가 끝났습니다. 베타분포로 구한 확률값을 위의 식에 넣어주면 다음과 같은 식이 도출됩니다.\n",
    "<br><br>\n",
    "$$P(\\theta|D)\\propto P(D|\\theta) * P(\\theta)$$\n",
    "<br><br>\n",
    "$$P(\\theta|D)\\propto \\theta^{a_H}(1-\\theta)^{a_T} *\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}$$\n",
    "<br><br>\n",
    "$$P(\\theta|D)\\propto \\theta^{a_H+\\alpha-1}(1-\\theta)^{a_T+\\beta-1}$$\n",
    "<br><br>\n",
    "\n",
    "이제 우리는 위의 식을 최대화 하는 $\\theta$를 구하면 됩니다.\n",
    "\n",
    "### MAP Calculation\n",
    "계산은 MLE에서와 동일합니다. 우리는 MLE를 계산할 때, 아래와 같은 방식으로 추정했습니다.\n",
    "\n",
    "$$\\hat{\\theta}=argmax_\\theta P(D|\\theta)$$\n",
    "\n",
    "$$P(D|\\theta)=\\theta^{a_H}(1-\\theta)^{a_T}$$\n",
    "<br>\n",
    "<br>\n",
    "$$\\hat{\\theta}={a_H\\over a_H+a_T}$$\n",
    "<br>\n",
    "MAP에서는 최대화의 목적함수가 **사후확률**로 바뀌었으며 이에 따라 최적의 $\\theta$값도 조금 달라지게 됩니다. 우리는 $\\theta$가 $\\alpha, \\beta$를 매개변수로 하는 베타분포를 따른다고 가정했으므로 계산이 가능합니다.\n",
    "<br>\n",
    "$$\\hat{\\theta}=argmax_\\theta P(\\theta|D)$$\n",
    "\n",
    "$$P(\\theta|D)\\propto \\theta^{a_H+\\alpha-1}(1-\\theta)^{a_T+\\beta-1}$$\n",
    "<br>\n",
    "<br>\n",
    "$$\\hat{\\theta}={a_H+\\alpha-1\\over a_H+\\alpha+a_T+\\beta-2}$$\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "결론적으로 MLE와 MAP로 모두 최적의 매개변수 추정이 가능합니다. 다만, MAP에서는 사전확률을 계산하기 위해 베타분포를 안다고 가정해야했고, 이 값이 최종 추정값에 영향을 미치게 됩니다. **하지만 만약 압정던지기를 무한히 수행한다면, 사전확률의 영향이 미미해져 MLE의 추정값과 MAP의 추정값은 동일하게 될 것입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Probability and Distributions\n",
    "### Probability\n",
    "Probability is a numerical description of **how likely an event is to occur** or how likely it is that a proposition is true. **Probability is a number between 0 and 1**, where, roughly speaking, 0 indicates impossibility and 1 indicates certainty. The higher the probability of an event, the more likely it is that the event will occur. A simple example is the tossing of a fair (unbiased) coin. Since the coin is fair, the two outcomes (\"heads\" and \"tails\") are both equally probable; the probability of \"heads\" equals the probability of \"tails\"; and since no other outcomes are possible, the probability of either \"heads\" or \"tails\" is 1/2 (which could also be written as 0.5 or 50%). \n",
    "<br><br>\n",
    "$$ 0\\leq P(E) \\leq 1$$\n",
    "<br>\n",
    "$$ P(\\Omega) = 1$$\n",
    "\n",
    "### Conditional Probability\n",
    "In probability theory, conditional probability is a measure of the probability of an event occurring **given that another event has (by assumption, presumption, assertion or evidence) occurred.** If the event of interest is A and the event B is known or assumed to have occurred, \"the conditional probability of A given B\", or \"the probability of A under the condition B\", is usually written as $P(A | B)$.\n",
    "<br><br><br>\n",
    "$$P(A|B)={P(A\\cap B)\\over P(B)}={P(B|A)P(A)\\over P(B)}$$\n",
    "\n",
    "### Frequently Used Distribution\n",
    "* Binomial Distribution\n",
    "* Poisson Distribution\n",
    "* Normal Distribution\n",
    "* Beta Distribution\n",
    "* F Distribution\n",
    "* t Distribution\n",
    "* $\\chi^2$ Distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
