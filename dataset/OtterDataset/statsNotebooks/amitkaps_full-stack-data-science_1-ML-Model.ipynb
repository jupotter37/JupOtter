{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "Startup XYZ is in the business of giving personal loans, structured as [non-recourse loans](http://www.investopedia.com/terms/n/nonrecoursedebt.asp). The defaults on their loans are much higher than their competitors. Also, the underlying collaterals lose their value way too quicky and has resulted in huge losses for Bank XYZ.\n",
    "\n",
    "Alice was recently appointed as the Senior VP of the Risk Organization. She comes from a strong analytics background and wants to leverage data science to identify customer's risk before approving loan.\n",
    "\n",
    "She's appointed you as a consultant to help her and the team solve this problem.\n",
    "\n",
    "*Note: This case study was inspired by the [bank marketing case study](https://archive.ics.uci.edu/ml/datasets/bank+marketing). The data is a modified version of what is available in that site*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brainstorming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frame\n",
    "\n",
    "The first step is to convert the business problem into an analytics problem\n",
    "\n",
    "Alice wants to know customer's risk. Let's try to predict the propensity of a customer to default, given the details he/she has entered on the loan application form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquire\n",
    "\n",
    "After discussions with the IT team of Startup XYZ, you have obtained some historical data from the bank. It has the following columns\n",
    "\n",
    "**Application Attributes**:\n",
    "- `years`: Number of years the applicant has been employed  \n",
    "- `ownership`: Whether the applicant owns a house or not  \n",
    "- `income`:  Annual income of the applicant  \n",
    "- `age`: Age of the applicant  \n",
    "- `amount` : Amount of Loan requested by the applicant  \n",
    "\n",
    "**Behavioural Attributes**:\n",
    "- `grade`:  Credit grade of the applicant\n",
    "\n",
    "**Outcome Variable**:\n",
    "\n",
    "- `default` : Whether the applicant has defaulted or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Default Variables\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the training dataset\n",
    "df = pd.read_csv(\"../data/historical_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first few rows of training dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the columns of the train dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data types of the train dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the number of records in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View summary of raw data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the dataset for compeleteness - by checking for missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if df has missing values.\n",
    "df.isnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a large dataset, this is hard to find if there are any missing values or not.\n",
    "# We can chain operators on the output. Let's use sum()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that `years` have missing values. The column is numeric. We have three options for dealing with missing values\n",
    "\n",
    "**Options to treat Missing Values**\n",
    "\n",
    "1. **REMOVE** - NAN rows\n",
    "2. **IMPUTATION** - Replace them with something??\n",
    "     - Mean\n",
    "     - Median\n",
    "     - Fixed Number - Domain Relevant\n",
    "     - High Number (999) - Issue with modelling\n",
    "3. **BINNING** - Categorical variable and \"Missing becomes a number\n",
    "4. **DOMAIN SPECIFIC** - Entry error, pipeline, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's replace missing values with mean\n",
    "# There's a fillna function\n",
    "df.years = df.years.fillna(np.mean(df.years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding unique values of years \n",
    "pd.unique(df.years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to check for quality - by checking for outliers in the data. For this workshop, we will skip doing that. But remember to check for outliers when doing in real-life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build some intuition around the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Single Variable Exploration - Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram for target variable - default\n",
    "df.default.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore grade\n",
    "df.grade.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore age\n",
    "df.age.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dual Variable Exploration - Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the impact of age with income\n",
    "df.plot.scatter(x='age', y='income', alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  EXERCISE\n",
    "** Three Variables Exploration **\n",
    "\n",
    "Explore the relationship between age, income and defualt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's again revisit the data types in the dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the columns are categorical in nature - grade and ownership.\n",
    "\n",
    "To build models, we need all of the features to be numeric. There exists a number of ways to convert categorical variables to numeric values.\n",
    "\n",
    "We will use one of the popular options: `LabelEncoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's not modify the original dataset. \n",
    "# Let's transform it in another dataset\n",
    "df_encoded = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate label encoder\n",
    "le_grade = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit label encoder\n",
    "le_grade = le_grade.fit(df_encoded[\"grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_encoded.grade = le_grade.transform(df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Do label encoding on ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common approaches:\n",
    "\n",
    "1. Linear models\n",
    "2. Tree-based models\n",
    "3. Neural Networks\n",
    "4. ... \n",
    "\n",
    "Some choices to consider:\n",
    "\n",
    "1. Interpretability\n",
    "2. Run-time\n",
    "3. Model complexity\n",
    "4. Scalability\n",
    "\n",
    "For the purpose of this workshop, we will use tree-based models.\n",
    "\n",
    "We will do the following two:\n",
    "\n",
    "1. Decision Tree\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "Let's first build a model using just two features to build some intuition around decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 -** Create features matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = df_encoded.loc[:,('age', 'amount')]\n",
    "y = df_encoded.loc[:,'default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2 -** Build decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the decision tree object\n",
    "clf_dt_2 = tree.DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the decision tree model\n",
    "clf_dt_2 = clf_dt_2.fit(X_2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 -** Visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf_dt_2, out_file='tree.dot', feature_names=X_2.columns,\n",
    "                                class_names=['no', 'yes'], filled=True, \n",
    "                                rounded=True, special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Incase you don't have graphviz installed\n",
    "# txt = open(\"tree_3.dot\").read().replace(\"\\\\n\", \"\\n  \").replace(\";\", \";\\n\")\n",
    "# print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = pydotplus.graph_from_dot_file('tree.dot')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_boundaries(X2, clf):\n",
    "    x_min, x_max = X2.iloc[:, 0].min() - 1, X2.iloc[:, 0].max() + 1\n",
    "    y_min, y_max = X2.iloc[:, 1].min() - 1, X2.iloc[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max - x_min)/100), \n",
    "                         np.arange(y_min, y_max, (y_max - y_min)/100))\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    target = clf.predict(X2)\n",
    "    plt.scatter(x = X2.iloc[:,0], y = X2.iloc[:,1], c = y, s = 20, cmap=plt.cm.magma)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.viridis, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(X_2, clf_dt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "Change the depth of the Decision Tree classifier to 10 and plot the decision boundaries again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand first just the difference between **Class** prediction and **Class Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class = clf_dt_10.predict(X_2)\n",
    "pred_proba = clf_dt_10.predict_proba(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(pred_proba[:,1], shade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "While we have created the model, we still don't have a *measure* of how good the model is. We need to measure some accuracy metric of the model and have confidence that it will generalize well. We should be confident that when we put the model in production (real-life), the accuracy we get from the model results should mirror the metrics we obtained when we built the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the right accuracy metric for the model is important. \n",
    "\n",
    "[This wiki](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) has a good overview of some of the common metrics.\n",
    "\n",
    "We will use a metric - **Area Under the Curve**\n",
    "\n",
    "#### Area Under the Curve\n",
    "\n",
    "In a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold. A test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100% sensitivity, 100% specificity). Therefore the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test \n",
    "([source](https://www.medcalc.org/manual/roc-curves.php))\n",
    "\n",
    "\n",
    "![](img/roc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_encoded.iloc[:,1:]\n",
    "y = df_encoded.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_df(clf, X, y):\n",
    "    clf = clf.fit(X,y)\n",
    "    y_pred = clf.predict(X)\n",
    "    y_proba = clf.predict_proba(X)[:,1]\n",
    "    pred_df = pd.DataFrame({\"actual\": np.array(y), \"predicted\": y_pred, \"probability\": y_proba})\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = pred_df(clf_dt, X,y)\n",
    "pred_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(pred_dt.predicted, pred_dt.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(pred_dt.predicted, pred_dt.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_prediction(pred_df):\n",
    "    pred_df_0 = pred_df[pred_df.actual == 0]\n",
    "    pred_df_1 = pred_df[pred_df.actual == 1]\n",
    "    sns.kdeplot(pred_df_0.probability, shade=True, label=\"no default\")\n",
    "    sns.kdeplot(pred_df_1.probability, shade=True, label=\"default\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_auc(pred_df):\n",
    "    fpr, tpr, thresholds = roc_curve(pred_df.actual, pred_df.probability)\n",
    "    auc_score = roc_auc_score(pred_df.actual,pred_df.probability)\n",
    "    plt.plot(fpr, tpr, label='AUC = %0.2f' % auc_score)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return print(\"AUC = %0.2f\" % auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_auc(pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Build a decison tree classifier with max_depth = 10 and plot confusion_matrix & auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Now that we have chosen the error metric, how do we find the generalization error?\n",
    "\n",
    "We do this using cross-validation. ([source]\n",
    "(https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
    "\n",
    "From wiki: \n",
    "> One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.\n",
    "\n",
    "![](img/cv.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `StratifiedKFold`.\n",
    "\n",
    "This ensures that in each fold, the proportion of positive class and negative class remain similar to the original dataset\n",
    "\n",
    "\n",
    "This is the process we will follow to get the mean cv-score\n",
    "\n",
    "1. Generate k-fold\n",
    "2. Train the model using k-1 fold\n",
    "3. Predict for the kth fold \n",
    "4. Find the accuracy.\n",
    "5. Append it to the array\n",
    "6. Repeat 2-5 for different validation folds\n",
    "7. Report the mean cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(clf, k):\n",
    "    \n",
    "    # Instantiate stratified k fold.\n",
    "    kf = StratifiedKFold(n_splits=k)\n",
    "    \n",
    "    # Let's use an array to store the results of cross-validation\n",
    "    kfold_auc_score = []\n",
    "\n",
    "    # Run kfold CV\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        clf = clf.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "        proba = clf.predict_proba(X.iloc[test_index])[:,1]\n",
    "        auc_score = roc_auc_score(y.iloc[test_index],proba)\n",
    "        print(auc_score)\n",
    "        kfold_auc_score.append(auc_score)\n",
    "    \n",
    "    print(\"Mean K Fold CV:\", np.mean(kfold_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(clf_dt, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Build a classifier with max_depth = 10 and run a 5-fold CV to get the auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build a classifier with max_depth = `20` and run a 5-fold CV to get the auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Decision trees in general have low bias and high variance. We can think about it like this: given a training set, we can keep asking questions until we are able to distinguish between ALL examples in the data set. We could keep asking questions until there is only a single example in each leaf. Since this allows us to correctly classify all elements in the training set, the tree is unbiased. However, there are many possible trees that could distinguish between all elements, which means higher variance.\n",
    "\n",
    "### How do we reduce variance?\n",
    "In order to reduce the variance of a single error tree, we usually place a restriction on the number of questions asked in a tree. This is true  for single decision trees which we have seen in previous notebooks.\n",
    "\n",
    "Along with this other method to do reduce variance is to **ensemble models** of decision trees. The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "### How to ensemble?\n",
    "\n",
    "1. **Averaging**: Build several estimators independently and then average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced. Examples:\n",
    "    - Bagging\n",
    "    - Random Forest\n",
    "    - Extremely Randomized Trees\n",
    " \n",
    "2. **Boosting**: Build base estimators sequentially and then try to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "    - AdaBoost\n",
    "    - Gradient Boosting (e.g. xgboost)\n",
    "    \n",
    "### Random Forest\n",
    "\n",
    "In random forests, each tree in the ensemble is built from a **sample drawn with replacement** (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a **random subset of the features**. \n",
    "\n",
    "As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**\n",
    "\n",
    "The advantage of the `scikit-learn` API is that the syntax remains fairly consistent across all the classifiers.\n",
    "\n",
    "If we change the DecisionTreeClassifier to RandomForestClassifier in the above code, we should be good to go :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(clf_rf, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Change the number of trees from 10 to 100 and make it 5-fold. And report the cross-validation error (Hint: You should get ~ 0.74. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed version of bagging and random forest can be found in the speakers' introductory machine learning workshop material\n",
    "\n",
    "[bagging](https://github.com/amitkaps/applied-machine-learning/blob/master/Module-03d-Model-Bagging.ipynb)  \n",
    "[random forest](https://github.com/amitkaps/applied-machine-learning/blob/master/Module-03e-Model-RandomForest.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "We choose the model and its hyper-parameters that has the best cross-validation score on the chosen error metric.\n",
    "\n",
    "In our case, it is random forest.\n",
    "\n",
    "Now - how do we get the model?\n",
    "\n",
    "We need to run the model with the chosen hyper-parameters on all of the train data. And serialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100)\n",
    "final_model = final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to serialize the model and the label encoders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(final_model, \"model.pkl\")\n",
    "joblib.dump(le_grade, \"le_grade.pkl\")\n",
    "joblib.dump(le_ownership, \"le_ownership.pkl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
