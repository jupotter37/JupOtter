{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff607e9d",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4b81e",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental theorem in probability theory, named after the Reverend Thomas Bayes. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Mathematically, Bayes' theorem states that the probability of event A occurring given that event B has occurred is equal to the probability of event B occurring given that event A has occurred, multiplied by the probability of event A occurring and divided by the probability of event B occurring. In other words, it provides a formal way of updating probabilities based on new evidence. Bayes' theorem is widely used in various fields such as statistics, machine learning, and artificial intelligence for tasks such as classification, regression, and estimation.\n",
    "\n",
    "Sure, let's illustrate Bayes' theorem with a simple example.\n",
    "\n",
    "Suppose we have a factory that produces light bulbs, and we know that:\n",
    "- 2% of the light bulbs are defective (event A: Defective bulbs).\n",
    "- Out of all the defective bulbs, 90% are identified as defective by a quality control test (event B: Identified as defective).\n",
    "- Additionally, 98% of the non-defective bulbs are correctly identified as non-defective by the test.\n",
    "\n",
    "Now, we want to find the probability that a randomly selected bulb is defective, given that it was identified as defective by the quality control test.\n",
    "\n",
    "Using Bayes' theorem, we can calculate this as follows:\n",
    "\n",
    "Let:\n",
    "- \\( P(A) \\) be the probability of a bulb being defective (prior probability).\n",
    "- \\( P(B|A) \\) be the probability of the bulb being identified as defective given that it is defective (likelihood).\n",
    "- \\( P(B) \\) be the probability of the bulb being identified as defective (evidence).\n",
    "\n",
    "Given:\n",
    "- \\( P(A) = 0.02 \\) (2% of bulbs are defective).\n",
    "- \\( P(B|A) = 0.90 \\) (90% of defective bulbs are identified as defective).\n",
    "- \\( P(B|\\neg A) = 0.98 \\) (98% of non-defective bulbs are correctly identified as non-defective).\n",
    "- \\( P(\\neg A) = 1 - P(A) = 0.98 \\) (Probability of a bulb not being defective).\n",
    "\n",
    "We can calculate \\( P(B) \\) using the law of total probability:\n",
    "\n",
    "\\[ P(B) = P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A) \\]\n",
    "\\[ P(B) = (0.90 \\times 0.02) + (0.98 \\times 0.98) \\]\n",
    "\\[ P(B) = 0.018 + 0.9604 \\]\n",
    "\\[ P(B) = 0.9784 \\]\n",
    "\n",
    "Now, we can use Bayes' theorem to find \\( P(A|B) \\), the probability of a bulb being defective given that it was identified as defective:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\\[ P(A|B) = \\frac{0.90 \\times 0.02}{0.9784} \\]\n",
    "\\[ P(A|B) = \\frac{0.018}{0.9784} \\]\n",
    "\\[ P(A|B) â‰ˆ 0.01838 \\]\n",
    "\n",
    "So, the probability that a randomly selected bulb is defective, given that it was identified as defective by the quality control test, is approximately 0.01838 or 1.838%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2dc4d",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0dab88",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is as follows:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred (posterior probability).\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred (likelihood).\n",
    "- \\( P(A) \\) is the prior probability of event A.\n",
    "- \\( P(B) \\) is the prior probability of event B.\n",
    "\n",
    "This formula describes how the probability of event A occurring, given that event B has occurred, is related to the likelihood of event B given event A, the prior probability of event A, and the prior probability of event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d650f8a",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e66f9",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in various fields and applications. Here are some common practical uses of Bayes' theorem:\n",
    "\n",
    "1. **Classification and Prediction**: In machine learning and statistics, Bayes' theorem is used for classification and prediction tasks. It helps in estimating the probability of a class or outcome given certain features or observations. Naive Bayes classifiers, for example, use Bayes' theorem to predict the probability of a class given the input features.\n",
    "\n",
    "2. **Medical Diagnosis**: Bayes' theorem is used in medical diagnosis to estimate the probability of a patient having a disease based on their symptoms and test results. It helps doctors make informed decisions by incorporating prior knowledge about the disease prevalence and the accuracy of diagnostic tests.\n",
    "\n",
    "3. **Spam Filtering**: In email filtering systems, Bayes' theorem is used to classify emails as spam or non-spam. It analyzes the probability of an email being spam given its content and other characteristics. Spam filters learn from past examples to improve their accuracy over time.\n",
    "\n",
    "4. **Risk Assessment**: Bayes' theorem is used in risk assessment and decision-making processes. It helps in evaluating the likelihood of different outcomes and their potential consequences. For example, in insurance, it can be used to assess the probability of certain events such as accidents or natural disasters.\n",
    "\n",
    "5. **Document Classification**: Bayes' theorem is used in natural language processing for document classification tasks such as sentiment analysis, topic modeling, and language identification. It helps in determining the probability of a document belonging to a particular category based on its content.\n",
    "\n",
    "6. **Fault Diagnosis**: Bayes' theorem is used in engineering and fault diagnosis to analyze system failures and predict potential issues. It helps in identifying the root causes of problems and improving system reliability.\n",
    "\n",
    "Overall, Bayes' theorem provides a framework for reasoning under uncertainty and is widely used in various fields to make informed decisions based on available evidence and prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d38352",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906b0a1",
   "metadata": {},
   "source": [
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. Conditional probability refers to the probability of an event occurring given that another event has already occurred. It is denoted by \\( P(A|B) \\), which reads as \"the probability of event A given event B.\"\n",
    "\n",
    "Bayes' theorem provides a way to update our beliefs about the probability of an event based on new evidence or information. It relates the conditional probability of an event to its prior probability and the conditional probability of its causes. The theorem is mathematically expressed as:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the posterior probability of event A given event B has occurred.\n",
    "- \\( P(B|A) \\) is the conditional probability of event B given event A has occurred.\n",
    "- \\( P(A) \\) is the prior probability of event A.\n",
    "- \\( P(B) \\) is the prior probability of event B.\n",
    "\n",
    "In essence, Bayes' theorem tells us how to update our initial beliefs (prior probability) about the likelihood of an event, based on new evidence (conditional probability). It provides a formal framework for incorporating new information into our existing knowledge to obtain a more accurate estimate of the probability of the event of interest. Therefore, Bayes' theorem and conditional probability are intimately connected, with Bayes' theorem being a fundamental tool for reasoning about conditional probabilities in uncertain situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f03f72",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa4375",
   "metadata": {},
   "source": [
    "Choosing the appropriate type of Naive Bayes classifier for a given problem depends on several factors, including the nature of the data and the assumptions that can be made about the distribution of features. Here's a guide on how to choose:\n",
    "\n",
    "1. **Nature of Features**:\n",
    "   - **Binary Features**: If your features are binary (e.g., presence or absence of a certain attribute), consider using **Bernoulli Naive Bayes**.\n",
    "   - **Categorical Features**: If your features are categorical (i.e., they take on discrete values), you might also consider using **Multinomial Naive Bayes**.\n",
    "   - **Continuous Features**: If your features are continuous (e.g., measurements), Gaussian Naive Bayes is more appropriate.\n",
    "\n",
    "2. **Assumptions about Feature Distribution**:\n",
    "   - **Gaussian Distribution**: If you assume that your features follow a Gaussian distribution, use **Gaussian Naive Bayes**. This assumption is common for continuous features.\n",
    "   - **Multinomial Distribution**: If your features represent counts or frequencies and can be modeled using a multinomial distribution, use **Multinomial Naive Bayes**.\n",
    "   - **Bernoulli Distribution**: If your features are binary or Boolean and can be modeled using a Bernoulli distribution, use **Bernoulli Naive Bayes**.\n",
    "\n",
    "3. **Performance Evaluation**:\n",
    "   - Experiment with different types of Naive Bayes classifiers and evaluate their performance using cross-validation or other validation techniques. Choose the one that gives the best performance on your specific problem and dataset.\n",
    "\n",
    "4. **Consideration of Assumptions**:\n",
    "   - Naive Bayes classifiers make strong assumptions about the independence of features. Consider whether these assumptions hold true for your dataset. If not, you might need to explore other machine learning algorithms.\n",
    "\n",
    "5. **Scalability**:\n",
    "   - Consider the scalability of the algorithm to the size of your dataset. Gaussian Naive Bayes tends to be faster and more scalable than Multinomial and Bernoulli Naive Bayes for large datasets.\n",
    "\n",
    "6. **Implementation Availability**:\n",
    "   - Depending on the programming libraries or frameworks you are using, some implementations of Naive Bayes classifiers may be readily available, while others may require more effort to implement.\n",
    "\n",
    "In summary, the choice of Naive Bayes classifier depends on the specific characteristics of your data, such as the type of features and the assumptions you can make about their distribution. Experimentation and performance evaluation are essential for selecting the most suitable classifier for your particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1b4cc",
   "metadata": {},
   "source": [
    "\n",
    "### Q6. Assignment:\n",
    "### You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "### Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "### each feature value for each class:\n",
    "### Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "### A 3 3 4 4 3 3 3\n",
    "### B 2 2 1 2 2 2 3\n",
    "### Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "### to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4401d",
   "metadata": {},
   "source": [
    "To classify the new instance with features \\( X_1 = 3 \\) and \\( X_2 = 4 \\) using Naive Bayes, we'll calculate the likelihood of each class given these features and then apply Bayes' theorem.\n",
    "\n",
    "Given:\n",
    "- Class A: \\( P(A) = \\frac{1}{2} \\) (equal prior probability)\n",
    "- Class B: \\( P(B) = \\frac{1}{2} \\) (equal prior probability)\n",
    "- Frequency of feature values for each class:\n",
    "\n",
    "\\[\n",
    "\\begin{array}{|c|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Class} & X1=1 & X1=2 & X1=3 & X2=1 & X2=2 & X2=3 & X2=4 \\\\\n",
    "\\hline\n",
    "A & 3 & 3 & 4 & 4 & 3 & 3 & 3 \\\\\n",
    "B & 2 & 2 & 1 & 2 & 2 & 2 & 3 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "We'll calculate the likelihood of observing \\( X_1 = 3 \\) and \\( X_2 = 4 \\) given each class using the counts from the table.\n",
    "\n",
    "For Class A:\n",
    "\\[ P(X_1=3|A) = \\frac{4}{13} \\]\n",
    "\\[ P(X_2=4|A) = \\frac{3}{13} \\]\n",
    "\\[ P(X_1=3, X_2=4|A) = P(X_1=3|A) \\times P(X_2=4|A) = \\frac{4}{13} \\times \\frac{3}{13} = \\frac{12}{169} \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ P(X_1=3|B) = \\frac{1}{7} \\]\n",
    "\\[ P(X_2=4|B) = \\frac{3}{7} \\]\n",
    "\\[ P(X_1=3, X_2=4|B) = P(X_1=3|B) \\times P(X_2=4|B) = \\frac{1}{7} \\times \\frac{3}{7} = \\frac{3}{49} \\]\n",
    "\n",
    "Now, we'll apply Bayes' theorem to calculate the posterior probabilities:\n",
    "\n",
    "For Class A:\n",
    "\\[ P(A|X_1=3, X_2=4) = \\frac{P(X_1=3, X_2=4|A) \\times P(A)}{P(X_1=3, X_2=4)} = \\frac{\\frac{12}{169} \\times \\frac{1}{2}}{P(X_1=3, X_2=4)} \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ P(B|X_1=3, X_2=4) = \\frac{P(X_1=3, X_2=4|B) \\times P(B)}{P(X_1=3, X_2=4)} = \\frac{\\frac{3}{49} \\times \\frac{1}{2}}{P(X_1=3, X_2=4)} \\]\n",
    "\n",
    "Since the denominators are the same, we can compare the numerators directly:\n",
    "\n",
    "For Class A:\n",
    "\\[ \\frac{12}{169} \\times \\frac{1}{2} = \\frac{12}{338} \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ \\frac{3}{49} \\times \\frac{1}{2} = \\frac{3}{98} \\]\n",
    "\n",
    "Since \\( \\frac{12}{338} > \\frac{3}{98} \\), the Naive Bayes classifier would predict the new instance to belong to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd22b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
