{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.1 Statistics </h1>\n",
    "<p> This notebook focus only the statics requried for Machine Learning. Here we will only use numpy<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.1 Mean, Meadian, Mode </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Mean: </strong> Mean is the average of the sample data. By dividing summation of all sample value by the number of sample value we can get the mean. \n",
    "\\begin{align}\n",
    "\\bar{x} & = \\frac{1}{n}\\sum_{i=1}^n x_i\\\\\n",
    "\\end{align}\n",
    "<strong>Median: </strong> Median is the midpoint of a sorted dataset. If the dataset has too many outlier then median is more useful than mean. For example, to understand what is the per capita income of a country the median is taken because the rich may be extremely rich which would skew the average and show a different picture than what the average people might experience. In that case, probably, taking the median would give a better insight.\n",
    "\n",
    "<strong>Mode: </strong> It's the most common value in the dataset. It's usefull to understand the concept of clustering or number of hit of a specific value. For example, a retailer may want to understand the mode of sizes purchased so that he can set stocking labels optimally. Say, store A has a mode of ‘small’ while store B has a mode of ‘XXL’.\n",
    "\n",
    "For a discrete random variable, the value with highest probability (the location at which the probability mass function has its peak); for a continuous random variable, a location at which the probability density function has a local peak.\n",
    "<p style=\"text-align:center\"><img src=\"mean-median-mode.png\" /> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 36 69 90 29  2 96 88 23 89]\n",
      " [48 96 35 71 40 53 60 43 20 49]\n",
      " [23 67 94 81 27 67 47 61  7 25]\n",
      " [12 94 86 28 72 81 90 65 76 71]\n",
      " [74  3 68 78 85 13 24 64 53  7]]\n",
      "Mean: [[44 59 70 69 50 43 63 64 35 48]]\n",
      "Median: [[48. 67. 69. 78. 40. 53. 60. 64. 23. 49.]] \n",
      "Mode: ModeResult(mode=array([[12,  3, 35, 28, 27,  2, 24, 43,  7,  7]]), count=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "# calculating mean median mode.\n",
    "dataset = (np.random.rand(5,10) * 100).astype(int)\n",
    "print(dataset)\n",
    "# Axis 0 will take the mean along y axis, axis 1 will calculate mean along x axis\n",
    "# keepdims will use the same dimension\n",
    "print(f\"Mean: {np.mean(dataset, axis=0, keepdims=True, dtype=int)}\")\n",
    "print(f\"Median: {np.median(dataset, axis=0, keepdims=True)} \")\n",
    "print(f\"Mode: {stats.mode(dataset, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.2 Normal Distribution </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Data creates a bell curve</li>\n",
    "    <li>The curve is symmetric about the mean</li>\n",
    "    <li>Most of the data is seen near the mean</li>\n",
    "    <li>Notation: $ \\mathcal{N}(\\mu,\\,\\sigma^{2})\\ $ </li>\n",
    "    <li>Mean = Median = Mode = $ \\mu $</li>\n",
    "    <li> variance = $ \\sigma^{2} $. Standard Devation = $ \\sigma $ </li>\n",
    "    <li>PDF:  </li>\n",
    "</ul>\n",
    "\\begin{align}\n",
    "P(x) = \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2}\n",
    "\\end{align}\n",
    "<img src=\"normal-distribution.png\" style=\"max-width:50%\"/>\n",
    "<strong>PDF(Probability Density Function):</strong> \n",
    "<ul>\n",
    "    <li>A random variable is continuous if it can be described by a PDF</li>\n",
    "    <li>The probability of happening a <strong>super exact</strong> random variable over any distribution is zero. Cause the probability is the area under the curve. And for a exact variable the we will not get a area instead we will get a line. And the area of the line is zero. If we say the probability of getting an exact random variable $ \\mu $ is zero. But the probability of getting a random variable between $ \\mu - \\sigma $ and $ \\mu + \\sigma $ is 68.27%</li>\n",
    "</ul>\n",
    "\\begin{align}\n",
    "\\int_{\\mu - \\sigma}^{\\mu + \\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 68.27\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{\\mu - 2\\sigma}^{\\mu + 2\\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 95.45\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{\\mu - 3\\sigma}^{\\mu + 3\\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 99.73\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.3 Other distributions: </h3>\n",
    "<strong>Bernoulli distribution:</strong> A random variable distributed according to the Bernoulli distribution can take on two possible values {0, 1}. Let, the probability of a random variable X = 1 is p. So, $ P(X = 1) = p $. \n",
    "\\begin{equation}\n",
    "  P(X)=\\begin{cases}\n",
    "    1 - p, & \\text{if $X=0$}.\\\\\n",
    "    p, & \\text{if $X=1$}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "More compactly, $ P(X) = p^x(1-p)^{1-x} $. And this is the PMF(Probability Mass Function) for Bernoulli distribution. One of the example of bernoulli's distribution is Logistic regression.\n",
    "\n",
    "<strong>Binomial distribution</strong> A sequence of identical bernoulli's event. If X is a Binomial random variable, we denote this $ X ∼ Bin(n, p) $, where p is the probability of success in a given trial and n is total number of trial. Probabililty Mass Function is given by: \n",
    "\\begin{equation}\n",
    "    P(X=k) = \\binom nk p^k(1-p)^{n-k}\n",
    "\\end{equation}\n",
    "Mean = $ np $. And variance = $ np(1-p) $\n",
    "\n",
    "<strong>Poisson distribution:</strong> It deals with arrival of events. It measures probability of the number of events happening over a fixed period of time, given a fixed average rate of occurrence and the event take places independently of the time since the last event. It is parameterized by average arrival rate $ \\lambda $. The PMF (Probability Mass Function) is given by:\n",
    "\\begin{equation}\n",
    "P(X = k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}\n",
    "\\end{equation}\n",
    "The mean and the variance is $ \\lambda $\n",
    "Example: You see 100 car goes over a road in a day. What is the probability that next day you will see 120 car running on the road. This can be calculated by poission distribuiton. Here $ \\lambda = 100  \\text{ and }  k = 120 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.4 Standard Deviation </h3>\n",
    "A measure of the amount of variation or dispersion of a set of values. It is a measure of how spread out numbers are. It's value is the square root of the Variance\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.39106965, 33.53445989, 17.5088549 , 33.74374016, 24.17767565,\n",
       "        35.3327044 , 23.95495773, 23.92153841, 22.64862027, 31.12169661]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use numpy to find standard deviation\n",
    "np.std(dataset, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.5 Correlation</h3>\n",
    "It measures the strength and direction of the linear relationship between two variables. It's a function of covariance. <strong>What sets them apart is the fact that correlation values are standardized whereas, covariance values are not</strong>. We can obtain the correlation coefficient of two variables by dividing the covariance of these variables by the product of the standard deviations of the same values. When we divide the covariance values by the standard deviation, it essentially scales the value down to a limited range of -1 to +1. This is precisely the range of the correlation values.\n",
    "\\begin{equation}\n",
    "\\rho (x, y) = \\frac{Cov(x, y)}{\\sigma_x \\sigma_y} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.85535781]\n",
      " [-0.85535781  1.        ]]\n",
      "[[ 1.         -0.85535781]\n",
      " [-0.85535781  1.        ]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = [-2.1, -1,  4.3]\n",
    "y = [3,  1.1,  0.12]\n",
    "z = np.stack((x, y), axis=0)\n",
    "print(np.corrcoef(z))\n",
    "print(np.corrcoef(x, y))\n",
    "print(np.corrcoef(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.6 Covariance</h3>\n",
    "Variance measures the variation of a single random variable. Covariance is a measure of how much two random variables vary together.\n",
    "\\begin{equation}\n",
    "Var(X) = \\sigma_x^2 = \\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})^2 \\\\\n",
    "Cov(X,Y) = \\sigma(x,y) = \\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) \\\\\n",
    "\\sigma(x,x) = \\sigma_x^2\n",
    "\\end{equation}\n",
    "Covariance matrix are symmatric. The diagonal element of the covariance matrix are variant and other elements are covaraince. If the non diagonal element of the covarance matrix are empty then it means the two random variable are independent. It has the units from the product of the units of the two variables. <strong>Use the covariance matrix when the variable are on similar scales and the correlation matrix when the scales of the variables differ.</strong>Using covariance, we can only gauge the direction of the relationship (whether the variables tend to move in tandem or show an inverse relationship). However, it does not indicate the strength of the relationship, nor the dependency between the variables.\n",
    "<img src=\"covariance_matrix.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0]\n",
      " [0 1 2]]\n",
      "[[ 1. -1.]\n",
      " [-1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Find covariance using numpy\n",
    "x = np.array([[2, 0], [1, 1], [0, 2]]).T\n",
    "# x0 = 2, 1, 0\n",
    "# x1 = 0, 1, 2\n",
    "# If x0 increase x1 decrease so the covaraince is negetive\n",
    "# Each row is treated as a single variable.\n",
    "cov = np.cov(x)\n",
    "print(x)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.71       -4.286     ]\n",
      " [-4.286       2.14413333]]\n",
      "[[11.71       -4.286     ]\n",
      " [-4.286       2.14413333]]\n",
      "11.709999999999999\n"
     ]
    }
   ],
   "source": [
    "x = [-2.1, -1,  4.3]\n",
    "y = [3,  1.1,  0.12]\n",
    "z = np.stack((x, y), axis=0)\n",
    "print(np.cov(z))\n",
    "print(np.cov(x, y))\n",
    "print(np.cov(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of variable X along direciton U is $ U^T\\Sigma U $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.7 Normalization, Scaling, Standarization</h3>\n",
    "<strong>Normalization</strong> means adjusting values measured on different scales to a notionally common scale. It is required only when features have different ranges. <strong> In scaling, we’re changing the range of your data while in normalization we’re changing the shape of the distribution of your data.</strong>. The point of normalization is to change ou observations so that they can be described as a normal distribution.\n",
    "we’ll only want to normalize our data if we’re going to be using a machine learning or statistics technique that assumes your data is normally distributed. For example t-tests, ANOVAs, linear regression, linear discriminant analysis (LDA) and Gaussian naive Bayes.\n",
    "\n",
    "<strong>Scaling: </strong> Scaling just changes the range of your data. It doesn't affect the shape. Scaling is also called feature-scaling.\n",
    "\n",
    "<strong>Standardization: </strong>Usually transform the data so that the data will have mean 0 and standard deviation 1. This standarization is called z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.8 Bayesian theorem </h3>\n",
    "Bayes’ theorem is a way to figure out conditional probability. Conditional probability is the probability of an event happening, given that it has some relationship to one or more other events. \n",
    "Example: Let a test identify correctly 99% of time that a person has a disease. And 1% of the time incorrectly. A person took the test and got positive result. What is the percentage that the person has the disease? It seems like it would be 99% but it's not. Let's say we have 1000 people who took the test. Only one of them have the disease. But 1000*1% = 10 people falsly identified to have the disease. So we have total 11(1 correct, 10 incorrect) people to have the disease. So the real chances of a person having the disease is 1/11 = 9%.\n",
    "So we need both the information of the frequency of disease(total percentage of people affected) and percentage of false test result.\n",
    "\n",
    "Bayesian theorem is:\n",
    "\\begin{equation}\n",
    " P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)} \n",
    "\\end{equation}\n",
    "Where, \n",
    "<p>P(A) -> Percentage of event A happening.</p>\n",
    "<p>P(B) -> Percentage of event B happening.</p>\n",
    "<p>p(A|B) -> Percentage of happening event A given event B</p>\n",
    "<p>p(B|A) -> Percentage of happening event B given event A</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.9 P-value</h3>\n",
    "<p>P-value is used to determine the statistical significance of the result of any statistical model. The lower the p-value, the more surprising the evidence is, the more ridiculous our null hypothesis ( the hypothesis that we are testing) looks. If the p-value is lower than a predetermined <strong> significance level</strong>($ \\alpha $), then we reject the null hypothesis. The choice of $ \\alpha $ depends on the situation and the field of study, but the most commonly used value is 0.05, corresponding to a 5% chance the results occurred at random.  A p-value doesn’t prove anything. It’s simply a way to use surprise as a basis for making a reasonable decision.</p>\n",
    "<p>Example of finding P value:</p>\n",
    "P-value = Random chance that support the null hypothesis + The probability of happening some other event that has the probability equal to the probability of null hypothesis happening +  The probability of happening some other event that has the probability less than the probability of null hypothesis happening\n",
    "<p>The p-value of getting two head of two coin flips are:</p>\n",
    "Random chance that support the null hypothesis = probability of getting two head = .25 <br>\n",
    "The probability of happening some other event that has the probability equal to the probability of null hypothesis happening = probability of getting two tail = .25<br>\n",
    "The probability of happening some other event that has the probability equal to the probability of null hypothesis happening = No event have probability less than .25 = 0<br>\n",
    "P-value = .25 +.25 + 0 = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used resources:\n",
    "    <ul>\n",
    "        <li>https://medium.com/technology-nineleaps/basics-of-statistics-for-machine-learning-engineers-bf2887ac716c</li>\n",
    "    <li>https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22</li>\n",
    "    <li>https://datascienceplus.com/understanding-the-covariance-matrix/</li>\n",
    "    <li>https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029</li>\n",
    "    <li>https://medium.com/@nsethi610/data-cleaning-scale-and-normalize-data-4a7c781dd628</li>\n",
    "    <li>https://www.youtube.com/watch?v=R13BD8qKeTg&t=399s</li>\n",
    "    <li>https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
