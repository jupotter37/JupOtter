{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Frequent Itemsets\n",
    "Data Mining 2022/2023   \n",
    "Danny Plenge and Gosia Migut  \n",
    "Revised by Aleksander Buszydlik\n",
    "\n",
    "**WHAT** This *optional* lab consists of several programming exercises and insight questions. These exercises are meant to let you practice with the theory covered in: [Chapter 6][1] from \"Mining of Massive Datasets\" by J. Leskovec, A. Rajaraman, J. D. Ullman. <br>\n",
    "\n",
    "**WHY** Practicing, both through programming and answering the insight questions, aims at deepening your knowledge and preparing you for the exam.  \n",
    "\n",
    "**HOW** Follow the exercises in this notebook either on your own or with a friend. Use [StackOverflow][2]\n",
    "to discuss the questions with your peers. For additional questions and feedback please consult the TAs during the assigned lab session. The answers to these exercises will not be provided.\n",
    "\n",
    "[1]: http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "[2]: https://stackoverflow.com/c/tud-cs/questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "In the following exercises you will work on implementing algorithms to detect frequent itemsets.\n",
    "* Exercise 1: A-Priori algorithm\n",
    "* Exercise 2 (optional): PCY algotihm\n",
    "\n",
    "In addition, we will be comparing the efficiency of the two algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/site-packages (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This installs the required library.\n",
    "!pip install sortedcontainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: A-Priori algorithm\n",
    "\n",
    "The A-Priori algorithm was introduced as a way to efficiently find association rules between items. During the lecture you learned how this knowledge may be very important to, for example, a store chain which would like to know about its customers' buying habits. A-Priori works well even with very large datasets that do not fit in memory because it finds the frequent itemsets iteratively, applying a bottom-up approach. This offers a significant improvement over naive approaches which try to verify for each candidate itemset whether it is frequent. As an example, if we know that watermelons aren't bought frequently, then it is also impossible that watermelons and pineapples are frequently bought together. In this exercise you will implement the A-Priori algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The A-Priori algorithm consists of three phases that are repeated until some number of frequent itemsets of a chosen size are found. The steps of the A-Priori algorithm are given below:\n",
    "\n",
    "1. Construct a set of candidate itemsets $C_k$\n",
    "2. Go through the data and for each basket construct subsets of size $k$. For each of these subsets, increment the support value if a subset exists in $C_k$.\n",
    "3. Filter the set of candidate itemsets to get the set of truly frequent itemsets. That is, verify if the support value of an itemset is equal to or larger than the support threshold.\n",
    "4. Go to step 1 for $k = k + 1$. Repeat until you found frequent itemsets of the required size.\n",
    "\n",
    "Below we define some helper functions that will be used throughout the assignment. Please do not modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedSet\n",
    "\n",
    "def get_subsets(set1, k):\n",
    "    result = SortedSet()\n",
    "    \n",
    "    set_list = set(set1)\n",
    "    subset = set()\n",
    "    get_subsets_(set_list, subset, k, result)\n",
    "    return result\n",
    "\n",
    "# This is a helper function for getSubsets\n",
    "def get_subsets_(set1, subset, subset_size, candidates):\n",
    "    if subset_size == len(subset):\n",
    "        candidates.add(frozenset(x for x in subset))\n",
    "    else:\n",
    "        for s in set1:\n",
    "            subset.add(s)\n",
    "            clone = set(set1)\n",
    "            clone.remove(s)\n",
    "            get_subsets_(clone, subset, subset_size, candidates)\n",
    "            subset.remove(s)\n",
    "\n",
    "# The Support Threshold\n",
    "support_threshold = 3\n",
    "\n",
    "baskets = list(set())\n",
    "baskets.append(set(\"Cat and dog bites\".lower().split(\" \")))\n",
    "baskets.append(set(\"Yahoo news claims a cat mated with a dog and produced viable offspring\".lower().split(\" \")))\n",
    "baskets.append(set(\"Cat killer likely is a big dog\".lower().split(\" \")))\n",
    "baskets.append(set(\"Professional free advice on dog training puppy training\".lower().split(\" \")))\n",
    "baskets.append(set(\"Cat and kitten training and behavior\".lower().split(\" \")))\n",
    "baskets.append(set(\"Dog & Cat provides dog training in Eugene Oregon\".lower().split(\" \")))\n",
    "baskets.append(set(\"Dog and cat is a slang term used by police officers for a male female relationship\".lower().split(\" \")))\n",
    "baskets.append(set(\"Shop for your show dog grooming and pet supplies\".lower().split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Implement `construct_candidates`\n",
    "\n",
    "Implement the functionality of the `construct_candidates` function. It performs the first step of the process, constructing the set $C_k$ containing all candidate itemsets of size $k$ given the set $L_{k-1}$ of filtered candidate itemsets of size $k - 1$. For the initial case $k = 1$, where no filtered candidate set is present yet, it returns all sets of size 1. For larger $k$, it should check the union of every possible pair of itemsets in $L_{kâˆ’1}$ . If the size of a union is $k$, then this union is a candidate itemset. Note that the size of the union may also be larger than $k$, in which case it is not a candidate.  \n",
    "**Note:** This approach often creates more candidate itemsets than necessary but for the purpose of this exercise it will suffice.  \n",
    "**Hint:** Remember that at this stage you should simply create a list of potential candidates (so you should not filter them yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_candidates(baskets, filtered, k):\n",
    "    \"\"\"\n",
    "    This function will create candidates for the A-Priori algorithm.\n",
    "    :param baskets: A list of baskets containing the strings\n",
    "    :param filtered: The set of filtered candidates from the last iteration\n",
    "    :param k: The size of the required itemsets\n",
    "    :return: A list of candidates (sets of strings)\n",
    "    \"\"\"\n",
    "    candidates = list()\n",
    "    \n",
    "    # First iteration\n",
    "    if filtered == None:\n",
    "        for basket in baskets:\n",
    "            for string in basket:\n",
    "                s = set()\n",
    "                s.add(string)\n",
    "                \n",
    "                if s not in candidates:\n",
    "                    candidates.append(s)\n",
    "    \n",
    "    else:     \n",
    "    # Create k-item combinations of itemsets from the filtered set\n",
    "        for st1 in filtered:\n",
    "            for st2 in filtered:\n",
    "                un = st1.union(st2)\n",
    "                if len(un) == k and un not in candidates:\n",
    "                    candidates.append(un)\n",
    "    \n",
    "    return candidates  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "filtered = None\n",
    "test_baskets =  [set(), set(\"abc\"), set(\"bcd\"), set(\"aaa\")]\n",
    "\n",
    "test_candidates = construct_candidates(test_baskets, filtered, k)\n",
    "expected_candidates = [{'b'}, {'c'}, {'a'}, {'d'}]\n",
    "\n",
    "assert sorted(test_candidates, key=lambda x: str(x)) == sorted(expected_candidates, key=lambda x: str(x)), f\"{test_candidates} != {expected_candidates}\"\n",
    "\n",
    "for candidate in test_candidates:\n",
    "    assert candidate in expected_candidates, f\"{candidate} is not in {expected_candidates}\"\n",
    "    \n",
    "assert len(test_candidates) == len(expected_candidates), f\"{test_candidates} != {expected_candidates}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "filtered = {frozenset({\"c\"}), frozenset(\"b\"), frozenset(\"a\")}\n",
    "\n",
    "test_candidates = construct_candidates(test_baskets, filtered, k)\n",
    "expected_candidates = [{'c', 'a'}, {'c', 'b'}, {'a', 'b'}]\n",
    "\n",
    "assert sorted(test_candidates, key=lambda x: str(x)) == sorted(expected_candidates, key=lambda x: str(x)), f\"{test_candidates} != {expected_candidates}\"\n",
    "sorted(test_candidates, key=lambda x: str(x))\n",
    "\n",
    "for candidate in test_candidates:\n",
    "    assert candidate in expected_candidates, f\"{candidate} is not in {expected_candidates}\"\n",
    "    \n",
    "assert len(test_candidates) == len(expected_candidates), f\"{test_candidates} != {expected_candidates}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement `count_candidates`\n",
    "\n",
    "Implement the functionality of the `count_candidates` function which performs the second step of the process.  \n",
    "**Hint:** You can use the `get_subsets` function to create subsets of size $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_candidates(baskets, candidates, k):\n",
    "    \"\"\"\n",
    "    This function will count the candidates for the A-Priori algorithm.\n",
    "    It will return a dictionary with the candidates as keys and corresponding amounts as values.\n",
    "    :param baskets: A list of baskets containing the strings\n",
    "    :param candidates: The list of candidates (sets of strings)\n",
    "    :param k: The size of the required itemsets\n",
    "    :return: A dictionary storing the amount for each unique candidate\n",
    "    \"\"\"\n",
    "    candidates_count = dict()\n",
    "    \n",
    "    for b in baskets:\n",
    "        occurences = get_subsets(b, k)\n",
    "        \n",
    "        for occ in candidates:\n",
    "            if occ in occurences:\n",
    "                if frozenset(occ) in candidates_count:\n",
    "                \n",
    "                    candidates_count[frozenset(occ)] = candidates_count[frozenset(occ)] +1\n",
    "                else:\n",
    "                    candidates_count[frozenset(occ)] = 1\n",
    "            \n",
    "\n",
    "    return candidates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "filtered = None\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\"), set(\"aaa\")]\n",
    "\n",
    "candidates = construct_candidates(test_baskets, filtered, k)\n",
    "counted_candidates = count_candidates(test_baskets, candidates, k)\n",
    "expected_counted_candidates = {frozenset({\"b\"}): 2, frozenset({\"a\"}): 2, frozenset({\"c\"}): 2, frozenset({\"d\"}): 1}\n",
    "\n",
    "assert counted_candidates == expected_counted_candidates, f\"{counted_candidates} != {expected_counted_candidates}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "filtered = {frozenset({\"c\"}), frozenset(\"b\"), frozenset(\"a\")}\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\")]\n",
    "candidates = construct_candidates(test_baskets, filtered, k)\n",
    "counted_candidates = count_candidates(test_baskets, candidates, k)\n",
    "expected_counted_candidates = {frozenset({'b', 'c'}): 2, frozenset({'a', 'b'}): 1, frozenset({'a', 'c'}): 1}\n",
    "\n",
    "assert counted_candidates == expected_counted_candidates, f\"{counted_candidates} != {expected_counted_candidates}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement `filter_candidates`\n",
    "\n",
    "This next function should verify whether the amount of occurrences stored for a candidate matches the support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_candidates(candidates_count, support_threshold):\n",
    "    \"\"\"\n",
    "    This function will filter the candidates for the A-Priori algorithm.\n",
    "    :param candidates_Count: A dictionary with the candidates as keys and corresponding amounts as values\n",
    "    :param support_threshold: The chosen support threshold\n",
    "    :return: A set representing the filtered candidate itemsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_candidates = set()\n",
    "    \n",
    "    print(len(candidates_count))\n",
    "    for cand,count in candidates_count.items():\n",
    "        if count >= support_threshold:\n",
    "            filtered_candidates.add(cand)\n",
    "    \n",
    "    return filtered_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "filtered = None\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\"), set(\"aaa\")]\n",
    "test_support_threshold = 2\n",
    "\n",
    "candidates = construct_candidates(test_baskets, filtered, test_support_threshold)\n",
    "counted_candidates = count_candidates(test_baskets, candidates, k)\n",
    "filtered_candidates = filter_candidates(counted_candidates, test_support_threshold)\n",
    "expected_filtered_candidates = {frozenset({\"c\"}), frozenset(\"a\"), frozenset(\"b\")}\n",
    "\n",
    "assert filtered_candidates == expected_filtered_candidates, f\"{filtered_candidates} != {expected_filtered_candidates}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\"), set(\"aaa\")]\n",
    "filtered = {frozenset({\"c\"}), frozenset(\"b\"), frozenset(\"a\")}\n",
    "\n",
    "candidates = construct_candidates(test_baskets, filtered, test_support_threshold)\n",
    "counted_candidates = count_candidates(test_baskets, candidates, k)\n",
    "filtered_candidates = filter_candidates(counted_candidates, test_support_threshold)\n",
    "expected_filtered_candidates = {frozenset({'b', 'c'})}\n",
    "\n",
    "assert filtered_candidates == expected_filtered_candidates, f\"{filtered_candidates} != {expected_filtered_candidates}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement `get_frequent_sets`\n",
    "\n",
    "Our last function implements the entire A-Priori algorithm by combining the methods we have created in previous steps. For each size from $1$ to $k$, it should:\n",
    "1. construct candidate itemsets\n",
    "2. count the occurrences of these itemsets\n",
    "3. filter them and return truly frequent itemsets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frequent_sets(baskets, support_threshold, k):\n",
    "    \"\"\"\n",
    "    This function will create a set of frequent item sets by performing the entire A-Priori algorithm.\n",
    "    :param baskets: A list of baskets containing the strings\n",
    "    :param support_threshold: The chosen support threshold\n",
    "    :param k: The size of the required itemsets\n",
    "    :return: A set containing the frozensets of all the 'frequent items'\n",
    "    \"\"\"\n",
    "    filtered_candidates = None\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        candidates = construct_candidates(baskets, filtered_candidates, i)\n",
    "        candidates_count = count_candidates(baskets, candidates, i)\n",
    "\n",
    "        filtered_candidates = filter_candidates(candidates_count, support_threshold)\n",
    "\n",
    "    return filtered_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\")]\n",
    "test_support_threshold = 2\n",
    "\n",
    "filtered_candidates = get_frequent_sets(test_baskets, test_support_threshold, k)\n",
    "expected_filtered_candidates = {frozenset({\"c\"}), frozenset(\"b\")}\n",
    "\n",
    "assert filtered_candidates == expected_filtered_candidates, f\"{filtered_candidates} != {expected_filtered_candidates}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\")]\n",
    "\n",
    "filtered_candidates = get_frequent_sets(test_baskets, test_support_threshold, k)\n",
    "expected_filtered_candidates = {frozenset({\"b\", \"c\"})}\n",
    "\n",
    "assert filtered_candidates == expected_filtered_candidates, f\"{filtered_candidates} != {expected_filtered_candidates}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Performing the A-Priori algorithm\n",
    "\n",
    "Run the A-Priori algorithm using the function `get_frequent_sets` to verify whether your code works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "[['a'], ['and'], ['cat'], ['dog'], ['training']]\n",
      "46\n",
      "9\n",
      "[['a', 'cat'], ['a', 'dog'], ['and', 'cat'], ['and', 'dog'], ['cat', 'dog']]\n",
      "46\n",
      "9\n",
      "4\n",
      "[['a', 'cat', 'dog'], ['and', 'cat', 'dog']]\n",
      "46\n",
      "46\n",
      "9\n",
      "46\n",
      "9\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 1)]) )\n",
    "print(sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 2)]) )\n",
    "print(sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 3)]) )\n",
    "assert sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 1)]) == [['a'], ['and'], ['cat'], ['dog'], ['training']], \"Incorrect A-Priori itemsets of size 1\"\n",
    "assert sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 2)]) == [['a', 'cat'], ['a', 'dog'], ['and', 'cat'], ['and', 'dog'], ['cat', 'dog']], \"Incorrect A-Priori itemsets of size 2\"\n",
    "assert sorted([sorted(list(x)) for x in get_frequent_sets(baskets, support_threshold, 3)]) == [['a', 'cat', 'dog'], ['and', 'cat', 'dog']], \"Incorrect A-Priori itemsets of size 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1}$: What are the frequent doubletons in our case? If we want to compute frequent itemsets of size k, how many passes through the data do we need to do using the A-Priori algorithm?\n",
    "\n",
    "To answer your first question, frequent doubletons are pairs of items that frequently co-occur in the dataset. In other words, these are itemsets of size 2 that have a high support count.\n",
    "\n",
    "To find frequent doubletons using the A-Priori algorithm, we need to perform two passes through the data. In the first pass, we count the occurrences of each item in the dataset and identify the frequent items. In the second pass, we use the frequent items from the first pass to generate candidate doubletons and count their occurrences. We then identify the frequent doubletons based on their support count.\n",
    "\n",
    "To compute frequent itemsets of size k using the A-Priori algorithm, we need to perform k passes through the data. In each pass, we generate candidate itemsets of size k based on the frequent itemsets from the previous pass and count their occurrences. We then identify the frequent itemsets based on their support count. This approach is known as the \"level-wise\" search strategy, where we generate candidate itemsets of size k from frequent itemsets of size k-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 2}$: An alternative would be to read through the baskets and immediately construct subsets of size $k$ and count how many times each of them occurred, thereby avoiding the calculation of frequent itemsets of size $1$ to $k âˆ’ 1$. Why is this not feasible for larger datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (extra practice): PCY algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make a small improvement to the A-Priori algorithm and turn it into the Park-Chen-Yu (PCY) algorithm. This algorithm allows for a more efficient use of memory during the first pass as it modifies the way in which candidate pairs are chosen to be frequent itemsets, that is, it affects the set $C_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Implement `count_PCY_candidates`\n",
    "\n",
    "Complete the implementation of the `count_PCY_candidates` function. It is very similar to the corresponding step of A-Priori. However, when iterating over the data with $k = 1$, you should also generate the subsets of size $k + 1 = 2$, hash them, and increment the value stored in a bucket where they are hashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_PCY_candidates(baskets, candidates, k, bucket_size, buckets):\n",
    "    \"\"\"\n",
    "    This function will count the candidates for the PCY algorithm \n",
    "    :param baskets: A list of baskets containing the strings\n",
    "    :param candidates: A list of candidates (strings)\n",
    "    :param k: The size of the required itemsets\n",
    "    :param bucket_size: The chosen bucket size\n",
    "    :param buckets: The list of buckets\n",
    "    :return: A dictionary showing the amount for each unique candidate\n",
    "    \"\"\"\n",
    "        \n",
    "    if k != 1:\n",
    "        return count_candidates(baskets, candidates, k)\n",
    " \n",
    "    for i in range(bucket_size):\n",
    "        buckets.append(0)\n",
    "    \n",
    "    candidates_count = dict()\n",
    "    \n",
    "    for b in baskets:\n",
    "        subsets = get_subsets(b, 1)\n",
    "        for c in subsets:\n",
    "            if frozenset(c) in candidates_count:\n",
    "                candidates_count[frozenset(c)] = candidates_count[frozenset(c)] + 1\n",
    "            else:\n",
    "                candidates_count[frozenset(c)] = 1\n",
    "                \n",
    "    for b in baskets:\n",
    "        subsets = get_subsets(b, 2)\n",
    "        for c in subsets:\n",
    "            buckets[hash(frozenset(c))%bucket_size] = buckets[hash(frozenset(c))%bucket_size] + 1\n",
    "                        \n",
    "            \n",
    "    print(sum(buckets))       \n",
    "\n",
    "    return candidates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "bucket_size = 4\n",
    "buckets = []\n",
    "test_baskets = [set(), set(\"abc\"), set(\"bcd\"), set(\"aaa\")]\n",
    "candidates = [{'b'}, {'c'}, {'a'}, {'b'}, {'c'}, {'d'}, {'a'}]\n",
    "\n",
    "counted_PCY_candidates = count_PCY_candidates(test_baskets, candidates, k, bucket_size, buckets)\n",
    "expected_counted_PCY_candidates = {frozenset({'a'}): 2, frozenset({'c'}): 2, frozenset({'b'}): 2, frozenset({'d'}): 1}\n",
    "\n",
    "assert counted_PCY_candidates == expected_counted_PCY_candidates, f\"{counted_PCY_candidates} != {expected_counted_PCY_candidates}\"\n",
    "assert sum(buckets) == 6, f\"Not all of the subsets have been counted. 6 subset should have been counted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement `construct_candidates`\n",
    "Next we will be implementing the `construct_candidates` function. Again, this implementation is very similar to the implementation of the A-Priori. However for k = 2, before adding an itemset to the set of candidates, also test that the itemset hashes to a frequent bucket (i.e. a bucket with a count of at least `support_threshold`). If this is not the case, the itemset should be skipped.  \n",
    "  \n",
    "**Hint:** Only frozensets can be hashed. You can convert a set to a frozenset in the following way:  \n",
    "\n",
    "```python\n",
    "s = set()  \n",
    "s = frozenset(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_threshold = 3;\n",
    "\n",
    "def construct_PCY_candidates(baskets, filtered, k, bucket_size, buckets):\n",
    "    \"\"\"\n",
    "    This function will create candidates for the A-Priori algorithm.\n",
    "    :param baskets: A list of strings containg the baskets\n",
    "    :param filtered: The filtered candidates from the last iteration\n",
    "    :param k: The chosen size k\n",
    "    :param bucket_size: The chosen bucket size\n",
    "    :param buckets: The list of buckets\n",
    "    :return: A list of candidates (sets of strings)\n",
    "    \"\"\"\n",
    "    \n",
    "    candidates = list()\n",
    "    \n",
    "    # First iteration\n",
    "    if filtered == None:\n",
    "        for b in baskets:\n",
    "            for s in b:\n",
    "                s1 = set()\n",
    "                s1.add(s)\n",
    "                \n",
    "                if s1 not in candidates:\n",
    "                    candidates.append(s1)\n",
    "                hvalue  = hash(frozenset(s1)) % bucket_size\n",
    "                buckets[hvalue] = 1\n",
    "\n",
    "    else: \n",
    "        \n",
    "            if k != 2:\n",
    "                candidates = construct_candidates(baskets, filtered, k)\n",
    "            else:\n",
    "                for st1 in filtered:\n",
    "                    for st2 in filtered:\n",
    "                        un = st1.union(st2)\n",
    "                        if len(un) == k and un not in candidates and buckets[hash(un) % bucket_size] >= support_threshold:\n",
    "                            candidates.append(un)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement `get_PCY_frequent_sets`\n",
    "\n",
    "Combine the two functions implemented previously (`construct_PCY_candidates` and `count_PCY_candidates`) into `get_PCY_frequent_sets` which will calculate the frequent itemsets of the PCY algorithm. You can use the `filter_candidates` function implemented for the A-Priori algorithm. Set the `bucket_size` to 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_PCY_frequent_sets(baskets, support_threshold, k, bucket_size):\n",
    "    \"\"\"\n",
    "    This function will get the frequent item sets by performing the whole PCY algorithm\n",
    "    :param baskets: A list of strings containg the baskets\n",
    "    :param support_threshold: The chosen support threshold\n",
    "    :param k: The chosen size k\n",
    "    :param bucket_size: The chosen bucket size\n",
    "    :return: A set containing the frozensets of all the 'frequent items'\n",
    "    \"\"\"\n",
    "    filtered_candidates = []\n",
    "    buckets = list()\n",
    "    \n",
    "    for i in range (1, k+1):\n",
    "        candidate_items = construct_PCY_candidates(baskets, filtered_candidates, i, bucket_size, buckets)\n",
    "        counted_candidates = count_PCY_candidates(baskets, candidate_items, i, bucket_size, buckets)\n",
    "        filtered_candidates = filter_candidates(counted_candidates, support_threshold)\n",
    "    \n",
    "    \n",
    "    return filtered_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "46\n",
      "293\n",
      "46\n",
      "7\n",
      "293\n",
      "46\n",
      "7\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "assert sorted([sorted(list(x)) for x in get_PCY_frequent_sets(baskets, support_threshold, 1, 256)]) == [['a'], ['and'], ['cat'], ['dog'], ['training']], \"Incorrect PCY itemsets of size 1\"\n",
    "assert sorted([sorted(list(x)) for x in get_PCY_frequent_sets(baskets, support_threshold, 2, 256)]) == [['a', 'cat'], ['a', 'dog'], ['and', 'cat'], ['and', 'dog'], ['cat', 'dog']], \"Incorrect PCY itemsets of size 2\"\n",
    "assert sorted([sorted(list(x)) for x in get_PCY_frequent_sets(baskets, support_threshold, 3, 256)]) == [['a', 'cat', 'dog'], ['and', 'cat', 'dog']], \"Incorrect PCY itemsets of size 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 3}$: Compared to the A-Priori algorithm, what is the difference in the number of candidate sets checked by the PCY algorithm?\n",
    "\n",
    "The PCY (Park, Chen, and Yu) algorithm is an improvement over the Apriori algorithm for frequent itemset mining in large datasets. The main difference between the two algorithms is the way they prune infrequent itemsets.\n",
    "\n",
    "In the Apriori algorithm, all candidate itemsets are generated and counted, even if some of them are unlikely to be frequent. This results in a large number of candidate itemsets, which can be computationally expensive to generate and count.\n",
    "\n",
    "On the other hand, the PCY algorithm uses a two-step approach to reduce the number of candidate itemsets. In the first step, it uses a hash function to map each item to a bucket. Then, it scans the dataset once to count the frequency of each item and the frequency of each pair of items that land in the same bucket. In the second step, it generates candidate itemsets using only the frequent items and pairs that have a count greater than a threshold value. This reduces the number of candidate itemsets significantly and improves the efficiency of the algorithm.\n",
    "\n",
    "Therefore, the PCY algorithm checks a smaller number of candidate sets compared to the Apriori algorithm, which results in faster processing times and reduced computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 4}$: What is the advantage of the PCY algorithm over the A-Priori algorithm?\n",
    "\n",
    "The PCY (Park-Chen-Yu) algorithm is an improvement over the Apriori algorithm, which is a popular algorithm for mining frequent itemsets in data mining. The PCY algorithm offers several advantages over the Apriori algorithm, including:\n",
    "\n",
    "Reduction in candidate itemsets: The Apriori algorithm generates all possible itemsets, even those that are infrequent. The PCY algorithm, on the other hand, reduces the number of candidate itemsets by using a hash table to count the frequency of candidate itemsets in the first pass over the data. The hash table is used to identify potentially frequent itemsets, which are then used to generate candidate itemsets in the second pass. This reduces the number of candidate itemsets and speeds up the mining process.\n",
    "\n",
    "Efficient use of memory: The Apriori algorithm needs to keep track of all frequent itemsets in memory, which can be a challenge for large datasets. The PCY algorithm, on the other hand, only needs to keep track of the hash table in memory, which is much smaller than the set of all frequent itemsets. This makes the PCY algorithm more memory-efficient.\n",
    "\n",
    "Better scalability: The PCY algorithm is more scalable than the Apriori algorithm, particularly for datasets with a large number of items. This is because the Apriori algorithm generates a large number of candidate itemsets, many of which are pruned, whereas the PCY algorithm generates fewer candidate itemsets due to the use of the hash table. This makes the PCY algorithm more suitable for large-scale data mining tasks.\n",
    "\n",
    "In summary, the PCY algorithm offers several advantages over the Apriori algorithm, including reduced candidate itemsets, more efficient use of memory, and better scalability. These advantages make the PCY algorithm a popular choice for frequent itemset mining in data mining tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 5}$: What is the influence of the bucket size on the algorithm? For example, what would happen if the bucket size was be too low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
