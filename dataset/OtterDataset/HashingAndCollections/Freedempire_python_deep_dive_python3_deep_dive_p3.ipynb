{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Deep Dive Part 3 - Dictionaries, Sets, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associative arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associative arrays\n",
    "\n",
    "* In computer science, an associative array, map, symbol table, or dictionary is an abstract data type that stores a collection of (key, value) pairs, such that each possible key appears at most once in the collection.\n",
    "* The name does not come from the associative property known in mathematics. Rather, it arises from the association of values with keys. It is not to be confused with associative processors.\n",
    "* The dictionary problem is the classic problem of designing efficient data structures that implement associative arrays. The two major solutions to the dictionary problem are *hash tables* and *search trees*. It is sometimes also possible to solve the problem using directly addressed arrays, binary search trees, or other more specialized structures.\n",
    "* In an associative array, the association between a key and a value is often known as a \"mapping\"; the same word may also be used to refer to the process of creating a new association.\n",
    "\n",
    "Operations\n",
    "\n",
    "* The operations that are usually defined for an associative array are:\n",
    "  * adding / removing elements\n",
    "  * looking up a value via key\n",
    "  * modifying an associated value\n",
    "\n",
    "Implementation comparison\n",
    "\n",
    "| Underlying data structure | Lookup or Removal (average) | Lookup or Removal (worst case) | Insertion (average) | Insertion (worst case) | Ordered |\n",
    "|---|---|---|---|---|---|\n",
    "| Hash table | O(1) | O(n) | O(1) | O(n) | No |\n",
    "| Self-balancing binary search tree | O(log n) | O(log n) | O(log n) | O(log n) | Yes |\n",
    "| Unbalanced binary search tree | O(log n) | O(n) | O(log n) | O(n) | Yes |\n",
    "| Sequential container of key–value pairs (e.g., association list)| O(n) | O(n) | O(1) | O(1) | No |\n",
    "\n",
    "Ordered dictionary\n",
    "\n",
    "* The basic definition of a dictionary does not mandate an order. To guarantee a fixed order of enumeration, ordered versions of the associative array are often used. There are two senses of an ordered dictionary:\n",
    "  * The order of enumeration is always deterministic for a given set of keys by sorting. This is the case for tree-based implementations, one representative being the `<map>` container of C++.\n",
    "  * The order of enumeration is key-independent and is instead based on the order of insertion. This is the case for the \"ordered dictionary\" in .NET Framework, the `LinkedHashMap` of Java and Python.\n",
    "* The latter is more common. Such ordered dictionaries can be implemented using an association list, by overlaying a doubly linked list on top of a normal dictionary, or by moving the actual data out of the sparse (unordered) array and into a dense insertion-ordered one.\n",
    "\n",
    "Dictionaries in Python\n",
    "\n",
    "* Dictionaries are everywhere in Python\n",
    "  * modules\n",
    "  * classes\n",
    "  * objects\n",
    "  * scopes\n",
    "  * sets\n",
    "  * custom dictionaries\n",
    "* It is one of the most important data structure in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash maps\n",
    "\n",
    "* One common concrete implementation of an associative array is a hash map.\n",
    "* In computing, a hash table, also known as a hash map or a hash set, is a data structure that implements an associative array, also called a dictionary, which is an abstract data type that maps keys to values.\n",
    "* A hash table uses a *hash function* to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found.\n",
    "* During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\n",
    "* Ideally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause *hash collisions* where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\n",
    "* Hashing is an example of a space-time tradeoff.\n",
    "  * If memory is infinite, the entire key can be used directly as an index to locate its value with a single memory access.\n",
    "  * If infinite time is available, values can be stored without regard for their keys, and a binary search or linear search can be used to retrieve the element.\n",
    "* In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.\n",
    "\n",
    "Hash function\n",
    "\n",
    "* A hash function is any function that can be used to map data of arbitrary size to fixed-size values, though there are some hash functions that support variable length output.\n",
    "* The values returned by a hash function are called hash values, hash codes, hash digests, digests, or simply hashes.\n",
    "* The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\n",
    "* Hash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval.\n",
    "* Hashing is a computationally and storage space-efficient form of data access that avoids the non-constant access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\n",
    "* A good hash function satisfies two basic properties:\n",
    "  * it should be very fast to compute;\n",
    "  * it should minimize duplication of output values (collisions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dictionaries\n",
    "\n",
    "* Python dictionaries are ubiquitous.\n",
    "  * namespaces\n",
    "  * classes\n",
    "  * modules\n",
    "  * functions\n",
    "  * sets\n",
    "  * custom dictionaries\n",
    "* Dictionaries are such an important part of Python that a lot of time and effort was put into making them as efficient as possible.\n",
    "\n",
    "PEP 412: Key-sharing dictionary\n",
    "\n",
    "* This PEP proposes a change in the implementation of the builtin dictionary type `dict`. The new implementation allows dictionaries which are used as attribute dictionaries (the `__dict__` attribute of an object) to share keys with other attribute dictionaries of instances of the same class.\n",
    "\n",
    "Compact dictionary\n",
    "\n",
    "* Python 3.6 introduced a more memory-efficient implementation of the `dict` type based on [a proposal by Raymond Hettinger](https://mail.python.org/pipermail/python-dev/2012-December/123028.html).\n",
    "* The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python's `hash()` function\n",
    "\n",
    "* `hash(object)`\n",
    "  * Return the hash value of the object (if it has one).\n",
    "  * Hash values are integers. They are used to quickly compare dictionary keys during a dictionary lookup.\n",
    "  * Numeric values that compare equal have the same hash value (even if they are of different types, as is the case for `1` and `1.0`).\n",
    "  * For objects with custom `__hash__()` methods, note that `hash()` truncates the return value based on the bit width of the host machine (`sys.hash_info.width`).\n",
    "  * Hash values for objects that compare equal remain equal during program run, but they can *change from run to run*, so you should never rely on a hash value being the same from one program run to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "hash(1)=1\n",
      "hash(1.0)=1\n",
      "hash(2)=2\n",
      "hash(2.1)=230584300921369602\n",
      "hash('1')=-2520627851638319182\n",
      "hash((1, 2))=-3550055125485641917\n",
      "hash(frozenset((1, 2)))=-1826646154956904602\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.hash_info.width)\n",
    "print(f'{hash(1)=}')\n",
    "print(f'{hash(1.0)=}')\n",
    "print(f'{hash(2)=}')\n",
    "print(f'{hash(2.1)=}')\n",
    "print(f'{hash('1')=}')\n",
    "print(f'{hash((1, 2))=}')\n",
    "print(f'{hash(frozenset((1, 2)))=}')\n",
    "# print(f'{hash([1, 2])=}') # unhashable type: 'list'\n",
    "# print(f'{hash((0, [1, 2]))=}') # unhashable type: 'list'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionaries\n",
    "\n",
    "Dictionary elements\n",
    "\n",
    "* Basic structure of dictionary elements: key value pairs.\n",
    "  * value -> any Python object\n",
    "  * key -> any hashable object, because hash tables require hash of an object to be constant for the life of the program\n",
    "\n",
    "Hashable objects\n",
    "\n",
    "* int, float, complex, binary, Decimal, Fraction -> immutable -> hashable\n",
    "* string -> immutable collection -> hashable\n",
    "* frozenset -> immutable collection, its elements are required to be hashable -> hashable\n",
    "* tuple -> immutable collection -> hashable only if all elements are also hashable\n",
    "* set, dictionary -> mutable collections -> unhashable\n",
    "* list -> mutable collection -> unhashable\n",
    "* function -> immutable -> hashable\n",
    "* custom class and object -> maybe hashable\n",
    "\n",
    "Requirements for hash functions\n",
    "\n",
    "* If an object is hashable:\n",
    "  * the hash of the object must be an integer value\n",
    "  * if two objects compare equal, the hashes must be equal\n",
    "* Two objects that do not compare equal may still have the same hash (hash collision).\n",
    "\n",
    "Ways of creating dictionaries\n",
    "\n",
    "* Use a comma-separated list of `key: value` pairs within braces: `{'jack': 4098, 'sjoerd': 4127} or {4098: 'jack', 4127: 'sjoerd'}`\n",
    "* Use a dict comprehension: `{}`, `{x: x ** 2 for x in range(10)}`\n",
    "* Use the type constructor: `dict()`, `dict([('foo', 100), ('bar', 200)])`, `dict(foo=100, bar=200)`, `dict(zip(['one', 'two', 'three'], [1, 2, 3]))`, `dict({'one': 1, 'three': 3}, two=2)`\n",
    "  * `class dict(**kwargs)`\n",
    "  * `class dict(mapping, **kwargs)`\n",
    "  * `class dict(iterable, **kwargs)`\n",
    "  * If keyword arguments are given, the keyword arguments and their values are added to the dictionary created from the positional argument.\n",
    "    * If a key being added is already present, the value from the keyword argument replaces the value from the positional argument.\n",
    "    * Keyword arguments only works for keys that are valid Python *identifiers*, and dictionary keys will then be a string of that name.\n",
    "* `classmethod fromkeys(iterable[, value])`\n",
    "  * Create a new dictionary with keys from `iterable` and values set to `value`.\n",
    "  * `fromkeys()` is a class method that returns a new dictionary. `value` defaults to `None`. All of the values refer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as an empty list. To get distinct values, use a dict comprehension instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "d7={0: None, 1: None, 2: None}\n",
      "d8={(0, 0): 0.0, (0, 1): 1.0, (0, 2): 2.0, (1, 0): 1.0, (1, 1): 1.4142135623730951, (1, 2): 2.23606797749979, (2, 0): 2.0, (2, 1): 2.23606797749979, (2, 2): 2.8284271247461903}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "d1 = {'one': 1, 'two': 2, 'three': 3}\n",
    "d2 = dict(one=1, two=2, three=3)\n",
    "d3 = dict((('one', 1), ('two', 2), ('three', 3)))\n",
    "d4 = dict(zip(('one', 'two', 'three'), (1, 2, 3)))\n",
    "d5 = dict({'one': 1, 'two': 2}, three=3)\n",
    "d6 = {k: v for k, v in zip(('one', 'two', 'three'), (1, 2, 3))}\n",
    "print(d1 == d2 == d3 == d4 == d5 == d6)\n",
    "d7 = dict.fromkeys(i for i in range(3)) # you can omit the outer parentheses when a generator expression is used as the sole argument to a function\n",
    "print(f'{d7=}')\n",
    "d8 = {(x, y): math.hypot(x, y) for x in range(3) for y in range(3)}\n",
    "print(f'{d8=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d1 == d2)=True\n",
      "(d1 is d2)=False\n",
      "(d1['list'] is d2['list'])=True\n",
      "(d1['list'] is d3['list'])=True\n"
     ]
    }
   ],
   "source": [
    "d1 = {'num': 1, 'list': [1, 2, 3]}\n",
    "d2 = dict(d1) # make a shallow copy of d1\n",
    "print(f'{(d1 == d2)=}')\n",
    "print(f'{(d1 is d2)=}')\n",
    "print(f'{(d1['list'] is d2['list'])=}') # true\n",
    "d3 = dict(d1, extra=2)\n",
    "print(f'{(d1['list'] is d3['list'])=}') # true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common operations\n",
    "\n",
    "Basic operations\n",
    "\n",
    "* `d[key] = value`\n",
    "  * creates `key` if it does not exist already\n",
    "  * assigns `value` to `key`\n",
    "* `d[key]`\n",
    "  * as an expression returns the value for specific key\n",
    "  * exception `KeyError` if `key` is not found\n",
    "* `d.get(key[, default])`\n",
    "  * returns the value for `key` if `key` is in `d`, else `default`\n",
    "  * if `default` is not given, it defaults to `None`\n",
    "  * this method never raises a `KeyError`\n",
    "* `key in d`, `key not in d`\n",
    "  * membership testing\n",
    "* `len(d)`\n",
    "  * number of items in dictionary\n",
    "* `d.clear()`\n",
    "  * clears out all items, `d` becomes empty with its id unchanged\n",
    "* `del d[key]`\n",
    "  * removes element with that `key` from `d`\n",
    "  * exception `KeyError` if `key` is not in `d`\n",
    "* `d.pop(key[, default])`\n",
    "  * if `key` is in `d`, remove it and return its value, else return `default`\n",
    "  * if `default` is not given and `key` is not in `d`, a `KeyError` is raised\n",
    "* `d.popitem()`\n",
    "  * removes an item from `d`\n",
    "  * returns a `(key, value)` pair\n",
    "  * pairs are returned in LIFO (last in, first out) order\n",
    "  * `KeyError` if `d` is empty\n",
    "  * `popitem()` is useful to destructively iterate over a dictionary, as often used in set algorithms\n",
    "  * since version 3.7, LIFO order is guaranteed, while in prior versions, `popitem()` would return an arbitrary item\n",
    "* `d.setdefault(key[, default])`\n",
    "  * if `key` is in the dictionary, return its value\n",
    "  * if not, insert `key` with a value of `default` and return `default`\n",
    "  * `default` defaults to `None`\n",
    "* `d.items()`\n",
    "  * returns a new view of `d`'s items (`(key, value)` pairs).\n",
    "* `d.update([other])`\n",
    "  * update `d` with the key/value pairs from `other`, overwriting existing keys\n",
    "  * returns `None`\n",
    "  * `update()` accepts either another dictionary object or an iterable of key/value pairs (as tuples or other iterables of length two)\n",
    "  * if keyword arguments are specified, the dictionary is then updated with those key/value pairs: `d.update(red=1, blue=2)`\n",
    "* `d | other`\n",
    "  * creates a new dictionary with the merged keys and values of `d` and `other`, which must both be dictionaries\n",
    "  * the values of `other` take priority when `d` and `other` share keys\n",
    "* `d |= other`\n",
    "  * update the dictionary `d` with keys and values from `other`, which may be either a mapping or an iterable of key/value pairs\n",
    "  * the values of `other` take priority when `d` and `other` share keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d={0: None, 1: None, 2: None}, id(d)=2284074067328\n",
      "d={}, id(d)=2284074067328\n"
     ]
    }
   ],
   "source": [
    "d = dict.fromkeys(i for i in range(3))\n",
    "print(f'{d=}, {id(d)=}')\n",
    "d.clear()\n",
    "print(f'{d=}, {id(d)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uppercases': {'W': 8, 'M': 3, 'S': 4, 'C': 5, 'A': 2, 'I': 7, 'T': 6, 'D': 1, 'L': 1, 'F': 3, 'E': 3, 'G': 3, 'H': 2, 'V': 1, 'U': 1, 'Y': 1, 'J': 1, 'P': 2, 'O': 1, 'R': 1}, 'lowercases': {'h': 62, 'a': 170, 't': 171, 's': 127, 'e': 255, 'v': 50, 'r': 143, 'n': 141, 'd': 52, 'y': 28, 'o': 131, 'u': 44, 'l': 88, 'b': 19, 'm': 51, 'i': 162, 'c': 70, 'w': 21, 'k': 8, 'z': 1, 'g': 30, 'p': 40, 'x': 4, 'f': 17, 'j': 3}, 'others': {'’': 6}, 'punctuations': {'?': 4, ',': 29, '.': 25, ':': 7, '-': 1, '/': 1, '!': 1}, 'digits': {'2': 1, '4': 1, '7': 1}}\n",
      "{'uppercases': {'A': 2, 'C': 5, 'D': 1, 'E': 3, 'F': 3, 'G': 3, 'H': 2, 'I': 7, 'J': 1, 'L': 1, 'M': 3, 'O': 1, 'P': 2, 'R': 1, 'S': 4, 'T': 6, 'U': 1, 'V': 1, 'W': 8, 'Y': 1}, 'lowercases': {'a': 170, 'b': 19, 'c': 70, 'd': 52, 'e': 255, 'f': 17, 'g': 30, 'h': 62, 'i': 162, 'j': 3, 'k': 8, 'l': 88, 'm': 51, 'n': 141, 'o': 131, 'p': 40, 'r': 143, 's': 127, 't': 171, 'u': 44, 'v': 50, 'w': 21, 'x': 4, 'y': 28, 'z': 1}, 'others': {'’': 6}, 'punctuations': {'!': 1, ',': 29, '-': 1, '.': 25, '/': 1, ':': 7, '?': 4}, 'digits': {'2': 1, '4': 1, '7': 1}}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def get_category(c):\n",
    "    # use dictionary, so that no need to iterate\n",
    "    category_dict = (dict.fromkeys(string.ascii_lowercase, 'lowercases') |\n",
    "                     dict.fromkeys(string.ascii_uppercase, 'uppercases') |\n",
    "                     dict.fromkeys(string.digits, 'digits') |\n",
    "                     dict.fromkeys(string.punctuation, 'punctuations'))\n",
    "    return category_dict.get(c, 'others')\n",
    "\n",
    "text = '''What’s the Metaverse and Why Should We Care About It?\n",
    "The metaverse is an immersive virtual reality environment that combines work, socializing, shopping, and gaming. Depending on who you talk to, it’s either a utopia or a dystopia. Some view it as the next version of the internet, while others see it as a better version of the online world Second Life. Major companies like Facebook, Microsoft, and Epic Games are investing heavily in its development.\n",
    "The concept of the metaverse has been around for decades, but recent advancements in technology have brought it closer to reality. Imagine a digital universe where you can create an avatar, interact with others, attend virtual events, and explore endless virtual landscapes. It’s a place where physical and digital boundaries blur, and the possibilities are limited only by our imagination.\n",
    "Here are some key points about the metaverse:\n",
    "Virtual Worlds: The metaverse consists of interconnected virtual worlds. These worlds can be entirely fictional or mirror real-world locations. Users can navigate through these spaces using their avatars.\n",
    "Social Interaction: In the metaverse, social interactions are central. You can chat with friends, attend virtual parties, collaborate on projects, or even meet new people. It’s like a 24/7 digital social gathering.\n",
    "Economy and Commerce: Just like in the real world, the metaverse has its economy. People buy and sell virtual goods, services, and properties. Cryptocurrencies play a significant role here.\n",
    "Gaming and Entertainment: Gaming is a major part of the metaverse. From immersive multiplayer games to virtual concerts, entertainment options are vast. Artists perform live in virtual venues, and users can participate from anywhere.\n",
    "Challenges and Concerns: While the metaverse promises exciting possibilities, it also raises concerns. Privacy, security, and ethical issues need careful consideration. Who owns the virtual spaces? How do we prevent abuse and harassment?\n",
    "The Future: The metaverse is still evolving, and its impact on society remains uncertain. Will it enhance our lives or lead to further isolation? Only time will tell.\n",
    "In summary, the metaverse is a digital frontier where creativity, collaboration, and innovation converge. Whether you’re an early adopter or a skeptic, it’s a concept worth exploring. Read more about it here and dive into this fascinating realm!'''\n",
    "\n",
    "char_count = {}\n",
    "\n",
    "for c in text:\n",
    "    if c.strip():\n",
    "        # method 1: use match case with guard\n",
    "        # match c:\n",
    "        #     case c if c in string.ascii_lowercase:\n",
    "        #         category = 'lowercases'\n",
    "        #     case c if c in string.ascii_uppercase:\n",
    "        #         category = 'uppercases'\n",
    "        #     case c if c in string.punctuation:\n",
    "        #         category = 'punctuations'\n",
    "        #     case c if c in string.digits:\n",
    "        #         category = 'digits'\n",
    "        #     case _:\n",
    "        #         category = 'others'\n",
    "\n",
    "        # method 2: use if-else\n",
    "        # if c in string.ascii_lowercase:\n",
    "        #     category = 'lowercases'\n",
    "        # elif c in string.ascii_uppercase:\n",
    "        #     category = 'uppercases'\n",
    "        # elif c in string.punctuation:\n",
    "        #     category = 'punctuations'\n",
    "        # elif c in string.digits:\n",
    "        #     category = 'digits'\n",
    "        # else:\n",
    "        #     category = 'others'\n",
    "\n",
    "        # method 3: use an function that wrapped the above process\n",
    "        category = get_category(c)\n",
    "\n",
    "        # char_count.setdefault(category, {})\n",
    "        # char_count[category][c] = char_count[category].get(c, 0) + 1\n",
    "        char_count[category][c] = char_count.setdefault(category, {}).get(c, 0) + 1 # the rhs evaluates first\n",
    "\n",
    "print(char_count)\n",
    "\n",
    "for k, v in char_count.items():\n",
    "    char_count[k] = dict(sorted(char_count[k].items()))\n",
    "print(char_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary views\n",
    "\n",
    "* The objects returned by `dict.keys()`, `dict.values()` and `dict.items()` are view objects.\n",
    "* They provide a *dynamic* view on the dictionary's entries, which means that when the dictionary changes, the view reflects these changes.\n",
    "* Dictionary views can be iterated over to yield their respective data, and support membership tests.\n",
    "* Views are read-only and not updatable.\n",
    "* Keys views are set-like since their entries are unique and hashable.\n",
    "* Items views also have set-like operations since the (key, value) pairs are unique and the keys are hashable. If all values in an items view are hashable as well, then the items view can interoperate with other sets.\n",
    "* Values views are not treated as set-like since the entries are generally not unique.\n",
    "* For set-like views, all of the operations defined for the abstract base class `collections.abc.Set` are available (for example, `==`, `<`, or `^`).\n",
    "* While using set operators, set-like views accept any iterable as the other operand, unlike sets which only accept sets as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1, 2])\n",
      "dict_values([10, 2])\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1, 'b': 2}\n",
    "values_view = d.values()\n",
    "print(values_view)\n",
    "d['a'] = 10\n",
    "print(values_view) # changed, dynamically reflect the values of the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': (2, 2), 'c': (3, 6)}\n",
      "{'d': 4, 'a': 1}\n"
     ]
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "d2 = {'b': 2, 'c': 6, 'd': 4}\n",
    "\n",
    "d1_keys = d1.keys()\n",
    "d2_keys = d2.keys()\n",
    "\n",
    "# create a dictionary with common keys and both values from dicts above\n",
    "common_keys = d1_keys & d2_keys\n",
    "d3 = {common_key: (d1[common_key], d2[common_key])\n",
    "      for common_key in common_keys}\n",
    "print(d3)\n",
    "\n",
    "# create a dictionary with only unique keys in both dicts above\n",
    "unique_keys = d1_keys ^ d2_keys\n",
    "d4 = {unique_key: d1.get(unique_key) or d2.get(unique_key) for unique_key in unique_keys}\n",
    "print(d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Updating, merging and copying\n",
    "\n",
    "Updating & merging\n",
    "\n",
    "* `update([other])` has three forms\n",
    "  * `d1.update(d2)`\n",
    "  * `d1.update(iterable)`: an iterable of key/value pairs (as tuples or other iterables of length two)\n",
    "  * `d1.update(**kwargs)`: only works for keys that are valid identifiers\n",
    "* Unpacking dictionaries: `d = {**d1, **d2, **d3}`\n",
    "  * unlike dictionary unpacking for function arguments, keys does not need to be valid identifiers\n",
    "\n",
    "Copying\n",
    "\n",
    "* Shallow copies\n",
    "  * container object is a new object\n",
    "  * copied container element keys / elements are shared references with original object\n",
    "  * `d.copy()`\n",
    "  * `{**d}`\n",
    "  * `dict(d)`\n",
    "  * `{k, v for k, v in d.items()}`, slower than the above\n",
    "* Deep copies\n",
    "  * no shared references\n",
    "  * sometimes requires recursion, have to be careful with circular references\n",
    "  * `copy.deepcopy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 5, 'c': 3, 'd': 4}\n"
     ]
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 2}\n",
    "d2 = {'c': 3, 'b': 5}\n",
    "d1.update(d2, d=4)\n",
    "print(d1) # insertion order are guaranteed, not updating order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy by shallow copy: 0.23981210007332265\n",
      "copy by unpacking: 0.22421070002019405\n",
      "copy by constructor: 0.22063910006545484\n",
      "copy by comprehension: 1.0174344999250025\n",
      "copy by deep copy: 8.563632600009441\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "from random import randrange\n",
    "from copy import deepcopy\n",
    "\n",
    "big_dict = {k: randrange(100) for k in range(1000000)}\n",
    "\n",
    "def copy_unpacking(d):\n",
    "    {**d}\n",
    "\n",
    "def copy_constructor(d):\n",
    "    dict(d)\n",
    "\n",
    "def copy_copy(d):\n",
    "    d.copy()\n",
    "\n",
    "def copy_comprehension(d):\n",
    "    {k: v for k, v in d.items()}\n",
    "\n",
    "def copy_deep(d):\n",
    "    deepcopy(d)\n",
    "\n",
    "print('copy by shallow copy:', timeit('copy_copy(big_dict)', globals=globals(), number=10))\n",
    "print('copy by unpacking:', timeit('copy_unpacking(big_dict)', globals=globals(), number=10))\n",
    "print('copy by constructor:', timeit('copy_constructor(big_dict)', globals=globals(), number=10))\n",
    "print('copy by comprehension:', timeit('copy_comprehension(big_dict)', globals=globals(), number=10)) # slower than other shallow copy methods\n",
    "print('copy by deep copy:', timeit('copy_deep(big_dict)', globals=globals(), number=10)) # deep copy is much slower than shallow copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom classes and hashing\n",
    "\n",
    "How Python inserts a key-value item in a dictionary\n",
    "\n",
    "* hash(key)\n",
    "* mod dictionary size\n",
    "* start index in hash table (sequence of slots)\n",
    "* generate probe sequence (sequence of valid indices)\n",
    "* iterate over probe sequence\n",
    "  * is the slot at that index empty?\n",
    "    * yes -> store the new item there (hash, key, value)\n",
    "    * no -> hash collision -> continue iteration to look for an empty slot\n",
    "      * more collision, more inefficient\n",
    "\n",
    "How Python finds a key in a dictionary\n",
    "\n",
    "* hash(key)\n",
    "* mod dictionary size\n",
    "* start index in hash table (sequence of slots)\n",
    "* generate probe sequence (sequences of valid indices)\n",
    "* look over probe sequence\n",
    "  * is slot empty?\n",
    "    * yes -> key does not exist in dictionary\n",
    "    * no -> are hashes equal and are keys equal?\n",
    "      * yes -> found the key\n",
    "      * no -> caused by collision upon insertion / resizing -> continue iteration to find key or empty slot\n",
    "\n",
    "Object hashes\n",
    "\n",
    "* An object hash in Python must satisfy the following:\n",
    "  * the result must be an integer\n",
    "  * if `a == b`, then `hash(a) == hash(b)`\n",
    "    * do not require that if `hash(a) == hash(b)` then `a == b`, i.e. two objects that are not equal, can have the same hash (hash collision)\n",
    "\n",
    "Custom classes\n",
    "\n",
    "* By default, custom class compare `==` if they have the same id.\n",
    "* By default, Python automatically make custom objects without `__eq__` method hashable.\n",
    "  * it uses the id to make a hash\n",
    "  * but this is not very useful\n",
    "* So we need to define equality for custom classes\n",
    "  * but this will lead to the lose of automatic id based hashing of the custom class\n",
    "    * because if Python uses the default hash based on id, it will cause contradiction: `obj1 == obj2` is true but `hash(obj1) == hash(obj2)` is false\n",
    "* So we need to define hash for custom classes\n",
    "  * `__hash__`\n",
    "    * set `__hash__` attribute to `None` to indicate the class is unhashable, this is what happens when only `__eq__` is defined but not `__hash__`\n",
    "    * `__hash__` must return an integer\n",
    "    * if `a == b`, then `hash(a) == hash(b)`\n",
    "\n",
    "What happens when calling `hash(obj)`\n",
    "\n",
    "* looks for `obj.__hash__`\n",
    "* `None` means not hashable\n",
    "* otherwise, calls `obj.__hash__()`\n",
    "* truncates returned integer to 32-bit or 64-bit depending on Python (`sys.hash_info.width`, `sys.hash_info.modulus`) -> `obj.__hash__() % sys.hash_info.modulus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(id=12372730557963379020, name=tony)\n",
      "843515511894909265\n",
      "False\n",
      "False\n",
      "843515511894909265\n",
      "Person(id=1, name=tony)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, id=None):\n",
    "        self._id = id if id is not None else int.from_bytes(os.urandom(8))\n",
    "        self.name = name\n",
    "\n",
    "    @property\n",
    "    def id(self):\n",
    "        return self._id\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, name):\n",
    "        if isinstance(name, str):\n",
    "            self._name = name\n",
    "        else:\n",
    "            raise ValueError('name should be a string')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Person(id={self._id}, name={self._name})'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self._id == other._id\n",
    "        else:\n",
    "            return NotImplemented\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self._id)\n",
    "    \n",
    "p1 = Person('tony')\n",
    "p2 = Person('freer')\n",
    "print(p1)\n",
    "print(hash(p1))\n",
    "print(p1 == p2)\n",
    "print(p1 == 1)\n",
    "p1.name = 'tom'\n",
    "print(hash(p1))\n",
    "\n",
    "p3 = Person('tony', 1)\n",
    "p4 = Person('freer', 1)\n",
    "print(p3)\n",
    "print(p3 == p4)\n",
    "print(hash(p3) == hash(p4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a Python function that will create and return a dictionary from another dictionary, but sorted by value. You can assume the values are all comparable and have a natural sort order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 0, 'b': 2, 'd': 4, 'a': 10}\n",
      "{'Wolfgang': 35, 'Frederic': 39, 'Ludwig': 56, 'Johann': 65}\n"
     ]
    }
   ],
   "source": [
    "def sort_dict_by_value(d):\n",
    "    sorted_items = sorted(d.items(), key=lambda item: item[1])\n",
    "    return dict(sorted_items)\n",
    "\n",
    "d = {'a': 10, 'b': 2, 'c': 0, 'd': 4}\n",
    "print(sort_dict_by_value(d))\n",
    "\n",
    "composers = {'Johann': 65, 'Ludwig': 56, 'Frederic': 39, 'Wolfgang': 35}\n",
    "print(sort_dict_by_value(composers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Given two dictionaries, `d1` and `d2`, write a function that creates a dictionary that contains only the keys common to both dictionaries, with values being a tuple containg the values from `d1` and `d2`. (Order of keys is not important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': (2, 20), 'c': (3, 30)}\n"
     ]
    }
   ],
   "source": [
    "def accumulate_intersection(d1, d2):\n",
    "    common_keys = d1.keys() & d2.keys()\n",
    "    return {common_key: (d1[common_key], d2[common_key]) for common_key in common_keys}\n",
    "\n",
    "d1 = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "d2 = {'b': 20, 'c': 30, 'y': 40, 'z': 50}\n",
    "\n",
    "print(accumulate_intersection(d1, d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "You have text data spread across multiple servers. Each server is able to analyze this data and return a dictionary that contains words and their frequency.\n",
    "\n",
    "Your job is to combine this data to create a single dictionary that contains all the words and their combined frequencies from all these data sources. Bonus points if you can make your dictionary sorted by frequency (highest to lowest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 16, 'javascript': 15, 'java': 13, 'c#': 12, 'c++': 10, 'go': 9}\n",
      "{'python': 17, 'javascript': 15, 'java': 13, 'c#': 12, 'c++': 10, 'go': 9, 'erlang': 5, 'haskell': 2, 'pascal': 1}\n"
     ]
    }
   ],
   "source": [
    "# from functools import reduce\n",
    "\n",
    "def combine_dicts(*dicts):\n",
    "    # combined_keys = reduce(lambda a, b: a | b, map(lambda d: d.keys(), dicts))\n",
    "    # return sort_dict_by_value({k: sum(d.get(k, 0) for d in dicts) for k in combined_keys}, True)\n",
    "    combined_dict = {}\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            combined_dict[k] = combined_dict.get(k, 0) + v\n",
    "    return sort_dict_by_value(combined_dict, True)\n",
    "\n",
    "def sort_dict_by_value(d, reverse=False):\n",
    "    return dict(sorted(d.items(), key=lambda item: item[1], reverse=reverse))\n",
    "\n",
    "d1 = {'python': 10, 'java': 3, 'c#': 8, 'javascript': 15}\n",
    "d2 = {'java': 10, 'c++': 10, 'c#': 4, 'go': 9, 'python': 6}\n",
    "d3 = {'erlang': 5, 'haskell': 2, 'python': 1, 'pascal': 1}\n",
    "\n",
    "print(combine_dicts(d1, d2))\n",
    "print(combine_dicts(d1, d2, d3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "For this exercise suppose you have a web API load balanced across multiple nodes. This API receives various requests for resources and logs each request to some local storage. Each instance of the API is able to return a dictionary containing the resource that was accessed (the dictionary key) and the number of times it was requested (the associated value).\n",
    "\n",
    "Your task here is to identify resources that have been requested on some, but not all the servers, so you can determine if you have an issue with your load balancer not distributing certain resource requests across all nodes.\n",
    "\n",
    "For simplicity, we will assume that there are exactly 3 nodes in the cluster.\n",
    "\n",
    "You should write a function that takes 3 dictionaries as arguments for node 1, node 2, and node 3, and returns a dictionary that contains only keys that are not found in **all** of the dictionaries. The value should be a list containing the number of times it was requested in each node (the node order should match the dictionary (node) order passed to your function). Use `0` if the resource was not requested from the corresponding node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'login': (0, 0, 1000), 'employee': (5000, 0, 0), 'user': (100, 230, 0)}\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def analyze_balance(*dicts):\n",
    "    keys_list = list(map(lambda d: d.keys(), dicts))\n",
    "    common_keys = reduce(lambda a, b: a & b, keys_list)\n",
    "    combined_keys = reduce(lambda a, b: a | b, keys_list)\n",
    "    differentiated_keys = combined_keys - common_keys\n",
    "    return {k: tuple(d.get(k, 0) for d in dicts) for k in differentiated_keys}\n",
    "\n",
    "n1 = {'employees': 100, 'employee': 5000, 'users': 10, 'user': 100}\n",
    "n2 = {'employees': 250, 'users': 23, 'user': 230}\n",
    "n3 = {'employees': 150, 'users': 4, 'login': 1000}\n",
    "\n",
    "print(analyze_balance(n1, n2, n3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic set theory\n",
    "\n",
    "What is a set\n",
    "\n",
    "* A set object is an *unordered* collection of *distinct* *hashable* objects.\n",
    "* Common uses include membership testing, removing duplicates from a sequence, and computing mathematical operations such as intersection, union, difference, and symmetric difference.\n",
    "  * `s1.intersection(s2)`, `s1 & s2`\n",
    "  * `s1.union(s2)`, `s1 | s2`\n",
    "  * `s1.difference(s2)`, `s1 - s2`\n",
    "  * `s1.symmetric_difference(s2)`, `s1 ^ s2`\n",
    "* Like other collections, sets support `x in set`, `len(set)`, and `for x in set`.\n",
    "  * For finite sets, the cardinality of a set is the number of elements in the set.\n",
    "  * An empty set contains no elements, i.e. cardinality 0, and can be create by `set()`.\n",
    "  * Two set are said to be disjoint if their intersection is an empty list, i.e. `len(s1 & s2) == 0` or `s1.isdisjoint(s2) == True`.\n",
    "* Being an unordered collection, sets do not record element position or order of insertion. Accordingly, sets do not support indexing, slicing, or other sequence-like behavior.\n",
    "* There are currently two built-in set types, set and frozenset.\n",
    "  * The set type is mutable — the contents can be changed using methods like `add()` and `remove()`. Since it is mutable, it has no hash value and cannot be used as either a dictionary key or as an element of another set.\n",
    "  * The frozenset type is immutable and hashable — its contents cannot be altered after it is created; it can therefore be used as a dictionary key or as an element of another set.\n",
    "\n",
    "Subsets and supersets\n",
    "\n",
    "* A set `s1` is a subset of `s2` if all the elements in `s1` are in `s2`.\n",
    "  * `s1 <= s2`\n",
    "  * `s1.issubset(s2)`\n",
    "* A set `s1` is a proper subset of `s2` if `s1` is a subset of `s2` but `s1` is not equal to `s2`.\n",
    "  * `s1 < s2`\n",
    "* A set `s1` is a superset of `s2` if `s2` is a subset of `s1`.\n",
    "  * `s1 >= s2`\n",
    "  * `s1.issupset(s2)`\n",
    "* A set `s1` is a proper superset of `s2` if `s2` is a proper subset of `s1`.\n",
    "  * `s1 > s2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python sets\n",
    "\n",
    "* `class set([iterable])`, `class frozenset([iterable])`\n",
    "  * Returns a new set or frozenset object whose elements are taken from `iterable`. The elements of a set must be *hashable*. To represent sets of sets, the inner sets must be frozenset objects. If iterable is not specified, a new empty set is returned.\n",
    "* Sets can be created by several means:\n",
    "  * Use a comma-separated list of elements within braces: `{'jack', 'sjoerd'}`\n",
    "  * Use unpacking: `{*{1, 2}, *{3, 4}}`\n",
    "    * unpacking for function arguments also works but the order of the arguments are not guaranteed\n",
    "  * Use a set comprehension: `{c for c in 'abracadabra' if c not in 'abc'}`\n",
    "  * Use the type constructor: `set()`, `set('foobar')`, `set(['a', 'b', 'foo'])`\n",
    "\n",
    "Membership testing\n",
    "\n",
    "* Testing membership of an element in a set is extremely efficient (hash table lookup).\n",
    "* Instead of writing code like `if a in (1, 2, 3):`, prefer using (as long as elements are hashable) `if a in {1, 2, 3}:` (with higher storage cost).\n",
    "  * list / tuple lookup -> scan until found\n",
    "  * set / dictionary -> hash table -> direct lookup (possible hash collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{1, 2, 3}\n",
      "{'p', 't', 'n', 'h', 'y', 'o'}\n",
      "{'p', 't', 'n', 'h', 'y', 'o'}\n",
      "{1, 'p', 't', 'n', 2, 'h', 'y', 'o'}\n"
     ]
    }
   ],
   "source": [
    "print(set())\n",
    "print(set((1, 2, 3)))\n",
    "# print(set((1, [1, 2]))) # elements must be hashable\n",
    "print(set('python'))\n",
    "print({c for c in 'python'}) # slower than the above way\n",
    "print({*'python', *[1, 2, 'p']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4230769230769231\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def scorer(string):\n",
    "    alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    string_letters = set(string.lower()) & alphabet\n",
    "    return len(string_letters) / len(alphabet)\n",
    "\n",
    "print(scorer('play the world!'))\n",
    "print(scorer('the quick brown fox jumps over the lazy dog'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common operations\n",
    "\n",
    "Operations available for both instances of set and frozenset\n",
    "\n",
    "* `len(s)`\n",
    "  * Return the number of elements in set `s` (cardinality of `s`).\n",
    "* `x in s`\n",
    "  * Test `x` for membership in `s`.\n",
    "* `x not in s`\n",
    "  * Test `x` for non-membership in `s`.\n",
    "* `isdisjoint(other)`\n",
    "  * Return `True` if the set has no elements in common with `other`. Sets are disjoint if and only if their intersection is the empty set.\n",
    "* `issubset(other)`, `set <= other`\n",
    "  * Test whether every element in the set is in `other`.\n",
    "* `set < other`\n",
    "  * Test whether the set is a proper subset of `other`, that is, `set <= other and set != other`.\n",
    "* `issuperset(other)`, `set >= other`\n",
    "  * Test whether every element in `other` is in the set.\n",
    "* `set > other`\n",
    "  * Test whether the set is a proper superset of `other`, that is, `set >= other and set != other`.\n",
    "* `union(*others)`, `set | other | ...`\n",
    "  * Return a new set with elements from the set and all others.\n",
    "* `intersection(*others)`, `set & other & ...`\n",
    "  * Return a new set with elements common to the set and all others.\n",
    "* `difference(*others)`, `set - other - ...`\n",
    "  * Return a new set with elements in the set that are not in the others.\n",
    "* `symmetric_difference(other)`, `set ^ other`\n",
    "  * Return a new set with elements in either the set or `other` but not both.\n",
    "* `copy()`\n",
    "  * Return a shallow copy of the set.\n",
    "* The non-operator versions of `union()`, `intersection()`,` difference()`, `symmetric_difference()`, `issubset()`, and `issuperset()` methods will accept any *iterable* as an argument.\n",
    "  * In contrast, their operator based counterparts require their arguments to be sets.\n",
    "  * This precludes error-prone constructions like `set('abc') & 'cbs'` in favor of the more readable `set('abc').intersection('cbs')`.\n",
    "* Instances of set are compared to instances of frozenset based on their members. For example, `set('abc') == frozenset('abc')` returns `True` and so does `set('abc') in set([frozenset('abc')])`.\n",
    "* Binary operations that mix set instances with frozenset return the type of the first operand. For example: `frozenset('ab') | set('bc')` returns an instance of frozenset.\n",
    "* The subset and equality comparisons do not generalize to a total ordering function. For example, any two nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return `False`: `a<b`, `a==b`, or `a>b`.\n",
    "* Since sets only define partial ordering (subset relationships), the output of the `list.sort()` method is undefined for lists of sets.\n",
    "\n",
    "Operations available for set that do not apply to immutable instances of frozenset\n",
    "\n",
    "* `update(*others)`, `set |= other | ...`\n",
    "  * Update the set, adding elements from all others.\n",
    "* `intersection_update(*others)`, `set &= other & ...`\n",
    "  * Update the set, keeping only elements found in it and all others.\n",
    "* `difference_update(*others)`, `set -= other | ...`\n",
    "  * Update the set, removing elements found in others.\n",
    "* `symmetric_difference_update(other)`, `set ^= other`\n",
    "  * Update the set, keeping only elements found in either set, but not in both.\n",
    "* `add(elem)`\n",
    "  * Add element `elem` to the set.\n",
    "* `remove(elem)`\n",
    "  * Remove element `elem` from the set. Raises `KeyError` if `elem` is not contained in the set.\n",
    "* `discard(elem)`\n",
    "  * Remove element `elem` from the set if it is present.\n",
    "* `pop()`\n",
    "  * Remove and return an arbitrary element from the set. Raises `KeyError` if the set is empty.\n",
    "* `clear()`\n",
    "  * Remove all elements from the set.\n",
    "* The non-operator versions of the `update()`, `intersection_update()`, `difference_update()`, and `symmetric_difference_update()` methods will accept any *iterable* as an argument.\n",
    "* The `elem` argument to the `__contains__()`, `remove()`, and `discard()` methods may be a set. To support searching for an equivalent *frozenset*, a temporary one is created from `elem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "{1, 2, 3, 4, 5, 6, 7, frozenset({1, 6})}\n",
      "{1, 2, 3, 4, 5, 6, frozenset({1, 6})}\n",
      "1\n",
      "{2, 3, 4, 5, 6, frozenset({1, 6})}\n",
      "{5, 6, frozenset({1, 6})}\n"
     ]
    }
   ],
   "source": [
    "s = {1, 2, 3, 4, 5, 6, frozenset((1, 6))}\n",
    "print(1 in s)\n",
    "print({1, 6} in s) # an temporary equivalent frozenset of {1, 6} is created to support searching \n",
    "s.add(7)\n",
    "print(s)\n",
    "s.remove(7)\n",
    "print(s)\n",
    "print(s.pop())\n",
    "print(s)\n",
    "s.discard(7) # no error for non-existing element\n",
    "s -= {1, 2} | {3, 4}\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.__sizeof__()=48\n",
      "s.__sizeof__()=200\n",
      "l.__sizeof__()=40\n",
      "d.__sizeof__()=208\n",
      "s.__sizeof__()=200\n",
      "l.__sizeof__()=72\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "s = set()\n",
    "l = []\n",
    "print(f'{d.__sizeof__()=}')\n",
    "print(f'{s.__sizeof__()=}')\n",
    "print(f'{l.__sizeof__()=}')\n",
    "\n",
    "d[1] = None\n",
    "s.add(1)\n",
    "l.append(1)\n",
    "print(f'{d.__sizeof__()=}')\n",
    "print(f'{s.__sizeof__()=}')\n",
    "print(f'{l.__sizeof__()=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen sets\n",
    "\n",
    "* Frozen sets are immutable sets, with the same properties and behaviors as sets except that they cannot be mutable.\n",
    "* Their elements can be mutable.\n",
    "* Frozenset is hashable, so that it can be used as a key in a dictionary and an element of another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(fs1 is fs2)=True\n",
      "(fs1 is fs3)=False\n",
      "type(s1 | fs1)=<class 'set'>\n",
      "type(fs1 | s1)=<class 'frozenset'>\n",
      "(fs1 == s4)=True\n",
      "(fs1 is s4)=False\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "fs1 = frozenset({1, 2, 3})\n",
    "fs2 = frozenset(fs1)\n",
    "print(f'{(fs1 is fs2)=}') # when making a shallow copy of a frozenset, the copy is actually the same object\n",
    "fs3 = deepcopy(fs1)\n",
    "print(f'{(fs1 is fs3)=}')\n",
    "\n",
    "s1 = {4, 5, 6}\n",
    "print(f'{type(s1 | fs1)=}') # the type of the result set depends on the first operand\n",
    "print(f'{type(fs1 | s1)=}')\n",
    "\n",
    "s4 = {1, 2, 3}\n",
    "print(f'{(fs1 == s4)=}')\n",
    "print(f'{(fs1 is s4)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({75, 'John'}): Person(name=John, age=75), frozenset({'Eric', 78}): Person(name=Eric, age=78)}\n",
      "Person(name=John, age=75)\n",
      "Person(name=John, age=75)\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self._name = name\n",
    "        self._age = age\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def age(self):\n",
    "        return self._age\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self._name}, age={self._age})'\n",
    "    \n",
    "    def key(self): # serves as dictionary key\n",
    "        return frozenset({self._name, self._age})\n",
    "    \n",
    "p1 = Person('John', 75)\n",
    "p2 = Person('Eric', 78)\n",
    "ps = {p1.key(): p1, p2.key(): p2}\n",
    "print(ps)\n",
    "print(ps[Person('John', 75).key()])\n",
    "print(ps[frozenset(('John', 75))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating a + b\n",
      "3\n",
      "3\n",
      "calculating a + b\n",
      "3\n",
      "calculating a + b\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def my_func(*, a, b):\n",
    "    print('calculating a + b')\n",
    "    return a + b\n",
    "\n",
    "print(my_func(a=1, b=2))\n",
    "print(my_func(a=1, b=2)) # look up in cache for the same function call, no calculation\n",
    "# one drawback of lru_cache\n",
    "print(my_func(b=2, a=1)) # calculate again although a and b have the same values as before\n",
    "# another drawback of lru_cache\n",
    "# print(my_func(a=[1, 2], b=[3, 4])) # unhashable type: list\n",
    "\n",
    "\n",
    "def memoizer(fn):\n",
    "    cache = {}\n",
    "    def inner(*args, **kwargs):\n",
    "        key = (args, frozenset(kwargs.items()))\n",
    "        if key in cache:\n",
    "            return cache[key]\n",
    "        else:\n",
    "            result = fn(*args, **kwargs)\n",
    "            cache[key] = result\n",
    "            return result\n",
    "    return inner\n",
    "        \n",
    "@ memoizer\n",
    "def my_func(*, a, b):\n",
    "    print('calculating a + b')\n",
    "    return a + b\n",
    "\n",
    "print(my_func(a=1, b=2))\n",
    "print(my_func(a=1, b=2))\n",
    "print(my_func(b=2, a=1)) # although the order of a, b changed, there is no need to recalculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary views\n",
    "\n",
    "Key view\n",
    "\n",
    "* `d.keys()` returns, instead of a list or an iterator, a lightweight object that\n",
    "  * maintains a reference to the dictionary\n",
    "  * implements methods such as:\n",
    "    * `__iter__`: iterable protocol\n",
    "    * `__contains__`: membership testing\n",
    "    * `__and__`: intersection of two views\n",
    "    * `__or__`: union of two views\n",
    "    * `__eq__`: same keys in both views\n",
    "    * `__lt__`: is one set of keys a subset of the other\n",
    "\n",
    "Dictionary views\n",
    "\n",
    "* Three ways to view the data in a dictionary\n",
    "  * `d.keys()`\n",
    "  * `d.values()`\n",
    "  * `d.items()`\n",
    "  * they are all iterables\n",
    "  * some may have set properties\n",
    "* The order of keys, values and items are the same.\n",
    "* In Python 3.6+, this order is the same as dictionary insertion order.\n",
    "\n",
    "Set behavior\n",
    "\n",
    "* The `keys()` view always behaves like a (frozen) set, since elements are unique and hashable.\n",
    "* The `items()` view may behave like a (frozen) set, if the values are hashable.\n",
    "* The `values()` view never behaves like a set, since values are not guaranteed unique and hashable.\n",
    "\n",
    "Modifying the dictionary while iterating over a view\n",
    "\n",
    "* Modifying values is usually not a problem.\n",
    "* Modifying keys can lead to exceptions or worse.\n",
    "  * Python does not allow modifying the size of the underlying dictionary while iterating over a view.\n",
    "  * Iterating views while adding or deleting entries in the dictionary may raise a `RuntimeError` or fail to iterate over all items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c', 3)\n",
      "('b', 2)\n",
      "('a', 1)\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "# for k, v in d.items(): # RuntimeError\n",
    "#     print(v)\n",
    "#     del d[k]\n",
    "\n",
    "# for k in list(d.keys()):\n",
    "#     # print(d[k])\n",
    "#     # del d[k]\n",
    "#     print(d.pop(k))\n",
    "\n",
    "# for _ in range(len(d)):\n",
    "#     print(d.popitem())\n",
    "\n",
    "while len(d) > 0:\n",
    "    print(d.popitem())\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1\n",
    "\n",
    "Basic info\n",
    "\n",
    "* In this project our goal is to validate one dictionary structure against a template dictionary.\n",
    "* A typical example of this might be working with JSON data inputs in an API. You are trying to validate this received JSON against some kind of template to make sure the received JSON conforms to that template, i.e. all the keys, structure and data type of the values are identical.\n",
    "* To keep things simple we'll assume that values can be either single values (like an integer, string, etc.), or a dictionary containing only single values or dictionary recursively. In other words, we're not going to deal with lists as possible values. Also we'll assume that all keys are required, and that no extra keys are permitted.\n",
    "* There are many 3rd party libraries that already exist to do this (such as `jsonschema`, `marshmallow`).\n",
    "* Write a function such this:\n",
    "    ```Python\n",
    "    def validate(data, template):\n",
    "    # return True / False\n",
    "    # in the case of False, return a string describing\n",
    "    # the first error encountered\n",
    "    # in the case of True, the string can be empty\n",
    "    return state, error\n",
    "    ```\n",
    "  * Sample returns:\n",
    "    * `validate(john, template)` -> `True, ''`\n",
    "    * `validate(eric, template)` -> `False, 'mismatched keys: bio.birthplace.city'`\n",
    "    * `validate(michael, template)` -> `False, 'bad type: bio.dob.month'`\n",
    "  * Better use exception instead of codes and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, '')\n",
      "(False, 'mismatch keys: bio.birthplace.city')\n",
      "(False, 'bad type: bio.dob.month')\n"
     ]
    }
   ],
   "source": [
    "def validate(data, template, prev_keys=None):\n",
    "    if prev_keys is None:\n",
    "        prev_keys = []\n",
    "    for k, v in template.items():\n",
    "        data_v = data.get(k, object()) # return default object() if k does not exist in data\n",
    "        # if data_v != object(): # __eq__ of object is based on id, so it's always false\n",
    "        if type(data_v) is not object:\n",
    "            data_v_type = type(data_v)\n",
    "            template_v_type = dict if isinstance(v, dict) else v\n",
    "            if data_v_type is not template_v_type:\n",
    "                prev_keys.append(k)\n",
    "                return False, f'bad type: {'.'.join(prev_keys)}'\n",
    "            else:\n",
    "                if isinstance(v, dict):\n",
    "                    prev_keys.append(k)\n",
    "                    state, error = validate(data_v, v, prev_keys)\n",
    "                    if not state:\n",
    "                        return state, error\n",
    "                    else:\n",
    "                        prev_keys.pop() # remove the last previous key if state is True\n",
    "        else:\n",
    "            prev_keys.append(k)\n",
    "            return False, f'mismatch keys: {'.'.join(prev_keys)}'\n",
    "    return True, ''\n",
    "\n",
    "template = {\n",
    "    'user_id': int,\n",
    "    'name': {\n",
    "        'first': str,\n",
    "        'last': str\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': int,\n",
    "            'month': int,\n",
    "            'day': int\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': str,\n",
    "            'city': str\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "john = {\n",
    "    'user_id': 100,\n",
    "    'name': {\n",
    "        'first': 'John',\n",
    "        'last': 'Cleese'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1939,\n",
    "            'month': 11,\n",
    "            'day': 27\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom',\n",
    "            'city': 'Weston-super-Mare'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "eric = {\n",
    "    'user_id': 101,\n",
    "    'name': {\n",
    "        'first': 'Eric',\n",
    "        'last': 'Idle'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1943,\n",
    "            'month': 3,\n",
    "            'day': 29\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "michael = {\n",
    "    'user_id': 102,\n",
    "    'name': {\n",
    "        'first': 'Michael',\n",
    "        'last': 'Palin'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1943,\n",
    "            'month': 'May',\n",
    "            'day': 5\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom',\n",
    "            'city': 'Sheffield'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(validate(john, template))\n",
    "print(validate(eric, template))\n",
    "print(validate(michael, template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: ok\n",
      "Eric: SchemaKeyMismatch('mismatch keys: bio.birthplace.city')\n",
      "Michael: SchemaTypeMismatch('bad type: bio.dob.month')\n",
      "Tony: SchemaTypeMismatch('bad type: bio')\n"
     ]
    }
   ],
   "source": [
    "class SchemaError(Exception):\n",
    "    pass\n",
    "\n",
    "class SchemaKeyMismatch(SchemaError):\n",
    "    pass\n",
    "\n",
    "class SchemaTypeMismatch(SchemaError, TypeError):\n",
    "    pass\n",
    "\n",
    "def validate(data, template, prev_keys=None):\n",
    "    if prev_keys is None:\n",
    "        prev_keys = []\n",
    "    for k, v in template.items():\n",
    "        data_v = data.get(k, object()) # return default object() if k does not exist in data\n",
    "        if type(data_v) is not object:\n",
    "            data_v_type = type(data_v)\n",
    "            template_v_type = dict if isinstance(v, dict) else v\n",
    "            if data_v_type is not template_v_type:\n",
    "                prev_keys.append(k)\n",
    "                raise SchemaTypeMismatch(f'bad type: {'.'.join(prev_keys)}')\n",
    "            else:\n",
    "                if isinstance(v, dict):\n",
    "                    prev_keys.append(k)\n",
    "                    validate(data_v, v, prev_keys)\n",
    "                    prev_keys.pop() # remove the last previous key if no exception raises\n",
    "        else:\n",
    "            prev_keys.append(k)\n",
    "            raise SchemaKeyMismatch(f'mismatch keys: {'.'.join(prev_keys)}')\n",
    "\n",
    "template = {\n",
    "    'user_id': int,\n",
    "    'name': {\n",
    "        'first': str,\n",
    "        'last': str\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': int,\n",
    "            'month': int,\n",
    "            'day': int\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': str,\n",
    "            'city': str\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "john = {\n",
    "    'user_id': 100,\n",
    "    'name': {\n",
    "        'first': 'John',\n",
    "        'last': 'Cleese'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1939,\n",
    "            'month': 11,\n",
    "            'day': 27\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom',\n",
    "            'city': 'Weston-super-Mare'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "eric = {\n",
    "    'user_id': 101,\n",
    "    'name': {\n",
    "        'first': 'Eric',\n",
    "        'last': 'Idle'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1943,\n",
    "            'month': 3,\n",
    "            'day': 29\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "michael = {\n",
    "    'user_id': 102,\n",
    "    'name': {\n",
    "        'first': 'Michael',\n",
    "        'last': 'Palin'\n",
    "    },\n",
    "    'bio': {\n",
    "        'dob': {\n",
    "            'year': 1943,\n",
    "            'month': 'May',\n",
    "            'day': 5\n",
    "        },\n",
    "        'birthplace': {\n",
    "            'country': 'United Kingdom',\n",
    "            'city': 'Sheffield'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tony = {\n",
    "    'user_id': 103,\n",
    "    'name': {\n",
    "        'first': 'Tony',\n",
    "        'last': 'King'\n",
    "    },\n",
    "    'bio': None\n",
    "}\n",
    "\n",
    "persons = [(john, 'John'), (eric, 'Eric'), (michael, 'Michael'), (tony, 'Tony')]\n",
    "\n",
    "for person, name in persons:\n",
    "    try:\n",
    "        validate(person, template)\n",
    "        print(f'{name}: ok')\n",
    "    except SchemaError as e:\n",
    "        print(f'{name}: {e.__repr__()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializaiton and deserialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Serialization and deserialization\n",
    "\n",
    "* In computing, serialization is the process of translating a data structure or object state into a format that can be stored (e.g. files in secondary storage devices, data buffers in primary storage devices) or transmitted (e.g. data streams over computer networks) and reconstructed later (possibly in a different computer environment).\n",
    "* When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references, this process is not straightforward.\n",
    "* Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked.\n",
    "* This process of serializing an object is also called marshalling an object in some situations.\n",
    "* The opposite operation, extracting a data structure from a series of bytes, is deserialization (also called unserialization or unmarshalling).\n",
    "\n",
    "Pickling and unpickling\n",
    "\n",
    "* Pickling is the process whereby a Python object hierarchy is converted into a *byte stream*.\n",
    "* Unpickling is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy.\n",
    "* Pickling (and unpickling) is alternatively known as serialization, marshalling, or flattening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling\n",
    "\n",
    "* The `pickle` module implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "* The data format used by pickle is Python-specific.\n",
    "  * This has the advantage that there are no restrictions imposed by external standards such as JSON or XDR (which can’t represent pointer sharing);\n",
    "  * however it means that non-Python programs may not be able to reconstruct pickled Python objects.\n",
    "* By default, the pickle data format uses a relatively compact binary representation. If you need optimal size characteristics, you can efficiently compress pickled data.\n",
    "* The `pickle` module keeps track of the objects it has already serialized, so that later references to the same object won't be serialized again.\n",
    "  * This has implications both for *recursive objects* and *object sharing*.\n",
    "  * Recursive objects are objects that contain references to themselves.\n",
    "  * Object sharing happens when there are multiple references to the same object in different places in the object hierarchy being serialized.\n",
    "  * `pickle` stores such objects only once, and ensures that all other references point to the master copy. Shared objects remain shared, which can be very important for mutable objects.\n",
    "* It is possible to construct malicious pickle data which will execute arbitrary code during unpickling.\n",
    "  * Never unpickle data that could have come from an untrusted source, or that could have been tampered with.\n",
    "  * Consider signing data with `hmac` if you need to ensure that it has not been tampered with.\n",
    "  * Safer serialization formats such as json may be more appropriate if you are processing untrusted data.\n",
    "\n",
    "Usage\n",
    "\n",
    "* `pickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)`\n",
    "  * Write the pickled representation of the object `obj` to the open file object `file`.\n",
    "  * This is equivalent to `Pickler(file, protocol).dump(obj)`.\n",
    "* `pickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)`\n",
    "  * Return the pickled representation of the object `obj` as a bytes object, instead of writing it to a file.\n",
    "* `pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)`\n",
    "  * Read the pickled representation of an object from the open file object `file` and return the reconstituted object hierarchy specified therein.\n",
    "  * This is equivalent to `Unpickler(file).load()`.\n",
    "  * The protocol version of the pickle is detected automatically, so no protocol argument is needed. Bytes past the pickled representation of the object are ignored.\n",
    "* `pickle.loads(data, /, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)`\n",
    "  * Return the reconstituted object hierarchy of the pickled representation `data` of an object. data must be a bytes-like object.\n",
    "  * The protocol version of the pickle is detected automatically, so no protocol argument is needed.\n",
    "  * Bytes past the pickled representation of the object are ignored.\n",
    "\n",
    "What can be pickled and unpickled?\n",
    "\n",
    "* The following types can be pickled:\n",
    "  * built-in constants (`None`, `True`, `False`, `Ellipsis`, and `NotImplemented`);\n",
    "  * integers, floating-point numbers, complex numbers;\n",
    "  * strings, bytes, bytearrays;\n",
    "  * tuples, lists, sets, and dictionaries containing only picklable objects;\n",
    "  * functions (built-in and user-defined) accessible from the top level of a module (using `def`, not `lambda`);\n",
    "  * classes accessible from the top level of a module;\n",
    "  * instances of such classes whose the result of calling `__getstate__()` is picklable.\n",
    "* Attempts to pickle unpicklable objects will raise the `PicklingError` exception.\n",
    "  * When this happens, an unspecified number of bytes may have already been written to the underlying file.\n",
    "  * Trying to pickle a highly recursive data structure may exceed the maximum recursion depth, a `RecursionError` will be raised in this case.\n",
    "  * You can carefully raise this limit with `sys.setrecursionlimit()`.\n",
    "* Functions (built-in and user-defined) are pickled by fully qualified name, not by value.\n",
    "  * This means that only the function name is pickled, along with the name of the containing module and classes.\n",
    "  * Neither the function's code, nor any of its function attributes are pickled.\n",
    "  * Thus the defining module must be importable in the unpickling environment, and the module must contain the named object, otherwise an exception will be raised.\n",
    "* Similarly, classes are pickled by fully qualified name, so the same restrictions in the unpickling environment apply.\n",
    "  * None of the class's code or data is pickled.\n",
    "  * These restrictions are why picklable functions and classes must be defined at the top level of a module.\n",
    "  * When class instances are pickled, their class's code and data are not pickled along with them.\n",
    "    * Only the instance data are pickled.\n",
    "    * This is done on purpose, so you can fix bugs in a class or add methods to the class and still load objects that were created with an earlier version of the class.\n",
    "    * If you plan to have long-lived objects that will see many versions of a class, it may be worthwhile to put a version number in the objects so that suitable conversions can be made by the class's `__setstate__()` method.\n",
    "\n",
    "Pickling class instances\n",
    "\n",
    "* In most cases, no additional code is needed to make instances picklable.\n",
    "* By default, pickle will retrieve the class and the attributes of an instance via introspection.\n",
    "* When a class instance is unpickled, its `__init__()` method is usually not invoked. The default behavior first creates an uninitialized instance and then restores the saved attributes. The following code shows an implementation of this behavior:\n",
    "    ```Python\n",
    "    def save(obj):\n",
    "        return (obj.__class__, obj.__dict__)\n",
    "\n",
    "    def restore(cls, attributes):\n",
    "        obj = cls.__new__(cls)\n",
    "        obj.__dict__.update(attributes)\n",
    "        return obj\n",
    "    ```\n",
    "* Classes can alter the default behavior by providing one or several special methods.\n",
    "  * `object.__getnewargs_ex__()`\n",
    "  * `object.__getnewargs__()`\n",
    "  * `object.__getstate__()`\n",
    "  * `object.__setstate__(state)`\n",
    "  * `object.__reduce__()`\n",
    "  * `object.__reduce_ex__(protocol)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Serialization\n",
    "\n",
    "* JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript).\n",
    "  * text-based object serialization\n",
    "  * open standard\n",
    "  * human readable\n",
    "* It's a very common format for web API's and general data interchange between systems.\n",
    "* Unlike pickling, it is considered safe, but\n",
    "  * a malicious JSON string may cause the decoder to consume considerable CPU and memory resources\n",
    "  * limiting the size of data to be parsed is recommended\n",
    "* JSON is a natural fit for serializing and deserializing Python dictionaries.\n",
    "  * Python dictionaries are objects.\n",
    "  * JSON is essentially a string. \n",
    "\n",
    "Supported data types\n",
    "\n",
    "* strings: delimited by double quotes, unicode\n",
    "* numbers: int, float\n",
    "* booleans: true, false\n",
    "* arrays (lists, tuples): delimited by square brackets\n",
    "* dictionaries: key-value pairs, keys must be strings, values are any supported data type\n",
    "* empty value: null\n",
    "\n",
    "`json` module\n",
    "\n",
    "* `json` exposes an API familiar to users of the standard library `marshal` and `pickle` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 82,\n",
      " 'boring': None,\n",
      " 'height': 1.8,\n",
      " 'name': 'John Cleese',\n",
      " 'sketches': [{'costars': ['Michael Palin'], 'title': 'Dead Parrot'},\n",
      "              {'costars': ['Michael Palin', 'Terry Jones'],\n",
      "               'title': 'Ministry of Silly Walks'}],\n",
      " 'walkFunny': True}\n",
      "<class 'int'>\n",
      "{\"a\": [1, 2, 3]}\n",
      "1\n",
      "1.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "# from fractions import Fraction\n",
    "# from decimal import Decimal\n",
    "\n",
    "d_json = '''\n",
    "{\n",
    "    \"name\": \"John Cleese\",\n",
    "    \"age\": 82,\n",
    "    \"height\": 1.8,\n",
    "    \"walkFunny\": true,\n",
    "    \"sketches\": [\n",
    "        {\n",
    "            \"title\": \"Dead Parrot\",\n",
    "            \"costars\": [\"Michael Palin\"]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Ministry of Silly Walks\",\n",
    "            \"costars\": [\"Michael Palin\", \"Terry Jones\"]\n",
    "        }\n",
    "    ],\n",
    "    \"boring\": null\n",
    "}\n",
    "'''\n",
    "d = json.loads(d_json)\n",
    "pprint(d)\n",
    "print(type(d['age']))\n",
    "\n",
    "d = {'a': (1, 2, 3)}\n",
    "d_json = json.dumps(d)\n",
    "print(d_json)\n",
    "\n",
    "print(json.dumps(1))\n",
    "print(json.dumps(1.1))\n",
    "# print(json.dumps(1+0j)) # Object of type complex is not JSON serializable\n",
    "# print(json.dumps(Fraction(1, 2))) # Object of type Fraction is not JSON serializable\n",
    "# print(json.dumps(Decimal('0.5'))) # Object of type Decimal is not JSON serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom JSON encoding\n",
    "\n",
    "Specifying a custom encoding function\n",
    "\n",
    "* One of the arguments of `dump` / `dumps` function is `default`:\n",
    "  * If specified, `default` should be a function that gets called for objects that can't otherwise be serialized.\n",
    "  * It should return a JSON encodable version of the object or raise a `TypeError`. If not specified, `TypeError` is raised.\n",
    "  * The function can include logic to differentiate between different types\n",
    "    * or we can use a single dispatch generic function (using `functools.singledispatch` decorator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07T21:29:56.469564+00:00\n",
      "{'time': datetime.datetime(2024, 2, 7, 21, 29, 56, 469564, tzinfo=datetime.timezone.utc), 'message': 'test', 'set': {1, 2, 3}, 'person': Person(name=Tony, age=18)}\n",
      "{\n",
      "    \"time\": \"2024-02-07T21:29:56.469564+00:00\",\n",
      "    \"message\": \"test\",\n",
      "    \"set\": [\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ],\n",
      "    \"person\": {\n",
      "        \"name\": \"Tony\",\n",
      "        \"age\": 18,\n",
      "        \"create_at\": \"2024-02-07T21:29:56.469564+00:00\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.create_at = datetime.datetime.now(datetime.UTC)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self.name}, age={self.age})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        # return {\n",
    "        #     'name': self.name,\n",
    "        #     'age': self.age,\n",
    "        #     'create_at': self.create_at # no need to call isoformat() on the datetime object, because when dump it, the serializer function will be called recursively\n",
    "        # }\n",
    "        return vars(self)\n",
    "\n",
    "def json_serializer(obj):\n",
    "    if isinstance(obj, datetime.datetime):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    elif isinstance(obj, Person):\n",
    "        return obj.to_json()\n",
    "\n",
    "current_dt = datetime.datetime.now(datetime.UTC)\n",
    "print(current_dt.isoformat())\n",
    "log_record = {'time': current_dt,\n",
    "              'message': 'test',\n",
    "              'set': {1, 2, 3},\n",
    "              'person': Person('Tony', 18)}\n",
    "print(log_record)\n",
    "# json.dumps(log_record) # Object of type datetime is not JSON serializable\n",
    "\n",
    "log_record_serialized = json.dumps(log_record, default=json_serializer, indent=4)\n",
    "print(log_record_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"created_at\": \"2024-02-08T07:55:16.221482+00:00\",\n",
      "    \"point_1\": {\n",
      "        \"x\": 0,\n",
      "        \"y\": 0\n",
      "    },\n",
      "    \"point_2\": {\n",
      "        \"x\": \"1.5\",\n",
      "        \"y\": \"-2.5\"\n",
      "    },\n",
      "    \"points\": \"{Point(x=0, y=0), Point(x=1.5, y=-2.5)}\",\n",
      "    \"created_by\": {\n",
      "        \"name\": \"Tony\",\n",
      "        \"age\": 24\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self.name}, age={self.age})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return vars(self)\n",
    "    \n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Point(x={self.x}, y={self.y})'\n",
    "    \n",
    "def json_serializer(obj):\n",
    "    if isinstance(obj, datetime.datetime):\n",
    "        return obj.isoformat()\n",
    "    else:\n",
    "        try:\n",
    "            return obj.to_json()\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                return vars(obj)\n",
    "            except TypeError:\n",
    "                return str(obj)\n",
    "    \n",
    "pt_1 = Point(0, 0)\n",
    "pt_2 = Point(Decimal('1.5'), Decimal('-2.5'))\n",
    "person = Person('Tony', 24)\n",
    "\n",
    "log_record = dict(\n",
    "    created_at=datetime.datetime.now(datetime.UTC),\n",
    "    point_1=pt_1,\n",
    "    point_2=pt_2,\n",
    "    points={pt_1, pt_2},\n",
    "    created_by=person\n",
    ")\n",
    "\n",
    "log_record_serialized = json.dumps(log_record, default=json_serializer, indent=4)\n",
    "print(log_record_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"created_at\": \"2024-02-08T08:04:21.292290+00:00\",\n",
      "    \"point_1\": {\n",
      "        \"x\": 0,\n",
      "        \"y\": 0\n",
      "    },\n",
      "    \"point_2\": {\n",
      "        \"x\": \"1.5\",\n",
      "        \"y\": \"-2.5\"\n",
      "    },\n",
      "    \"points\": \"{Point(x=0, y=0), Point(x=1.5, y=-2.5)}\",\n",
      "    \"created_by\": {\n",
      "        \"name\": \"Tony\",\n",
      "        \"age\": 24\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from functools import singledispatch\n",
    "import datetime\n",
    "from decimal import Decimal\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self.name}, age={self.age})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return vars(self)\n",
    "    \n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Point(x={self.x}, y={self.y})'\n",
    "\n",
    "@singledispatch\n",
    "def json_serializer(obj):\n",
    "    try:\n",
    "        return obj.to_json()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            return vars(obj)\n",
    "        except TypeError:\n",
    "            return str(obj)\n",
    "        \n",
    "@json_serializer.register(datetime.datetime)\n",
    "def _(obj):\n",
    "    return obj.isoformat()\n",
    "\n",
    "pt_1 = Point(0, 0)\n",
    "pt_2 = Point(Decimal('1.5'), Decimal('-2.5'))\n",
    "person = Person('Tony', 24)\n",
    "\n",
    "log_record = dict(\n",
    "    created_at=datetime.datetime.now(datetime.UTC),\n",
    "    point_1=pt_1,\n",
    "    point_2=pt_2,\n",
    "    points={pt_1, pt_2},\n",
    "    created_by=person\n",
    ")\n",
    "\n",
    "log_record_serialized = json.dumps(log_record, default=json_serializer, indent=4)\n",
    "print(log_record_serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `JSONEncoder`\n",
    "\n",
    "* `class json.JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)`\n",
    "  * Extensible JSON encoder for Python data structures.\n",
    "  * Supports the following objects and types by default:\n",
    "\n",
    "    Python|JSON\n",
    "    ---|---\n",
    "    dict|object\n",
    "    list, tuple|array\n",
    "    str|string\n",
    "    int, float, int- & float-derived Enums|number\n",
    "    True|true\n",
    "    False|false\n",
    "    None|null\n",
    "\n",
    "  * To extend this to recognize other objects, subclass and implement a `default()` method with another method that returns a serializable object if possible, otherwise it should call the superclass implementation (to raise `TypeError`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": [1, 2], \"b\": [3, 4], \"c\": true, \"d\": null}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "default_json_encoder = json.JSONEncoder()\n",
    "print(default_json_encoder.encode({'a': [1, 2], 'b': (3, 4), 'c': True, 'd': None}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "\"2024-02-08T20:10:13.450292\"\n",
      "{\"a\": 1, \"b\": false, \"c\": [1, 2]}\n",
      "{\"name\": \"Tony\", \"time\": \"2024-02-08T20:10:13.450292\", \"set\": [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return obj.isoformat()\n",
    "        else:\n",
    "            try:\n",
    "                iter(obj)\n",
    "            except TypeError:\n",
    "                pass\n",
    "            else:\n",
    "                return list(obj)\n",
    "            # return json.JSONEncoder.default(self, obj)\n",
    "            return super().default(obj)\n",
    "        \n",
    "custom_encoder = CustomJSONEncoder()\n",
    "print(custom_encoder.encode({1, 2, 3}))\n",
    "print(custom_encoder.encode(datetime.datetime.now()))\n",
    "print(custom_encoder.encode({'a': 1, 'b': False, 'c': (1, 2)}))\n",
    "# print(custom_encoder.encode(1 + 0j))\n",
    "\n",
    "dumped = json.dumps(dict(name='Tony', time=datetime.datetime.now(), set={1, 2}), cls=CustomJSONEncoder)\n",
    "print(dumped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan inf inf -inf\n"
     ]
    }
   ],
   "source": [
    "print(float('nan'), float('inf'), float('infinity'), float('-inf')) # allow_nan argument controls whether these should be serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"created_by\":\"Tony\",\n",
      "    \"created_at\":{\n",
      "        \"datatype\":\"datetime\",\n",
      "        \"isoformat\":\"2024-02-08T10:01:01.726969+00:00\",\n",
      "        \"date\":\"2024-02-08\",\n",
      "        \"time\":\"10:01:01.726969\",\n",
      "        \"year\":2024,\n",
      "        \"month\":2,\n",
      "        \"day\":8,\n",
      "        \"hour\":10,\n",
      "        \"minute\":1,\n",
      "        \"second\":1\n",
      "    },\n",
      "    \"set\":[\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "    ],\n",
      "    \"1.2\":\"float\",\n",
      "    \"null\":\"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs |= dict(skipkeys=True, allow_nan=False, separators=(',', ':'))\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return dict(\n",
    "                datatype='datetime',\n",
    "                isoformat=obj.isoformat(),\n",
    "                date=obj.date().isoformat(),\n",
    "                time=obj.time().isoformat(),\n",
    "                year=obj.year,\n",
    "                month=obj.month,\n",
    "                day=obj.day,\n",
    "                hour=obj.hour,\n",
    "                minute=obj.minute,\n",
    "                second=obj.second\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                iter(obj)\n",
    "            except TypeError:\n",
    "                pass\n",
    "            else:\n",
    "                return list(obj)\n",
    "            return super().default(obj)\n",
    "        \n",
    "d = {\n",
    "    'created_by': 'Tony',\n",
    "    'created_at': datetime.datetime.now(datetime.UTC),\n",
    "    'set': {1, 2, 3},\n",
    "    1.2: 'float',\n",
    "    None: 'None',\n",
    "    0j: 'complex'\n",
    "}\n",
    "\n",
    "print(json.dumps(d, cls=CustomJSONEncoder, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom JSON decoding\n",
    "\n",
    "* `json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)`\n",
    "  * Deserialize `fp` (a `.read()`-supporting text file or binary file containing a JSON document) to a Python object using this conversion table.\n",
    "  * `object_hook` is an optional function that will be called with the result of any object literal decoded (a `dict`). The return value of `object_hook` will be used instead of the `dict`. This feature can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
    "  * `object_pairs_hook` is an optional function that will be called with the result of any object literal decoded with an *ordered list of pairs*. The return value of `object_pairs_hook` will be used instead of the `dict`. This feature can be used to implement custom decoders. If `object_hook` is also defined, the `object_pairs_hook` takes priority.\n",
    "  * `parse_float`, if specified, will be called with the string of every JSON float to be decoded. By default, this is equivalent to `float(num_str)`. This can be used to use another datatype or parser for JSON floats (e.g. `decimal.Decimal`).\n",
    "  * `parse_int`, if specified, will be called with the string of every JSON int to be decoded. By default, this is equivalent to `int(num_str)`. This can be used to use another datatype or parser for JSON integers (e.g. `float`).\n",
    "  * `parse_constant`, if specified, will be called with one of the following strings: `'-Infinity'`, `'Infinity'`, `'NaN'`. This can be used to raise an exception if invalid JSON numbers are encountered.\n",
    "  * To use a custom JSONDecoder subclass, specify it with the `cls` kwarg; otherwise `JSONDecoder` is used. Additional keyword arguments will be passed to the constructor of the class.\n",
    "  * If the data being deserialized is not a valid JSON document, a `JSONDecodeError` will be raised.\n",
    "* `json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)`\n",
    "  * Deserialize s (a `str`, `bytes` or `bytearray` instance containing a JSON document) to a Python object using this conversion table.\n",
    "\n",
    "Schemas\n",
    "\n",
    "* Deserializing custom JSON types and objects is difficult.\n",
    "* In general, we need to know the structure of the JSON data in order to custom deserialize.\n",
    "  * This is referred to as the schema, a pre-defined agreement on how the JSON is going to be structured or serialized.\n",
    "  * The schema might be for the entire JSON, or for sub-components only.\n",
    "\n",
    "Overriding basic type serializations\n",
    "\n",
    "* Notice that `object_hook` only allows us to customize deserialization of objects (dicts).\n",
    "* We can override the way numbers are handled by using some extra keyword-arguments in `load` / `loads`:\n",
    "  * `parse_float`\n",
    "  * `parse_int`\n",
    "  * `parse_constant`\n",
    "* There's no overrides for strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'times': {'created': {'type': 'datetime', 'value': '2024-02-10T08:09:55'}, 'updated': {'type': 'datetime', 'value': '2024-02-11T09:10:00'}}, 'message': 'time of creation and update', 'myShare': {'type': 'fraction', 'numerator': 1, 'denominator': 2}}\n",
      "{'times': {'created': datetime.datetime(2024, 2, 10, 8, 9, 55), 'updated': datetime.datetime(2024, 2, 11, 9, 10)}, 'message': 'time of creation and update', 'myShare': Fraction(1, 2)}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "from fractions import Fraction\n",
    "\n",
    "serialized = '''\n",
    "{\n",
    "    \"times\": {\n",
    "        \"created\": {\n",
    "            \"type\": \"datetime\",\n",
    "            \"value\": \"2024-02-10T08:09:55\"\n",
    "        },\n",
    "        \"updated\": {\n",
    "            \"type\": \"datetime\",\n",
    "            \"value\": \"2024-02-11T09:10:00\"\n",
    "        }\n",
    "    },\n",
    "    \"message\": \"time of creation and update\",\n",
    "    \"myShare\": {\n",
    "        \"type\": \"fraction\",\n",
    "        \"numerator\": 1,\n",
    "        \"denominator\": 2\n",
    "    }\n",
    "}\n",
    "'''\n",
    "print(json.loads(serialized))\n",
    "\n",
    "def custom_decoder(dict_obj):\n",
    "    if dict_obj.get('type') == 'datetime':\n",
    "        value = dict_obj.get('value')\n",
    "        return datetime.datetime.fromisoformat(value)\n",
    "    elif dict_obj.get('type') == 'fraction':\n",
    "        return Fraction(dict_obj['numerator'], dict_obj['denominator'])\n",
    "    else:\n",
    "        return dict_obj\n",
    "    \n",
    "print(json.loads(serialized, object_hook=custom_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3, 4], 'b': 100, 'c': 10.5, 'd': None, 'e': nan, 'f': inf, 'g': -inf}\n",
      "int handler <class 'str'> 1\n",
      "int handler <class 'str'> 2\n",
      "int handler <class 'str'> 3\n",
      "int handler <class 'str'> 4\n",
      "int handler <class 'str'> 100\n",
      "float handler <class 'str'> 10.5\n",
      "Constant handler <class 'str'> NaN\n",
      "Constant handler <class 'str'> Infinity\n",
      "Constant handler <class 'str'> -Infinity\n",
      "object hook <class 'dict'> {'a': ['1', '2', '3', '4'], 'b': '100', 'c': '10.5', 'd': None, 'e': 'constant NaN', 'f': 'constant Infinity', 'g': 'constant -Infinity'}\n",
      "{'a': ['1', '2', '3', '4'], 'b': '100', 'c': '10.5', 'd': None, 'e': 'constant NaN', 'f': 'constant Infinity', 'g': 'constant -Infinity'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def obj_hook(obj_dict):\n",
    "    print('object hook', type(obj_dict), obj_dict)\n",
    "    return obj_dict\n",
    "\n",
    "def int_handler(obj):\n",
    "    print('int handler', type(obj), obj)\n",
    "    return obj\n",
    "\n",
    "def float_handler(obj):\n",
    "    print('float handler', type(obj), obj)\n",
    "    return obj\n",
    "\n",
    "def constant_handler(obj):\n",
    "    print('Constant handler', type(obj), obj)\n",
    "    return f'constant {obj}'\n",
    "\n",
    "j = '''\n",
    "{\n",
    "    \"a\": [1, 2, 3, 4],\n",
    "    \"b\": 100,\n",
    "    \"c\": 10.5,\n",
    "    \"d\": null,\n",
    "    \"e\": NaN,\n",
    "    \"f\": Infinity,\n",
    "    \"g\": -Infinity\n",
    "}\n",
    "'''\n",
    "print(json.loads(j))\n",
    "print(json.loads(j, object_hook=obj_hook, parse_constant=constant_handler, parse_float=float_handler, parse_int=int_handler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `JSONDecoder`\n",
    "\n",
    "* `class json.JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)`\n",
    "  * Performs the following translations in decoding by default:\n",
    "\n",
    "    JSON|Python\n",
    "    ---|---\n",
    "    object|dict\n",
    "    array|list\n",
    "    string|str\n",
    "    number (int)|int\n",
    "    number (real)|float\n",
    "    true|True\n",
    "    false|False\n",
    "    null|None\n",
    "\n",
    "  * It also understands `NaN`, `Infinity`, and `-Infinity` as their corresponding *float* values, which is outside the JSON spec.\n",
    "  * If `strict` is false (`True` is the default), then control characters will be allowed inside strings. Control characters in this context are those with character codes in the 0–31 range, including `'\\t'` (tab), `'\\n'`, `'\\r'` and `'\\0'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode <class 'str'> \n",
      "{\n",
      "    \"a\": 100,\n",
      "    \"b\": [1, 2, 3],\n",
      "    \"c\": NaN,\n",
      "    \"d\": {\n",
      "        \"e\": Infinity,\n",
      "        \"f\": -Infinity\n",
      "    },\n",
      "    \"g\": 10.5\n",
      "}\n",
      "\n",
      "{'a': 100, 'b': [1, 2, 3], 'c': nan, 'd': {'e': inf, 'f': -inf}, 'g': 10.5}\n",
      "inf <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class CustomJSONDecoder(json.JSONDecoder):\n",
    "    # def object_hook(self, obj_dict): # no effect\n",
    "    #     print('object hook', type(obj_dict), obj_dict)\n",
    "    #     return obj_dict\n",
    "\n",
    "    def decode(self, obj):\n",
    "        print('decode', type(obj), obj)\n",
    "        return super().decode(obj)\n",
    "    \n",
    "j = '''\n",
    "{\n",
    "    \"a\": 100,\n",
    "    \"b\": [1, 2, 3],\n",
    "    \"c\": NaN,\n",
    "    \"d\": {\n",
    "        \"e\": Infinity,\n",
    "        \"f\": -Infinity\n",
    "    },\n",
    "    \"g\": 10.5\n",
    "}\n",
    "'''\n",
    "deserialized = json.loads(j, cls=CustomJSONDecoder)\n",
    "print(deserialized)\n",
    "print(deserialized['d']['e'], type(deserialized['d']['e']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'about': 'test',\n",
      " 'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}],\n",
      " 'float': 10.5,\n",
      " 'int': 10,\n",
      " 'point': Point(x=10, y=10),\n",
      " 'point_dict': {'p1': Point(x=2, y=2), 'p2': Point(x=3, y=3)},\n",
      " 'point_list': [Point(x=0, y=0), Point(x=1, y=-1)]}\n",
      "{\"about\": \"test\", \"int\": 10, \"float\": 10.5, \"point\": {\"type\": \"point\", \"value\": {\"x\": 10, \"y\": 10}}, \"point_list\": [{\"type\": \"point\", \"value\": {\"x\": 0, \"y\": 0}}, {\"type\": \"point\", \"value\": {\"x\": 1, \"y\": -1}}], \"point_dict\": {\"p1\": {\"type\": \"point\", \"value\": {\"x\": 2, \"y\": 2}}, \"p2\": {\"type\": \"point\", \"value\": {\"x\": 3, \"y\": 3}}}, \"dicts\": [{\"a\": 1, \"b\": 2}, {\"c\": 3, \"d\": 4}]}\n",
      "{'about': 'test',\n",
      " 'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}],\n",
      " 'float': 10.5,\n",
      " 'int': 10,\n",
      " 'point': Point(x=10, y=10),\n",
      " 'point_dict': {'p1': Point(x=2, y=2), 'p2': Point(x=3, y=3)},\n",
      " 'point_list': [Point(x=0, y=0), Point(x=1, y=-1)]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Point(x={self.x}, y={self.y})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return vars(self)\n",
    "\n",
    "\n",
    "def serialize_point(obj):\n",
    "    if isinstance(obj, Point):\n",
    "        return dict(type='point', value=obj.to_json())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CustomJSONDecoder(json.JSONDecoder):\n",
    "    def decode(self, string):\n",
    "        obj = super().decode(string)\n",
    "        pattern = r'\"type\"\\s*:\\s*\"point\"'\n",
    "        if re.search(pattern, string):\n",
    "            self.parse_point(obj)\n",
    "        return obj\n",
    "    \n",
    "    # def parse_point(self, obj):\n",
    "    #     if obj.get('type') == 'point':\n",
    "    #         return Point(**obj['value'])\n",
    "    #     else:\n",
    "    #         for k, v in obj.items():\n",
    "    #             if isinstance(v, list):\n",
    "    #                 for i, e in enumerate(v):\n",
    "    #                     if isinstance(e, dict):\n",
    "    #                         v[i] = self.parse_point(e)\n",
    "    #             elif isinstance(v, dict):\n",
    "    #                 obj[k] = self.parse_point(v)\n",
    "    #         return obj # if not point return the object unchanged\n",
    "\n",
    "    def parse_point(self, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            if obj.get('type') == 'point':\n",
    "                obj = Point(**obj['value'])\n",
    "            else:\n",
    "                for k, v in obj.items():\n",
    "                    obj[k] = self.parse_point(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for i, e in enumerate(obj):\n",
    "                obj[i] = self.parse_point(e)\n",
    "        return obj\n",
    "        \n",
    "\n",
    "d = {'about': 'test',\n",
    "     'int': 10, 'float': 10.5,\n",
    "     'point': Point(10, 10),\n",
    "     'point_list': [Point(0, 0), Point(1, -1)],\n",
    "     'point_dict': {'p1': Point(2, 2), 'p2': Point(3, 3)},\n",
    "     'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}]}\n",
    "\n",
    "d_serialized = json.dumps(d, default=serialize_point)\n",
    "pprint(d)\n",
    "print(d_serialized)\n",
    "\n",
    "d_deserialized = json.loads(d_serialized, cls=CustomJSONDecoder)\n",
    "pprint(d_deserialized)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'about': 'test',\n",
      " 'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}],\n",
      " 'float': 10.5,\n",
      " 'int': 10,\n",
      " 'point': Point(x=1.1, y=2.2),\n",
      " 'point_dict': {'p1': Point(x=2, y=2), 'p2': Point(x=3, y=3)},\n",
      " 'point_list': [Point(x=0, y=0), Point(x=1, y=-1)]}\n",
      "{\"about\": \"test\", \"int\": 10, \"float\": 10.5, \"point\": {\"type\": \"point\", \"value\": {\"x\": 1.1, \"y\": 2.2}}, \"point_list\": [{\"type\": \"point\", \"value\": {\"x\": 0, \"y\": 0}}, {\"type\": \"point\", \"value\": {\"x\": 1, \"y\": -1}}], \"point_dict\": {\"p1\": {\"type\": \"point\", \"value\": {\"x\": 2, \"y\": 2}}, \"p2\": {\"type\": \"point\", \"value\": {\"x\": 3, \"y\": 3}}}, \"dicts\": [{\"a\": 1, \"b\": 2}, {\"c\": 3, \"d\": 4}]}\n",
      "{'about': 'test',\n",
      " 'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}],\n",
      " 'float': Decimal('10.5'),\n",
      " 'int': 10,\n",
      " 'point': Point(x=1.1, y=2.2),\n",
      " 'point_dict': {'p1': Point(x=2, y=2), 'p2': Point(x=3, y=3)},\n",
      " 'point_list': [Point(x=0, y=0), Point(x=1, y=-1)]}\n",
      "type(d_deserialized['point'].x)=<class 'decimal.Decimal'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from pprint import pprint\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Point(x={self.x}, y={self.y})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return vars(self)\n",
    "\n",
    "\n",
    "def serialize_point(obj):\n",
    "    if isinstance(obj, Point):\n",
    "        return dict(type='point', value=obj.to_json())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CustomJSONDecoder(json.JSONDecoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs |= dict(parse_float=Decimal, object_hook=self.parse_point)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def parse_point(self, obj): # this is much simpler than overriding decode()\n",
    "        if obj.get('type') == 'point':\n",
    "            return Point(**obj['value'])\n",
    "        return obj\n",
    "        \n",
    "\n",
    "d = {'about': 'test',\n",
    "     'int': 10, 'float': 10.5,\n",
    "     'point': Point(1.1, 2.2),\n",
    "     'point_list': [Point(0, 0), Point(1, -1)],\n",
    "     'point_dict': {'p1': Point(2, 2), 'p2': Point(3, 3)},\n",
    "     'dicts': [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}]}\n",
    "\n",
    "d_serialized = json.dumps(d, default=serialize_point)\n",
    "pprint(d)\n",
    "print(d_serialized)\n",
    "\n",
    "d_deserialized = json.loads(d_serialized, cls=CustomJSONDecoder)\n",
    "pprint(d_deserialized)\n",
    "print(f'{type(d_deserialized['point'].x)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON schema\n",
    "\n",
    "* [JSON Schema](https://json-schema.org/) is a vocabulary that you can use to annotate and validate JSON documents.\n",
    "* After you create the JSON Schema document, you can validate the example data against your schema using a validator in a language of your choice.\n",
    "* `pip install jsonschema` for validation\n",
    "  * https://json-schema.org/implementations#validators-python\n",
    "  * https://github.com/python-jsonschema/jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"$id\": \"https://example.com/product.schema.json\",\n",
    "    \"title\": \"Product\",\n",
    "    \"description\": \"A product from Acme's catalog\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"productId\": {\n",
    "            \"description\": \"The unique identifier for a product\",\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"productName\": {\n",
    "            \"description\": \"Name of the product\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"price\": {\n",
    "            \"description\": \"The price of the product\",\n",
    "            \"type\": \"number\",\n",
    "            \"exclusiveMinimum\": 0\n",
    "        },\n",
    "        \"tags\": {\n",
    "            \"description\": \"Tags for the product\",\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"minItems\": 1,\n",
    "            \"uniqueItems\": true # should it be True?\n",
    "        },\n",
    "        \"dimensions\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"length\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"width\": {\n",
    "                    \"type\": \"number\"\n",
    "                },\n",
    "                \"height\": {\n",
    "                    \"type\": \"number\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"length\", \"width\", \"height\"]\n",
    "        },\n",
    "        \"warehouseLocation\": {\n",
    "            \"description\": \"Coordinates of the warehouse where the product is located.\",\n",
    "            \"$ref\": \"https://example.com/geographical-location.schema.json\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"productId\", \"productName\", \"price\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data validation libraries\n",
    "\n",
    "* [Pydantic](https://github.com/pydantic/pydantic)\n",
    "  * `pip install pydantic`\n",
    "  * Data validation using Python type hints.\n",
    "  * Fast and extensible.\n",
    "  * Define how data should be in pure, canonical Python 3.8+; validate it with Pydantic.\n",
    "* [YAML](https://yaml.org/)\n",
    "  * `pip install pyyaml` or `pip install ruamel.yaml`\n",
    "  * A human-friendly data serialization language for all programming languages.\n",
    "  * It is commonly used for configuration files and in applications where data is being stored or transmitted.\n",
    "  * YAML targets many of the same communications applications as Extensible Markup Language (XML) but has a minimal syntax that intentionally differs from Standard Generalized Markup Language (SGML).\n",
    "  * It uses Python-style indentation to indicate nesting and does not require quotes around most string values (it also supports JSON style `[...]` for lists and `{...}` mixed in the same file).\n",
    "  * Custom data types are allowed, but YAML natively encodes scalars (such as strings, integers, and floats), lists, and associative arrays (also known as maps, dictionaries or hashes).\n",
    "* [serpy](https://serpy.readthedocs.io/en/latest/)\n",
    "  * `pip install serpy`\n",
    "  * A super simple object serialization framework built for speed.\n",
    "  * serpy serializes complex datatypes (Django Models, custom classes, ...) to simple native types (dicts, lists, strings, ...). The native types can then be easily converted to JSON or any other format needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following classes:\n",
    "\n",
    "```Python\n",
    "class Stock:\n",
    "    def __init__(self, symbol, date, open_, high, low, close, volume):\n",
    "        self.symbol = symbol\n",
    "        self.date = date\n",
    "        self.open = open_\n",
    "        self.high = high\n",
    "        self.low = low\n",
    "        self.close = close\n",
    "        self.volume = volume\n",
    "        \n",
    "class Trade:\n",
    "    def __init__(self, symbol, timestamp, order, price, volume, commission):\n",
    "        self.symbol = symbol\n",
    "        self.timestamp = timestamp\n",
    "        self.order = order\n",
    "        self.price = price\n",
    "        self.commission = commission\n",
    "        self.volume = volume\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Given the above class, write a custom `JSONEncoder` class to **serialize** dictionaries that contain instances of these particular classes. Keep in mind that you will want to deserialize the data too, so you will need some technique to indicate the object type in your serialization.\n",
    "\n",
    "For example you may have an object such as this one that needs to be serialized:\n",
    "\n",
    "```Python\n",
    "activity = {\n",
    "    \"quotes\": [\n",
    "        Stock('TSLA', date(2018, 11, 22), \n",
    "              Decimal('338.19'), Decimal('338.64'), Decimal('337.60'), Decimal('338.19'), 365_607),\n",
    "        Stock('AAPL', date(2018, 11, 22), \n",
    "              Decimal('176.66'), Decimal('177.25'), Decimal('176.64'), Decimal('176.78'), 3_699_184),\n",
    "        Stock('MSFT', date(2018, 11, 22), \n",
    "              Decimal('103.25'), Decimal('103.48'), Decimal('103.07'), Decimal('103.11'), 4_493_689)\n",
    "    ],\n",
    "    \n",
    "    \"trades\": [\n",
    "        Trade('TSLA', datetime(2018, 11, 22, 10, 5, 12), 'buy', Decimal('338.25'), 100, Decimal('9.99')),\n",
    "        Trade('AAPL', datetime(2018, 11, 22, 10, 30, 5), 'sell', Decimal('177.01'), 20, Decimal('9.99'))\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write code to reverse the serialization you just created. Write a custom decoder that can deserialize a JSON structure containing `Stock` and `Trade` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quotes\": [\n",
      "    {\n",
      "      \"type\": \"stock\",\n",
      "      \"value\": {\n",
      "        \"symbol\": \"TSLA\",\n",
      "        \"date\": {\n",
      "          \"type\": \"date\",\n",
      "          \"value\": \"2018-11-22\"\n",
      "        },\n",
      "        \"open\": \"338.19\",\n",
      "        \"high\": \"338.64\",\n",
      "        \"low\": \"337.60\",\n",
      "        \"close\": \"338.19\",\n",
      "        \"volume\": 365607\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"stock\",\n",
      "      \"value\": {\n",
      "        \"symbol\": \"AAPL\",\n",
      "        \"date\": {\n",
      "          \"type\": \"date\",\n",
      "          \"value\": \"2018-11-22\"\n",
      "        },\n",
      "        \"open\": \"176.66\",\n",
      "        \"high\": \"177.25\",\n",
      "        \"low\": \"176.64\",\n",
      "        \"close\": \"176.78\",\n",
      "        \"volume\": 3699184\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"stock\",\n",
      "      \"value\": {\n",
      "        \"symbol\": \"MSFT\",\n",
      "        \"date\": {\n",
      "          \"type\": \"date\",\n",
      "          \"value\": \"2018-11-22\"\n",
      "        },\n",
      "        \"open\": \"103.25\",\n",
      "        \"high\": \"103.48\",\n",
      "        \"low\": \"103.07\",\n",
      "        \"close\": \"103.11\",\n",
      "        \"volume\": 4493689\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"trades\": [\n",
      "    {\n",
      "      \"type\": \"trade\",\n",
      "      \"value\": {\n",
      "        \"symbol\": \"TSLA\",\n",
      "        \"timestamp\": {\n",
      "          \"type\": \"datetime\",\n",
      "          \"value\": \"2018-11-22T10:05:12\"\n",
      "        },\n",
      "        \"order\": \"buy\",\n",
      "        \"price\": \"338.25\",\n",
      "        \"commission\": \"9.99\",\n",
      "        \"volume\": 100\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"trade\",\n",
      "      \"value\": {\n",
      "        \"symbol\": \"AAPL\",\n",
      "        \"timestamp\": {\n",
      "          \"type\": \"datetime\",\n",
      "          \"value\": \"2018-11-22T10:30:05\"\n",
      "        },\n",
      "        \"order\": \"sell\",\n",
      "        \"price\": \"177.01\",\n",
      "        \"commission\": \"9.99\",\n",
      "        \"volume\": 20\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{'quotes': [Stock(symbol=TSLA, date=2018-11-22, open=338.19, high=338.64, low=337.60, close=338.19, volume=365607), Stock(symbol=AAPL, date=2018-11-22, open=176.66, high=177.25, low=176.64, close=176.78, volume=3699184), Stock(symbol=MSFT, date=2018-11-22, open=103.25, high=103.48, low=103.07, close=103.11, volume=4493689)], 'trades': [Trade(symbol=TSLA, timestamp=2018-11-22 10:05:12, order=buy, price=338.25, volume=100, commission=9.99), Trade(symbol=AAPL, timestamp=2018-11-22 10:30:05, order=sell, price=177.01, volume=20, commission=9.99)]}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date\n",
    "from decimal import Decimal\n",
    "import json\n",
    "\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, symbol, date, open, high, low, close, volume):\n",
    "        self.symbol = symbol\n",
    "        self.date = date\n",
    "        self.open = open\n",
    "        self.high = high\n",
    "        self.low = low\n",
    "        self.close = close\n",
    "        self.volume = volume\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Stock(symbol={self.symbol}, date={self.date}, open={self.open}, high={self.high}, low={self.low}, close={self.close}, volume={self.volume})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return dict(type='stock', value=vars(self))\n",
    "\n",
    "\n",
    "class Trade:\n",
    "    def __init__(self, symbol, timestamp, order, price, volume, commission):\n",
    "        self.symbol = symbol\n",
    "        self.timestamp = timestamp\n",
    "        self.order = order\n",
    "        self.price = price\n",
    "        self.commission = commission\n",
    "        self.volume = volume\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Trade(symbol={self.symbol}, timestamp={self.timestamp}, order={self.order}, price={self.price}, volume={self.volume}, commission={self.commission})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return dict(type='trade', value=vars(self))\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Decimal):\n",
    "            # return dict(type='decimal', value=str(obj))\n",
    "            return str(obj) # just return the string of a Decimal is simpler\n",
    "        elif isinstance(obj, datetime): # datetime is subclass of date\n",
    "            return dict(type='datetime', value=obj.isoformat())\n",
    "        elif isinstance(obj, date):\n",
    "            return dict(type='date', value=obj.isoformat())\n",
    "        else:\n",
    "            try:\n",
    "                return obj.to_json()\n",
    "            except AttributeError:\n",
    "                return super().default(obj)\n",
    "            \n",
    "\n",
    "class CustomJSONDecoder(json.JSONDecoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        # kwargs |= dict(object_hook=self.object_hook)\n",
    "        kwargs |= dict(object_hook=self.object_hook, parse_float=Decimal)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def object_hook(self, obj):\n",
    "        obj_type = obj.get('type')\n",
    "        match obj_type:\n",
    "            case 'date':\n",
    "                return self.parse_date(obj)\n",
    "            case 'datetime':\n",
    "                return self.parse_datetime(obj)\n",
    "            case 'stock':\n",
    "                return self.parse_stock(obj)\n",
    "            case 'trade':\n",
    "                return self.parse_trade(obj)\n",
    "            # case 'decimal': # handle Decimal with parse_float instead\n",
    "            #     return self.parse_decimal(obj)\n",
    "            case _:\n",
    "                return obj\n",
    "            \n",
    "    def parse_date(self, obj):\n",
    "        return date.fromisoformat(obj['value'])\n",
    "    \n",
    "    def parse_datetime(self, obj):\n",
    "        return datetime.fromisoformat(obj['value'])\n",
    "    \n",
    "    def parse_stock(self, obj):\n",
    "        return Stock(**obj['value'])\n",
    "    \n",
    "    def parse_trade(self, obj):\n",
    "        return Trade(**obj['value'])\n",
    "    \n",
    "    # def parse_decimal(self, obj):\n",
    "    #     return Decimal(obj['value'])\n",
    "\n",
    "\n",
    "activity = {\n",
    "    \"quotes\": [\n",
    "        Stock('TSLA', date(2018, 11, 22), \n",
    "              Decimal('338.19'), Decimal('338.64'), Decimal('337.60'), Decimal('338.19'), 365_607),\n",
    "        Stock('AAPL', date(2018, 11, 22), \n",
    "              Decimal('176.66'), Decimal('177.25'), Decimal('176.64'), Decimal('176.78'), 3_699_184),\n",
    "        Stock('MSFT', date(2018, 11, 22), \n",
    "              Decimal('103.25'), Decimal('103.48'), Decimal('103.07'), Decimal('103.11'), 4_493_689)\n",
    "    ],\n",
    "    \"trades\": [\n",
    "        Trade('TSLA', datetime(2018, 11, 22, 10, 5, 12), 'buy', Decimal('338.25'), 100, Decimal('9.99')),\n",
    "        Trade('AAPL', datetime(2018, 11, 22, 10, 30, 5), 'sell', Decimal('177.01'), 20, Decimal('9.99'))\n",
    "    ]\n",
    "}\n",
    "\n",
    "serialized = json.dumps(activity, cls=CustomJSONEncoder, indent=2)\n",
    "print(serialized)\n",
    "\n",
    "deserialized = json.loads(serialized, cls=CustomJSONDecoder)\n",
    "print(deserialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Container datatype|Explanation\n",
    "---|---\n",
    "`ChainMap`|dict-like class for creating a single view of multiple mappings\n",
    "`Counter`|dict subclass for counting hashable objects\n",
    "`OrderedDict`|dict subclass that remembers the order entries were added\n",
    "`defaultdict`|dict subclass that calls a factory function to supply missing values\n",
    "`UserDict`|wrapper around dictionary objects for easier dict subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `defaultdict`\n",
    "\n",
    "* `class collections.defaultdict(default_factory=None, /[, ...])`\n",
    "  * Return a new dictionary-like object.\n",
    "  * `defaultdict` is a subclass of the built-in `dict` class. It overrides one method and adds one writable instance variable. The remaining functionality is the same as for the dict class and is not documented here.\n",
    "  * The first argument provides the initial value for the `default_factory` attribute; it defaults to `None`. All remaining arguments are treated the same as if they were passed to the `dict` constructor, including keyword arguments.\n",
    "  * `defaultdict` objects support the following method in addition to the standard dict operations:\n",
    "    * `__missing__(key)`\n",
    "      * If the `default_factory` attribute is `None`, this raises a `KeyError` exception with the `key` as argument.\n",
    "      * If `default_factory` is not `None`, it is called *without arguments* to provide a default value for the given key, this value is inserted in the dictionary for the key, and returned.\n",
    "      * If calling `default_factory` raises an exception this exception is propagated unchanged.\n",
    "      * This method is called by the `__getitem__()` method of the `dict` class when the requested key is not found; whatever it returns or raises is then returned or raised by `__getitem__()`.\n",
    "      * Note that `__missing__()` is not called for any operations besides `__getitem__()`. This means that `get()` will, like normal dictionaries, return `None` as a default rather than using `default_factory`.\n",
    "  * `defaultdict` objects support the following instance variable:\n",
    "    * `default_factory`\n",
    "        * This attribute is used by the `__missing__()` method; it is initialized from the first argument to the constructor, if present, or to `None`, if absent.\n",
    "        * If it is not `None`, it must be a callable that takes 0 argument and returns the desired default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = {}\n",
    "# d['a'] # KeyError\n",
    "d.get('a') # return None, but the key 'a' is not inserted to d\n",
    "d.setdefault('a', 0) # return 0, and the key 'a' is inserted to d, this actually behaves similarly to defaultdict\n",
    "print(d['a'])\n",
    "\n",
    "# default_dict_int = defaultdict(lambda: 0) # same as below\n",
    "default_dict_int = defaultdict(int)\n",
    "print(default_dict_int['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': ['john', 'jill'], 'brown': ['jack'], 'unknown': ['eric', 'michael']}\n",
      "defaultdict(<class 'list'>, {'blue': ['john', 'jill'], 'brown': ['jack'], 'unknown': ['eric', 'michael']})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "persons = {\n",
    "    'john': {'age': 20, 'eye_color': 'blue'},\n",
    "    'jack': {'age': 25, 'eye_color': 'brown'},\n",
    "    'jill': {'age': 22, 'eye_color': 'blue'},\n",
    "    'eric': {'age': 35},\n",
    "    'michael': {'age': 27}\n",
    "}\n",
    "\n",
    "# method 1:\n",
    "eye_colors = {}\n",
    "\n",
    "for person, details in persons.items():\n",
    "    eye_color = details.get('eye_color', 'unknown')\n",
    "    eye_colors.setdefault(eye_color, [])\n",
    "    eye_colors[eye_color].append(person)\n",
    "\n",
    "print(eye_colors)\n",
    "\n",
    "# method 2:\n",
    "eye_colors = defaultdict(list)\n",
    "\n",
    "for person, details in persons.items():\n",
    "    details = defaultdict(lambda: 'unknown', details)\n",
    "    eye_color = details['eye_color']\n",
    "    eye_colors[eye_color].append(person)\n",
    "\n",
    "print(eye_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_func_1\n",
      "my_func_1\n",
      "my_func_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.function_stats.<locals>.<lambda>()>,\n",
       "            {'my_func_1': {'count': 2,\n",
       "              'first_called_at': datetime.datetime(2024, 2, 10, 3, 24, 29, 748864, tzinfo=datetime.timezone.utc)},\n",
       "             'my_func_2': {'count': 1,\n",
       "              'first_called_at': datetime.datetime(2024, 2, 10, 3, 24, 29, 749864, tzinfo=datetime.timezone.utc)}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "import datetime\n",
    "from functools import wraps\n",
    "\n",
    "def function_stats():\n",
    "    data = defaultdict(lambda: {'count': 0, 'first_called_at': datetime.datetime.now(datetime.UTC)})\n",
    "    Stats = namedtuple('Stats', 'decorator data') # this is actually not necessary\n",
    "\n",
    "    def decorator(fn):\n",
    "        @wraps(fn)\n",
    "        def inner(*args, **kwargs):\n",
    "            data[fn.__name__]['count'] += 1\n",
    "            return fn(*args, **kwargs)\n",
    "        return inner\n",
    "    \n",
    "    return Stats(decorator, data)\n",
    "\n",
    "stats = function_stats()\n",
    "\n",
    "@stats.decorator\n",
    "def my_func_1():\n",
    "    print('my_func_1')\n",
    "\n",
    "@stats.decorator\n",
    "def my_func_2():\n",
    "    print('my_func_2')\n",
    "\n",
    "my_func_1()\n",
    "my_func_1()\n",
    "my_func_2()\n",
    "\n",
    "stats.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OrderedDict`\n",
    "\n",
    "* Ordered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in `dict` class gained the ability to remember insertion order (this new behavior became guaranteed in Python 3.7).\n",
    "* Some differences from dict still remain:\n",
    "  * The regular `dict` was designed to be very good at mapping operations. Tracking insertion order was secondary.\n",
    "  * The `OrderedDict` was designed to be good at reordering operations. Space efficiency, iteration speed, and the performance of update operations were secondary.\n",
    "  * The `OrderedDict` algorithm can handle frequent reordering operations better than `dict`. This makes it suitable for implementing various kinds of LRU caches.\n",
    "  * The equality operation for `OrderedDict` checks for matching order.\n",
    "    * A regular `dict` can emulate the order sensitive equality test with `p == q and all(k1 == k2 for k1, k2 in zip(p, q))`.\n",
    "  * The `popitem()` method of OrderedDict has a different signature. It accepts an optional argument to specify which item is popped.\n",
    "    * A regular `dict` can emulate `OrderedDict`’s `od.popitem(last=True)` with `d.popitem()` which is guaranteed to pop the rightmost (last) item.\n",
    "    * A regular `dict` can emulate `OrderedDict`’s `od.popitem(last=False)` with `(k := next(iter(d)), d.pop(k))` which will return and remove the leftmost (first) item if it exists.\n",
    "  * `OrderedDict` has a `move_to_end()` method to efficiently reposition an element to an endpoint.\n",
    "    * A regular `dict` can emulate `OrderedDict`’s `od.move_to_end(k, last=True)` with `d[k] = d.pop(k)` which will move the key and its associated value to the rightmost (last) position.\n",
    "    * A regular dict does not have an *efficient* equivalent for `OrderedDict`’s `od.move_to_end(k, last=False)` which moves the key and its associated value to the leftmost (first) position.\n",
    "  * Until Python 3.8, `dict` lacked a `__reversed__()` method.\n",
    "* `class collections.OrderedDict([items])`\n",
    "  * Return an instance of a `dict` subclass that has methods specialized for rearranging dictionary order.\n",
    "  * `popitem(last=True)`\n",
    "  * `move_to_end(key, last=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'a': 1, 'b': 2, 'c': 3})\n",
      "{'c': 3, 'b': 2, 'a': 1}\n",
      "OrderedDict({'c': 3, 'b': 2, 'a': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "d_ordered = OrderedDict(d)\n",
    "print(d_ordered)\n",
    "print(dict(reversed(d.items())))\n",
    "print(OrderedDict(reversed(d_ordered.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Counter`\n",
    "\n",
    "* A counter tool is provided to support convenient and rapid tallies.\n",
    "* `class collections.Counter([iterable-or-mapping])`\n",
    "  * A `Counter` is a `dict` subclass for counting *hashable* objects.\n",
    "  * It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts.\n",
    "  * Elements are counted from an *iterable* or initialized from another *mapping* (or counter).\n",
    "  * `Counter` objects have a dictionary interface except that they return a zero count for missing items instead of raising a `KeyError`.\n",
    "  * Setting a count to zero does not remove an element from a counter. Use `del` to remove it entirely.\n",
    "* Counter objects support additional methods beyond those available for all dictionaries:\n",
    "  * `elements()`\n",
    "    * Return an *iterator* over elements repeating each as many times as its count. Elements are returned in the order first encountered.\n",
    "    * If an element's count is less than one, `elements()` will ignore it.\n",
    "  * `most_common([n])`\n",
    "    * Return a list of the `n` most common elements and their counts from the most common to the least. If `n` is omitted or `None`, `most_common()` returns all elements in the counter.\n",
    "    * Elements with equal counts are ordered in the order first encountered.\n",
    "  * `subtract([iterable-or-mapping])`\n",
    "    * Elements are subtracted from an iterable or from another mapping (or counter). Like `dict.update()` but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative.\n",
    "  * `total()`\n",
    "    * Compute the sum of the counts.\n",
    "* The usual dictionary methods are available for Counter objects except for two which work differently for counters.\n",
    "  * `fromkeys(iterable)`\n",
    "    * This class method is not implemented for `Counter` objects.\n",
    "  * `update([iterable-or-mapping])`\n",
    "    * Elements are counted from an iterable or added-in from another mapping (or counter). Like `dict.update()` but adds counts instead of replacing them. Also, the iterable is expected to be a sequence of elements (keys), not a sequence of `(key, value)` pairs.\n",
    "* Counters support rich comparison operators for equality, subset, and superset relationships: `==`, `!=`, `<`, `<=`, `>`, `>=`. All of those tests treat missing elements as having zero counts so that `Counter(a=1) == Counter(a=1, b=0)` returns true.\n",
    "* Several mathematical operations are provided for combining Counter objects to produce multisets (counters that have counts greater than zero).\n",
    "  * Addition and subtraction combine counters by adding or subtracting the counts of corresponding elements.\n",
    "  * Intersection and union return the minimum and maximum of corresponding counts.\n",
    "  * Equality and inclusion compare corresponding counts.\n",
    "  * Each operation can accept inputs with signed counts, but the output will exclude results with counts of zero or less.\n",
    "  * Unary addition and subtraction are shortcuts for adding an empty counter or subtracting from an empty counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter()\n",
      "Counter({'h': 2, 'l': 2, 'o': 2, 'e': 1, ',': 1, ' ': 1, 'p': 1, 'y': 1, 't': 1, 'n': 1})\n",
      "Counter({'blue': 12, 'green': 5, 'red': 4})\n",
      "Counter({'dogs': 8, 'cats': 4})\n",
      "['a', 'a', 'c', 'c', 'c']\n",
      "Counter()\n",
      "Counter({'c': 8, 'a': 4, 'b': 1})\n",
      "Counter({'c': 3, 'a': 2})\n",
      "Counter({'b': 2})\n",
      "Counter({'c': 3, 'a': 2})\n",
      "Counter({'c': 5, 'b': 3, 'a': 2})\n",
      "False\n",
      "True\n",
      "[('b', -2), ('d', 0), ('a', 2), ('c', 3)]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter())\n",
    "print(Counter('hello, python'))\n",
    "print(Counter({'red': 4, 'blue': 12, 'green': 5}))\n",
    "print(Counter(cats=4, dogs=8))\n",
    "\n",
    "c = Counter(a=2, b=-2, c=3, d=0)\n",
    "print(list(c.elements()))\n",
    "d = Counter(a=2, b=3, c=5)\n",
    "print(c - d)\n",
    "print(c + d)\n",
    "print(+c)\n",
    "print(-c)\n",
    "print(c & d)\n",
    "print(c | d)\n",
    "print(c == d)\n",
    "print(c <= d)\n",
    "print(c.most_common()[::-1])\n",
    "print(c.total())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterDict({'a': 3, 'b': 1, 'c': 1})\n",
      "0\n",
      "CounterDict({'a': 3, 'b': 1, 'c': 1})\n",
      "CounterDict({'a': 3, 'b': 1, 'c': 1, 'd': 2})\n",
      "7\n",
      "['a', 'a', 'a', 'b', 'c', 'd', 'd']\n"
     ]
    }
   ],
   "source": [
    "class CounterDict:\n",
    "    def __init__(self, iterable=None, /, **kwargs):\n",
    "        try:\n",
    "            dict1 = dict(iterable)\n",
    "        except (TypeError, ValueError):\n",
    "            dict1 = {}\n",
    "            for item in iterable:\n",
    "                dict1[item] = dict1.get(item, 0) + 1\n",
    "        dict2 = dict(**kwargs)\n",
    "        dict_combined = dict1 | dict2\n",
    "        for k in dict1.keys() & dict2.keys():\n",
    "            dict_combined[k] += dict1[k]\n",
    "        self.dict = dict_combined\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CounterDict({self.dict})'\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.dict.get(key, 0) # return 0 if key does not exist, but the key will not be inserted into the counter\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.dict[key] = value\n",
    "    \n",
    "    def elements(self):\n",
    "        for k, v in self.dict.items():\n",
    "            for _ in range(v):\n",
    "                yield k\n",
    "\n",
    "    def total(self):\n",
    "        return sum(self.dict.values())\n",
    "\n",
    "# d = dict(['a1', 'b2', 'c3']) # this works, as each item of the list, e.g. 'a1', is iterable\n",
    "# print(d) # {'a': '1', 'b': '2', 'c': '3'}\n",
    "\n",
    "counter = CounterDict({'a': 1, 'b': 2})\n",
    "counter = CounterDict({'a': 1, 'b': 2}, a=2)\n",
    "counter = CounterDict(['a', 'b', 'c'], a=2)\n",
    "print(counter)\n",
    "print(counter['d'])\n",
    "print(counter)\n",
    "counter['d'] = 2\n",
    "print(counter)\n",
    "print(counter.total())\n",
    "print(list(counter.elements()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard 120\n",
      "Counter({'keyboard': 120, 'battery': 113, 'mouse': 85, 'case': 78, 'cable': 71, 'charger': 62})\n",
      "Counter({'keyboard': 19, 'battery': 11, 'charger': 10, 'case': 9, 'mouse': 8, 'cable': 4})\n",
      "Counter({'battery': 102, 'keyboard': 101, 'mouse': 77, 'case': 69, 'cable': 67, 'charger': 52})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "widgets = ['battery', 'charger', 'cable', 'case', 'keyboard', 'mouse']\n",
    "sales = [(random.choice(widgets), random.randint(1, 10)) for _ in range(100)]\n",
    "refunds = [(random.choice(widgets), random.randint(1, 5)) for _ in range(20)]\n",
    "\n",
    "count = 0\n",
    "for item in sales:\n",
    "    if item[0] == 'keyboard':\n",
    "        count += item[1]\n",
    "print('keyboard', count)\n",
    "\n",
    "sale_counter = Counter(k for k, v in sales for _ in range(v))\n",
    "refund_counter = Counter(k for k, v in refunds for _ in range(v))\n",
    "print(sale_counter)\n",
    "print(refund_counter)\n",
    "net_sale = sale_counter - refund_counter\n",
    "print(net_sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChainMap`\n",
    "\n",
    "* A `ChainMap` class is provided for quickly linking a number of mappings so they can be treated as a single unit.\n",
    "* It is often much faster than creating a new dictionary and running multiple `update()` calls.\n",
    "* The class can be used to simulate nested scopes and is useful in templating.\n",
    "* `class collections.ChainMap(*maps)`\n",
    "  * A `ChainMap` groups multiple dicts or other mappings together to create a single, *updatable view*. If no maps are specified, a single empty dictionary is provided so that a new chain always has at least one mapping.\n",
    "  * The underlying mappings are stored in a *list*. That list is public and can be accessed or updated using the maps attribute. There is no other state.\n",
    "  * Lookups search the underlying mappings successively until a key is found. In contrast, writes, updates, and deletions only operate on the *first* mapping.\n",
    "  * A `ChainMap` incorporates the underlying mappings *by reference*. So, if one of the underlying mappings gets updated, those changes will be reflected in ChainMap.\n",
    "* All of the usual dictionary methods are supported. In addition, there is a `maps` attribute, a method for creating new subcontexts, and a property for accessing all but the first mapping:\n",
    "  * `maps`\n",
    "  * `new_child(m=None, **kwargs)`\n",
    "  * `parents`\n",
    "\n",
    "Parent-child relationship\n",
    "\n",
    "* `ChainMap(d1, d2, d3)`\n",
    "  * `d1` is called a child, `d2` and `d3` are parents.\n",
    "  * `d.parents`: returns a new `ChainMap` containing the parent elements only.\n",
    "  * `d.new_child(d4)`: adds `d4` to the front of the chain, same as `ChainMap(d4, d1, d2, d3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6})\n",
      "False\n",
      "[{'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}]\n",
      "ChainMap({'c': 3, 'd': 4}, {'e': 5, 'f': 6})\n",
      "ChainMap({'g': 7, 'h': 8}, {'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6})\n",
      "ChainMap({'g': 7, 'h': 8}, ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}))\n",
      "ChainMap(ChainMap({'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}), {'g': 7, 'h': 8})\n",
      "ChainMap(ChainMap({'a': 1, 'b': 2, 'c': 10, 'g': 70}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}), {'g': 7, 'h': 8})\n",
      "ChainMap({'a': 1, 'b': 2, 'c': 10, 'g': 70}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}, {'g': 7, 'h': 8})\n",
      "ChainMap({'a': 1, 'b': 2, 'c': 30, 'g': 70}, {'c': 3, 'd': 4}, {'e': 5, 'f': 6}, {'g': 7, 'h': 8})\n",
      "{'a': 1, 'b': 2, 'c': 30, 'g': 70}\n"
     ]
    }
   ],
   "source": [
    "from collections import ChainMap\n",
    "\n",
    "d1 = {'a': 1, 'b': 2}\n",
    "d2 = {'c': 3, 'd': 4}\n",
    "d3 = {'e': 5, 'f': 6}\n",
    "d4 = {'g': 7, 'h': 8}\n",
    "\n",
    "chained = ChainMap(d1, d2, d3)\n",
    "print(chained)\n",
    "print(isinstance(chained, dict)) # ChainMap is not subclass of dict\n",
    "print(chained.maps) # returns a list of underlying dicts\n",
    "print(chained.parents) # same as ChainMap(*chained.maps[1:])\n",
    "print(chained.new_child(d4)) # same as ChainMap(*chained.maps[:].insert(0, d4)), and chained = ChainMap(d4, chained) is a different approach that has similar effects\n",
    "print(ChainMap(d4, chained))\n",
    "chained_chainmap_child = ChainMap(chained, d4)\n",
    "print(chained_chainmap_child)\n",
    "chained_chainmap_child['c'] = 10 # only modifies the child of the child\n",
    "chained_chainmap_child['g'] = 70\n",
    "print(chained_chainmap_child)\n",
    "\n",
    "chained.maps.append(d4) # this will change the ChainMap, actually all operations on ChainMap can be done by changing the underlying dicts in maps\n",
    "print(chained)\n",
    "\n",
    "chained['c'] = 30\n",
    "print(chained) # the child is changed\n",
    "print(d1) # the underlying dict of the child is also changed\n",
    "# del chained['d'] # KeyError, as 'd' does not exist in the child although it does exist in the ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod.deepdive.com\n",
      "ChainMap({'use_pwd': 'my_pwd'}, {'host': 'prod.deepdive.com', 'port': 2428, 'database': 'deepdive', 'user_id': '$pg_user', 'user_pwd': '$pg_pwd'})\n",
      "{'host': 'prod.deepdive.com', 'port': 2428, 'database': 'deepdive', 'user_id': '$pg_user', 'user_pwd': '$pg_pwd'}\n"
     ]
    }
   ],
   "source": [
    "from collections import ChainMap\n",
    "\n",
    "config = {\n",
    "    'host': 'prod.deepdive.com',\n",
    "    'port': 2428,\n",
    "    'database': 'deepdive',\n",
    "    'user_id': '$pg_user',\n",
    "    'user_pwd': '$pg_pwd',\n",
    "}\n",
    "\n",
    "local_config = ChainMap({}, config) # create a local config mapping by using ChainMap without copying data from config\n",
    "print(local_config['host'])\n",
    "local_config['use_pwd'] = 'my_pwd' # only modifies the ChainMap object local_config, config intact\n",
    "print(local_config)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```UserDict```\n",
    "\n",
    "* The class, `UserDict` acts as a wrapper around dictionary objects. The need for this class has been partially supplanted by the ability to subclass directly from `dict`; however, this class can be easier to work with because the underlying dictionary is accessible as an attribute.\n",
    "* It is not a subclass of `dict` but a mapping type.\n",
    "* It is actually a head-start on recreating a Python dictionary from scratch that offers different subclassing possibilities.\n",
    "* `class collections.UserDict([initialdata])`\n",
    "  * Class that simulates a dictionary.\n",
    "  * The instance's contents are kept in a regular dictionary, which is accessible via the `data` attribute of `UserDict` instances.\n",
    "  * If `initialdata` is provided, `data` is initialized with its contents.\n",
    "  * A reference to `initialdata` will not be kept, allowing it to be used for other purposes.\n",
    "* In addition to supporting the methods and operations of mappings, `UserDict` instances provide the following attribute:\n",
    "  * `data`\n",
    "    * A real dictionary used to store the contents of the `UserDict` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'a': 1}\n",
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 1, 'c': 3}\n",
      "[('a', 1), ('b', 1), ('c', 3)]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "class IntDict(dict):\n",
    "    def __init__(self, iterable=None, /, **kwargs):\n",
    "        super().__init__(IntDict.mapping_conversion(iterable, kwargs))\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # super().__setitem__(key, IntDict.value_conversion(value))\n",
    "        super().__setitem__(key, int(value))\n",
    "        \n",
    "    @classmethod\n",
    "    def mapping_conversion(cls, iterable, kwargs):\n",
    "        if isinstance(iterable, dict):\n",
    "            iterable = iterable.items()\n",
    "        elif iterable is None:\n",
    "            iterable = []\n",
    "        chained = chain(iterable, kwargs.items())\n",
    "        converted = {}\n",
    "        for k, v in chained:\n",
    "            # converted[k] = IntDict.value_conversion(v)\n",
    "            converted[k] = int(v)\n",
    "        return converted\n",
    "    \n",
    "    # @classmethod\n",
    "    # def value_conversion(cls, value):\n",
    "    #     try:\n",
    "    #         return int(value)\n",
    "    #     except (TypeError, ValueError):\n",
    "    #         raise ValueError('the value of each item must be a legal argument of int()')\n",
    "\n",
    "int_d = IntDict()\n",
    "print(int_d)\n",
    "int_d['a'] = 1\n",
    "print(int_d)\n",
    "int_d['b'] = '2'\n",
    "print(int_d)\n",
    "# int_d['a'] = '1a' # ValueError, invalid value for int()\n",
    "\n",
    "# int_d = IntDict({'a': '1', 'b': 1.2}, c='3.5') # '3.5' invalid value for int()\n",
    "int_d = IntDict({'a': '1', 'b': 1.2}, c=3)\n",
    "print(int_d)\n",
    "print(list(int_d.items()))\n",
    "print(int_d.get('d', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 1.2, 'c': '1'}\n",
      "[('a', 1), ('b', 1), ('c', 1)]\n",
      "{'a': 1, 'b': 1, 'c': 1}\n",
      "{'a': 1, 'b': 1.2, 'c': '1'}\n"
     ]
    }
   ],
   "source": [
    "from collections import UserDict\n",
    "\n",
    "class IntDict(UserDict):\n",
    "    def __setitem__(self, key, value):\n",
    "        int(value) # test whether value is a legal argument of int()\n",
    "        super().__setitem__(key, value) # the original value remains unchanged\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return int(super().__getitem__(key))\n",
    "    \n",
    "\n",
    "int_d = IntDict({'a': 1, 'b': 1.2}, c='1')\n",
    "# int_d = IntDict({'a': 1, 'b': '1.2'}, c='1') # although __init__ is not implemented, it still successfully find the invalid value '1.2'\n",
    "print(int_d)\n",
    "print(list(int_d.items()))\n",
    "print(dict(int_d))\n",
    "print(int_d.data)\n",
    "# int_d['d'] = '1.5' # invalid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red': 10, 'green': 10, 'blue': 0}\n",
      "10\n",
      "[('red', 10), ('green', 10), ('blue', 0)]\n"
     ]
    }
   ],
   "source": [
    "from collections import UserDict\n",
    "from numbers import Real\n",
    "\n",
    "class LimitedDict(UserDict):\n",
    "    def __init__(self, keyset, value_range, *args, **kwargs):\n",
    "        self.keyset = keyset\n",
    "        self.value_range = value_range\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key not in self.keyset:\n",
    "            raise KeyError(f'{key!r} is not in keyset {self.keyset}')\n",
    "        if not isinstance(value, Real):\n",
    "            raise TypeError(f'{value!r} is not a real number')\n",
    "        if value < self.value_range[0] or value > self.value_range[1]:\n",
    "            raise ValueError(f'{value} is not in the range of {self.value_range}')\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "\n",
    "class ColorDict(LimitedDict):\n",
    "    def __init__(self, *args, default=0, **kwargs):\n",
    "        self.keyset = {'red', 'green', 'blue'}\n",
    "        self.value_range = (0, 255)\n",
    "        super().__init__(self.keyset, self.value_range, *args, **kwargs)\n",
    "        difference = self.keyset - self.keys()\n",
    "        for k in difference: # set missing color value to default\n",
    "            self[k] = default\n",
    "\n",
    "\n",
    "\n",
    "color_d = ColorDict(red=10, green=10)\n",
    "print(color_d)\n",
    "# color_d = ColorDict(red=10, green=10, purple=20) # invalid key 'purple'\n",
    "# color_d = ColorDict(red=10, green=10, blue=2000) # invalid value 2000\n",
    "print(color_d['red'])\n",
    "# color_d['blue'] = 300 # value out of range\n",
    "print(list(color_d.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "* You have text data spread across multiple servers. Each server is able to analyze this data and return a dictionary that contains words and their frequency.\n",
    "* Your job is to combine this data to create a single dictionary that contains all the words and their combined frequencies from all these data sources.\n",
    "* Bonus points if you can make your dictionary sorted by frequency (highest to lowest).\n",
    "* For example, you may have three servers that each return these dictionaries:\n",
    "    ```Python\n",
    "    d1 = {'python': 10, 'java': 3, 'c#': 8, 'javascript': 15}\n",
    "    d2 = {'java': 10, 'c++': 10, 'c#': 4, 'go': 9, 'python': 6}\n",
    "    d3 = {'erlang': 5, 'haskell': 2, 'python': 1, 'pascal': 1}\n",
    "    ```\n",
    "  * Your resulting dictionary should look like this:\n",
    "    ```Python\n",
    "    d = {'python': 17,\n",
    "         'javascript': 15,\n",
    "         'java': 13,\n",
    "         'c#': 12,\n",
    "         'c++': 10,\n",
    "         'go': 9,\n",
    "         'erlang': 5,\n",
    "         'haskell': 2,\n",
    "         'pascal': 1}\n",
    "    ```\n",
    "* Implement two different solutions to this problem:\n",
    "  * Using `defaultdict` objects\n",
    "  * Using `Counter` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'python': 17, 'java': 13, 'c#': 12, 'javascript': 15, 'c++': 10, 'go': 9, 'erlang': 5, 'haskell': 2, 'pascal': 1})\n",
      "Counter({'python': 17, 'javascript': 15, 'java': 13, 'c#': 12, 'c++': 10, 'go': 9, 'erlang': 5, 'haskell': 2, 'pascal': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def combine_dicts_defaultdict(dicts):\n",
    "    combined = defaultdict(int)\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            combined[k] += v\n",
    "    return combined\n",
    "\n",
    "def combine_dicts_counter(dicts):\n",
    "    # return Counter(k for d in dicts for k, v in d.items() for _ in range(v))\n",
    "    combined = Counter()\n",
    "    for d in dicts:\n",
    "        combined.update(d)\n",
    "    return Counter(dict(combined.most_common()))\n",
    "\n",
    "\n",
    "d1 = {'python': 10, 'java': 3, 'c#': 8, 'javascript': 15}\n",
    "d2 = {'java': 10, 'c++': 10, 'c#': 4, 'go': 9, 'python': 6}\n",
    "d3 = {'erlang': 5, 'haskell': 2, 'python': 1, 'pascal': 1}\n",
    "\n",
    "dicts = d1, d2, d3\n",
    "print(combine_dicts_defaultdict(dicts))\n",
    "print(combine_dicts_counter(dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "* Suppose you have a list of all possible eye colors:\n",
    "    ```Python\n",
    "    eye_colors = (\"amber\", \"blue\", \"brown\", \"gray\", \"green\", \"hazel\", \"red\", \"violet\")\n",
    "    ```\n",
    "* Some other collection (say recovered from a database, or an external API) contains a list of `Person` objects that have `eye_color` property.\n",
    "* Your goal is to create a dictionary that contains the number of people that have the eye color as specified in `eye_colors`. The wrinkle here is that even if no one matches some eye color, say `amber`, your dictionary should still contain an entry `\"amber\": 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'violet': 12, 'gray': 10, 'red': 10, 'green': 8, 'hazel': 7, 'brown': 3, 'amber': 0, 'blue': 0})\n",
      "defaultdict(<class 'int'>, {'amber': 0, 'blue': 0, 'brown': 3, 'gray': 10, 'green': 8, 'hazel': 7, 'red': 10, 'violet': 12})\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from random import seed, choices\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, eye_color):\n",
    "        self.eye_color = eye_color\n",
    "\n",
    "def eye_color_counter(persons, eye_colors):\n",
    "    # counter = Counter(dict.fromkeys(eye_colors, 0))\n",
    "    counter = Counter({eye_color: 0 for eye_color in eye_colors})\n",
    "    counter.update(p.eye_color for p in persons)\n",
    "    return counter\n",
    "\n",
    "def eye_color_defaultdict(persons, eye_colors):\n",
    "    counter = defaultdict(int, ((eye_color, 0) for eye_color in eye_colors))\n",
    "    for p in persons:\n",
    "        counter[p.eye_color] += 1\n",
    "    return counter\n",
    "\n",
    "seed(0)\n",
    "eye_colors = (\"amber\", \"blue\", \"brown\", \"gray\", \"green\", \"hazel\", \"red\", \"violet\")\n",
    "persons = [Person(color) for color in choices(eye_colors[2:], k = 50)]\n",
    "counter_c = eye_color_counter(persons, eye_colors)\n",
    "counter_d = eye_color_defaultdict(persons, eye_colors)\n",
    "print(counter_c)\n",
    "print(counter_d)\n",
    "print(counter_c.total() == 50)\n",
    "print(sum(v for v in counter_d.values()) == 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "* You are given three JSON files, representing a default set of settings, and environment specific settings.\n",
    "  * `common.json`\n",
    "  * `dev.json`\n",
    "  * `prod.json`\n",
    "* Your goal is to write a function that has a single argument (the environment name) and returns the \"combined\" dictionary that merges the two dictionaries together, with the environment specific settings overriding any common settings already defined.\n",
    "* For simplicity, assume that the argument values are going to be the same as the file names, without the `.json` extension. So for example, `dev` or `prod`.\n",
    "* The wrinkle: We don't want to duplicate data for the \"merged\" dictionary, using `ChainMap` to implement this instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChainMap({'data': ChainMap({'input_root': '/dev/path/inputs',\n",
      "                            'numerics': ChainMap({'type': 'float'},\n",
      "                                                 {'precision': 6,\n",
      "                                                  'type': 'Decimal'}),\n",
      "                            'operators': {'add': '__add__'},\n",
      "                            'output_root': '/dev/path/outputs'},\n",
      "                           {'input_root': '/default/path/inputs',\n",
      "                            'numerics': {'precision': 6, 'type': 'Decimal'},\n",
      "                            'output_root': '/default/path/outputs'}),\n",
      "          'database': ChainMap({'pwd': 'test', 'user': 'test'},\n",
      "                               {'db_name': 'deepdive',\n",
      "                                'port': 5432,\n",
      "                                'schema': 'public'}),\n",
      "          'logs': ChainMap({'format': '%(asctime)s: %(levelname)s: '\n",
      "                                      '%(clientip)s %(user)s %(filename)s '\n",
      "                                      '%(funcName)s %(message)s',\n",
      "                            'level': 'trace'},\n",
      "                           {'format': '%(asctime)s: %(levelname)s: '\n",
      "                                      '%(clientip)s %(user)s %(message)s',\n",
      "                            'level': 'info'})},\n",
      "         {'data': {'input_root': '/default/path/inputs',\n",
      "                   'numerics': {'precision': 6, 'type': 'Decimal'},\n",
      "                   'output_root': '/default/path/outputs'},\n",
      "          'database': {'db_name': 'deepdive', 'port': 5432, 'schema': 'public'},\n",
      "          'logs': {'format': '%(asctime)s: %(levelname)s: %(clientip)s '\n",
      "                             '%(user)s %(message)s',\n",
      "                   'level': 'info'}})\n",
      "test\n",
      "5432\n",
      "6\n",
      "info\n"
     ]
    }
   ],
   "source": [
    "from collections import ChainMap\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def chain_settings(environment, path, default_settings='common', file_extension='.json'):\n",
    "    environment_settings_path = f'{os.path.join(*path, environment)}{file_extension}'\n",
    "    default_settings_path = f'{os.path.join(*path, default_settings)}{file_extension}'\n",
    "    with open(environment_settings_path) as env_file:\n",
    "        with open(default_settings_path) as default_file:\n",
    "            env_dict = json.load(env_file)\n",
    "            default_dict = json.load(default_file)\n",
    "            return chain_recursive(env_dict, default_dict)\n",
    "        \n",
    "def chain_recursive(d1, d2):\n",
    "    chained = ChainMap(d1, d2)\n",
    "    for k, v in d1.items():\n",
    "        if isinstance(v, dict) and k in d2:\n",
    "            chained[k] = chain_recursive(v, d2[k])\n",
    "    return chained\n",
    "\n",
    "dev_settings = chain_settings('dev', ('.', 'p3_exercise1'))\n",
    "prod_settings = chain_settings('prod', ('.', 'p3_exercise1'))\n",
    "pprint(dev_settings)\n",
    "print(dev_settings['database']['pwd'])\n",
    "print(dev_settings['database']['port'])\n",
    "print(dev_settings['data']['numerics']['precision'])\n",
    "print(prod_settings['logs']['level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MappingProxyType`\n",
    "\n",
    "* `class types.MappingProxyType(mapping)`\n",
    "  * *Read-only* proxy of a mapping.\n",
    "  * It provides a dynamic view on the mapping's entries, which means that when the mapping changes, the view reflects these changes.\n",
    "  * Supported operations:\n",
    "    * `key in proxy`\n",
    "      * Return `True` if the underlying mapping has a key `key`, else `False`.\n",
    "    * `proxy[key]`\n",
    "      * Return the item of the underlying mapping with key `key`. Raises a `KeyError` if `key` is not in the underlying mapping.\n",
    "    * `iter(proxy)`\n",
    "      * Return an iterator over the keys of the underlying mapping. This is a shortcut for `iter(proxy.keys())`.\n",
    "    * `len(proxy)`\n",
    "      * Return the number of items in the underlying mapping.\n",
    "    * `copy()`\n",
    "      * Return a *shallow* copy of the underlying mapping.\n",
    "    * `get(key[, default])`\n",
    "      * Return the value for `key` if `key` is in the underlying mapping, else `default`. If `default` is not given, it defaults to `None`, so that this method never raises a `KeyError`.\n",
    "    * `items()`\n",
    "      * Return a new view of the underlying mapping's items (`(key, value)` pairs).\n",
    "    * `keys()`\n",
    "      * Return a new view of the underlying mapping's keys.\n",
    "    * `values()`\n",
    "      * Return a new view of the underlying mapping's values.\n",
    "    * `reversed(proxy)`\n",
    "      * Return a reverse iterator over the keys of the underlying mapping.\n",
    "    * `hash(proxy)`\n",
    "      * Return a hash of the underlying mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'a': 1, '__dict__': <attribute '__dict__' of 'MyClass' objects>, '__weakref__': <attribute '__weakref__' of 'MyClass' objects>, '__doc__': None}\n",
      "<class 'mappingproxy'>\n",
      "{}\n",
      "<class 'dict'>\n",
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "from types import MappingProxyType\n",
    "\n",
    "class MyClass:\n",
    "    a = 1\n",
    "\n",
    "print(MyClass.__dict__)\n",
    "print(type(MyClass.__dict__))\n",
    "my_class = MyClass()\n",
    "print(my_class.__dict__)\n",
    "print(type(my_class.__dict__))\n",
    "\n",
    "d = {'a': 1, 'b': 2}\n",
    "mp = MappingProxyType(d)\n",
    "print(mp)\n",
    "d['c'] = 3\n",
    "print(mp) # the mapping proxy also changed automatically as it dynamically reflects the underlying mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
