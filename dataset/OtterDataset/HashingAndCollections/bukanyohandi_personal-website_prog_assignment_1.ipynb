{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> CSC4120 Programming Assignment 1 </h1>\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "   The submission <font color = #FF0000>deadline is January 28 (Sun.), 2024, 11:59 pm</font>. Solutions submitted after the deadline will be graded as 0 points. Please submit an **ipynb** file and clearly state your group members' student IDs. Otherwise, your points will be deducted.\n",
    "\n",
    "## What you need to do\n",
    "\n",
    "1. Understand the document distance problem.\n",
    "\n",
    "2. Understand the python code and how we improve the algorithm in each step.\n",
    "\n",
    "3. Implement merge sort and the dictionary version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student IDs\n",
    "\n",
    "\\###\n",
    "\n",
    "120040025 - Yohandi\n",
    "\n",
    "120040007 - Andrew Nathanael\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import cProfile\n",
    "import string\n",
    "\n",
    "filename_1 = \"file3.txt\"\n",
    "filename_2 = \"file5.txt\"\n",
    "translation_table = str.maketrans(string.punctuation + string.ascii_uppercase,\n",
    "                                     \" \"*len(string.punctuation) + string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial version of document distance\n",
    "\n",
    "This program computes the \"distance\" between two text files as the angle between their word frequency vectors (in radians).\n",
    "\n",
    "For each input file, a word-frequency vector is computed as follows:\n",
    "\n",
    "   (1) the specified file is read in\n",
    "\n",
    "   (2) it is converted into a list of alphanumeric \"words\"\n",
    "\n",
    "       Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "       characters.  Non-alphanumeric characters are treated as blanks.\n",
    "       Case is not significant.\n",
    "\n",
    "   (3) for each word, its frequency of occurrence is determined\n",
    "\n",
    "The \"distance\" between two vectors is the angle between them.\n",
    "\n",
    "If $ x = (x_1, x_2, ..., x_n) $ is the first vector ($ x_i $ = freq of word i)\n",
    "and $ y = (y_1, y_2, ..., y_n) $ is the second vector,\n",
    "then the angle between them is defined as:\n",
    "\n",
    "   $$ d(x,y) = \\arccos{\\left(\\frac{\\operatorname*{innerProduct}(x,y)}{\\operatorname*{norm}(x) * \\operatorname{norm}(y)}\\right)} $$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\operatorname*{innerProduct}(x,y) = x_1*y_1 + x_2*y_2 + \\cdots + x_n*y_n \\\\[1em]\n",
    "\\operatorname*{norm}(x) = \\sqrt{\\operatorname*{innerProduct}(x,x)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "   ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "Run the code and report the running time.\n",
    "\n",
    "\\###\n",
    "\n",
    "Running Time: 5.044s\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619319 (radians)\n",
      "         76653 function calls in 5.044 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.005    0.003 573875801.py:1(read_file)\n",
      "        2    4.324    2.162    4.399    2.199 573875801.py:13(get_words_from_line_list)\n",
      "    25115    0.019    0.000    0.075    0.000 573875801.py:24(get_words_from_string)\n",
      "        2    0.609    0.305    0.609    0.305 573875801.py:37(count_frequency)\n",
      "        2    0.000    0.000    5.014    2.507 573875801.py:51(word_frequencies_for_file)\n",
      "        3    0.028    0.009    0.028    0.009 573875801.py:61(inner_product)\n",
      "        1    0.000    0.000    0.029    0.029 573875801.py:76(vector_angle)\n",
      "        1    0.002    0.002    5.044    5.044 573875801.py:86(docdist1)\n",
      "        1    0.000    0.000    5.044    5.044 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "      104    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    5.044    5.044 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1049    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.004    0.002    0.005    0.002 {method 'readlines' of '_io._IOBase' objects}\n",
      "    25115    0.016    0.000    0.016    0.000 {method 'split' of 'str' objects}\n",
      "    25115    0.041    0.000    0.041    0.000 {method 'translate' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r', encoding= 'utf-8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \", filename)\n",
    "        sys.exit()\n",
    "\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word, 1])\n",
    "    return L\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(L1, L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as lists of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for word1, count1 in L1:\n",
    "        for word2, count2 in L2:\n",
    "            if word1 == word2:\n",
    "                sum += count1 * count2\n",
    "    return sum\n",
    "\n",
    "def vector_angle(L1, L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1, L2)\n",
    "    denominator = math.sqrt(inner_product(L1, L1) * inner_product(L2, L2))\n",
    "    return math.acos(numerator / denominator)\n",
    "\n",
    "def docdist1():\n",
    "    document_vector_1 = word_frequencies_for_file(filename_1)\n",
    "    document_vector_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(document_vector_1, document_vector_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist1()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change concatenate to extend in get_words_from_line_list\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Running Time: 0.800s (improvement made from 5.044s)\n",
    "\n",
    "As highlighted by the `cProfile` results, only from the two calls of the `get_words_from_line_list` function:\n",
    "- The original code runs in 4.324s, while\n",
    "- The changed code runs in 0.009s\n",
    "\n",
    "If we compare the code side by side:\n",
    "- The original code uses\n",
    "```py\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list\n",
    "```\n",
    ", while\n",
    "- The changed code uses\n",
    "```py\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "```\n",
    "\n",
    "The bottleneck was made due to concatenation being slower than the `extend` function. Here is why:\n",
    "- Each time the command $L_1 + L_2$ is run (both are lists), Python is enforced to create a new list that combines both $L_1$ and $L_2$, making the complexity $\\Theta(L_1 + L_2)$ due to iteration over both $L_1$ and $L_2$.\n",
    "- On the other hand, the $L_1.\\texttt{extend}(L_2)$ simply adds each element from $L_2$ to the end of $L_1$, making the complexity $\\Theta(L_2)$ due to iteration over $L_2$. Moreover, in the constant side, the added elements are done directly to $L_1$ while the concatenation creates a new list and copies all that back to $L_1$.\n",
    "\n",
    "\\###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619319 (radians)\n",
      "         101768 function calls in 0.800 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.009    0.005    0.053    0.026 2488429402.py:1(get_words_from_line_list)\n",
      "        1    0.002    0.002    0.800    0.800 2488429402.py:12(docdist2)\n",
      "        2    0.000    0.000    0.006    0.003 573875801.py:1(read_file)\n",
      "    25115    0.009    0.000    0.041    0.000 573875801.py:24(get_words_from_string)\n",
      "        2    0.706    0.353    0.706    0.353 573875801.py:37(count_frequency)\n",
      "        2    0.000    0.000    0.765    0.382 573875801.py:51(word_frequencies_for_file)\n",
      "        3    0.033    0.011    0.033    0.011 573875801.py:61(inner_product)\n",
      "        1    0.000    0.000    0.033    0.033 573875801.py:76(vector_angle)\n",
      "        1    0.000    0.000    0.800    0.800 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "      104    0.000    0.000    0.001    0.000 codecs.py:319(decode)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.800    0.800 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1049    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    25115    0.002    0.000    0.002    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.005    0.002    0.005    0.003 {method 'readlines' of '_io._IOBase' objects}\n",
      "    25115    0.008    0.000    0.008    0.000 {method 'split' of 'str' objects}\n",
      "    25115    0.023    0.000    0.023    0.000 {method 'translate' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "def docdist2():\n",
    "    document_vector_1 = word_frequencies_for_file(filename_1)\n",
    "    document_vector_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(document_vector_1, document_vector_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist2()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort the document vector\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Running Time: 0.724s (improvement made from 0.800s)\n",
    "\n",
    "As highlighted by the `cProfile` results, the performance bottleneck is now down to the `count_frequency` function:\n",
    "- The code with unsorted document vector has the `count_frequency` function runs in 0.706s, while\n",
    "- The code with sorted document vector has the `count_frequency` function runs in 0.643s.\n",
    "\n",
    "Although with a drawback of having additional 0.025s for the insertion sort, the optimized code still runs faster due to:\n",
    "- Sorted nature of the data in the `inner_product` function that allows a single pass (managed using a merge-like process) process, which is efficient.\n",
    "- Sorted nature of the data makes less comparisons using a fact that if $x > y$ and $y > z$ then $x > z$ (transitive characteristic).\n",
    "- Early termination possibilities without processing the remaining words as there can be no more matching words in the other list due to the alphabetical ordering.\n",
    "\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619319 (radians)\n",
      "         105521 function calls in 0.724 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.008    0.004    0.048    0.024 2488429402.py:1(get_words_from_line_list)\n",
      "        2    0.025    0.012    0.025    0.012 2713057197.py:1(insertion_sort)\n",
      "        2    0.000    0.000    0.721    0.361 2713057197.py:20(word_frequencies_for_file)\n",
      "        3    0.001    0.000    0.001    0.000 2713057197.py:31(inner_product)\n",
      "        1    0.002    0.002    0.724    0.724 2713057197.py:57(docdist3)\n",
      "        2    0.000    0.000    0.005    0.003 573875801.py:1(read_file)\n",
      "    25115    0.008    0.000    0.037    0.000 573875801.py:24(get_words_from_string)\n",
      "        2    0.643    0.321    0.643    0.322 573875801.py:37(count_frequency)\n",
      "        1    0.000    0.000    0.001    0.001 573875801.py:76(vector_angle)\n",
      "        1    0.000    0.000    0.724    0.724 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "      104    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.724    0.724 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "     3753    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1049    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    25115    0.002    0.000    0.002    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.005    0.002    0.005    0.003 {method 'readlines' of '_io._IOBase' objects}\n",
      "    25115    0.007    0.000    0.007    0.000 {method 'split' of 'str' objects}\n",
      "    25115    0.021    0.000    0.021    0.000 {method 'translate' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use \n",
    "    0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j - 1\n",
    "        while i > -1 and A[i] > key:\n",
    "            A[i + 1] = A[i]\n",
    "            i = i - 1\n",
    "        A[i + 1] = key\n",
    "    return A\n",
    "    \n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(L1, L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(L1) and j < len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum\n",
    "\n",
    "def docdist3():\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist3()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Change sorting from insertion sort to merge sort\n",
    "\n",
    "Implement merge sort.\n",
    "\n",
    "Compare the running time, analyze why we get improvement (or why not), identify it using `cProfile`.\n",
    "\n",
    "\\###\n",
    "\n",
    "Running Time: 0.699s (improvement made from 0.724s)\n",
    "\n",
    "The previously made improvement has a 0.025s drawback due to insertion sort's time complexity being $\\mathcal{O}(N^2)$. The merge sort algorithm further reduces such drawback, making it down to 0.004s. Although in terms of the running time, the improvement made this time does not really affect much in total; however, an improvement is still an improvement, especially since we are focusing on the sorting algorithm running time. 0.025s to 0.004s is significant.\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619319 (radians)\n",
      "         132390 function calls (130296 primitive calls) in 0.699 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.009    0.004    0.050    0.025 2488429402.py:1(get_words_from_line_list)\n",
      "   2096/2    0.004    0.000    0.005    0.002 2528663488.py:1(merge_sort)\n",
      "        2    0.000    0.000    0.695    0.348 2528663488.py:36(word_frequencies_for_file)\n",
      "        1    0.002    0.002    0.699    0.699 2528663488.py:47(docdist3)\n",
      "        3    0.001    0.000    0.001    0.000 2713057197.py:31(inner_product)\n",
      "        2    0.000    0.000    0.006    0.003 573875801.py:1(read_file)\n",
      "    25115    0.009    0.000    0.039    0.000 573875801.py:24(get_words_from_string)\n",
      "        2    0.634    0.317    0.634    0.317 573875801.py:37(count_frequency)\n",
      "        1    0.000    0.000    0.001    0.001 573875801.py:76(vector_angle)\n",
      "        1    0.000    0.000    0.699    0.699 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "      104    0.000    0.000    0.001    0.000 codecs.py:319(decode)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.699    0.699 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "    28528    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1049    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    25115    0.002    0.000    0.002    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.005    0.002    0.005    0.003 {method 'readlines' of '_io._IOBase' objects}\n",
      "    25115    0.008    0.000    0.008    0.000 {method 'split' of 'str' objects}\n",
      "    25115    0.022    0.000    0.022    0.000 {method 'translate' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def merge_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, and return result.\n",
    "    \"\"\"\n",
    "    if len(A) > 1:\n",
    "        mid = len(A) // 2\n",
    "        left_half = A[:mid]\n",
    "        right_half = A[mid:]\n",
    "\n",
    "        merge_sort(left_half)\n",
    "        merge_sort(right_half)\n",
    "\n",
    "        i = j = k = 0\n",
    "\n",
    "        while i < len(left_half) and j < len(right_half):\n",
    "            if left_half[i][0] < right_half[j][0]:\n",
    "                A[k] = left_half[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                A[k] = right_half[j]\n",
    "                j += 1\n",
    "            k += 1\n",
    "\n",
    "        while i < len(left_half):\n",
    "            A[k] = left_half[i]\n",
    "            i += 1\n",
    "            k += 1\n",
    "\n",
    "        while j < len(right_half):\n",
    "            A[k] = right_half[j]\n",
    "            j += 1\n",
    "            k += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    freq_mapping = merge_sort(freq_mapping)\n",
    "    return freq_mapping\n",
    "\n",
    "def docdist3():\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist3()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use dictionaries instead of lists\n",
    "\n",
    "Implement the algorithm using dictionaries instead of lists. \n",
    "\n",
    "Analyze why we get improvement and identify it using `cProfile`.\n",
    "\n",
    "\\### \n",
    "\n",
    "Running time: 0.093s (improvement made from 0.699s)\n",
    "\n",
    "In Python, dictionaries are implemented using hash tables, which is a data structure that maps keys to values using a hash function to compute an index. Accessing elements in a dictionary is typically an $\\mathcal{O}(1)$ operation. As highlight by `cProfile`, `count_frequency` that has a major impact in the code that uses lists:\n",
    "- Runs in 0.634s in the code that uses lists.\n",
    "- Runs in 0.024s in the code that uses dictionaries.\n",
    "\n",
    "When using lists, the function requires a linear search through the list for each word in the input $\\texttt{word}$ _ $\\texttt{list}$. In the worst-case scenario, the function essentially performs an $\\mathcal{O}(N)$ operation for each word and the fact that each word might be unique. Definitely that impact of accessing the element in $N \\times \\mathcal{O}(1) = \\mathcal{O}(N)$ is significant compared to $N \\times \\mathcal{O}(N) = \\mathcal{O}(N^2)$.\n",
    "\n",
    "\\###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.619319 (radians)\n",
      "         251296 function calls in 0.093 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.008    0.004 3965631452.py:1(read_file)\n",
      "        2    0.009    0.004    0.046    0.023 3965631452.py:13(get_words_from_line_list)\n",
      "    25115    0.008    0.000    0.035    0.000 3965631452.py:24(get_words_from_string)\n",
      "        2    0.024    0.012    0.037    0.018 3965631452.py:37(count_frequency)\n",
      "        2    0.000    0.000    0.091    0.045 3965631452.py:47(word_frequencies_for_file)\n",
      "        3    0.000    0.000    0.000    0.000 3965631452.py:57(inner_product)\n",
      "        1    0.000    0.000    0.000    0.000 3965631452.py:71(vector_angle)\n",
      "        1    0.002    0.002    0.093    0.093 3965631452.py:80(docdist5)\n",
      "        1    0.000    0.000    0.093    0.093 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "      104    0.000    0.000    0.001    0.000 codecs.py:319(decode)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1169(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "      104    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.093    0.093 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.acos}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    25115    0.002    0.000    0.002    0.000 {method 'extend' of 'list' objects}\n",
      "   150577    0.013    0.000    0.013    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.006    0.003    0.007    0.004 {method 'readlines' of '_io._IOBase' objects}\n",
      "    25115    0.007    0.000    0.007    0.000 {method 'split' of 'str' objects}\n",
      "    25115    0.020    0.000    0.020    0.000 {method 'translate' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r', encoding= 'utf-8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file: \", filename)\n",
    "        sys.exit()\n",
    "\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Input a list of words\n",
    "    Return a DICTIONARY of (word, frequency) pairs\n",
    "    \"\"\"\n",
    "    word_frequency = {}\n",
    "    for word in word_list:\n",
    "        word_frequency[word] = word_frequency.get(word, 0) + 1\n",
    "    return word_frequency\n",
    "\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return dictionary of (word,frequency) pairs for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(D1, D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for key in D2:\n",
    "        if key in D1:\n",
    "            sum += D1[key] * D2[key]\n",
    "    return sum\n",
    "\n",
    "def vector_angle(D1, D2):\n",
    "    \"\"\"\n",
    "    The input are two vectors represented as dictionary of (word,freq) pairs.\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(D1, D2)\n",
    "    denominator = math.sqrt(inner_product(D1, D1) * inner_product(D2, D2))\n",
    "    return math.acos(numerator / denominator)\n",
    "\n",
    "def docdist5():\n",
    "    word_dict_1 = word_frequencies_for_file(filename_1)\n",
    "    word_dict_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(word_dict_1, word_dict_2)\n",
    "    print(\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "\n",
    "cProfile.run(\"docdist5()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b2d0d3375fa4c09a79b62c1c2a6607fb9977a0272e3dcc1e342ecd43aadb5b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
