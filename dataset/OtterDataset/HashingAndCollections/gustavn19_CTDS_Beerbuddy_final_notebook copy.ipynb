{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Recommender System\n",
    "This notebook implements data preprocessing and modeling techniques to create a beer recommender system. I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavnielsen/Documents/Comp_tools_project/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions\n",
    "These functions clean the dataset by handling duplicates, missing values, and incorrect formats. They prepare the data for splitting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df_filtered = df.drop_duplicates([\"name\", \"reviewer\", \"review_text\"]) # Remove duplicate entries\n",
    "    print(\"Size after drop_duplicates: \", len(df_filtered))\n",
    "    \n",
    "    df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n",
    "    df_filtered = df_filtered.dropna(subset=['rating'])  # Drop rows where 'rating' is NaN\n",
    "    print(\"Size after drop rating NA: \", len(df_filtered))\n",
    "    \n",
    "    df_filtered['abv'] = pd.to_numeric(df_filtered['abv'].str.rstrip('%'), errors='coerce') \n",
    "    df_filtered = df_filtered.dropna(subset=['abv'])\n",
    "    print(\"Size after drop abv NA: \", len(df_filtered))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def create_test_train(df, reviewer_col=\"reviewer\", random_state=7, test_size=100, mask_percentage=0.10):\n",
    "    \"\"\"\n",
    "    Splits a dataset into training and test sets, masking a portion of test set entries.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset to split.\n",
    "    - reviewer_col (str): The column name containing reviewer IDs.\n",
    "    - random_state (int): The random state for reproducibility.\n",
    "    - test_size (int): The number of reviewers to sample for the test set.\n",
    "    - mask_percentage (float): The percentage of beers to mask for each reviewer in the test set.\n",
    "\n",
    "    Returns:\n",
    "    - df_train (pd.DataFrame): The training set.\n",
    "    - df_test_masked (pd.DataFrame): The test set with masked entries.\n",
    "    \"\"\"\n",
    "    # Randomly sample reviewers\n",
    "    sampled_reviewers = df[reviewer_col].sample(n=test_size, random_state=random_state)\n",
    "    \n",
    "    # Get reviews from the sampled reviewers\n",
    "    df_test = df[df[reviewer_col].isin(sampled_reviewers)]\n",
    "    \n",
    "    # Group by reviewer to get each user's beers\n",
    "    df_test_grouped = df_test.groupby(reviewer_col)\n",
    "    \n",
    "    # Randomly mask a percentage of beers for each reviewer\n",
    "    test_set_masked = []\n",
    "    for reviewer, group in df_test_grouped:\n",
    "        # Calculate how many beers to mask\n",
    "        num_to_mask = max(int(len(group) * mask_percentage), 1)\n",
    "        \n",
    "        # Sample the calculated number of beers\n",
    "        masked_group = group.sample(n=num_to_mask, random_state=random_state)\n",
    "        test_set_masked.append(masked_group)\n",
    "    \n",
    "    # Combine masked reviews into a single DataFrame\n",
    "    df_test_masked = pd.concat(test_set_masked)\n",
    "    \n",
    "    # Remove masked reviews from the training data\n",
    "    df_train = df.drop(df_test_masked.index)\n",
    "    \n",
    "    # Display dataset summaries\n",
    "    print(\"\\n### Dataset Summary ###\")\n",
    "    print(f\"Total reviewers sampled: {len(sampled_reviewers)}\")\n",
    "    print(f\"Training set size: {df_train.shape}\")\n",
    "    print(f\"Test set size: {df_test_masked.shape}\")\n",
    "    \n",
    "    return df_train, df_test_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop_duplicates:  1157819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/h53w_qjs60509nsf4jbr01c00000gn/T/ipykernel_38694/3114772741.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['rating'] = pd.to_numeric(df_filtered['rating'], errors='coerce')  # Set erros to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after drop rating NA:  1157807\n",
      "Size after drop abv NA:  1154739\n"
     ]
    }
   ],
   "source": [
    "# Load data and preprocess\n",
    "df = pd.read_pickle('encoded_beers_SBERT.pkl')\n",
    "\n",
    "df_filtered = preprocess_data(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery</th>\n",
       "      <th>subgenre</th>\n",
       "      <th>abv</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>algorithm_rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>sbert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¯ðŸ‡ªJersey</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>Jerseyislandbeer</td>\n",
       "      <td>December 14, 2023</td>\n",
       "      <td>330ml can from Shoprite in Livingstone. At hom...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.037878353, 0.00593541, 0.0062317043, -0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¬ðŸ‡§Ipswich, England</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.99</td>\n",
       "      <td>Grumbo</td>\n",
       "      <td>February 28, 2022</td>\n",
       "      <td>18/2/2022. Can sample courtesy of fonefan, che...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.037820198, -0.044825517, 0.07764052, 0.065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡¸ðŸ‡ªTyresÃ¶, Sweden</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>omhper</td>\n",
       "      <td>February 19, 2022</td>\n",
       "      <td>--Sample, thanks fonefan! -- Hazy deep golden,...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.056960188, -0.00059301173, 0.11057871, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡«ðŸ‡®Vasa, Finland</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>oh6gdx</td>\n",
       "      <td>January 31, 2022</td>\n",
       "      <td>Panda from a can, thanks fonefan!. Golden colo...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.003549767, -0.010705345, 0.02083684, 0.0106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Wild Dog Pale Ale</td>\n",
       "      <td>Wild Dog (Tiemann Beer)</td>\n",
       "      <td>American Pale Ale</td>\n",
       "      <td>5.2</td>\n",
       "      <td>ðŸ‡©ðŸ‡°Haderslev, Denmark</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>martin00sr</td>\n",
       "      <td>January 8, 2022</td>\n",
       "      <td>Can @Ulfborg. Cloudy amber, white head. Malty ...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.01005388, -0.02942978, 0.0016338513, 0.017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               name                  brewery           subgenre  abv  \\\n",
       "0   1  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "1   2  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "2   3  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "3   4  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "4   6  Wild Dog Pale Ale  Wild Dog (Tiemann Beer)  American Pale Ale  5.2   \n",
       "\n",
       "               location  rating  average_rating          reviewer  \\\n",
       "0              ðŸ‡¯ðŸ‡ªJersey     3.5            2.99  Jerseyislandbeer   \n",
       "1    ðŸ‡¬ðŸ‡§Ipswich, England     3.2            2.99            Grumbo   \n",
       "2      ðŸ‡¸ðŸ‡ªTyresÃ¶, Sweden     3.5            2.99            omhper   \n",
       "3       ðŸ‡«ðŸ‡®Vasa, Finland     2.8            2.99            oh6gdx   \n",
       "4  ðŸ‡©ðŸ‡°Haderslev, Denmark     2.6            2.99        martin00sr   \n",
       "\n",
       "         review_date                                        review_text  \\\n",
       "0  December 14, 2023  330ml can from Shoprite in Livingstone. At hom...   \n",
       "1  February 28, 2022  18/2/2022. Can sample courtesy of fonefan, che...   \n",
       "2  February 19, 2022  --Sample, thanks fonefan! -- Hazy deep golden,...   \n",
       "3   January 31, 2022  Panda from a can, thanks fonefan!. Golden colo...   \n",
       "4    January 8, 2022  Can @Ulfborg. Cloudy amber, white head. Malty ...   \n",
       "\n",
       "  algorithm_rating  total_reviews  \\\n",
       "0             28.0             11   \n",
       "1             28.0             11   \n",
       "2             28.0             11   \n",
       "3             28.0             11   \n",
       "4             28.0             11   \n",
       "\n",
       "                                     sbert_embedding  \n",
       "0  [0.037878353, 0.00593541, 0.0062317043, -0.011...  \n",
       "1  [-0.037820198, -0.044825517, 0.07764052, 0.065...  \n",
       "2  [0.056960188, -0.00059301173, 0.11057871, 0.02...  \n",
       "3  [0.003549767, -0.010705345, 0.02083684, 0.0106...  \n",
       "4  [-0.01005388, -0.02942978, 0.0016338513, 0.017...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Dataset Summary ###\n",
      "Total reviewers sampled: 100\n",
      "Training set size: (1149910, 14)\n",
      "Test set size: (4829, 14)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test_masked = create_test_train(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for retrieving beer information\n",
    "beer_info = df_filtered[['name', 'abv', 'subgenre']]\n",
    "\n",
    "# Drop duplicate rows based on the 'name' column (i.e. beers)\n",
    "beer_info = beer_info.drop_duplicates(subset='name')\n",
    "\n",
    "beer_info.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create locality-sensitive hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable to store the model\n",
    "sbert_model = None\n",
    "\n",
    "def encode_sbert(query, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Encodes a query using SBERT. Loads the model if not already loaded.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str or list of str): The query or list of queries to encode.\n",
    "        model_name (str): The name of the SBERT model to load (default is 'all-MiniLM-L6-v2').\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding(s) for the input query/queries.\n",
    "    \"\"\"\n",
    "    global sbert_model  # Use the global variable to store the model\n",
    "    \n",
    "    # Load the model if it's not already loaded\n",
    "    if sbert_model is None:\n",
    "        sbert_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode the query and return the embeddings\n",
    "    return sbert_model.encode(query)\n",
    "\n",
    "def generate_hyperplanes(dim, num_hash_functions):\n",
    "    \"\"\"\n",
    "    Generate random hyperplanes for hash functions.\n",
    "    \n",
    "    Parameters:\n",
    "    - dim: Dimensionality of the embeddings.\n",
    "    - num_hash_functions: Number of hash functions per table.\n",
    "    \n",
    "    Returns:\n",
    "    - A matrix of shape (num_hash_functions, dim) where each row is a hyperplane.\n",
    "    \"\"\"\n",
    "    return np.random.randn(num_hash_functions, dim)\n",
    "\n",
    "def hash_vectors(vectors, hyperplanes):\n",
    "    \"\"\"\n",
    "    Hash a batch of vectors using a set of hyperplanes.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "    - hyperplanes: Matrix of hyperplanes (2D array of shape [k, d]).\n",
    "\n",
    "    Returns:\n",
    "    - A matrix of binary hash values (shape [n_samples, k]).\n",
    "    \"\"\"\n",
    "    # Compute dot products and return binary hash values\n",
    "    return (np.dot(vectors, hyperplanes.T) > 0).astype(int)\n",
    "\n",
    "class LSHVectorized:\n",
    "    def __init__(self, d, k, L):\n",
    "        \"\"\"\n",
    "        Initialize the LSH scheme with vectorized support.\n",
    "\n",
    "        Parameters:\n",
    "        - d: Dimensionality of the input vectors.\n",
    "        - k: Number of hash functions per table.\n",
    "        - L: Number of hash tables.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.tables = [defaultdict(list) for _ in range(L)]\n",
    "        self.hyperplanes = [generate_hyperplanes(d, k) for _ in range(L)]\n",
    "\n",
    "    def add_vectors(self, vectors, identifiers):\n",
    "        \"\"\"\n",
    "        Add a batch of vectors to the LSH index.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Input vectors (2D array of shape [n_samples, d]).\n",
    "        - identifiers: A list of unique identifiers for the vectors.\n",
    "        \"\"\"\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all vectors at once\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Add vectors to their corresponding buckets\n",
    "            for identifier, key in zip(identifiers, hash_keys):\n",
    "                table[key].append(identifier)\n",
    "\n",
    "    def query(self, vectors):\n",
    "        \"\"\"\n",
    "        Query the LSH index to find similar items for a batch of vectors.\n",
    "\n",
    "        Parameters:\n",
    "        - vectors: Query vectors (2D array of shape [n_samples, d]).\n",
    "\n",
    "        Returns:\n",
    "        - A list of sets, where each set contains the candidates for a query vector.\n",
    "        \"\"\"\n",
    "        candidates = [set() for _ in range(len(vectors))]\n",
    "        for table, hyperplanes in zip(self.tables, self.hyperplanes):\n",
    "            # Compute hash values for all query vectors\n",
    "            hash_values = hash_vectors(vectors, hyperplanes)\n",
    "            \n",
    "            # Convert binary hash values to tuples for dictionary keys\n",
    "            hash_keys = [tuple(h) for h in hash_values]\n",
    "            \n",
    "            # Retrieve candidates for each query\n",
    "            for i, key in enumerate(hash_keys):\n",
    "                candidates[i].update(table.get(key, []))\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.vstack(df_train[\"sbert_embedding\"].values)  # Combine embeddings into a 2D array\n",
    "identifiers = df_train.index.tolist()  # Use review IDs as identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LSH ##\n",
    "# Initialize LSH scheme\n",
    "d = 384\n",
    "k = 13\n",
    "L = 30\n",
    "\n",
    "lsh = LSHVectorized(d, k, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors to the LSH index\n",
    "lsh.add_vectors(vectors, identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_ratings_user_based(user_item_matrix, similarity_matrix):\n",
    "   \n",
    "    \"\"\"\n",
    "    this function predicts the ratings for the user_item_matrix using the similarity_matrix\n",
    "    \n",
    "\n",
    "    Parameters: \n",
    "    \n",
    "    - user_item_matrix (DataFrame): User-item matrix with ratings centered around the user mean.\n",
    "    - similarity_matrix (DataFrame): User-user similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "        - pred (DataFrame): Predicted ratings for all user-item pairs.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Compute predictions\n",
    "    similarity_sum = np.abs(similarity_matrix).sum(axis=1)[:, None]\n",
    "    pred = np.dot(similarity_matrix, user_item_matrix) / (similarity_sum + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def collaborative_filtering(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Predicts user ratings for items using user-based collaborative filtering with cosine similarity. \n",
    "    Preprocesses the input data to create a centered user-item matrix, computes user similarities, \n",
    "    and generates predicted ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input data with 'reviewer', 'name', and 'rating' columns.\n",
    "\n",
    "    Returns:\n",
    "    - pr_df (DataFrame): Predicted ratings for all user-item pairs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    user_item_matrix = df.pivot_table(\n",
    "    index=\"reviewer\",     # Rows: Reviewers\n",
    "    columns=\"name\",       # Columns: Beer names\n",
    "    values=\"rating\",      # Values: Ratings\n",
    "    fill_value=0          # Fill missing ratings with 0\n",
    "    )\n",
    "    \n",
    "    user_item_np = np.where(user_item_matrix != 0, (user_item_matrix - 3) / 2, 0) # scale to [-1,1]\n",
    "    user_item_matrix = pd.DataFrame(user_item_np, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predicted_ratings = predict_ratings_user_based(user_item_matrix, cosine_similarity_matrix)\n",
    "\n",
    "    df_out = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "   \n",
    "    return df_out\n",
    "\n",
    "\n",
    "collab_df = collaborative_filtering(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_beer_matrix = df_train.pivot_table(\n",
    "    index=\"reviewer\",     # Rows: Reviewers\n",
    "    columns=\"name\",       # Columns: Beer names\n",
    "    values=\"rating\",      # Values: Ratings\n",
    "    fill_value=0          # Fill missing ratings with 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reviews = np.sum(user_beer_matrix > 0, axis=1)\n",
    "beta = 0.55 + ((0.45) / (1+np.log(n_reviews))) # Describe how much weight to put on collaborative filtering (1-beta), so more weight is on users with many reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Term Explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define reference context for flavor-related words. The first 20 is from a aromatic kit used for sommeliers, the rest is ai-generated.\n",
    "context_words = [\n",
    "    \"bitter\", \"sweet\", \"salt\", \"sour\", \"umami\",\n",
    "    \"lemon\", \"grapefruit\", \"apple\", \"pear\", \"blackcurrant\", \"prune\", \"melon\", \n",
    "    \"banana\", \"acacia\", \"rose\", \"cut grass\", \"hay\", \"bay leaf\", \"thyme\", \n",
    "    \"tomato\", \"pepper\", \"nutmeg\", \"clove\", \"bread\", \"butter\", \"vanilla\", \n",
    "    \"hazelnut\", \"toast\", \"malt\", \"caramel\", \"honey\", \"coffee\", \"licorice\",\n",
    "    \"pine\", \"grass\", \"resin\", \"floral\", \"perfume\", \"incense\", \"cinnamon\",\n",
    "    \"ginger\", \"anise\", \"nut\", \"almond\", \"walnut\", \"chestnut\", \"peanut\",\n",
    "    \"soy\", \"mushroom\", \"earth\", \"dust\", \"wood\", \"barnyard\", \"horse\",\n",
    "    \"wet\", \"dry\", \"metallic\", \"sulfur\", \"fish\", \"cheese\", \"butter\",\n",
    "    \"cream\", \"leather\", \"silk\", \"rubber\", \"barnyard\", \"ammonia\",\n",
    "    \"rotten\", \"acid\"\n",
    "]\n",
    "custom_stop_words = [\"beer\", \"beers\", \"bottle\", \"taste\", \"nice\", \"aroma\", \"like\", \"good\", \"great\", \"head\", \"flavor\", \"flavors\", \"flavour\", \"flavours\", \"brew\", \"can\"]\n",
    "context_embeddings = encode_sbert(context_words)\n",
    "\n",
    "# Function to filter terms dynamically\n",
    "def is_flavor_related(term, context_embeddings, threshold=0.35):\n",
    "    term_embedding = sbert_model.encode([term])[0]\n",
    "    cosine_similarity = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    max_similarity = max(cosine_similarity(term_embedding, context) for context in context_embeddings)\n",
    "    return max_similarity > threshold\n",
    "\n",
    "def plot_bucket(bucket_vectors, cluster_labels, perplexity=30, n_iter=5000, learning_rate=200):\n",
    "    \"\"\"\n",
    "    Visualizes differences within an LSH bucket using t-SNE with configurable parameters.\n",
    "    \n",
    "    Args:\n",
    "        bucket_vectors (np.ndarray): High-dimensional vectors of beers in the bucket.\n",
    "        cluster_labels (np.ndarray): Cluster labels assigned to each vector.\n",
    "        subgenres (np.ndarray): Subgenre or categorical labels for each beer.\n",
    "        perplexity (int): The t-SNE perplexity parameter, balancing local/global data views.\n",
    "        n_iter (int): Number of iterations for t-SNE optimization.\n",
    "        learning_rate (float): Learning rate for t-SNE optimization.\n",
    "    \"\"\"\n",
    "    # t-SNE reducer with tuned parameters\n",
    "    reducer = TSNE(\n",
    "        n_components=2, \n",
    "        random_state=42, \n",
    "        perplexity=perplexity, \n",
    "        n_iter=n_iter, \n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    reduced_vectors = reducer.fit_transform(bucket_vectors)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    scatter = plt.scatter(\n",
    "        reduced_vectors[:, 0],\n",
    "        reduced_vectors[:, 1],\n",
    "        c=cluster_labels,\n",
    "        cmap='plasma',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Cluster Label')\n",
    "    plt.title(f\"t-SNE Visualization (Perplexity={perplexity}, n_iter={n_iter}, LR={learning_rate})\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def getThemes(df_filtered, beer_name, query_embedding, limit=100):\n",
    "    # Initialize CountVectorizer with custom stopwords\n",
    "    default_stop_words = CountVectorizer(stop_words='english').get_stop_words()\n",
    "    all_stop_words = list(set(default_stop_words).union(custom_stop_words))\n",
    "\n",
    "    # Pass the combined stop words to CountVectorizer\n",
    "    vectorizer = CountVectorizer(max_features=100, stop_words=all_stop_words, token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
    "    df_beer = df_filtered[df_filtered[\"name\"] == beer_name]\n",
    "    # Extract top terms from cluster reviews\n",
    "    term_matrix = vectorizer.fit_transform(df_beer[\"review_text\"])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    term_counts = np.array(term_matrix.sum(axis=0)).flatten()\n",
    "    top_terms = [terms[i] for i in term_counts.argsort()[-limit:]]  # Top 5 terms\n",
    "    filtered_top_terms = [term for term in top_terms if is_flavor_related(term, context_embeddings)]\n",
    "    \n",
    "    # Return the terms most similar to the query\n",
    "    term_embeddings = np.vstack([encode_sbert(term) for term in filtered_top_terms])\n",
    "    \n",
    "    # Calculate cosine similarity between query and terms\n",
    "    similarities = cosine_similarity(query_embedding, term_embeddings)[0]\n",
    "    \n",
    "    # Create a DataFrame to store terms and their similarities\n",
    "    term_similarity_df = pd.DataFrame({\n",
    "        'term': filtered_top_terms,\n",
    "        'similarity': similarities\n",
    "    })\n",
    "    \n",
    "    # Sort terms by similarity to the query\n",
    "    term_similarity_df = term_similarity_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Return the top similar themes\n",
    "    return term_similarity_df['term'].head(10).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reccomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_beer_A(query_embedding, df_train, user_name, beer_info, beta, abv_desired=None, style_desired=None, n_clusters=5):\n",
    "    # Query the LSH index\n",
    "    candidates = lsh.query(query_embedding)\n",
    "    print(len(candidates[0]))\n",
    "    # Filter bucket vectors and metadata\n",
    "    bucket_data = df_train[df_train[\"id\"].isin(list(candidates[0]))]\n",
    "    bucket_vectors = np.vstack(bucket_data[\"sbert_embedding\"].to_numpy())\n",
    "    \n",
    "    # Extract subgenre information\n",
    "    subgenres = bucket_data[\"subgenre\"].values  # Adjust column name as necessary\n",
    "\n",
    "    # Perform clustering on bucket vectors\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=7)\n",
    "    cluster_labels = kmeans.fit_predict(bucket_vectors)\n",
    "    \n",
    "    # Assign query to the nearest cluster\n",
    "    query_cluster = kmeans.predict(query_embedding)[0]\n",
    "\n",
    "    # Filter beers in the same cluster as the query\n",
    "    cluster_indices = np.where(cluster_labels == query_cluster)[0]\n",
    "    cluster_vectors = bucket_vectors[cluster_indices]\n",
    "    cluster_beers = bucket_data.iloc[cluster_indices]\n",
    "    print(len(cluster_beers))\n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, cluster_vectors)[0]\n",
    "\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': cluster_beers[\"name\"].values,  # Adjust column name if necessary\n",
    "    })\n",
    "    \n",
    "    LSH_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "    print(len(LSH_score))\n",
    "\n",
    "    collab_filtering_scores = predcicted_rating_user[LSH_score.index.tolist()] # Get CF_score for user for the beers in cluster\n",
    "\n",
    "\n",
    "    # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "    abv = beer_info.loc[LSH_score.index.tolist()][\"abv\"]\n",
    "\n",
    "    alpha = 0.05\n",
    "    if abv_desired:\n",
    "        if abv_desired == 0:\n",
    "            abv_weight = -2 * abs(abv - abv_desired)\n",
    "        else:\n",
    "            abv_weight = -alpha * ((abv - abv_desired)**2) / (abv_desired**1.5 + 1)\n",
    "        abv_diff = abs(abv.values - abv_desired)\n",
    "    else:\n",
    "        abv_weight = abv - abv\n",
    "        abv_diff = 0\n",
    "    \n",
    "    # Add bonus for match in style\n",
    "    style_bonus = np.zeros(len(LSH_score))\n",
    "    if style_desired:\n",
    "        relevant_styles = beer_info.loc[LSH_score.index.tolist()][\"subgenre\"]\n",
    "        style_mask = relevant_styles == style_desired\n",
    "        style_bonus[style_mask] = 0.05\n",
    "    \n",
    "    beta = beta[user_name]\n",
    "\n",
    "    # Combine weights and scores\n",
    "    weighted_score = (\n",
    "        beta * LSH_score +\n",
    "        (1-beta) * collab_filtering_scores +\n",
    "        abv_weight +\n",
    "        style_bonus\n",
    "    )\n",
    "\n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': LSH_score.index,\n",
    "        'score': weighted_score,\n",
    "        'abv': abv.values,\n",
    "        'LSH_score': LSH_score.values,\n",
    "        'LSH_score_weighted': LSH_score.values * beta,\n",
    "        'collab_score': collab_filtering_scores.values,\n",
    "        'collab_score_weighted': collab_filtering_scores.values * (1-beta),\n",
    "        'abv_diff': abv_diff,\n",
    "        'abv_weight': abv_weight.values,\n",
    "        'Style bonus': style_bonus,\n",
    "        'Weight beta': beta\n",
    "    })\n",
    "    \n",
    "    # Remove index of weighted score and keep the beer name as a column\n",
    "    beer_weighted_score.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Get the 10 beers with the highest weighted scores\n",
    "    #beer_weighted_score = beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "    #beer_weighted_score['notes'] = \"\"\n",
    "    # Apply getThemes to each beer in the DataFrame\n",
    "    #beer_weighted_score['notes'] = beer_weighted_score['beer'].apply(lambda x: getThemes(df_train, x, query_embedding))\n",
    "    #beer_weighted_score.loc[:9, 'notes'] = beer_weighted_score.loc[:9, 'beer'].apply(\n",
    "    #    lambda x: getThemes(df_train, x, query_embedding)) # TODO Fix!\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122106\n",
      "10879\n",
      "2939\n",
      "Top 5 recommended beers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer</th>\n",
       "      <th>score</th>\n",
       "      <th>abv</th>\n",
       "      <th>LSH_score</th>\n",
       "      <th>LSH_score_weighted</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>collab_score_weighted</th>\n",
       "      <th>abv_diff</th>\n",
       "      <th>abv_weight</th>\n",
       "      <th>Style bonus</th>\n",
       "      <th>Weight beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Cyclic Beer Farm Saison</td>\n",
       "      <td>0.467894</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.751576</td>\n",
       "      <td>0.471238</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>Theodor SchiÃ¸tz Anarkist Bloody Weizen</td>\n",
       "      <td>0.460542</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.747391</td>\n",
       "      <td>0.468614</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 Fonteinen Zenne y Frontera - Oloroso &amp; Pedro XimÃ©nez Blend (Season 17|18 Blend No. 50)</td>\n",
       "      <td>0.460244</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.731065</td>\n",
       "      <td>0.458378</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>Zwettler Zwickl</td>\n",
       "      <td>0.456061</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>SchÃ¼tzen BrÃ¤u</td>\n",
       "      <td>0.455110</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.754124</td>\n",
       "      <td>0.472836</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.017315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Insel-Brauerei Seepferd</td>\n",
       "      <td>0.454555</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.733217</td>\n",
       "      <td>0.459727</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>Stupavar Herbal Ale 13Â°</td>\n",
       "      <td>0.448392</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.728242</td>\n",
       "      <td>0.456607</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>De Boei Noorderzon</td>\n",
       "      <td>0.445241</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.714707</td>\n",
       "      <td>0.448121</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>De Proefbrouwerij / Trillium Bouket Farmhouse Ale</td>\n",
       "      <td>0.438676</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.698950</td>\n",
       "      <td>0.438241</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>Ã˜lfabrikken Hvid Jul</td>\n",
       "      <td>0.437744</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.706354</td>\n",
       "      <td>0.442883</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          beer  \\\n",
       "643                                                                    Cyclic Beer Farm Saison   \n",
       "2511                                                    Theodor SchiÃ¸tz Anarkist Bloody Weizen   \n",
       "15    3 Fonteinen Zenne y Frontera - Oloroso & Pedro XimÃ©nez Blend (Season 17|18 Blend No. 50)   \n",
       "2899                                                                           Zwettler Zwickl   \n",
       "2261                                                                             SchÃ¼tzen BrÃ¤u   \n",
       "1272                                                                   Insel-Brauerei Seepferd   \n",
       "2424                                                                   Stupavar Herbal Ale 13Â°   \n",
       "660                                                                         De Boei Noorderzon   \n",
       "695                                          De Proefbrouwerij / Trillium Bouket Farmhouse Ale   \n",
       "2913                                                                      Ã˜lfabrikken Hvid Jul   \n",
       "\n",
       "         score  abv  LSH_score  LSH_score_weighted  collab_score  \\\n",
       "643   0.467894  5.8   0.751576            0.471238      0.000924   \n",
       "2511  0.460542  5.2   0.747391            0.468614      0.000607   \n",
       "15    0.460244  6.9   0.731065            0.458378      0.005071   \n",
       "2899  0.456061  5.5   0.736462            0.461761      0.000169   \n",
       "2261  0.455110  4.4   0.754124            0.472836     -0.001099   \n",
       "1272  0.454555  5.5   0.733217            0.459727      0.001586   \n",
       "2424  0.448392  5.2   0.728242            0.456607      0.000225   \n",
       "660   0.445241  6.0   0.714707            0.448121     -0.000852   \n",
       "695   0.438676  6.5   0.698950            0.438241      0.002883   \n",
       "2913  0.437744  8.5   0.706354            0.442883      0.001671   \n",
       "\n",
       "      collab_score_weighted  abv_diff  abv_weight  Style bonus  Weight beta  \n",
       "643                0.000345       1.2   -0.003688          0.0        0.627  \n",
       "2511               0.000226       1.8   -0.008299          0.0        0.627  \n",
       "15                 0.001892       0.1   -0.000026          0.0        0.627  \n",
       "2899               0.000063       1.5   -0.005763          0.0        0.627  \n",
       "2261              -0.000410       2.6   -0.017315          0.0        0.627  \n",
       "1272               0.000592       1.5   -0.005763          0.0        0.627  \n",
       "2424               0.000084       1.8   -0.008299          0.0        0.627  \n",
       "660               -0.000318       1.0   -0.002561          0.0        0.627  \n",
       "695                0.001075       0.5   -0.000640          0.0        0.627  \n",
       "2913               0.000623       1.5   -0.005763          0.0        0.627  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a query\n",
    "test_query = \"Light, refreshing bitter beer with a orange taste\"\n",
    "user_name = \"100Beier\"\n",
    "query_embedding = encode_sbert(test_query).reshape(1, -1)\n",
    "beer_recommendations= recommend_beer_A(query_embedding, df_train, user_name, beer_info, beta, abv_desired=7)\n",
    "\n",
    "print(\"Top 5 recommended beers:\")\n",
    "# Set max column width to display full array\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(beer_recommendations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of experiment B short pipeline without KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_beer_B(query_embedding, df_train, user_name, beer_info, beta, abv_desired=None, style_desired=None, n_clusters=5):\n",
    "    # Query the LSH index\n",
    "    candidates = lsh.query(query_embedding)\n",
    "    # Filter bucket vectors and metadata\n",
    "    bucket_data = df_train[df_train[\"id\"].isin(list(candidates[0]))]\n",
    "    bucket_vectors = np.vstack(bucket_data[\"sbert_embedding\"].to_numpy())\n",
    "    \n",
    "    # Extract subgenre information\n",
    "    subgenres = bucket_data[\"subgenre\"].values \n",
    "    \n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, bucket_vectors)[0]\n",
    "\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': df_train[df_train[\"id\"].isin(list(candidates[0]))][\"name\"].values,\n",
    "    })\n",
    "    \n",
    "    LSH_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "    \n",
    "    collab_filtering_scores = predcicted_rating_user[LSH_score.index.tolist()] # Get CF_score for user for the beers in cluster\n",
    "\n",
    "    # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "    abv = beer_info.loc[LSH_score.index.tolist()][\"abv\"]\n",
    "\n",
    "    alpha = 0.05\n",
    "    if abv_desired:\n",
    "        if abv_desired == 0:\n",
    "            abv_weight = -2 * abs(abv - abv_desired)\n",
    "        else:\n",
    "            abv_weight = -alpha * ((abv - abv_desired)**2) / (abv_desired**1.5 + 1)\n",
    "        abv_diff = abs(abv.values - abv_desired)\n",
    "    else:\n",
    "        abv_weight = abv-abv\n",
    "        abv_diff = 0\n",
    "\n",
    "    beta = beta[user_name]    \n",
    "    \n",
    "    # Add bonus for match in style\n",
    "    style_bonus = np.zeros(len(LSH_score))\n",
    "    if style_desired:\n",
    "        relevant_styles = beer_info.loc[LSH_score.index.tolist()][\"subgenre\"]\n",
    "        style_mask = relevant_styles == style_desired\n",
    "        style_bonus[style_mask] = 0.05\n",
    "    \n",
    "    \n",
    "    # Combine weights and scores\n",
    "    weighted_score = (\n",
    "        beta * LSH_score +\n",
    "        (1-beta) * collab_filtering_scores +\n",
    "        abv_weight +\n",
    "        style_bonus\n",
    "    )\n",
    "\n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': LSH_score.index,\n",
    "        'score': weighted_score,\n",
    "        'abv': abv.values,\n",
    "        'LSH_score': LSH_score.values,\n",
    "        'LSH_score_weighted': LSH_score.values * beta,\n",
    "        'collab_score': collab_filtering_scores.values,\n",
    "        'collab_score_weighted': collab_filtering_scores.values * (1-beta),\n",
    "        'abv_diff': abv_diff,\n",
    "        'abv_weight': abv_weight.values,\n",
    "        'Style bonus': style_bonus,\n",
    "        'Weight beta': beta\n",
    "    })\n",
    "    \n",
    "    # Remove index of weighted score and keep the beer name as a column\n",
    "    beer_weighted_score.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reccomendation using only cosine similarity\n",
    "def recommend_beer_C(query_embedding, df_train, vectors):\n",
    "\n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, vectors)[0]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': df_train[\"name\"].values,\n",
    "    })\n",
    "    \n",
    "    cosine_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "\n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': cosine_score.index,\n",
    "        'cosine_score': cosine_score.values,\n",
    "    })\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='cosine_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reccomend beer just using collaborative filtering\n",
    "def recommend_beer_D(user_name):\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': predcicted_rating_user.index,\n",
    "        'collab_score': predcicted_rating_user.values,\n",
    "    })\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='collab_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145506\n",
      "18805\n",
      "4051\n",
      "239032\n",
      "21141\n",
      "2950\n",
      "258455\n",
      "19303\n",
      "4389\n",
      "160762\n",
      "16006\n",
      "2663\n",
      "218136\n",
      "23909\n",
      "4214\n",
      "105088\n",
      "9396\n",
      "2039\n",
      "239705\n",
      "25372\n",
      "4388\n",
      "261242\n",
      "34400\n",
      "5012\n",
      "174295\n",
      "18106\n",
      "3883\n",
      "161519\n",
      "16106\n",
      "2434\n",
      "233264\n",
      "16947\n",
      "4118\n",
      "289542\n",
      "27054\n",
      "3018\n",
      "158319\n",
      "16798\n",
      "3708\n",
      "217848\n",
      "22993\n",
      "4289\n",
      "123013\n",
      "13445\n",
      "3333\n",
      "229720\n",
      "20713\n",
      "2930\n",
      "77491\n",
      "5502\n",
      "2219\n",
      "160749\n",
      "14809\n",
      "2577\n",
      "157869\n",
      "11913\n",
      "2433\n",
      "102375\n",
      "12508\n",
      "3399\n",
      "118350\n",
      "12443\n",
      "2271\n",
      "214860\n",
      "23455\n",
      "4266\n",
      "204064\n",
      "20380\n",
      "4261\n",
      "68693\n",
      "5731\n",
      "1744\n",
      "126946\n",
      "9048\n",
      "2140\n",
      "116326\n",
      "11870\n",
      "2254\n",
      "73457\n",
      "9093\n",
      "2857\n",
      "84156\n",
      "7663\n",
      "1835\n",
      "191463\n",
      "18430\n",
      "2655\n",
      "142628\n",
      "14111\n",
      "3625\n",
      "63430\n",
      "7425\n",
      "2530\n",
      "123980\n",
      "13704\n",
      "2758\n",
      "104989\n",
      "7002\n",
      "2889\n",
      "221552\n",
      "28445\n",
      "4797\n",
      "281545\n",
      "22703\n",
      "3135\n",
      "77034\n",
      "9653\n",
      "3013\n",
      "120633\n",
      "12153\n",
      "3270\n",
      "119239\n",
      "15823\n",
      "3708\n",
      "108859\n",
      "13766\n",
      "3572\n",
      "122269\n",
      "13898\n",
      "2818\n",
      "133101\n",
      "17138\n",
      "3830\n",
      "78406\n",
      "7130\n",
      "2152\n",
      "151801\n",
      "19231\n",
      "4148\n",
      "161697\n",
      "15818\n",
      "2429\n",
      "285839\n",
      "28977\n",
      "4849\n",
      "169567\n",
      "14886\n",
      "2656\n",
      "285463\n",
      "27127\n",
      "2907\n",
      "163486\n",
      "20695\n",
      "4269\n",
      "67589\n",
      "5045\n",
      "1337\n",
      "173862\n",
      "21970\n",
      "4361\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_true_A = 0\n",
    "num_false_A = 0\n",
    "total_time_A = 0.0\n",
    "times_A = []\n",
    "for i in range(50):\n",
    "    review_row = df_test_masked.iloc[i]\n",
    "    real_beer = review_row[\"name\"]\n",
    "    query = review_row[\"sbert_embedding\"].reshape(1, -1)\n",
    "    user = review_row[\"reviewer\"]\n",
    "    abv_desired = review_row[\"abv\"]\n",
    "    style_desired = review_row[\"subgenre\"]\n",
    "    start_time = time.perf_counter()\n",
    "    beer_recommendations= recommend_beer_A(query_embedding=query, df_train=df_train, user_name=user, beer_info=beer_info, beta=beta, abv_desired=None, style_desired=None)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time_A += elapsed_time\n",
    "    times_A.append(elapsed_time)\n",
    "    \n",
    "    if real_beer in beer_recommendations[\"beer\"].head(20).tolist():\n",
    "        num_true_A += 1\n",
    "    else:\n",
    "        num_false_A +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true_B = 0\n",
    "num_false_B = 0\n",
    "total_time_B = 0.0\n",
    "times_B = []\n",
    "for i in range(2000):\n",
    "    review_row = df_test_masked.iloc[i]\n",
    "    real_beer = review_row[\"name\"]\n",
    "    query = review_row[\"sbert_embedding\"].reshape(1, -1)\n",
    "    user = review_row[\"reviewer\"]\n",
    "    abv_desired = review_row[\"abv\"]\n",
    "    style_desired = review_row[\"subgenre\"]\n",
    "    start_time = time.perf_counter()\n",
    "    beer_recommendations= recommend_beer_B(query_embedding=query, df_train=df_train, user_name=user, beer_info=beer_info, beta = beta, abv_desired=None, style_desired=None)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time_B += elapsed_time\n",
    "    times_B.append(elapsed_time)\n",
    "    \n",
    "    if real_beer in beer_recommendations[\"beer\"].head(20).tolist():\n",
    "        num_true_B += 1\n",
    "    else:\n",
    "        num_false_B +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_true_C = 0\n",
    "num_false_C = 0\n",
    "total_time_C = 0.0\n",
    "times_C = []\n",
    "for i in range(2000):\n",
    "    review_row = df_test_masked.iloc[i]\n",
    "    real_beer = review_row[\"name\"]\n",
    "    query = review_row[\"sbert_embedding\"].reshape(1, -1)\n",
    "    user = review_row[\"reviewer\"]\n",
    "    abv_desired = review_row[\"abv\"]\n",
    "    style_desired = review_row[\"subgenre\"]\n",
    "    start_time = time.perf_counter()\n",
    "    beer_recommendations= recommend_beer_C(query_embedding=query, df_train=df_train, vectors=vectors)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time_C += elapsed_time\n",
    "    times_C.append(elapsed_time)\n",
    "    \n",
    "    if real_beer in beer_recommendations[\"beer\"].head(20).tolist():\n",
    "        num_true_C += 1\n",
    "    else:\n",
    "        num_false_C +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true_D = 0\n",
    "num_false_D = 0\n",
    "total_time_D = 0.0\n",
    "times_D = []\n",
    "errors = []\n",
    "for i in range(2000):\n",
    "    review_row = df_test_masked.iloc[i]\n",
    "    real_beer = review_row[\"name\"]\n",
    "    query = review_row[\"sbert_embedding\"].reshape(1, -1)\n",
    "    user = review_row[\"reviewer\"]\n",
    "    abv_desired = review_row[\"abv\"]\n",
    "    style_desired = review_row[\"subgenre\"]\n",
    "    start_time = time.perf_counter()\n",
    "    beer_recommendations= recommend_beer_D(user_name=user)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time_D += elapsed_time\n",
    "    times_D.append(elapsed_time)\n",
    "    \n",
    "    if real_beer in beer_recommendations[\"beer\"].head(20).tolist():\n",
    "        num_true_D += 1\n",
    "    else:\n",
    "        num_false_D +=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Summary:\n",
      "  Experiment           Type  Queries in top 20  Queries not in top 20  \\\n",
      "0          A  LSH/KMEANS/CF                  3                     47   \n",
      "1          B         LSH/CF                  1                     49   \n",
      "2          C         COSINE                  4                     46   \n",
      "3          D             CF                  3                     47   \n",
      "\n",
      "   Precision  Recall  Accuracy (%)  Average Time (s)  \n",
      "0       0.05    0.06           6.0          1.316225  \n",
      "1       0.05    0.02           2.0          0.356019  \n",
      "2       0.05    0.08           8.0          0.971998  \n",
      "3       0.05    0.06           6.0          0.001234  \n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_recall(tp, total_cases, recommendations_per_case=20):\n",
    "    \"\"\"\n",
    "    Calculate Precision and Recall.\n",
    "\n",
    "    Parameters:\n",
    "    - tp: True Positives\n",
    "    - total_cases: Total number of test cases\n",
    "    - recommendations_per_case: Number of recommendations per test case (default=20)\n",
    "\n",
    "    Returns:\n",
    "    - precision: TP / (TP + FP)\n",
    "    - recall: TP / Total Relevant Items\n",
    "    \"\"\"\n",
    "    fp = tp * (recommendations_per_case - 1)  # Each TP has (recommendations_per_case -1) FPs\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / total_cases if total_cases > 0 else 0\n",
    "    return precision, recall\n",
    "total_test_cases = 50\n",
    "# Calculate Precision and Recall for each experiment\n",
    "precision_A, recall_A = calculate_precision_recall(num_true_A, num_true_A+num_false_A)\n",
    "precision_B, recall_B = calculate_precision_recall(num_true_B, num_true_A+num_false_B)\n",
    "precision_C, recall_C = calculate_precision_recall(num_true_C, num_true_A+num_false_C)\n",
    "precision_D, recall_D = calculate_precision_recall(num_true_D, num_true_A+num_false_D)\n",
    "\n",
    "summary_data = {\n",
    "    'Experiment': ['A', 'B', 'C', 'D'],\n",
    "    'Type': [\"LSH/KMEANS/CF\", \"LSH/CF\", \"COSINE\", \"CF\"],\n",
    "    'Queries in top 20': [num_true_A, num_true_B, num_true_C, num_true_D],\n",
    "    'Queries not in top 20': [num_false_A, num_false_B, num_false_C, num_false_D],\n",
    "    'Precision': [precision_A, precision_B, precision_C, precision_D],\n",
    "    'Recall': [recall_A, recall_B, recall_C, recall_D],\n",
    "    'Accuracy (%)': [\n",
    "        (num_true_A / (num_true_A + num_false_A)) * 100,\n",
    "        (num_true_B / (num_true_B + num_false_B)) * 100,\n",
    "        (num_true_C / (num_true_C + num_false_C)) * 100,\n",
    "        (num_true_D / (num_true_D + num_false_D)) * 100\n",
    "    ],\n",
    "    'Average Time (s)': [\n",
    "        total_time_A / 50,\n",
    "        total_time_B / 50,\n",
    "        total_time_C / 50,\n",
    "        total_time_D / 50\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary table\n",
    "print(\"Experiment Summary:\")\n",
    "print(summary_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BIIR Country - Belgian Farmhouse Ale'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(beer_recommendations[\"beer\"] == 'BIIR Country - Belgian Farmhouse Ale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended beers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer</th>\n",
       "      <th>score</th>\n",
       "      <th>abv</th>\n",
       "      <th>LSH_score</th>\n",
       "      <th>LSH_score_weighted</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>collab_score_weighted</th>\n",
       "      <th>abv_diff</th>\n",
       "      <th>abv_weight</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)</td>\n",
       "      <td>0.655155</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.777055</td>\n",
       "      <td>0.660497</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>[orange, oranges, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, fruitiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Insel-Brauerei Insel Saison</td>\n",
       "      <td>0.650174</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.772663</td>\n",
       "      <td>0.656764</td>\n",
       "      <td>-0.005514</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>[orange, tasting, bitter, citrus, sweetness, ale, wine, bitterness, sour, fruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Legenda Brutal Bitter IPA</td>\n",
       "      <td>0.639414</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.756718</td>\n",
       "      <td>0.643210</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>[orange, bitter, citrus, citrusy, sweetness, ipa, alcohol, bitterness, grape, grapefruit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Baden Baden Witbier</td>\n",
       "      <td>0.635766</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.761292</td>\n",
       "      <td>0.647098</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>[orange, oranges, bitter, citrus, sweetness, ale, bitterness, ales, drinkability, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>MONYO American Beauty APA</td>\n",
       "      <td>0.621311</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.737444</td>\n",
       "      <td>0.626828</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>[orange, tasting, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Browar Brodacz MÃ³zg</td>\n",
       "      <td>0.621038</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.735744</td>\n",
       "      <td>0.625382</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>[orange, bitternes, bitter, citrus, citrusy, ale, bitterness, ales, sour, drinkable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Basqueland Saison (Lasai'son)</td>\n",
       "      <td>0.616947</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.622744</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.005763</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, bitterness, beery, aromas, sour, fruit, spicy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>FanÃ¸ Vestkyst</td>\n",
       "      <td>0.616771</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.730639</td>\n",
       "      <td>0.621043</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, ipa, ale, bitterness, grapefruit, fruit, spicy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Kaapse Tess</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.617705</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>[orange, bitter, citrus, sweetness, wine, bitterness, grape, grapefruit, fruitiness, sour]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Orca / Heidenpeters / Ale Mania Head in the Clouds</td>\n",
       "      <td>0.606479</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.742507</td>\n",
       "      <td>0.631131</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>[orange, bitter, citrus, bitterness, grapefruit, sour, lager, phenolic, coffee, freshness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   beer     score  abv  \\\n",
       "639             NÃ¸rrebro Pacific Summer Ale (Ã˜kologisk)  0.655155  5.6   \n",
       "424                         Insel-Brauerei Insel Saison  0.650174  5.5   \n",
       "508                           Legenda Brutal Bitter IPA  0.639414  8.2   \n",
       "82                                  Baden Baden Witbier  0.635766  4.9   \n",
       "529                           MONYO American Beauty APA  0.621311  5.6   \n",
       "161                                 Browar Brodacz MÃ³zg  0.621038  5.7   \n",
       "92                        Basqueland Saison (Lasai'son)  0.616947  5.5   \n",
       "292                                       FanÃ¸ Vestkyst  0.616771  5.7   \n",
       "451                                         Kaapse Tess  0.607172  5.0   \n",
       "653  Orca / Heidenpeters / Ale Mania Head in the Clouds  0.606479  3.9   \n",
       "\n",
       "     LSH_score  LSH_score_weighted  collab_score  collab_score_weighted  \\\n",
       "639   0.777055            0.660497     -0.002144              -0.000322   \n",
       "424   0.772663            0.656764     -0.005514              -0.000827   \n",
       "508   0.756718            0.643210     -0.000722              -0.000108   \n",
       "82    0.761292            0.647098     -0.000240              -0.000036   \n",
       "529   0.737444            0.626828     -0.003306              -0.000496   \n",
       "161   0.735744            0.625382     -0.000103              -0.000015   \n",
       "92    0.732640            0.622744     -0.000227              -0.000034   \n",
       "292   0.730639            0.621043      0.000377               0.000056   \n",
       "451   0.726712            0.617705     -0.001917              -0.000288   \n",
       "653   0.742507            0.631131     -0.000244              -0.000037   \n",
       "\n",
       "     abv_diff  abv_weight  \\\n",
       "639       1.4   -0.005020   \n",
       "424       1.5   -0.005763   \n",
       "508       1.2   -0.003688   \n",
       "82        2.1   -0.011296   \n",
       "529       1.4   -0.005020   \n",
       "161       1.3   -0.004329   \n",
       "92        1.5   -0.005763   \n",
       "292       1.3   -0.004329   \n",
       "451       2.0   -0.010246   \n",
       "653       3.1   -0.024615   \n",
       "\n",
       "                                                                                              notes  \n",
       "639  [orange, oranges, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, fruitiness]  \n",
       "424                [orange, tasting, bitter, citrus, sweetness, ale, wine, bitterness, sour, fruit]  \n",
       "508       [orange, bitter, citrus, citrusy, sweetness, ipa, alcohol, bitterness, grape, grapefruit]  \n",
       "82          [orange, oranges, bitter, citrus, sweetness, ale, bitterness, ales, drinkability, sour]  \n",
       "529        [orange, tasting, bitter, citrus, citrusy, sweetness, ale, bitterness, grapefruit, sour]  \n",
       "161            [orange, bitternes, bitter, citrus, citrusy, ale, bitterness, ales, sour, drinkable]  \n",
       "92               [orange, bitter, citrus, sweetness, bitterness, beery, aromas, sour, fruit, spicy]  \n",
       "292             [orange, bitter, citrus, sweetness, ipa, ale, bitterness, grapefruit, fruit, spicy]  \n",
       "451      [orange, bitter, citrus, sweetness, wine, bitterness, grape, grapefruit, fruitiness, sour]  \n",
       "653      [orange, bitter, citrus, bitterness, grapefruit, sour, lager, phenolic, coffee, freshness]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def recommend_beer(query_embedding, df_train, user_name, abv_desired, n_clusters=15):    \n",
    "    # Query the LSH index\n",
    "    candidates = lsh.query(query_embedding)\n",
    "\n",
    "    # Filter bucket vectors and metadata\n",
    "    bucket_data = df_train[df_train[\"id\"].isin(list(candidates[0]))]\n",
    "    bucket_vectors = np.vstack(bucket_data[\"sbert_embedding\"].to_numpy())\n",
    "    \n",
    "    # Extract subgenre information\n",
    "    subgenres = bucket_data[\"subgenre\"].values  # Adjust column name as necessary\n",
    "    \n",
    "    # Perform clustering on bucket vectors\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(bucket_vectors)\n",
    "    \n",
    "    # Assign query to the nearest cluster\n",
    "    query_cluster = kmeans.predict(query_embedding)[0]\n",
    "    \n",
    "    perplexities = [50]\n",
    "    n_iters = [10000]\n",
    "    learning_rates = [100, 200]\n",
    "    \n",
    "    param_combinations = [(p, n, lr) for p in perplexities for n in n_iters for lr in learning_rates]\n",
    "    \n",
    "    #for perplexity, n_iter, learning_rate in param_combinations:\n",
    "    #    plot_bucket(bucket_vectors, cluster_labels, subgenres, perplexity, n_iter, learning_rate)\n",
    "        \n",
    "    # Filter beers in the same cluster as the query\n",
    "    cluster_indices = np.where(cluster_labels == query_cluster)[0]\n",
    "    cluster_vectors = bucket_vectors[cluster_indices]\n",
    "    cluster_beers = bucket_data.iloc[cluster_indices]\n",
    "    \n",
    "    # Compute similarities within the selected cluster\n",
    "    sims = cosine_similarity(query_embedding, cluster_vectors)[0]\n",
    "\n",
    "    # Perform collaborative filtering\n",
    "    predcicted_rating_user = collab_df.loc[user_name]\n",
    "    \n",
    "    beer_LSH = pd.DataFrame({\n",
    "        'similarity': sims,\n",
    "        'beer': cluster_beers[\"name\"].values,  # Adjust column name if necessary\n",
    "    })\n",
    "    \n",
    "    LSH_score = beer_LSH.groupby('beer')['similarity'].mean()\n",
    "    \n",
    "    collab_filtering_scores = predcicted_rating_user[LSH_score.index.tolist()]\n",
    "    \n",
    "    # Penalise difference in abv by using a nonlinear function penalising greater differences more\n",
    "    abv = beer_info.loc[LSH_score.index.tolist()][\"abv\"]\n",
    "\n",
    "    alpha = 0.05\n",
    "    if abv_desired == 0:\n",
    "        abv_weight = -2 * abs(abv - abv_desired)\n",
    "    else:\n",
    "        abv_weight = -alpha * ((abv - abv_desired)**2) / (abv_desired**1.5 + 1)\n",
    "    \n",
    "\n",
    "    # Combine weights and scores\n",
    "    weighted_score = (\n",
    "        0.85 * LSH_score +\n",
    "        0.15 * collab_filtering_scores +\n",
    "        abv_weight\n",
    "    )\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    beer_weighted_score = pd.DataFrame({\n",
    "        'beer': LSH_score.index,\n",
    "        'score': weighted_score,\n",
    "        'abv': abv.values,\n",
    "        'LSH_score': LSH_score.values,\n",
    "        'LSH_score_weighted': LSH_score.values * 0.85,\n",
    "        'collab_score': collab_filtering_scores.values,\n",
    "        'collab_score_weighted': collab_filtering_scores.values * 0.15,\n",
    "        'abv_diff': abs(abv.values - abv_desired),\n",
    "        'abv_weight': abv_weight.values\n",
    "    })\n",
    "    \n",
    "    # Remove index of weighted score and keep the beer name as a column\n",
    "    beer_weighted_score.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Get the 10 beers with the highest weighted scores\n",
    "    beer_weighted_score = beer_weighted_score.sort_values(by='score', ascending=False).head(10)\n",
    "    \n",
    "    # Apply getThemes to each beer in the DataFrame\n",
    "    beer_weighted_score['notes'] = beer_weighted_score['beer'].apply(lambda x: getThemes(df_train, x, query_embedding))\n",
    "\n",
    "\n",
    "    return beer_weighted_score.sort_values(by='score', ascending=False)\n",
    "    \n",
    "\n",
    "# Create a query\n",
    "test_query = \"Light, refreshing bitter beer with a orange taste\"\n",
    "user_name = \"Jerseyislandbeer\"\n",
    "query_embedding = encode_sbert(test_query).reshape(1, -1)\n",
    "beer_recommendations= recommend_beer(query_embedding, df_train, user_name, 7)\n",
    "\n",
    "print(\"Top 5 recommended beers:\")\n",
    "# Set max column width to display full array\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(beer_recommendations.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for improvement\n",
    "Add better stop-words, flavor, flavour, flavors etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation settup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
