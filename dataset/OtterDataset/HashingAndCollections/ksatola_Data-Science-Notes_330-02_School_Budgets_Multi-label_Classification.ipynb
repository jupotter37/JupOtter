{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School Budgets: Use Data to Have a Social Impact\n",
    "\n",
    "Data science isn't just for predicting ad-clicks-it's also useful for social impact! This course is a case study from a machine learning competition on DrivenData. You'll explore a problem related to school district budgeting. By **building a model to automatically classify items in a school's budget**, it makes it easier and faster for schools to compare their spending with other schools. In this course, you'll begin by building a baseline model that is a simple, first-pass approach. In particular, you'll do some **natural language processing** to prepare the budgets for modeling. Next, you'll have the opportunity to try your own techniques and see how they compare to participants from the competition. Finally, you'll see how the winner was able to combine a number of expert techniques to build the most accurate model.\n",
    "\n",
    "You're going to be working with school district budget data. This data can be classified in many ways according to certain labels, e.g. Function: Career & Academic Counseling, or Position_Type: Librarian.\n",
    "\n",
    "Your goal is to develop a model that predicts the probability for each possible label by relying on some correctly labeled examples. We have ourselves a **multi-class-multi-label classification problem**, because there are 9 broad categories that each take on many possible sub-label instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Now it's time to check out the dataset! You'll use pandas (which has been pre-imported as pd) to load your data into a DataFrame and then do some **Exploratory Data Analysis (EDA)** of it.\n",
    "\n",
    "The training data is available as `TrainingData.csv`. Your first task is to load it into a DataFrame using `pd.read_csv()` along with the keyword argument `index_col=0`.\n",
    "\n",
    "Use methods such as `.info()`, `.head()`, and `.tail()` to explore the budget data and the properties of the features and labels.\n",
    "\n",
    "Some of the column names correspond to features - descriptions of the budget items - such as the `Job_Title_Description column`. The values in this column tell us if a budget item is for a teacher, custodian, or other employee.\n",
    "\n",
    "Some columns correspond to the budget item labels you will be trying to predict with your model. For example, the `Object_Type` column describes whether the budget item is related classroom supplies, salary, travel expenses, etc.\n",
    "\n",
    "Use `df.info()` to answer the following questions:\n",
    "\n",
    "- How many rows are there in the training data?\n",
    "- How many columns are there in the training data?\n",
    "- How many non-null entries are in the `Job_Title_Description` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'data/dc19/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplemental *</td>\n",
       "      <td>...</td>\n",
       "      <td>Non-Certificated Salaries And Wages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Care and Upkeep of Building Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I CARRYOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Student Transportation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Other Non-Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>REPAIR AND MAINTENANCE SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMIN. SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDENT TRANSPORT SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618.29</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>49768.82</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>...</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplies and Materials</td>\n",
       "      <td>...</td>\n",
       "      <td>Supplies And Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Community Services *</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2304.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I PI+HOMELESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Function          Use          Sharing   Reporting  \\\n",
       "198                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "209   Student Transportation     NO_LABEL  Shared Services  Non-School   \n",
       "750     Teacher Compensation  Instruction  School Reported      School   \n",
       "931                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "1524                NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "\n",
       "     Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "198      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "209      NO_LABEL      NO_LABEL    Other Non-Compensation  NO_LABEL   \n",
       "750   Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "931      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "1524     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "\n",
       "       Operating_Status               Object_Description  \\\n",
       "198       Non-Operating                   Supplemental *   \n",
       "209   PreK-12 Operating  REPAIR AND MAINTENANCE SERVICES   \n",
       "750   PreK-12 Operating     Personal Services - Teachers   \n",
       "931       Non-Operating                 General Supplies   \n",
       "1524      Non-Operating           Supplies and Materials   \n",
       "\n",
       "              ...                        Sub_Object_Description  \\\n",
       "198           ...           Non-Certificated Salaries And Wages   \n",
       "209           ...                                           NaN   \n",
       "750           ...                                           NaN   \n",
       "931           ...                              General Supplies   \n",
       "1524          ...                        Supplies And Materials   \n",
       "\n",
       "     Location_Description  FTE                  Function_Description  \\\n",
       "198                   NaN  NaN  Care and Upkeep of Building Services   \n",
       "209       ADMIN. SERVICES  NaN             STUDENT TRANSPORT SERVICE   \n",
       "750                   NaN  1.0                                   NaN   \n",
       "931                   NaN  NaN                           Instruction   \n",
       "1524                  NaN  NaN            Other Community Services *   \n",
       "\n",
       "          Facility_or_Department Position_Extra     Total  \\\n",
       "198                          NaN            NaN  -8291.86   \n",
       "209                          NaN            NaN    618.29   \n",
       "750                          NaN        TEACHER  49768.82   \n",
       "931   Instruction And Curriculum            NaN     -1.02   \n",
       "1524                         NaN            NaN   2304.43   \n",
       "\n",
       "                                    Program_Description  \\\n",
       "198                                                 NaN   \n",
       "209                                PUPIL TRANSPORTATION   \n",
       "750                               Instruction - Regular   \n",
       "931   \"Title I, Part A Schoolwide Activities Related...   \n",
       "1524                                                NaN   \n",
       "\n",
       "                                       Fund_Description                Text_1  \n",
       "198   Title I - Disadvantaged Children/Targeted Assi...    TITLE I CARRYOVER   \n",
       "209                                        General Fund                   NaN  \n",
       "750                              General Purpose School                   NaN  \n",
       "931                              General Operating Fund                   NaN  \n",
       "1524  Title I - Disadvantaged Children/Targeted Assi...   TITLE I PI+HOMELESS  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'TrainingData.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344986</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>27.04000</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384803</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERSONNEL-PAID LEAVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAFF SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224382</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Special Education</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>OTHER PERSONAL SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>School</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EXCEPTIONAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.39000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305347</th>\n",
       "      <td>Facilities &amp; Maintenance</td>\n",
       "      <td>O&amp;M</td>\n",
       "      <td>Leadership &amp; Management</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>Gifted</td>\n",
       "      <td>Custodian</td>\n",
       "      <td>Other Compensation/Stipend</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Extra Duty Pay/Overtime For Support Personnel</td>\n",
       "      <td>...</td>\n",
       "      <td>Extra Duty Pay/Overtime For Support Personnel</td>\n",
       "      <td>Unallocated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Facilities Maintenance And Operations</td>\n",
       "      <td>Gifted And Talented</td>\n",
       "      <td>ANY CUS WHO IS NOT A SUPER</td>\n",
       "      <td>5.29000</td>\n",
       "      <td>Gifted And Talented</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>ADDL REGULAR PAY-NOT SMOOTHED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101861</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Poverty</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF REGULAR EMPLOYEES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TITLE I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>1575.03504</td>\n",
       "      <td>GENERAL ELEMENTARY EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Function          Use                  Sharing  \\\n",
       "344986   Substitute Compensation  Instruction          School Reported   \n",
       "384803                  NO_LABEL     NO_LABEL                 NO_LABEL   \n",
       "224382   Substitute Compensation  Instruction          School Reported   \n",
       "305347  Facilities & Maintenance          O&M  Leadership & Management   \n",
       "101861      Teacher Compensation  Instruction          School Reported   \n",
       "\n",
       "         Reporting       Student_Type Position_Type  \\\n",
       "344986      School        Unspecified    Substitute   \n",
       "384803    NO_LABEL           NO_LABEL      NO_LABEL   \n",
       "224382      School  Special Education    Substitute   \n",
       "305347  Non-School             Gifted     Custodian   \n",
       "101861      School            Poverty       Teacher   \n",
       "\n",
       "                       Object_Type     Pre_K   Operating_Status  \\\n",
       "344986                    Benefits  NO_LABEL  PreK-12 Operating   \n",
       "384803                    NO_LABEL  NO_LABEL      Non-Operating   \n",
       "224382     Substitute Compensation  NO_LABEL  PreK-12 Operating   \n",
       "305347  Other Compensation/Stipend  Non PreK  PreK-12 Operating   \n",
       "101861    Base Salary/Compensation  NO_LABEL  PreK-12 Operating   \n",
       "\n",
       "                                   Object_Description  \\\n",
       "344986                              EMPLOYEE BENEFITS   \n",
       "384803                              EMPLOYEE BENEFITS   \n",
       "224382                 OTHER PERSONAL SERVICES          \n",
       "305347  Extra Duty Pay/Overtime For Support Personnel   \n",
       "101861                  SALARIES OF REGULAR EMPLOYEES   \n",
       "\n",
       "                    ...                \\\n",
       "344986              ...                 \n",
       "384803              ...                 \n",
       "224382              ...                 \n",
       "305347              ...                 \n",
       "101861              ...                 \n",
       "\n",
       "                               Sub_Object_Description  Location_Description  \\\n",
       "344986                                            NaN                   NaN   \n",
       "384803                                            NaN  PERSONNEL-PAID LEAVE   \n",
       "224382                                            NaN               School    \n",
       "305347  Extra Duty Pay/Overtime For Support Personnel           Unallocated   \n",
       "101861                                            NaN                   NaN   \n",
       "\n",
       "        FTE                   Function_Description Facility_or_Department  \\\n",
       "344986  NaN                UNALLOC BUDGETS/SCHOOLS                    NaN   \n",
       "384803  NaN                            NON-PROJECT                    NaN   \n",
       "224382  0.0         EXCEPTIONAL                                       NaN   \n",
       "305347  NaN  Facilities Maintenance And Operations    Gifted And Talented   \n",
       "101861  NaN                                TITLE I                    NaN   \n",
       "\n",
       "                     Position_Extra       Total  \\\n",
       "344986   PROFESSIONAL-INSTRUCTIONAL    27.04000   \n",
       "384803   PROFESSIONAL-INSTRUCTIONAL         NaN   \n",
       "224382                          NaN   200.39000   \n",
       "305347  ANY CUS WHO IS NOT A SUPER      5.29000   \n",
       "101861   PROFESSIONAL-INSTRUCTIONAL  1575.03504   \n",
       "\n",
       "                  Program_Description                Fund_Description  \\\n",
       "344986  GENERAL HIGH SCHOOL EDUCATION                             NaN   \n",
       "384803                 STAFF SERVICES                             NaN   \n",
       "224382                            NaN  GENERAL FUND                     \n",
       "305347            Gifted And Talented          General Operating Fund   \n",
       "101861   GENERAL ELEMENTARY EDUCATION                             NaN   \n",
       "\n",
       "                               Text_1  \n",
       "344986            REGULAR INSTRUCTION  \n",
       "384803                        CENTRAL  \n",
       "224382                            NaN  \n",
       "305347  ADDL REGULAR PAY-NOT SMOOTHED  \n",
       "101861            REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1560 entries, 198 to 101861\n",
      "Data columns (total 25 columns):\n",
      "Function                  1560 non-null object\n",
      "Use                       1560 non-null object\n",
      "Sharing                   1560 non-null object\n",
      "Reporting                 1560 non-null object\n",
      "Student_Type              1560 non-null object\n",
      "Position_Type             1560 non-null object\n",
      "Object_Type               1560 non-null object\n",
      "Pre_K                     1560 non-null object\n",
      "Operating_Status          1560 non-null object\n",
      "Object_Description        1461 non-null object\n",
      "Text_2                    382 non-null object\n",
      "SubFund_Description       1183 non-null object\n",
      "Job_Title_Description     1131 non-null object\n",
      "Text_3                    296 non-null object\n",
      "Text_4                    193 non-null object\n",
      "Sub_Object_Description    364 non-null object\n",
      "Location_Description      874 non-null object\n",
      "FTE                       449 non-null float64\n",
      "Function_Description      1340 non-null object\n",
      "Facility_or_Department    252 non-null object\n",
      "Position_Extra            1026 non-null object\n",
      "Total                     1542 non-null float64\n",
      "Program_Description       1192 non-null object\n",
      "Fund_Description          819 non-null object\n",
      "Text_1                    1132 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 316.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the data\n",
    "\n",
    "You'll continue your EDA in this exercise by computing **summary statistics** for the numeric data in the dataset. The data has been pre-loaded into a DataFrame called df.\n",
    "\n",
    "You can use `df.info()` to determine which columns of the data are numeric, specifically type float64. You'll notice that there are two numeric columns, called `FTE` and `Total`.\n",
    "\n",
    "`FTE`: Stands for `\"full-time equivalent\"`. If the budget item is associated to an employee, this number tells us the percentage of full-time that the employee works. A value of 1 means the associated employee works for the school full-time. A value close to 0 means the item is associated to a part-time or contracted employee.\n",
    "`Total`: Stands for the `total cost of the expenditure`. This number tells us how much the budget item cost.\n",
    "\n",
    "After printing **summary statistics** for the numeric data, your job is to plot a histogram of the non-null FTE column to see the distribution of part-time and full-time employees in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              FTE         Total\n",
      "count  449.000000  1.542000e+03\n",
      "mean     0.493532  1.446867e+04\n",
      "std      0.452844  7.916752e+04\n",
      "min     -0.002369 -1.044084e+06\n",
      "25%      0.004310  1.108111e+02\n",
      "50%      0.440000  7.060299e+02\n",
      "75%      1.000000  5.347760e+03\n",
      "max      1.047222  1.367500e+06\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcHVWZ//HPlwRB9iUNEwIhBAGNiEFbBRUFQdkUFNky7KIBBR0FFxBGUOE3jAqoP0QMQwhrWIchIKgIBBAFSQRC2CSEQEIyJCQSwiIQeOaPcy7cXKrT1ctduvv7fr3q1beWW/XU7eQ+fU5VPUcRgZmZWa0Vmh2AmZm1JicIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjAzs0JOENZrJJ0j6d97aV/DJb0gaVCenyzpy72x77y/GyUd0lv768JxT5H0rKT/7YV9bSHpXklLJH2jxPYh6V359QRJp3ThWMv8PmxgcIKwUiTNkvRy/jJ6TtKfJR0p6c1/QxFxZET8uOS+dlreNhHxVESsFhGv90LsJ0u6uGb/u0bEBT3ddxfj2Ag4FhgVEf9StF7SXZIWSTq9Zt3vJLXXvOW7wOSIWD0iftnLsS7zO+rN34f1HU4Q1hWfi4jVgY2B04DvAef19kEkDe7tfbaIjYGFETG/g/XHAxcAmwCfryQESfsBMyNiSsH+HqxXsGZOENZlEbE4IiYB+wGHSNoSlu22kDRE0vW5tbFI0h2SVpB0ETAcuC53WXxX0ojc/XG4pKeAW6qWVSeLTSX9VdJiSddKWicfa3tJc6pjrPwFLGkX4PvAfvl49+f1b3ZZ5bhOlPSkpPmSLpS0Zl5XieMQSU/l7qETOvpsJK2Z378g7+/EvP+dgJuADXIcEwrevglwS0QsBu4BRkpaAzgun0P1cW4BdgDOyvvbvLYbTtKhkv60nF9lR+ewvN/R4KrP75TcknxB0nWS1pV0iaTnJd0jaUTVPt8t6ab8b+FRSft2NS5rPCcI67aI+CswB9iuYPWxeV0bsD7pCy4i4iDgKVJrZLWI+EnVez4JvAfYuYNDHgx8CdgAWAp02q0SEb8D/h9weT7e+ws2OzRPOwAjgdWAs2q2+TiwBbAj8ANJ7+ngkP8fWDPv55M55sMi4o/ArsDcHMehBe+dDnxa0lpAO/AQ8GPg5xHxXM15fQq4Azg67+/vHX4IXdTJ76ja/sBBwDBgU+AvwPnAOsDDwEkAklYlJcdLgfWAMcDZkt7bWzFbfThBWE/NJX0h1HoNGApsHBGvRcQd0Xnhr5Mj4sWIeLmD9RdFxPSIeBH4d2DfXrpoegBwRkTMjIgXSF09+9e0Xn4YES9HxP3A/cDbEk2OZT/g+IhYEhGzgNNJX6Jl/Acp2d4G/ApYEdiK9Jf8pZJul3R0906xLs6PiMdzi+dG4PGI+GNELAWuBLbO230WmBUR50fE0oj4G3A1sHdzwraynCCsp4YBiwqW/xSYAfxB0kxJx5XY1+wurH+S9AU6pFSUy7dB3l/1vgeTWj4V1XcdvURqZdQaAryjYF/DygQREYsiYr/cyvkFqTXydVIX03RgJ+BISaPK7K8spTu6XsjTAV146zNVr18umK98RhsDH8ndjc9Jeo6UlN92od5aS3+9GGgNIOlDpC+/t/VzR8QSUjfTsbkr4VZJ90TEzUBHLYnOWhgbVb0eTmqlPAu8CKxSFdcgUtdW2f3OJX2JVe97KekLb8NO3lvt2RzTxqTuocq+nu7CPirGAndFxHRJ7wPOjIhXJT0AbFm1/2rLfA6U/AKOiF2LFnc14OWYDdwWEZ/uxX1aA7gFYV0maQ1JnwUuAy6OiAcKtvmspHdJEvA88HqeIH3xjuzGoQ+UNErSKsCPgKvybZd/B1aWtLukFYETgZWq3vcMMEJVt+TWmAh8S9ImklbjrWsWS7sSXI7lCuBUSatL2hg4Brh4+e9clqT1gKOAk/OiJ4AdcmztwMwO3nofsJekVZSedzi8K8et0d3fUZHrgc0lHSRpxTx9aDnXcaxFOEFYV1wnaQnpL8ITgDOAwzrYdjPgj8ALpIuXZ0fE5LzuP4ATc3fDt7tw/IuACaTunpWBb0C6qwr4GvBfpL/WXyRdIK+4Mv9cKOlvBfsdn/d9O+nL+J+krp3u+Ho+/kxSy+rSvP+u+Bnwo3w9BNLn9SnS5z6p4HbXijOBV0lf7hcAl3TxuNW6+zt6m9ya/AzpovZc0u/vP1k2iVsLkgcMMjOzIm5BmJlZIScIMzMr5ARhZmaFnCDMzKyQE4QZxfWc+qvamk1mHXGCMDOzQn6S2myAyA8tqtlxWN/hFoS1tOWViVYqL352VS2hOyX9i6SfS/qHpEckbV21/SxJx0t6KK8/X9LKHRz3Pbkr5jlJD0raIy//kKRnqgv5SfqipPvy6xUkHSfpcUkLJV2hXJY8r98ml8h+TtL9krbv4PiHSbquan6GpCuq5mdLGp1ffzSX116cf360arvJkk6VdCephtTImuMMlTSt8jCcUonwmUoDQz3RxdpM1t9EhCdPLTkBq5KeHj6M1Nr9AKne0Xvz+gl5/oOkJ6tvIT0JfTAwCDgFuLVqf7NIRe82IlWgvRM4Ja/bHpiTX69IKjT4fVLxvU8BS4At8vqHgF2r9nsNcGx+/U3gLlINp5WA3wAT87phwEJgN9IfZ5/O820F5z4SeC5vN5RU9O/pqnX/yOvWya8Pyp/RmDy/bt52Mql093vz+hXzsi8DI0hlSsZWfd7PV53n0Mpn7WlgTm5BWCsrUyb6moiYGhH/JH1R/zMiLoxUF+ly3io5XXFWRMyOiEXAqaQv1FrbkCqRnhYRr0bELaR6QpVtLwAOBMitg51JJTUAjgBOiIg5EfEKqZ7S3rnFcSBwQ0TcEBFvRMRNwBRSwlhGRMwkJaXRpHElfg88Lendef6OiHgD2B14LCIuyp/RROAR4HNVu5sQEQ/m9a/lZaNIieKkiBhXte0bwJaS3hkR8yLCI9YNYL4GYa3szTLRVcsGk+omVZQtOV1RWzJ8g4LjbgDMzl/A1dtWynZfDDyci+ftS/qynlcV8zWSqt/7Oql0+MbAPpKqv7xXBG4tiAHSuBDbA+/Kr58jJYdt83wl1idr3ldbYryojPoBpFbSVZUFEfGi0vCm3wbOy91Sx0bEIx3EZ/2cWxDWyiploteqmlaLiK/2YJ+1JcPnFmwzF9iopvrrm2W7I+JpUgHCL5C6dqoT1mxS91N1zCvn98wmDXpUvW7ViDitg1grCaIyiNBtpATxSd5KELWlypeJNSsquHYyqXvuUlUNuhQRv49UlnsoqSVybgex2QDgBGGtrB5loo+StGHuGvo+qRuq1t2kiqzfzcfcntRlc1nVNhcC3wXeR+raqjiHVO57YwBJbZL2zOsuBj4naWdJgyStnJ+/6GjMidtIw6C+MyLmkIYY3QVYF7g3b3MD6TP6V0mDcwtgFOmzW57XgH1I1x0uyhfX15e0h9IQoa+QKvG+vrydWP/mBGEtK+pTJvpS4A+kctwzSReya4/7KrAHaQzpZ4GzgYNrulquIXcnRRoCteIXwCTSSHpLSBesP5L3OxvYk5SYFpBaFN+hg/+HkcaZfoGUGIiI53PMd+ZrLETEQtK1mmNJF7y/C3w2Ip7t7IPI57kXaZzo8aTuu2NJn/UiUkvla53tx/ovl/u2AUPSLODLEfHHXtrf48ARvbU/s1bjFoRZN0j6Iqlv/5Zmx2JWL76LyayLJE0m9fMfVHOnk1m/4i4mMzMr5C4mMzMr1Ke7mIYMGRIjRoxodhhmZn3K1KlTn42Its6269MJYsSIEUyZMqXZYZiZ9SmSap++L+QuJjMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlaobglC0nhJ8yVNr1p2uaT78jSrahzfEZJerlp3Tr3iMjOzcur5HMQE4CxS3XwAImK/ymtJpwOLq7Z/PCJG1zEeMzPrgroliIi4XdKIonWSRBqq8VP1Or6ZmfVMs56k3g54JiIeq1q2iaR7geeBEyPijqI3ShoLjAUYPnx43QM1M+vIiON+27Rjzzpt97ofo1kXqccAE6vm5wHDI2Jr4BjSOLlrFL0xIsZFRHtEtLe1dVpKxMzMuqnhLQhJg0nDHH6wsiwiXiGNgUtETM0jdW0O1LXQUrOyfyMyv5lZTzWjBbET8EgehB14c2D3Qfn1SGAz0ti7ZmbWJPW8zXUi8BdgC0lzJB2eV+3Pst1LAJ8Apkm6H7gKODIiFtUrNjMz61w972Ia08HyQwuWXQ1cXa9YzMys6/wktZmZFXKCMDOzQk4QZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZWyAnCzMwK1S1BSBovab6k6VXLTpb0tKT78rRb1brjJc2Q9KiknesVl5mZlVPPFsQEYJeC5WdGxOg83QAgaRSwP/De/J6zJQ2qY2xmZtaJuiWIiLgdWFRy8z2ByyLilYh4ApgBfLhesZmZWeeacQ3iaEnTchfU2nnZMGB21TZz8rK3kTRW0hRJUxYsWFDvWM3MBqxGJ4hfA5sCo4F5wOl5uQq2jaIdRMS4iGiPiPa2trb6RGlmZo1NEBHxTES8HhFvAOfyVjfSHGCjqk03BOY2MjYzM1tWQxOEpKFVs18AKnc4TQL2l7SSpE2AzYC/NjI2MzNb1uB67VjSRGB7YIikOcBJwPaSRpO6j2YBRwBExIOSrgAeApYCR0XE6/WKzczMOle3BBERYwoWn7ec7U8FTq1XPGZm1jV+ktrMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMysUN0ShKTxkuZLml617KeSHpE0TdI1ktbKy0dIelnSfXk6p15xmZlZOfVsQUwAdqlZdhOwZURsBfwdOL5q3eMRMTpPR9YxLjMzK6FuCSIibgcW1Sz7Q0QszbN3ARvW6/hmZtYzzbwG8SXgxqr5TSTdK+k2Sdt19CZJYyVNkTRlwYIF9Y/SzGyA6lKCkLS2pK16elBJJwBLgUvyonnA8IjYGjgGuFTSGkXvjYhxEdEeEe1tbW09DcXMzDrQaYKQNFnSGpLWAe4Hzpd0RncPKOkQ4LPAARERABHxSkQszK+nAo8Dm3f3GGZm1nNlWhBrRsTzwF7A+RHxQWCn7hxM0i7A94A9IuKlquVtkgbl1yOBzYCZ3TmGmZn1jjIJYrCkocC+wPVldyxpIvAXYAtJcyQdDpwFrA7cVHM76yeAaZLuB64CjoyIRYU7NjOzhhhcYpsfAb8H7oyIe/Jf+I919qaIGFOw+LwOtr0auLpELGZm1iCdJoiIuBK4smp+JvDFegZlZmbNV+Yi9eaSbq48ES1pK0kn1j80MzNrpjLXIM4lPfH8GkBETAP2r2dQZmbWfGUSxCoR8deaZUsLtzQzs36jTIJ4VtKmQABI2pv0YJuZmfVjZe5iOgoYB7xb0tPAE8CBdY3KzMyarsxdTDOBnSStCqwQEUvqH5aZmTVbmbuY1pd0HnBVRCyRNCo/9GZmZv1YmWsQE0gPym2Q5/8OfLNeAZmZWWsokyCGRMQVwBsAeTyH1+salZmZNV2ZBPGipHV56y6mbYDFdY3KzMyarsxdTMcCk4BNJd0JtAF71zUqMzNrujJ3MU2V9ElgC0DAoxHxWt0jMzOzpipzF9MUYCwwNyKmOzmYmQ0MZa5B7A8MA+6RdJmknSWpznGZmVmTdZogImJGRJxAGgL0UmA88JSkH+ZhSM3MrB8q04JA0lbA6cBPSQP77A08D9xSv9DMzKyZOr1ILWkq8BxpNLjjIuKVvOpuSR+rZ3BmZtY8ZW5z3SfXY3qbiNirl+MxM7MWUaaLaaGkMyRNydPpktase2RmZtZUZRLEeGAJsG+engfOL7NzSeMlza8MV5qXrSPpJkmP5Z9r5+WS9EtJMyRNk/SBrp+OmZn1ljIJYtOIOCkiZubph8DIkvufAOxSs+w44OaI2Ay4Oc8D7ApslqexwK9LHsPMzOqgTIJ4WdLHKzP5wvTLZXYeEbcDi2oW7wlckF9fAHy+avmFkdwFrCVpaJnjmJlZ7ytzkfqrwAX5uoNIX/iH9uCY60fEPICImCdpvbx8GDC7ars5edkyw5tKGktqYTB8+PAehGFmZstTphbTfcD7Ja2R55+vUyxFT2dHQTzjSEOg0t7e/rb1ZmbWOzpMEJKO6WA5ABFxRjeP+Yykobn1MBSYn5fPATaq2m5DYG43j2FmZj20vGsQq3cyddck4JD8+hDg2qrlB+e7mbYBFle6oszMrPE6bEHku5V6RNJEYHtgiKQ5wEnAacAVeVzrp4B98uY3ALsBM4CXgMN6enwzM+u+MqU2RgK/ALYhXRP4C/Ctjp6urhYRYzpYtWPBtgEc1dk+zcysMcrc5nopcAUwFNgAuBKYWM+gzMys+cokCEXERRGxNE8XU3B3kZmZ9S9lnoO4VdJxwGWkxLAf8NvKWBARUfsgnJmZ9QNlEsR++ecRNcu/REoYZctumJlZH1LmQblNGhGImZm1ljJ3MQ0CdgdGVG/fgwflzMysDyjTxXQd8E/gAeCN+oZjZmatokyC2DAitqp7JGZm1lLK3OZ6o6TP1D0SMzNrKWVaEHcB10haAXiNVHU1ImKNukZmZmZNVSZBnA5sCzyQy2GYmdkAUKaL6TFgupODmdnAUqYFMQ+YLOlG4JXKQt/mambWv5VJEE/k6R15MjOzAaDMk9Q/BJC0akS8WP+QzMysFXR6DULStpIeAh7O8++XdHbdIzMzs6Yqc5H658DOwEKAiLgf+EQ9gzIzs+YrkyCIiNk1i16vQyxmZtZCylykni3po0BIegfwDXJ3k5mZ9V9lWhBHksaKHgbMAUbjsaPNzPq9MncxPQsc0IBYzMyshZTpYupVkrYALq9aNBL4AbAW8BVgQV7+/Yi4ocHhmZlZ1vAEERGPkrqpKoMRPQ1cAxwGnBkRP2t0TGZm9nal7mKqox2BxyPiySbHYWZmNcoMOboWcDBvH3L0G71w/P2BiVXzR0s6GJgCHBsR/yiIZywwFmD48OG9EIKZmRUp04K4gZQcHgCmVk09km+Z3QO4Mi/6NbApqftpHqnM+NtExLiIaI+I9ra2tp6GYWZmHShzDWLliDimDsfeFfhbRDwDUPkJIOlc4Po6HNPMzEoq04K4SNJXJA2VtE5l6oVjj6Gqe0nS0Kp1XwCm98IxzMysm8q0IF4FfgqcAFQGDQrS7andImkV4NPAEVWLfyJpdN73rJp1ZmbWYGUSxDHAu/IDc70iIl4C1q1ZdlBv7d/MzHquTBfTg8BL9Q7EzMxaS5kWxOvAfZJuZdkhR3vjNlczM2tRZRLE/+TJzMwGkDLF+i5oRCBmZtZayjxJ/QRv3b30pojo9l1MZmbW+sp0MbVXvV4Z2AfojecgzMyshXV6F1NELKyano6InwOfakBsZmbWRGW6mD5QNbsCqUWxet0iMjOzllCmi6m6aN5S0lPO+9YlGjMzaxll7mLaoRGBmJlZaynTxbQS8EXePh7Ej+oXlpmZNVuZLqZrgcWkMSBe6WRbMzPrJ8okiA0jYpe6R2JmZi2lTLG+P0t6X90jMTOzllKmBfFx4ND8RPUrgICIiK3qGpmZmTVVmQSxa92jMDOzllPmNtcnGxGImZm1ljLXIMzMbABygjAzs0JOEGZmVqjMReq6kDQLWEIa0nRpRLRLWge4nPTU9ixg34j4R7NiNDMbyJrdgtghIkZHRGXMieOAmyNiM+DmPG9mZk3Q7ARRa0+gMsTpBcDnmxiLmdmA1swEEcAfJE2VNDYvWz8i5gHkn+s1LTozswGuadcggI9FxFxJ6wE3SXqkzJtyMhkLMHz48HrGZ2Y2oDWtBRERc/PP+cA1wIeBZyQNBcg/5xe8b1xEtEdEe1tbWyNDNjMbUJqSICStKmn1ymvgM8B0YBJwSN7sEFKpcTMza4JmdTGtD1wjqRLDpRHxO0n3AFdIOhx4CtinSfGZmQ14TUkQETETeH/B8oXAjo2PyMzMarXaba5mZtYinCDMzKyQE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBmJlZIScIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBmJlZIScIMzMr5ARhZmaFnCDMzKxQs8akHtBGHPfbphx31mm7N+W4ZtY3uQVhZmaFnCDMzKxQwxOEpI0k3SrpYUkPSvq3vPxkSU9Lui9PuzU6NjMze0szrkEsBY6NiL9JWh2YKummvO7MiPhZE2IyM7MaDU8QETEPmJdfL5H0MDCs0XGYmdnyNfUahKQRwNbA3XnR0ZKmSRovae0O3jNW0hRJUxYsWNCgSM3MBp6mJQhJqwFXA9+MiOeBXwObAqNJLYzTi94XEeMioj0i2tva2hoWr5nZQNOUBCFpRVJyuCQi/hsgIp6JiNcj4g3gXODDzYjNzMySZtzFJOA84OGIOKNq+dCqzb4ATG90bGZm9pZm3MX0MeAg4AFJ9+Vl3wfGSBoNBDALOKIJsZmZWdaMu5j+BKhg1Q2NjsX6v2aVNQGXNrG+z09Sm5lZIScIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBmJlZIScIMzMr1IxaTGZmvaqZJVX6MyeIAcR1icysK9zFZGZmhZwgzMyskLuYzPoZdyVab3ELwszMCrkFYQ3hu0wGBv+e+xe3IMzMrJBbEGZ14r+mra9zC8LMzAo5QZiZWaGWSxCSdpH0qKQZko5rdjxmZgNVSyUISYOAXwG7AqOAMZJGNTcqM7OBqaUSBPBhYEZEzIyIV4HLgD2bHJOZ2YDUancxDQNmV83PAT5SvYGkscDYPPuCpEd7cLwhwLM9eH9f4fPsX3ye/Uu3zlP/2aNjblxmo1ZLECpYFsvMRIwDxvXKwaQpEdHeG/tqZT7P/sXn2b+08nm2WhfTHGCjqvkNgblNisXMbEBrtQRxD7CZpE0kvQPYH5jU5JjMzAaklupiioilko4Gfg8MAsZHxIN1PGSvdFX1AT7P/sXn2b+07HkqIjrfyszMBpxW62IyM7MW4QRhZmaFBkSC6Kx8h6SVJF2e198taUTjo+y5Eud5jKSHJE2TdLOkUvdCt5qy5Vgk7S0pJLXkLYSdKXOekvbNv9MHJV3a6Bh7Q4l/t8Ml3Srp3vxvd7dmxNkTksZLmi9pegfrJemX+TOYJukDjY6xUET064l0sftxYCTwDuB+YFTNNl8Dzsmv9wcub3bcdTrPHYBV8uuv9tfzzNutDtwO3AW0NzvuOv0+NwPuBdbO8+s1O+46nec44Kv59ShgVrPj7sZ5fgL4ADC9g/W7ATeSngXbBri72TFHxIBoQZQp37EncEF+fRWwo6Sih/ZaWafnGRG3RsRLefYu0nMmfU3Zciw/Bn4C/LORwfWiMuf5FeBXEfEPgIiY3+AYe0OZ8wxgjfx6Tfrgs1ERcTuwaDmb7AlcGMldwFqShjYmuo4NhARRVL5jWEfbRMRSYDGwbkOi6z1lzrPa4aS/WPqaTs9T0tbARhFxfSMD62Vlfp+bA5tLulPSXZJ2aVh0vafMeZ4MHChpDnAD8PXGhNZQXf3/2xAt9RxEnXRavqPkNq2u9DlIOhBoBz5Z14jqY7nnKWkF4Ezg0EYFVCdlfp+DSd1M25Nag3dI2jIinqtzbL2pzHmOASZExOmStgUuyuf5Rv3Da5iW/A4aCC2IMuU73txG0mBSM3Z5zcFWVKpMiaSdgBOAPSLilQbF1ps6O8/VgS2ByZJmkfpzJ/XBC9Vl/91eGxGvRcQTwKOkhNGXlDnPw4ErACLiL8DKpAJ3/UlLlhkaCAmiTPmOScAh+fXewC2Rrxz1IZ2eZ+56+Q0pOfTF/mro5DwjYnFEDImIERExgnStZY+ImNKccLutzL/b/yHdeICkIaQup5kNjbLnypznU8COAJLeQ0oQCxoaZf1NAg7OdzNtAyyOiHnNDqrfdzFFB+U7JP0ImBIRk4DzSM3WGaSWw/7Ni7h7Sp7nT4HVgCvzNfinImKPpgXdDSXPs88reZ6/Bz4j6SHgdeA7EbGweVF3XcnzPBY4V9K3SN0uh/a1P+AkTSR1BQ7J11JOAlYEiIhzSNdWdgNmAC8BhzUn0mW51IaZmRUaCF1MZmbWDU4QZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGH9jqQ2SX+SNF3S56uWXytpg27s6+5cSXS7mnXb5Sqq90l653L2MbnyoJ6kWfmZhdpttpf00ar5IyUd3JVYzXqbE4T1R2NIxRe3Bb4DIOlzwN8ioqtPp+4IPBIRW0fEHTXrDgB+FhGjI+LlHsa8PfBmgoiIcyLiwh7u06xHnCCsP3oNeCewEvBGLp/yTdKDgoUkbZzHyKiMlTFc0mhSRdjdalsJkr4M7Av8QNIluQVwfdX6syQdWiZYpfFHjgS+lY+znaSTJX07r58s6UxJt0t6WNKHJP23pMcknVK1nwMl/TXv4zeSBpX9wMyKOEFYf3QpsDPwO1Il0K+RSim/tJz3nJW32Qq4BPhlRNwH/IA0bsYyrYSI+C9SeYTvRMQBPQk2ImYB5wBn5uPUtlQAXo2IT+TtrgWOItWcOlTSurkExX7AxyJiNOnJ6h7FZdbvS23YwBMRi4HdASStDXwP2EvSucDawOm56Fu1bYG98uuLSC2HVlIpIfIA8GClTo+kmaQibx8HPgjck8uovBPoq/W2rEU4QVh/9wPgVNJ1iamk1sW15CJ3y9HVGjRLWbZFvvLyNpZ0FGnAH0g1eDpTqbz7RtXryvxgUrnoCyLi+FLRmpXgLibrtyRtBmwQEbcBq5C+TIPiL+8/81aRxgOAP3XxcE8Co5TGN1+TXH20IxHxq9ydNDpfOF9CKlXeXTcDe0taD0DSOuqjY45b63CCsP5RXIWXAAAAd0lEQVTsVODE/HoiaRChu4CfFWz7DeAwSdOAg4B/68qBImI2acyCaaRrGPd2MdbrgC9ULlJ38b1ExEOkc/1DPoebgKYPWWl9m6u5mplZIbcgzMyskBOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK/R/qbf99B2YuQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high variance in expenditures makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring datatypes in pandas\n",
    "\n",
    "It's always good to know what datatypes you're working with, especially when the inefficient pandas type object may be involved. Towards that end, let's explore what we have.\n",
    "\n",
    "The data has been loaded into the workspace as `df`. Your job is to look at the DataFrame attribute `.dtypes`, and call its `.value_counts()` method in order to answer the question below.\n",
    "\n",
    "Make sure to call `df.dtypes.value_counts()`, and not df.value_counts()! Check out the difference in the Shell. df.value_counts() will return an error, because it is a Series method, not a DataFrame method.\n",
    "\n",
    "How many columns with dtype object are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels as categorical variables\n",
    "\n",
    "Remember, **your ultimate goal is to predict the probability that a certain label is attached to a budget line item**. You just saw that many columns in your data are the inefficient object type. Does this include the labels you're trying to predict? Let's find out!\n",
    "\n",
    "There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take. The 9 labels have been loaded into a list called LABELS. In the Shell, check out the type for these labels using `df[LABELS].dtypes`.\n",
    "\n",
    "You will notice that every label is encoded as an object datatype. Because **category datatypes are much more efficient** your task is to convert the labels to category types using the `.astype()` method.\n",
    "\n",
    "Note: `.astype()` only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the `.apply()` method and provide a **lambda function** called `categorize_label` that applies `.astype()` to each column, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function            object\n",
       "Use                 object\n",
       "Sharing             object\n",
       "Reporting           object\n",
       "Student_Type        object\n",
       "Position_Type       object\n",
       "Object_Type         object\n",
       "Pre_K               object\n",
       "Operating_Status    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "df[LABELS].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting unique labels\n",
    "\n",
    "There are over 100 unique labels. In this exercise, you will explore this fact by counting and plotting the number of unique values for each category of label.\n",
    "\n",
    "The dataframe `df` and the `LABELS` list have been loaded into the workspace; the `LABELS` columns of `df` have been converted to **category types**.\n",
    "\n",
    "pandas, which has been pre-imported as pd, provides a `pd.Series.nunique` method for counting the number of unique values in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing log loss with NumPy\n",
    "\n",
    "To see how the **log loss metric** handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function `compute_log_loss()`.\n",
    "\n",
    "5 one-dimensional numeric arrays simulating different types of predictions have been pre-loaded: actual_labels, correct_confident, correct_not_confident, wrong_not_confident, and wrong_confident.\n",
    "\n",
    "Your job is to compute the log loss for each sample set provided using the `compute_log_loss(predicted_values, actual_values)`. It takes the predicted values as the first argument and the actual values as the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "correct_confident = [0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
    "correct_not_confident = [0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35]\n",
    "wrong_not_confident = [0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65]\n",
    "wrong_confident = [0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\" Computes the logarithmic loss between predicted and\n",
    "         actual when these are 1D arrays.\n",
    "\n",
    "         :param predicted: The predicted probabilities as floats between 0-1\n",
    "         :param actual: The actual binary labels. Either 0 or 1.\n",
    "         :param eps (optional): log(0) is inf, so we need to offset our\n",
    "         predicted values slightly by eps from 0 or 1.\n",
    "     \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                        + (1 - actual) \n",
    "                        * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.026677430412431348\n",
      "Log loss, correct and not confident: 0.32548727220550666\n",
      "Log loss, wrong and not confident: 32.236990899179226\n",
      "Log loss, wrong and confident: 32.236990899179226\n",
      "Log loss, actual labels: 1.4028870802592218e-10\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log loss** penalizes highly confident wrong answers much more than any other type. This will be a good metric to use on your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a train-test split in scikit-learn\n",
    "\n",
    "Alright, you've been patient and awesome. It's finally time to start training models!\n",
    "\n",
    "The first step is to `split the data into a training set and a test set`. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least `min_count` examples of each label appear in each split: `multilabel_train_test_split`.\n",
    "\n",
    "You'll start with a simple model that uses just the numeric columns of your DataFrame when calling `multilabel_train_test_split`. The data has been read into a DataFrame df and a list consisting of just the numeric columns is available as `NUMERIC_COLUMNS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/data/multilabel.py\n",
    "# See also: https://github.com/drivendataorg/box-plots-sklearn/blob/master/notebooks/1.0-full-model.ipynb\n",
    "\n",
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', \n",
    "          'Object_Type', 'Pre_K', 'Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1040 entries, 198 to 101861\n",
      "Data columns (total 2 columns):\n",
      "FTE      1040 non-null float64\n",
      "Total    1040 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 24.4 KB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 520 entries, 209 to 448628\n",
      "Data columns (total 2 columns):\n",
      "FTE      520 non-null float64\n",
      "Total    520 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 12.2 KB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1040 entries, 198 to 101861\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 113.8 KB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 520 entries, 209 to 448628\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 56.9 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only and replane all NaNs with -1000 to distinguish their values from 0\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-8291.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49768.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>-1000.0</td>\n",
       "      <td>2304.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>-1000.0</td>\n",
       "      <td>1505.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>-1000.0</td>\n",
       "      <td>2400.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FTE     Total\n",
       "198  -1000.0  -8291.86\n",
       "750      1.0  49768.82\n",
       "1524 -1000.0   2304.43\n",
       "1770 -1000.0   1505.85\n",
       "1951 -1000.0   2400.59"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_Substitute Compensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel &amp; Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_Non PreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status_PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "198                             0                                      0   \n",
       "750                             0                                      0   \n",
       "1524                            0                                      0   \n",
       "1770                            0                                      0   \n",
       "1951                            0                                      0   \n",
       "\n",
       "      Function_Communications  Function_Curriculum Development  \\\n",
       "198                         0                                0   \n",
       "750                         0                                0   \n",
       "1524                        0                                0   \n",
       "1770                        0                                0   \n",
       "1951                        0                                0   \n",
       "\n",
       "      Function_Data Processing & Information Services  \\\n",
       "198                                                 0   \n",
       "750                                                 0   \n",
       "1524                                                0   \n",
       "1770                                                0   \n",
       "1951                                                0   \n",
       "\n",
       "      Function_Development & Fundraising  Function_Enrichment  \\\n",
       "198                                    0                    0   \n",
       "750                                    0                    0   \n",
       "1524                                   0                    0   \n",
       "1770                                   0                    1   \n",
       "1951                                   0                    0   \n",
       "\n",
       "      Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "198                                   0                                  0   \n",
       "750                                   0                                  0   \n",
       "1524                                  0                                  0   \n",
       "1770                                  0                                  0   \n",
       "1951                                  0                                  0   \n",
       "\n",
       "      Function_Facilities Planning                 ...                  \\\n",
       "198                              0                 ...                   \n",
       "750                              0                 ...                   \n",
       "1524                             0                 ...                   \n",
       "1770                             0                 ...                   \n",
       "1951                             0                 ...                   \n",
       "\n",
       "      Object_Type_Rent/Utilities  Object_Type_Substitute Compensation  \\\n",
       "198                            0                                    0   \n",
       "750                            0                                    0   \n",
       "1524                           0                                    0   \n",
       "1770                           0                                    0   \n",
       "1951                           0                                    0   \n",
       "\n",
       "      Object_Type_Supplies/Materials  Object_Type_Travel & Conferences  \\\n",
       "198                                0                                 0   \n",
       "750                                0                                 0   \n",
       "1524                               0                                 0   \n",
       "1770                               0                                 0   \n",
       "1951                               0                                 1   \n",
       "\n",
       "      Pre_K_NO_LABEL  Pre_K_Non PreK  Pre_K_PreK  \\\n",
       "198                1               0           0   \n",
       "750                0               1           0   \n",
       "1524               1               0           0   \n",
       "1770               1               0           0   \n",
       "1951               1               0           0   \n",
       "\n",
       "      Operating_Status_Non-Operating  Operating_Status_Operating, Not PreK-12  \\\n",
       "198                                1                                        0   \n",
       "750                                0                                        0   \n",
       "1524                               1                                        0   \n",
       "1770                               0                                        0   \n",
       "1951                               0                                        0   \n",
       "\n",
       "      Operating_Status_PreK-12 Operating  \n",
       "198                                    0  \n",
       "750                                    1  \n",
       "1524                                   0  \n",
       "1770                                   1  \n",
       "1951                                   1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "With split data in hand, you're only a few lines away from training a model.\n",
    "\n",
    "In this exercise, you will import the `logistic regression` and `one versus rest classifiers` in order to fit a **multi-class logistic regression model** to the NUMERIC_COLUMNS of your feature data.\n",
    "\n",
    "Then you'll test and print the accuracy with the `.score()` method to see the results of training.\n",
    "\n",
    "Before you train! Remember, we're ultimately going to be using `logloss` to score our model, so don't worry too much about the accuracy here. Keep in mind that you're throwing away all of the text data in the dataset - that's by far most of the data! So don't get your hopes up for a killer performance just yet. We're just interested in getting things up and running at the moment.\n",
    "\n",
    "All data necessary to call `multilabel_train_test_split()` has been loaded into the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your model to predict values on holdout data\n",
    "\n",
    "You're ready to make some predictions! Remember, the `train-test-split` you've carried out so far is for model development. The original competition provides an additional test set, for which you'll never actually see the correct labels. This is called the `\"holdout data.\"`\n",
    "\n",
    "The point of the **holdout data** is to provide a fair test for machine learning competitions. If the labels aren't known by anyone but DataCamp, DrivenData, or whoever is hosting the competition, you can be sure that no one submits a mere copy of labels to artificially pump up the performance on their model.\n",
    "\n",
    "Remember that **the original goal is to predict the probability of each label**. In this exercise you'll do just that by using the `.predict_proba()` method on your trained model.\n",
    "\n",
    "First, however, you'll need to load the holdout data, which is available in the workspace as the file `HoldoutData.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>SubFund_Description</th>\n",
       "      <th>Job_Title_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Total</th>\n",
       "      <th>Text_2</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TIME CARD CERTIFIEDAddl</td>\n",
       "      <td>Alternative Schools Instruction</td>\n",
       "      <td>175.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Extra Duty/Signing Bonus Pay</td>\n",
       "      <td>Basic Educational Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43424.905849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>OTHER PERSONAL SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB TEACHER ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAFF DEV AND INSTR MEDIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>INST STAFF TRAINING SVCS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.090000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>TEACHER TRAINING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>TERMINAL LEAVE VACATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSPECTOR &amp; SERVICE TECHNICIAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRANSPORTATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PUPIL TRANSPORTATION SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5274.805500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>TERMINAL LEAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>Extra Duty/Signing Bonus Pay</td>\n",
       "      <td>Undistributed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Principal &amp; Asst. Principal Support</td>\n",
       "      <td>Educator Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Curriculum &amp; Instructional Staff Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44789.326495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Object_Description         Program_Description  \\\n",
       "237     Personal Services - Teachers       Instruction - Regular   \n",
       "466     Extra Duty/Signing Bonus Pay  Basic Educational Services   \n",
       "784   OTHER PERSONAL SERVICES                                NaN   \n",
       "1786  TERMINAL LEAVE VACATION                                NaN   \n",
       "2643    Extra Duty/Signing Bonus Pay               Undistributed   \n",
       "\n",
       "     SubFund_Description           Job_Title_Description  \\\n",
       "237                  NaN                             NaN   \n",
       "466                  NaN                             NaN   \n",
       "784                  NaN  SUB TEACHER ALL                  \n",
       "1786                 NaN  INSPECTOR & SERVICE TECHNICIAN   \n",
       "2643                 NaN                             NaN   \n",
       "\n",
       "     Facility_or_Department               Sub_Object_Description  \\\n",
       "237                     NaN                                  NaN   \n",
       "466                     NaN                              General   \n",
       "784                     NaN                                  NaN   \n",
       "1786                    NaN                                  NaN   \n",
       "2643                    NaN  Principal & Asst. Principal Support   \n",
       "\n",
       "                Location_Description  FTE  \\\n",
       "237                              NaN  0.0   \n",
       "466                          School   NaN   \n",
       "784   STAFF DEV AND INSTR MEDIA       0.0   \n",
       "1786  TRANSPORTATION                  0.0   \n",
       "2643               Educator Quality   NaN   \n",
       "\n",
       "                              Function_Description           Position_Extra  \\\n",
       "237                                            NaN  TIME CARD CERTIFIEDAddl   \n",
       "466                                    Instruction                      NaN   \n",
       "784                 INST STAFF TRAINING SVCS                            NaN   \n",
       "1786                PUPIL TRANSPORTATION SERVICES                       NaN   \n",
       "2643  Curriculum & Instructional Staff Development                      NaN   \n",
       "\n",
       "                               Text_4         Total Text_2 Text_3  \\\n",
       "237   Alternative Schools Instruction    175.350000    NaN    NaN   \n",
       "466                               NaN  43424.905849    NaN    NaN   \n",
       "784                               NaN     75.090000    NaN    NaN   \n",
       "1786                              NaN   5274.805500    NaN    NaN   \n",
       "2643                              NaN  44789.326495    NaN    NaN   \n",
       "\n",
       "                    Fund_Description                          Text_1  \n",
       "237           General Purpose School                             NaN  \n",
       "466                     General Fund                             NaN  \n",
       "784   GENERAL FUND                    TEACHER TRAINING                \n",
       "1786  GENERAL FUND                    TERMINAL LEAVE                  \n",
       "2643                    General Fund                             NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv(path+'HoldoutData.csv', index_col=0)\n",
    "holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can write the predictions to a .csv and submit for scoring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out your results to a csv for submission\n",
    "\n",
    "At last, you're ready to submit some predictions for scoring. In this exercise, you'll write your predictions to a .csv using the `.to_csv()` method on a pandas DataFrame. Then you'll evaluate your performance according to the **LogLoss metric** discussed earlier!\n",
    "\n",
    "You'll need to make sure your submission obeys the correct format.\n",
    "\n",
    "To do this, you'll use your predictions values to create a new DataFrame, `prediction_df`.\n",
    "\n",
    "Interpreting LogLoss & Beating the Benchmark:\n",
    "\n",
    "When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: **2.0455**, which merely submitted uniform probabilities for each class.\n",
    "\n",
    "Remember, `the lower the log loss the better`. Is your model's log loss lower than 2.0455?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.52295372e-02, 2.53472616e-02, 4.99263293e-01, ...,\n",
       "        5.43833253e-08, 1.81559426e-02, 5.00535064e-01],\n",
       "       [2.51118136e-02, 1.41085520e-02, 2.96272733e-03, ...,\n",
       "        8.57576612e-02, 1.15521435e-02, 9.39766790e-01],\n",
       "       [6.52405284e-02, 2.53447801e-02, 4.99683470e-01, ...,\n",
       "        5.43898562e-08, 1.81516744e-02, 5.00229586e-01],\n",
       "       ...,\n",
       "       [6.52422388e-02, 2.53443940e-02, 4.99748847e-01, ...,\n",
       "        5.43908724e-08, 1.81510104e-02, 5.00182055e-01],\n",
       "       [6.40115208e-02, 2.56291361e-02, 4.52343694e-01, ...,\n",
       "        5.35759255e-08, 1.86427171e-02, 5.34733951e-01],\n",
       "       [2.68595827e-02, 1.35829495e-02, 5.62693205e-03, ...,\n",
       "        8.94353532e-02, 1.05498529e-02, 9.07132169e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_Substitute Compensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel &amp; Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_Non PreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status_PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.499263</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.013562</td>\n",
       "      <td>0.048954</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.499304</td>\n",
       "      <td>0.499444</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.499972</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>5.438333e-08</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>0.500535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.014109</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.038501</td>\n",
       "      <td>0.014139</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025662</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.071322</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>0.776877</td>\n",
       "      <td>0.182703</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>8.575766e-02</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.939767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.065241</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.499683</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.048954</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.499701</td>\n",
       "      <td>0.499761</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>5.438986e-08</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>0.500230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.064673</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.477906</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.048966</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.479124</td>\n",
       "      <td>0.483298</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.500813</td>\n",
       "      <td>0.499159</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>5.405218e-08</td>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.516067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>0.025052</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.038469</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.037001</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>0.070186</td>\n",
       "      <td>0.041370</td>\n",
       "      <td>0.777023</td>\n",
       "      <td>0.182573</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>8.562962e-02</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.940701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "237                      0.065230                               0.025347   \n",
       "466                      0.025112                               0.014109   \n",
       "784                      0.065241                               0.025345   \n",
       "1786                     0.064673                               0.025474   \n",
       "2643                     0.025052                               0.014128   \n",
       "\n",
       "      Function_Communications  Function_Curriculum Development  \\\n",
       "237                  0.499263                         0.013329   \n",
       "466                  0.002963                         0.038501   \n",
       "784                  0.499683                         0.013329   \n",
       "1786                 0.477906                         0.013286   \n",
       "2643                 0.002896                         0.038469   \n",
       "\n",
       "      Function_Data Processing & Information Services  \\\n",
       "237                                          0.018965   \n",
       "466                                          0.014139   \n",
       "784                                          0.018963   \n",
       "1786                                         0.019067   \n",
       "2643                                         0.014159   \n",
       "\n",
       "      Function_Development & Fundraising  Function_Enrichment  \\\n",
       "237                             0.009383             0.023369   \n",
       "466                             0.005702             0.037037   \n",
       "784                             0.009382             0.023371   \n",
       "1786                            0.009449             0.023285   \n",
       "2643                            0.005713             0.037001   \n",
       "\n",
       "      Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "237                            0.013562                           0.048954   \n",
       "466                            0.020637                           0.043679   \n",
       "784                            0.013564                           0.048954   \n",
       "1786                           0.013476                           0.048966   \n",
       "2643                           0.020602                           0.043682   \n",
       "\n",
       "      Function_Facilities Planning                 ...                  \\\n",
       "237                       0.006267                 ...                   \n",
       "466                       0.005695                 ...                   \n",
       "784                       0.006266                 ...                   \n",
       "1786                      0.006310                 ...                   \n",
       "2643                      0.005706                 ...                   \n",
       "\n",
       "      Object_Type_Rent/Utilities  Object_Type_Substitute Compensation  \\\n",
       "237                     0.009385                             0.499304   \n",
       "466                     0.025662                             0.010424   \n",
       "784                     0.009384                             0.499701   \n",
       "1786                    0.009451                             0.479124   \n",
       "2643                    0.025709                             0.010203   \n",
       "\n",
       "      Object_Type_Supplies/Materials  Object_Type_Travel & Conferences  \\\n",
       "237                         0.499444                          0.006638   \n",
       "466                         0.071322                          0.041397   \n",
       "784                         0.499761                          0.006639   \n",
       "1786                        0.483298                          0.006621   \n",
       "2643                        0.070186                          0.041370   \n",
       "\n",
       "      Pre_K_NO_LABEL  Pre_K_Non PreK  Pre_K_PreK  \\\n",
       "237         0.500027        0.499972    0.030563   \n",
       "466         0.776877        0.182703    0.038604   \n",
       "784         0.500012        0.499988    0.030567   \n",
       "1786        0.500813        0.499159    0.030361   \n",
       "2643        0.777023        0.182573    0.038537   \n",
       "\n",
       "      Operating_Status_Non-Operating  Operating_Status_Operating, Not PreK-12  \\\n",
       "237                     5.438333e-08                                 0.018156   \n",
       "466                     8.575766e-02                                 0.011552   \n",
       "784                     5.438986e-08                                 0.018152   \n",
       "1786                    5.405218e-08                                 0.018374   \n",
       "2643                    8.562962e-02                                 0.011589   \n",
       "\n",
       "      Operating_Status_PreK-12 Operating  \n",
       "237                             0.500535  \n",
       "466                             0.939767  \n",
       "784                             0.500230  \n",
       "1786                            0.516067  \n",
       "2643                            0.940701  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv(path+'predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "#score = score_submission(pred_path='predictions.csv')\n",
    "\n",
    "# Print score\n",
    "#print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model, trained with numeric data only, yields logloss score: 1.9067227623381413"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incredible! Even though your basic model scored 0.0 accuracy, it nevertheless performs better than the benchmark score of 2.0455. You've now got the basics down and have made a first pass at this complicated supervised learning problem. It's time to step up your game and incorporate the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing text\n",
    "\n",
    "[Tokenization](https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html) is the process of chopping up a character sequence into pieces called tokens.\n",
    "\n",
    "How do we determine what constitutes a **token**? Often, tokens are separated by whitespace. But we can specify other delimiters as well. For example, if we decided to tokenize on punctuation, then any punctuation mark would be treated like a whitespace. How we tokenize text in our DataFrame can affect the statistics we use in our model.\n",
    "\n",
    "<img src=\"images/nlp_tokens.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/nlp_bag_of_words.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "A particular cell in our budget DataFrame may have the string content Title I - Disadvantaged Children/Targeted Assistance. The number of **n-grams** generated by this text data is sensitive to whether or not we tokenize on punctuation, as you'll show in the following exercise.\n",
    "\n",
    "<img src=\"images/nlp_ngram.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "How many tokens (1-grams) are in the string \"`Title I - Disadvantaged Children/Targeted Assistance`\" if we tokenize on punctuation? (answer: 6). Tokenizing on punctuation means that Children/Targeted becomes two tokens and - is dropped altogether. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your NLP credentials with n-grams\n",
    "\n",
    "You're well on your way to **NLP** superiority. Let's test your mastery of **n-grams**!\n",
    "\n",
    "In the workspace, we have the loaded a python list, `one_grams`, which contains all 1-grams of the string `petro-vend fuel and fluids`, tokenized on punctuation. Specifically,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_grams = ['petro', 'vend', 'fuel', 'and', 'fluids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, your job is to determine the sum of the sizes of 1-grams, 2-grams and 3-grams generated by the `string petro-vend fuel and fluids`, tokenized on punctuation.\n",
    "\n",
    "Recall that the **n-gram** of a sequence consists of all ordered subsequences of length n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_count(tokenized_list, n=1):\n",
    "    return len(tokenized_list) - abs(1 - n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_count(one_grams, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_count(one_grams, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_count(one_grams, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 1-grams + 2-grams + 3-grams is 5 + 4 + 3 = 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a bag-of-words in scikit-learn\n",
    "\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the **bag-of-words** representations resulting from different token patterns.\n",
    "\n",
    "You will focus on one feature only, the `Position_Extra` column, which describes any additional information not captured by the `Position_Type` label.\n",
    "\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using `df.loc[8960]`. Looking at the output reveals that this `Object_Description` is overtime pay. For who? The `Position Type` is merely \"other\", but the `Position Extra` elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\n",
    "\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n",
    "\n",
    "For comparison purposes, the first 15 tokens of `vec_basic`, which splits `df.Position_Extra` into tokens when it encounters only whitespace characters, have been printed along with the length of the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                                         Student Transportation\n",
       "Use                                                                 O&M\n",
       "Sharing                                                 Shared Services\n",
       "Reporting                                                    Non-School\n",
       "Student_Type                                                Unspecified\n",
       "Position_Type                                                     Other\n",
       "Object_Type                                  Other Compensation/Stipend\n",
       "Pre_K                                                          Non PreK\n",
       "Operating_Status                                      PreK-12 Operating\n",
       "Object_Description        Extra Duty Pay/Overtime For Support Personnel\n",
       "Text_2                                                              NaN\n",
       "SubFund_Description                                          Operations\n",
       "Job_Title_Description                     TRANSPORTATION,BUS DR., RADIO\n",
       "Text_3                                                              NaN\n",
       "Text_4                                     transportation - Second Runs\n",
       "Sub_Object_Description    Extra Duty Pay/Overtime For Support Personnel\n",
       "Location_Description                                        Unallocated\n",
       "FTE                                                                 NaN\n",
       "Function_Description                                     Transportation\n",
       "Facility_or_Department                        Transportation Department\n",
       "Position_Extra                                               BUS DRIVER\n",
       "Total                                                           1752.45\n",
       "Program_Description                                       Undistributed\n",
       "Fund_Description                                 General Operating Fund\n",
       "Text_1                                                    EXTENDED DAYS\n",
       "Name: 8960, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[8960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                       534\n",
       "PROFESSIONAL-INSTRUCTIONAL                270\n",
       "UNDESIGNATED                              196\n",
       "PARAPROFESSIONAL                           63\n",
       "TEACHER BACHELOR                           50\n",
       "PROFESSIONAL-OTHER                         43\n",
       "ADMINISTRATOR                              41\n",
       "CRAFTS, TRADES, AND SERVICES               34\n",
       "OFFICE/ADMINISTRATIVE SUPPORT              33\n",
       "TEACHER MASTER                             24\n",
       "SUBSTITUTE TEACHER                         21\n",
       "BUS DRIVER                                 20\n",
       "CLINIC ASSISTANT                           14\n",
       "TIME CARD CERTIFIEDAddl                     8\n",
       "DEGREED SUBSTITUTE                          8\n",
       "CCOACH CERT TCHRACCT                        7\n",
       "CERTIFIED SUBSTITUTE                        7\n",
       "POLICE PATROL MAN                           7\n",
       "TEACHER                                     7\n",
       "ANY CUS WHO IS NOT A SUPER                  6\n",
       "NURSE                                       6\n",
       "NONE                                        6\n",
       "CO CLERICAL                                 4\n",
       "REGISTRAR                                   4\n",
       "RESOURCE OFFICER (NO SUB REQD)              4\n",
       "SUPPLIES AND MATERIALS                      4\n",
       "BUILDING CUSTODIAN                          4\n",
       "PURCHASED ASSETS, MINOR EQUIP & RENTAL      3\n",
       "PRINCIPAL                                   3\n",
       "CONTRACTUAL SERVICES - OTHER                3\n",
       "                                         ... \n",
       "SUPERVISOR -  MON.                          1\n",
       "ADM SECRETARY                               1\n",
       "NETWORK ENGINEER                            1\n",
       "GIFTED & TALENTED COACH                     1\n",
       "WAREHOUSE SUPER                             1\n",
       "OCCUPATIONAL THERAPIST                      1\n",
       "EXECUTIVE DIRECTOR                          1\n",
       "LARGE HS MGR                                1\n",
       "TEACHER -  DAYS                             1\n",
       "CONSULTANT  DAY                             1\n",
       "3RD GRADE                                   1\n",
       "MO CAMPBELL OPTIONAL PAY                    1\n",
       "Career Ladder III/Ext Learning              1\n",
       "ELEM MGR MED SIZE                           1\n",
       "2ND GRADE                                   1\n",
       "TEACHER - S.E  DAYS                         1\n",
       "ART                                         1\n",
       "ASSESSMENT SPECIALIST                       1\n",
       "ASST PRIN HIGH SCHOOL                       1\n",
       "SCHOOL ASST - KDG                           1\n",
       "PSYCHOLOGICAL                               1\n",
       "CAMPUS MONITOR                              1\n",
       "ELEM MGR AVG SIZE                           1\n",
       "INTERRELATED                                1\n",
       "INSTRUC COACH CO-TCHR                       1\n",
       "TEACHER - S.E.  DAYS                        1\n",
       "COUNSELOR MIDDLE SCHOOL                     1\n",
       "1ST GRADE                                   1\n",
       "POLICE TEMP                                 1\n",
       "HS FOOD SERVICE WORKER                      1\n",
       "Name: Position_Extra, Length: 119, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Position_Extra'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'art', 'assessment', 'assistant', 'asst', 'athletic']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra to replace NaNs with empty strings.\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text columns for tokenization\n",
    "\n",
    "In order to get a **bag-of-words** representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. `CountVectorizer` **expects each row to just be a single string**, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "\n",
    "In this exercise, you'll complete the function definition `combine_text_columns()`. When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the `.fit_transform()` method.\n",
    "\n",
    "Note that the function uses`NUMERIC_COLUMNS` and `LABELS` to determine which columns to drop. These lists have been loaded into the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FTE',\n",
       " 'Facility_or_Department',\n",
       " 'Function',\n",
       " 'Function_Description',\n",
       " 'Fund_Description',\n",
       " 'Job_Title_Description',\n",
       " 'Location_Description',\n",
       " 'Object_Description',\n",
       " 'Object_Type',\n",
       " 'Operating_Status',\n",
       " 'Position_Extra',\n",
       " 'Position_Type',\n",
       " 'Pre_K',\n",
       " 'Program_Description',\n",
       " 'Reporting',\n",
       " 'Sharing',\n",
       " 'Student_Type',\n",
       " 'SubFund_Description',\n",
       " 'Sub_Object_Description',\n",
       " 'Text_1',\n",
       " 'Text_2',\n",
       " 'Text_3',\n",
       " 'Text_4',\n",
       " 'Total',\n",
       " 'Use'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop=NUMERIC_COLUMNS + LABELS\n",
    "set(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FTE',\n",
       " 'Function',\n",
       " 'Object_Type',\n",
       " 'Operating_Status',\n",
       " 'Position_Type',\n",
       " 'Pre_K',\n",
       " 'Reporting',\n",
       " 'Sharing',\n",
       " 'Student_Type',\n",
       " 'Total',\n",
       " 'Use'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find intersection of to_drop and df.columns lists\n",
    "to_drop = set(to_drop) #& set(df.columns.tolist())\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in a token?\n",
    "\n",
    "Now you will use `combine_text_columns` to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a **bag-of-words** using the `.fit_transform()` method.\n",
    "\n",
    "You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1404 tokens in the dataset\n",
      "There are 1117 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df, to_drop=NUMERIC_COLUMNS + LABELS)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that tokenizing on alpha-numeric tokens reduced the number of tokens, just as in the last exercise. We'll keep this in mind when building a better model with the Pipeline object next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate pipeline\n",
    "\n",
    "In order to make your life easier as you start to work with all of the data in your original DataFrame, `df`, it's time to turn to one of scikit-learn's most useful objects: the **Pipeline**.\n",
    "\n",
    "For the next few exercises, you'll reacquaint yourself with **pipelines** and `train a classifier on some synthetic (sample) data of multiple datatypes` before using the same techniques on the main dataset.\n",
    "\n",
    "The sample data is stored in the DataFrame, `sample_df`, which has three kinds of feature data: numeric, text, and numeric with missing values. It also has a label column with two classes, `a` and `b`.\n",
    "\n",
    "In this exercise, your job is to instantiate a pipeline that trains using the numeric column of the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>text</th>\n",
       "      <th>with_missing</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.856306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.433240</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.973454</td>\n",
       "      <td>foo</td>\n",
       "      <td>4.310229</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.829785</td>\n",
       "      <td>foo bar</td>\n",
       "      <td>2.469828</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.062947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.852981</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.786003</td>\n",
       "      <td>foo bar</td>\n",
       "      <td>1.826475</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     numeric     text  with_missing label\n",
       "0 -10.856306      NaN      4.433240     b\n",
       "1   9.973454      foo      4.310229     b\n",
       "2   2.829785  foo bar      2.469828     a\n",
       "3 -15.062947      NaN      2.852981     b\n",
       "4  -5.786003  foo bar      1.826475     a"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(path+'sample_df.csv', index_col=0)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - numeric, no nans:  0.62\n"
     ]
    }
   ],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='lbfgs')))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to incorporate numeric data with missing values by adding a preprocessing step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing numeric features\n",
    "\n",
    "What would have happened if you had included the with `'with_missing'` column in the last exercise? Without imputing missing values, the pipeline would not be happy (try it and see). So, in this exercise you'll improve your pipeline a bit by using the `Imputer()` imputation transformer from scikit-learn to fill in missing values in your sample data.\n",
    "\n",
    "`By default, the imputer transformer replaces NaNs with the mean value of the column`. That's a good enough imputation strategy for the sample data, so you won't need to pass anything extra to the imputer.\n",
    "\n",
    "After importing the transformer, you will edit the steps list used in the previous exercise by inserting a `(name, transform)` tuple. Recall that steps are processed sequentially, so make sure the new tuple encoding your preprocessing step is put in the right place.\n",
    "\n",
    "The `sample_df` is in the workspace, in case you'd like to take another look. Make sure to select both numeric columns- in the previous exercise we couldn't use with_missing because we had no preprocessing step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-41e1d9626353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fit the pipeline to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 215\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1288\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='lbfgs')))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>with_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2.326497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>-12.717469</td>\n",
       "      <td>3.827838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-25.570546</td>\n",
       "      <td>3.312594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>-3.140744</td>\n",
       "      <td>1.687315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>-0.980916</td>\n",
       "      <td>4.986243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numeric  with_missing\n",
       "592   2.326497           NaN\n",
       "660 -12.717469      3.827838\n",
       "185 -25.570546      3.312594\n",
       "822  -3.140744      1.687315\n",
       "693  -0.980916      4.986243"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b\n",
       "592  0  1\n",
       "660  0  1\n",
       "185  0  1\n",
       "822  1  0\n",
       "693  0  1"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all numeric, incl nans:  0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='lbfgs')))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to use preprocessing in pipelines with numeric data, and it looks like the accuracy has improved because of it! Text data preprocessing is next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text features\n",
    "\n",
    "Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the text column from the sample data.\n",
    "\n",
    "To preprocess the text, you'll turn to `CountVectorizer()` to generate a **bag-of-words** representation of the data, as before. Using the default arguments, add a `(step, transform)` tuple to the steps list in your pipeline.\n",
    "\n",
    "Make sure you select only the text column for splitting your training and test sets.\n",
    "\n",
    "As usual, your `sample_df` is ready and waiting in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592        NaN\n",
       "660    bar foo\n",
       "185    bar foo\n",
       "822        bar\n",
       "693        NaN\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with empty strings\n",
    "X_train.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     750\n",
       "unique      5\n",
       "top       bar\n",
       "freq      160\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592           \n",
       "660    bar foo\n",
       "185    bar foo\n",
       "822        bar\n",
       "693           \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bar        160\n",
       "           151\n",
       "foo bar    149\n",
       "bar foo    147\n",
       "foo        143\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  b\n",
       "592  0  1\n",
       "660  0  1\n",
       "185  0  1\n",
       "822  1  0\n",
       "693  0  1"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing values in a\n",
    "(y_train['a'] == np.nan).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing values in b\n",
    "(y_train['b'] == np.nan).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 2)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-6d7e47e8247d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Compute and print accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on sample data - just text data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    326\u001b[0m                                                tokenize)\n\u001b[1;32m    327\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 328\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    144\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like you're ready to create a pipeline for processing multiple datatypes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple types of processing: FunctionTransformer\n",
    "\n",
    "The next two exercises will introduce new topics you'll need to make your **pipeline** truly excel.\n",
    "\n",
    "Any step in the **pipeline** must be an object that implements the fit and transform methods. The `FunctionTransformer` ([docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html)) creates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines.\n",
    "\n",
    "You are working with numeric data that needs imputation, and text data that needs to be converted into a **bag-of-words**. You'll create functions that separate the text from the numeric variables and see how the `.fit()` and `.transform()` methods work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data\n",
      "0        NaN\n",
      "1        foo\n",
      "2    foo bar\n",
      "3        NaN\n",
      "4    foo bar\n",
      "Name: text, dtype: object\n",
      "\n",
      "Numeric Data\n",
      "     numeric  with_missing\n",
      "0 -10.856306      4.433240\n",
      "1   9.973454      4.310229\n",
      "2   2.829785      2.469828\n",
      "3 -15.062947      2.852981\n",
      "4  -5.786003      1.826475\n"
     ]
    }
   ],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple types of processing: FeatureUnion\n",
    "\n",
    "Now that you can separate text and numeric data in your pipeline, you're ready to perform separate steps on each by nesting pipelines and using `FeatureUnion()`.\n",
    "\n",
    "These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. Here, for example, you don't want to impute our text data, and you don't want to create a bag-of-words with our numeric data. Instead, you want to deal with these separately and then join the results together using `FeatureUnion()`.\n",
    "\n",
    "In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. The results of those pipelines are joined using `FeatureUnion()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-f46c353b8928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Fit pl to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Compute and print accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m             delayed(_fit_transform_one)(trans, X, y, weight,\n\u001b[1;32m    792\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 793\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1032\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    326\u001b[0m                                                tokenize)\n\u001b[1;32m    327\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 328\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    144\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FunctionTransformer on the main dataset\n",
    "\n",
    "In this exercise you're going to use `FunctionTransformer` on the primary budget data, before instantiating a multiple-datatype pipeline in the next exercise.\n",
    "\n",
    "Recall that you used a custom function `combine_text_columns` to select and properly format text data for tokenization; it is loaded into the workspace and ready to be put to work in a function transformer!\n",
    "\n",
    "Concerning the numeric data, you can use `NUMERIC_COLUMNS`, preloaded as usual, to help design a subset-selecting lambda function.\n",
    "\n",
    "You're all finished with sample data. The original df is back in the workspace, ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplemental *</td>\n",
       "      <td>...</td>\n",
       "      <td>Non-Certificated Salaries And Wages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Care and Upkeep of Building Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>-8291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I CARRYOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Student Transportation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Other Non-Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>REPAIR AND MAINTENANCE SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMIN. SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDENT TRANSPORT SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>618.29</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>49768.82</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>...</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td></td>\n",
       "      <td>-1.02</td>\n",
       "      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplies and Materials</td>\n",
       "      <td>...</td>\n",
       "      <td>Supplies And Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Community Services *</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2304.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I PI+HOMELESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Function          Use          Sharing   Reporting  \\\n",
       "198                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "209   Student Transportation     NO_LABEL  Shared Services  Non-School   \n",
       "750     Teacher Compensation  Instruction  School Reported      School   \n",
       "931                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "1524                NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "\n",
       "     Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "198      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "209      NO_LABEL      NO_LABEL    Other Non-Compensation  NO_LABEL   \n",
       "750   Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "931      NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "1524     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "\n",
       "       Operating_Status               Object_Description  \\\n",
       "198       Non-Operating                   Supplemental *   \n",
       "209   PreK-12 Operating  REPAIR AND MAINTENANCE SERVICES   \n",
       "750   PreK-12 Operating     Personal Services - Teachers   \n",
       "931       Non-Operating                 General Supplies   \n",
       "1524      Non-Operating           Supplies and Materials   \n",
       "\n",
       "              ...                        Sub_Object_Description  \\\n",
       "198           ...           Non-Certificated Salaries And Wages   \n",
       "209           ...                                           NaN   \n",
       "750           ...                                           NaN   \n",
       "931           ...                              General Supplies   \n",
       "1524          ...                        Supplies And Materials   \n",
       "\n",
       "     Location_Description  FTE                  Function_Description  \\\n",
       "198                   NaN  NaN  Care and Upkeep of Building Services   \n",
       "209       ADMIN. SERVICES  NaN             STUDENT TRANSPORT SERVICE   \n",
       "750                   NaN  1.0                                   NaN   \n",
       "931                   NaN  NaN                           Instruction   \n",
       "1524                  NaN  NaN            Other Community Services *   \n",
       "\n",
       "          Facility_or_Department Position_Extra     Total  \\\n",
       "198                          NaN                 -8291.86   \n",
       "209                          NaN                   618.29   \n",
       "750                          NaN        TEACHER  49768.82   \n",
       "931   Instruction And Curriculum                    -1.02   \n",
       "1524                         NaN                  2304.43   \n",
       "\n",
       "                                    Program_Description  \\\n",
       "198                                                 NaN   \n",
       "209                                PUPIL TRANSPORTATION   \n",
       "750                               Instruction - Regular   \n",
       "931   \"Title I, Part A Schoolwide Activities Related...   \n",
       "1524                                                NaN   \n",
       "\n",
       "                                       Fund_Description                Text_1  \n",
       "198   Title I - Disadvantaged Children/Targeted Assi...    TITLE I CARRYOVER   \n",
       "209                                        General Fund                   NaN  \n",
       "750                              General Purpose School                   NaN  \n",
       "931                              General Operating Fund                   NaN  \n",
       "1524  Title I - Disadvantaged Children/Targeted Assi...   TITLE I PI+HOMELESS  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n"
     ]
    }
   ],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a model to the pipeline\n",
    "\n",
    "You're about to take everything you've learned so far and implement it in a Pipeline that works with the real, DrivenData budget line item data you've been exploring.\n",
    "\n",
    "Surprise! The structure of the pipeline is exactly the same as earlier in this chapter:\n",
    "\n",
    "- the **preprocessing step** uses FeatureUnion to join the results of nested pipelines that each rely on FunctionTransformer to select multiple datatypes\n",
    "- the **model step** stores the model object\n",
    "\n",
    "You can then call familiar methods like `.fit()` and `.score()` on the Pipeline object `pl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.21346153846153845\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a different class of model\n",
    "\n",
    "Now you're cruising. One of the great strengths of pipelines is how easy they make the process of testing different models.\n",
    "\n",
    "Until now, you've been using the model step `('clf', OneVsRestClassifier(LogisticRegression()))` in your pipeline.\n",
    "\n",
    "But what if you want to try a different model? Do you need to build an entirely new pipeline? New nests? New FeatureUnions? Nope! You just have a simple one-line change, as you'll see in this exercise.\n",
    "\n",
    "In particular, you'll swap out the logistic-regression model and replace it with a random forest classifier, which uses the statistics of an ensemble of decision trees to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.27692307692307694\n"
     ]
    }
   ],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you adjust the model or parameters to improve accuracy?\n",
    "\n",
    "You just saw a substantial improvement in accuracy by swapping out the model. Pipelines are amazing!\n",
    "\n",
    "Can you make it better? Try changing the parameter `n_estimators` of RandomForestClassifier(), whose default value is 10, to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.3153846153846154\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nlp_txt_preprocessing.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "## How many tokens?\n",
    "\n",
    "Recall from previous excersises that how you tokenize text affects the **n-gram** statistics used in your model.\n",
    "\n",
    "Going forward, you'll use alpha-numeric sequences, and only alpha-numeric sequences, as tokens. Alpha-numeric tokens contain only letters a-z and numbers 0-9 (no other characters). In other words, you'll `tokenize on punctuation` to generate n-gram statistics.\n",
    "\n",
    "In this exercise, you'll make sure you remember how to tokenize on punctuation.\n",
    "\n",
    "Assuming we tokenize on punctuation, accepting only alpha-numeric sequences as tokens, how many tokens are in the following string from the main dataset? `PLANNING,RES,DEV,& EVAL`. (correct 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding what's a word\n",
    "\n",
    "Before you build up to the winning pipeline, it will be useful to look a little deeper into how the text features will be processed.\n",
    "\n",
    "In this exercise, you will use `CountVectorizer` on the training data `X_train` (preloaded into the workspace) to see the effect of tokenization on punctuation.\n",
    "\n",
    "Remember, since `CountVectorizer` expects a vector, you'll need to use the preloaded function, `combine_text_columns` before fitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00a', '12', '1st', '2nd', '4th', '5th', '70h', '8', 'a', 'aaps']\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram range in scikit-learn\n",
    "\n",
    "In this exercise you'll insert a `CountVectorizer` instance into your pipeline for the main dataset, and compute multiple **n-gram** features to be used in the model.\n",
    "\n",
    "In order to look for **ngram** relationships at multiple scales, you will use the `ngram_range` parameter.\n",
    "\n",
    "Special functions: You'll notice a couple of new steps provided in the pipeline in this and many of the remaining exercises. Specifically, the `dim_red` step following the `vectorizer` step , and the `scale` step preceeding the `clf` (classification) step.\n",
    "\n",
    "These have been added in order to account for the fact that you're using a reduced-size sample of the full dataset in this course. To make sure the models perform as the expert competition winner intended, we have to apply a **dimensionality reduction** technique, which is what the `dim_red` step does, and we have to **scale the features** to lie between -1 and 1, which is what the `scale` step does.\n",
    "\n",
    "The `dim_red` step uses a scikit-learn function called `SelectKBest()`, applying something called the **chi-squared test** to select the K \"best\" features. The `scale` step uses a scikit-learn function called `MaxAbsScaler()` in order to squash the relevant features into the interval -1 to 1.\n",
    "\n",
    "You won't need to do anything extra with these functions here, just complete the vectorizing pipeline steps below. However, notice how easy it was to add more processing steps to our pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.19038461538461537\n"
     ]
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1552151662973142"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean log loss\n",
    "y_pred = pl.predict(X_test)\n",
    "np.mean(compute_log_loss(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement interaction modeling in scikit-learn\n",
    "\n",
    "It's time to add **interaction features** to your model. The `PolynomialFeatures` object in scikit-learn does just that, but here you're going to use a custom interaction object, `SparseInteractions`. Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.\n",
    "\n",
    "<img src=\"images/nlp_interaction_terms1.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/nlp_interaction_terms2.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "`SparseInteractions` does the same thing as `PolynomialFeatures`, but it uses sparse matrices to do so. You can get the code for `SparseInteractions` at this [GitHub Gist](https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/features/SparseInteractions.py).\n",
    "\n",
    "`PolynomialFeatures` and `SparseInteractions` both take the argument `degree`, which tells them what polynomial degree of interactions to compute.\n",
    "\n",
    "You're going to consider interaction terms of `degree=2` in your pipeline. You will insert these steps after the preprocessing steps you've built out so far, but before the classifier steps.\n",
    "\n",
    "**Pipelines with interaction terms** take a while to train (since you're making n features into n-squared features!), so as long as you set it up right, we'll do the heavy lifting and tell you what your score is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0073873507161948"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Mean log loss\n",
    "y_pred = pl.predict(X_test)\n",
    "np.mean(compute_log_loss(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is hashing a useful trick?\n",
    "\n",
    "A [hash function](https://en.wikipedia.org/wiki/Feature_hashing#Feature_vectorization_using_the_hashing_trick) takes an input, in your case a token, and outputs a hash value. For example, the input may be a string and the hash value may be an integer.\n",
    "\n",
    "<img src=\"images/nlp_hashing_trick1.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/nlp_hashing_trick2.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "We've loaded a familiar python datatype, a dictionary called `hash_dict`, that makes this mapping concept a bit more explicit. In fact, python dictionaries ARE hash tables!\n",
    "\n",
    "By explicitly stating how many possible outputs the hashing function may have, we limit the size of the objects that need to be processed. With these limits known, computation can be made more efficient and we can get results faster, even on large datasets.\n",
    "\n",
    "Using the above information, answer the following:\n",
    "\n",
    "Why is hashing a useful trick?\n",
    "\n",
    "- Hashing isn't useful unless you're working with numbers.\n",
    "- Some problems are memory-bound and not easily parallelizable, but hashing parallelizes them.\n",
    "- Some problems are memory-bound and not easily parallelizable, and hashing enforces a fixed length computation instead of using a mutable datatype (like a dictionary). (correct)\n",
    "- Hashing enforces a mutable length computation instead of using a fixed length datatype, like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_dict = {'and': 780, 'fluids': 354, 'fuel': 895, 'petro': 354, 'vend': 785}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the hashing trick in scikit-learn\n",
    "\n",
    "In this exercise you will check out the scikit-learn implementation of `HashingVectorizer` before adding it to your pipeline later.\n",
    "\n",
    "`HashingVectorizer` acts just like `CountVectorizer` in that it can accept `token_pattern` and `ngram_range` parameters. The important difference is that **it creates hash values from the text**, so that we get all the computational advantages of hashing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0 -0.160128\n",
      "1  0.160128\n",
      "2 -0.480384\n",
      "3 -0.320256\n",
      "4  0.160128\n"
     ]
    }
   ],
   "source": [
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some text is hashed to the same value but this doesn't neccessarily hurt performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the winning model\n",
    "\n",
    "You have arrived! This is where all of your hard work pays off. It's time to build the model that won DrivenData's competition.\n",
    "\n",
    "You've constructed a robust, powerful pipeline capable of processing training and testing data. Now that you understand the data and know all of the tools you need, you can essentially solve the whole problem in a relatively small number of lines of code. Wow!\n",
    "\n",
    "All you need to do is add the `HashingVectorizer` step to the pipeline to replace the `CountVectorizer` step.\n",
    "\n",
    "The parameters `non_negative=True`, `norm=None`, and `binary=False` make the HashingVectorizer perform similarly to the default settings on the `CountVectorizer` so you can just replace one with the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1, 2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/ksatola/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0085795619106497"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Mean log loss\n",
    "y_pred = pl.predict(X_test)\n",
    "np.mean(compute_log_loss(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the performance is about the same, but this is expected since the `HashingVectorizer` should work the same as the `CountVectorizer`. Try this pipeline out on the whole dataset on your local machine to see its full power!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_Substitute Compensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel &amp; Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_Non PreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating, Not PreK-12</th>\n",
       "      <th>Operating_Status_PreK-12 Operating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "209                             0                                      0   \n",
       "931                             0                                      0   \n",
       "2939                            0                                      0   \n",
       "3395                            0                                      0   \n",
       "4490                            0                                      0   \n",
       "\n",
       "      Function_Communications  Function_Curriculum Development  \\\n",
       "209                         0                                0   \n",
       "931                         0                                0   \n",
       "2939                        0                                0   \n",
       "3395                        0                                0   \n",
       "4490                        0                                0   \n",
       "\n",
       "      Function_Data Processing & Information Services  \\\n",
       "209                                                 0   \n",
       "931                                                 0   \n",
       "2939                                                0   \n",
       "3395                                                0   \n",
       "4490                                                0   \n",
       "\n",
       "      Function_Development & Fundraising  Function_Enrichment  \\\n",
       "209                                    0                    0   \n",
       "931                                    0                    0   \n",
       "2939                                   0                    0   \n",
       "3395                                   0                    0   \n",
       "4490                                   0                    0   \n",
       "\n",
       "      Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "209                                   0                                  0   \n",
       "931                                   0                                  0   \n",
       "2939                                  0                                  0   \n",
       "3395                                  0                                  0   \n",
       "4490                                  0                                  0   \n",
       "\n",
       "      Function_Facilities Planning                 ...                  \\\n",
       "209                              0                 ...                   \n",
       "931                              0                 ...                   \n",
       "2939                             0                 ...                   \n",
       "3395                             0                 ...                   \n",
       "4490                             0                 ...                   \n",
       "\n",
       "      Object_Type_Rent/Utilities  Object_Type_Substitute Compensation  \\\n",
       "209                            0                                    0   \n",
       "931                            0                                    0   \n",
       "2939                           0                                    0   \n",
       "3395                           0                                    0   \n",
       "4490                           0                                    0   \n",
       "\n",
       "      Object_Type_Supplies/Materials  Object_Type_Travel & Conferences  \\\n",
       "209                                0                                 0   \n",
       "931                                0                                 0   \n",
       "2939                               0                                 0   \n",
       "3395                               0                                 0   \n",
       "4490                               0                                 0   \n",
       "\n",
       "      Pre_K_NO_LABEL  Pre_K_Non PreK  Pre_K_PreK  \\\n",
       "209                1               0           0   \n",
       "931                1               0           0   \n",
       "2939               1               0           0   \n",
       "3395               1               0           0   \n",
       "4490               1               0           0   \n",
       "\n",
       "      Operating_Status_Non-Operating  Operating_Status_Operating, Not PreK-12  \\\n",
       "209                                0                                        0   \n",
       "931                                1                                        0   \n",
       "2939                               0                                        0   \n",
       "3395                               0                                        0   \n",
       "4490                               0                                        0   \n",
       "\n",
       "      Operating_Status_PreK-12 Operating  \n",
       "209                                    1  \n",
       "931                                    0  \n",
       "2939                                   1  \n",
       "3395                                   1  \n",
       "4490                                   1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original notebook\n",
    "\n",
    "https://github.com/datacamp/course-resources-ml-with-experts-budgets/blob/master/notebooks/1.0-full-model.ipynb\n",
    "\n",
    "or in data/dc19/1.0-full-model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
