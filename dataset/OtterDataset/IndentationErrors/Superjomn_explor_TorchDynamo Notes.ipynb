{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall torch -y\n",
        "!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118 --force"
      ],
      "metadata": {
        "id": "QymGt9x98hQl"
      },
      "id": "QymGt9x98hQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "208f3970",
      "metadata": {
        "id": "208f3970"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch._dynamo import optimize\n",
        "from typing import *\n",
        "from torch import _dynamo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the valid backends"
      ],
      "metadata": {
        "id": "MfOUK6SV-zUB"
      },
      "id": "MfOUK6SV-zUB"
    },
    {
      "cell_type": "code",
      "source": [
        "_dynamo.list_backends()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGlDbGXy-obW",
        "outputId": "166cd045-f20b-4000-c1fc-8be9c986da24"
      },
      "id": "sGlDbGXy-obW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aot_ts_nvfuser',\n",
              " 'cudagraphs',\n",
              " 'inductor',\n",
              " 'ipex',\n",
              " 'nvprims_nvfuser',\n",
              " 'onnxrt',\n",
              " 'tensorrt',\n",
              " 'tvm']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optimizer() usage with inductor as backend"
      ],
      "metadata": {
        "id": "kl3vIxtD-3_5"
      },
      "id": "kl3vIxtD-3_5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A naive example"
      ],
      "metadata": {
        "id": "M96heyoMA-h0"
      },
      "id": "M96heyoMA-h0"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    x = F.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "SyuoQza--7Os"
      },
      "id": "SyuoQza--7Os",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._inductor import config as inductor_config\n",
        "from torch._dynamo import config as dynamo_config\n",
        "\n",
        "inductor_config.debug = True\n",
        "dynamo_config.verbose = True"
      ],
      "metadata": {
        "id": "45WebTphE2dh"
      },
      "id": "45WebTphE2dh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo = Net()\n",
        "foo = torch.compile(foo)"
      ],
      "metadata": {
        "id": "TIW9R-cGBDJc"
      },
      "id": "TIW9R-cGBDJc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhuU13T3BL8j",
        "outputId": "084bdb35-fd14-4794-f01b-46ac83bc7a38"
      },
      "id": "VhuU13T3BL8j",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): Net(\n",
              "    (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When enable `inductor.debug`, it could dump the python code it codegened."
      ],
      "metadata": {
        "id": "kok22EXnHh1y"
      },
      "id": "kok22EXnHh1y"
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((2, 128))\n",
        "\n",
        "foo(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAvJRtdxD24H",
        "outputId": "b0a42b77-2ccd-4507-b8f7-69796e47e0e4"
      },
      "id": "pAvJRtdxD24H",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-02-24 02:00:07,038] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
            "DEBUG:filelock:Attempting to acquire lock 140315786009520 on /tmp/torchinductor_root/locks/cpqwqezuqcpct4tbqmlhjjp3hbo6hvqmumb4g7x4z3r6m7zzu7wx.lock\n",
            "DEBUG:filelock:Lock 140315786009520 acquired on /tmp/torchinductor_root/locks/cpqwqezuqcpct4tbqmlhjjp3hbo6hvqmumb4g7x4z3r6m7zzu7wx.lock\n",
            "DEBUG:filelock:Attempting to release lock 140315786009520 on /tmp/torchinductor_root/locks/cpqwqezuqcpct4tbqmlhjjp3hbo6hvqmumb4g7x4z3r6m7zzu7wx.lock\n",
            "DEBUG:filelock:Lock 140315786009520 released on /tmp/torchinductor_root/locks/cpqwqezuqcpct4tbqmlhjjp3hbo6hvqmumb4g7x4z3r6m7zzu7wx.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140315784350448 on /tmp/torchinductor_root/locks/cdpfcbmnbo2tiqauemmeoyifop6bs6dplr52qcc4drscewsrxkauciazhaeabewqhtl5n6yhs73v5bs7xy4mhm2p4fkphmc2mhuz7lpa.lock\n",
            "DEBUG:filelock:Lock 140315784350448 acquired on /tmp/torchinductor_root/locks/cdpfcbmnbo2tiqauemmeoyifop6bs6dplr52qcc4drscewsrxkauciazhaeabewqhtl5n6yhs73v5bs7xy4mhm2p4fkphmc2mhuz7lpa.lock\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "from ctypes import c_void_p, c_long\n",
            "import torch\n",
            "import math\n",
            "import random\n",
            "from torch import empty_strided, as_strided, device\n",
            "from torch._inductor.codecache import AsyncCompile\n",
            "from torch._inductor.select_algorithm import extern_kernels\n",
            "\n",
            "aten = torch.ops.aten\n",
            "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
            "async_compile = AsyncCompile()\n",
            "\n",
            "import triton\n",
            "import triton.language as tl\n",
            "from torch._inductor.triton_ops.autotune import grid\n",
            "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
            "\n",
            "\n",
            "kernel_cpp_0 = async_compile.cpp('''\n",
            "#include \"/tmp/torchinductor_root/zt/cztcl2vp5yqlnhofzpqfficjcxgyict6e3xhfdd7sdbkipp4p44x.h\"\n",
            "extern \"C\" void kernel(float* __restrict__ in_out_ptr0,\n",
            "                       bool* __restrict__ out_ptr0)\n",
            "{\n",
            "    {\n",
            "        #pragma GCC ivdep\n",
            "        for(long i0=0; i0<20; i0+=1)\n",
            "        {\n",
            "            auto tmp0 = in_out_ptr0[i0];\n",
            "            auto tmp1 = tmp0 * (tmp0>0);\n",
            "            auto tmp2 = static_cast<float>(0);\n",
            "            auto tmp3 = tmp1 <= tmp2;\n",
            "            in_out_ptr0[i0] = tmp1;\n",
            "            out_ptr0[i0] = tmp3;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "''')\n",
            "\n",
            "\n",
            "async_compile.wait(globals())\n",
            "del async_compile\n",
            "\n",
            "def call(args):\n",
            "    primals_1, primals_2, primals_3 = args\n",
            "    args.clear()\n",
            "    buf0 = empty_strided((2, 10), (10, 1), device='cpu', dtype=torch.float32)\n",
            "    extern_kernels.addmm(primals_2, primals_3, as_strided(primals_1, (128, 10), (1, 128)), alpha=1, beta=1, out=buf0)\n",
            "    del primals_1\n",
            "    del primals_2\n",
            "    buf1 = buf0; del buf0  # reuse\n",
            "    buf2 = empty_strided((2, 10), (10, 1), device='cpu', dtype=torch.bool)\n",
            "    kernel_cpp_0(c_void_p(buf1.data_ptr()), c_void_p(buf2.data_ptr()))\n",
            "    return (buf1, primals_3, buf2, )\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    from torch._dynamo.testing import rand_strided\n",
            "    from torch._inductor.utils import print_performance\n",
            "    primals_1 = rand_strided((10, 128), (128, 1), device='cpu', dtype=torch.float32)\n",
            "    primals_2 = rand_strided((10, ), (1, ), device='cpu', dtype=torch.float32)\n",
            "    primals_3 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)\n",
            "    print_performance(lambda: call([primals_1, primals_2, primals_3]))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140315784350448 on /tmp/torchinductor_root/locks/cdpfcbmnbo2tiqauemmeoyifop6bs6dplr52qcc4drscewsrxkauciazhaeabewqhtl5n6yhs73v5bs7xy4mhm2p4fkphmc2mhuz7lpa.lock\n",
            "DEBUG:filelock:Lock 140315784350448 released on /tmp/torchinductor_root/locks/cdpfcbmnbo2tiqauemmeoyifop6bs6dplr52qcc4drscewsrxkauciazhaeabewqhtl5n6yhs73v5bs7xy4mhm2p4fkphmc2mhuz7lpa.lock\n",
            "[2023-02-24 02:00:14,842] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
            "/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py:1251: UserWarning: Your compiler for AOTAutograd is returning a a function that doesn't take boxed arguments. Please wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. See https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1216, 0.0000, 0.0000, 0.4786, 0.0000, 0.0000, 0.6883, 0.2427, 0.0000,\n",
              "         0.0000],\n",
              "        [0.8512, 0.0000, 0.0000, 0.7956, 0.0000, 0.2226, -0.0000, -0.0000, 0.2839,\n",
              "         -0.0000]], grad_fn=<CompiledFunctionBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dive into dynamo"
      ],
      "metadata": {
        "id": "2sO0MfPoIPc8"
      },
      "id": "2sO0MfPoIPc8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the definition of `_dynamo.optimize`: \n",
        "\n",
        "```python\n",
        "def optimize(\n",
        "    backend=\"inductor\",\n",
        "    *,\n",
        "    nopython=False,\n",
        "    guard_export_fn=None,\n",
        "    guard_fail_fn=None,\n",
        "    disable=False,\n",
        "    dynamic=False,\n",
        "):\n",
        "```\n",
        "\n",
        "The `backend` argument could be either a `str` or a `callable`.\n",
        "Let's hack it with a custom callable to dump something."
      ],
      "metadata": {
        "id": "fx2N_KyVIt2U"
      },
      "id": "fx2N_KyVIt2U"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "16d974c3",
      "metadata": {
        "id": "16d974c3"
      },
      "outputs": [],
      "source": [
        "my_graph_id = 0\n",
        "def my_compiler( \n",
        "        gm: torch.fx.GraphModule,\n",
        "        inputs: List[torch.Tensor]):\n",
        "    global my_graph_id\n",
        "    print(f\"my_compiler() called with FX graph-{my_graph_id}:\")\n",
        "    my_graph_id += 1\n",
        "    gm.print_readable()\n",
        "    print()\n",
        "    #print(\"tabular:\")\n",
        "    #gm.graph.print_tabular(); print()\n",
        "    #print(f\"code: {gm.graph.python_code()}\")\n",
        "    return gm.forward  # python callable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1"
      ],
      "metadata": {
        "id": "WTM6v_bLPc9F"
      },
      "id": "WTM6v_bLPc9F"
    },
    {
      "cell_type": "code",
      "source": [
        "def foo1(a:torch.tensor, b:torch.tensor):\n",
        "  x = a + b\n",
        "  if b.sum() < 0:\n",
        "    x = x * -1\n",
        "  return x\n",
        "\n",
        "foo1_ = optimize(my_compiler)(foo1)"
      ],
      "metadata": {
        "id": "SVObPqF3KLla"
      },
      "id": "SVObPqF3KLla",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, this kernel contains a `if` `if b.sum() < 0`, since the `b.sum()` is determined by its value(dynamic), so it should break the graph into two cases:\n",
        "\n",
        "The first, when the condition is true:\n",
        "\n",
        "```python\n",
        "x = a + b\n",
        "x = x * -1\n",
        "return x\n",
        "```\n",
        "\n",
        "The second, when the condition is false:\n",
        "\n",
        "```python\n",
        "x = a + b\n",
        "return x\n",
        "```"
      ],
      "metadata": {
        "id": "RH6jw-pRKfg6"
      },
      "id": "RH6jw-pRKfg6"
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset() # reset all che compilation cache\n",
        "\n",
        "a = torch.randn((2, 3))\n",
        "b = torch.randn((2, 3))\n",
        "\n",
        "# It should tigger both cases of the if-else\n",
        "foo1_(a, b)\n",
        "foo1_(a, -b)"
      ],
      "metadata": {
        "id": "_0Gp__rxKYRY",
        "outputId": "5cfb88db-322c-409a-f89c-573378fde0f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_0Gp__rxKYRY",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_compiler() called with FX graph:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor, b : torch.Tensor):\n",
            "        # File: <ipython-input-9-dd0c51f20b11>:2, code: x = a + b\n",
            "        add = a + b;  a = None\n",
            "        \n",
            "        # File: <ipython-input-9-dd0c51f20b11>:3, code: if b.sum() < 0:\n",
            "        sum_1 = b.sum();  b = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (add, lt)\n",
            "        \n",
            "\n",
            "tabular:\n",
            "opcode         name    target                   args          kwargs\n",
            "-------------  ------  -----------------------  ------------  --------\n",
            "placeholder    a       a                        ()            {}\n",
            "placeholder    b       b                        ()            {}\n",
            "call_function  add     <built-in function add>  (a, b)        {}\n",
            "call_method    sum_1   sum                      (b,)          {}\n",
            "call_function  lt      <built-in function lt>   (sum_1, 0)    {}\n",
            "output         output  output                   ((add, lt),)  {}\n",
            "\n",
            "my_compiler() called with FX graph:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, x : torch.Tensor):\n",
            "        # File: <ipython-input-9-dd0c51f20b11>:4, code: x = x * -1\n",
            "        mul = x * -1;  x = None\n",
            "        return (mul,)\n",
            "        \n",
            "\n",
            "tabular:\n",
            "opcode         name    target                   args       kwargs\n",
            "-------------  ------  -----------------------  ---------  --------\n",
            "placeholder    x       x                        ()         {}\n",
            "call_function  mul     <built-in function mul>  (x, -1)    {}\n",
            "output         output  output                   ((mul,),)  {}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8036, -0.5172, -0.2097],\n",
              "        [ 0.0542,  2.3458,  0.0871]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the exaple above, it do break into two graphs, but not from expected:\n",
        "\n",
        "- graph1: the expressions before the if, with the condition computation\n",
        "- graph2: the expressions after the if"
      ],
      "metadata": {
        "id": "JyKD7EnHQY4T"
      },
      "id": "JyKD7EnHQY4T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2"
      ],
      "metadata": {
        "id": "tWRo8thZPiTT"
      },
      "id": "tWRo8thZPiTT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute once case"
      ],
      "metadata": {
        "id": "KZCajhxNXhEd"
      },
      "id": "KZCajhxNXhEd"
    },
    {
      "cell_type": "code",
      "source": [
        "def foo2(a:torch.tensor, b:torch.tensor):\n",
        "  x = a + b\n",
        "  if b.sum() < 0:\n",
        "    x = x * -1\n",
        "  if a.sum() < 0:\n",
        "    x = x * -1\n",
        "  x = 2 * x\n",
        "  return x\n",
        "\n",
        "foo2_ = optimize(my_compiler)(foo2)"
      ],
      "metadata": {
        "id": "24StYyTRPlH_"
      },
      "execution_count": 43,
      "outputs": [],
      "id": "24StYyTRPlH_"
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset() # reset all che compilation cache\n",
        "my_graph_id = 0\n",
        "\n",
        "a = torch.ones((2, 3))\n",
        "b = torch.ones((2, 3))\n",
        "\n",
        "# It should tigger only one case of the if-else\n",
        "foo2_(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zKWsiCFP08s",
        "outputId": "883c4a8d-e589-4ca5-b7da-fdf5b96d671e"
      },
      "id": "5zKWsiCFP08s",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_compiler() called with FX graph-0:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor, b : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:2, code: x = a + b\n",
            "        add = a + b;  a = None\n",
            "        \n",
            "        # File: <ipython-input-43-f6e4dc936826>:3, code: if b.sum() < 0:\n",
            "        sum_1 = b.sum();  b = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (add, lt)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-1:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:5, code: if a.sum() < 0:\n",
            "        sum_1 = a.sum();  a = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (lt,)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-2:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, x : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:7, code: x = 2 * x\n",
            "        mul = 2 * x;  x = None\n",
            "        return (mul,)\n",
            "        \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 4., 4.],\n",
              "        [4., 4., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exectue all the cases"
      ],
      "metadata": {
        "id": "gS_r-Wf-XlzO"
      },
      "id": "gS_r-Wf-XlzO"
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset() # reset all che compilation cache\n",
        "my_graph_id = 0\n",
        "\n",
        "# It should tigger all the four combinations of the if-conditions\n",
        "foo2_(a, b)\n",
        "foo2_(a, -b)\n",
        "foo2_(-a, b)\n",
        "foo2_(-a, -b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnsXks_iUy3K",
        "outputId": "c7ca2e17-4a49-49d4-f98c-0fbc1ec6795e"
      },
      "id": "bnsXks_iUy3K",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_compiler() called with FX graph-0:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor, b : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:2, code: x = a + b\n",
            "        add = a + b;  a = None\n",
            "        \n",
            "        # File: <ipython-input-43-f6e4dc936826>:3, code: if b.sum() < 0:\n",
            "        sum_1 = b.sum();  b = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (add, lt)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-1:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:5, code: if a.sum() < 0:\n",
            "        sum_1 = a.sum();  a = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (lt,)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-2:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, x : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:7, code: x = 2 * x\n",
            "        mul = 2 * x;  x = None\n",
            "        return (mul,)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-3:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor, x : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:4, code: x = x * -1\n",
            "        mul = x * -1;  x = None\n",
            "        \n",
            "        # File: <ipython-input-43-f6e4dc936826>:5, code: if a.sum() < 0:\n",
            "        sum_1 = a.sum();  a = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (mul, lt)\n",
            "        \n",
            "\n",
            "my_compiler() called with FX graph-4:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, x : torch.Tensor):\n",
            "        # File: <ipython-input-43-f6e4dc936826>:6, code: x = x * -1\n",
            "        mul = x * -1;  x = None\n",
            "        \n",
            "        # File: <ipython-input-43-f6e4dc936826>:7, code: x = 2 * x\n",
            "        mul_1 = 2 * mul;  mul = None\n",
            "        return (mul_1,)\n",
            "        \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4., -4., -4.],\n",
              "        [-4., -4., -4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch._dynamo.reset() # reset all che compilation cache\n",
        "my_graph_id = 0\n",
        "\n",
        "a = torch.randn((2, 3))\n",
        "b = torch.randn((2, 3))\n",
        "\n",
        "# It should tigger only one case of the if-else\n",
        "foo2_(a, b)"
      ],
      "metadata": {
        "outputId": "daf6add5-3292-4fb2-f1f4-230517d4f211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8oFkOuYVEmk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_compiler() called with FX graph-0:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor, b : torch.Tensor):\n",
            "        # File: <ipython-input-24-9cf32d8775c0>:2, code: x = a + b\n",
            "        add = a + b;  a = None\n",
            "        \n",
            "        # File: <ipython-input-24-9cf32d8775c0>:3, code: if b.sum() < 0:\n",
            "        sum_1 = b.sum();  b = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (add, lt)\n",
            "        \n",
            "\n",
            "tabular:\n",
            "opcode         name    target                   args          kwargs\n",
            "-------------  ------  -----------------------  ------------  --------\n",
            "placeholder    a       a                        ()            {}\n",
            "placeholder    b       b                        ()            {}\n",
            "call_function  add     <built-in function add>  (a, b)        {}\n",
            "call_method    sum_1   sum                      (b,)          {}\n",
            "call_function  lt      <built-in function lt>   (sum_1, 0)    {}\n",
            "output         output  output                   ((add, lt),)  {}\n",
            "\n",
            "my_compiler() called with FX graph-1:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, a : torch.Tensor):\n",
            "        # File: <ipython-input-24-9cf32d8775c0>:5, code: if a.sum() < 0:\n",
            "        sum_1 = a.sum();  a = None\n",
            "        lt = sum_1 < 0;  sum_1 = None\n",
            "        return (lt,)\n",
            "        \n",
            "\n",
            "tabular:\n",
            "opcode         name    target                  args        kwargs\n",
            "-------------  ------  ----------------------  ----------  --------\n",
            "placeholder    a       a                       ()          {}\n",
            "call_method    sum_1   sum                     (a,)        {}\n",
            "call_function  lt      <built-in function lt>  (sum_1, 0)  {}\n",
            "output         output  output                  ((lt,),)    {}\n",
            "\n",
            "my_compiler() called with FX graph-2:\n",
            "class GraphModule(torch.nn.Module):\n",
            "    def forward(self, x : torch.Tensor):\n",
            "        # File: <ipython-input-24-9cf32d8775c0>:6, code: x = x * -1\n",
            "        mul = x * -1;  x = None\n",
            "        return (mul,)\n",
            "        \n",
            "\n",
            "tabular:\n",
            "opcode         name    target                   args       kwargs\n",
            "-------------  ------  -----------------------  ---------  --------\n",
            "placeholder    x       x                        ()         {}\n",
            "call_function  mul     <built-in function mul>  (x, -1)    {}\n",
            "output         output  output                   ((mul,),)  {}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3537, -0.0531,  0.9512],\n",
              "        [-1.3276,  1.3997, -0.3662]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "id": "t8oFkOuYVEmk"
    },
    {
      "cell_type": "markdown",
      "id": "8d1a562b",
      "metadata": {
        "id": "8d1a562b"
      },
      "source": [
        "## Non-torch function call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "478f5710",
      "metadata": {
        "id": "478f5710"
      },
      "outputs": [],
      "source": [
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f5691731",
      "metadata": {
        "id": "f5691731",
        "outputId": "9c54463f-3e95-4e6c-de6e-d2509e318019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    func(a, b)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "def func(a, b):\n",
        "    import numpy as np\n",
        "    aa = np.randn((2,3))\n",
        "    sum = a + b\n",
        "    return sum.numpy() + aa\n",
        "    return aa\n",
        "\n",
        "  func(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45ea114",
      "metadata": {
        "id": "a45ea114"
      },
      "outputs": [],
      "source": [
        "torch._dynamo.reset()\n",
        "torch._dynamo.config.verbose=True\n",
        "func = optimize(my_compiler)(draw_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e73bc9",
      "metadata": {
        "id": "45e73bc9",
        "outputId": "1fecdb66-bc92-44ac-f1da-fe9373c56a74"
      },
      "outputs": [
        {
          "ename": "InternalTorchDynamoError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:324\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     orig_code_map[out_code] \u001b[38;5;241m=\u001b[39m code\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py:445\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    443\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:311\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    299\u001b[0m tracer \u001b[38;5;241m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    300\u001b[0m     instructions,\n\u001b[1;32m    301\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m output \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39moutput\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1738\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1737\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo start tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1738\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:588\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m ):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:552\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m     unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1042\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.LOAD_ATTR\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1041\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m-> 1042\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mBuiltinVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstantVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(result)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/builtin.py:566\u001b[0m, in \u001b[0;36mBuiltinVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/builtin.py:971\u001b[0m, in \u001b[0;36mBuiltinVariable.call_getattr\u001b[0;34m(self, tx, obj, name_var, default)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (PythonModuleVariable, DummyModule)):\n\u001b[0;32m--> 971\u001b[0m     member \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mreplay_record_enabled:\n",
            "\u001b[0;31mKeyError\u001b[0m: randn\n\nfrom user code:\n   File \"/tmp/ipykernel_2032177/1399088902.py\", line 3, in draw_example\n    aa = np.randn((2,3))\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInternalTorchDynamoError\u001b[0m                  Traceback (most recent call last)",
            "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:337\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:404\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:104\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mgraph_module\u001b[38;5;241m.\u001b[39m_forward_from_src \u001b[38;5;241m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:262\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    260\u001b[0m initial_grad_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:394\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    393\u001b[0m     exception_handler(e, code, frame)\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mInternalTorchDynamoError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "func(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e5476a",
      "metadata": {
        "id": "e8e5476a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}