{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a08a3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.validation import check_array,check_consistent_length\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from scipy import sparse as sp\n",
    "from math import log\n",
    "def contingency_matrix(\n",
    "    labels_true, labels_pred, *, eps=None, sparse=False, dtype=np.int64\n",
    "):\n",
    "    \"\"\"Build a contingency matrix describing the relationship between labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_true : array-like of shape (n_samples,)\n",
    "        Ground truth class labels to be used as a reference.\n",
    "\n",
    "    labels_pred : array-like of shape (n_samples,)\n",
    "        Cluster labels to evaluate.\n",
    "\n",
    "    eps : float, default=None\n",
    "        If a float, that value is added to all values in the contingency\n",
    "        matrix. This helps to stop NaN propagation.\n",
    "        If ``None``, nothing is adjusted.\n",
    "\n",
    "    sparse : bool, default=False\n",
    "        If `True`, return a sparse CSR continency matrix. If `eps` is not\n",
    "        `None` and `sparse` is `True` will raise ValueError.\n",
    "\n",
    "        .. versionadded:: 0.18\n",
    "\n",
    "    dtype : numeric type, default=np.int64\n",
    "        Output dtype. Ignored if `eps` is not `None`.\n",
    "\n",
    "        .. versionadded:: 0.24\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    contingency : {array-like, sparse}, shape=[n_classes_true, n_classes_pred]\n",
    "        Matrix :math:`C` such that :math:`C_{i, j}` is the number of samples in\n",
    "        true class :math:`i` and in predicted class :math:`j`. If\n",
    "        ``eps is None``, the dtype of this array will be integer unless set\n",
    "        otherwise with the ``dtype`` argument. If ``eps`` is given, the dtype\n",
    "        will be float.\n",
    "        Will be a ``sklearn.sparse.csr_matrix`` if ``sparse=True``.\n",
    "    \"\"\"\n",
    "\n",
    "    if eps is not None and sparse:\n",
    "        raise ValueError(\"Cannot set 'eps' when sparse=True\")\n",
    "\n",
    "    classes, class_idx = np.unique(labels_true, return_inverse=True)\n",
    "    clusters, cluster_idx = np.unique(labels_pred, return_inverse=True)\n",
    "    n_classes = classes.shape[0]\n",
    "    n_clusters = clusters.shape[0]\n",
    "    # Using coo_matrix to accelerate simple histogram calculation,\n",
    "    # i.e. bins are consecutive integers\n",
    "    # Currently, coo_matrix is faster than histogram2d for simple cases\n",
    "    contingency = sp.coo_matrix(\n",
    "        (np.ones(class_idx.shape[0]), (class_idx, cluster_idx)),\n",
    "        shape=(n_classes, n_clusters),\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    if sparse:\n",
    "        contingency = contingency.tocsr()\n",
    "        contingency.sum_duplicates()\n",
    "    else:\n",
    "        contingency = contingency.toarray()\n",
    "        if eps is not None:\n",
    "            # don't use += as contingency is integer\n",
    "            contingency = contingency + eps\n",
    "    return contingency\n",
    "\n",
    "def check_clusterings(labels_true, labels_pred):\n",
    "    \"\"\"Check that the labels arrays are 1D and of same dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_true : array-like of shape (n_samples,)\n",
    "        The true labels.\n",
    "\n",
    "    labels_pred : array-like of shape (n_samples,)\n",
    "        The predicted labels.\n",
    "    \"\"\"\n",
    "    labels_true = check_array(\n",
    "        labels_true,\n",
    "        ensure_2d=False,\n",
    "        ensure_min_samples=0,\n",
    "        dtype=None,\n",
    "    )\n",
    "\n",
    "    labels_pred = check_array(\n",
    "        labels_pred,\n",
    "        ensure_2d=False,\n",
    "        ensure_min_samples=0,\n",
    "        dtype=None,\n",
    "    )\n",
    "\n",
    "    type_label = type_of_target(labels_true)\n",
    "    type_pred = type_of_target(labels_pred)\n",
    "\n",
    "    if \"continuous\" in (type_pred, type_label):\n",
    "        msg = (\n",
    "            \"Clustering metrics expects discrete values but received\"\n",
    "            f\" {type_label} values for label, and {type_pred} values \"\n",
    "            \"for target\"\n",
    "        )\n",
    "        warnings.warn(msg, UserWarning)\n",
    "\n",
    "    # input checks\n",
    "    if labels_true.ndim != 1:\n",
    "        raise ValueError(\"labels_true must be 1D: shape is %r\" % (labels_true.shape,))\n",
    "    if labels_pred.ndim != 1:\n",
    "        raise ValueError(\"labels_pred must be 1D: shape is %r\" % (labels_pred.shape,))\n",
    "    check_consistent_length(labels_true, labels_pred)\n",
    "\n",
    "    return labels_true, labels_pred\n",
    "\n",
    "def mutual_info_score(labels_true, labels_pred, *, contingency=None):\n",
    "    \"\"\"Mutual Information between two clusterings.\n",
    "\n",
    "    The Mutual Information is a measure of the similarity between two labels\n",
    "    of the same data. Where :math:`|U_i|` is the number of the samples\n",
    "    in cluster :math:`U_i` and :math:`|V_j|` is the number of the\n",
    "    samples in cluster :math:`V_j`, the Mutual Information\n",
    "    between clusterings :math:`U` and :math:`V` is given as:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        MI(U,V)=\\\\sum_{i=1}^{|U|} \\\\sum_{j=1}^{|V|} \\\\frac{|U_i\\\\cap V_j|}{N}\n",
    "        \\\\log\\\\frac{N|U_i \\\\cap V_j|}{|U_i||V_j|}\n",
    "\n",
    "    This metric is independent of the absolute values of the labels:\n",
    "    a permutation of the class or cluster label values won't change the\n",
    "    score value in any way.\n",
    "\n",
    "    This metric is furthermore symmetric: switching :math:`U` (i.e\n",
    "    ``label_true``) with :math:`V` (i.e. ``label_pred``) will return the\n",
    "    same score value. This can be useful to measure the agreement of two\n",
    "    independent label assignments strategies on the same dataset when the\n",
    "    real ground truth is not known.\n",
    "\n",
    "    Read more in the :ref:`User Guide <mutual_info_score>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_true : array-like of shape (n_samples,), dtype=integral\n",
    "        A clustering of the data into disjoint subsets, called :math:`U` in\n",
    "        the above formula.\n",
    "\n",
    "    labels_pred : array-like of shape (n_samples,), dtype=integral\n",
    "        A clustering of the data into disjoint subsets, called :math:`V` in\n",
    "        the above formula.\n",
    "\n",
    "    contingency : {array-like, sparse matrix} of shape \\\n",
    "            (n_classes_true, n_classes_pred), default=None\n",
    "        A contingency matrix given by the\n",
    "        :func:`~sklearn.metrics.cluster.contingency_matrix` function. If value\n",
    "        is ``None``, it will be computed, otherwise the given value is used,\n",
    "        with ``labels_true`` and ``labels_pred`` ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mi : float\n",
    "       Mutual information, a non-negative value, measured in nats using the\n",
    "       natural logarithm.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    adjusted_mutual_info_score : Adjusted against chance Mutual Information.\n",
    "    normalized_mutual_info_score : Normalized Mutual Information.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The logarithm used is the natural logarithm (base-e).\n",
    "    \"\"\"\n",
    "    if contingency is None:\n",
    "        labels_true, labels_pred = check_clusterings(labels_true, labels_pred)\n",
    "        contingency = contingency_matrix(labels_true, labels_pred, sparse=True)\n",
    "    else:\n",
    "        contingency = check_array(\n",
    "            contingency,\n",
    "            accept_sparse=[\"csr\", \"csc\", \"coo\"],\n",
    "            dtype=[int, np.int32, np.int64],\n",
    "        )\n",
    "\n",
    "    if isinstance(contingency, np.ndarray):\n",
    "        # For an array\n",
    "        nzx, nzy = np.nonzero(contingency)\n",
    "        nz_val = contingency[nzx, nzy]\n",
    "    else:\n",
    "        # For a sparse matrix\n",
    "        nzx, nzy, nz_val = sp.find(contingency)\n",
    "\n",
    "    contingency_sum = contingency.sum()\n",
    "    pi = np.ravel(contingency.sum(axis=1))\n",
    "    pj = np.ravel(contingency.sum(axis=0))\n",
    "    print(pi)\n",
    "    print(pj)\n",
    "    # Since MI <= min(H(X), H(Y)), any labelling with zero entropy, i.e. containing a\n",
    "    # single cluster, implies MI = 0\n",
    "    if pi.size == 1 or pj.size == 1:\n",
    "        return 0.0\n",
    "\n",
    "    log_contingency_nm = np.log(nz_val)\n",
    "    contingency_nm = nz_val / contingency_sum\n",
    "    # Don't need to calculate the full outer product, just for non-zeroes\n",
    "    outer = pi.take(nzx).astype(np.int64, copy=False) * pj.take(nzy).astype(\n",
    "        np.int64, copy=False\n",
    "    )\n",
    "    log_outer = -np.log(outer) + log(pi.sum()) + log(pj.sum())\n",
    "\n",
    "    mi = (\n",
    "        contingency_nm * (log_contingency_nm - log(contingency_sum))\n",
    "        + contingency_nm * log_outer\n",
    "    )\n",
    "   \n",
    "    mi = np.where(np.abs(mi) < np.finfo(mi.dtype).eps, 0.0, mi)\n",
    "    return np.clip(mi.sum(), 0.0, None)\n",
    "\n",
    "\n",
    "def normalized_mutual_info_score(\n",
    "    labels_true, labels_pred, *, average_method=\"arithmetic\"\n",
    "):\n",
    "    \"\"\"Normalized Mutual Information between two clusterings.\n",
    "\n",
    "    Normalized Mutual Information (NMI) is a normalization of the Mutual\n",
    "    Information (MI) score to scale the results between 0 (no mutual\n",
    "    information) and 1 (perfect correlation). In this function, mutual\n",
    "    information is normalized by some generalized mean of ``H(labels_true)``\n",
    "    and ``H(labels_pred))``, defined by the `average_method`.\n",
    "\n",
    "    This measure is not adjusted for chance. Therefore\n",
    "    :func:`adjusted_mutual_info_score` might be preferred.\n",
    "\n",
    "    This metric is independent of the absolute values of the labels:\n",
    "    a permutation of the class or cluster label values won't change the\n",
    "    score value in any way.\n",
    "\n",
    "    This metric is furthermore symmetric: switching ``label_true`` with\n",
    "    ``label_pred`` will return the same score value. This can be useful to\n",
    "    measure the agreement of two independent label assignments strategies\n",
    "    on the same dataset when the real ground truth is not known.\n",
    "\n",
    "    Read more in the :ref:`User Guide <mutual_info_score>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_true : int array-like of shape (n_samples,)\n",
    "        A clustering of the data into disjoint subsets.\n",
    "\n",
    "    labels_pred : int array-like of shape (n_samples,)\n",
    "        A clustering of the data into disjoint subsets.\n",
    "\n",
    "    average_method : {'min', 'geometric', 'arithmetic', 'max'}, default='arithmetic'\n",
    "        How to compute the normalizer in the denominator.\n",
    "\n",
    "        .. versionadded:: 0.20\n",
    "\n",
    "        .. versionchanged:: 0.22\n",
    "           The default value of ``average_method`` changed from 'geometric' to\n",
    "           'arithmetic'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nmi : float\n",
    "       Score between 0.0 and 1.0 in normalized nats (based on the natural\n",
    "       logarithm). 1.0 stands for perfectly complete labeling.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    v_measure_score : V-Measure (NMI with arithmetic mean option).\n",
    "    adjusted_rand_score : Adjusted Rand Index.\n",
    "    adjusted_mutual_info_score : Adjusted Mutual Information (adjusted\n",
    "        against chance).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    Perfect labelings are both homogeneous and complete, hence have\n",
    "    score 1.0::\n",
    "\n",
    "      >>> from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "      >>> normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
    "      ... # doctest: +SKIP\n",
    "      1.0\n",
    "      >>> normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
    "      ... # doctest: +SKIP\n",
    "      1.0\n",
    "\n",
    "    If classes members are completely split across different clusters,\n",
    "    the assignment is totally in-complete, hence the NMI is null::\n",
    "\n",
    "      >>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
    "      ... # doctest: +SKIP\n",
    "      0.0\n",
    "    \"\"\"\n",
    "    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)\n",
    "    classes = np.unique(labels_true)\n",
    "    clusters = np.unique(labels_pred)\n",
    "    # Special limit cases: no clustering since the data is not split.\n",
    "    # It corresponds to both labellings having zero entropy.\n",
    "    # This is a perfect match hence return 1.0.\n",
    "    if (\n",
    "        classes.shape[0] == clusters.shape[0] == 1\n",
    "        or classes.shape[0] == clusters.shape[0] == 0\n",
    "    ):\n",
    "        return 1.0\n",
    "\n",
    "    contingency = contingency_matrix(labels_true, labels_pred, sparse=True)\n",
    "    contingency = contingency.astype(np.float64, copy=False)\n",
    "    # Calculate the MI for the two clusterings\n",
    "    mi = mutual_info_score(labels_true, labels_pred, contingency=contingency)\n",
    "    #print(labels_true)\n",
    "   # print(labels_pred)\n",
    "    # At this point mi = 0 can't be a perfect match (the special case of a single\n",
    "    # cluster has been dealt with before). Hence, if mi = 0, the nmi must be 0 whatever\n",
    "    # the normalization.\n",
    "   \n",
    "    if mi == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate entropy for each labeling\n",
    "    h_true, h_pred = entropy(labels_true), entropy(labels_pred)\n",
    "\n",
    "    normalizer = _generalized_average(h_true, h_pred, average_method)\n",
    "    \n",
    "    return mi / normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1b01d34",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2254884474.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[56], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    n_labels = len(labels)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def entropy2(labels):\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    # Compute standard entropy.\n",
    "    for i in probs:\n",
    "        ent -= i * log(i, base=n_classes)\n",
    "\n",
    "    return ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35422459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1]\n",
      "[6]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a =[0,1,2,3,4,5]\n",
    "b =[5,5,5,5,5,5]\n",
    "c = normalized_mutual_info_score(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0edc7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto\n",
      "True\n",
      "True\n",
      "A.sum() 0\n",
      "nan\n",
      "A.sum() 6\n",
      "1.4591479170272448\n",
      "A.sum() 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooli\\AppData\\Local\\Temp\\ipykernel_6796\\977389363.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  pA = A / A.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a =[0,1,2,3,4,5]\n",
    "b =[5,5,5,5,5,5]\n",
    "\n",
    "[0, 0, 0, 0]\n",
    "[0, 1, 2, 3]\n",
    "\n",
    "def shannon_entropy(A, mode=\"auto\", verbose=False):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/42683287/python-numpy-shannon-entropy-array\n",
    "    \"\"\"\n",
    "    A = np.asarray(A)\n",
    "\n",
    "    # Determine distribution type\n",
    "    if mode == \"auto\":\n",
    "        condition = np.all(A.astype(float) == A.astype(int))\n",
    "        print(condition)\n",
    "        if condition:\n",
    "            mode = \"discrete\"\n",
    "        else:\n",
    "            mode = \"continuous\"\n",
    "    if verbose:\n",
    "        print(mode, file=sys.stderr)\n",
    "    # Compute shannon entropy\n",
    "    pA = A / A.sum()\n",
    "    print(f\"A.sum() {A.sum()}\")\n",
    "    # Remove zeros\n",
    "    pA = pA[np.nonzero(pA)[0]]\n",
    "    if mode == \"continuous\":\n",
    "        return -np.sum(pA*np.log2(A))  \n",
    "    if mode == \"discrete\":\n",
    "        return -np.sum(pA*np.log2(pA))   \n",
    "\n",
    "def mutual_information(x,y, mode=\"auto\", normalized=False):\n",
    "    \"\"\"\n",
    "    I(X, Y) = H(X) + H(Y) - H(X,Y)\n",
    "    https://stackoverflow.com/questions/20491028/optimal-way-to-compute-pairwise-mutual-information-using-numpy\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    # Determine distribution type\n",
    "    print(mode)\n",
    "    if mode == \"auto\":\n",
    "        condition_1 = np.all(x.astype(float) == x.astype(int))\n",
    "        condition_2 = np.all(y.astype(float) == y.astype(int))\n",
    "        print(condition_1)\n",
    "        print(condition_2)\n",
    "        if all([condition_1, condition_2]):\n",
    "            mode = \"discrete\"\n",
    "        else:\n",
    "            mode = \"continuous\"\n",
    "\n",
    "    H_x = shannon_entropy(x, mode=mode)\n",
    "    print(H_x)\n",
    "    H_y = shannon_entropy(y, mode=mode)\n",
    "    print(H_y)\n",
    "    H_xy = shannon_entropy(np.concatenate([x,y]), mode=mode)\n",
    "\n",
    "    # Mutual Information\n",
    "    I_xy = H_x + H_y - H_xy\n",
    "    if normalized:\n",
    "        return I_xy/np.sqrt(H_x*H_y)\n",
    "    else:\n",
    "        return  I_xy\n",
    "    \n",
    "mutual_information([0, 0, 0, 0],[0, 1, 2, 3],normalized =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf943e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f7acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SOM\n",
      "{'0': {'3', 'c', 'b', 'a'}, '1': {'6', 'd'}}\n",
      "{'0': {'c', 'b', 'a'}, '1': {'3', 'd'}, '2': {'6'}}\n",
      "The mutual information of the two covers is 0.4920936619047235\n"
     ]
    }
   ],
   "source": [
    "from sys import argv\n",
    "from math import log\n",
    "import os\n",
    "print(os.getcwd())\n",
    "S = 0\n",
    "\n",
    "def read_cover(filename):\n",
    "    cover = {}\n",
    "    global S\n",
    "    nodes = set()\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            node, c = line.split()\n",
    "            nodes.add(node)\n",
    "            if c not in cover:\n",
    "                cover[c] = set([node])\n",
    "            else:\n",
    "                cover[c].add(node)\n",
    "    S = len(nodes)\n",
    "    return cover, nodes\n",
    "\n",
    "def mutual_info(c_A, c_B):\n",
    "    print(c_A) \n",
    "    print(c_B)\n",
    "    N_mA = len(c_A)\n",
    "    N_mB = len(c_B)\n",
    "    I_num = 0\n",
    "    for i in c_A:\n",
    "        for j in c_B:\n",
    "            n_i = len(c_A[i])\n",
    "            n_j = len(c_B[j])\n",
    "            n_ij = len(c_A[i] & c_B[j])\n",
    "            if n_ij == 0:\n",
    "                continue\n",
    "            log_term = log((n_ij * S) / (n_i * n_j))\n",
    "\n",
    "            I_num += n_ij * log_term\n",
    "    I_num *= -2\n",
    "\n",
    "    I_den = 0\n",
    "    for i in c_A:\n",
    "        n_i = len(c_A[i])\n",
    "        I_den += n_i * log(n_i / S)\n",
    "\n",
    "    for j in c_B:\n",
    "        n_j = len(c_B[j])\n",
    "        I_den += n_j * log(n_j / S)\n",
    "\n",
    "    I = I_num / I_den\n",
    "    return I\n",
    "\n",
    "def main():\n",
    "    if len(argv) < 3:\n",
    "        print('Enter the filename of the two covers as command line args')\n",
    "        return\n",
    "\n",
    "    c_A, nodes_A = read_cover(\"cover1\")\n",
    "    c_B, nodes_B = read_cover(\"cover2\")\n",
    "    \n",
    "   #if nodes_A == nodes_B:\n",
    "   #    print('Improper covers! Please check the inputs.')\n",
    "   #    return\n",
    "    I = mutual_info(c_A, c_B)\n",
    "    print('The mutual information of the two covers is {}'.format(I))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import newSom \n",
    "import importlib\n",
    "importlib.reload(newSom)\n",
    "import experiment\n",
    "import dataset_read\n",
    "import researchpy as rp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e98fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jupyter-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataread = dataset_read.DATAREAD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"CustomerSegmentation/Train.csv\")\n",
    "csv2 = pd.read_csv(\"CustomerSegmentation/Test.csv\")\n",
    "csv = csv.drop(columns=['ID','Segmentation'])\n",
    "csv2 = csv2.drop(columns=['ID'])   \n",
    "\n",
    "csv['Family_Size'] = pd.to_numeric(csv['Family_Size'])\n",
    "csv2['Family_Size'] = pd.to_numeric(csv2['Family_Size'])\n",
    "csv['Work_Experience'] = pd.to_numeric(csv['Work_Experience'])\n",
    "csv2['Work_Experience'] = pd.to_numeric(csv2['Work_Experience'])\n",
    "\n",
    "csv_original_encode1 = csv\n",
    "csv_original_encode2 = csv2\n",
    "\n",
    "# class label do not need to onehot encoding, label ercoding will be OK\n",
    "dataread.label_encoding(csv_original_encode1,\"Var_1\")\n",
    "#one hot encoding vs proposed\n",
    "dataread.effect_encoding(csv_original_encode1,[\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\",\"Family_Size\",\"Work_Experience\"])\n",
    "\n",
    "\n",
    "csv_training_original_encoded = dataread.original_encoding_data.sample(int(dataread.original_encoding_data.shape[0]*0.5))\n",
    "\n",
    "\n",
    "dataread.label_encoding(csv_original_encode2,\"Var_1\")\n",
    "#one hot encoding vs proposed\n",
    "dataread.effect_encoding(csv_original_encode2,[\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\",\"Family_Size\",\"Work_Experience\"])\n",
    "\n",
    "#dataread.original_encoding_data is udpated through dataread.label_encoding function\n",
    "csv_test_original_encoded = dataread.original_encoding_data\n",
    "\n",
    "dataread.label_encoding(csv,\"Gender\")\n",
    "dataread.label_encoding(csv,\"Ever_Married\")\n",
    "dataread.label_encoding(csv,\"Graduated\")\n",
    "dataread.label_encoding(csv,\"Profession\")\n",
    "dataread.label_encoding(csv,\"Spending_Score\")\n",
    "dataread.label_encoding(csv,\"Var_1\")\n",
    "dataread.label_encoding(csv,\"Family_Size\")\n",
    "dataread.label_encoding(csv,\"Work_Experience\")\n",
    "\n",
    "\n",
    "\n",
    "dataread.label_encoding(csv2,\"Gender\")\n",
    "dataread.label_encoding(csv2,\"Ever_Married\")\n",
    "dataread.label_encoding(csv2,\"Graduated\")\n",
    "dataread.label_encoding(csv2,\"Profession\")\n",
    "dataread.label_encoding(csv2,\"Spending_Score\")\n",
    "dataread.label_encoding(csv2,\"Var_1\")\n",
    "dataread.label_encoding(csv2,\"Family_Size\")\n",
    "dataread.label_encoding(csv2,\"Work_Experience\")\n",
    "\n",
    "\n",
    "\n",
    "csv_training = csv.sample(int(csv.shape[0]*0.5))\n",
    "csv_test = csv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataread.initializedataset(csv,csv_training,csv_test,csv_training_original_encoded,csv_test_original_encoded,\"Var_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onhot encoding vs proposed\n",
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,False,class_num,best_num, scope_num,unstable_repeat_num,0,interval,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf83b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
