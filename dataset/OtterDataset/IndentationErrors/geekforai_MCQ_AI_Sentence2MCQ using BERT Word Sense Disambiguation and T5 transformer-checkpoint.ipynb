{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7DFNSwyfFuu"
   },
   "source": [
    "Author: **Ramsri Goutham Golla**  [Linkedin](https://www.linkedin.com/in/ramsrig/)   [Twitter](https://twitter.com/ramsri_goutham/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BERT Word Sense Disambiguation is adapted from the awesome repo here. [BERT WSD](https://github.com/BPYap/BERT-WSD) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvo1s6FWjn6s"
   },
   "source": [
    "## Installation and mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6313,
     "status": "ok",
     "timestamp": 1637230927811,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "T4q45GmGwVbT"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet transformers==2.9.0\n",
    "!pip install --quiet nltk==3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1637230952653,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "w4M6OJHMqxfc",
    "outputId": "6a60f9c3-24d3-4225-c1c3-c2bc7764d6f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# connect your personal google drive to store the trained model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uccuJrda4qay"
   },
   "source": [
    "## Generate distractors (wrong choices) for MCQ options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1637230954328,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "R07mVhsI4w45",
    "outputId": "cfa5edc7-9a55-412b-95d2-3befdffc9d12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Amit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "sentence1 = \"Srivatsan loves to watch cricket during his free time\"\n",
    "sentence2 = \"Srivatsan is annoyed by a cricket in his room\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637230955863,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "MLt3WH3X5gJp",
    "outputId": "e3997adf-545f-4707-a338-71ba277edaf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cricket.n.01') :  leaping insect; male makes chirping noises by rubbing the forewings together \n",
      "\n",
      "Synset('cricket.n.02') :  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An example of a word with two different senses\n",
    "original_word = \"cricket\"\n",
    "\n",
    "syns = wn.synsets(original_word,'n')\n",
    "\n",
    "for syn in syns:\n",
    "  print (syn, \": \",syn.definition(),\"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1637230957228,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "Nsxh1ZjF5d-j",
    "outputId": "01708b74-5948-4265-9489-7861279486dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original word:  Cricket\n",
      "['Grasshopper']\n",
      "Synset('cricket.n.02')\n",
      "cricket\n",
      "\n",
      "original word:  Cricket\n",
      "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n"
     ]
    }
   ],
   "source": [
    "# Distractors from Wordnet\n",
    "def get_distractors_wordnet(syn,word):\n",
    "    distractors=[]\n",
    "    word= word.lower()\n",
    "    orig_word = word\n",
    "    if len(word.split())>0:\n",
    "        word = word.replace(\" \",\"_\")\n",
    "    hypernym = syn.hypernyms()\n",
    "    if len(hypernym) == 0: \n",
    "        return distractors\n",
    "    for item in hypernym[0].hyponyms():\n",
    "        name = item.lemmas()[0].name()\n",
    "        #print (\"name \",name, \" word\",orig_word)\n",
    "        if name == orig_word:\n",
    "            continue\n",
    "        name = name.replace(\"_\",\" \")\n",
    "        name = \" \".join(w.capitalize() for w in name.split())\n",
    "        if name is not None and name not in distractors:\n",
    "            distractors.append(name)\n",
    "    return distractors\n",
    "\n",
    "\n",
    "synset_to_use = wn.synsets(original_word,'n')[0]\n",
    "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
    "\n",
    "print (\"\\noriginal word: \",original_word.capitalize())\n",
    "print (distractors_calculated)\n",
    "\n",
    "\n",
    "original_word = \"cricket\"\n",
    "synset_to_use = wn.synsets(original_word,'n')[1]\n",
    "print(synset_to_use)\n",
    "print(original_word)\n",
    "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
    "\n",
    "print (\"\\noriginal word: \",original_word.capitalize())\n",
    "print (distractors_calculated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neRbWQhO4GnG"
   },
   "source": [
    "## Download pretrained BERT WSD Model and extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rELsk4JIMhJ3"
   },
   "source": [
    "Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\n",
    "\n",
    "Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
    "\n",
    "Place the zip file in your Google drive home folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1637230960751,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "MNz0zFZzrXqN",
    "outputId": "a63810e4-0dc2-4931-95a8-3822693bcadb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "bert_wsd_pytorch = \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
    "extract_directory = \"Bert\"\n",
    "\n",
    "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
    "\n",
    "#  If unzipped folder exists don't unzip again.\n",
    "if not os.path.isdir(extracted_folder):\n",
    "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
    "      zip_ref.extractall(extract_directory)\n",
    "else:\n",
    "  print (extracted_folder,\" is extracted already\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GtYSH2ewtO4"
   },
   "source": [
    "## Find the correct sense (contextual meaning) of a given word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EnmszaP9zSpe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at Bert/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6 were not used when initializing BertWSD: ['similarity_loss_factor', 'similarity_linear.weight', 'similarity_linear.bias', 'ranking_loss_factor']\n",
      "- This IS expected if you are initializing BertWSD from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertWSD from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertWSD(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
    "\n",
    "class BertWSD(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "# def _forward(args, model, batch):\n",
    "#     batch = tuple(t.to(args.device) for t in batch)\n",
    "#     outputs = model.bert(input_ids=batch[0], attention_mask=batch[1], token_type_ids=batch[2])\n",
    "\n",
    "#     return model.dropout(outputs[1])\n",
    "    \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dir = \"Bert/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
    "\n",
    "\n",
    "model = BertWSD.from_pretrained(model_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "# add new special token\n",
    "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
    "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1637231022756,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "I0bWxo4vFUfH",
    "outputId": "8970fbe2-4091-483d-bfc9-2f60f017b126"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Amit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
    "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
    "\n",
    "\n",
    "\n",
    "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
    "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
    "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
    "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
    "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
    "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
    "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
    "        context-example pairs (if available)\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for record in tqdm(records, disable=disable_progress_bar):\n",
    "        tokens_a = tokenizer.tokenize(record.sentence)\n",
    "\n",
    "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
    "\n",
    "        pairs = []\n",
    "        for seq, label in sequences:\n",
    "            tokens_b = tokenizer.tokenize(seq)\n",
    "\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "            # The convention in BERT is:\n",
    "            # (a) For sequence pairs:\n",
    "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "            #\n",
    "            # Where \"type_ids\" are used to indicate whether this is the first\n",
    "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "            # embedding vector (and position vector). This is not *strictly* necessary\n",
    "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "            # it easier for the model to learn the concept of sequences.\n",
    "            #\n",
    "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "            # the entire model is fine-tuned.\n",
    "            tokens = tokens_a + [sep_token]\n",
    "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "            tokens += tokens_b + [sep_token]\n",
    "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
    "\n",
    "            if cls_token_at_end:\n",
    "                tokens = tokens + [cls_token]\n",
    "                segment_ids = segment_ids + [cls_token_segment_id]\n",
    "            else:\n",
    "                tokens = [cls_token] + tokens\n",
    "                segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = max_seq_length - len(input_ids)\n",
    "            if pad_on_left:\n",
    "                input_ids = ([pad_token] * padding_length) + input_ids\n",
    "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            else:\n",
    "                input_ids = input_ids + ([pad_token] * padding_length)\n",
    "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            pairs.append(\n",
    "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
    "            )\n",
    "\n",
    "        features.append(pairs)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM09g5ljMJDp"
   },
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=1rVyHMMl0YoQrQO8aLD54prOIKIlmzwT0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2858,
     "status": "ok",
     "timestamp": 1637231030561,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "wJSpZRuOF-52",
    "outputId": "827bd37c-54ff-4bb2-e55a-b25b06c0564e"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4263864990.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    def extract_word_between_tags(sentence):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pywsd.lesk import simple_lesk\n",
    "\n",
    "def extract_word_between_tags(sentence):\n",
    "    start_tag = \"[TGT]\"\n",
    "    end_tag = \"[TGT]\"\n",
    "\n",
    "    start_index = sentence.find(start_tag) + len(start_tag)\n",
    "    end_index = sentence.find(end_tag, start_index)\n",
    "\n",
    "    if start_index == -1 or end_index == -1:\n",
    "        return None\n",
    "    \n",
    "    word = sentence[start_index:end_index].strip()\n",
    "    return word\n",
    "\n",
    "\n",
    "def get_sense(sentence):\n",
    "    # Extract the ambiguous word within [TGT] tags\n",
    "    answer=extract_word_between_tags(sentence)\n",
    "    re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sentence)\n",
    "    if re_result is None:\n",
    "        print(\"\\nIncorrect input format. Please try again.\")\n",
    "        return None, None\n",
    "\n",
    "    ambiguous_word = re_result.group(1).strip()\n",
    "\n",
    "    # Apply Lesk algorithm to disambiguate the sense\n",
    "    sense = simple_lesk(sentence, ambiguous_word, pos='n')\n",
    "    meaning = sense.definition()\n",
    "\n",
    "    return sense, meaning, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwg3jDQJYKCh"
   },
   "source": [
    "## Generate a question using context and answer with T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAdXVQN8YfED"
   },
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=1Dc6W3F__okw1q6GxhKs46lvgeeBsP0iG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "6a94fafe03024a6eaad37959ae64cc73",
      "142d016eb8214aa28f19be6b4fbca339",
      "1f66d75ab094423d99bb4648b1290698",
      "fae887e257514fbb801c0c5d331f57c6",
      "2de42e44240b463f905735646ec5abfd",
      "e309f41ad5184122a86aec00b02ff626",
      "00a5c4c124024b71818660fc555d916d",
      "6c0840f318024ab9a16fd99fe8767fd3",
      "d3fbc0d0728148e3a08dc882bbfc3ef4",
      "c5aef9f69ad94c0287ee688fdd10bbb3",
      "179becad93544a29b2741191f8bec893",
      "411d08235cbc429283405673051f88c5",
      "ba839dd8d584448e880b1a2a19554d8f",
      "7063e4b4cfc24887a83a354033d20a29",
      "e421731c8412433091e58699d9214628",
      "16678cc9ab1a4ba1bc1da2c8a9bde9b6",
      "704a5be7508e47449bdc1161a5fe8cd4",
      "cd5f9302f6284729857f408842194ea4",
      "07624b5f2dcc40228c6a97a81de3ac3e",
      "4d592c9566f34af9aea2c4d1575fed8d",
      "a18e76af94ab4101bde6ccb1ba1b3da4",
      "6e48c134789c4200a3143b077628faed",
      "9b093515743d4e69b216834573f96602",
      "f910423ef6e143d1a8a7d95be91bd1b3",
      "9dbed6d8b4b04194beb3da32d358927d",
      "f4ab9ebc94d84300a0c13ce2b8c93fea",
      "0ce1aafc7ed94eaca3809367cb9e2696",
      "49fae8c6167b4e2481e73682075e37a6",
      "df4c9d848f5c4e0eb29e098e7695c695",
      "36a27f29392d4083b8e49c16081d59d0",
      "9e6c30f8f75249019d52dd9323421b2e",
      "c729906924654cf5b6ce0f4332db20d9",
      "554bf9faea064f91b95e50a0d45ed377"
     ]
    },
    "executionInfo": {
     "elapsed": 42333,
     "status": "ok",
     "timestamp": 1637231076617,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "wyazTS9RJ46n",
    "outputId": "7ad2f250-a700-4427-f252-ee85b3db18a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Amit\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amit\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Srivatsan loves to watch cricket during his free time answer: cricket </s>\n",
      "<pad>  What sport does Srivatsan enjoy watching?</s>\n",
      "\n",
      "**************************************\n",
      "\n",
      "context: Srivatsan is annoyed by a cricket in his room answer: cricket </s>\n",
      "<pad>  What insect is in Srivatsan's room?</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "def get_question(sentence,answer):\n",
    "  text = \"context: {} answer: {} </s>\".format(sentence,answer)\n",
    "  print (text)\n",
    "  max_len = 512\n",
    "  encoding = question_tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outs = question_model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=200)\n",
    "\n",
    "\n",
    "  dec = [question_tokenizer.decode(ids) for ids in outs]\n",
    "\n",
    "\n",
    "  Question = dec[0].replace(\"question:\",\"\")\n",
    "  Question= Question.strip()\n",
    "  return Question\n",
    "\n",
    "\n",
    "sentence1 = \"Srivatsan loves to watch **cricket** during his free time\"\n",
    "sentence2 = \"Srivatsan is annoyed by a **cricket** in his room\"\n",
    "\n",
    "\n",
    "answer = \"cricket\"\n",
    "\n",
    "sentence_for_T5 = sentence1.replace(\"**\",\" \")\n",
    "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "ques = get_question(sentence_for_T5,answer)\n",
    "print (ques)\n",
    "\n",
    "\n",
    "print (\"\\n**************************************\\n\")\n",
    "sentence_for_T5 = sentence2.replace(\"**\",\" \")\n",
    "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "ques = get_question(sentence_for_T5,answer)\n",
    "print (ques)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jQ1QK_zYCFu"
   },
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10198,
     "status": "ok",
     "timestamp": 1637231089491,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "ZKbPKBjr-KTp",
    "outputId": "f32552c4-7226-4080-dc67-6e79ab5fae52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Synset('cricket.n.02')\n",
      "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
      "<re.Match object; span=(25, 44), match='[TGT] cricket [TGT]'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'re.Match' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ques,answer,distractors,meaning\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m question,answer,distractors,meaning \u001b[38;5;241m=\u001b[39m \u001b[43mgetMCQs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m (question)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m (answer)\n",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m, in \u001b[0;36mgetMCQs\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sense \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m   distractors \u001b[38;5;241m=\u001b[39m \u001b[43mget_distractors_wordnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msense\u001b[49m\u001b[43m,\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m     12\u001b[0m   distractors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord not found in Wordnet. So unable to extract distractors.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mget_distractors_wordnet\u001b[1;34m(syn, word)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_distractors_wordnet\u001b[39m(syn,word):\n\u001b[0;32m      3\u001b[0m     distractors\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 4\u001b[0m     word\u001b[38;5;241m=\u001b[39m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m      5\u001b[0m     orig_word \u001b[38;5;241m=\u001b[39m word\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word\u001b[38;5;241m.\u001b[39msplit())\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 're.Match' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "def getMCQs(sent):\n",
    "  sentence_for_bert = sent.replace(\"**\",\" [TGT] \")\n",
    "  sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
    "  # try:\n",
    "  sense,meaning,answer = get_sense(sentence_for_bert)\n",
    "  print(sense)\n",
    "  print(meaning)\n",
    "  print(answer)\n",
    "  if sense is not None:\n",
    "    distractors = get_distractors_wordnet(sense,answer)\n",
    "  else: \n",
    "    distractors = [\"Word not found in Wordnet. So unable to extract distractors.\"]\n",
    "  sentence_for_T5 = sent.replace(\"**\",\" \")\n",
    "  sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "  ques = get_question(sentence_for_T5,answer)\n",
    "  return ques,answer,distractors,meaning\n",
    "\n",
    "\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence1)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence2)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NI2Y7Qu4eUBq"
   },
   "source": [
    "**Few more examples with disambiguation words (word with contextual meanings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7852,
     "status": "ok",
     "timestamp": 1637231097337,
     "user": {
      "displayName": "Ramsri Goutham",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6-RtlVqaGTKKM6H88RM0th8AtQQX0An95Pvxb5Cg=s64",
      "userId": "00967418115712089730"
     },
     "user_tz": -330
    },
    "id": "gp0Sa7EVdqgf",
    "outputId": "171e8c47-e4b5-4f44-c33a-12c99d848b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "context: John went to river bank to cry answer: bank </s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1432: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beam_id = beam_token_id // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did John go to cry?\n",
      "bank\n",
      "['Ascent', 'Canyonside', 'Coast', 'Descent', 'Escarpment', 'Hillside', 'Mountainside', 'Piedmont', 'Ski Slope']\n",
      "sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "# More examples\n",
    "\n",
    "sentence = \"John went to river **bank** to cry\"\n",
    "# sentence = \"John went to deposit money in the **bank**\"\n",
    "\n",
    "# sentence = \"John bought a **mouse** for his computer.\"\n",
    "# sentence = \"John saw a **mouse** under his bed.\"\n",
    "\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIgV34ynlAi3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfWUmWkH2qjIItFyxxIQmz",
   "collapsed_sections": [],
   "name": "Sentence2MCQ using BERT Word Sense Disambiguation and T5 transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a5c4c124024b71818660fc555d916d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07624b5f2dcc40228c6a97a81de3ac3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ce1aafc7ed94eaca3809367cb9e2696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_554bf9faea064f91b95e50a0d45ed377",
      "placeholder": "​",
      "style": "IPY_MODEL_c729906924654cf5b6ce0f4332db20d9",
      "value": " 792k/792k [00:00&lt;00:00, 1.81MB/s]"
     }
    },
    "142d016eb8214aa28f19be6b4fbca339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16678cc9ab1a4ba1bc1da2c8a9bde9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e48c134789c4200a3143b077628faed",
      "placeholder": "​",
      "style": "IPY_MODEL_a18e76af94ab4101bde6ccb1ba1b3da4",
      "value": " 892M/892M [00:24&lt;00:00, 37.4MB/s]"
     }
    },
    "179becad93544a29b2741191f8bec893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f66d75ab094423d99bb4648b1290698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00a5c4c124024b71818660fc555d916d",
      "placeholder": "​",
      "style": "IPY_MODEL_e309f41ad5184122a86aec00b02ff626",
      "value": "Downloading: 100%"
     }
    },
    "2de42e44240b463f905735646ec5abfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_179becad93544a29b2741191f8bec893",
      "placeholder": "​",
      "style": "IPY_MODEL_c5aef9f69ad94c0287ee688fdd10bbb3",
      "value": " 1.21k/1.21k [00:00&lt;00:00, 21.0kB/s]"
     }
    },
    "36a27f29392d4083b8e49c16081d59d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "411d08235cbc429283405673051f88c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7063e4b4cfc24887a83a354033d20a29",
       "IPY_MODEL_e421731c8412433091e58699d9214628",
       "IPY_MODEL_16678cc9ab1a4ba1bc1da2c8a9bde9b6"
      ],
      "layout": "IPY_MODEL_ba839dd8d584448e880b1a2a19554d8f"
     }
    },
    "49fae8c6167b4e2481e73682075e37a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d592c9566f34af9aea2c4d1575fed8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554bf9faea064f91b95e50a0d45ed377": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a94fafe03024a6eaad37959ae64cc73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f66d75ab094423d99bb4648b1290698",
       "IPY_MODEL_fae887e257514fbb801c0c5d331f57c6",
       "IPY_MODEL_2de42e44240b463f905735646ec5abfd"
      ],
      "layout": "IPY_MODEL_142d016eb8214aa28f19be6b4fbca339"
     }
    },
    "6c0840f318024ab9a16fd99fe8767fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e48c134789c4200a3143b077628faed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704a5be7508e47449bdc1161a5fe8cd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7063e4b4cfc24887a83a354033d20a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5f9302f6284729857f408842194ea4",
      "placeholder": "​",
      "style": "IPY_MODEL_704a5be7508e47449bdc1161a5fe8cd4",
      "value": "Downloading: 100%"
     }
    },
    "9b093515743d4e69b216834573f96602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dbed6d8b4b04194beb3da32d358927d",
       "IPY_MODEL_f4ab9ebc94d84300a0c13ce2b8c93fea",
       "IPY_MODEL_0ce1aafc7ed94eaca3809367cb9e2696"
      ],
      "layout": "IPY_MODEL_f910423ef6e143d1a8a7d95be91bd1b3"
     }
    },
    "9dbed6d8b4b04194beb3da32d358927d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df4c9d848f5c4e0eb29e098e7695c695",
      "placeholder": "​",
      "style": "IPY_MODEL_49fae8c6167b4e2481e73682075e37a6",
      "value": "Downloading: 100%"
     }
    },
    "9e6c30f8f75249019d52dd9323421b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18e76af94ab4101bde6ccb1ba1b3da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba839dd8d584448e880b1a2a19554d8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5aef9f69ad94c0287ee688fdd10bbb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c729906924654cf5b6ce0f4332db20d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd5f9302f6284729857f408842194ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3fbc0d0728148e3a08dc882bbfc3ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4c9d848f5c4e0eb29e098e7695c695": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e309f41ad5184122a86aec00b02ff626": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e421731c8412433091e58699d9214628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d592c9566f34af9aea2c4d1575fed8d",
      "max": 891695056,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07624b5f2dcc40228c6a97a81de3ac3e",
      "value": 891695056
     }
    },
    "f4ab9ebc94d84300a0c13ce2b8c93fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e6c30f8f75249019d52dd9323421b2e",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36a27f29392d4083b8e49c16081d59d0",
      "value": 791656
     }
    },
    "f910423ef6e143d1a8a7d95be91bd1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae887e257514fbb801c0c5d331f57c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3fbc0d0728148e3a08dc882bbfc3ef4",
      "max": 1208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c0840f318024ab9a16fd99fe8767fd3",
      "value": 1208
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
