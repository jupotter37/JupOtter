{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62169ce6-d3ff-486e-8af5-4fc9a5c00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ddbba5-f6a5-4367-837b-bcdea631a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708])\n",
      "torch.Size([140])\n",
      "torch.Size([500])\n",
      "torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayday\\Desktop\\Master_Thesis\\experiment\\utils.py:87: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n"
     ]
    }
   ],
   "source": [
    "data='cora'\n",
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation(data)\n",
    "#splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "#adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data(data,splitstr)\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(idx_train.shape)\n",
    "print(idx_val.shape)\n",
    "print(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f516b9ec-672b-4a67-99b1-bbf1323a7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42522538-1af7-4041-894c-3100f095ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=features.shape[0]\n",
    "feature_size=features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "hidden_dim=1024\n",
    "dropout=0.5\n",
    "model=my_GCN(n,feature_size,hidden_dim,num_classes,dropout)\n",
    "model=model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)\n",
    "\n",
    "epochs=500\n",
    "patience=10\n",
    "test=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffcf9578-d717-4873-a300-cfd4d01f74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 train loss:1.988 acc:12.14 | val loss:1.741 acc:26.80\n",
      "Epoch:0002 train loss:1.187 acc:64.29 | val loss:1.115 acc:76.00\n",
      "Epoch:0003 train loss:0.495 acc:99.29 | val loss:0.973 acc:71.20\n",
      "Epoch:0004 train loss:0.247 acc:97.14 | val loss:0.853 acc:74.60\n",
      "Epoch:0005 train loss:0.114 acc:98.57 | val loss:0.766 acc:76.80\n",
      "Epoch:0006 train loss:0.045 acc:100.00 | val loss:0.761 acc:76.00\n",
      "Epoch:0007 train loss:0.024 acc:100.00 | val loss:0.786 acc:75.80\n",
      "Epoch:0008 train loss:0.017 acc:100.00 | val loss:0.806 acc:75.20\n",
      "Epoch:0009 train loss:0.011 acc:100.00 | val loss:0.820 acc:75.80\n",
      "Epoch:0010 train loss:0.008 acc:100.00 | val loss:0.832 acc:75.20\n",
      "Epoch:0011 train loss:0.006 acc:100.00 | val loss:0.846 acc:75.20\n",
      "Epoch:0012 train loss:0.004 acc:100.00 | val loss:0.862 acc:75.00\n",
      "Epoch:0013 train loss:0.003 acc:100.00 | val loss:0.879 acc:74.40\n",
      "Epoch:0014 train loss:0.003 acc:100.00 | val loss:0.895 acc:74.60\n",
      "Epoch:0015 train loss:0.004 acc:100.00 | val loss:0.900 acc:74.80\n",
      "Epoch:0016 train loss:0.003 acc:100.00 | val loss:0.898 acc:74.80\n",
      "Train cost: 1.1687s\n",
      "Load 5th epoch\n",
      "Val acc.:76.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test():\n",
    "    #model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "    \n",
    "t_total = time.time()\n",
    "bad_counter = 0\n",
    "best = 999999999\n",
    "best_epoch = 0\n",
    "acc = 0\n",
    "for epoch in range(epochs):\n",
    "    loss_tra,acc_tra = train()\n",
    "    loss_val,acc_val = validate()\n",
    "    if(epoch+1)%1 == 0: \n",
    "        print('Epoch:{:04d}'.format(epoch+1),\n",
    "            'train',\n",
    "            'loss:{:.3f}'.format(loss_tra),\n",
    "            'acc:{:.2f}'.format(acc_tra*100),\n",
    "            '| val',\n",
    "            'loss:{:.3f}'.format(loss_val),\n",
    "            'acc:{:.2f}'.format(acc_val*100))\n",
    "    if loss_val < best:\n",
    "        best = loss_val\n",
    "        best_epoch = epoch\n",
    "        acc = acc_val\n",
    "        #torch.save(model.state_dict(), checkpt_file)\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "    if bad_counter == patience:\n",
    "        break\n",
    "\n",
    "#if test:\n",
    "#    acc = test()[1]\n",
    "\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print('Load {}th epoch'.format(best_epoch))\n",
    "print(\"Val\",\"acc.:{:.1f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6477916-3c0a-42a5-925c-7ca5bd3c39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2708, 16]\n",
    "# [2708, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4f28a6-47bb-4aae-a7b3-c7b941a071e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1557039151.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(support.shape)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(adj.to_dense().shape)\n",
    "        print(support.shape)\n",
    "        print(output.shape)\n",
    "\n",
    "\n",
    "torch.Size([2708, 2708]) adj\n",
    "torch.Size([2708, 16])  support= input x weight\n",
    "torch.Size([2708, 2724])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
