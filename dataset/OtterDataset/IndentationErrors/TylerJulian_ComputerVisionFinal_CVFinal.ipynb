{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)               # '0' is the webcam's ID. usually it is 0 or 1. 'cap' is the video object.\n",
    "cap.set(15, 4)                         # '15' references video's brightness. '-4' sets the brightness.\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, im = cap.read()\n",
    "    if im is None:\n",
    "        break\n",
    "    #cv2.imshow('orig step 0',im)\n",
    "    #convert to hsv then split into 3 values\n",
    "    hsv = cv2.cvtColor(im,cv2.COLOR_BGR2HSV)\n",
    "    #FINDS THE GREEN VALUES\n",
    "    mask = cv2.inRange(hsv, (40,25,25),(100,255,255))\n",
    "    #filters out non green values\n",
    "    imask = mask>0\n",
    "    green = np.zeros_like(im, np.uint8)\n",
    "    green[imask] = im[imask]\n",
    "    #thresholds the frame and convert all of the green to white and everything else to black\n",
    "    hsv = cv2.cvtColor(green, cv2.COLOR_BGR2HSV)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    th, threshed = cv2.threshold(s,50,255,cv2.THRESH_BINARY)\n",
    "    #finds the contours on the threshold image\n",
    "    cnts = cv2.findContours(threshed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    canvas = im.copy()\n",
    "    cnts = sorted(cnts,key = cv2.contourArea)\n",
    "    #if a green section was detected then this segments executes\n",
    "    if cnts:\n",
    "        #this finds the largest contour which should be the placeholder image.\n",
    "        #this can be modified to find the second/third/fourth largest image.\n",
    "        cnt = cnts[-1]\n",
    "        arclen = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02* arclen, True)\n",
    "        #cv2.drawContours(canvas, [cnt], -1, (255,0,0), 1, cv2.LINE_AA)\n",
    "        #cv2.drawContours(canvas, [approx], -1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        #cv2.imshow('square detection final',canvas)\n",
    "        \n",
    "        #creates a blank black image\n",
    "        blank = np.zeros_like(im, np.uint8)\n",
    "        #draws the approximate contour onto the blank image then converts it to grayscale. This converts the red contour line to white\n",
    "        cv2.drawContours(blank, [approx], -1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        blank = cv2.cvtColor(blank,cv2.COLOR_BGR2GRAY)\n",
    "        blank = np.float32(blank)\n",
    "        \n",
    "        #detects the corners and stores them into a list of corners\n",
    "        dst = cv2.cornerHarris(blank,2,3,0.04)\n",
    "        ret, dst = cv2.threshold(dst,0.1*dst.max(),255,0)\n",
    "        dst = np.uint8(dst)\n",
    "        ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "        corners = cv2.cornerSubPix(blank,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "        #this creates a list of corners again\n",
    "        tempCorners = []\n",
    "        for i in range(1, len(corners)):\n",
    "            tempCorners.append(corners[i])\n",
    "        #if the detected green segment is rectangular/square then we proceed to this segment\n",
    "        if len(tempCorners) == 4:\n",
    "            #print('Square:')\n",
    "            #overlay image\n",
    "            input = cv2.imread('cola.jpg')\n",
    "            #cv2.imshow('input',input)\n",
    "            #input image size, this can be determined based off the actual image size dynamically.\n",
    "            input_pts = np.float32([[1000,0],[0,0],[0,562],[1000,562]])\n",
    "            #uses the list of corners again but in a format that works with warp perspective\n",
    "            output_pts = np.float32([tempCorners[1],tempCorners[0],tempCorners[2],tempCorners[3]])\n",
    "            # sort to organize the output points\n",
    "            \n",
    "            \n",
    "            \n",
    "            #warps the original image to that of the placeholder item\n",
    "            M = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "            out = cv2.warpPerspective(input,M,(canvas.shape[1], canvas.shape[0]),flags=cv2.INTER_LINEAR)\n",
    "            \n",
    "            #overlays the input image.\n",
    "            canvas = cv2.addWeighted(canvas,0.7,out,0.3,0)\n",
    "        canvas[dst>0.1*dst.max()]=[0,0,255]\n",
    "        \n",
    "        #original image.\n",
    "        cv2.imshow('original', im)\n",
    "        #shows the final image with contours and the overlaid image. The contours can easily be removed.\n",
    "        cv2.imshow('Final', canvas)\n",
    "        \n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff                              # press [Esc] to exit.\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-c81e29b37e99>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-c81e29b37e99>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    sorted(output_pts, key=lambda x: x[1])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "input_pts = np.sort(input_pts, 1)\n",
    "            if input_pts[0][0] > input_pts[1][0]:\n",
    "                input_pts[0][0],  input_pts[1][0] =  input_pts[1][0], input_pts[0][0]\n",
    "                \n",
    "            if input_pts[2][0] > input_pts[3][0]:\n",
    "                input_pts[2][0],  input_pts[3][0] =  input_pts[3][0], input_pts[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pts = np.sort(output_pts, 1)\n",
    "            if output_pts[0][0] > output_pts[1][0]:\n",
    "                output_pts[0][0],  output_pts[1][0] =  output_pts[1][0], output_pts[0][0]\n",
    "                \n",
    "            if output_pts[2][0] > output_pts[3][0]:\n",
    "                output_pts[2][0],  output_pts[3][0] =  output_pts[3][0], output_pts[2][0]\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
