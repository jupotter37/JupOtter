{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[adaptado de [Programa de cursos integrados Aprendizado de máquina](https://www.coursera.org/specializations/machine-learning-introduction) de [Andrew Ng](https://www.coursera.org/instructor/andrewng)  ([Stanford University](http://online.stanford.edu/), [DeepLearning.AI](https://www.deeplearning.ai/) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar arquivos adicionais para o laboratório.\n",
    "!wget https://github.com/fabiobento/dnn-course-2024-1/raw/main/00_course_folder/ml_intro/class_03/9%20-%20Atividade%20Avaliativa%20-%20Regress%C3%A3o%20Log%C3%ADstica/lab_utils_ml_intro_assig_week_3.zip\n",
    "!unzip -n -q lab_utils_ml_intro_assig_week_3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar se estamos no Google Colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística\n",
    "\n",
    "Neste exercício, você implementará a regressão logística e a aplicará a dois conjuntos de dados diferentes.\n",
    "\n",
    "\n",
    "# Tópicos\n",
    "- [ 1 - Pacotes ](#1)\n",
    "- [ 2 - Regressão Logística](#2)\n",
    "  - [ 2.1 Definição do Problema](#2.1)\n",
    "  - [ 2.2 Carregando e visualizando os dados](#2.2)\n",
    "  - [ 2.3  Função Sigmoid](#2.3)\n",
    "  - [ 2.4 Função de custo para regressão logística](#2.4)\n",
    "  - [ 2.5 Gradiente para regressão logística](#2.5)\n",
    "  - [ 2.6 Parâmetros de aprendizagem usando gradiente descendente ](#2.6)\n",
    "  - [ 2.7 Plotando a fronteira de decisão](#2.7)\n",
    "  - [ 2.8 Avaliando a regressão logística](#2.8)\n",
    "- [ 3 - Regressão Lógística Regularizada](#3)\n",
    "  - [ 3.1 Definição do Problema](#3.1)\n",
    "  - [ 3.2 Carregando e Visualizando os Dados](#3.2)\n",
    "  - [ 3.3 Mapeamento de Características](#3.3)\n",
    "  - [ 3.4 Função de custo para regressão logística regularizada](#3.4)\n",
    "  - [ 3.5 Gradiente para regressão logística regularizada](#3.5)\n",
    "  - [ 3.6 Parâmetros de aprendizagem usando gradiente descendente](#3.6)\n",
    "  - [ 3.7 Plotando a fronteira de decisão](#3.7)\n",
    "  - [ 3.8 Avaliando modelo de regressão logística regularizado](#3.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Pacotes \n",
    "\n",
    "Primeiro, vamos executar a célula abaixo para importar todos os pacotes que você precisará durante esta tarefa.\n",
    "- [numpy](www.numpy.org) é o pacote fundamental para computação científica com Python.\n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca famosa para plotar gráficos em Python.\n",
    "- ``utils.py`` contém funções auxiliares para esta tarefa. Você não precisa modificar o código neste arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Regressão Logística\n",
    "\n",
    "Nesta parte do exercício, você construirá um modelo de regressão logística para prever se um aluno será admitido em uma universidade.\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Definição do problema\n",
    "\n",
    "Suponha que você seja o administrador de um departamento universitário e queira determinar a chance de admissão de cada candidato com base nos resultados de dois exames.\n",
    "* Você tem dados históricos de candidatos anteriores que podem ser usados como conjunto de treinamento para regressão logística.\n",
    "* Para cada exemplo de treinamento, você tem as notas do candidato em dois exames e a decisão de admissão.\n",
    "* Sua tarefa é construir um modelo de classificação que estime a probabilidade de admissão de um candidato com base nas notas desses dois exames.\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Carregando e visualizando os dados\n",
    "\n",
    "Você começará carregando o conjunto de dados para esta tarefa.\n",
    "- A função `load_dataset()` mostrada abaixo carrega os dados nas variáveis `X_train` e `y_train`\n",
    "   - `X_train` contém notas de exames em dois exames para um aluno\n",
    "   - `y_train` é a decisão de admissão\n",
    "       - `y_train = 1` se o aluno foi admitido\n",
    "       - `y_train = 0` se o aluno não foi admitido\n",
    "   - Tanto `X_train` quanto `y_train` são arrays numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# carregar o conjunto de dados\n",
    "X_train, y_train = load_data(\"data/ex2data1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veja as variáveis\n",
    "Vamos nos familiarizar mais com seu conjunto de dados.\n",
    "- Um bom lugar para começar é simplesmente imprimir cada variável e ver o que ela contém.\n",
    "\n",
    "O código abaixo imprime os primeiros cinco valores de `X_train` e o tipo da variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"Os primeiros cinco elementos em X_train são:\\n\", X_train[:5])\n",
    "print(\"Tipo de X_train:\",type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora imprima os primeiros cinco valores de `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"Os primeiros cinco elementos em y_train são:\\n\", y_train[:5])\n",
    "print(\"Tipo de y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifique as dimensões de suas variáveis\n",
    "\n",
    "Outra forma útil de se familiarizar com seus dados é visualizar suas dimensões. Vamos imprimir a forma de `X_train` e `y_train` e ver quantos exemplos de treinamento temos em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('A forma do X_train é: ' + str(X_train.shape))\n",
    "print('A forma de y_train é: ' + str(y_train.shape))\n",
    "print('Temos m = %d exemplos de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize seus dados\n",
    "\n",
    "Antes de começar a implementar qualquer algoritmo de aprendizagem, é sempre bom visualizar os dados, se possível.\n",
    "- O código abaixo exibe os dados em um gráfico 2D (conforme mostrado abaixo), onde os eixos são as notas dos dois exames e os exemplos positivos e negativos são mostrados com marcadores diferentes.\n",
    "- Usamos uma função auxiliar no arquivo ``utils.py`` para gerar este gráfico.\n",
    "\n",
    "<img src=\"images/figure 1.png\" width=\"450\" height=\"450\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plotar os exmplos\n",
    "plot_data(X_train, y_train[:], pos_label=\"Aprovado\", neg_label=\"Não-aprovado \")\n",
    "\n",
    "# Definir o rótulo do eixo y\n",
    "plt.ylabel('Pontuação na prova 2') \n",
    "# Definir o rótulo do eixo x\n",
    "plt.xlabel('Pontuação na prova 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu objetivo é construir um modelo de regressão logística que se ajuste a esses dados.\n",
    "- Com este modelo, você pode prever se um novo aluno será admitido com base nas notas dos dois exames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Função sigmóide\n",
    "\n",
    "Lembre-se que para regressão logística, o modelo é representado como\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "onde a função $g$ é a função sigmóide. A função sigmóide é definida como:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Vamos implementar a função sigmóide primeiro, para que ela possa ser usada no restante desta tarefa.\n",
    "\n",
    "<a name='ex-01'></a>\n",
    "### Exercício 1\n",
    "Complete a função `sigmoid` para calcular\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Observe que\n",
    "- `z` nem sempre é um número único, mas também pode ser uma matriz de números.\n",
    "- Se a entrada for uma matriz de números, gostaríamos de aplicar a função sigmóide a cada valor da matriz de entrada.\n",
    "\n",
    "Se tiver dúvidas, você pode conferir as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcular o sigmoide de z\n",
    "\n",
    "    Args:\n",
    "        z (ndarray): vetor numérica de qualquer tamanho.\n",
    "\n",
    "    Retorns:\n",
    "        g (ndarray): sigmoid(z), com a mesma forma de z\n",
    "         \n",
    "    \"\"\"\n",
    "          \n",
    "    ### INICIE SEU CÓDIGO AQUI ### \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI ### \n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "       \n",
    "   * O `numpy` tem uma função chamada [`np.exp()`](https://numpy.org/doc/stable/reference/generated/numpy.exp.html), que oferece uma maneira conveniente de calcular o exponencial ( $e^{z}$) de todos os elementos da matriz de entrada (`z`).\n",
    "\n",
    " \n",
    "<details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b> Clique para ainda mais dicas</b></font></summary>\n",
    "        \n",
    "  - Você pode traduzir $e^{-z}$ em código como `np.exp(-z)` \n",
    "    \n",
    "  - Você pode traduzir $1/e^{-z}$ em código como `1/np.exp(-z)` \n",
    "    \n",
    "    Se você ainda estiver com dificuldades, pode verificar as dicas apresentadas abaixo para descobrir como calcular `g` \n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular g</b></font></summary>\n",
    "        <code>g = 1 / (1 + np.exp(-z))</code>\n",
    "    </details>\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando terminar, tente testar alguns valores chamando `sigmoid(x)` na célula abaixo. \n",
    "- Para valores positivos grandes de x, o sigmoide deve estar próximo de 1, enquanto para valores negativos grandes, o sigmoide deve estar próximo de 0. \n",
    "- A avaliação de `sigmoid(0)` deve lhe dar exatamente 0,5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Observação: você pode editar esse valor\n",
    "value = 0\n",
    "\n",
    "print (f\"sigmoid({value}) = {sigmoid(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>sigmoid(0)<b></td>\n",
    "    <td> 0.5 </td> \n",
    "  </tr>\n",
    "</table>\n",
    "    \n",
    "- Como mencionado anteriormente, seu código também deve funcionar com vetores e matrizes. Para uma matriz, sua função deve executar a função sigmoide em cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid([ -1, 0, 1, 2]) = \" + str(sigmoid(np.array([-1, 0, 1, 2]))))\n",
    "\n",
    "# TESTE DA UNIDADE\n",
    "from public_tests import *\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><b>sigmoid([-1, 0, 1, 2])<b></td> \n",
    "    <td>[0.26894142        0.5           0.73105858        0.88079708]</td> \n",
    "  </tr>    \n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Função de custo para regressão logística\n",
    "\n",
    "Nesta seção, você implementará a função de custo para regressão logística.\n",
    "\n",
    "<a name='ex-02'></a>\n",
    "### Exercício 2\n",
    "\n",
    "Complete a função `compute_cost` usando as equações abaixo.\n",
    "\n",
    "Lembre-se de que, para a regressão logística, a função de custo tem a forma \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "onde\n",
    "* m é o número de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ é o custo de um único ponto de dados, que é - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ é a previsão do modelo, enquanto $y^{(i)}$, que é o rótulo real\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ m que a função $g$ é a função sigmoide.\n",
    "  * Pode ser útil calcular primeiro uma variável intermediária $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ onde $n$ é o número de recursos, antes de calcular $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$\n",
    "\n",
    "Observação:\n",
    "* Enquanto estiver fazendo isso, lembre-se de que as variáveis `X_train` e `y_train` não são valores escalares, mas matrizes de forma ($m, n$) e ($𝑚$,1), respectivamente, em que $𝑛$ é o número de recursos e $𝑚$ é o número de exemplos de treinamento.\n",
    "* Você pode usar a função sigmoide que implementou acima para essa parte.\n",
    "\n",
    "Se tiver dúvidas, consulte as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cost(X, y, w, b, *argv):\n",
    "    \"\"\"\n",
    "    Calcula o custo de todos os exemplos\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m examples by n features\n",
    "      y : (ndarray Shape (m,))  valor alvo\n",
    "      w : (ndarray Shape (n,))  valores dos parâmetros do modelo      \n",
    "      b : (scalar)              valores dos parâmetros do modelo      \n",
    "      *argv : não utilizado, para compatibilidade com a versão regularizada abaixo\n",
    "    Returns:\n",
    "      total_cost : (escalar) custo \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI ### \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para Dicas</b></font></summary>\n",
    "    \n",
    "    * Você pode representar um operador de soma, por exemplo: $h = \\sum\\limits_{i = 0}^{m-1} 2i$ no código da seguinte forma:   \n",
    "    ```python \n",
    "        h = 0\n",
    "        for i in range(m):\n",
    "            h = h + 2*i\n",
    "    ```\n",
    "   * Em seguida, você pode retornar o `total_cost` como `loss_sum` dividido por `m`.\n",
    "   * Se você for novato em Python, verifique se o código está devidamente recuado com espaços ou tabulações consistentes. Caso contrário, ele poderá produzir uma saída diferente ou gerar um erro `IndentationError: unexpected indent`. Para obter detalhes, consulte [esse tópico](https://community.deeplearning.ai/t/indentation-in-python-indentationerror-unexpected-indent/159398) no fórum de DeepLearning.AI.\n",
    "     \n",
    "   <details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b> Clique para mai Dicas</b></font></summary>\n",
    "        \n",
    "    * Veja como você pode estruturar a implementação geral dessa função\n",
    "        \n",
    "    ```python \n",
    "    def compute_cost(X, y, w, b, *argv):\n",
    "        m, n = X.shape\n",
    "    \n",
    "        ### INICIE SEU CÓDIGO AQUI ###\n",
    "        loss_sum = 0 \n",
    "        \n",
    "        # Fazer um loop em cada exemplo de treinamento\n",
    "        for i in range(m): \n",
    "            \n",
    "            # Primeiro calcule z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b\n",
    "            z_wb = 0 \n",
    "            # Fazer um loop em cada recurso\n",
    "            for j in range(n): \n",
    "                # Adicione o termo correspondente a z_wb\n",
    "                z_wb_ij = # Seu código para calcular w[j] * X[i][j]\n",
    "                z_wb += z_wb_ij # equivalente a z_wb = z_wb + z_wb_ij\n",
    "            # Adicione o termo de polarização a z_wb\n",
    "            z_wb += b #equivalente a z_wb = z_wb + b\n",
    "        \n",
    "            f_wb = # Seu código aqui para calcular a previsão f_wb para um exemplo de treinamento\n",
    "            loss =  # Seu código aqui para calcular a perda para um exemplo de treinamento\n",
    "            \n",
    "            loss_sum += loss # equivalent to loss_sum = loss_sum + loss\n",
    "        \n",
    "        total_cost = (1 / m) * loss_sum  \n",
    "        ### TERMINE SEU CÓDIGO AQUI ### \n",
    "        \n",
    "        return total_cost\n",
    "    ```\n",
    "       Se ainda estiver com dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular `z_wb_ij`, `f_wb` e `cost`.\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica pra calcular z_wb_ij</b></font></summary>\n",
    "           &emsp; &emsp; <code>z_wb_ij = w[j]*X[i][j] </code>\n",
    "    </details>\n",
    "        \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica pra calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$ onde $g$ é a função sigmoid. Você pode simplesmente chamar a função `sigmoid` implementada acima.\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f</b></font></summary>\n",
    "               &emsp; &emsp; Você pode calcular f_wb como <code>f_wb = sigmoid(z_wb) </code>\n",
    "           </details>\n",
    "    </details>\n",
    "\n",
    "     <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular a perda</b></font></summary>\n",
    "          &emsp; &emsp; Você pode usar função <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.log.html\">np.log</a> para calcular o log\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular a perda</b></font></summary>\n",
    "              &emsp; &emsp; Você pode calcular a perda com <code>loss =  -y[i] * np.log(f_wb) - (1 - y[i]) * np.log(1 - f_wb)</code>\n",
    "          </details>\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute as células abaixo para verificar sua implementação da função `compute_cost` com duas inicializações diferentes dos parâmetros $w$ e $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "# Calcular e exibir o custo com w e b inicializados como zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train, y_train, initial_w, initial_b)\n",
    "print('Custo em w e b iniciais (zeros): {:.3f}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo inicial w e b (zeros)<b></td>\n",
    "    <td> 0.693 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Calcular e exibir o custo com w e b diferentes de zero\n",
    "test_w = np.array([0.2, 0.2])\n",
    "test_b = -24.\n",
    "cost = compute_cost(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Custo de w e b (não-zeros) no conjunto de teste: {:.3f}'.format(cost))\n",
    "\n",
    "\n",
    "# TESTE DA UNIDADE\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo de w e b (não-zeros) no conjunto de teste:<b></td>\n",
    "    <td> 0.218 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 Gradiente para regressão logística\n",
    "\n",
    "Nesta seção, você implementará o gradiente para a regressão logística.\n",
    "\n",
    "Lembre-se de que o algoritmo de descida de gradiente é:\n",
    "\n",
    "$$\\begin{align*}& \\text{repita até a convergência:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{para j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "onde os parâmetros $b$, $w_j$ são atualizados simultaneamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name='ex-03'></a>\n",
    "### Exercício 3\n",
    "\n",
    "Complete a função `compute_gradient` para calcular $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ das equações (2) e (3) abaixo.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "* m é o número de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(x^{(i)})$ é a predição do modelo, enquanto $y^{(i)}$ é o rótulo verdadeiro\n",
    "\n",
    "\n",
    "**Nota**: Embora esse gradiente pareça idêntico ao gradiente da regressão linear, a fórmula é, na verdade, diferente porque a regressão linear e a regressão logística têm definições diferentes de $f_{\\mathbf{w},b}(x)$.\n",
    "\n",
    "Como antes, você pode usar a função sigmoide que implementou acima e, se tiver dúvidas, pode consultar as dicas apresentadas após a célula abaixo para ajudá-lo com a implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, *argv): \n",
    "    \"\"\"\n",
    "    Calcula o gradiente para regressão logística \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos n características\n",
    "      y : (ndarray Shape (m,))  valor alvo\n",
    "      w : (ndarray Shape (n,))  valores dos parâmetros do modelo\n",
    "      b : (scalar)              valores dos parâmetros do modelo\n",
    "      *argv : não utilizado, para compatibilidade com a versão regularizada abaixo\n",
    "    Returns\n",
    "      dj_dw : (ndarray Shape (n,)) O gradiente do custo em relação aos parâmetros w. \n",
    "      dj_db : (scalar)             O gradiente do custo em relação aos parâmetros b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    ### INICIE SEU CÓDIGO AQUI ### \n",
    "    for i in range(m):\n",
    "        z_wb = None\n",
    "        for j in range(n): \n",
    "            z_wb += None\n",
    "        z_wb += None\n",
    "        f_wb = None\n",
    "        \n",
    "        dj_db_i = None\n",
    "        dj_db += None\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw[j] = None\n",
    "            \n",
    "    dj_dw = None\n",
    "    dj_db = None\n",
    "    ### TERMINE SEU CÓDIGO AQUI ### \n",
    "\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para Dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Veja como você pode estruturar a implementação geral dessa função\n",
    "    ```python \n",
    "       def compute_gradient(X, y, w, b, *argv): \n",
    "            m, n = X.shape\n",
    "            dj_dw = np.zeros(w.shape)\n",
    "            dj_db = 0.\n",
    "        \n",
    "            ### INICIE SEU CÓDIGO AQUI ### \n",
    "            for i in range(m):\n",
    "                # Calcule f_wb (exatamente como você fez na função compute_cost acima)\n",
    "                f_wb = \n",
    "        \n",
    "                # Calcule o gradiente para b a partir deste exemplo\n",
    "                dj_db_i = # Seu código aqui para calcular o erro\n",
    "        \n",
    "                # some a dj_db\n",
    "                dj_db += dj_db_i\n",
    "        \n",
    "                # obter dj_dw para cada atributo\n",
    "                for j in range(n):\n",
    "                    # Você codifica aqui para calcular o gradiente do i-ésimo exemplo para o j-ésimo atributo\n",
    "                    dj_dw_ij =  \n",
    "                    dj_dw[j] += dj_dw_ij\n",
    "        \n",
    "            # dividir dj_db e dj_dw pelo número total de exemplos\n",
    "            dj_dw = dj_dw / m\n",
    "            dj_db = dj_db / m\n",
    "            ### TERMINE SEU CÓDIGO AQUI ### \n",
    "       \n",
    "            return dj_db, dj_dw\n",
    "    ```\n",
    "   * Se você for novato em Python, verifique se o código está devidamente recuado com espaços ou tabulações consistentes. Caso contrário, ele poderá produzir uma saída diferente ou gerar um erro `IndentationError: unexpected indent`. Para obter detalhes, consulte [esse tópico](https://community.deeplearning.ai/t/indentation-in-python-indentationerror-unexpected-indent/159398) no fórum de DeepLearning.AI.\n",
    "\n",
    "\n",
    "    * Se ainda tiver dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular `f_wb`, `dj_db_i` e `dj_dw_ij` \n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Lembre-se de que você calculou f_wb em <code>compute_cost</code> acima - para obter dicas detalhadas sobre como calcular cada termo intermediário, consulte a seção de dicas abaixo desse exercício\n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas pra calcular f_wb</b></font></summary>\n",
    "              &emsp; &emsp; Você pode calcular f_wb com\n",
    "               <pre>\n",
    "               for i in range(m):   \n",
    "                   # Calcule f_wb (exatamente como você fez na função compute_cost acima)\n",
    "                   z_wb = 0\n",
    "                   # Fazer um loop em cada recurso\n",
    "                   for j in range(n): \n",
    "                       # Adicione o termo correspondente a z_wb\n",
    "                       z_wb_ij = X[i, j] * w[j]\n",
    "                       z_wb += z_wb_ij\n",
    "            \n",
    "                   # Adicionar termo de viés \n",
    "                   z_wb += b\n",
    "        \n",
    "                   # Calcular a previsão do modelo\n",
    "                   f_wb = sigmoid(z_wb)\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_db_i</b></font></summary>\n",
    "           &emsp; &emsp; Você pode calcular dj_db_i como <code>dj_db_i = f_wb - y[i]</code>\n",
    "    </details>\n",
    "        \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica pra calcular dj_dw_ij</b></font></summary>\n",
    "        &emsp; &emsp; Você pode calcular dj_dw_ij como <code>dj_dw_ij = (f_wb - y[i])* X[i][j]</code>\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute as células abaixo para verificar sua implementação da função `compute_gradient` com duas inicializações diferentes dos parâmetros $w$ e $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Calcular e exibir o gradiente com w e b inicializados como zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "\n",
    "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db em w and b (zeros) iniciais:{dj_db}' )\n",
    "print(f'dj_dw e, w and b (zeros) iniciais:{dj_dw.tolist()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db em w and b (zeros) iniciais:<b></td>\n",
    "    <td> -0.1 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>dj_dw e, w and b (zeros) iniciais:<b></td>\n",
    "    <td> [-12.00921658929115, -11.262842205513591] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Calcular e exibir o custo e o gradiente com w e b diferentes de zero\n",
    "test_w = np.array([ 0.2, -0.5])\n",
    "test_b = -24\n",
    "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('dj_db em w and b de teste:', dj_db)\n",
    "print('dj_dw em w and b de teste:', dj_dw.tolist())\n",
    "\n",
    "# TESTE DA UNDADE    \n",
    "compute_gradient_test(compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db em w and b de teste:<b></td>\n",
    "    <td> -0.5999999999991071 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>dj_dw em w and b de teste:<b></td>\n",
    "    <td>  [-44.8313536178737957, -44.37384124953978] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Parâmetros de aprendizagem usando a descida de gradiente \n",
    "\n",
    "Da mesma forma que na tarefa anterior, agora você encontrará os parâmetros ideais de um modelo de regressão logística usando a descida gradiente. \n",
    "- Você não precisa implementar nada para esta parte. Basta executar as células abaixo. \n",
    "\n",
    "- Uma boa maneira de verificar se a descida de gradiente está funcionando corretamente é observar\n",
    "o valor de $J(\\mathbf{w},b)$ e verificar se ele está diminuindo a cada etapa. \n",
    "\n",
    "- Supondo que você tenha implementado o gradiente e calculado o custo corretamente, o valor de $J(\\mathbf{w},b)$ nunca deve aumentar e deve convergir para um valor estável no final do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Executa a descida do gradiente em lote para aprender theta. Atualiza theta tomando \n",
    "    num_iters etapas de gradiente com taxa de aprendizado alfa\n",
    "    \n",
    "    Args:\n",
    "      X :    (ndarray Shape (m, n) dados, m exemplos n características\n",
    "      y :    (ndarray Shape (m,))  valor alvo\n",
    "      w_in : (ndarray Shape (n,))  valores dos parâmetros do modelo\n",
    "      b_in : (scalar)              valores dos parâmetros do modelo\n",
    "      cost_function :              função para calcular custo\n",
    "      gradient_function :          função para calcular o gradiente\n",
    "      alpha : (float)              taxa de aprendizado\n",
    "      num_iters : (int)            número de iterações para executar a descida do gradiente\n",
    "      lambda_ : (scalar, float)    constante de regularização\n",
    "      \n",
    "    Returns:\n",
    "      w : (ndarray Shape (n,)) Valores atualizados dos parâmetros do modelo após executar a descida do gradiente\n",
    "      b : (scalar)             Valor atualizado do parâmetro do modelo após a execução da descida do gradiente\n",
    "    \"\"\"\n",
    "    \n",
    "    # Número de exemplos de treinamento\n",
    "    m = len(X)\n",
    "    \n",
    "    # um vetor para armazenar os custos J e w em cada iteração, principalmente para gráficos posteriores\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calcular o gradiente e atualizar os parâmetros\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Atualizar parâmetros usando w, b, alfa e gradiente\n",
    "        w_in = w_in - alpha * dj_dw               \n",
    "        b_in = b_in - alpha * dj_db              \n",
    "       \n",
    "        # Salvar o custo J em cada iteração\n",
    "        if i<100000:      # Evitar o esgotamento de recursos \n",
    "            cost =  cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Imprimir o custo a cada intervalo de 10 vezes ou tantas iterações se < 10\n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteração {i:4}: Custo {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history #retornar w e J,e histórico de w para gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos executar o algoritmo de descida de gradiente acima para aprender os parâmetros do nosso conjunto de dados.\n",
    "\n",
    "**Nota**\n",
    "O bloco de código abaixo leva alguns minutos para ser executado, especialmente com uma versão não vetorizada. Você pode reduzir as `iterações` para testar sua implementação e iterar mais rapidamente. Se você tiver tempo mais tarde, tente executar 100.000 iterações para obter melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "initial_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "# Algumas configurações de descida de gradiente\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>Saída Esperada: Custo     0.30, (Clique para ver detalhes):</b>\n",
    "</summary>\n",
    "\n",
    "    # Com as seguintes configurações\n",
    "    np.random.seed(1)\n",
    "    initial_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "    initial_b = -8\n",
    "    iterations = 10000\n",
    "    alpha = 0.001\n",
    "    #\n",
    "\n",
    "```\n",
    "Iteração    0: Custo     0.96   \n",
    "Iteração 1000: Custo     0.31   \n",
    "Iteração 2000: Custo     0.30   \n",
    "Iteração 3000: Custo     0.30   \n",
    "Iteração 4000: Custo     0.30   \n",
    "Iteração 5000: Custo     0.30   \n",
    "Iteração 6000: Custo     0.30   \n",
    "Iteração 7000: Custo     0.30   \n",
    "Iteração 8000: Custo     0.30   \n",
    "Iteração 9000: Custo     0.30   \n",
    "Iteração 9999: Custo     0.30   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.7\"></a>\n",
    "### 2.7 Traçando a fronteira  de decisão\n",
    "\n",
    "Agora usaremos os parâmetros finais da descida de gradiente para plotar o ajuste linear. Se você implementou as partes anteriores corretamente, deverá ver um gráfico semelhante ao seguinte:   \n",
    "<img src=\"images/figure 2.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "Usaremos uma função auxiliar no arquivo `utils.py` para criar esse gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(w, b, X_train, y_train)\n",
    "# Definir o rótulo do eixo y\n",
    "plt.ylabel('Pontuação da prova 2') \n",
    "# Definir o rótulo do eixo x\n",
    "plt.xlabel('Pontuação da prova 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.8\"></a>\n",
    "### 2.8 Avaliação da regressão logística\n",
    "\n",
    "Podemos avaliar a qualidade dos parâmetros que encontramos verificando a qualidade da previsão do modelo aprendido em nosso conjunto de treinamento. \n",
    "\n",
    "Você implementará a função `predict` abaixo para fazer isso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-04'></a>\n",
    "### Exercício 4\n",
    "\n",
    "Complete a função `predict` para produzir previsões `1` ou `0` com um conjunto de dados e um vetor de parâmetros aprendidos $w$ e $b$.\n",
    "- Primeiro, você precisa calcular a previsão do modelo $f(x^{(i)}) = g(w \\cdot x^{(i)} + b)$ para cada exemplo \n",
    "    - Você já implementou isso antes nas partes acima\n",
    "- Interpretamos o resultado do modelo ($f(x^{(i)})$) como a probabilidade de que $y^{(i)}=1$ dado $x^{(i)}$ e parametrizado por $w$.\n",
    "- Portanto, para obter uma previsão final ($y^{(i)}=0$ ou $y^{(i)}=1$) do modelo de regressão logística, você pode usar a seguinte heurística -\n",
    "  if $f(x^{(i)}) >= 0.5$, predizer $y^{(i)}=1$\n",
    "  \n",
    "  if $f(x^{(i)}) < 0.5$, predizer $y^{(i)}=0$\n",
    "    \n",
    "Se tiver dúvidas, você pode consultar as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Prever se o rótulo é 0 ou 1 usando os parâmetros de regressão logística aprendidos\n",
    "    de regressão logística aprendidos w\n",
    "    \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados,m exemplos, n recursos\n",
    "      w : (ndarray Shape (n,))  valores dos parâmetros do modelo\n",
    "      b : (scalar)              valores dos parâmetros do modelo\n",
    "\n",
    "    Returns:\n",
    "      p : (ndarray (m,)) As previsões para X usando um limite de 0,5\n",
    "    \"\"\"\n",
    "    # Número de exemplos de treinamento\n",
    "    m, n = X.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    ### INICIE SEU CÓDIGO AQUI ### \n",
    "    # Fazer um loop em cada exemplo\n",
    "    for i in range(m):   \n",
    "        z_wb = None\n",
    "        # Fazer um loop em cada recurso\n",
    "        for j in range(n): \n",
    "            # Adicione o termo correspondente a z_wb\n",
    "            z_wb += None\n",
    "        \n",
    "        # Adicionar termo de viés \n",
    "        z_wb += None\n",
    "        \n",
    "        # Calcule a previsão para este exemplo\n",
    "        f_wb = None\n",
    "\n",
    "        # Aplicar o limiar (thershold)\n",
    "        p[i] = None\n",
    "        \n",
    "    ### TERMINE SEU CÓDIGO AQUI ### \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para Dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Veja como você pode estruturar a implementação geral dessa função\n",
    "    ```python \n",
    "       def predict(X, w, b): \n",
    "            # Número de exemplos de treinamento\n",
    "            m, n = X.shape   \n",
    "            p = np.zeros(m)\n",
    "   \n",
    "            ### INICIE SEU CÓDIGO AQUI ### \n",
    "            # Fazer um loop em cada exemplo\n",
    "            for i in range(m):   \n",
    "                \n",
    "                # Calcular f_wb (exatamente como você fez na função compute_cost acima) \n",
    "                # usando algumas linhas de código\n",
    "                f_wb = \n",
    "\n",
    "                # Calcule a previsão para esse exemplo de treinamento \n",
    "                p[i] = # Seu código aqui para calcular a previsão com base em f_wb\n",
    "        \n",
    "            ### TERMINE SEU CÓDIGO AQUI ### \n",
    "            return p\n",
    "    ```\n",
    "  \n",
    "        Se ainda estiver com dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular `f_wb` e `p[i]` \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Lembre-se de que você calculou f_wb em <code>compute_cost</code> acima — Para obter dicas detalhadas sobre como calcular cada termo intermediário, consulte a seção de dicas abaixo desse exercício\n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f_wb</b></font></summary>\n",
    "              &emsp; &emsp; Você pode calcular f_wb como\n",
    "               <pre>\n",
    "               for i in range(m):   \n",
    "                    # Calcule f_wb (exatamente como você fez na função compute_cost acima)\n",
    "                    z_wb = 0\n",
    "                    # Fazer um loop em cada recurso\n",
    "                    for j in range(n): \n",
    "                       # Adicionar o termo correspondente a z_wb\n",
    "                       z_wb_ij = X[i, j] * w[j]\n",
    "                       z_wb += z_wb_ij\n",
    "                    # Adicionar o termo de viés\n",
    "                    z_wb += b\n",
    "                # Calcule a previsão do modelo\n",
    "                f_wb = sigmoid(z_wb)\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular p[i]</b></font></summary>\n",
    "           &emsp; &emsp; Por exemplo, se você quiser dizer que x = 1 se y for menor que 3 e 0 caso contrário, você pode expressar isso em código como <code>x = y < 3 </code>. Agora faça o mesmo apra p[i] = 1 if f_wb >= 0.5 e 0 caso contrário. \n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular p[i]</b></font></summary>\n",
    "              &emsp; &emsp; Você pode calcular p[i] como <code>p[i] = f_wb >= 0.5</code>\n",
    "          </details>\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de concluir a função `predict`, vamos executar o código abaixo para informar a precisão do treinamento de seu classificador, calculando a porcentagem de exemplos corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Teste seu código de previsão\n",
    "np.random.seed(1)\n",
    "tmp_w = np.random.randn(2)\n",
    "tmp_b = 0.3    \n",
    "tmp_X = np.random.randn(4, 2) - 0.5\n",
    "\n",
    "tmp_p = predict(tmp_X, tmp_w, tmp_b)\n",
    "print(f'Saída da previsão: formato {tmp_p.shape}, valor {tmp_p}')\n",
    "\n",
    "# TESTES DA UNIDADE\n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Espereda** \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Saída da previsão: formato (4,), valor [0. 1. 1. 1.]<b></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar isso para calcular a precisão no conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Calcule a precisão em nosso conjunto de treinamento\n",
    "p = predict(X_train, w,b)\n",
    "print('Acurácia de Treino: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Acurácia de Treino (aprox):<b></td>\n",
    "    <td> 92.00 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Regressão logística regularizada\n",
    "\n",
    "Nesta parte do exercício, você implementará a regressão logística regularizada para prever se os microchips de uma fábrica serão aprovados no controle de qualidade (QA). Durante o QA, cada microchip passa por vários testes para garantir que esteja funcionando corretamente. \n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 Definição do problema\n",
    "\n",
    "Suponha que você seja o gerente de produtos da fábrica e tenha os resultados dos testes de alguns microchips em dois testes diferentes. \n",
    "- A partir desses dois testes, você gostaria de determinar se os microchips devem ser aceitos ou rejeitados. \n",
    "- Para ajudá-lo a tomar a decisão, você tem um conjunto de dados de resultados de testes de microchips anteriores, a partir dos quais pode criar um modelo de regressão logística.\n",
    "\n",
    "<a name=\"3.2\"></a>\n",
    "### 3.2 Carregando e visualizando os dados\n",
    "\n",
    "De forma semelhante às partes anteriores deste exercício, vamos começar carregando o conjunto de dados para esta tarefa e visualizando-o. \n",
    " \n",
    "- A função `load_dataset()` mostrada abaixo carrega os dados nas variáveis `X_train` e `y_train`\n",
    "  - `X_train` contém os resultados dos testes para os microchips de dois testes\n",
    "  - `y_train` contém os resultados do controle de qualidade  \n",
    "      - `y_train = 1` se o microchip foi aceito \n",
    "      - `y_train = 0` se o microchip foi rejeitado \n",
    "  - Tanto `X_train` quanto `y_train` são matrizes numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados\n",
    "X_train, y_train = load_data(\"data/ex2data2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exibir as variáveis\n",
    "\n",
    "O código abaixo imprime os cinco primeiros valores de `X_train` e `y_train` e o tipo das variáveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# imprimir X_train\n",
    "print(\"X_train:\", X_train[:5])\n",
    "print(\"Tipo de X_train:\",type(X_train))\n",
    "\n",
    "# imprimir y_train\n",
    "print(\"y_train:\", y_train[:5])\n",
    "print(\"Tipo de y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifique as dimensões de suas variáveis\n",
    "\n",
    "Outra maneira útil de se familiarizar com seus dados é visualizar suas dimensões. Vamos imprimir a forma de `X_train` e `y_train` e ver quantos exemplos de treinamento temos em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print ('O formaro de X_train é: ' + str(X_train.shape))\n",
    "print ('O formato de y_train é: ' + str(y_train.shape))\n",
    "print ('Temo m = %d exemplos de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize seus dados\n",
    "\n",
    "A função auxiliar `plot_data` (de `utils.py`) é usada para gerar uma figura como a Figura 3, em que os eixos são as duas pontuações de teste, e os exemplos positivos (y = 1, aceito) e negativos (y = 0, rejeitado) são mostrados com marcadores diferentes.\n",
    "\n",
    "<img src=\"images/figure 3.png\"  width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plotar os exemplos\n",
    "plot_data(X_train, y_train[:], pos_label=\"Aceito\", neg_label=\"Rejeitado\")\n",
    "\n",
    "# Definir o rótulo do eixo y\n",
    "plt.ylabel('Teste 2 de Microchip 2') \n",
    "# Definir o rótulo do eixo x\n",
    "plt.xlabel('Teste 2 de Microchip 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Figura 3 mostra que nosso conjunto de dados não pode ser separado em exemplos positivos e negativos por uma linha reta através do gráfico. Portanto, uma aplicação direta da regressão logística não terá um bom desempenho nesse conjunto de dados, pois a regressão logística só conseguirá encontrar um limite de decisão linear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.3\"></a>\n",
    "### 3.3 Mapeamento de recursos\n",
    "\n",
    "Uma maneira de ajustar melhor os dados é criar mais recursos a partir de cada ponto de dados. Na função fornecida `map_feature`, mapearemos os recursos em todos os termos polinomiais de $x_1$ e $x_2$ até a sexta potência.\n",
    "\n",
    "$$\\mathrm{map\\_feature}(x) = \n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_1^2\\\\\n",
    "x_1 x_2\\\\\n",
    "x_2^2\\\\\n",
    "x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1 x_2^5\\\\\n",
    "x_2^6\\end{array}\\right]$$\n",
    "\n",
    "Como resultado desse mapeamento, nosso vetor de dois recursos (as pontuações em dois testes de controle de qualidade) foi transformado em um vetor de 27 dimensões. \n",
    "\n",
    "- Um classificador de regressão logística treinado nesse vetor de recursos de dimensão mais alta terá um limite de decisão mais complexo e será não linear quando desenhado em nosso gráfico bidimensional. \n",
    "- Fornecemos a função `map_feature` para você em utils.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"Formato original dos dados:\", X_train.shape)\n",
    "\n",
    "mapped_X =  map_feature(X_train[:, 0], X_train[:, 1])\n",
    "print(\"Forma após o mapeamento de recursos:\", mapped_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também imprimir os primeiros elementos de `X_train` e `mapped_X` para ver a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"X_train[0] mapeado:\", mapped_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o mapeamento de recursos nos permita criar um classificador mais expressivo, ele também é mais suscetível ao ajuste excessivo. Nas próximas partes do exercício, você implementará a regressão logística regularizada para ajustar os dados e também verá por si mesmo como a regularização pode ajudar a combater o problema do ajuste excessivo.\n",
    "\n",
    "<a name=\"3.4\"></a>\n",
    "### 3.4 Função de custo para regressão logística regularizada\n",
    "\n",
    "Nesta parte, você implementará a função de custo para a regressão logística regularizada.\n",
    "\n",
    "Lembre-se de que, para a regressão logística regularizada, a função de custo tem a forma\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{m}  \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "Compare isso com a função de custo sem regularização (que você implementou acima), que tem o seguinte formato \n",
    "\n",
    "$$ J(\\mathbf{w}.b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\\right]$$\n",
    "\n",
    "A diferença é o termo de regularização, que é $$\\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$$ \n",
    "Observe que o parâmetro $b$ não é regularizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-05'></a>\n",
    "### Exercício 5\n",
    "\n",
    "Complete a função `compute_cost_reg` abaixo para calcular o seguinte termo para cada elemento em $w$ \n",
    "$$\\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "O código inicial adiciona isso ao custo sem regularização (que você calculou acima em `compute_cost`) para calcular o custo com regulatização.\n",
    "\n",
    "Se tiver dúvidas, você pode consultar as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Calcula o custo de todos os exemplos\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos, n recursos\n",
    "      y : (ndarray Shape (m,))  valor alvo\n",
    "      w : (ndarray Shape (n,))  valores dos parametros do modelo\n",
    "      b : (escalar)              valores dos parametros do modelo\n",
    "      lambda_ : (escalar, float) Controla a quantidade de regularização\n",
    "    Returns:\n",
    "      total_cost : (escalar)     custo \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Chama a função compute_cost que você implementou acima\n",
    "    cost_without_reg = compute_cost(X, y, w, b) \n",
    "    \n",
    "    # Você precisa calcular esse valor\n",
    "    reg_cost = 0.\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "        \n",
    "    \n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "    # Adicione o custo de regularização para obter o custo total\n",
    "    total_cost = cost_without_reg + reg_cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Veja como você pode estruturar a implementação geral dessa função\n",
    "    ```python \n",
    "       def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "   \n",
    "           m, n = X.shape\n",
    "    \n",
    "            # Chama a função compute_cost que você implementou acima\n",
    "            cost_without_reg = compute_cost(X, y, w, b) \n",
    "    \n",
    "            # Você precisa calcular esse valor\n",
    "            reg_cost = 0.\n",
    "    \n",
    "            ### INICIE SEU CÓDIGO AQUI ###\n",
    "            for j in range(n):\n",
    "                reg_cost_j = # Seu código aqui para calcular o custo de w[j]\n",
    "                reg_cost = reg_cost + reg_cost_j\n",
    "            reg_cost = (lambda_/(2 * m)) * reg_cost\n",
    "            ### TERMINE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "            # Adicione o custo de regularização para obter o custo total\n",
    "            total_cost = cost_without_reg + reg_cost\n",
    "\n",
    "        return total_cost\n",
    "    ```\n",
    "      Se ainda tiver dúvidas, você pode consultar as dicas apresentadas abaixo para descobrir como calcular o `reg_cost_j` \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular reg_cost_j</b></font></summary>\n",
    "           &emsp; &emsp; Você pode calcular reg_cost_j como <code>reg_cost_j = w[j]**2 </code> \n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to check your implementation of the `compute_cost_reg` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5\n",
    "initial_b = 0.5\n",
    "lambda_ = 0.5\n",
    "cost = compute_cost_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(\"Custo Regularizado :\", cost)\n",
    "\n",
    "# TESTE DA UNIDADE\n",
    "compute_cost_reg_test(compute_cost_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo Regularizado : <b></td>\n",
    "    <td> 0.6618252552483948 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.5\"></a>\n",
    "### 3.5 Gradiente para regressão logística regularizada\n",
    "\n",
    "Nesta seção, você implementará o gradiente para regressão logística regularizada.\n",
    "\n",
    "\n",
    "O gradiente da função de custo regularizado tem dois componentes. O primeiro, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ é um escalar, o outro é um vetor com a mesma forma dos parâmetros $\\mathbf{w}$, em que o elemento $j^\\mathrm{th}$ é definido da seguinte forma:\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b} = \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})$$\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} = \\left( \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j  \\quad\\, \\text{para} \\, j=0...(n-1)$$\n",
    "\n",
    "Compare isso com o gradiente da função de custo sem regularização (que você implementou acima), que tem a forma \n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "Como você pode ver,$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ é o mesmo, a diferença é o seguinte termo em $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, que é $$\\frac{\\lambda}{m} w_j  \\quad\\, \\text{para}\\,  j=0...(n-1)$$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-06'></a>\n",
    "### Exercício 6\n",
    "\n",
    "Preencha a função `compute_gradient_reg` abaixo para modificar o código abaixo e calcular o seguinte termo\n",
    "\n",
    "$$\\frac{\\lambda}{m} w_j \\quad\\, \\, \\text{for} \\, j=0...(n-1)$$\n",
    "\n",
    "O código inicial adicionará esse termo ao $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$ retornado de `compute_gradient` acima para obter o gradiente da função de custo regularizado.\n",
    "\n",
    "\n",
    "Se tiver dúvidas, você pode consultar as dicas apresentadas após a célula abaixo para ajudá-lo na implementação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
    "    \"\"\"\n",
    "    Calcula o gradiente para regressão logística com regularização\n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados,m exemplos, n recursos\n",
    "      y : (ndarray Shape (m,))  valor alvo\n",
    "      w : (ndarray Shape (n,))  valores de parâmetros do modelo\n",
    "      b : (scalar)                valores de parâmetros do modelo\n",
    "      lambda_ : (scalar,float)  constante de regularização\n",
    "    Returns\n",
    "      dj_db : (scalar)             O gradiente do custo em relação ao parâmetro b. \n",
    "      dj_dw : (ndarray Shape (n,)) O gradiente do custo em relação ao parâmetro w. \n",
    "\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "        \n",
    "    ### TERMINE SEU CÓDIGO AQUI ###\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Veja como você pode estruturar a implementação geral dessa função\n",
    "    ```python \n",
    "    def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
    "        m, n = X.shape\n",
    "    \n",
    "        dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "        ### INICIE SEU CÓDIGO AQUI ###\n",
    "        # Fazer um loop sobre os elementos de w\n",
    "        for j in range(n): \n",
    "            \n",
    "            dj_dw_j_reg = # Seu código aqui para calcular o termo de regularização para dj_dw[j]\n",
    "            \n",
    "            # Adicione o termo de regularização ao elemento correspondente de dj_dw\n",
    "            dj_dw[j] = dj_dw[j] + dj_dw_j_reg\n",
    "        \n",
    "        ### TERMINE SEU CÓDIGO AQUI ###\n",
    "        \n",
    "        return dj_db, dj_dw\n",
    "    ```\n",
    "  \n",
    "    Se ainda tiver dúvidas, consulte as dicas apresentadas abaixo para descobrir como calcular o `dj_dw_j_reg` \n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dicar para calcular dj_dw_j_reg</b></font></summary>\n",
    "           &emsp; &emsp; Você pode calcular dj_dw_j_reg com <code>dj_dw_j_reg = (lambda_ / m) * w[j] </code> \n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para verificar sua implementação da função `compute_gradient_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1) \n",
    "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5 \n",
    "initial_b = 0.5\n",
    " \n",
    "lambda_ = 0.5\n",
    "dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(f\"dj_db: {dj_db}\", )\n",
    "print(f\"Primeiros elementos de regularização dj_dw:\\n {dj_dw[:4].tolist()}\", )\n",
    "\n",
    "# TESTE DA UNIDADE    \n",
    "compute_gradient_reg_test(compute_gradient_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db:</b>0.07138288792343</td> </tr>\n",
    "  <tr>\n",
    "      <td> <b>Primeiros elementos de regularização dj_dw:</b> </td> </tr>\n",
    "   <tr>\n",
    "   <td> [[-0.010386028450548], [0.011409852883280], [0.0536273463274], [0.003140278267313]] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.6\"></a>\n",
    "### 3.6 Aprendendo parâmetros usando a descida gradiente\n",
    "\n",
    "Da mesma forma que nas partes anteriores, você usará a função de descida de gradiente implementada acima para aprender os parâmetros ideais $w$,$b$. \n",
    "- Se você tiver concluído corretamente o custo e o gradiente da regressão logística regularizada, deverá ser capaz de passar para a próxima célula para aprender os parâmetros $w$. \n",
    "- Depois de treinar nossos parâmetros, nós os usaremos para traçar o limite de decisão. \n",
    "\n",
    "**Nota**\n",
    "\n",
    "O bloco de código abaixo leva um bom tempo para ser executado, especialmente com uma versão não vetorizada. Você pode reduzir as `iterações` para testar sua implementação e iterar mais rapidamente. Se você tiver tempo mais tarde, execute 100.000 iterações para ver melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Inicialização dos parâmetros de ajuste\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "initial_b = 1.\n",
    "\n",
    "# Defina o parâmetro de regularização lambda_ (você pode tentar variar isso)\n",
    "lambda_ = 0.01    \n",
    "\n",
    "# Algumas configurações de descida de gradiente\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_mapped, y_train, initial_w, initial_b, \n",
    "                                    compute_cost_reg, compute_gradient_reg, \n",
    "                                    alpha, iterations, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>Saída Esperada: Custo < 0.5  (Clique para detalhes)</b>\n",
    "</summary>\n",
    "\n",
    "```\n",
    "# Com as seguintes configurações\n",
    "#np.random.seed(1)\n",
    "#initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "#initial_b = 1.\n",
    "#lambda_ = 0.01;                                          \n",
    "#iterations = 10000\n",
    "#alpha = 0.01\n",
    "Iteração    0: Custo     0.72   \n",
    "Iteração 1000: Custo     0.59   \n",
    "Iteração 2000: Custo     0.56   \n",
    "Iteração 3000: Custo     0.53   \n",
    "Iteração 4000: Custo     0.51   \n",
    "Iteração 5000: Custo     0.50   \n",
    "Iteração 6000: Custo     0.48   \n",
    "Iteração 7000: Custo     0.47   \n",
    "Iteração 8000: Custo     0.46   \n",
    "Iteração 9000: Custo     0.45   \n",
    "Iteração 9999: Custo     0.45       \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.7\"></a>\n",
    "### 3.7 Plotar fronteira de decisão\n",
    "Para ajudá-lo a visualizar o modelo aprendido por esse classificador, usaremos a nossa função `plot_decision_boundary` que plota o limite de decisão (não linear) que separa os exemplos positivos dos negativos. \n",
    "\n",
    "- Na função, plotamos o limite de decisão não linear calculando as previsões do classificador em uma grade com espaçamento uniforme e, em seguida, desenhamos um gráfico de contorno de onde as previsões mudam de y = 0 para y = 1.\n",
    "\n",
    "- Depois de aprender os parâmetros $w$,$b$, a próxima etapa é traçar um limite de decisão semelhante ao da Figura 4.\n",
    "\n",
    "<img src=\"images/figure 4.png\"  width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(w, b, X_mapped, y_train)\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Teste 2 de Microchip 2') \n",
    "# Set the x-axis label\n",
    "plt.xlabel('Teste 2 de Microchip 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.8\"></a>\n",
    "### 3.8 Avaliação do modelo de regressão logística regularizada\n",
    "\n",
    "Você usará a função `predict` que implementou acima para calcular a precisão do modelo de regressão logística regularizada no conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Calcule a precisão no conjunto de treinamento\n",
    "p = predict(X_mapped, w, b)\n",
    "\n",
    "print('Acurácia de Treino: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Acurácia de Treino:</b>~ 80%</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parabéns por ter concluído esse laboratório! No próximo tópico da disciplina você usará algoritmos de aprendizado mais avançados: redes neurais!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
