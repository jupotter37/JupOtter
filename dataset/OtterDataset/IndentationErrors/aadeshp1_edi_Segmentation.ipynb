{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72aa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc29ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/Users/atharva/Desktop/A. Segmentation/1. Original Images/a. Training Set/'\n",
    "mask_dir = '/Users/atharva/Desktop/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/3. Hard Exudates/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0042122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob.glob(image_dir + '*.jpg')\n",
    "mask_files = glob.glob(mask_dir + '*.tif') \n",
    "X = []  # Initialize the list to store preprocessed images\n",
    "Y = []  # Initialize the list to store masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3e5eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2890659318.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def unet_model(input_shape):\n",
    "   inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up2 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up2 = tf.keras.layers.Conv2D(128, 2, activation='relu', padding='same')(up2)\n",
    "    merge2 = tf.keras.layers.concatenate([conv2, up2], axis=3)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge2)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up1 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up1 = tf.keras.layers.Conv2D(64, 2, activation='relu', padding='same')(up1)\n",
    "    merge1 = tf.keras.layers.concatenate([conv1, up1], axis=3)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge1)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdba898",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_file in enumerate(image_files):\n",
    "    image = cv2.imread(image_file)\n",
    "    mask = cv2.imread(mask_files[i], cv2.IMREAD_GRAYSCALE)  # Updated to read .tif files as grayscale\n",
    "\n",
    "    # Preprocess and resize the image and mask\n",
    "    image = cv2.resize(image, (128, 128))  # Adjust the size as needed\n",
    "    mask = cv2.resize(mask, (128, 128))\n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    X.append(image)\n",
    "    Y.append(mask)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)  # Adjust the input shape according to your dataset\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, batch_size=32, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e17b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:21:39.402062: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-23 21:21:39.402133: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-23 21:21:39.402136: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-23 21:21:39.402207: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-23 21:21:39.402472: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:21:40.207532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 23s 3s/step - loss: 0.6771 - accuracy: 0.3592 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 17s 3s/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 6.9052e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 26s 4s/step - loss: 5.4095e-04 - accuracy: 1.0000 - val_loss: 8.3746e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 39s 4s/step - loss: 6.8482e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tDiscarded (victim of GPU error/recovery) (00000005:kIOGPUCommandBufferCallbackErrorInnocentVictim)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x11261e7a0>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x1410c5200>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x28a417a00>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x1410c5200>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 25s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141e4b890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "image_dir = '/Users/atharva/Desktop/A. Segmentation/1. Original Images/a. Training Set/'\n",
    "mask_dir = '/Users/atharva/Desktop/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/3. Hard Exudates/'\n",
    "image_files = glob.glob(image_dir + '*.jpg')\n",
    "mask_files = glob.glob(mask_dir + '*.tif')\n",
    "\n",
    "X = []  # Initialize the list to store preprocessed images\n",
    "Y = []  # Initialize the list to store masks\n",
    "\n",
    "def unet_model(input_shape):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up2 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up2 = tf.keras.layers.Conv2D(128, 2, activation='relu', padding='same')(up2)\n",
    "    merge2 = tf.keras.layers.concatenate([conv2, up2], axis=3)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge2)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up1 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up1 = tf.keras.layers.Conv2D(64, 2, activation='relu', padding='same')(up1)\n",
    "    merge1 = tf.keras.layers.concatenate([conv1, up1], axis=3)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge1)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Rest of your code for loading and preprocessing images\n",
    "\n",
    "for i, image_file in enumerate(image_files):\n",
    "    image = cv2.imread(image_file)\n",
    "    mask = cv2.imread(mask_files[i], cv2.IMREAD_GRAYSCALE)  # Updated to read .tif files as grayscale\n",
    "\n",
    "    # Preprocess and resize the image and mask\n",
    "    image = cv2.resize(image, (256, 256))  # Adjust the size as needed\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    X.append(image)\n",
    "    \n",
    "    # Ensure binary mask (you may need to adjust the threshold)\n",
    "    mask = (mask > 128).astype(np.float32)\n",
    "    Y.append(mask)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "input_shape = (256, 256, 3)  # Adjust the input shape according to your dataset\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adding Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=32, epochs=5, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5114daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharva/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Hard_Exudates.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1e566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:51:38.419594: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-23 21:51:38.419619: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-23 21:51:38.419622: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-23 21:51:38.419849: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-23 21:51:38.420220: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 21:51:39.225851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 22s 3s/step - loss: 0.6677 - accuracy: 0.9410 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 24s 3s/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 5.0555e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 26s 3s/step - loss: 3.9731e-04 - accuracy: 1.0000 - val_loss: 9.4249e-09 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 18s 2s/step - loss: 7.7968e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 16s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28f2540d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "image_dir = '/Users/atharva/Desktop/A. Segmentation/1. Original Images/a. Training Set/'\n",
    "mask_dir = '/Users/atharva/Desktop/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/1. Microaneurysms/'\n",
    "image_files = glob.glob(image_dir + '*.jpg')\n",
    "mask_files = glob.glob(mask_dir + '*.tif')\n",
    "\n",
    "X = []  # Initialize the list to store preprocessed images\n",
    "Y = []  # Initialize the list to store masks\n",
    "\n",
    "def unet_model(input_shape):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up2 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up2 = tf.keras.layers.Conv2D(128, 2, activation='relu', padding='same')(up2)\n",
    "    merge2 = tf.keras.layers.concatenate([conv2, up2], axis=3)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge2)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up1 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up1 = tf.keras.layers.Conv2D(64, 2, activation='relu', padding='same')(up1)\n",
    "    merge1 = tf.keras.layers.concatenate([conv1, up1], axis=3)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge1)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Rest of your code for loading and preprocessing images\n",
    "\n",
    "for i, image_file in enumerate(image_files):\n",
    "    image = cv2.imread(image_file)\n",
    "    mask = cv2.imread(mask_files[i], cv2.IMREAD_GRAYSCALE)  # Updated to read .tif files as grayscale\n",
    "\n",
    "    # Preprocess and resize the image and mask\n",
    "    image = cv2.resize(image, (256, 256))  # Adjust the size as needed\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    X.append(image)\n",
    "    \n",
    "    # Ensure binary mask (you may need to adjust the threshold)\n",
    "    mask = (mask > 128).astype(np.float32)\n",
    "    Y.append(mask)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "input_shape = (256, 256, 3)  # Adjust the input shape according to your dataset\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adding Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=32, epochs=5, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8ead1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharva/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Microaneurysms.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 53\n",
      "Number of masks: 53\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 20s 3s/step - loss: 0.6821 - accuracy: 0.2817 - val_loss: 0.4133 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 16s 2s/step - loss: 0.3487 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 15s 3s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 4.1526e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "image_dir = '/Users/atharva/Desktop/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages/a. Training Set/'\n",
    "mask_dir = '/Users/atharva/Desktop/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages/'\n",
    "image_files = glob.glob(image_dir + '*.jpg')\n",
    "mask_files = glob.glob(mask_dir + '*.tif')\n",
    "\n",
    "X = []  # Initialize the list to store preprocessed images\n",
    "Y = []  # Initialize the list to store masks\n",
    "print(\"Number of images:\", len(image_files))\n",
    "print(\"Number of masks:\", len(mask_files))\n",
    "\n",
    "def unet_model(input_shape):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up2 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up2 = tf.keras.layers.Conv2D(128, 2, activation='relu', padding='same')(up2)\n",
    "    merge2 = tf.keras.layers.concatenate([conv2, up2], axis=3)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge2)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up1 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up1 = tf.keras.layers.Conv2D(64, 2, activation='relu', padding='same')(up1)\n",
    "    merge1 = tf.keras.layers.concatenate([conv1, up1], axis=3)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge1)\n",
    "    conv5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Rest of your code for loading and preprocessing images\n",
    "\n",
    "for i, image_file in enumerate(image_files):\n",
    "    image = cv2.imread(image_file)\n",
    "    mask = cv2.imread(mask_files[i], cv2.IMREAD_GRAYSCALE)  # Updated to read .tif files as grayscale\n",
    "\n",
    "    # Preprocess and resize the image and mask\n",
    "    image = cv2.resize(image, (256, 256))  # Adjust the size as needed\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    X.append(image)\n",
    "    \n",
    "    # Ensure binary mask (you may need to adjust the threshold)\n",
    "    mask = (mask > 128).astype(np.float32)\n",
    "    Y.append(mask)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "input_shape = (256, 256, 3)  # Adjust the input shape according to your dataset\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adding Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X, Y, batch_size=32, epochs=5, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061aded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
