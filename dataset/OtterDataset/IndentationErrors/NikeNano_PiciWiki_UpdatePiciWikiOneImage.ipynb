{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from IPython import embed\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class MyPca():\n",
    "\n",
    "\tdef __init__(self,nbrOFeatures):\n",
    "\t\tself.pca=PCA(n_components=nbrOFeatures)\n",
    "\n",
    "\tdef flattenInput(self,x):\n",
    "\t\tif(x.shape!=2):\n",
    "\t\t\tprint(\"problem with the input!\")\n",
    "\t\tpass\n",
    "\n",
    "\tdef fitPca(self,X):\n",
    "\t\tself.pca.fit(x)\n",
    "\n",
    "\tdef transformPca(self,y):\n",
    "\t\treturn (self.pca.transform(y))\n",
    "\n",
    "class Extractor():\n",
    "\tdef __init__ (self):\n",
    "\t\tbase_model = InceptionV3(weights='imagenet')\n",
    "\t\tself.model = Model(inputs=base_model.input, outputs=base_model.get_layer('mixed9_1').output)\n",
    "\t\t#self.model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "\tdef loadAndPreprocess(self,input_path='cropped.jpg'):\n",
    "\t\timg_path = input_path\n",
    "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\treturn(x)\n",
    "\tdef predict(self,input_path='cropped.jpg'):\n",
    "\t\tx=self.loadAndPreprocess(input_path)\n",
    "\t\treturn self.model.predict(x)\n",
    "\n",
    "class Similarity():\n",
    "\n",
    " \tdef eucledianDistance(self,x,y):\n",
    " \t\treturn (np.sqrt(np.sum(np.power(a-b,2) for a, b in zip(x, y))))\n",
    " \tdef manhatttan(self,x,y):\n",
    " \t\treturn(sum(np.abs(a-b)for a,b in zip(x,y)))\n",
    " \tdef cosSimilarity(self,x,y):\n",
    " \t\tnumerator=np.dot(x,y)\n",
    " \t\tdenominator=np.linalg.norm(x)*np.linalg.norm(y)\n",
    " \t\t#print(np.abs(x))\n",
    " \t\treturn (numerator/denominator)\n",
    " \tdef chebyshev(self,x,y,root=3):\n",
    " \t\treturn(np.power(np.sum(np.power(a-b,2) for a,b in zip(x,y)),1/root))\n",
    "\n",
    " \tdef getAllSimilarities(self,x,y):\n",
    " \t\tsimilarity=[self.eucledianDistance(x,y),self.manhatttan(x,y),self.cosSimilarity(x,y),self.chebyshev(x,y)]\n",
    " \t\treturn (similarity)\n",
    "\n",
    "\n",
    "class BuildBase():\n",
    " \t\tpathList=[]\n",
    " \t\tmodel=Extractor()\n",
    " \t\tmeasureSimilary=Similarity()\n",
    "\n",
    " \t\tdef setImagePathCloths(self,inputList):\n",
    " \t\t\tself.pathList=inputList\n",
    " \t\tdef setImageExtracted(self,image):\n",
    " \t\t\tself.imageExtracted=image\n",
    " \t\tdef getSimilaririesForList(self):\n",
    " \t\t\tdistance=[]\n",
    " \t\t\tvectorsCloths=[]\n",
    " \t\t\tfor images in self.pathList:\n",
    " \t\t\t\tvectorsCloths.append(self.model.predict(images).flatten())\n",
    " \t\t\tfor images in self.imageExtracted:\n",
    " \t\t\t\tvectorImage=[self.model.predict(images).flatten()]\n",
    " \t\t\tfor index in range(0,len(vectorsCloths)):\n",
    " \t\t\t\tdistance.append(self.measureSimilary.getAllSimilarities(vectorImage[0],vectorsCloths[index]))\n",
    " \t\t\treturn (distance)\n",
    "\n",
    "#myPathList=['PicturesTest/HM1.jpg','PicturesTest/HM2.jpg','PicturesTest/HM3.jpg','PicturesTest/HM4.jpg','PicturesTest/HM5.jpg','PicturesTest/HM6.jpg']\n",
    "myPathList=['PicturesTest/HMTest1.jpg','PicturesTest/HMTest2.jpg','PicturesTest/HMTest3.jpg','PicturesTest/HMTest4.jpg','PicturesTest/HM2.jpg','PicturesTest/HM4.jpg','PicturesTest/HM1.jpg']\n",
    "test=BuildBase()\n",
    "test.setImagePathCloths(myPathList)\n",
    "embed()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72fbbcfe2587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-013ea791ece3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTracker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Niklas/Documents/Project_Emil/PiciWiki/models/research/object_detection/Tracker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolorsys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from Tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-7-e5a2812ce812>, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-e5a2812ce812>\"\u001b[0;36m, line \u001b[0;32m85\u001b[0m\n\u001b[0;31m    return result_list\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import webbrowser as wb\n",
    "import tkinter as tk\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "#from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "from collections import namedtuple\n",
    "from PIL import ImageTk\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Interactive ():\n",
    "    # What model to download.\n",
    "    MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "    MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "    NUM_CLASSES = 90\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loadModel()\n",
    "    def loadModel(self):\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(self.PATH_TO_CKPT, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "    def load_image_into_numpy_array(self,image):\n",
    "        (im_width, im_height) = image.size\n",
    "        return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "    def getBox(self,boxes,scores,classes,width,height):\n",
    "        boxes=np.squeeze(boxes)\n",
    "        scores=np.squeeze(scores)\n",
    "        classes=np.squeeze(classes).astype(np.int32)\n",
    "        myList=[]\n",
    "        for index,score in enumerate(scores):\n",
    "            if score > 0.5:\n",
    "                #print(\"here\")\n",
    "                x0=boxes[index][1]*width\n",
    "                y0=boxes[index][0]*height\n",
    "                x1=boxes[index][3]*width\n",
    "                y1=boxes[index][2]*height\n",
    "                myList.append([x0,y0,x1,y1,classes[index]])\n",
    "        return(myList)\n",
    "\n",
    "    def objectDetection(self,TEST_IMAGE_PATH):\n",
    "                    \n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np,\n",
    "                        np.squeeze(boxes),\n",
    "                        np.squeeze(classes).astype(np.int32),\n",
    "                        np.squeeze(scores),\n",
    "                        self.category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        line_thickness=8)\n",
    "                    #getBox(boxes, scores,classes,width,height)\n",
    "                    # The function aboe print the boxes and so on! \n",
    "                    # \n",
    "                    #plt.figure(figsize=IMAGE_SIZE)\n",
    "                    #plt.imshow(image_np)\n",
    "                    result_list.append(self.getBox(boxes, scores,classes,width,height))\n",
    "                return result_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Rect = namedtuple('Rect', 'x0, y0, x1, y1')\n",
    "\n",
    "#def cropImage2(crop_area,imagePath=TEST_IMAGE_PATH[0]):\n",
    "#    image=Image.open(imagePath)\n",
    "#    crop_area=crop_area\n",
    "#    image.show()\n",
    "#    print(crop_area)\n",
    "#    image_cropped = image.crop(crop_area)\n",
    "#    print(\"here\")\n",
    "#    image_cropped.show()\n",
    "\n",
    "class ImageMapper(object):\n",
    "    def __init__(self, image, img_rects):\n",
    "        self.width, self.height = image.width(), image.height()\n",
    "        #print(self.width, self.height)\n",
    "        self.img_rects = img_rects\n",
    "        \n",
    "    def find_rect(self, x, y):\n",
    "        #print(x,y)\n",
    "        for i, r in enumerate(self.img_rects):\n",
    "            if (r.x0 <= x <= r.x1) and (r.y0 <= y <= r.y1):\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "class Demo(tk.Frame):\n",
    "    image_reacts=[]\n",
    "    Rect = namedtuple('Rect', 'x0, y0, x1, y1')\n",
    "    labels=[]\n",
    "    PATH_TO_TEST_IMAGES_DIR = 'PicturesTest'\n",
    "    TEST_IMAGE_PATH = [ os.path.join('PicturesTest', 'HM{}.jpg'.format(i)) for i in range(3, 4) ]\n",
    "\n",
    "    def __init__(self, reacts,labels,master=None,):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        self.grid()\n",
    "        self.create_widgets()\n",
    "        self.setReact(reacts)\n",
    "        self.setLabels(labels)\n",
    "        self.myPathList=['PicturesTest/HM0.jpg','PicturesTest/HM1.jpg','PicturesTest/HM2.jpg','PicturesTest/HM3.jpg','PicturesTest/HM4.jpg']\n",
    "        self.similarityModel=BuildBase()\n",
    "        self.similarityModel.setImagePathCloths(self.myPathList)\n",
    "    \n",
    "    def setReact(self,image_rects):\n",
    "        for image_react in image_rects:\n",
    "            self.image_reacts.append(image_react)\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        self.msg_text = tk.StringVar()\n",
    "        self.msg = tk.Message(self, textvariable=self.msg_text, width=100)\n",
    "        self.msg.grid(row=0, column=0)\n",
    "\n",
    "        #self.picture = tk.PhotoImage(file='image1.gif')\n",
    "                        # 'x0, y0, x1, y1'\n",
    "        #img_rects = [Rect(24, 24, 326, 548),\n",
    "                     #Rect(401, 63, 996, 609)]\n",
    "        #self.imagemapper = ImageMapper(self.picture, img_rects)\n",
    "        path = TEST_IMAGE_PATH[0]\n",
    "\n",
    "        #Creates a Tkinter-compatible photo image, which can be used everywhere Tkinter expects an image object.\n",
    "        self.picture = ImageTk.PhotoImage(Image.open(path))\n",
    "\n",
    "        self.imagemapper = ImageMapper(self.picture, self.image_reacts)\n",
    "        # use Label widget to display image\n",
    "        self.image = tk.Label(self, image=self.picture, borderwidth=0)\n",
    "        self.image.bind('<Button-1>', self.image_click)\n",
    "        self.image.grid(row=1, column=0)\n",
    "\n",
    "        self.quitButton = tk.Button(self, text='Quit', command=self.quit)\n",
    "        self.quitButton.grid(row=2, column=0)\n",
    "\n",
    "    def image_click(self, event):\n",
    "        hit = self.imagemapper.find_rect(event.x, event.y)\n",
    "        self.msg_text.set('{} clicked'.format('nothing' if hit is None else\n",
    "                                              'rect[{}]'.format(hit)))\n",
    "        #print(\"the label of the hit is {}\".format(self.labels[hit]))\n",
    "        num=self.labels[hit]\n",
    "        image_object=self.image_reacts[hit]\n",
    "        crop_area= (image_object.x0,image_object.y0,image_object.x1,image_object.y1)\n",
    "        self.cropImage(crop_area,self.TEST_IMAGE_PATH[0])\n",
    "        #self.openLink(num)\n",
    "    \n",
    "    def setLabels(self,labels):\n",
    "        self.labels=labels\n",
    "           \n",
    "    def openLink(self, Url):\n",
    "        print(Url)\n",
    "        wb.open_new_tab(Url)\n",
    "        \n",
    "    def cropImage(self, crop_area,imagePath):\n",
    "        img=Image.open(imagePath)\n",
    "        #crop_area=crop_area\n",
    "        crop_area=crop_area\n",
    "        image_cropped = img.crop(crop_area)\n",
    "        width, height = img.size\n",
    "        #print(img.size)\n",
    "        #print(\"here\")\n",
    "        #image_cropped.show()\n",
    "        image_cropped.save(\"PicturesTest/out.jpg\", \"JPEG\")\n",
    "        EXTRACTED_IMAGE_PATH = ['PicturesTest/out.jpg']\n",
    "        self.similarityModel.setImageExtracted(EXTRACTED_IMAGE_PATH)\n",
    "        #self.nicePrintOut(self.similarityModel.getSimilaririesForList())\n",
    "        self.openUrl(self.similarityModel.getSimilaririesForList())\n",
    "        \n",
    "    #def nicePrintOut(self,listsOfSimilarity):\n",
    "    #    for list in listsOfSimilarity:\n",
    "    #        print(list)\n",
    "    #        print('/n')\n",
    "        \n",
    "    def openUrl(self,listsOfSimilarity):\n",
    "        mydict=dict()\n",
    "        for index,myList in enumerate(listsOfSimilarity):\n",
    "            mydict[self.myPathList[index]]=(myList[2],'http://www.hm.com/se/erdem')\n",
    "        self.openLink(mydict[max(mydict, key=mydict.get)][1])\n",
    "        \n",
    "        \n",
    "PATH_TO_TEST_IMAGES_DIR = 'PicturesTest'\n",
    "TEST_IMAGE_PATH = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'HM{}.jpg'.format(i)) for i in range(3, 4) ]\n",
    "model = Interactive()\n",
    "results = model.objectDetection(TEST_IMAGE_PATH)\n",
    "results = np.squeeze(results)\n",
    "Reacts = []\n",
    "Labels = []\n",
    "try:\n",
    "    results.shape[1]\n",
    "    for result in results:\n",
    "        Reacts.append(Rect(result[0], result[1],result[2], result[3]))\n",
    "        Labels.append(result[4])\n",
    "except (ValueError,IndexError):\n",
    "    Reacts.append(Rect(results[0], results[1],results[2], results[3]))\n",
    "    Labels.append(results[4])\n",
    "app = Demo(Reacts,Labels)\n",
    "app.master.title('Image Mapper')\n",
    "app.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
