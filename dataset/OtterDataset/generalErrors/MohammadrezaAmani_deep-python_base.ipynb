{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the Django template system.\n",
    "\n",
    "How it works:\n",
    "\n",
    "The Lexer.tokenize() method converts a template string (i.e., a string\n",
    "containing markup with custom template tags) to tokens, which can be either\n",
    "plain text (TokenType.TEXT), variables (TokenType.VAR), or block statements\n",
    "(TokenType.BLOCK).\n",
    "\n",
    "The Parser() class takes a list of tokens in its constructor, and its parse()\n",
    "method returns a compiled template -- which is, under the hood, a list of\n",
    "Node objects.\n",
    "\n",
    "Each Node is responsible for creating some sort of output -- e.g. simple text\n",
    "(TextNode), variable values in a given context (VariableNode), results of basic\n",
    "logic (IfNode), results of looping (ForNode), or anything else. The core Node\n",
    "types are TextNode, VariableNode, IfNode and ForNode, but plugin modules can\n",
    "define their own custom node types.\n",
    "\n",
    "Each Node has a render() method, which takes a Context and returns a string of\n",
    "the rendered node. For example, the render() method of a Variable Node returns\n",
    "the variable's value as a string. The render() method of a ForNode returns the\n",
    "rendered output of whatever was inside the loop, recursively.\n",
    "\n",
    "The Template class is a convenient wrapper that takes care of template\n",
    "compilation and rendering.\n",
    "\n",
    "Usage:\n",
    "\n",
    "The only thing you should ever use directly in this file is the Template class.\n",
    "Create a compiled template object with a template_string, then call render()\n",
    "with a context. In the compilation stage, the TemplateSyntaxError exception\n",
    "will be raised if the template doesn't have proper syntax.\n",
    "\n",
    "Sample code:\n",
    "\n",
    ">>> from django import template\n",
    ">>> s = '<html>{% if test %}<h1>{{ varvalue }}</h1>{% endif %}</html>'\n",
    ">>> t = template.Template(s)\n",
    "\n",
    "(t is now a compiled template, and its render() method can be called multiple\n",
    "times with multiple contexts)\n",
    "\n",
    ">>> c = template.Context({'test':True, 'varvalue': 'Hello'})\n",
    ">>> t.render(c)\n",
    "'<html><h1>Hello</h1></html>'\n",
    ">>> c = template.Context({'test':False, 'varvalue': 'Hello'})\n",
    ">>> t.render(c)\n",
    "'<html></html>'\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "import logging\n",
    "import re\n",
    "from enum import Enum\n",
    "\n",
    "from django.template.context import BaseContext\n",
    "from django.utils.formats import localize\n",
    "from django.utils.html import conditional_escape, escape\n",
    "from django.utils.regex_helper import _lazy_re_compile\n",
    "from django.utils.safestring import SafeData, SafeString, mark_safe\n",
    "from django.utils.text import get_text_list, smart_split, unescape_string_literal\n",
    "from django.utils.timezone import template_localtime\n",
    "from django.utils.translation import gettext_lazy, pgettext_lazy\n",
    "\n",
    "from .exceptions import TemplateSyntaxError\n",
    "\n",
    "# template syntax constants\n",
    "FILTER_SEPARATOR = \"|\"\n",
    "FILTER_ARGUMENT_SEPARATOR = \":\"\n",
    "VARIABLE_ATTRIBUTE_SEPARATOR = \".\"\n",
    "BLOCK_TAG_START = \"{%\"\n",
    "BLOCK_TAG_END = \"%}\"\n",
    "VARIABLE_TAG_START = \"{{\"\n",
    "VARIABLE_TAG_END = \"}}\"\n",
    "COMMENT_TAG_START = \"{#\"\n",
    "COMMENT_TAG_END = \"#}\"\n",
    "SINGLE_BRACE_START = \"{\"\n",
    "SINGLE_BRACE_END = \"}\"\n",
    "\n",
    "# what to report as the origin for templates that come from non-loader sources\n",
    "# (e.g. strings)\n",
    "UNKNOWN_SOURCE = \"<unknown source>\"\n",
    "\n",
    "# Match BLOCK_TAG_*, VARIABLE_TAG_*, and COMMENT_TAG_* tags and capture the\n",
    "# entire tag, including start/end delimiters. Using re.compile() is faster\n",
    "# than instantiating SimpleLazyObject with _lazy_re_compile().\n",
    "tag_re = re.compile(r\"({%.*?%}|{{.*?}}|{#.*?#})\")\n",
    "\n",
    "logger = logging.getLogger(\"django.template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenType(Enum):\n",
    "    TEXT = 0\n",
    "    VAR = 1\n",
    "    BLOCK = 2\n",
    "    COMMENT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableDoesNotExist(Exception):\n",
    "    def __init__(self, msg, params=()):\n",
    "        self.msg = msg\n",
    "        self.params = params\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.msg % self.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Origin:\n",
    "    def __init__(self, name, template_name=None, loader=None):\n",
    "        self.name = name\n",
    "        self.template_name = template_name\n",
    "        self.loader = loader\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<%s name=%r>\" % (self.__class__.__qualname__, self.name)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            isinstance(other, Origin)\n",
    "            and self.name == other.name\n",
    "            and self.loader == other.loader\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def loader_name(self):\n",
    "        if self.loader:\n",
    "            return \"%s.%s\" % (\n",
    "                self.loader.__module__,\n",
    "                self.loader.__class__.__name__,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Template:\n",
    "    def __init__(self, template_string, origin=None, name=None, engine=None):\n",
    "        # If Template is instantiated directly rather than from an Engine and\n",
    "        # exactly one Django template engine is configured, use that engine.\n",
    "        # This is required to preserve backwards-compatibility for direct use\n",
    "        # e.g. Template('...').render(Context({...}))\n",
    "        if engine is None:\n",
    "            from .engine import Engine\n",
    "\n",
    "            engine = Engine.get_default()\n",
    "        if origin is None:\n",
    "            origin = Origin(UNKNOWN_SOURCE)\n",
    "        self.name = name\n",
    "        self.origin = origin\n",
    "        self.engine = engine\n",
    "        self.source = str(template_string)  # May be lazy.\n",
    "        self.nodelist = self.compile_nodelist()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<%s template_string=\"%s...\">' % (\n",
    "            self.__class__.__qualname__,\n",
    "            self.source[:20].replace(\"\\n\", \"\"),\n",
    "        )\n",
    "\n",
    "    def _render(self, context):\n",
    "        return self.nodelist.render(context)\n",
    "\n",
    "    def render(self, context):\n",
    "        \"Display stage -- can be called many times\"\n",
    "        with context.render_context.push_state(self):\n",
    "            if context.template is None:\n",
    "                with context.bind_template(self):\n",
    "                    context.template_name = self.name\n",
    "                    return self._render(context)\n",
    "            else:\n",
    "                return self._render(context)\n",
    "\n",
    "    def compile_nodelist(self):\n",
    "        \"\"\"\n",
    "        Parse and compile the template source into a nodelist. If debug\n",
    "        is True and an exception occurs during parsing, the exception is\n",
    "        annotated with contextual line information where it occurred in the\n",
    "        template source.\n",
    "        \"\"\"\n",
    "        if self.engine.debug:\n",
    "            lexer = DebugLexer(self.source)\n",
    "        else:\n",
    "            lexer = Lexer(self.source)\n",
    "\n",
    "        tokens = lexer.tokenize()\n",
    "        parser = Parser(\n",
    "            tokens,\n",
    "            self.engine.template_libraries,\n",
    "            self.engine.template_builtins,\n",
    "            self.origin,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            return parser.parse()\n",
    "        except Exception as e:\n",
    "            if self.engine.debug:\n",
    "                e.template_debug = self.get_exception_info(e, e.token)\n",
    "            raise\n",
    "\n",
    "    def get_exception_info(self, exception, token):\n",
    "        \"\"\"\n",
    "        Return a dictionary containing contextual line information of where\n",
    "        the exception occurred in the template. The following information is\n",
    "        provided:\n",
    "\n",
    "        message\n",
    "            The message of the exception raised.\n",
    "\n",
    "        source_lines\n",
    "            The lines before, after, and including the line the exception\n",
    "            occurred on.\n",
    "\n",
    "        line\n",
    "            The line number the exception occurred on.\n",
    "\n",
    "        before, during, after\n",
    "            The line the exception occurred on split into three parts:\n",
    "            1. The content before the token that raised the error.\n",
    "            2. The token that raised the error.\n",
    "            3. The content after the token that raised the error.\n",
    "\n",
    "        total\n",
    "            The number of lines in source_lines.\n",
    "\n",
    "        top\n",
    "            The line number where source_lines starts.\n",
    "\n",
    "        bottom\n",
    "            The line number where source_lines ends.\n",
    "\n",
    "        start\n",
    "            The start position of the token in the template source.\n",
    "\n",
    "        end\n",
    "            The end position of the token in the template source.\n",
    "        \"\"\"\n",
    "        start, end = token.position\n",
    "        context_lines = 10\n",
    "        line = 0\n",
    "        upto = 0\n",
    "        source_lines = []\n",
    "        before = during = after = \"\"\n",
    "        for num, next in enumerate(linebreak_iter(self.source)):\n",
    "            if start >= upto and end <= next:\n",
    "                line = num\n",
    "                before = escape(self.source[upto:start])\n",
    "                during = escape(self.source[start:end])\n",
    "                after = escape(self.source[end:next])\n",
    "            source_lines.append((num, escape(self.source[upto:next])))\n",
    "            upto = next\n",
    "        total = len(source_lines)\n",
    "\n",
    "        top = max(1, line - context_lines)\n",
    "        bottom = min(total, line + 1 + context_lines)\n",
    "\n",
    "        # In some rare cases exc_value.args can be empty or an invalid\n",
    "        # string.\n",
    "        try:\n",
    "            message = str(exception.args[0])\n",
    "        except (IndexError, UnicodeDecodeError):\n",
    "            message = \"(Could not get exception message)\"\n",
    "\n",
    "        return {\n",
    "            \"message\": message,\n",
    "            \"source_lines\": source_lines[top:bottom],\n",
    "            \"before\": before,\n",
    "            \"during\": during,\n",
    "            \"after\": after,\n",
    "            \"top\": top,\n",
    "            \"bottom\": bottom,\n",
    "            \"total\": total,\n",
    "            \"line\": line,\n",
    "            \"name\": self.origin.name,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linebreak_iter(template_source):\n",
    "    yield 0\n",
    "    p = template_source.find(\"\\n\")\n",
    "    while p >= 0:\n",
    "        yield p + 1\n",
    "        p = template_source.find(\"\\n\", p + 1)\n",
    "    yield len(template_source) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, token_type, contents, position=None, lineno=None):\n",
    "        \"\"\"\n",
    "        A token representing a string from the template.\n",
    "\n",
    "        token_type\n",
    "            A TokenType, either .TEXT, .VAR, .BLOCK, or .COMMENT.\n",
    "\n",
    "        contents\n",
    "            The token source string.\n",
    "\n",
    "        position\n",
    "            An optional tuple containing the start and end index of the token\n",
    "            in the template source. This is used for traceback information\n",
    "            when debug is on.\n",
    "\n",
    "        lineno\n",
    "            The line number the token appears on in the template source.\n",
    "            This is used for traceback information and gettext files.\n",
    "        \"\"\"\n",
    "        self.token_type = token_type\n",
    "        self.contents = contents\n",
    "        self.lineno = lineno\n",
    "        self.position = position\n",
    "\n",
    "    def __repr__(self):\n",
    "        token_name = self.token_type.name.capitalize()\n",
    "        return '<%s token: \"%s...\">' % (\n",
    "            token_name,\n",
    "            self.contents[:20].replace(\"\\n\", \"\"),\n",
    "        )\n",
    "\n",
    "    def split_contents(self):\n",
    "        split = []\n",
    "        bits = smart_split(self.contents)\n",
    "        for bit in bits:\n",
    "            # Handle translation-marked template pieces\n",
    "            if bit.startswith(('_(\"', \"_('\")):\n",
    "                sentinel = bit[2] + \")\"\n",
    "                trans_bit = [bit]\n",
    "                while not bit.endswith(sentinel):\n",
    "                    bit = next(bits)\n",
    "                    trans_bit.append(bit)\n",
    "                bit = \" \".join(trans_bit)\n",
    "            split.append(bit)\n",
    "        return split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self, template_string):\n",
    "        self.template_string = template_string\n",
    "        self.verbatim = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<%s template_string=\"%s...\", verbatim=%s>' % (\n",
    "            self.__class__.__qualname__,\n",
    "            self.template_string[:20].replace(\"\\n\", \"\"),\n",
    "            self.verbatim,\n",
    "        )\n",
    "\n",
    "    def tokenize(self):\n",
    "        \"\"\"\n",
    "        Return a list of tokens from a given template_string.\n",
    "        \"\"\"\n",
    "        in_tag = False\n",
    "        lineno = 1\n",
    "        result = []\n",
    "        for token_string in tag_re.split(self.template_string):\n",
    "            if token_string:\n",
    "                result.append(self.create_token(token_string, None, lineno, in_tag))\n",
    "                lineno += token_string.count(\"\\n\")\n",
    "            in_tag = not in_tag\n",
    "        return result\n",
    "\n",
    "    def create_token(self, token_string, position, lineno, in_tag):\n",
    "        \"\"\"\n",
    "        Convert the given token string into a new Token object and return it.\n",
    "        If in_tag is True, we are processing something that matched a tag,\n",
    "        otherwise it should be treated as a literal string.\n",
    "        \"\"\"\n",
    "        if in_tag:\n",
    "            # The [0:2] and [2:-2] ranges below strip off *_TAG_START and\n",
    "            # *_TAG_END. The 2's are hard-coded for performance. Using\n",
    "            # len(BLOCK_TAG_START) would permit BLOCK_TAG_START to be\n",
    "            # different, but it's not likely that the TAG_START values will\n",
    "            # change anytime soon.\n",
    "            token_start = token_string[0:2]\n",
    "            if token_start == BLOCK_TAG_START:\n",
    "                content = token_string[2:-2].strip()\n",
    "                if self.verbatim:\n",
    "                    # Then a verbatim block is being processed.\n",
    "                    if content != self.verbatim:\n",
    "                        return Token(TokenType.TEXT, token_string, position, lineno)\n",
    "                    # Otherwise, the current verbatim block is ending.\n",
    "                    self.verbatim = False\n",
    "                elif content[:9] in (\"verbatim\", \"verbatim \"):\n",
    "                    # Then a verbatim block is starting.\n",
    "                    self.verbatim = \"end%s\" % content\n",
    "                return Token(TokenType.BLOCK, content, position, lineno)\n",
    "            if not self.verbatim:\n",
    "                content = token_string[2:-2].strip()\n",
    "                if token_start == VARIABLE_TAG_START:\n",
    "                    return Token(TokenType.VAR, content, position, lineno)\n",
    "                # BLOCK_TAG_START was handled above.\n",
    "                assert token_start == COMMENT_TAG_START\n",
    "                return Token(TokenType.COMMENT, content, position, lineno)\n",
    "        return Token(TokenType.TEXT, token_string, position, lineno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugLexer(Lexer):\n",
    "    def _tag_re_split_positions(self):\n",
    "        last = 0\n",
    "        for match in tag_re.finditer(self.template_string):\n",
    "            start, end = match.span()\n",
    "            yield last, start\n",
    "            yield start, end\n",
    "            last = end\n",
    "        yield last, len(self.template_string)\n",
    "\n",
    "    # This parallels the use of tag_re.split() in Lexer.tokenize().\n",
    "    def _tag_re_split(self):\n",
    "        for position in self._tag_re_split_positions():\n",
    "            yield self.template_string[slice(*position)], position\n",
    "\n",
    "    def tokenize(self):\n",
    "        \"\"\"\n",
    "        Split a template string into tokens and annotates each token with its\n",
    "        start and end position in the source. This is slower than the default\n",
    "        lexer so only use it when debug is True.\n",
    "        \"\"\"\n",
    "        # For maintainability, it is helpful if the implementation below can\n",
    "        # continue to closely parallel Lexer.tokenize()'s implementation.\n",
    "        in_tag = False\n",
    "        lineno = 1\n",
    "        result = []\n",
    "        for token_string, position in self._tag_re_split():\n",
    "            if token_string:\n",
    "                result.append(self.create_token(token_string, position, lineno, in_tag))\n",
    "                lineno += token_string.count(\"\\n\")\n",
    "            in_tag = not in_tag\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, tokens, libraries=None, builtins=None, origin=None):\n",
    "        # Reverse the tokens so delete_first_token(), prepend_token(), and\n",
    "        # next_token() can operate at the end of the list in constant time.\n",
    "        self.tokens = list(reversed(tokens))\n",
    "        self.tags = {}\n",
    "        self.filters = {}\n",
    "        self.command_stack = []\n",
    "\n",
    "        if libraries is None:\n",
    "            libraries = {}\n",
    "        if builtins is None:\n",
    "            builtins = []\n",
    "\n",
    "        self.libraries = libraries\n",
    "        for builtin in builtins:\n",
    "            self.add_library(builtin)\n",
    "        self.origin = origin\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<%s tokens=%r>\" % (self.__class__.__qualname__, self.tokens)\n",
    "\n",
    "    def parse(self, parse_until=None):\n",
    "        \"\"\"\n",
    "        Iterate through the parser tokens and compiles each one into a node.\n",
    "\n",
    "        If parse_until is provided, parsing will stop once one of the\n",
    "        specified tokens has been reached. This is formatted as a list of\n",
    "        tokens, e.g. ['elif', 'else', 'endif']. If no matching token is\n",
    "        reached, raise an exception with the unclosed block tag details.\n",
    "        \"\"\"\n",
    "        if parse_until is None:\n",
    "            parse_until = []\n",
    "        nodelist = NodeList()\n",
    "        while self.tokens:\n",
    "            token = self.next_token()\n",
    "            # Use the raw values here for TokenType.* for a tiny performance boost.\n",
    "            token_type = token.token_type.value\n",
    "            if token_type == 0:  # TokenType.TEXT\n",
    "                self.extend_nodelist(nodelist, TextNode(token.contents), token)\n",
    "            elif token_type == 1:  # TokenType.VAR\n",
    "                if not token.contents:\n",
    "                    raise self.error(\n",
    "                        token, \"Empty variable tag on line %d\" % token.lineno\n",
    "                    )\n",
    "                try:\n",
    "                    filter_expression = self.compile_filter(token.contents)\n",
    "                except TemplateSyntaxError as e:\n",
    "                    raise self.error(token, e)\n",
    "                var_node = VariableNode(filter_expression)\n",
    "                self.extend_nodelist(nodelist, var_node, token)\n",
    "            elif token_type == 2:  # TokenType.BLOCK\n",
    "                try:\n",
    "                    command = token.contents.split()[0]\n",
    "                except IndexError:\n",
    "                    raise self.error(token, \"Empty block tag on line %d\" % token.lineno)\n",
    "                if command in parse_until:\n",
    "                    # A matching token has been reached. Return control to\n",
    "                    # the caller. Put the token back on the token list so the\n",
    "                    # caller knows where it terminated.\n",
    "                    self.prepend_token(token)\n",
    "                    return nodelist\n",
    "                # Add the token to the command stack. This is used for error\n",
    "                # messages if further parsing fails due to an unclosed block\n",
    "                # tag.\n",
    "                self.command_stack.append((command, token))\n",
    "                # Get the tag callback function from the ones registered with\n",
    "                # the parser.\n",
    "                try:\n",
    "                    compile_func = self.tags[command]\n",
    "                except KeyError:\n",
    "                    self.invalid_block_tag(token, command, parse_until)\n",
    "                # Compile the callback into a node object and add it to\n",
    "                # the node list.\n",
    "                try:\n",
    "                    compiled_result = compile_func(self, token)\n",
    "                except Exception as e:\n",
    "                    raise self.error(token, e)\n",
    "                self.extend_nodelist(nodelist, compiled_result, token)\n",
    "                # Compile success. Remove the token from the command stack.\n",
    "                self.command_stack.pop()\n",
    "        if parse_until:\n",
    "            self.unclosed_block_tag(parse_until)\n",
    "        return nodelist\n",
    "\n",
    "    def skip_past(self, endtag):\n",
    "        while self.tokens:\n",
    "            token = self.next_token()\n",
    "            if token.token_type == TokenType.BLOCK and token.contents == endtag:\n",
    "                return\n",
    "        self.unclosed_block_tag([endtag])\n",
    "\n",
    "    def extend_nodelist(self, nodelist, node, token):\n",
    "        # Check that non-text nodes don't appear before an extends tag.\n",
    "        if node.must_be_first and nodelist.contains_nontext:\n",
    "            raise self.error(\n",
    "                token,\n",
    "                \"%r must be the first tag in the template.\" % node,\n",
    "            )\n",
    "        if not isinstance(node, TextNode):\n",
    "            nodelist.contains_nontext = True\n",
    "        # Set origin and token here since we can't modify the node __init__()\n",
    "        # method.\n",
    "        node.token = token\n",
    "        node.origin = self.origin\n",
    "        nodelist.append(node)\n",
    "\n",
    "    def error(self, token, e):\n",
    "        \"\"\"\n",
    "        Return an exception annotated with the originating token. Since the\n",
    "        parser can be called recursively, check if a token is already set. This\n",
    "        ensures the innermost token is highlighted if an exception occurs,\n",
    "        e.g. a compile error within the body of an if statement.\n",
    "        \"\"\"\n",
    "        if not isinstance(e, Exception):\n",
    "            e = TemplateSyntaxError(e)\n",
    "        if not hasattr(e, \"token\"):\n",
    "            e.token = token\n",
    "        return e\n",
    "\n",
    "    def invalid_block_tag(self, token, command, parse_until=None):\n",
    "        if parse_until:\n",
    "            raise self.error(\n",
    "                token,\n",
    "                \"Invalid block tag on line %d: '%s', expected %s. Did you \"\n",
    "                \"forget to register or load this tag?\"\n",
    "                % (\n",
    "                    token.lineno,\n",
    "                    command,\n",
    "                    get_text_list([\"'%s'\" % p for p in parse_until], \"or\"),\n",
    "                ),\n",
    "            )\n",
    "        raise self.error(\n",
    "            token,\n",
    "            \"Invalid block tag on line %d: '%s'. Did you forget to register \"\n",
    "            \"or load this tag?\" % (token.lineno, command),\n",
    "        )\n",
    "\n",
    "    def unclosed_block_tag(self, parse_until):\n",
    "        command, token = self.command_stack.pop()\n",
    "        msg = \"Unclosed tag on line %d: '%s'. Looking for one of: %s.\" % (\n",
    "            token.lineno,\n",
    "            command,\n",
    "            \", \".join(parse_until),\n",
    "        )\n",
    "        raise self.error(token, msg)\n",
    "\n",
    "    def next_token(self):\n",
    "        return self.tokens.pop()\n",
    "\n",
    "    def prepend_token(self, token):\n",
    "        self.tokens.append(token)\n",
    "\n",
    "    def delete_first_token(self):\n",
    "        del self.tokens[-1]\n",
    "\n",
    "    def add_library(self, lib):\n",
    "        self.tags.update(lib.tags)\n",
    "        self.filters.update(lib.filters)\n",
    "\n",
    "    def compile_filter(self, token):\n",
    "        \"\"\"\n",
    "        Convenient wrapper for FilterExpression\n",
    "        \"\"\"\n",
    "        return FilterExpression(token, self)\n",
    "\n",
    "    def find_filter(self, filter_name):\n",
    "        if filter_name in self.filters:\n",
    "            return self.filters[filter_name]\n",
    "        else:\n",
    "            raise TemplateSyntaxError(\"Invalid filter: '%s'\" % filter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only matches constant *strings* (things in quotes or marked for\n",
    "# translation). Numbers are treated as variables for implementation reasons\n",
    "# (so that they retain their type when passed to filters).\n",
    "constant_string = r\"\"\"\n",
    "(?:%(i18n_open)s%(strdq)s%(i18n_close)s|\n",
    "%(i18n_open)s%(strsq)s%(i18n_close)s|\n",
    "%(strdq)s|\n",
    "%(strsq)s)\n",
    "\"\"\" % {\n",
    "    \"strdq\": r'\"[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\"',  # double-quoted string\n",
    "    \"strsq\": r\"'[^'\\\\]*(?:\\\\.[^'\\\\]*)*'\",  # single-quoted string\n",
    "    \"i18n_open\": re.escape(\"_(\"),\n",
    "    \"i18n_close\": re.escape(\")\"),\n",
    "}\n",
    "constant_string = constant_string.replace(\"\\n\", \"\")\n",
    "\n",
    "filter_raw_string = r\"\"\"\n",
    "^(?P<constant>%(constant)s)|\n",
    "^(?P<var>[%(var_chars)s]+|%(num)s)|\n",
    " (?:\\s*%(filter_sep)s\\s*\n",
    "     (?P<filter_name>\\w+)\n",
    "         (?:%(arg_sep)s\n",
    "             (?:\n",
    "              (?P<constant_arg>%(constant)s)|\n",
    "              (?P<var_arg>[%(var_chars)s]+|%(num)s)\n",
    "             )\n",
    "         )?\n",
    " )\"\"\" % {\n",
    "    \"constant\": constant_string,\n",
    "    \"num\": r\"[-+.]?\\d[\\d.e]*\",\n",
    "    \"var_chars\": r\"\\w\\.\",\n",
    "    \"filter_sep\": re.escape(FILTER_SEPARATOR),\n",
    "    \"arg_sep\": re.escape(FILTER_ARGUMENT_SEPARATOR),\n",
    "}\n",
    "\n",
    "filter_re = _lazy_re_compile(filter_raw_string, re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterExpression:\n",
    "    \"\"\"\n",
    "    Parse a variable token and its optional filters (all as a single string),\n",
    "    and return a list of tuples of the filter name and arguments.\n",
    "    Sample::\n",
    "\n",
    "        >>> token = 'variable|default:\"Default value\"|date:\"Y-m-d\"'\n",
    "        >>> p = Parser('')\n",
    "        >>> fe = FilterExpression(token, p)\n",
    "        >>> len(fe.filters)\n",
    "        2\n",
    "        >>> fe.var\n",
    "        <Variable: 'variable'>\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"token\", \"filters\", \"var\", \"is_var\")\n",
    "\n",
    "    def __init__(self, token, parser):\n",
    "        self.token = token\n",
    "        matches = filter_re.finditer(token)\n",
    "        var_obj = None\n",
    "        filters = []\n",
    "        upto = 0\n",
    "        for match in matches:\n",
    "            start = match.start()\n",
    "            if upto != start:\n",
    "                raise TemplateSyntaxError(\n",
    "                    \"Could not parse some characters: \"\n",
    "                    \"%s|%s|%s\" % (token[:upto], token[upto:start], token[start:])\n",
    "                )\n",
    "            if var_obj is None:\n",
    "                if constant := match[\"constant\"]:\n",
    "                    try:\n",
    "                        var_obj = Variable(constant).resolve({})\n",
    "                    except VariableDoesNotExist:\n",
    "                        var_obj = None\n",
    "                elif (var := match[\"var\"]) is None:\n",
    "                    raise TemplateSyntaxError(\n",
    "                        \"Could not find variable at start of %s.\" % token\n",
    "                    )\n",
    "                else:\n",
    "                    var_obj = Variable(var)\n",
    "            else:\n",
    "                filter_name = match[\"filter_name\"]\n",
    "                args = []\n",
    "                if constant_arg := match[\"constant_arg\"]:\n",
    "                    args.append((False, Variable(constant_arg).resolve({})))\n",
    "                elif var_arg := match[\"var_arg\"]:\n",
    "                    args.append((True, Variable(var_arg)))\n",
    "                filter_func = parser.find_filter(filter_name)\n",
    "                self.args_check(filter_name, filter_func, args)\n",
    "                filters.append((filter_func, args))\n",
    "            upto = match.end()\n",
    "        if upto != len(token):\n",
    "            raise TemplateSyntaxError(\n",
    "                \"Could not parse the remainder: '%s' \"\n",
    "                \"from '%s'\" % (token[upto:], token)\n",
    "            )\n",
    "\n",
    "        self.filters = filters\n",
    "        self.var = var_obj\n",
    "        self.is_var = isinstance(var_obj, Variable)\n",
    "\n",
    "    def resolve(self, context, ignore_failures=False):\n",
    "        if self.is_var:\n",
    "            try:\n",
    "                obj = self.var.resolve(context)\n",
    "            except VariableDoesNotExist:\n",
    "                if ignore_failures:\n",
    "                    obj = None\n",
    "                else:\n",
    "                    string_if_invalid = context.template.engine.string_if_invalid\n",
    "                    if string_if_invalid:\n",
    "                        if \"%s\" in string_if_invalid:\n",
    "                            return string_if_invalid % self.var\n",
    "                        else:\n",
    "                            return string_if_invalid\n",
    "                    else:\n",
    "                        obj = string_if_invalid\n",
    "        else:\n",
    "            obj = self.var\n",
    "        for func, args in self.filters:\n",
    "            arg_vals = []\n",
    "            for lookup, arg in args:\n",
    "                if not lookup:\n",
    "                    arg_vals.append(mark_safe(arg))\n",
    "                else:\n",
    "                    arg_vals.append(arg.resolve(context))\n",
    "            if getattr(func, \"expects_localtime\", False):\n",
    "                obj = template_localtime(obj, context.use_tz)\n",
    "            if getattr(func, \"needs_autoescape\", False):\n",
    "                new_obj = func(obj, autoescape=context.autoescape, *arg_vals)\n",
    "            else:\n",
    "                new_obj = func(obj, *arg_vals)\n",
    "            if getattr(func, \"is_safe\", False) and isinstance(obj, SafeData):\n",
    "                obj = mark_safe(new_obj)\n",
    "            else:\n",
    "                obj = new_obj\n",
    "        return obj\n",
    "\n",
    "    def args_check(name, func, provided):\n",
    "        provided = list(provided)\n",
    "        # First argument, filter input, is implied.\n",
    "        plen = len(provided) + 1\n",
    "        # Check to see if a decorator is providing the real function.\n",
    "        func = inspect.unwrap(func)\n",
    "\n",
    "        args, _, _, defaults, _, _, _ = inspect.getfullargspec(func)\n",
    "        alen = len(args)\n",
    "        dlen = len(defaults or [])\n",
    "        # Not enough OR Too many\n",
    "        if plen < (alen - dlen) or plen > alen:\n",
    "            raise TemplateSyntaxError(\n",
    "                \"%s requires %d arguments, %d provided\" % (name, alen - dlen, plen)\n",
    "            )\n",
    "\n",
    "        return True\n",
    "\n",
    "    args_check = staticmethod(args_check)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.token\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<%s %r>\" % (self.__class__.__qualname__, self.token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\"\n",
    "    A template variable, resolvable against a given context. The variable may\n",
    "    be a hard-coded string (if it begins and ends with single or double quote\n",
    "    marks)::\n",
    "\n",
    "        >>> c = {'article': {'section':'News'}}\n",
    "        >>> Variable('article.section').resolve(c)\n",
    "        'News'\n",
    "        >>> Variable('article').resolve(c)\n",
    "        {'section': 'News'}\n",
    "        >>> class AClass: pass\n",
    "        >>> c = AClass()\n",
    "        >>> c.article = AClass()\n",
    "        >>> c.article.section = 'News'\n",
    "\n",
    "    (The example assumes VARIABLE_ATTRIBUTE_SEPARATOR is '.')\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"var\", \"literal\", \"lookups\", \"translate\", \"message_context\")\n",
    "\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "        self.literal = None\n",
    "        self.lookups = None\n",
    "        self.translate = False\n",
    "        self.message_context = None\n",
    "\n",
    "        if not isinstance(var, str):\n",
    "            raise TypeError(\"Variable must be a string or number, got %s\" % type(var))\n",
    "        try:\n",
    "            # First try to treat this variable as a number.\n",
    "            #\n",
    "            # Note that this could cause an OverflowError here that we're not\n",
    "            # catching. Since this should only happen at compile time, that's\n",
    "            # probably OK.\n",
    "\n",
    "            # Try to interpret values containing a period or an 'e'/'E'\n",
    "            # (possibly scientific notation) as a float;  otherwise, try int.\n",
    "            if \".\" in var or \"e\" in var.lower():\n",
    "                self.literal = float(var)\n",
    "                # \"2.\" is invalid\n",
    "                if var[-1] == \".\":\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                self.literal = int(var)\n",
    "        except ValueError:\n",
    "            # A ValueError means that the variable isn't a number.\n",
    "            if var[0:2] == \"_(\" and var[-1] == \")\":\n",
    "                # The result of the lookup should be translated at rendering\n",
    "                # time.\n",
    "                self.translate = True\n",
    "                var = var[2:-1]\n",
    "            # If it's wrapped with quotes (single or double), then\n",
    "            # we're also dealing with a literal.\n",
    "            try:\n",
    "                self.literal = mark_safe(unescape_string_literal(var))\n",
    "            except ValueError:\n",
    "                # Otherwise we'll set self.lookups so that resolve() knows we're\n",
    "                # dealing with a bonafide variable\n",
    "                if VARIABLE_ATTRIBUTE_SEPARATOR + \"_\" in var or var[0] == \"_\":\n",
    "                    raise TemplateSyntaxError(\n",
    "                        \"Variables and attributes may \"\n",
    "                        \"not begin with underscores: '%s'\" % var\n",
    "                    )\n",
    "                self.lookups = tuple(var.split(VARIABLE_ATTRIBUTE_SEPARATOR))\n",
    "\n",
    "    def resolve(self, context):\n",
    "        \"\"\"Resolve this variable against a given context.\"\"\"\n",
    "        if self.lookups is not None:\n",
    "            # We're dealing with a variable that needs to be resolved\n",
    "            value = self._resolve_lookup(context)\n",
    "        else:\n",
    "            # We're dealing with a literal, so it's already been \"resolved\"\n",
    "            value = self.literal\n",
    "        if self.translate:\n",
    "            is_safe = isinstance(value, SafeData)\n",
    "            msgid = value.replace(\"%\", \"%%\")\n",
    "            msgid = mark_safe(msgid) if is_safe else msgid\n",
    "            if self.message_context:\n",
    "                return pgettext_lazy(self.message_context, msgid)\n",
    "            else:\n",
    "                return gettext_lazy(msgid)\n",
    "        return value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<%s: %r>\" % (self.__class__.__name__, self.var)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.var\n",
    "\n",
    "    def _resolve_lookup(self, context):\n",
    "        \"\"\"\n",
    "        Perform resolution of a real variable (i.e. not a literal) against the\n",
    "        given context.\n",
    "\n",
    "        As indicated by the method's name, this method is an implementation\n",
    "        detail and shouldn't be called by external code. Use Variable.resolve()\n",
    "        instead.\n",
    "        \"\"\"\n",
    "        current = context\n",
    "        try:  # catch-all for silent variable failures\n",
    "            for bit in self.lookups:\n",
    "                try:  # dictionary lookup\n",
    "                    current = current[bit]\n",
    "                    # ValueError/IndexError are for numpy.array lookup on\n",
    "                    # numpy < 1.9 and 1.9+ respectively\n",
    "                except (TypeError, AttributeError, KeyError, ValueError, IndexError):\n",
    "                    try:  # attribute lookup\n",
    "                        # Don't return class attributes if the class is the context:\n",
    "                        if isinstance(current, BaseContext) and getattr(\n",
    "                            type(current), bit\n",
    "                        ):\n",
    "                            raise AttributeError\n",
    "                        current = getattr(current, bit)\n",
    "                    except (TypeError, AttributeError):\n",
    "                        # Reraise if the exception was raised by a @property\n",
    "                        if not isinstance(current, BaseContext) and bit in dir(current):\n",
    "                            raise\n",
    "                        try:  # list-index lookup\n",
    "                            current = current[int(bit)]\n",
    "                        except (\n",
    "                            IndexError,  # list index out of range\n",
    "                            ValueError,  # invalid literal for int()\n",
    "                            KeyError,  # current is a dict without `int(bit)` key\n",
    "                            TypeError,\n",
    "                        ):  # unsubscriptable object\n",
    "                            raise VariableDoesNotExist(\n",
    "                                \"Failed lookup for key [%s] in %r\",\n",
    "                                (bit, current),\n",
    "                            )  # missing attribute\n",
    "                if callable(current):\n",
    "                    if getattr(current, \"do_not_call_in_templates\", False):\n",
    "                        pass\n",
    "                    elif getattr(current, \"alters_data\", False):\n",
    "                        current = context.template.engine.string_if_invalid\n",
    "                    else:\n",
    "                        try:  # method call (assuming no args required)\n",
    "                            current = current()\n",
    "                        except TypeError:\n",
    "                            try:\n",
    "                                signature = inspect.signature(current)\n",
    "                            except ValueError:  # No signature found.\n",
    "                                current = context.template.engine.string_if_invalid\n",
    "                            else:\n",
    "                                try:\n",
    "                                    signature.bind()\n",
    "                                except TypeError:  # Arguments *were* required.\n",
    "                                    # Invalid method call.\n",
    "                                    current = context.template.engine.string_if_invalid\n",
    "                                else:\n",
    "                                    raise\n",
    "        except Exception as e:\n",
    "            template_name = getattr(context, \"template_name\", None) or \"unknown\"\n",
    "            logger.debug(\n",
    "                \"Exception while resolving variable '%s' in template '%s'.\",\n",
    "                bit,\n",
    "                template_name,\n",
    "                exc_info=True,\n",
    "            )\n",
    "\n",
    "            if getattr(e, \"silent_variable_failure\", False):\n",
    "                current = context.template.engine.string_if_invalid\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        return current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # Set this to True for nodes that must be first in the template (although\n",
    "    # they can be preceded by text nodes.\n",
    "    must_be_first = False\n",
    "    child_nodelists = (\"nodelist\",)\n",
    "    token = None\n",
    "\n",
    "    def render(self, context):\n",
    "        \"\"\"\n",
    "        Return the node rendered as a string.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def render_annotated(self, context):\n",
    "        \"\"\"\n",
    "        Render the node. If debug is True and an exception occurs during\n",
    "        rendering, the exception is annotated with contextual line information\n",
    "        where it occurred in the template. For internal usage this method is\n",
    "        preferred over using the render method directly.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.render(context)\n",
    "        except Exception as e:\n",
    "            if context.template.engine.debug:\n",
    "                # Store the actual node that caused the exception.\n",
    "                if not hasattr(e, \"_culprit_node\"):\n",
    "                    e._culprit_node = self\n",
    "                if (\n",
    "                    not hasattr(e, \"template_debug\")\n",
    "                    and context.render_context.template.origin == e._culprit_node.origin\n",
    "                ):\n",
    "                    e.template_debug = (\n",
    "                        context.render_context.template.get_exception_info(\n",
    "                            e,\n",
    "                            e._culprit_node.token,\n",
    "                        )\n",
    "                    )\n",
    "            raise\n",
    "\n",
    "    def get_nodes_by_type(self, nodetype):\n",
    "        \"\"\"\n",
    "        Return a list of all nodes (within this node and its nodelist)\n",
    "        of the given type\n",
    "        \"\"\"\n",
    "        nodes = []\n",
    "        if isinstance(self, nodetype):\n",
    "            nodes.append(self)\n",
    "        for attr in self.child_nodelists:\n",
    "            nodelist = getattr(self, attr, None)\n",
    "            if nodelist:\n",
    "                nodes.extend(nodelist.get_nodes_by_type(nodetype))\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeList(list):\n",
    "    # Set to True the first time a non-TextNode is inserted by\n",
    "    # extend_nodelist().\n",
    "    contains_nontext = False\n",
    "\n",
    "    def render(self, context):\n",
    "        return SafeString(\"\".join([node.render_annotated(context) for node in self]))\n",
    "\n",
    "    def get_nodes_by_type(self, nodetype):\n",
    "        \"Return a list of all nodes of the given type\"\n",
    "        nodes = []\n",
    "        for node in self:\n",
    "            nodes.extend(node.get_nodes_by_type(nodetype))\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNode(Node):\n",
    "    child_nodelists = ()\n",
    "\n",
    "    def __init__(self, s):\n",
    "        self.s = s\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<%s: %r>\" % (self.__class__.__name__, self.s[:25])\n",
    "\n",
    "    def render(self, context):\n",
    "        return self.s\n",
    "\n",
    "    def render_annotated(self, context):\n",
    "        \"\"\"\n",
    "        Return the given value.\n",
    "\n",
    "        The default implementation of this method handles exceptions raised\n",
    "        during rendering, which is not necessary for text nodes.\n",
    "        \"\"\"\n",
    "        return self.s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_value_in_context(value, context):\n",
    "    \"\"\"\n",
    "    Convert any value to a string to become part of a rendered template. This\n",
    "    means escaping, if required, and conversion to a string. If value is a\n",
    "    string, it's expected to already be translated.\n",
    "    \"\"\"\n",
    "    value = template_localtime(value, use_tz=context.use_tz)\n",
    "    value = localize(value, use_l10n=context.use_l10n)\n",
    "    if context.autoescape:\n",
    "        if not issubclass(type(value), str):\n",
    "            value = str(value)\n",
    "        return conditional_escape(value)\n",
    "    else:\n",
    "        return str(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableNode(Node):\n",
    "    child_nodelists = ()\n",
    "\n",
    "    def __init__(self, filter_expression):\n",
    "        self.filter_expression = filter_expression\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Variable Node: %s>\" % self.filter_expression\n",
    "\n",
    "    def render(self, context):\n",
    "        try:\n",
    "            output = self.filter_expression.resolve(context)\n",
    "        except UnicodeDecodeError:\n",
    "            # Unicode conversion can fail sometimes for reasons out of our\n",
    "            # control (e.g. exception rendering). In that case, we fail\n",
    "            # quietly.\n",
    "            return \"\"\n",
    "        return render_value_in_context(output, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for token keyword arguments\n",
    "kwarg_re = _lazy_re_compile(r\"(?:(\\w+)=)?(.+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_kwargs(bits, parser, support_legacy=False):\n",
    "    \"\"\"\n",
    "    Parse token keyword arguments and return a dictionary of the arguments\n",
    "    retrieved from the ``bits`` token list.\n",
    "\n",
    "    `bits` is a list containing the remainder of the token (split by spaces)\n",
    "    that is to be checked for arguments. Valid arguments are removed from this\n",
    "    list.\n",
    "\n",
    "    `support_legacy` - if True, the legacy format ``1 as foo`` is accepted.\n",
    "    Otherwise, only the standard ``foo=1`` format is allowed.\n",
    "\n",
    "    There is no requirement for all remaining token ``bits`` to be keyword\n",
    "    arguments, so return the dictionary as soon as an invalid argument format\n",
    "    is reached.\n",
    "    \"\"\"\n",
    "    if not bits:\n",
    "        return {}\n",
    "    match = kwarg_re.match(bits[0])\n",
    "    kwarg_format = match and match[1]\n",
    "    if not kwarg_format:\n",
    "        if not support_legacy:\n",
    "            return {}\n",
    "        if len(bits) < 3 or bits[1] != \"as\":\n",
    "            return {}\n",
    "\n",
    "    kwargs = {}\n",
    "    while bits:\n",
    "        if kwarg_format:\n",
    "            match = kwarg_re.match(bits[0])\n",
    "            if not match or not match[1]:\n",
    "                return kwargs\n",
    "            key, value = match.groups()\n",
    "            del bits[:1]\n",
    "        else:\n",
    "            if len(bits) < 3 or bits[1] != \"as\":\n",
    "                return kwargs\n",
    "            key, value = bits[2], bits[0]\n",
    "            del bits[:3]\n",
    "        kwargs[key] = parser.compile_filter(value)\n",
    "        if bits and not kwarg_format:\n",
    "            if bits[0] != \"and\":\n",
    "                return kwargs\n",
    "            del bits[:1]\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}