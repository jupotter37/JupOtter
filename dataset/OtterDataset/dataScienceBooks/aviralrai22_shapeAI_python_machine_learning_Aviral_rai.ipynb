{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn0uloH4uw9F",
        "outputId": "49b5463c-cbb4-4985-9275-bf65d77098eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(379, 13)\n",
            "(127, 13)\n",
            "(127,)\n",
            "(379,)\n",
            "the model performance for trainingf set\n",
            "rmse is 4.82312164565186.\n",
            "\n",
            "\n",
            "the model performance for testing set\n",
            "rmse is4.346982391119951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import linear_model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "from sklearn.datasets  import  load_boston\n",
        "dff = load_boston()\n",
        "#dff\n",
        "#dff.keys() #dataset keys of the dictionary\n",
        "#print (dff.filename)\n",
        "#print(dff.data)\n",
        "#print(dff.target)\n",
        "#print(dff.DESCR)\n",
        "#print(dff.data_module)\n",
        "#print(dff.feature_names)\n",
        "table =pd.DataFrame(dff.data,columns=dff.feature_names)\n",
        "table.head()  #to print all the list just write the  no in the like this table.head (n) n=1,2,35,5,etc\n",
        "\n",
        "table['TARGET']=dff.target  #add the new column name TARGET\n",
        "table.head()\n",
        "\n",
        "#now check whether is data is empty \n",
        "table.isnull()\n",
        "table.isnull().sum() #it will give the info about all the data is not null or is null \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x=table.drop('TARGET' ,axis=1)\n",
        "y =table['TARGET']\n",
        "x_train, x_test, y_train, y_test =train_test_split(x , y, test_size=0.25, random_state =3)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics  import mean_squared_error\n",
        "\n",
        "#fitting the model in the training dataset\n",
        "linear_model= LinearRegression()\n",
        "linear_model.fit(x_train,y_train)\n",
        "#it will fit the data and execute it\n",
        "\n",
        "y_train_predict=linear_model.predict(x_train)\n",
        "rmse =  ( np.sqrt ( mean_squared_error( y_train,y_train_predict) ) )\n",
        "\n",
        "print(\"the model performance for trainingf set\")\n",
        "print(\"rmse is {}.\".format(rmse))\n",
        "print(\"\\n\")\n",
        "\n",
        "#now on testing\n",
        "y_test_predict=linear_model.predict(x_test)\n",
        "rmse=(np.sqrt(mean_squared_error(y_test,y_test_predict)))\n",
        " \n",
        "\n",
        "print(\"the model performance for testing set\")\n",
        "print(\"rmse is{}\".format(rmse))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gb87JQnCDi2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}