{"cells":[{"metadata":{"_uuid":"2ee819371337360a1436a9aa0baf2592c546fe5b"},"cell_type":"markdown","source":"I made this notebook by following this: https://www.kaggle.com/kanncaa1/data-sciencetutorial-for-beginners\n\nThis is for self study only."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"9ae6221d-3b43-4ea3-8822-0bf145e091e9","_uuid":"a2a409dd1057f948f278dac08a58ec37ebb522c3"},"cell_type":"markdown","source":"# Read the data and do some initial data checking "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":false},"cell_type":"code","source":"# read the data\ndata = pd.read_csv('../input/pokemon-challenge/pokemon.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"29d78221-1307-4031-bc4f-60c8888d43a6","_uuid":"b5fd7c72ea59b4d96c037ab342b05204592bddfa","trusted":false},"cell_type":"code","source":"# check the info of the data\ndata.info()\n\n# therea are 800 rows with 12 columns. ","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"3ce192c9-48dc-4525-807b-1fdd9a35c887","_uuid":"3798802ab048983c55e42414d1f5858eb6f2620b","trusted":false},"cell_type":"code","source":"# since there are many features, see the correlation between features by using heatmap plot\nplt.figure(figsize=(14,8))\nsns.heatmap(data.corr(),annot=True,linewidths=.5)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"23246454-e3f6-457e-a738-73b3e9bfad12","_uuid":"c89a99cb94473e60fdcdb2758d92f8c417a92703","trusted":false},"cell_type":"code","source":"# for a quick view, we can see the pairplot too. \n# only use this if the data is small, otherwise it takes a long time to run\nsns.pairplot(data)\n\n# we can see some linear regression relationship between some features, such as attack vs. hp, attack vs. defense etc. ","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"0b8926e0-ab8c-4747-b80d-b35d947f8738","_uuid":"391e5fda0f8745f16c4fd22ccd9c247c4eb0f696","trusted":false},"cell_type":"code","source":"# check the head of the data and see what they are\ndata.head(10)\n\n# NaN noticed. Need to deal with missing number. ","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"345c54fc-93c7-420e-a319-3eaba5dbe645","_uuid":"e0a6f68e682a9696618df63d3e9fa48cdc40aad4","trusted":false},"cell_type":"code","source":"# check the info \ndata.info()","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"1905392d-e799-4c32-8dc0-203f5b439a82","_uuid":"9c87dd8f1433f01aa889f0e849bcf41003de66c8","trusted":false},"cell_type":"code","source":"# check data describe\ndata.describe()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"2bfdd7d7-62e6-41e9-a474-9cce8433ba29","_uuid":"a5edba3e49bb26ddfbd5f4aa36226edfd6f17273","trusted":false},"cell_type":"code","source":"# check describe for categorical data\ndata.describe(include = ['O'])\n\n# name is unique\n# There are 18 unique type 1, most common is Water\n# There are 18 unique type 2, most common is flying","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"aefa864c-c122-42fa-8009-27221d949e0d","_uuid":"2c673f0acfbb9b3b0c35dc7b7097bc01cf52b1cc","trusted":false},"cell_type":"code","source":"# check missing value\ndata.isnull().any()\n\n# Name and Type 2 have missing value","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"3b740f70-cde5-4bf6-8499-46a0573f1d55","_uuid":"a8db281387cc15781fef417e9df7801479c0dbd4","trusted":false},"cell_type":"code","source":"# list all the column name for easy using later\ndata.columns","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"2e464a86-e9d4-4ea7-ad44-5b65e352a4ae","_uuid":"31578ec5b6ab2dbf6062f20066e6a4ea09bc65bb"},"cell_type":"markdown","source":"# Data Visulization - Matplotlib\n\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle"},{"metadata":{"_cell_guid":"3c9c3fb4-f5aa-4d33-93dd-76150ccdc41c","_uuid":"c83429df205475537216f2b0c2ef5f87f2c03639","trusted":false},"cell_type":"code","source":"# Line plot - just as an example since non of the data has time associated\nplt.figure(figsize=(14,8))\ndata['Speed'].plot(kind='line',label='Speed',linestyle = ':',color = 'g',grid=True,alpha=0.5)\ndata['Attack'].plot(kind='line',label='Attack',linestyle = '-',color = 'r',grid=True,alpha=0.5)\n\nplt.legend(loc = 'upper right')\nplt.xlabel('x-axis')\nplt.ylabel('y-axis')\nplt.title('Line Plot Example')","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"727f0e39-39a6-43ed-8698-9e4323b89aa5","_uuid":"62192481dc93919dfc9b89eaf8b5291baf9fe00e","trusted":false},"cell_type":"code","source":"# scatter plot - see how attack associate with defense\nplt.figure(figsize=(14,8))\nplt.scatter(x = 'Attack', y = 'Defense',data=data,alpha = 0.5, marker ='o',c = 'r')\nplt.xlabel('Attack')\nplt.ylabel('Defense')\nplt.title('Attack vs. Defense Scatter Plot')","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"bfbe94d1-4642-4b53-9dcb-5cdc081e7cc1","_uuid":"5d415a6443f5205a9750ed5886861c382de23ba2","trusted":false},"cell_type":"code","source":"# histogram - Speed\nplt.figure(figsize=(14,8))\ndata.hist('Speed',bins=50, figsize=(14,8))","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"bc13adb5-90b1-4ee1-9e8b-4d1991ba78f8","_uuid":"075711a54c64c1c2964f8c7e4a4f6b1378b0c322","trusted":false},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.hist('Speed',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"3095c9d8-28d5-4d33-b7ca-cea064a56b06","_uuid":"3329f74c0f96e9f80ac85144c292899737f4d017"},"cell_type":"markdown","source":"# Use Dictionary wisely\n\nWhy we need dictionary?\n\n- It has 'key' and 'value'\n- Faster than lists \n- What is key and value. Example:\n    dictionary = {'spain' : 'madrid'}\n    Key is spain.\n    Values is madrid. \n\nIt's that easy. \nLets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary.\n"},{"metadata":{"_cell_guid":"bbc1abae-c1ba-4ac4-9ba4-a3502a60e7cf","_uuid":"b878270aa95c0feba1cc6c53f9de0c6350078b82","trusted":false},"cell_type":"code","source":"#create dictionary and look its keys and values\ndictionary = { 'spain': 'madrid','usa': 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"0af1dfbd-06ca-4994-895a-157ee42b9e17","_uuid":"13a161cb5c42b8b2f8013373d7db9dd9fcd327f3","trusted":false},"cell_type":"code","source":"# dictionary can be updated. \n# you can do update, add, remove, check and clear the whole dictionary\n\n# update city name\ndictionary['usa'] = 'San Francisco' \nprint(dictionary) # you can see city for USA is updated to San Francisco from Vegas\n\n# add new entry\ndictionary['france'] = 'Paris'\nprint(dictionary)\n\n# remove entry\ndel dictionary['spain']\nprint(dictionary)\n\n#check if an entry is in a dictionary\nprint('france' in dictionary)\n\n# clear the whole dictionary\ndictionary.clear()\nprint(dictionary)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"b9ba9152-b571-4c24-9fee-136a0a71a62c","_uuid":"f9705a03918bacaa6130e69a16c7d2d026fa5119"},"cell_type":"markdown","source":"# Pandas\n\nUse Pandas to work with data frame"},{"metadata":{"_cell_guid":"fef5a92d-f1ab-4ef4-82d9-82cf21e5d747","_uuid":"7af329bded606934be42ce0d21b040f849617215","collapsed":true,"trusted":false},"cell_type":"code","source":"# read dataset\ndata = pd.read_csv('../input/pokemon-challenge/pokemon.csv')","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"fd6d7aac-8498-406f-8220-4d97239ab7d2","_uuid":"1da1d398e8cac9ca1d6b4ad2fb12bff9367f3b6f","trusted":false},"cell_type":"code","source":"series = data['Defense']  #if we just grab a column, only use one [], we get a series\nprint(type(series))\n\ndata_frame = data[['Defense']] # if we use double [], we get a data frame\nprint(type(data_frame))","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"2625416d-4e30-46cc-9629-dedbf42a7982","_uuid":"eeb870ebc32b29bc57fed874ee175c2348fb8488"},"cell_type":"markdown","source":"**Manipulate data frame using some operations**\n\n- comparison: ==, >, <, !=\n- logic operation: and, or , not\n- filtering \n\n"},{"metadata":{"_cell_guid":"16a5de6e-db77-4b25-a371-7486b7c0e8f3","_uuid":"897ebbcf226c7bdbd805a33945f003a8412960d3","trusted":false},"cell_type":"code","source":"# comparison\nprint('Is 3 equal to 2? ', 3==2)\nprint('Is 3 greater than 2? ', 3>2)\nprint('Is 3 less than to 2? ', 3<2)\nprint('Is 3 not equal to 2? ', 3!=2)","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"56928fdb-21bf-4ae3-808d-eb213552ed47","_uuid":"6b5a7d641e6397fa9fdfb3d01d535e2eeec586ac","trusted":false},"cell_type":"code","source":"# logical operation\nprint(True and True)\nprint(True or False)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"1cdfa893-03a4-41c0-987a-b0158ef3ac62","_uuid":"f5fad77e30460139c72e19fd7373c4fb4bfa1998","trusted":false},"cell_type":"code","source":"# filtering \ndata[data['Attack']>180] # there are 2 pokemons which attack is greater than 180","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"bbdc042c-e8d5-4103-aabe-bc8bba235d32","_uuid":"b59bdf570fd7569091131e4314fddd2dd5470e5f","trusted":false},"cell_type":"code","source":"# filtering 2\ndata[(data['Attack']>180) & (data['Defense'] > 100)] \n\n# there is only one with attack > 180 and defense > 100","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"7224679c-069c-43cd-863d-2848ae10d900","_uuid":"30917095948f87ffd3a85b382384d6a7905360ea"},"cell_type":"markdown","source":"**Basic Functions: While and For Loop**\n\n"},{"metadata":{"_cell_guid":"f6308040-1d94-4ac9-b588-d6c8b1989893","_uuid":"29a09fa2f412c7dc3dfc8557b3a78354b8044eb1","trusted":false},"cell_type":"code","source":"# while loop\ni = 0\n\nwhile i !=5: \n    print('i is ', i)\n    i += 1\nprint('i is equal to 5')","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"9dbb36e0-5477-4841-9975-f55d25718749","_uuid":"ea3c0b3311783a2e8b6d75d4eb26a8590d3b6ac7","trusted":false},"cell_type":"code","source":"# for loop \nlist = [1,2,3,4,5]\nfor i in list:\n    print('i is ',i)\n","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"a837b5a7-856a-4834-a2ab-47e47b1dce25","_uuid":"708d7679f80888d28f6953dc90343ddc62a724cf","trusted":false},"cell_type":"code","source":"# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(list):\n    print(index,\" : \",value)\nprint('')  ","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"02b724a0-b512-458c-b056-94af5ec6a1f1","_uuid":"157f5681b3fe8c82c590da1fb4c7d3471d1903aa","trusted":false},"cell_type":"code","source":"dictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"071a4752-c02f-4f9c-bee9-40540c2cb9bb","_uuid":"03593f5c985add085b709dc2cd41c3518b8f0c16","trusted":false},"cell_type":"code","source":"# for pandas, we can achieve index and value: \n# use function of iterrows to iterate over DataFrame rows as (index, Series) pairs.\nfor index,value in data[['Attack']][0:1].iterrows():\n    print(index,\" : \",value)","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"4183e6f5-664b-4e14-a1ca-882922a6b151","_uuid":"b1c88fcec4f8c344106d8013a494135c1bf825da"},"cell_type":"markdown","source":"**USER DEFINED FUNCTION**"},{"metadata":{"_cell_guid":"b69dba3a-2641-4728-b14d-997afbfd9292","_uuid":"71641ab7e2c0f400b44d83c539d06aecd13f94bb","trusted":false},"cell_type":"code","source":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"b9556308-9e3b-4d3c-8cfc-0ab9dd677c29","_uuid":"46112f69dcceda154c7dcecf27208584bafc31f8","trusted":false},"cell_type":"code","source":"# nested function: \ndef square():\n    def add():\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\n\nprint(square())","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"162ad88e-8093-43d1-bd74-9913546c7508","_uuid":"3f02df0d0f6b18f8aaa8517ac641972c5608f23a"},"cell_type":"markdown","source":"**LAMBDA FUNCTION**"},{"metadata":{"_cell_guid":"6f7ded2a-8c2f-4610-99df-c4960c682bb3","_uuid":"552f9439020dfc612b8920665ecab35994526a75","trusted":false},"cell_type":"code","source":"square = lambda x: x**2\nprint(square(2))\n\ntot = lambda x,y,z: x+y+z\nprint(tot(1,2,3))","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"557577e2-0d87-44cc-b99d-e312514f2e74","_uuid":"683fefcd28e71eda51da4507fd6ccd4da1b25f8d"},"cell_type":"markdown","source":"**ANONYMOUS FUNCTİON**\n\nLike lambda function but it can take more than one arguments.\n\nmap(func,seq) : applies a function to all the items in a list"},{"metadata":{"_cell_guid":"04a469bc-1f6b-41b1-b00f-d971ee0f3434","_uuid":"2c181b8952e5674ec08167c4c127a5ad1f0050be"},"cell_type":"markdown","source":"**ITERATORS**\n\n- iterable is an object that can return an iterator\n\n- iterable: an object with an associated iter() method \nexample: list, strings and dictionaries\n\n- iterator: produces next value with next() method"},{"metadata":{"_cell_guid":"f8decbca-eefe-40f9-8cd2-bc3050b52f9f","_uuid":"9404adb16dceb050e7af9da3246442b010d9d6d7","trusted":false},"cell_type":"code","source":"name = 'karen'\nit = iter(name)\nprint(next(it)) # print next iteration\n\nprint(*it) # print remaining iteration","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"55665aa1-aedd-42c8-a9c7-6765e635076c","_uuid":"287e1d8f1a844f6db43617e5a86bd1b6e406a992"},"cell_type":"markdown","source":"**LIST COMPREHENSİON**\n\nOne of the most important topic of this kernel\n\nWe use list comprehension for data analysis often. \n\nlist comprehension: collapse for loops for building lists into a single line \n\nEx: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension."},{"metadata":{"_cell_guid":"deffcc25-d5cd-4ad7-8a5f-16490dd40aef","_uuid":"b9f9dfe92220ced48ae4d13cd6b709b28ff90663","trusted":false},"cell_type":"code","source":"num = [1,2,3]\nnum2 = [i + 1 for i in num]\nprint(num2)","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"2683f1cf-cd74-4e87-abb0-f3469ce2d2df","_uuid":"8491a89a83aea33cb093485fdde6cb431bdcfb11","trusted":false},"cell_type":"code","source":"num = [5,10,15]\nnum2 = [i**2 if i ==10 else i-5 if i < 7 else i +5 for i in num]\nnum2","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"be9ba107-f7c6-433d-a425-1a79857ca037","_uuid":"d29d813552811fd9063c92d0ab93daedf8e6634b","trusted":false},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\n\nthreshold = data['Speed'].mean()\ndata['speed_level'] = ['high' if i > threshold else 'low' for i in data['Speed']]\n\n# check out first 10 rows\ndata.loc[:10,['speed_level','Speed']]","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"76810efe-d47f-4c3b-a507-bfd92734a26b","_uuid":"b1f9f7723511965f16a5e61db761e5c6774bbefd"},"cell_type":"markdown","source":"# 3.CLEANING DATA\n\n**DIAGNOSE DATA for CLEANING**\n\nWe need to diagnose and clean data before exploring. \n\nUnclean data:\n- Column name inconsistency like upper-lower case letter or space between words\n- missing data\n- different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"_cell_guid":"5b1edba5-947d-48bb-ad17-6788e1fc2303","_uuid":"ad5abcbfe28ad2d8cd15b4963334434163cc260a","trusted":false},"cell_type":"code","source":"data = pd.read_csv('../input/pokemon-challenge/pokemon.csv')\ndata.head()","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"3cea1f16-e9b9-4955-8467-36401936e9d6","_uuid":"10535d7757e73b09ba312da9da98a1044bd64b73","trusted":false},"cell_type":"code","source":"data.tail()","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"fa63c360-8c33-4e03-885b-8ad2f1711d0c","_uuid":"9c4656193fb8d72b4aadb64a5b457958182ef9a1","trusted":false},"cell_type":"code","source":"data.columns","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"08fbdd82-e114-4170-910b-4347fd250287","_uuid":"f3efb4444127396598d7cb31b5bbb4d152fe76e3","trusted":false},"cell_type":"code","source":"data.shape","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"0c1468c0-6252-4365-882d-40ded9c131f1","_uuid":"5501c5c09db12acd4c9b7fae5fbe27f92b3c85f0","trusted":false},"cell_type":"code","source":"data.info()","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"22f03dbd-6800-4818-b1f8-935dfee4f52c","_uuid":"edf307772280d53747194a6e1092682ae7e9f0bd"},"cell_type":"markdown","source":"**EXPLOTARY DATA ANALYSIS**\n\nvalue_counts(): Frequency counts \n\noutliers: the value that is considerably higher or lower from rest of the data\n- Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1) "},{"metadata":{"_cell_guid":"cae4c718-2fb7-4aec-9ffc-95f939164188","_uuid":"0bda0c962200df1e3cee3ded80e3bd7270c85980","trusted":false},"cell_type":"code","source":"# value_counts()\ndata['Type 1'].value_counts(dropna =False)  # if there are nan values that also be counted)","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"e4ce9121-ed66-4cb4-889c-00a67c9993d8","_uuid":"2eb1f0281114ec4cfd2ae780b465948e500d9799","trusted":false},"cell_type":"code","source":"data.describe()","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"5f18939c-9cd0-4c9a-b78f-9578472a2fda","_uuid":"c2137ea225efde409f3335284d6da2b2f9126c15"},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**"},{"metadata":{"_cell_guid":"910d5047-9701-437f-a5b4-d1d949755e95","_uuid":"c33666a041802e9ce8cbcf642b04d50b5727648e","trusted":false},"cell_type":"code","source":"# Box plots: visualize basic statistics like outliers, min/max or quantiles\ndata.boxplot(column = 'Attack',by = 'Legendary')","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"7033ddd9-7c03-45b4-88b4-ecafd850daa6","_uuid":"c8ffd3efce002722d5644ad38e2eff8023a1f7ca"},"cell_type":"markdown","source":"**TIDY DATA**"},{"metadata":{"_cell_guid":"49bfa003-cef8-495d-94c4-e17b41c13250","_uuid":"923c5921ca477b440906ed7a6097a950b1557753","trusted":false},"cell_type":"code","source":"# first make a smaller dataset\ndata_new = data.head()\ndata_new","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"ada9613d-2950-40b5-8434-d4cd83ab43c0","_uuid":"5aaad3d15fe60ac0dc34c88f42450bc522c67f8a","trusted":false},"cell_type":"code","source":"# let's melt\nmelted = pd.melt(frame = data_new, id_vars = 'Name', value_vars = ['Attack', 'Defense'])\nmelted","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"60a31ae4-ff9e-4dff-85a6-cacc3e466a0e","_uuid":"ba3007084d678688f004709015d52b2b8a05888b"},"cell_type":"markdown","source":"**PIVOTING DATA**"},{"metadata":{"_cell_guid":"c50be487-a9f2-4c8d-bf7d-6bbf9d7e5762","_uuid":"65840723fb596e64a45524913f828da36d6a387d","trusted":false},"cell_type":"code","source":"melted.pivot(index = 'Name',columns = 'variable',values ='value')","execution_count":46,"outputs":[]},{"metadata":{"_cell_guid":"f83dbdc6-024b-4b6b-808a-e15c4d01f5cb","_uuid":"f39c2d0ec218087b415ef809e5d659ed312980e0"},"cell_type":"markdown","source":"**CONCATENATING DATA¶**"},{"metadata":{"_cell_guid":"c529cb03-9e4d-4364-a9db-8256b7b4d5f6","_uuid":"85371107324747f47c41711efefd6c799f99e4ad","trusted":false},"cell_type":"code","source":"data1 = data.head()\ndata2 = data.tail()\n\ncon_data = pd.concat([data1, data2], axis=0,ignore_index = True)\ncon_data","execution_count":47,"outputs":[]},{"metadata":{"_cell_guid":"9c1bc123-0bb1-4db7-b2b4-e06f6828a1dc","_uuid":"83d3ac03a433d9f12cd3b1eb015c508185e1f28c","trusted":false},"cell_type":"code","source":"data1 = data['Attack'].head()\ndata2 = data['Defense'].head()\ncon_data_col = pd.concat([data1,data2],axis = 1)\ncon_data_col\n","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"40671ec4-88f1-4f35-90a4-867a0c38fbe7","_uuid":"e81d9d0d75340c952fd8d1fdad2cbb0cd989c88c"},"cell_type":"markdown","source":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical. \n\nWe can make conversion data types like from str to categorical or from int to float \n\nWhy is category important:\n- make dataframe smaller in memory\n- can be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"_cell_guid":"e196bcd5-5804-41bb-bc7e-df00d8bc20ec","_uuid":"9145c66dda142a0130f81822c6956dd38af14e57","trusted":false},"cell_type":"code","source":"data.dtypes","execution_count":49,"outputs":[]},{"metadata":{"_cell_guid":"0d6e6b3d-a1f3-4d82-a4d6-459ecf7f69c5","_uuid":"035d36189bb4708cd8d516cf86de982f93b83037","collapsed":true,"trusted":false},"cell_type":"code","source":"# let's convert objects to categorical and int to float\ndata[\"Type 1\"] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')\n","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"d0cc80b1-9775-44cc-ac5b-2aecf870b57d","_uuid":"777e1879c68a4b6569826e2b8f39b0f34bfaca39","trusted":false},"cell_type":"code","source":"data.dtypes","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"5bcff0e8-5834-415a-959e-adc2ade76158","_uuid":"36c851b10446a62b57cbaa6410a3fc675979214d"},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n- leave as is\n- drop them with dropna()\n- fill missing value with fillna()\n- fill missing values with test statistics like mean \n- Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"_cell_guid":"73ff9466-83b8-4936-a8cd-6a277e1b51d1","_uuid":"6756e8a6cb50d15efd722005eeae61e1008e0605","trusted":false},"cell_type":"code","source":"# we can check missing value using info()\ndata.info()\n\n# we can see total rows is 800. Name has 799, one is missing. \n# Type 2 has 414 non-null, so many are missing ","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"04c8c3f9-5fc9-4f2a-a675-a1990a1778e6","_uuid":"aca16a9005176efdeb31e0224dee29719a29ad63","trusted":false},"cell_type":"code","source":"data['Type 2'].value_counts(dropna=False)\n\n# we can see that NaN=386","execution_count":53,"outputs":[]},{"metadata":{"_cell_guid":"10a2dd9c-3577-44bf-92db-917ca369ac5c","_uuid":"461815f4e42f652b52c2881550ecb4493789fd57","trusted":false},"cell_type":"code","source":"# method 1: drop NaN\ndata1 = data # make a copy of data to data1\ndata1['Type 2'].dropna(inplace = True)\n\n# check if NaN is dropped - there is no more NaN \ndata1['Type 2'].value_counts(dropna = False)","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"1b23a14d-1816-4ff2-8d4a-61ed2daea245","_uuid":"9d1ce1a5ddcdb3fd3248f9c7bb1a2f7a0131b7ea","collapsed":true,"trusted":false},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"6b06cc4a-2f99-42dc-802c-ad8b2defdda2","_uuid":"93fee2bf8e0acb42feb336a0e87f829d6176848a","collapsed":true,"trusted":false},"cell_type":"code","source":"data['Type 2'].fillna('empty',inplace = True)","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"b994c508-c205-4e17-9693-956f2ed4d4d0","_uuid":"31e33910872bc049d56ec8d0185d78f9321d9e87","collapsed":true,"trusted":false},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":57,"outputs":[]},{"metadata":{"_cell_guid":"bef93d5c-e438-4616-8b4b-fa35deff1068","_uuid":"54888db0abb1d551f748a6d5c01b65145b0a2e63"},"cell_type":"markdown","source":"# 4. PANDAS FOUNDATION\n- single column = series\n- NaN = not a number\n- dataframe.values = numpy"},{"metadata":{"_cell_guid":"2adfc8e5-74d2-4c3d-a0af-548ae762afbc","_uuid":"7ea5e0779e7b750a196ce96211e8f00c7923ac12","trusted":false},"cell_type":"code","source":"# data frames from dictionary\ndata_dict = {'country':['Spain','France'], 'population':['11','12']}\ndf = pd.DataFrame(data_dict)\ndf","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"77e96fbb-b02d-4441-a124-25294bce4457","_uuid":"99ef3f609e9620d7554dd307eae168c3ab7327d0","trusted":false},"cell_type":"code","source":"# add a new column\ndf['capital']=['marid','paris']\ndf","execution_count":59,"outputs":[]},{"metadata":{"_cell_guid":"fb6a5d11-06e4-4f4d-9616-388a5e25c518","_uuid":"7e0e7f37d357c411fc0559bc737fa91fd092e716","trusted":false},"cell_type":"code","source":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"347b631b-db6a-48cb-a765-5db2831e541c","_uuid":"76a999f72b9d910c0ca61eef197b4fa50b6811af","collapsed":true},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\nPlot\n\nSubplot\n\nHistogram:\n- bins: number of bins\n- range(tuble): min and max values of bins\n- normed(boolean): normalize or not\n- cumulative(boolean): compute cumulative distribution"},{"metadata":{"_cell_guid":"f750705c-cd69-4ca0-8170-e1e4458c78ab","_uuid":"b1f22d38f386cd7f5150b6631f568a3245417e36","trusted":false},"cell_type":"code","source":"# ploting several features in a plot graph\ndata1 = data[['Attack','Defense','Speed']]\ndata1.plot()\n\n# very confusing ","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"b2683055-bcb7-4b80-ad95-477a6e33008a","_uuid":"ac777491472afd48c41c009c2e5da1c20ebdcfcd","trusted":false},"cell_type":"code","source":"# instead, we can do subplot\ndata1.plot(subplots=True)","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"9ecb32c1-08e1-4f11-8cc8-1de4bf14fbe5","_uuid":"ff9c8f88a673e7efae1c12eae29820a5e3a8baab","trusted":false},"cell_type":"code","source":"# scatter plot\ndata1.plot(kind ='scatter',x = 'Attack',y='Defense')","execution_count":63,"outputs":[]},{"metadata":{"_cell_guid":"51831a79-d0fb-4ca6-9b02-0df110a11a10","_uuid":"7dcbaafbd5ce6f7b1c7fe6ce1efd709fa87519c3","trusted":false},"cell_type":"code","source":"# histogram\ndata1.plot(kind ='hist',y='Attack', bins = 50,range =(0,250),grid = False, normed = True)","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"2a27e90c-454a-4d74-88f3-8264949a332c","_uuid":"2fafb0d937821eae36091fc3c061006e04d06c6e","trusted":false},"cell_type":"code","source":"data1['Attack'].plot.hist(bins = 50, normed=True, range=(0,250))\nplt.legend()","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"cd77deba-e2a7-415d-8299-4459a8806676","_uuid":"0cbbc25d98f482f18c34635568d697077afabd8e","trusted":false},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\n\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\n","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"d6b4c229-e107-457b-9bba-1ecd54c3ed64","_uuid":"68cb779baca6f72993ea26a64dc4af56875ee430","trusted":false},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 2, ncols=1)\n\ndata1['Defense'].plot.hist(bins = 50, range = (0,250), normed = True, ax = axes[0],legend = 'Defense')\ndata1['Defense'].plot.hist(bins = 50, range = (0,250), normed = True, ax = axes[1], cumulative = True, legend = 'Defense')","execution_count":67,"outputs":[]},{"metadata":{"_cell_guid":"e9f825b1-42f2-4390-8f6d-3cf9303190cb","_uuid":"703e17e13218f81430858275988141dad60fb4c3"},"cell_type":"markdown","source":"**INDEXING PANDAS TIME SERIES**\n- datetime = object\n- parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"_cell_guid":"83d0a037-19eb-4a48-ab2c-e35d0e5e9d4e","_uuid":"62ab596c43b73022847085bc39be6f344e05a8c2","trusted":false},"cell_type":"code","source":"time_list = ['2018-03-01', '2018-03-02']\nprint(type(time_list[1])) # you can see it's a string \n\n# we can convert string to datetime \ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":68,"outputs":[]},{"metadata":{"_cell_guid":"94e5f458-2ef7-4cd1-afc3-962e3eaec80b","_uuid":"45e6b3c992d283e6ecf9201432dc7ca55b87e95d","trusted":false},"cell_type":"code","source":"data2 = data.head()\ndata2\n\n# add 5 date\ntime_list = ['2018-02-15', '2018-02-20', '2018-02-28', '2018-03-01', '2018-03-02']\ndatetime_object = pd.to_datetime(time_list)\ndata2['date'] = datetime_object","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"585b4d05-497e-466a-84dd-fe99fd73d58e","_uuid":"e45632eef5b38f1200140170127b72fc33fc6b95","trusted":false},"cell_type":"code","source":"data2","execution_count":70,"outputs":[]},{"metadata":{"_cell_guid":"9431bebc-fe8b-4905-9a38-94d56bd5c422","_uuid":"a49d6a1b6c7738e4e6fc1e7d73c91c9b51bdd6f7","trusted":false},"cell_type":"code","source":"# we can make date as index \ndata2 = data2.set_index('date')\ndata2","execution_count":71,"outputs":[]},{"metadata":{"_cell_guid":"69cb8d1f-21d2-42ae-8b25-170cb0685e12","_uuid":"be4cb82db0d0b601be0e97e97476607a57c58eb4","trusted":false},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"2018-02-15\"])\nprint(data2.loc[\"2018-02-28\":\"2018-03-02\"])","execution_count":72,"outputs":[]},{"metadata":{"_cell_guid":"3ddb228f-c2b2-4213-80c1-944b176d1296","_uuid":"2c7939fd48e4b4f1dc9979eb3d2ad0caab29f125"},"cell_type":"markdown","source":"**RESAMPLING PANDAS TIME SERIES**\n\n- Resampling: statistical method over different time intervals\n- Needs string to specify frequency like \"M\" = month or \"A\" = year\n- Downsampling: reduce date time rows to slower frequency like from daily to weekly\n- Upsampling: increase date time rows to faster frequency like from daily to hourly\n- Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’"},{"metadata":{"_cell_guid":"988b0359-48a1-41dc-82ac-98d0a15ee187","_uuid":"5cecd6cd6a9e3f4600cae6685a7fb3445acb8df0","trusted":false},"cell_type":"code","source":"data2","execution_count":73,"outputs":[]},{"metadata":{"_cell_guid":"0c6fa551-48d1-4850-a381-3736a0d01218","_uuid":"34332db19444617f3ab4344b641ba6842a33f6df","trusted":false},"cell_type":"code","source":"# summary by month using resampling\ndata2.resample(rule = 'M').mean()","execution_count":74,"outputs":[]},{"metadata":{"_cell_guid":"07533fd8-d004-4553-ac19-159c92d7a265","_uuid":"f3b19412897b290c0f810bbafddbe054f383f929"},"cell_type":"markdown","source":"# MANIPULATING DATA FRAMES WITH PANDAS\n\n**INDEXING DATA FRAMES**\n- Indexing using square brackets\n- Using column attribute and row label\n- Using loc accessor\n- Selecting only some columns"},{"metadata":{"_cell_guid":"6c338fcd-dcb9-4e95-bc37-23f9555b12ef","_uuid":"690c6430327bdfdab31d60263ce24c9c28f2f46e","collapsed":true,"trusted":false},"cell_type":"code","source":"data = pd.read_csv('../input/pokemon-challenge/pokemon.csv')","execution_count":75,"outputs":[]},{"metadata":{"_cell_guid":"abdde9ed-d82f-4dc0-bb79-c72abb1eccea","_uuid":"97618937bfdf605da8eee42c32907c95ec78fc6c","trusted":false},"cell_type":"code","source":"data.head()","execution_count":76,"outputs":[]},{"metadata":{"_cell_guid":"3cc95ec2-4191-435a-b599-a11ac7cfef3a","_uuid":"ea0abb640cb827a6573885ac4cb3dfff82aca4ef","trusted":false},"cell_type":"code","source":"# we can use [] \ndata['HP'][0]","execution_count":77,"outputs":[]},{"metadata":{"_cell_guid":"d09aab49-afec-4d4c-9226-13d61df310ae","_uuid":"55a30094bc2de8c23aff27dbdeb2529156a2b611","trusted":false},"cell_type":"code","source":"# we can use columns\ndata.HP[0]","execution_count":78,"outputs":[]},{"metadata":{"_cell_guid":"6e56b3e1-2b5c-4c24-82dd-4d67634edd1b","_uuid":"b7bf0f5fb4ce2d642aa465d6bb4043ea8e22b6e0","trusted":false},"cell_type":"code","source":"# use loc\ndata.loc[0,['HP']]","execution_count":79,"outputs":[]},{"metadata":{"_cell_guid":"327c48b3-0ce0-4027-a8f3-9a7ff7bdc231","_uuid":"6a3d909b306a3888d155524eda39f650d93ff0bb","trusted":false},"cell_type":"code","source":"# select certain columns\ndata[['Attack','HP']].head()","execution_count":80,"outputs":[]},{"metadata":{"_cell_guid":"91d0b9c5-2de7-4f94-b0d4-6b0b4d3fa89b","_uuid":"bdf41fcf205f8c108e43051cf2c481a5f73aec69"},"cell_type":"markdown","source":"**SLICING DATA FRAME**\n\nDifference between selecting columns\n- Series and data frames\n- Slicing and indexing series\n- Reverse slicing\n- From something to end"},{"metadata":{"_cell_guid":"cd7ca16e-5d6d-4ade-be30-068b98cda665","_uuid":"daf5662a1d74c7969f2507f32b7fcb9803832fc4","trusted":false},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":81,"outputs":[]},{"metadata":{"_cell_guid":"2761b379-57c8-4d39-ad42-b29283288100","_uuid":"c445eb3140cb5715685c9b420e0c7f587358bb56","trusted":false},"cell_type":"code","source":"# slicing and indexing series\ndata.loc[1:10,'HP': 'Defense']","execution_count":82,"outputs":[]},{"metadata":{"_cell_guid":"82918418-5782-4b5c-bb8d-19c2cb51cab1","_uuid":"1bed6c030dcc7fa0130f5d9645c298ea9bb430be","trusted":false},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"] ","execution_count":83,"outputs":[]},{"metadata":{"_cell_guid":"e7256208-a069-4320-b051-3d4df45d9871","_uuid":"2e425965bff8e58b5541a73f4cdd774d383506a0","trusted":false},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":] ","execution_count":84,"outputs":[]},{"metadata":{"_cell_guid":"c10a3dec-40db-49a2-b8aa-a578e42f2017","_uuid":"d44ae282b01433534e24e731fa6194d1c1fbc2d5"},"cell_type":"markdown","source":"**FILTERING DATA FRAMES**\n\nCreating boolean series Combining filters Filtering column based others"},{"metadata":{"_cell_guid":"d0e5ce69-5fdb-41f1-b4a5-13bcc1bc810f","_uuid":"18929ce6646184c606fdb250071dff009128e4f9","trusted":false},"cell_type":"code","source":"data[data['HP']>200]","execution_count":85,"outputs":[]},{"metadata":{"_cell_guid":"0560a1de-0278-4a70-8043-d29ef1d296b8","_uuid":"9186ab39ad762182f8b2fb2a0d689a22d077aa6c","trusted":false},"cell_type":"code","source":"# combining filters \ndata[(data['HP']>200) & (data['Attack']>5)]","execution_count":86,"outputs":[]},{"metadata":{"_cell_guid":"5422c261-6db9-4e7e-8eea-eb0aff1b0650","_uuid":"91647fd1419e46e294d74e85d65a0ad48fa86e30","scrolled":true,"trusted":false},"cell_type":"code","source":"# filter column based on others\ndata.HP[data['Speed']<10]","execution_count":87,"outputs":[]},{"metadata":{"_cell_guid":"0a42afb7-4d25-4b68-a110-90aa5fb6e9c0","_uuid":"27d492eeb354a5a37524472d0461c2b4e87e20b3"},"cell_type":"markdown","source":"**TRANSFORMING DATA**\n- Plain python functions\n- Lambda function: to apply arbitrary python function to every element\n- Defining column using other columns"},{"metadata":{"_cell_guid":"371931df-eb9a-4815-bb8c-b26976471ee8","_uuid":"b72e6ac52afdea709187756caf9463e0e2521933","trusted":false},"cell_type":"code","source":"def divident(item):\n    return item/2\n\ndata.HP.apply(divident).head()","execution_count":88,"outputs":[]},{"metadata":{"_cell_guid":"0102dae9-607c-420b-9201-31cdbf022617","_uuid":"07ea435e76038dd23ef7a9ed98f77d24900bc4f7","trusted":false},"cell_type":"code","source":"# for simple function, we can use lambda\n\ndata.HP.apply(lambda x: x/2).head()","execution_count":89,"outputs":[]},{"metadata":{"_cell_guid":"bfa6b11e-a323-41d1-8d83-d233a0faccaf","_uuid":"68d7b26abb71066727bdf7c7be77890196501a36","trusted":false},"cell_type":"code","source":"# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":90,"outputs":[]},{"metadata":{"_cell_guid":"8a445f68-cfd0-4bd9-bf45-5480311ab5d8","_uuid":"936d6c894a77dab5c87439c46f248f511b86e0a3"},"cell_type":"markdown","source":"**INDEX OBJECTS AND LABELED DATA**\n\nindex: sequence of label"},{"metadata":{"_cell_guid":"d2b7b1be-f47d-4522-a185-70e13cdc8f5f","_uuid":"4086504158efcd34465cce624377202dab709b37","trusted":false},"cell_type":"code","source":"# current index name \nprint(data.index.name)","execution_count":91,"outputs":[]},{"metadata":{"_cell_guid":"eb368625-c7a7-45c0-a628-01b449ac72cb","_uuid":"b86589acb262433a76da352f9492737a4ba17ffa","trusted":false},"cell_type":"code","source":"# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":92,"outputs":[]},{"metadata":{"_cell_guid":"19a22b02-c196-4160-8b03-fdf505fe6b2e","_uuid":"1c8f67570a5c290f61b48b988cb3b22a73ea7237","trusted":false},"cell_type":"code","source":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","execution_count":93,"outputs":[]},{"metadata":{"_cell_guid":"20dbfedf-f892-4eaa-a57a-b7ddb77e0b26","_uuid":"3a1aae657c7396ced89fbc3949cd8447b003a9a3","collapsed":true,"trusted":false},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use data.index = data[\"#\"]","execution_count":94,"outputs":[]},{"metadata":{"_cell_guid":"b84bb0eb-adff-4f93-9191-d14fb601a763","_uuid":"0a58b1c71b5658cb7bcf425680e692c8ba4652bf"},"cell_type":"markdown","source":"**HIERARCHICAL INDEXING**\n\nSetting indexing"},{"metadata":{"_cell_guid":"0bc27a6f-8a62-4733-b22c-d5d3e9efd0dd","_uuid":"e62a8fbea3b8802b41cae15b3028c11a53a827d8","trusted":false},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('../input/pokemon-challenge/pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":95,"outputs":[]},{"metadata":{"_cell_guid":"1c6b5364-fcd8-476d-8e92-3ebabf8de344","_uuid":"067d72db6501a492e95465aea32aaa9e8debe0d3","trusted":false},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\n","execution_count":96,"outputs":[]},{"metadata":{"_cell_guid":"1b0c7314-e7b0-4ebf-907d-7965242e0c15","_uuid":"54884fb24fc076823010fd5387d7cdab6d0597ed"},"cell_type":"markdown","source":"**PIVOTING DATA FRAMES**\n\npivoting: reshape tool"},{"metadata":{"_cell_guid":"ac458432-dc96-408b-b63f-e30be4efe0ff","_uuid":"340231fd670d35b2364ca769e2f0da91576dd63c","trusted":false},"cell_type":"code","source":"dic = {\"treatment\": ['A','A','B','B'], \"gender\": ['F','M','F','M'],'response': [10,45,9,10],'age':[15,4,74,28]}\ndf = pd.DataFrame(dic)\ndf","execution_count":97,"outputs":[]},{"metadata":{"_cell_guid":"1d46625b-36bd-484d-b483-b670dac2abb2","_uuid":"35042fd60cf1d0db86fe5fa700dbf387a4ce432e","trusted":false},"cell_type":"code","source":"# piviting \ndf.pivot(index = 'treatment',columns = 'gender',values = 'response')","execution_count":98,"outputs":[]},{"metadata":{"_cell_guid":"1c9c67b6-a761-42ae-b8c5-c1470e655530","_uuid":"b560f9a6bcfd8ad4360875b5196b4a83d8ed1c22"},"cell_type":"markdown","source":"**STACKING and UNSTACKING DATAFRAME**\n- deal with multi label indexes\n- level: position of unstacked index\n- swaplevel: change inner and outer level index position"},{"metadata":{"_cell_guid":"299f25c6-bd17-4517-b993-35e05e0ee53c","_uuid":"7314182c4159b77d43e3aca4d74ea75cfb6246b5","trusted":false},"cell_type":"code","source":"# take a look at df\ndf","execution_count":99,"outputs":[]},{"metadata":{"_cell_guid":"7ee6ccb0-5350-4d2a-8b15-83ec3f7e1c91","_uuid":"75ba757b561666bb3d19c4b9bcc5e3e8a57898ad","trusted":false},"cell_type":"code","source":"df1 = df.set_index(keys = ['treatment','gender'])\ndf1","execution_count":100,"outputs":[]},{"metadata":{"_cell_guid":"d8bf1b23-bd76-4171-b864-9dd2aa8bdb73","_uuid":"1a528ff12bf38f06e63923bb1907bd05ca2325a0","trusted":false},"cell_type":"code","source":"# unstack \n# level determine indexes\ndf1.unstack(level = 0)\n\n# treatement is the first level, so when we unstack the dataset, treatment got unstacked","execution_count":101,"outputs":[]},{"metadata":{"_cell_guid":"991a6594-f65e-4e8e-b2a2-b1b978f5efdf","_uuid":"7e06eb9574c612452c9f56eff4b72e1d50c60344","trusted":false},"cell_type":"code","source":"df1.unstack(level = 1)\n\n# now we can also unstack the second order or indexing, gender","execution_count":102,"outputs":[]},{"metadata":{"_cell_guid":"063cdb3b-8192-4d2e-91cb-6ba904f02c87","_uuid":"281b07f42fbe58a3b3c750b8248a95ef30bfd0ba","trusted":false},"cell_type":"code","source":"# change order of indexing \ndf2 = df1.swaplevel(0,1)\ndf2\n\n# now gender is the first order and treatment is the second","execution_count":103,"outputs":[]},{"metadata":{"_cell_guid":"4ebfce4f-d112-4e6a-a173-854ae40bef92","_uuid":"c2e3ddaba957ff12001df26aad5fc96cc98bde3b"},"cell_type":"markdown","source":"**MELTING DATA FRAMES**\n\nReverse of pivoting"},{"metadata":{"_cell_guid":"5c812269-bd39-4a3b-bec0-83c3f3d0e970","_uuid":"a2428f12c2f43360779c0b6118167c70e63671a1","trusted":false},"cell_type":"code","source":"df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":104,"outputs":[]},{"metadata":{"_cell_guid":"4f1ba1e5-1f84-44af-bfb4-f595771c75bf","_uuid":"7ffd9cd4bd33f871fc82a28645309e6a84fd692c","trusted":false},"cell_type":"code","source":"pd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","execution_count":105,"outputs":[]},{"metadata":{"_cell_guid":"8d57f1e9-cb07-4c67-bef1-7c545511617d","_uuid":"c766c45415f2e6ac52b966f07a35cbb514483ca3"},"cell_type":"markdown","source":"**CATEGORICALS AND GROUPBY**"},{"metadata":{"_cell_guid":"829ce511-8236-4415-bc43-eaf299c3e128","_uuid":"a066e481362cc0a12abca6afd936d5a516339a4f","trusted":false},"cell_type":"code","source":"df","execution_count":106,"outputs":[]},{"metadata":{"_cell_guid":"f5d313a6-7647-4355-b381-d73a8d6b45ac","_uuid":"61e254c40380174b4f7db6b684f42965231a9ddf","trusted":false},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby('treatment').mean()\n# there are other methods like sum, std,max or min","execution_count":107,"outputs":[]},{"metadata":{"_cell_guid":"7906ba83-f09d-4355-8aef-1520cc7d2b6e","_uuid":"54adedf162501aefd658ba6d56c6a8efec4579ba","trusted":false},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby('treatment').age.mean()","execution_count":108,"outputs":[]},{"metadata":{"_cell_guid":"cb012e93-c0ec-48e0-b805-2edf483a8270","_uuid":"983af8b85891a8776f96ccab26e3e2a9c8f5676e","trusted":false},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby('treatment')[['age','response']].mean()","execution_count":109,"outputs":[]},{"metadata":{"_cell_guid":"538b14f9-8bfd-4190-b8fe-2df18b2bc0bc","_uuid":"ee688a22f77f7ab3ee21b2b1e3af1d88eac90a3d","trusted":false},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\ndf[\"gender\"] = df[\"gender\"].astype(\"category\")\ndf[\"treatment\"] = df[\"treatment\"].astype(\"category\")\ndf.info()","execution_count":110,"outputs":[]},{"metadata":{"_cell_guid":"d28a38af-98bc-4c8a-b80a-a3d3534eaa0c","_uuid":"d2eb5f322abc8d428cc20d24d5177640c588d660"},"cell_type":"markdown","source":"   # Machine Learning\n\nMachine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using python."},{"metadata":{"_cell_guid":"431abd10-41e8-4aed-8e66-0a9396b8d337","_uuid":"843dcd1a055829079f676918c70a046d543948f3","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":111,"outputs":[]},{"metadata":{"_cell_guid":"6dbf1d4e-0845-40b3-8dcb-828dd18be1af","_uuid":"f62fb807d5a6292519ea681c55ed228d93a06ea9","trusted":false},"cell_type":"code","source":"# read csv (comma separated value) into data\ndata = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\nprint(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')","execution_count":112,"outputs":[]},{"metadata":{"_cell_guid":"bba79288-0d5d-421d-9b9a-d8e3cc6e2e3d","_uuid":"f997dbd3976fac94097c1dadc4cabec365f727cc","collapsed":true},"cell_type":"markdown","source":"# A. SUPERVISED LEARNING\n\nSupervised learning: It uses data that has labels. Example, there are orthopedic patients data that have labels normal and abnormal.\n\nThere are features(predictor variable) and target variable. Features are like pelvic radius or sacral slope. Target variables are labels normal and abnormal\n\nAim is that as given features(input) predict whether target variable(output) is normal or abnormal\n\n- Classification: target variable consists of categories like normal or abnormal\n- Regression: target variable is continious like stock market\n- If these explanations are not enough for you, just google them. However, be careful about terminology: features = predictor variable = independent variable = columns = inputs. target variable = responce variable = class = dependent variable = output = result\n\nSome methods we can consider: \n- EDA(Exploratory Data Analysis)\n- K-Nearest Neighbors (KNN)\n- Regression\n- Cross Validation (CV)\n- ROC Curve\n- Hyperparameter Tuning\n- Pre-procesing Data"},{"metadata":{"_cell_guid":"1228d19e-2bfa-4b2d-82dd-cfe0d6d09395","_uuid":"d8f40dde09bafcb03b778fb27e2591fe5585bd1d","collapsed":true},"cell_type":"markdown","source":"**Step 1: EXPLORATORY DATA ANALYSIS (EDA)**"},{"metadata":{"_cell_guid":"c7470eb8-ef32-40c9-8b39-eb16c0aa1d1c","_uuid":"959b99a2b80a59e3830a7aa8dab652908d9fa690","trusted":false},"cell_type":"code","source":"# check the head of the data and get a taste of what it looks like\ndata.head()","execution_count":113,"outputs":[]},{"metadata":{"_cell_guid":"6c9c1b55-c629-4062-9138-c599090ae57a","_uuid":"b8c97648972bf2e82997c9258974b2a9fc18ed11","trusted":false},"cell_type":"code","source":"data.info()\n\n# check out how big is the data and see if there are any NaN\n# there are 310 entries, \n# features are float type\n# target is object type, such as string\n","execution_count":115,"outputs":[]},{"metadata":{"_cell_guid":"b3feab51-2c25-49a5-9994-9389645d4109","_uuid":"8ce1ec67f7d96bba068e9f93540890654243c0d2","trusted":false},"cell_type":"code","source":"data.describe()\n\n# In order to visualize data, values should be closer each other. So we can check this by checking out describe()","execution_count":116,"outputs":[]},{"metadata":{"_cell_guid":"eabf11a8-5bfd-4690-bfca-7a9c0fbfe59e","_uuid":"80e64ffd47ad287482188d6f25ac376362101d7b","trusted":false},"cell_type":"code","source":"# when data is not too large, we can quickly plot pairplot to see the relationship between each feature\nsns.pairplot(data, hue = 'class')","execution_count":117,"outputs":[]},{"metadata":{"_cell_guid":"ca2c4f74-20eb-41be-bfdf-6413800a0040","_uuid":"c436640466da37e7ce7fd77fceddfa650c085e11","trusted":false},"cell_type":"code","source":"# do some value counts: \ndata['class'].value_counts()\n\nsns.countplot(x = 'class',data=data)","execution_count":118,"outputs":[]},{"metadata":{"_cell_guid":"ab032639-6837-4387-9e78-4695f7e89e8b","_uuid":"c68d787c9d8284305b6dd0629e48d98798f8092e","collapsed":true},"cell_type":"markdown","source":"**K-NEAREST NEIGHBORS (KNN)**\n\nKNN: Look at the K closest labeled data points\n- Classification method.\n- First we need to train our data. Train = fit\n- fit(): fits the data, train the data.\n- predict(): predicts the data \n\nLets learn how to implement it with sklearn\n- x: features\n- y: target variables(normal, abnormal)\n- n_neighbors: K. In this example it is 3. it means that Look at the 3 closest labeled data points\n\nFor evaluating the model, we need to split our data train and test sets.\n\n- train: use train set by fitting\n- test: make prediction on test set.\n- With train and test sets, fitted data and tested data are completely different\n- train_test_split(x,y,test_size = 0.3,random_state = 1)\n- x: features\n- y: target variables (normal,abnormal)\n- test_size: percentage of test size. Example test_size = 0.3, test size = 30% and train size = 70%\n- random_state: sets a seed. If this seed is same number, train_test_split() produce exact same split at each time\n- fit(x_train,y_train): fit on train sets\n- score(x_test,y_test)): predict and give accuracy on test sets"},{"metadata":{"_cell_guid":"98d87258-cd27-4be2-9161-b63f3b41665b","_uuid":"ea2cc4841be8b9baa157fcd5b50d51eb0c6230bf","collapsed":true,"trusted":false},"cell_type":"code","source":"# KNN\n# import the library and define KNN object \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# set x and y\nx = data.loc[:,data.columns !='class']\ny = data['class']\n","execution_count":119,"outputs":[]},{"metadata":{"_cell_guid":"2a4e01c9-7663-42d6-82cd-7cbad8cf0f7f","_uuid":"0859402adabec48920d63edd291f287fc9857c6c","trusted":false},"cell_type":"code","source":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n\n# fit the data\nknn.fit(x_train, y_train)\n\n# predict the data \nprediction = knn.predict(x_test)\n\n# check the accuracy score\nprint(\"With KNN(N = 3), the accuracy is: \",knn.score(x_test,y_test))","execution_count":120,"outputs":[]},{"metadata":{"_cell_guid":"676c3f17-67d4-424c-aea5-e4303f70a7c6","_uuid":"48e1208087ea532426b2a3180f1eb3b7f8207de2"},"cell_type":"markdown","source":"Accuracy is 86% so is it good ? I do not know actually, we will see at the end of tutorial. \n\nNow the question is why we choose K = 3 or what value we need to choose K. The answer is in model complexity\n\nModel complexity:\n\nK has general name. It is called a hyperparameter. For now just know K is hyperparameter and we need to choose it that gives best performace.\n\nLiterature says if k is small, model is complex model can lead to overfit. It means that model memorizes the train sets and cannot predict test set with good accuracy.\n\nIf k is big, model that is less complex model can lead to underfit.\n\nAt below, I range K value from 1 to 25(exclude) and find accuracy for each K value. As you can see in plot, when K is 1 it memozize train sets and cannot give good accuracy on test set (overfit). Also if K is 18, model is lead to underfit. Again accuracy is not enough. However look at when K is 18(best performance), accuracy has highest value almost 88%."},{"metadata":{"_cell_guid":"6d496c01-e5e9-4d9f-9700-d43963aa3f92","_uuid":"dc8533e59664e23c261821e420f8575b70242462","trusted":false},"cell_type":"code","source":"# Model complexity \nneig = np.arange(1,25) # set an arange from 1 to 24\n\n# create empty list to hold train and test accuracy\ntrain_accuracy=[]\ntest_accuracy=[]\n\n# loop over differen neig values and put the result to train and test accuracy list\nfor i, k in enumerate(neig):\n    # k from 1 to 24\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    #fit\n    knn.fit(x_train, y_train)\n    \n    # train accuracy\n    train_accuracy.append(knn.score(x_train,y_train))\n    \n    # test accuracy\n    test_accuracy.append(knn.score(x_test,y_test))\n\n# make the plot\nplt.figure(figsize=(13,8))\nplt.plot(neig,test_accuracy, label = 'Testing Accuracy')\nplt.plot(neig,train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Score of Accuracy')\nplt.title('k value vs. Accuracy')\n\n# keep the plot\nplt.show()\n\n# find the best score and # of k\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy), 1+test_accuracy.index(np.max(test_accuracy))))","execution_count":127,"outputs":[]},{"metadata":{"_cell_guid":"3934a269-45f7-4d39-8e8a-086dfa6e8288","_uuid":"84f5bed031d34625dbc4ea7aaa50537f49376a96","collapsed":true},"cell_type":"markdown","source":"**ML Summary, PART 1**\n\n- learned what is supervised learning \n- explore the data before selecting a model\n- learn of KNN\n    - how to split train vs. test set\n    - how to fit, predict data\n    - how to use score() to get model accuracy\n    - how to choose hyperparameter (K), Basically run through a list of K and find the one with the highest accuracy score"},{"metadata":{"_cell_guid":"187e1204-764e-4360-85c6-5d1baa3f6221","_uuid":"a6e8a38d6bd3117dc4f227eb44e28cf5ede39653","collapsed":true},"cell_type":"markdown","source":"**REGRESSION**\n\n- Regression is one of the supervised learning \n- There are linear and logistic regressions \n- Let's pick pelvic_incidence and sacral_slope for a simple regression model. (I looked at pairplot before and pick two measurements that look very linear related. "},{"metadata":{"trusted":false,"_uuid":"33bcb9ec0baff4281e0d2f5fcbcea138ba751ea6"},"cell_type":"code","source":"# create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable\n\n# pick out the abnormal one and see how pelvic_incidence and sacral_slope were correlative\ndata1 = data[data['class']=='Abnormal']\nx = data1['pelvic_incidence'].reshape(-1,1)\ny = data1['sacral_slope'].reshape(-1,1)\n\n# plot the scatter plot\nplt.figure(figsize=(8,8))\nplt.scatter(x, y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')","execution_count":141,"outputs":[]},{"metadata":{"_uuid":"b8be870a36387610542ab4541d370e20a8b78550"},"cell_type":"markdown","source":"Linear regression\n\n- y = ax + b where y = target, x = feature and a = parameter of model\n- We choose parameter of model(a) according to minimum error function that is lost function\n- In linear regression we use Ordinary Least Square (OLS) as lost function.\n- OLS: sum all residuals but some positive and negative residuals can cancel each other so we sum of square of residuals. It is called OLS\n- Score: Score uses R^2 method that is ((y_pred - y_mean)^2 )/(y_actual - y_mean)^2\n"},{"metadata":{"trusted":false,"_uuid":"6bdb425827f29e0533544712579bfe690db34821"},"cell_type":"code","source":"# linear regression\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\n\n# fit\nreg.fit(x,y)\n\n#predict \npredicted = reg.predict(x)\n\nprint('R^2 scores: ',reg.score(x,y))\n\n# plot the regression line and scatter plot\nplt.plot(x,predicted, color = 'black', linewidth = 3)\nplt.scatter(x,y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')","execution_count":149,"outputs":[]},{"metadata":{"_uuid":"13a7529ec0f4a5e770b38ac152dbb75255a059d2"},"cell_type":"markdown","source":"As you know in KNN method we use train test split with random_state that split exactly same at each time. However, if we do not use random_state, data is split differently at each time and according to split accuracy will be different. Therefore, we can conclude that model performance is dependent on train_test_split. For example you split, fit and predict data 5 times and accuracies are 0.89, 0.9, 0.91, 0.92 and 0.93, respectively. Which accuracy do you use? Do you know what accuracy will be at 6th times split, train and predict. The answer is I do not know but if I use cross validation I can find acceptable accuracy. \n\n**Cross Validation (CV)**\n\n- K folds = K fold CV.\n- Look at this image it defines better than me :)\n- When K is increase, computationally cost is increase\n- cross_val_score(reg,x,y,cv=5): use reg(linear regression) with x and y that we define at above and K is 5. It means 5 times(split, train,predict)"},{"metadata":{"trusted":false,"_uuid":"1fc61f37ce0e3153026e44911536aea6a5ee5bfd"},"cell_type":"code","source":"# CV\n\nfrom sklearn.model_selection import cross_val_score\nreg = LinearRegression()\nk = 5\ncv_result = cross_val_score(reg, x,y,cv = k) # use R^2 score\nprint('CV scores: ', cv_result)\nprint('CV scores average: ', cv_result.mean())\n\n# acceptable range is 0.39","execution_count":151,"outputs":[]},{"metadata":{"_uuid":"ff5b8a0ba880a170e9fdac73974a223cb61f4487"},"cell_type":"markdown","source":"**Regularized Regression**\n\nAs we learn linear regression choose parameters (coefficients) while minimizing lost function. If linear regression thinks that one of the feature is important, it gives high coefficient to this feature. However, this can cause overfitting that is like memorizing in KNN. In order to avoid overfitting, we use regularization that penalize large coefficients.\n\n- Ridge regression: First regularization technique. Also it is called L2 regularization.\n    - Ridge regression lost fuction = OLS + alpha * sum(parameter^2)\n    - alpha is parameter we need to choose to fit and predict. Picking alpha is similar to picking K in KNN. As you understand alpha is hyperparameter that we need to choose for best accuracy and model complexity. This process is called hyperparameter tuning.\n    - What if alpha is zero? lost function = OLS so that is linear rigression :)\n    - If alpha is small that can cause overfitting\n    - If alpha is big that can cause underfitting. But do not ask what is small and big. These can be change from problem to problem.\n\n- Lasso regression: Second regularization technique. Also it is called L1 regularization.\n    - Lasso regression lost fuction = OLS + alpha * sum(absolute_value(parameter))\n    - It can be used to select important features od the data. Because features whose values are not shrinked to zero, is chosen by lasso regression\n    - In order to choose feature, I add new features in our regression data\n\nLinear vs Ridge vs Lasso First impression: \n- Linear Feature Selection: 1.Lasso 2.Ridge \n- Regression model: 1.Ridge 2.Lasso 3.Linear"},{"metadata":{"trusted":false,"_uuid":"35e3d99eb1370fa753c34791879d13cca8e804e8"},"cell_type":"code","source":"# Ridge\nfrom sklearn.linear_model import Ridge\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state = 2, test_size = 0.3)\nridge = Ridge(alpha = 0.1, normalize = True)\nridge.fit(x_train, y_train)\nridge_predict = ridge.predict(x_test)\nprint('Ridge socre: ', ridge.score(x_test,y_test))","execution_count":152,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0aec11a303b24100f0e94a8b81f726f179775628"},"cell_type":"code","source":"# Lasso\nfrom sklearn.linear_model import Lasso\n\n# get some x variable \nx = data1[['pelvic_incidence','pelvic_tilt numeric','lumbar_lordosis_angle','pelvic_radius']]\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state=3,test_size = 0.3)\nlasso = Lasso(alpha=0.1,normalize = True)\nlasso.fit(x_train,y_train)\nlasso_predict = lasso.predict(x_test)\nprint('Lasso score: ', lasso.score(x_test,y_test))\nprint('Lasso coefficients: ', lasso.coef_)\n\n# check the coefficients ,and you can see 'pelvic_incidence','pelvic_tilt numeric' are important features, but the rest are not","execution_count":158,"outputs":[]},{"metadata":{"_cell_guid":"d5f66bc2-cb4f-4154-9713-f9d33b19a374","_uuid":"ad9fd504b9a86f1b67a07d4af366709e75c49302","collapsed":true},"cell_type":"markdown","source":" **Accuracy**\n \n We can use confusion matrix as a model measurement matric in imbalance data. \n \n- tp = true positive(20), fp = false positive(7), fn = false negative(8), tn = true negative(58)\n- tp = Prediction is positive(normal) and actual is positive(normal).\n- fp = Prediction is positive(normal) and actual is negative(abnormal).\n- fn = Prediction is negative(abnormal) and actual is positive(normal).\n- tn = Prediction is negative(abnormal) and actual is negative(abnormal)\n- precision = tp / (tp+fp)\n- recall = tp / (tp+fn)\n- f1 = 2 precision recall / ( precision + recall)\n "},{"metadata":{"_cell_guid":"e36c9ab6-473d-4f1c-a0df-76759ecf0350","_uuid":"8f030704402aef0369085fd33818dd0d35e43392","trusted":false},"cell_type":"code","source":"# Confusion matrix with random forest\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nx = data.loc[:,data.columns != 'class']\ny = data[['class']]\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 1)\nrf = RandomForestClassifier(random_state = 4)\nrf.fit(x_train, y_train)\ny_pred = rf.predict(x_test)\ncm=confusion_matrix(y_test,y_pred)\nprint('Confusion matrix: \\n',cm)\nprint('Classification Report: \\n', classification_report(y_test, y_pred))\n","execution_count":165,"outputs":[]},{"metadata":{"_cell_guid":"7b409c96-2adb-43ed-9ba6-f45d03c0ed7b","_uuid":"510a9ceb9f76fd69324780f5f60f435bd88eeda4","trusted":false},"cell_type":"code","source":"# visualize with seaborn library\nsns.heatmap(cm,annot=True, fmt = 'd')","execution_count":167,"outputs":[]},{"metadata":{"_cell_guid":"91371012-358c-419d-b466-e09107d01c08","_uuid":"c2fec5368e2e6608a70eb028dac51f9235c9e94f","collapsed":true},"cell_type":"markdown","source":"**ROC Curve with Logistic Regression**\n\n- logistic regression output is probabilities\n- If probability is higher than 0.5 data is labeled 1(abnormal) else 0(normal)\n- By default logistic regression threshold is 0.5\n- ROC is receiver operationg characteristic. In this curve x axis is false positive rate and y axis is true positive rate\n- If the curve in plot is closer to left-top corner, test is more accurate.\n- Roc curve score is auc that is computation area under the curve from prediction scores\n- We want auc to closer 1\n- fpr = False Positive Rate\n- tpr = True Positive Rate"},{"metadata":{"trusted":false,"_uuid":"7affbfa2de944a43213b43deedd39a804cda71b9"},"cell_type":"code","source":"# ROC Curve with logistic regression \nfrom sklearn.metrics import roc_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# abnormal = 1, normal = 0\ndata['class_binary'] = [1 if i =='Abnormal' else 0 for i in data['class']]\n\nx=data.loc[:,'pelvic_incidence':'degree_spondylolisthesis']\ny=data['class_binary']\n\nx_trian, x_test, y_train, y_test = train_test_split(x,y,test_size =0.3, random_state = 42)\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\n\ny_pred_prob = logreg.predict_proba(x_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test,y_pred_prob)\n\n# make the ROC plot\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\n","execution_count":193,"outputs":[]},{"metadata":{"_uuid":"ad278b411936a244e11420b58340b25efa81677d"},"cell_type":"markdown","source":"**HYPERPARAMETER TUNING**\n\nFor example:\n- k at KNN\n- alpha at Ridge and Lasso\n- Random forest parameters like max_depth\n- linear regression parameters(coefficients)\n\nHyperparameter tuning:\n- try all of combinations of different parameters\n- fit all of them\n- measure prediction performance\n- see how well each performs\n- finally choose best hyperparameters\n\nWe only need is one line code that is** GridSearchCV**\n- grid: K is from 1 to 50(exclude)\n- GridSearchCV takes knn and grid and makes grid search. It means combination of all hyperparameters. Here it is k.\n"},{"metadata":{"trusted":false,"_uuid":"ca224f4b366c73c4d3909851b50e72ac0d73b3e6"},"cell_type":"code","source":"# grid search cross validation with 1 hyperparameter\nfrom sklearn.model_selection import GridSearchCV\ngrid = {'n_neighbors': np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, grid, cv = 3)\nknn_cv.fit(x,y)\n\n# print hyperparameter\nprint('Tuned hyperparameter k: {}'.format(knn_cv.best_params_))\nprint('Best score: {}'.format(knn_cv.best_score_))","execution_count":194,"outputs":[]},{"metadata":{"_uuid":"e996981261f2aebc441a13e93465843ffea33d4c"},"cell_type":"markdown","source":"Other grid search example with 2 hyperparameter\n\n- First hyperparameter is C:logistic regression regularization parameter\n    - If C is high: overfit\n    - If C is low: underfit\n\n- Second hyperparameter is penalty(lost function): l1 (Lasso) or l2(Ridge) as we learnt at linear regression part."},{"metadata":{"trusted":false,"_uuid":"25b0ff5ebde3de0515aa4a2a81692c2b1d9026c1"},"cell_type":"code","source":"# grid search cross validation with 2 hyperparameter\n# 1. hyperparameter is C:logistic regression regularization parameter\n# 2. penalty l1 or l2\n# Hyperparameter grid\nparam_grid = {'C': np.logspace(-3, 3, 7), 'penalty': ['l1', 'l2']}\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 12)\nlogreg = LogisticRegression()\nlogreg_cv = GridSearchCV(logreg, param_grid, cv = 3)\nlogreg_cv.fit(x_train, y_train)\n\nprint('Tuned hyperparameters: {}'.format(logreg_cv.best_params_))\nprint('Best Accuracy: {}'.format(logreg_cv.best_score_))","execution_count":200,"outputs":[]},{"metadata":{"_uuid":"f8bfee1d310c6c9c29f9f4747d1e951b746be10f"},"cell_type":"markdown","source":"**PRE-PROCESSING DATA**\n\n- In real life data can include objects or categorical data in order to use them in sklearn we need to encode them into numerical data\n- In data, class is abnormal and normal. Lets convert them into numeric value (actually I did it in logistic regression part with different method)\n- 2 different feature is created with the name class_Abnormal and class_Normal\n- However we need to drop one of the column because they are duplicated"},{"metadata":{"trusted":false,"_uuid":"b0268ed34de7fd5b8d404feebf36005953534059"},"cell_type":"code","source":"# load data\ndata = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\n\n# get dummies\ndf = pd.get_dummies(data)\ndf.head(10)","execution_count":201,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7fe288a837540863f49b8e063f59d03352d74fe9"},"cell_type":"code","source":"# drop one of the dummy varaible to avoide duplicate\ndf.drop('class_Normal',axis = 1, inplace = True)\ndf.head(10)","execution_count":202,"outputs":[]},{"metadata":{"_uuid":"60eab68c32156e12c305f1aa677bcc067a38a147"},"cell_type":"markdown","source":"**Other preprocessing step is centering, scaling or normalizing**\n\n- For example, KNN uses form of distance for classificaiton like some other methods. Therefore, we need to scale data. For this reason, we use\n    - standardization: ( x - x.mean) / x.variance or x - x.min / x.range\n- pipeline: The purpose of the pipeline is to assemble several steps like svm(classifier) and standardization(pre-processing)\n- How we create parameters name: for example SVM_ _C : stepName__parameterName\n- Then grid search to find best parameters"},{"metadata":{"trusted":false,"_uuid":"a6da711623d9b2918300f2a694cc4d33629dbae4"},"cell_type":"code","source":"#  SVM, pre-process and pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nsteps = [('scalar', StandardScaler()),\n         ('SVM', SVC())]\npipeline = Pipeline(steps)\nparameters = {'SVM__C':[1, 10, 100],\n              'SVM__gamma':[0.1, 0.01]}\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 1)\ncv = GridSearchCV(pipeline,param_grid=parameters,cv=3)\ncv.fit(x_train,y_train)\n\ny_pred = cv.predict(x_test)\n\nprint(\"Accuracy: {}\".format(cv.score(x_test, y_test)))\nprint(\"Tuned Model Parameters: {}\".format(cv.best_params_))","execution_count":204,"outputs":[]},{"metadata":{"_uuid":"878341723159a5f2ef51f466900a31f1812e6154"},"cell_type":"markdown","source":"**UNSUPERVISED LEARNING**\n\n* Unsupervised learning: It uses data that has unlabeled and uncover hidden patterns from unlabeled data. Example, there are orthopedic patients data that do not have labels. You do not know which orthopedic patient is normal or abnormal.\n* As you know orthopedic patients data is labeled (supervised) data. It has target variables. In order to work on unsupervised learning, lets drop target variables and to visualize just consider pelvic_radius and degree_spondylolisthesis"},{"metadata":{"_uuid":"ff49200170094784c6624bcc2156314f1f16e196"},"cell_type":"markdown","source":"**KMEANS**\n\nLets try our first unsupervised method that is KMeans Cluster\n\nKMeans Cluster: The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity\n\nKMeans(n_clusters = 2): n_clusters = 2 means that create 2 cluster"},{"metadata":{"trusted":false,"_uuid":"68cfffa38bc76dd065453d5c76109bac4c65e7c7"},"cell_type":"code","source":"data = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\nplt.scatter(data['pelvic_radius'],data['degree_spondylolisthesis'])\nplt.xlabel('pelvic_radius')\nplt.ylabel('degree_spondylolisthesis')","execution_count":205,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9659f76e735acafb804c52a86b1061a4bf5cc762"},"cell_type":"code","source":"# KMean clustering\ndata2 = data[['pelvic_radius','degree_spondylolisthesis']]\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 2)\nkmeans.fit(data2)\nlabels = kmeans.predict(data2)\nplt.scatter(data['pelvic_radius'],data['degree_spondylolisthesis'],c = labels)","execution_count":213,"outputs":[]},{"metadata":{"_uuid":"244868712fd37cf4f1fd36179cfb2fc452a2ac86"},"cell_type":"markdown","source":"**EVALUATING OF CLUSTERING**\n\nWe cluster data in two groups. In order to evaluate clustering we will use cross tabulation table."},{"metadata":{"trusted":false,"_uuid":"611cab74c33f17ed385b6fe173fd8a2d38596cb2"},"cell_type":"code","source":"# cross tabulation table\ndf = pd.DataFrame({'labels':labels,\"class\":data['class']})\nct = pd.crosstab(df['labels'],df['class'])\nprint(ct)","execution_count":215,"outputs":[]},{"metadata":{"_uuid":"738c517c236293efc5b34e462b4c33a4357f2b4a"},"cell_type":"markdown","source":"The new question is that we know how many class data includes, but what if number of class is unknow in data. This is kind of like hyperparameter in KNN or regressions.\n\nHow many cluster to choose??\n\n- inertia: how spread out the clusters are distance from each sample\n- lower inertia means more clusters\n- What is the best number of clusters ? *There are low inertia and not too many cluster trade off so we can choose below = Think of 2, or 3\n"},{"metadata":{"trusted":false,"_uuid":"6e2f8caf504313e5af54aa46cbd15e25bdd8d4ac"},"cell_type":"code","source":"# inertia\ninertia_list = np.empty(8)\nfor i in range(1,8):\n    kmeans = KMeans(n_clusters = i)\n    kmeans.fit(data2)\n    inertia_list[i] = kmeans.inertia_\n\nplt.plot(range(0,8),inertia_list,'-o')\nplt.xlabel('Number of cluster')\nplt.ylabel('Inertia')","execution_count":222,"outputs":[]},{"metadata":{"_uuid":"6b4ae8bc89a83e6a9d702c124e089b4b06ec8bf4"},"cell_type":"markdown","source":"**STANDARDIZATION**\n\n- Standardizaton is important for both supervised and unsupervised learning\n- Do not forget standardization as pre-processing\n- As we already have visualized data so you got the idea. Now we can use all features for clustering.\n- We can use pipeline like supervised learning."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"41ecdbe0cfae46ebbdff4383ee9501a9933bc04a"},"cell_type":"code","source":"data = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\ndata3 = data.drop('class', axis = 1)","execution_count":224,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d3b6b301763086e4d1494a6e949ebeb6f4e56898"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nscalar = StandardScaler()\nkmeans = KMeans(n_clusters = 2)\npipe = make_pipeline(scalar,kmeans)\npipe.fit(data3)\nlabels = pipe.predict(data3)\ndf = pd.DataFrame({'labels':labels,\"class\":data['class']})\nct = pd.crosstab(df['labels'],df['class'])\nprint(ct)","execution_count":233,"outputs":[]},{"metadata":{"_uuid":"0a0ec318f6226333648a7db34b96d64c135fe03a"},"cell_type":"markdown","source":"**HIERARCHY**\n\n- vertical lines are clusters\n- height on dendogram: distance between merging cluster\n- method= 'single' : closest points of clusters"},{"metadata":{"trusted":false,"_uuid":"371e9f47cb0fe65da3863855b29b2269dae164f8"},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, dendrogram\n\nmerg = linkage(data3.loc[200:220,:], method = 'single')\ndendrogram(merg, leaf_rotation=90, leaf_font_size = 6)\nplt.show()","execution_count":235,"outputs":[]},{"metadata":{"_uuid":"b532071f4177f0207c21ae52b0305545dcd20c7d"},"cell_type":"markdown","source":"**T - Distributed Stochastic Neighbor Embedding (T - SNE)**\n\n- learning rate: 50-200 in normal\n- fit_transform: it is both fit and transform. t-sne has only have fit_transform\n- Varieties have same position relative to one another"},{"metadata":{"trusted":false,"_uuid":"e0de3524f14467afe7a1b6741deaeb5dd157f281"},"cell_type":"code","source":"from sklearn.manifold import TSNE\nmodel = TSNE(learning_rate=100)\ntransformed = model.fit_transform(data2)\nx = transformed[:,0]\ny = transformed[:,1]\n\ncolor_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\nplt.scatter(x,y,c = color_list )\nplt.xlabel('pelvic_radius')\nplt.xlabel('degree_spondylolisthesis')\nplt.show()","execution_count":238,"outputs":[]},{"metadata":{"_uuid":"eee925cfb7e9afc2da775c770b8bcc0e9dcddd45"},"cell_type":"markdown","source":"**PRINCIPLE COMPONENT ANALYSIS (PCA)**\n\n- Fundemental dimension reduction technique\n- first step is decorrelation:\n    - rotates data samples to be aligned with axes\n    - shifts data asmples so they have mean zero\n    - no information lost\n    - fit() : learn how to shift samples\n    - transform(): apply the learned transformation. It can also be applies test data\n- Resulting PCA features are not linearly correlated\n- Principle components: directions of variance"},{"metadata":{"trusted":false,"_uuid":"049c4aca6b1fc678a9c8f268910292263b7336e7"},"cell_type":"code","source":"# PCA\nfrom sklearn.decomposition import PCA\nmodel = PCA()\nmodel.fit(data3)\ntransformed = model.transform(data3)\nprint('Principle components: ',model.components_)","execution_count":239,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"911dc3b44603c71458af95f69958d28d5f4d36e5"},"cell_type":"code","source":"# PCA variance\nscaler = StandardScaler()\npca = PCA()\npipeline = make_pipeline(scaler,pca)\npipeline.fit(data3)\n\nplt.bar(range(pca.n_components_), pca.explained_variance_)\nplt.xlabel('PCA feature')\nplt.ylabel('variance')\nplt.show()","execution_count":240,"outputs":[]},{"metadata":{"_uuid":"8131b23bbf964b21bd43a12d3dcaf418b46972ac"},"cell_type":"markdown","source":"- Second step: intrinsic dimension: number of feature needed to approximate the data essential idea behind dimension reduction\n- PCA identifies intrinsic dimension when samples have any number of features\n- intrinsic dimension = number of PCA feature with significant variance\n- In order to choose intrinsic dimension try all of them and find best accuracy"},{"metadata":{"trusted":false,"_uuid":"dff760735331051cad8da6e845edaae507fff6b6"},"cell_type":"code","source":"# apply PCA\npca = PCA(n_components = 2)\npca.fit(data3)\ntransformed = pca.transform(data3)\nx = transformed[:,0]\ny = transformed[:,1]\nplt.scatter(x,y,c = color_list)\nplt.show()","execution_count":241,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e65806a7c1da44efd9b56952f8820ddb24169311"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}