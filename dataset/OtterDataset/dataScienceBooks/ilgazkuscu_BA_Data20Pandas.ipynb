{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import uproot # for reading .root files\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "\n",
    "#import awkward as ak # for handling complex and nested data structures efficiently\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator # for minor ticks\n",
    "from lmfit.models import PolynomialModel, GaussianModel # for the signal and background fits\n",
    "import vector #to use vectors\n",
    "import requests # for HTTP access\n",
    "import aiohttp # HTTP client support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ATLAS Open Data directory\n",
    "path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/\" # web address\n",
    "tuple_path = \"/project/etp1/gduckeck/atlas/13TeV/GamGam/Data/\" #Current path!\n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/\" # web address\n",
    "\n",
    "#tuple_path = \\\"~/Downloads/GamGamNew/\\\" # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_list = ['data15_periodD','data15_periodE','data15_periodF','data15_periodG','data15_periodH','data15_periodJ','data16_periodA','data16_periodB','data16_periodC','data16_periodD','data16_periodE','data16_periodF','data16_periodG','data16_periodK','data16_periodL']\n",
    "samples_list = ['data_A', 'data_B', 'data_C','data_D'] # add if you want more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_B\n"
     ]
    }
   ],
   "source": [
    "print(samples_list[1])\n",
    "\n",
    "# This is now appended to our file path to retrieve the data15_periodG.root file\n",
    "data_B_path = path + samples_list[3] + \".GamGam.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/data_D.GamGam.root'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_B_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process data_A. Error: https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/data_A.GamGam.root\n",
      "Failed to process data_B. Error: https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/data_B.GamGam.root\n",
      "Failed to process data_C. Error: https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/data_C.GamGam.root\n",
      "Failed to process data_D. Error: https://atlas-opendata.web.cern.ch/atlas-opendata/13TeV/GamGam/Data/data_D.GamGam.root\n",
      "The number of entries in the tree are: 3602176\n",
      "The information stored in the tree is: ['runNumber', 'eventNumber', 'channelNumber', 'mcWeight', 'scaleFactor_PILEUP', 'scaleFactor_ELE', 'scaleFactor_MUON', 'scaleFactor_PHOTON', 'scaleFactor_TAU', 'scaleFactor_BTAG', 'scaleFactor_LepTRIGGER', 'scaleFactor_PhotonTRIGGER', 'trigE', 'trigM', 'trigP', 'lep_n', 'lep_truthMatched', 'lep_trigMatched', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_E', 'lep_z0', 'lep_charge', 'lep_type', 'lep_isTightID', 'lep_ptcone30', 'lep_etcone20', 'lep_trackd0pvunbiased', 'lep_tracksigd0pvunbiased', 'met_et', 'met_phi', 'jet_n', 'jet_pt', 'jet_eta', 'jet_phi', 'jet_E', 'jet_jvt', 'jet_trueflav', 'jet_truthMatched', 'jet_MV2c10', 'photon_n', 'photon_truthMatched', 'photon_trigMatched', 'photon_pt', 'photon_eta', 'photon_phi', 'photon_E', 'photon_isTightID', 'photon_ptcone30', 'photon_etcone20', 'photon_convType', 'tau_n', 'tau_pt', 'tau_eta', 'tau_phi', 'tau_E', 'tau_isTightID', 'tau_truthMatched', 'tau_trigMatched', 'tau_nTracks', 'tau_BDTid', 'ditau_m', 'lep_pt_syst', 'met_et_syst', 'jet_pt_syst', 'photon_pt_syst', 'tau_pt_syst', 'XSection', 'SumWeights', 'largeRjet_n', 'largeRjet_pt', 'largeRjet_eta', 'largeRjet_phi', 'largeRjet_E', 'largeRjet_m', 'largeRjet_truthMatched', 'largeRjet_D2', 'largeRjet_tau32', 'largeRjet_pt_syst', 'tau_charge']\n"
     ]
    }
   ],
   "source": [
    "# Accessing the file from the online database (\":analysis\" opens the tree in a desired manner)\n",
    "for sample in samples_list:\n",
    "    # Construct the file path\n",
    "    file_path = f\"{path}{sample}.GamGam.root\" #e.g. tree = .../GamGam/Data/data15_periodD.root + :analysis\n",
    "    \n",
    "    try:\n",
    "        # Open the tree named \":analysis\" in each file\n",
    "        with uproot.open(file_path + \": mini\") as t:\n",
    "            tree = t\n",
    "            \n",
    "            # Print the number of entries in the tree\n",
    "            print(f\"Processing {sample}:\")\n",
    "            print(f\"Number of entries in the tree: {tree.num_entries}\")\n",
    "            \n",
    "            # Print the information stored in the tree\n",
    "         \n",
    "            \n",
    "            # Perform any additional operations on the tree here\n",
    "            # For example, applying cuts, extracting data, etc.\n",
    "            # ...\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {sample}. Error: {e}\")\n",
    "\n",
    "\n",
    "# The number of entries in the tree can be viewed\n",
    "print(\"The number of entries in the tree are:\", tree.num_entries)\n",
    "\n",
    "# All the information stored in the tree can be viewed using the .keys() method.\n",
    "print(\"The information stored in the tree is:\", tree.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we'd like to see the energies of the photons. \n",
    "We can access this from our tree using the key `photon_e`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = [\"photon_pt\", \"photon_eta\", \"photon_phi\", \"photon_E\",\n",
    "                                  \"photon_isTightID\", \"photon_etcone20\"]\n",
    "fraction = 1 #lower to deload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi,photon_E):\n",
    "    # first photon is [0], 2nd photon is [1] etc\n",
    "    px_0 = photon_pt[0]*math.cos(photon_phi[0]) # x-component of photon[0] momentum\n",
    "    py_0 = photon_pt[0]*math.sin(photon_phi[0]) # y-component of photon[0] momentum\n",
    "    pz_0 = photon_pt[0]*math.sinh(photon_eta[0]) # z-component of photon[0] momentum\n",
    "    px_1 = photon_pt[1]*math.cos(photon_phi[1]) # x-component of photon[1] momentum\n",
    "    py_1 = photon_pt[1]*math.sin(photon_phi[1]) # y-component of photon[1] momentum\n",
    "    pz_1 = photon_pt[1]*math.sinh(photon_eta[1]) # z-component of photon[1] momentum\n",
    "    sumpx = px_0 + px_1 # x-component of diphoton momentum\n",
    "    sumpy = py_0 + py_1 # y-component of diphoton momentum\n",
    "    sumpz = pz_0 + pz_1 # z-component of diphoton momentum \n",
    "    sump = math.sqrt(sumpx**2 + sumpy**2 + sumpz**2) # magnitude of diphoton momentum \n",
    "    sumE = photon_E[0] + photon_E[1] # energy of diphoton system\n",
    "    m2 = sumE**2 - sump**2\n",
    "    if m2>0.:\n",
    "        m = m2**0.5\n",
    "    else:\n",
    "        print('calc_myy error neg mass**2', m2)\n",
    "        m = 0.\n",
    "    return m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis, this entry should be removed because the photons do not match all our requirements.\n",
    "We can turn these checks and calculations into a set of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "    return photon_isTightID[0]==True and photon_isTightID[1]==True\n",
    "\n",
    "def cut_photon_pt(photon_pt):\n",
    "    return photon_pt[0]>40000 and photon_pt[1]>30000\n",
    "\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "    return (abs(photon_eta[0])>1.52 or abs(photon_eta[0])<1.37) and (abs(photon_eta[1])>1.52 or abs(photon_eta[1])<1.37)\n",
    "\n",
    "def cut_n_photon(photon_n):\n",
    "    return photon_n>=2\n",
    "\n",
    "def cut_isolation_et(photon_etcone20):\n",
    "    # Keep only the events where first two photons have isolation pt < 4 GeV\n",
    "    return (photon_etcone20[0] < 4000) and (photon_etcone20[1] < 4000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may verify on your own that these functions give the same outputs as the previous code block.\n",
    "Now, \n",
    "    we shall apply these functions over the entire data tree using a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "    frames = []  # define empty list to hold data\n",
    "    for val in samples_list:  # loop over each file\n",
    "        fileString = tuple_path + val + \".GamGam.root\"  # file name to open\n",
    "        temp = read_file(fileString)  # call the function read_file defined earlier\n",
    "        frames.append(temp)  # append DataFrame returned from read_file to list of DataFrames\n",
    "\n",
    "    # Concatenate list of pandas DataFrames\n",
    "    data = pd.concat(frames, ignore_index=True)  \n",
    "    \n",
    "    return data  # return concatenated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    start = time.time()\n",
    "    print(\"Processing: \" + path)\n",
    "    data_all = pd.DataFrame()\n",
    "    tree = uproot.open(path + \":mini\")\n",
    "    numevents = tree.num_entries\n",
    "    \n",
    "    total_events = 0\n",
    "    cutflow = {\n",
    "        'initial': 0,\n",
    "        'tight_id': 0,\n",
    "        'pt_cut': 0,\n",
    "        'isolation': 0,\n",
    "        'eta_cut': 0\n",
    "    }\n",
    "\n",
    "    for data in tree.iterate([\"photon_pt\", \"photon_eta\", \"photon_phi\", \"photon_E\",\n",
    "                              \"photon_isTightID\", \"photon_etcone20\"],\n",
    "                             library=\"pd\",\n",
    "                             entry_stop=numevents*fraction):\n",
    "        nIn = len(data.index)\n",
    "        total_events += nIn\n",
    "        cutflow['initial'] += nIn\n",
    "\n",
    "        print(\"before cut\", len(data.index))\n",
    "        data = data[np.vectorize(cut_photon_reconstruction)(data.photon_isTightID)]\n",
    "        cutflow['tight_id'] += len(data.index)\n",
    "        print(\"istight-cut\", len(data.index))\n",
    "\n",
    "        data = data[np.vectorize(cut_photon_pt)(data.photon_pt)]\n",
    "        cutflow['pt_cut'] += len(data.index)\n",
    "        print(\"pt-cut\", len(data.index))\n",
    "\n",
    "        data = data[np.vectorize(cut_isolation_et)(data.photon_etcone20)]\n",
    "        cutflow['isolation'] += len(data.index)\n",
    "        print(\"iso-cut\", len(data.index))\n",
    "\n",
    "        data = data[np.vectorize(cut_photon_eta_transition)(data.photon_eta)]\n",
    "        cutflow['eta_cut'] += len(data.index)\n",
    "        print(\"eta-cut\", len(data.index))\n",
    "\n",
    "        data['myy'] = np.vectorize(calc_myy)(data.photon_pt, data.photon_eta, data.photon_phi, data.photon_E)\n",
    "\n",
    "        nOut = len(data.index)\n",
    "        data_all = pd.concat([data_all, data], ignore_index=True)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"\\t nIn: {nIn},\\t nOut: \\t{nOut}\\t in {round(elapsed,1)}s\")\n",
    "\n",
    "    print(\"\\nCutflow Summary:\")\n",
    "    print(f\"{'Cut':<20}{'Events':<10}{'Percentage':<10}\")\n",
    "    print(\"-\" * 40)\n",
    "    for cut, count in cutflow.items():\n",
    "        percentage = (count / total_events) * 100\n",
    "        print(f\"{cut:<20}{count:<10}{percentage:.2f}%\")\n",
    "\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/data_A.GamGam.root\n",
      "before cut 430344\n",
      "istight-cut 54379\n",
      "pt-cut 34625\n",
      "iso-cut 22381\n",
      "eta-cut 22350\n",
      "\t nIn: 430344,\t nOut: \t22350\t in 3.9s\n",
      "\n",
      "Cutflow Summary:\n",
      "Cut                 Events    Percentage\n",
      "----------------------------------------\n",
      "initial             430344    100.00%\n",
      "tight_id            54379     12.64%\n",
      "pt_cut              34625     8.05%\n",
      "isolation           22381     5.20%\n",
      "eta_cut             22350     5.19%\n",
      "Processing: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/data_B.GamGam.root\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# time at start of whole processing\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# process all files\u001b[39;00m\n\u001b[1;32m      3\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start \u001b[38;5;66;03m# time after whole processing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(elapsed,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# print total time taken to process every file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[102], line 5\u001b[0m, in \u001b[0;36mget_data_from_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m samples_list:  \u001b[38;5;66;03m# loop over each file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     fileString \u001b[38;5;241m=\u001b[39m tuple_path \u001b[38;5;241m+\u001b[39m val \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.GamGam.root\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# file name to open\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileString\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# call the function read_file defined earlier\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(temp)  \u001b[38;5;66;03m# append DataFrame returned from read_file to list of DataFrames\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Concatenate list of pandas DataFrames\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[129], line 17\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m total_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m cutflow \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_cut\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m }\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39miterate([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_eta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_phi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_E\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_isTightID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphoton_etcone20\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m                          library\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m                          entry_stop\u001b[38;5;241m=\u001b[39mnumevents\u001b[38;5;241m*\u001b[39mfraction):\n\u001b[1;32m     21\u001b[0m     nIn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     22\u001b[0m     total_events \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nIn\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/uproot/behaviors/TBranch.py:1066\u001b[0m, in \u001b[0;36mHasBranches.iterate\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, step_size, decompression_executor, interpretation_executor, library, ak_add_doc, how, report)\u001b[0m\n\u001b[1;32m   1064\u001b[0m arrays \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1065\u001b[0m interp_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mak_add_doc\u001b[39m\u001b[38;5;124m\"\u001b[39m: ak_add_doc}\n\u001b[0;32m-> 1066\u001b[0m \u001b[43m_ranges_or_baskets_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges_or_baskets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbranchid_interpretation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_entry_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_entry_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m _fix_asgrouped(\n\u001b[1;32m   1081\u001b[0m     arrays,\n\u001b[1;32m   1082\u001b[0m     expression_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     ak_add_doc,\n\u001b[1;32m   1087\u001b[0m )\n\u001b[1;32m   1089\u001b[0m output \u001b[38;5;241m=\u001b[39m language\u001b[38;5;241m.\u001b[39mcompute_expressions(\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1091\u001b[0m     arrays,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_path,\n\u001b[1;32m   1097\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/uproot/behaviors/TBranch.py:3105\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets, interp_options)\u001b[0m\n\u001b[1;32m   3102\u001b[0m     decompression_executor\u001b[38;5;241m.\u001b[39msubmit(chunk_to_basket, obj, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, uproot\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mTBasket\u001b[38;5;241m.\u001b[39mModel_TBasket):\n\u001b[0;32m-> 3105\u001b[0m     \u001b[43minterpretation_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasket_to_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3108\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/uproot/source/futures.py:104\u001b[0m, in \u001b[0;36mTrivialExecutor.submit\u001b[0;34m(self, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, task, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Immediately runs ``task(*args)``.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TrivialFuture(\u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/uproot/behaviors/TBranch.py:3080\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays.<locals>.basket_to_array\u001b[0;34m(basket)\u001b[0m\n\u001b[1;32m   3077\u001b[0m basket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(basket_arrays) \u001b[38;5;241m==\u001b[39m branchid_num_baskets[branch\u001b[38;5;241m.\u001b[39mcache_key]:\n\u001b[0;32m-> 3080\u001b[0m     arrays[branch\u001b[38;5;241m.\u001b[39mcache_key] \u001b[38;5;241m=\u001b[39m \u001b[43minterpretation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbasket_arrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentry_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentry_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbranch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbranch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3089\u001b[0m     \u001b[38;5;66;03m# no longer needed, save memory\u001b[39;00m\n\u001b[1;32m   3090\u001b[0m     basket_arrays\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/uproot/interpretation/jagged.py:317\u001b[0m, in \u001b[0;36mAsJagged.final_array\u001b[0;34m(self, basket_arrays, entry_start, entry_stop, entry_offsets, library, branch, options)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m contents:\n\u001b[1;32m    316\u001b[0m     content[before : before \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(cnt)] \u001b[38;5;241m=\u001b[39m cnt\n\u001b[0;32m--> 317\u001b[0m     before \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cnt)\n\u001b[1;32m    319\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\u001b[38;5;241m.\u001b[39m_wrap_almost_finalized(content)\n\u001b[1;32m    321\u001b[0m output \u001b[38;5;241m=\u001b[39m JaggedArray(offsets, content)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit our data to effectively detect the Higgs boson! We will use a combination of a 4th order polynomial and a Gaussian function. The polynomial function represents the background, while the Gaussian function represents our signal. The Gaussian model is used to fit the signal due to the nature of the detector's resolution. The fourth-order polynomial is chosen for the background because it offers enough flexibility to capture the overall shape without overfitting, thereby reducing the influence of spurious data—random, irrelevant fluctuations or noise that do not correspond to the true signal or background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['myy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "\n",
    "\n",
    "data_x,_ = np.histogram(ak.to_numpy(data['myy']), \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "# data fit\n",
    "polynomial_mod = PolynomialModel( 4 ) # 4th order polynomial\n",
    "gaussian_mod = GaussianModel() # Gaussian\n",
    "\n",
    "# set initial guesses for the parameters of the polynomial model\n",
    "# c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "pars = polynomial_mod.guess(data_x, # data to use to guess parameter values\n",
    "                            x=bin_centres, c0=data_x.max(), c1=0,\n",
    "                            c2=0, c3=0, c4=0 )\n",
    "\n",
    "# set initial guesses for the parameters of the Gaussian model\n",
    "pars += gaussian_mod.guess(data_x, # data to use to guess parameter values\n",
    "                        x=bin_centres, amplitude=100, \n",
    "                        center=125, sigma=2 )\n",
    "\n",
    "model = polynomial_mod + gaussian_mod # combined model\n",
    "\n",
    "# fit the model to the data\n",
    "out = model.fit(data_x, # data to be fit\n",
    "                pars, # guesses for the parameters\n",
    "                x=bin_centres, weights=1/data_x_errors ) #ASK\n",
    "\n",
    "# background part of fit\n",
    "params_dict = out.params.valuesdict() # get the parameters from the fit to data\n",
    "c0 = params_dict['c0'] # c0 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "c1 = params_dict['c1'] # c1 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "c2 = params_dict['c2'] # c2 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "c3 = params_dict['c3'] # c3 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "c4 = params_dict['c4'] # c4 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "\n",
    "# get the background only part of the fit to data\n",
    "background = c0 + c1*bin_centres + c2*bin_centres**2 + c3*bin_centres**3 + c4*bin_centres**4\n",
    "\n",
    "# data fit - background fit = signal fit\n",
    "signal_x = data_x - background \n",
    "\n",
    "# *************\n",
    "# Main plot \n",
    "# *************\n",
    "plt.axes([0.1,0.3,0.85,0.65]) # left, bottom, width, height \n",
    "main_axes = plt.gca() # get current axes\n",
    "\n",
    "# plot the data points\n",
    "main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors, \n",
    "                fmt='ko', # 'k' means black and 'o' means circles\n",
    "                label='Data' ) \n",
    "\n",
    "# plot the signal + background fit\n",
    "main_axes.plot(bin_centres, # x\n",
    "            out.best_fit, # y\n",
    "            '-r', # single red line\n",
    "            label='Sig+Bkg Fit ($m_H=125$ GeV)' )\n",
    "\n",
    "# plot the background only fit\n",
    "main_axes.plot(bin_centres, # x\n",
    "            background, # y\n",
    "            '--r', # dashed red line\n",
    "            label='Bkg (4th order polynomial)' )\n",
    "\n",
    "# set the x-limit of the main axes\n",
    "main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "\n",
    "# separation of x-axis minor ticks\n",
    "main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "# set the axis tick parameters for the main axes\n",
    "main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                    direction='in', # Put ticks inside and outside the axes\n",
    "                    top=True, # draw ticks on the top axis\n",
    "                    labelbottom=False, # don't draw tick labels on bottom axis\n",
    "                    right=True ) # draw ticks on right axis\n",
    "\n",
    "# write y-axis label for main \n",
    "main_axes.set_ylabel('Events / '+str(step_size)+' GeV', \n",
    "                    horizontalalignment='right') \n",
    "\n",
    "# set the y-axis limit for the main axes\n",
    "main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.1 ) \n",
    "\n",
    "# set minor ticks on the y-axis of the main axes\n",
    "main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "# avoid displaying y=0 on the main axes\n",
    "main_axes.yaxis.get_major_ticks()[0].set_visible(False) \n",
    "\n",
    "# Add text 'ATLAS Open Data' on plot\n",
    "plt.text(0.2, # x\n",
    "        0.92, # y\n",
    "        'ATLAS Open Data', # text\n",
    "        transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "        fontsize=13 ) \n",
    "\n",
    "# Add text 'for education' on plot\n",
    "plt.text(0.2, # x\n",
    "        0.86, # y\n",
    "        'for education', # text\n",
    "        transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "        style='italic',\n",
    "        fontsize=8 ) \n",
    "\n",
    "lumi = 36.1\n",
    "lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "plt.text(0.2, # x\n",
    "        0.8, # y\n",
    "        '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "        transform=main_axes.transAxes ) # coordinate system used is that of main_axes \n",
    "\n",
    "# Add a label for the analysis carried out\n",
    "plt.text(0.2, # x\n",
    "        0.74, # y\n",
    "        r'$H \\rightarrow \\gamma\\gamma$', # text \n",
    "        transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "# draw the legend\n",
    "main_axes.legend(frameon=False, # no box around the legend\n",
    "                loc='lower left' ) # legend location \n",
    "\n",
    "\n",
    "# *************\n",
    "# Data-Bkg plot \n",
    "# *************\n",
    "plt.axes([0.1,0.1,0.85,0.2]) # left, bottom, width, height\n",
    "sub_axes = plt.gca() # get the current axes\n",
    "\n",
    "# set the y axis to be symmetric about Data-Background=0\n",
    "sub_axes.yaxis.set_major_locator( MaxNLocator(nbins='auto', \n",
    "                                            symmetric=True) )\n",
    "\n",
    "# plot Data-Background\n",
    "sub_axes.errorbar(x=bin_centres, y=signal_x, yerr=data_x_errors,\n",
    "                fmt='ko' ) # 'k' means black and 'o' means circles\n",
    "\n",
    "# draw the fit to data\n",
    "sub_axes.plot(bin_centres, # x\n",
    "            out.best_fit-background, # y\n",
    "            '-r' ) # single red line\n",
    "\n",
    "# draw the background only fit\n",
    "sub_axes.plot(bin_centres, # x\n",
    "            background-background, # y\n",
    "            '--r' )  # dashed red line\n",
    "\n",
    "# set the x-axis limits on the sub axes\n",
    "sub_axes.set_xlim( left=xmin, right=xmax ) \n",
    "\n",
    "# separation of x-axis minor ticks\n",
    "sub_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "# x-axis label\n",
    "sub_axes.set_xlabel(r'di-photon invariant mass $\\mathrm{m_{\\gamma\\gamma}}$ [GeV]',\n",
    "                    x=1, horizontalalignment='right', \n",
    "                    fontsize=13 ) \n",
    "\n",
    "# set the tick parameters for the sub axes\n",
    "sub_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                    direction='in', # Put ticks inside and outside the axes\n",
    "                    top=True, # draw ticks on the top axis\n",
    "                    right=True ) # draw ticks on right axis \n",
    "\n",
    "# separation of y-axis minor ticks\n",
    "sub_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "# y-axis label on the sub axes\n",
    "sub_axes.set_ylabel( 'Events-Bkg' ) \n",
    "\n",
    "\n",
    "# Generic features for both plots\n",
    "main_axes.yaxis.set_label_coords( -0.09, 1 ) # x,y coordinates of the y-axis label on the main axes\n",
    "sub_axes.yaxis.set_label_coords( -0.09, 0.5 ) # x,y coordinates of the y-axis label on the sub axes make it pandas eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is—a clear peak in the invariant mass spectrum around 125 GeV, signaling the presence of the Higgs boson! While our main task may be done, there's still more to explore. Here are some additional tasks you can try with this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check how many events are being thrown away by each cut in '[Applying a cut](#applying_cut)'\n",
    "* Add more cuts from the [Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#se0090) in '[Changing a cut](#changing_cut)' and '[Applying a cut](#applying_cut)'\n",
    "* Find the reduced chi-squared for the fit in '[Plotting](#plotting)'\n",
    "* Find the mean of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Find the width of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Try different initial guesses for the parameters of the fit in '[Plotting](#plotting)'\n",
    "* Try different functions for the fit in '[Plotting](#plotting)'\n",
    "* Your idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
