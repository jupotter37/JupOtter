{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eIfdgZzdwdti",
        "X5TyPFgPMa4a",
        "LD43kL3tSgz-",
        "JPt--IfXguTz",
        "9PTGrszCgwbu",
        "KEylV2nQmdq4",
        "wdCWyOxzNGVr",
        "OYi_INqrVMJB",
        "gpF6r3N0XWo5",
        "CPHH1oHGYvw6",
        "6igcvAQscIA5",
        "dW0qSf99gezo",
        "OrMsAClJiF3G",
        "wJY9o2XF-WIb",
        "Nuc4r-tpO4o6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Course:** Machine Learning by Dr. Seyyed Salehi\n",
        "\n",
        "**Homework:** HW1\n",
        "\n",
        "**Name:** Mohammad Mohammadi\n",
        "\n",
        "**Student ID:** 402208592"
      ],
      "metadata": {
        "id": "9JbKLJNkfqlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 - Linear Regression\n",
        "We have a linear regression model with p parameters. with least squares method, we train the model with training data of (x1, y1), ..., (xN, yN) which are randomly chosen from the population. Now imagine B^ is the estimation of least squares. Imagine we have a series of test data (x ̄1 , y ̄1 ), ..., (x ̄N , y ̄ N) which are chosen randomly from the same population.\n",
        "Now, with having :\n",
        "\n",
        "$R_{te}(\\beta) = \\frac{1}{M} \\sum_{i=1}^{M} (y_i - \\beta^T x_i)^2, \\quad R_{tr}(\\beta) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\beta^T x_i)^2$\n",
        "\n",
        "show that we have :\n",
        "\n",
        "$E[R_{tr}(\\hat{\\beta})] \\leq E[R_{te}(\\hat{\\beta})]$"
      ],
      "metadata": {
        "id": "eIfdgZzdwdti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer 1\n",
        "\n",
        "*   $R_{tr}(\\beta)$ is our training risk. It's equation is calculated upon training datapoints (xi, yi).\n",
        "*   Respectively, $R_{te}(\\beta)$ is our testing risk. It's equation is calculated upon test datapoints (xˉi, yˉi).\n",
        "\n",
        "Now using these definitions we have:\n",
        "*   By definition, β̂ is obtained by minimizing $R_{tr}(\\beta)$ over the training data. Hence, for any β, including the true parameter vector, we have $R_{tr}(\\hat\\beta) \\leq R_{tr}(\\beta)$.\n",
        "*   Since β̂ is fitted to minimize $R_{tr}(\\beta)$ on the training data, the expected training risk $E[R_{tr}(\\hat\\beta)]$ is biased downwards because it does not account for the model's generalization to new, unseen data. In contrast, $E[R_{te}(\\hat\\beta)]$ measures the expected risk over new samples from the population.\n",
        "*   The test data are not used to fit β̂, so $E[R_{te}(\\hat\\beta)]$ includes the model's error across a broader set of samples from the same population. Because the test samples are independent of the training process and are chosen randomly, the overlap is expected to be inadequate, therefore, the expectation $E[R_{te}(\\hat\\beta)]$ provides an unbiased estimate of the model's performance on new data.\n",
        "*   The process of fitting β̂ to the training data can lead to overfitting, especially if p (the number of parameters) is large relative to N (the number of training samples). Overfitting results in low training error but potentially high testing error due to the model capturing noise in the training data as if it were signal.\n",
        "*   The inequality $E[R_{tr}(\\hat{\\beta})] \\leq E[R_{te}(\\hat{\\beta})]$ reflects the concept that, on average, a model's performance on the data it was trained on (training data) is at least as good as, if not better than, its performance on new, unseen data (test data). This is because the training process optimizes performance on the training set, potentially at the expense of generalizability to new data.\n",
        "\n",
        "In conclusion of the facts above, the expected training error $E[R_{tr}(\\hat\\beta)]$ is typically lower than the expected test error $E[R_{te}(\\hat\\beta)]$ because the model parameters β̂ are optimized for the training data, which can lead to overfitting and a lack of generalizability to unseen data. The expected test error provides a more unbiased estimate of the model's performance on new data from the same population, which is obvious based on the facts mentioned."
      ],
      "metadata": {
        "id": "X5TyPFgPMa4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 - Linear Regression\n",
        "\n",
        "In Lasso Regression, optimal weight vector is:\n",
        "\n",
        "$\\omega^* = \\arg\\min_{\\omega} J_{\\lambda}(\\omega)$\n",
        "\n",
        "where:\n",
        "\n",
        "$J_{\\lambda} =1/2 \\left\\| y - X\\omega \\right\\|_2^2 + \\lambda \\left\\| \\omega \\right\\|_1$\n",
        "\n",
        "and we have:\n",
        "\n",
        "$X \\in \\mathbb{R}^{n \\times d}$\n",
        "\n",
        "and we have done whitening on data.  ($XX^T = I$)\n",
        "\n",
        "(a) Show that whitening on data causes the features to become independent in a way that $\\omega_{i}^*$ is derived solely from the ith feature. To Prove this, first start by showing that J can be written az below:\n",
        "\n",
        "$J_{\\lambda}(\\omega) = g(y) + \\sum_{i=1}^{d} f(X_{:,i}; y_i; \\omega_i; \\lambda)$\n",
        "\n",
        "Where $X_{:,i}$ is the ith column of the matrix X.\n",
        "\n",
        "(b) If $\\omega_i \\geq 0$, then find $\\omega_i$.\n",
        "\n",
        "(c) If $\\omega_i < 0$, then find $\\omega_i$.\n",
        "\n",
        "(d) With respect to the last parts, under what circumstances $ω_i$ becomes zero? How can we apply these circumstances?\n",
        "\n",
        "(e) As you know, in regression ridge, normalization expression in cost function appears as $1λ/2||ω||_2^2$. In this case when does the $ω_i$ become zero? What's the difference between this and previous one?\n"
      ],
      "metadata": {
        "id": "LD43kL3tSgz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer 2\n",
        "\n"
      ],
      "metadata": {
        "id": "-ILP5fUkW8GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "By definition, whitening the data such that $XX^T = I$ ensures that the features are orthogonal and normalized. This implies that the covariance matrix of the features X is the identity matrix, meaning all features are independent of each other and have equal variance.\n",
        "\n",
        "**Decomposing $J_{\\lambda}(\\omega)$:**\n",
        "We want to show that if the data is whitened, we can rewrite $J_{\\lambda}(\\omega) = \\frac{1}{2} \\| y - X\\omega \\|_2^2 + \\lambda \\| \\omega \\|_1$\n",
        "\n",
        "as\n",
        "\n",
        "$J_{\\lambda}(\\omega) = g(y) + \\sum_{i=1}^{d} \\left( \\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda |\\omega_i| \\right)$.\n",
        "\n",
        "In order to do so, let's start by simplifying the main equation, part by part:\n",
        "\n",
        "1.  **Squared Error Term:**\n",
        "\n",
        "Let's first focus on the squared error term $\\| y - X\\omega \\|_2^2$. Under the condition $XX^T = I$, we can expand this term as:\n",
        "\n",
        "$(y - X\\omega)^T(y - X\\omega) = y^Ty - 2\\omega^TX^Ty + \\omega^TX^TX\\omega$\n",
        "\n",
        "Given that $XX^T = I$, it implies $X^TX = I$ for whitened data, simplifying to:\n",
        "\n",
        "$y^Ty - 2\\omega^TX^Ty + \\omega^T\\omega$\n",
        "\n",
        "The term $y^Ty$ is constant with respect to ω and can be considered as part of $g(y)$. The last term can be decomposed into individual contributions from each $\\omega_i$ since $X^TX = I$ ensures independence among features.\n",
        "\n",
        "2.  **Regularization Term:**\n",
        "\n",
        "The regularization term $\\lambda \\| \\omega \\|_1$ naturally decomposes into a sum over the individual components of ω, as $\\| \\omega \\|_1$ is the sum of the absolute values of the components of ω.\n",
        "\n",
        "Therefore, combining these insights, $J_{\\lambda}(\\omega)$ can be decomposed into:\n",
        "\n",
        "$J_{\\lambda}(\\omega) = g(y) + \\sum_{i=1}^{d} \\left( \\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda |\\omega_i| \\right)$\n",
        "\n",
        "Where $g(y) = \\frac{1}{2}y^Ty$ is a function solely of y, and each term in the sum $\\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda |\\omega_i|$ corresponds to $f(X_{:,i}; y_i; \\omega_i; \\lambda)$, which depends only on the ith feature $X_{:,i}$, its corresponding weight $ω_i$ , and λ.\n",
        "\n",
        "This decomposition shows that due to the whitening process, the optimization problem for finding $ω^*$ in Lasso Regression becomes separable by features. Each weight $ω^*$ can be optimized independently based on its corresponding feature $X_{:,i}$ and the target y, reflecting the fact that whitening has rendered the features independent in the context of this optimization problem."
      ],
      "metadata": {
        "id": "JPt--IfXguTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b\n",
        "\n",
        "To find $\\omega_i$ given $\\omega_i \\geq 0$, we start from the simplified objective function of Lasso Regression for a single weight $\\omega_i$, considering the data has been whitened and features have become independent. The objective function for the ith feature can be expressed as:\n",
        "\n",
        "$f(ω_i) = \\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda |\\omega_i|$\n",
        "\n",
        "Given $\\omega_i \\geq 0$, the regularization term simplifies to $\\lambda \\omega_i$, and we aim to find the $\\omega_i$ that minimizes this function.\n",
        "\n",
        "First, we compute the derivative of $f(ω_i)$ with respect to $ω_i$:\n",
        "\n",
        "$\\frac{df(\\omega_i)}{d\\omega_i} = -X_{:,i}^T(y - X_{:,i}\\omega_i) + \\lambda$\n",
        "\n",
        "Obviously, to find the minimum of $f(ω_i)$, we set its derivative equal to zero:\n",
        "\n",
        "$-X_{:,i}^T(y - X_{:,i}\\omega_i) + \\lambda = 0$\n",
        "\n",
        "Reordering the equation we have:\n",
        "\n",
        "$\\omega_i(X_{:,i}^TX_{:,i})= X_{:,i}^Ty - \\lambda$\n",
        "\n",
        "Due to the whitening process (which means each feature vector $X_{:,i}$ is normalized), we have $X_{:,i}^TX_{:,i} = 1$, hence we can simplify the equation to:\n",
        "\n",
        "$\\omega_i = X_{:,i}^Ty - \\lambda$\n",
        "\n",
        "Now we should consider the condition $ω_i \\geq 0$, this leads us to the soft-thresholding operation used in Lasso, where $\\omega_i$ is set to zero if applying the threshold would result in a negative value. The correct formula, taking into account the positivity constraint and the soft-thresholding operation, would be:\n",
        "\n",
        "$\\omega_i = \\max\\left(0, X_{:,i}^Ty - \\lambda\\right)$\n",
        "\n",
        "This equation directly solves for $\\omega_i$ under the condition that $ω_i \\geq 0$, incorporating both the derivative of the objective function to finding the minimum of the objective function and the soft-thresholding operation required by the Lasso regularization term.\n"
      ],
      "metadata": {
        "id": "9PTGrszCgwbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part c\n",
        "\n",
        "To find $\\omega_i$ given $\\omega_i < 0$, we need to revisit the Lasso Regression objective function with the regularization term reflecting this condition. Given the objective function for a single feature after whitening, we have:\n",
        "\n",
        "$f(ω_i) = \\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda |\\omega_i|$\n",
        "\n",
        "Given $\\omega_i < 0$, the absolute value in the regularization term becomes $- \\omega_i$, (since $|ω_i| = -ω_i$ when $ω_i < 0$).  Thus, the objective function becomes:\n",
        "\n",
        "\n",
        "$f(ω_i) = \\frac{1}{2}(y - X_{:,i}\\omega_i)^2 + \\lambda (-\\omega_i)$\n",
        "\n",
        "First, we compute the derivative of $f(ω_i)$ with respect to $ω_i$ and including the negative sign from the regularization term, we get::\n",
        "\n",
        "$\\frac{df(\\omega_i)}{d\\omega_i} = -X_{:,i}^T(y - X_{:,i}\\omega_i) - \\lambda$\n",
        "\n",
        "Obviously, to find the minimum of $f(ω_i)$, we set its derivative equal to zero:\n",
        "\n",
        "$-X_{:,i}^T(y - X_{:,i}\\omega_i) - \\lambda = 0$\n",
        "\n",
        "Reordering the equation we have:\n",
        "\n",
        "$\\omega_i(X_{:,i}^TX_{:,i})= X_{:,i}^Ty + \\lambda$\n",
        "\n",
        "Due to the whitening process (which means each feature vector $X_{:,i}$ is normalized), we have $X_{:,i}^TX_{:,i} = 1$, hence we can simplify the equation to:\n",
        "\n",
        "$\\omega_i = X_{:,i}^Ty + \\lambda$\n",
        "\n",
        "Now we should consider the condition $ω_i < 0$, we need to apply a condition similar to soft-thresholding but for negative $\\omega_i$. The correct formula, taking into account the negativity constraint and the soft-thresholding operation, would be:\n",
        "\n",
        "$\\omega_i = \\min\\left(0, X_{:,i}^Ty + \\lambda\\right)$\n",
        "\n",
        "This equation directly solves for $\\omega_i$ under the condition that $ω_i < 0$, applying the principle of soft-thresholding to ensure that the solution adheres to the $ω_i< 0$ condition by adjusting for the negative regularization term.\n"
      ],
      "metadata": {
        "id": "KEylV2nQmdq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part d\n",
        "\n",
        "In the context of Lasso Regression, the weight $ω_i$ becomes zero under circumstances that are directly tied to the strength of the regularization parameter λ and the correlation between the ith feature $X_{:,i}$ and the target variable y. The Lasso method encourages sparsity in the model weights, which means it drives some weights to exactly zero, effectively selecting a subset of the most important features.\n",
        "\n",
        "From the discussions on finding $ω_i$ for $ω_i \\geq 0$ and $ω_i < 0$, we derived that:\n",
        "\n",
        "*   For $ω_i \\geq 0$,  $\\omega_i = \\max\\left(0, X_{:,i}^Ty - \\lambda\\right)$\n",
        "*   For $ω_i < 0$, $\\omega_i = \\min\\left(0, X_{:,i}^Ty + \\lambda\\right)$\n",
        "\n",
        "**Circumstances under Which $\\omega_i$ Becomes Zero**:\n",
        "\n",
        "$\\omega_i$ becomes zero if the adjustment for the regularization (either adding or subtracting λ) brings the term within the soft-thresholding operation to a value that does not support maintaining a positive or negative weight. Specifically:\n",
        "\n",
        "*   If the correlation between $X_{:,i}$ and y (measured as $X_{:,i}^Ty$) is less than λ, and we are considering the case for $ω_i \\geq 0$, then $ω_i$ will be set to zero because the term $X_{:,i}^Ty - λ$ will be non-positive.\n",
        "*   Similarly, if the absolute value of the correlation is less than λ when considering $ω_i < 0$, then $ω_i$ will also be zero because $X_{:,i}^Ty + λ$  will be non-negative, but we're looking at cases where it would need to be negative to maintain a non-zero weight.\n",
        "\n",
        "**Applying These Circumstances**:\n",
        "\n",
        "To apply these circumstances in Lasso Regression for feature selection or regularization:\n",
        "\n",
        "1.  **Choose an Appropriate λ:** The choice of λ is crucial as it dictates the level of sparsity in the model. A larger λ encourages more weights to be set to zero, simplifying the model but potentially underfitting the data. Cross-validation is commonly used to select an optimal λ that balances model complexity and fit.\n",
        "2.  **Calculate Correlation:** For each feature $X_{:,i}$, we calculate its correlation with the target variable y (i.e., $X_{:,i}^Ty$). This step is part of fitting the Lasso model.\n",
        "3.  **Apply Soft-Thresholding:** For each feature, we apply the soft-thresholding rule as discussed. This involves comparing the absolute value of the correlation $|X_{:,i}^Ty|$ to λ and setting $ω_i$ to zero if it falls below the threshold.\n",
        "\n",
        "By following these steps, Lasso Regression automatically performs feature selection by removing features whose correlation with the target variable is not strong enough to overcome the penalty imposed by the regularization term λ. This property makes Lasso an attractive option for both regularization and feature selection in linear models."
      ],
      "metadata": {
        "id": "wdCWyOxzNGVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part e\n",
        "\n",
        "In Ridge Regression, the regularization term in the cost function is given by $1λ/2||ω||_2^2$, where $||ω||_2^2$ is the squared L2 norm of the weight vector ω, and λ is the regularization parameter. This term penalizes large weights by adding to the cost function a value that increases with the square of the magnitude of the weights. The key difference from Lasso Regression, which uses an L1 penalty $λ||ω||_1$, is in how these regularization terms influence the weights.\n",
        "\n",
        "**When does $ω_i$ become zero in Ridge Regression?**\n",
        "\n",
        "In Ridge Regression, $ω_i$ does not become exactly zero due to the nature of the L2 penalty. The L2 norm penalizes the square of the weights, and as such, while it encourages the weights to be small to minimize the overall cost function, it does not set them to zero. The gradient descent steps used to minimize the cost function in Ridge Regression will decrease the magnitude of the weights, but the continuous nature of the L2 penalty means there's no specific threshold at which the weight directly goes to zero as there is with the L1 penalty in Lasso Regression.\n",
        "\n",
        "**Difference between Ridge and Lasso Regression regarding $ω_i$**\n",
        "\n",
        "*   **Sparsity:** Lasso Regression can produce sparse models, where some weights are exactly zero. This property makes Lasso useful for feature selection, as it can completely remove some features from the model. Ridge Regression, on the other hand, tends to shrink the weights evenly but does not set them to zero. All features remain part of the model, but their influence is moderated.\n",
        "*   **Penalty and Regularization Effect:** The L1 penalty in Lasso Regression makes the cost function non-differentiable at $ω_i = 0$, which leads to sparsity. The L2 penalty in Ridge Regression is differentiable everywhere, and its effect is to ensure that the weights do not grow too large, protecting against overfitting by distributing the penalty across all weights more uniformly.\n",
        "*   **Usage:** Lasso Regression is preferred when we suspect that many features are irrelevant or when we want a model that is simple and interpretable due to having only a subset of all the possible predictors. Ridge Regression is preferred when we believe most features have a similar influence on the output or when we have multicollinearity among the features, as the L2 penalty helps handle multicollinearity better by distributing weights across correlated features."
      ],
      "metadata": {
        "id": "OYi_INqrVMJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refs\n",
        "\n",
        "1.  **Linear Regression, Lasso (L1 regularization), and Ridge (L2 regularization):**\n",
        "\n",
        "    *   Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman. (Contents on web refferenced to this book)\n",
        "    *   An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. (Contents on web refferenced to this book)\n",
        "    *   https://www.mygreatlearning.com/blog/understanding-of-lasso-regression/\n",
        "    *   https://builtin.com/data-science/l2-regularization\n",
        "\n",
        "2.  **Optimization and Regularization Techniques:**\n",
        "\n",
        "    *   Convex Optimization by Stephen Boyd and Lieven Vandenberghe. (Contents on web refferenced to this book)\n",
        "\n",
        "3.  **Machine Learning and Data Science Blogs:**\n",
        "\n",
        "    *   Towards Data Science on Medium: Some articles in the serie on Lasso and Ridge regression.\n",
        "    *   Distill.pub"
      ],
      "metadata": {
        "id": "gpF6r3N0XWo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 - Linear Classification\n",
        "\n",
        "The update rule for Perceptron weight vector is:\n",
        "\n",
        "$$\\text{if } x^{(t)} \\text{ is misclassified then: } \\omega^{(t+1)} = \\omega^{(t)} + \\eta x^{(t)} y^{(t)}$$\n",
        "\n",
        "\n",
        "(a) Show that in Perceptron Classifier, weight vector $ω$ can be writen as a linear combination of data $x^{(i)}$. Also find the coefficients $a_i$ in the linear combination $\\omega = \\sum_{i=1}^{N} \\alpha_i x^{(i)}$.\n",
        "\n",
        "(b) In what case is the mentioned rule for updating weight vector $ω$ equal to the rule below for updating $a_i$:\n",
        "\n",
        "$$\\text{if } \\sum_{i=1}^{N} \\alpha y^{(i)} y^{(j)} x^{(j)T} < 0 \\text{ then } \\alpha_i = \\alpha_i + 1$$"
      ],
      "metadata": {
        "id": "CPHH1oHGYvw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "JPHFTVm9cGhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "\n",
        "To demonstrate that the weight vector ω in a Perceptron Classifier can be written as a linear combination of the data $x^{(i)}$, and to find the coefficients $a_i$ in the linear combination$\\omega = \\sum_{i=1}^{N} \\alpha_i x^{(i)}$, we need to delve into the update rule of the Perceptron and its implications over multiple iterations.\n",
        "\n",
        "The Perceptron update rule is given as:\n",
        "\n",
        "$\\text{if } x^{(t)} \\text{ is misclassified then: } \\omega^{(t+1)} = \\omega^{(t)} + \\eta x^{(t)} y^{(t)}$\n",
        "\n",
        "This rule suggests that the weight vector is updated by adding a scaled version of the misclassified input vector $x^{(t)}$, where the scaling factor is $\\eta y^{(t)}$. $y^{(t)}$ is the true label of $x^{(t)}$, and η is the learning rate.\n",
        "\n",
        "**Constructing Linear Combination of ω**\n",
        "\n",
        "Initially, let's assume the weight vector ω is initialized to zero ($ω^{(0)} = 0$). Each time a data point $x^{(t)} is misclassified, ω is updated according to the rule above. After T updates, the weight vector ω can be represented as the sum of all updates:\n",
        "\n",
        "$$\\omega = \\sum_{t=1}^{T} \\eta x^{(t)} y^{(t)}$$\n",
        "\n",
        "Here, the sum is over all misclassified points over the training process, not over all data points in the dataset. However, if we consider $a_i = 0$ for correctly classified instances (i.e., instances that do not lead to an update), we can rewrite the expression to include all N instances in the dataset:\n",
        "\n",
        "$$\\omega = \\sum_{i=1}^{N} \\alpha_i x^{(i)}$$\n",
        "\n",
        "**Finding Coefficients $a_i$**\n",
        "\n",
        "The coefficient $a_i$ corresponds to $\\eta y^{(i)}$ for each time $x^{(i)}$ was misclassified and thus contributed to updating ω. If a particular $x^{(i)}$ was never misclassified, $a_i = 0$. If $x^{(i)}$ was misclassified multiple times, $a_i$ accumulates the sum of $\\eta y^{(i)}$ for each misclassification.\n",
        "\n",
        "Given that η is a constant learning rate, $a_i$ for each $x^{(i)}$ that contributed to an update can be represented as:\n",
        "\n",
        "$$\\alpha_i = \\eta \\cdot \\text{Count}_{\\text{misclassified}}(x^{(i)}) \\cdot y^{(i)}$$\n",
        "\n",
        "Where $\\text{Count}_{\\text{misclassified}}(x^{(i)})$ denotes the number of times $x^{(i)}$ was misclassified and led to an update. This is a simplified representation, assuming η is constant throughout the training. If η changes, $a_i$ would accumulate the specific $\\eta y^{(i)}$ values used at each update.\n",
        "\n"
      ],
      "metadata": {
        "id": "6igcvAQscIA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b\n",
        "\n",
        "#### **It's removed!**\n",
        "\n",
        "**Just a correction:**\n",
        "\n",
        "The correct mathematical expression should consider the inner product $x^{(i)T} x^{(j)}$, thus correcting the rule to:\n",
        "\n",
        "$$\\text{if } \\sum_{i=1}^{N} \\alpha_i y^{(i)} y^{(j)} x^{(i)T} x^{(j)} < 0 \\text{ then } \\alpha_j = \\alpha_j + 1$$"
      ],
      "metadata": {
        "id": "dW0qSf99gezo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 - Linear Classification\n",
        "\n",
        "Take a Multinomial Naive Bayes model for the problem of binary classification on textual data. The number of words in our dictionary (Total number of model features) is d. For a textual sample X, values $c_1, c_2, ..., c_d$ are the features vector. In other words, each $c_i$ shows the number of times that the ith word has been seen in our expression. Parameters of this model are as below:\n",
        "(y is the output of the model, or the sample class)\n",
        "\n",
        "$$P_y = P(y=1)$$\n",
        "\n",
        "$$P_{i|y=1} = P(\\text{word } i \\text{ appears in a specific document position}|y = 1)$$\n",
        "\n",
        "$$P_{i|y=0} = P(\\text{word } i \\text{ appears in a specific document position}|y = 0)$$\n",
        "\n",
        "(a) Write an expression for the conditional probability $P(y = 1|x)$ for the textual sample x based on the model parameters.\n",
        "\n",
        "(b) Show that decision boundry of the trained model is linear.\n",
        "\n",
        "(c) Show that the conditional probability written in part (a) is a logistic function:\n",
        "\n",
        "$$P(y = 1|x) = \\frac{1}{1 + e^{-(\\theta^T x + \\theta_0)}}\n",
        "$$"
      ],
      "metadata": {
        "id": "OrMsAClJiF3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "V9nnASU6jY46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "\n",
        "To compute the conditional probability $P(y=1|x)$ for the textual sample x using a Multinomial Naive Bayes model, we will apply Bayes' theorem, leveraging the naive assumption that features (word occurrences in this case) are conditionally independent given the class y. This allows us to simplify the computation of the joint probability of features given the class.\n",
        "\n",
        "For binary classification with y∈{0,1}, and specifically for $P(y=1|x)$, Bayes' theorem can be written as:\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{P(x | y = 1)P(y = 1)}{P(x)}$$\n",
        "\n",
        "Since P(x) is the same for both classes, when we're comparing P(y=1∣x) to P(y=0∣x), it's sufficient to compare their numerators for classification purposes. However, we focus on expressing P(y=1∣x) fully.\n",
        "\n",
        "Expanding P(x∣y=1) under the naive Bayes assumption and given the multinomial distribution of words, we get:\n",
        "\n",
        "$$P(x | y = 1) = \\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}$$\n",
        "\n",
        "Where $c_i$ is the count of occurrences of word i in the document, and d is the size of the vocabulary.\n",
        "\n",
        "So, P(y=1∣x) can be written as:\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i} P(y = 1)}{P(x)}$$\n",
        "\n",
        "\n",
        "To compute P(x), which is the probability of observing the document regardless of class, we can sum over all possible classes:\n",
        "\n",
        "$$P(x) = P(x | y = 1)P(y = 1) + P(x | y = 0)P(y = 0)$$\n",
        "\n",
        "Given the components we have:\n",
        "\n",
        "$$P(x | y = 1)P(y = 1) = \\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1)$$\n",
        "\n",
        "$$P(x | y = 0)P(y = 0) = \\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 0)^{c_i}\\right)P(y = 0)$$\n",
        "\n",
        "\n",
        "Therefore, the complete expression for P(y=1∣x) becomes:\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1)}{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1) + \\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 0)^{c_i}\\right)P(y = 0)}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "BHXIMTGDnNX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b\n",
        "\n",
        "\n",
        "To show that the decision boundary of the trained Multinomial Naive Bayes model for binary classification on textual data is linear, we need to analyze the decision rule based on comparing the posterior probabilities P(y=1∣x) and P(y=0∣x). Specifically, a classifier predicts y=1 if P(y=1∣x)>P(y=0∣x), and y=0 otherwise. This decision is equivalent to comparing the logarithm of the ratios of these probabilities due to the monotonic property of the logarithm function, which preserves the inequality direction.\n",
        "\n",
        "Starting from the expressions for P(y=1∣x) and P(y=0∣x), we can use the log probability for the decision rule to avoid numerical underflow and to simplify the expression:\n",
        "\n",
        "$$\\log\\left(\\frac{P(y = 1 | x)}{P(y = 0 | x)}\\right) > 0$$\n",
        "\n",
        "Using the formula for (y=1∣x) and P(y=0∣x), this can be expanded to:\n",
        "\n",
        "$$\\log\\left(\\frac{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1)}{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 0)^{c_i}\\right)P(y = 0)}\\right) > 0$$\n",
        "\n",
        "Simplifying logarithms, we get:\n",
        "\n",
        "$$\\sum_{i=1}^{d} c_i \\log\\left(\\frac{P(\\text{word } i | y = 1)}{P(\\text{word } i | y = 0)}\\right) + \\log\\left(\\frac{P(y = 1)}{P(y = 0)}\\right) > 0$$\n",
        "\n",
        "This equation represents a linear decision rule in the space of $c_i$ (the counts of words in the document). The reason it is linear is because the decision criterion is based on a weighted sum of the features ($c_i$), where the weights are the log ratios of the conditional probabilities of each word given the classes. The term\n",
        "$log(\\frac{P(y=0)}{P(y=1)})$ acts as a bias term.\n",
        "\n",
        "Thus, the decision boundary between y=1 and y=0 is defined by the set of points for which:\n",
        "\n",
        "$$\\sum_{i=1}^{d} c_i \\log\\left(\\frac{P(\\text{word } i | y = 1)}{P(\\text{word } i | y = 0)}\\right) + \\log\\left(\\frac{P(y = 1)}{P(y = 0)}\\right) = 0$$\n",
        "\n",
        "This is the equation of a hyperplane in the d-dimensional feature space, which confirms that the decision boundary of the Multinomial Naive Bayes model is linear.\n",
        "\n",
        "For the sake of better comprehension we can see that in 2-dimensional feature space if we let:\n",
        "\n",
        "$w_1 = \\log\\left(\\frac{P(\\text{word } 1 | y = 1)}{P(\\text{word } 1 | y = 0)}\\right)$\n",
        "\n",
        "$w_2 = \\log\\left(\\frac{P(\\text{word } 2 | y = 1)}{P(\\text{word } 2 | y = 0)}\\right)\n",
        "$\n",
        "\n",
        "$b = \\log\\left(\\frac{P(y = 1)}{P(y = 0)}\\right)\n",
        "$\n",
        "\n",
        "The equation simplifies to:\n",
        "\n",
        "$$w_1c_1 + w_2c_2 + b = 0$$\n",
        "\n",
        "Which is the equation of a line in 2D space, where c1 and c2 are the axes coordinates, w1 and w2 are the coefficients that determine the direction and steepness of the line, and b is the intercept with the c1-c2 plane."
      ],
      "metadata": {
        "id": "N8k0hTF0rDhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part c\n",
        "\n",
        "\n",
        "To show that the conditional probability P(y=1∣x) from part (a) can be expressed as a logistic function, we take the expression we derived in part (a):\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1)}{\\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 1)^{c_i}\\right)P(y = 1) + \\left(\\prod_{i=1}^{d} P(\\text{word } i | y = 0)^{c_i}\\right)P(y = 0)}$$\n",
        "\n",
        "We showed that the decision rule can be written in terms of a logistic function when comparing P(y=1∣x) to P(y=0∣x). To align it with the logistic function form, we recall the log-odds representation:\n",
        "\n",
        "$$\\log\\left(\\frac{P(y = 1 | x)}{P(y = 0 | x)}\\right) = \\sum_{i=1}^{d} c_i \\log\\left(\\frac{P(\\text{word } i | y = 1)}{P(\\text{word } i | y = 0)}\\right) + \\log\\left(\\frac{P(y = 1)}{P(y = 0)}\\right)$$\n",
        "\n",
        "Let's define $\\theta_i = \\log\\left(\\frac{P(\\text{word } i | y = 1)}{P(\\text{word } i | y = 0)}\\right) \\quad \\text{for} \\quad i=1 \\quad \\text{to} \\quad d$ and $\\theta_0 = \\log\\left(\\frac{P(y = 1)}{P(y = 0)}\\right)$. Then, we can rewrite the log-odds as:\n",
        "\n",
        "$$\\log\\left(\\frac{P(y = 1 | x)}{P(y = 0 | x)}\\right) = \\sum_{i=1}^{d} \\theta_i c_i + \\theta_0 = \\theta^T x + \\theta_0$$\n",
        "\n",
        "\n",
        "Where $θ^Tx$ denotes the dot product of the parameter vector θ and the feature vector x (with x including $c_1, .., c_d$).\n",
        "\n",
        "\n",
        "The logistic function is defined as:\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{1}{1 + e^{-z)}}$$\n",
        "\n",
        "\n",
        "Where $z = θ^Tx + \\theta_0$. Substituting z with our expression for the log-odds gives:\n",
        "\n",
        "$$P(y = 1 | x) = \\frac{1}{1 + e^{-(\\theta^T x + \\theta_0)}}$$"
      ],
      "metadata": {
        "id": "FAco8wlU48JL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 - Linear Classification\n",
        "\n",
        "Assume a classification problem with 3 classes in 2 dimenssions with distributions as below:\n",
        "\n",
        "$$P(x|\\omega_1) = \\mathcal{N}(0, I)$$\n",
        "\n",
        "$$P(x|\\omega_2) = \\mathcal{N}(\\begin{bmatrix}1& 1\\end{bmatrix}^T, I)$$\n",
        "\n",
        "$$P(x|\\omega_3) = 0.5 \\times \\mathcal{N}(\\begin{bmatrix}0.5& 0.5\\end{bmatrix}^T, I) + 0.5 \\times \\mathcal{N}(\\begin{bmatrix}-0.5& 0.5\\end{bmatrix}^T, I)$$\n",
        "\n",
        "$$P(\\omega_1) = P(\\omega_2) = p(\\omega_3)\n",
        "$$\n",
        "\n",
        "(a) With posterior probability calculation, calssify point $x = \\begin{bmatrix}0.3& 0.3\\end{bmatrix}^T$ for the least probability of error mode.\n",
        "\n",
        "(b) Assume for a specific point, we don't have the first characteristic (which means $x = \\begin{bmatrix}{*}& 0.3\\end{bmatrix}^T$). classify this point."
      ],
      "metadata": {
        "id": "wJY9o2XF-WIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "R6Hw-uTRDbnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "\n",
        "To classify the point x=[0.3 0.3] with the least probability of error, we compute the posterior probability for each class and then choose the class with the highest posterior probability. The posterior probability for class $ω_i$, given x, is given by Bayes' theorem as below:\n",
        "\n",
        "$$P(\\omega_i|x) = \\frac{P(x|\\omega_i)P(\\omega_i)}{P(x)}$$\n",
        "\n",
        "As we have $P(\\omega_1) = P(\\omega_2) = p(\\omega_3)$, assuming these probabilities are equal and sum to 1, we can simplify the computation by focusing on the numerator $P(x∣ω_i)P(ω_i)$, since the denominators will be the same across all classes and P(x) is a normalizing constant that does not affect the comparison.\n",
        "\n",
        "From the question, we have distribustions for each class as below:\n",
        "\n",
        "\n",
        "1.  for $ω_1$: $$P(x|\\omega_1) = \\mathcal{N}(0, I)$$\n",
        "2.  for $ω_2$: $$P(x|\\omega_2) = \\mathcal{N}(\\begin{bmatrix}1& 1\\end{bmatrix}^T, I)$$\n",
        "3.  for $ω_3$: $$P(x|\\omega_3) = 0.5 \\times \\mathcal{N}(\\begin{bmatrix}0.5& 0.5\\end{bmatrix}^T, I) + 0.5 \\times \\mathcal{N}(\\begin{bmatrix}-0.5& 0.5\\end{bmatrix}^T, I)$$\n",
        "\n",
        "Our normal distribution $\\mathcal{N}(𝜇, Σ)$ has a probability density function (PDF) as below:\n",
        "\n",
        "\n",
        "$$P(x) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}e^{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$$\n",
        "\n",
        "In our case, $Σ = I$, the identity matrix, so $|Σ|^\\frac{1}{2} = 1$ and $Σ^-1 = I$.\n",
        "Thus, for a 2-dimensional identity covariance matrix, the PDF simplifies to:\n",
        "\n",
        "$$P(x) = \\frac{1}{2\\pi}e^{-\\frac{1}{2}(x-\\mu)^T(x-\\mu)}$$\n",
        "\n",
        "Let's calculate the likelihood $P(x∣ω_i)$ for each class for the point x = [0.3 0.3], and identify the class with the highest posterior probability to classify point x.\n",
        "\n",
        "We use MultivariateNormal class from scipy library of python to do so as below:"
      ],
      "metadata": {
        "id": "2DjQkSPzDc5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Define the point x\n",
        "x = np.array([0.3, 0.3])\n",
        "\n",
        "# Mean vectors for each class\n",
        "mu_1 = np.array([0, 0])\n",
        "mu_2 = np.array([1, 1])\n",
        "mu_3_1 = np.array([0.5, 0.5])\n",
        "mu_3_2 = np.array([-0.5, 0.5])\n",
        "\n",
        "# Covariance matrix (identity for all classes)\n",
        "cov = np.array([[1, 0], [0, 1]])\n",
        "\n",
        "# Calculate likelihoods P(x|ω_i)\n",
        "likelihood_1 = multivariate_normal.pdf(x, mean=mu_1, cov=cov)\n",
        "likelihood_2 = multivariate_normal.pdf(x, mean=mu_2, cov=cov)\n",
        "likelihood_3 = 0.5 * multivariate_normal.pdf(x, mean=mu_3_1, cov=cov) + 0.5 * multivariate_normal.pdf(x, mean=mu_3_2, cov=cov)\n",
        "\n",
        "\n",
        "print(\"For w1, P(x|w1)=\", likelihood_1)\n",
        "print(\"For w2, P(x|w2)=\", likelihood_2)\n",
        "print(\"For w3, P(x|w3)=\", likelihood_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g1fM4W3sJ9Da",
        "outputId": "037369bf-e8a4-4db8-fe01-48f888cd4d68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For w1, P(x|w1)= 0.1454566657817508\n",
            "For w2, P(x|w2)= 0.09750251890301381\n",
            "For w3, P(x|w3)= 0.1330980768626826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that $P(ω_1)=P(ω_2)=P(ω_3)$ and are constants that cancel out in the comparison, the class with the highest posterior probability for point x is $ω_1$, as it has the highest likelihood.\n",
        "\n",
        "Therefore, with the least probability of error, the point x=[0.3 0.3] should be classified into class $ω_1$."
      ],
      "metadata": {
        "id": "0RlpKndIKaiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b\n",
        "\n",
        "As distributions are Gaussian and we're missing only one of two dimensions, we focusing on the available dimension.\n",
        "\n",
        "Since the covariance matrix for each class is the identity matrix I and the distributions are independent across dimensions, we can consider only the second dimension for classifying this point. Essentially, we evaluate $P(x_2|ω_i)$ for each class i, where $x_2 = 0.3$ is the second characteristic of x.\n",
        "\n",
        "The distributions along the second dimension change as below:\n",
        "\n",
        "1.  For $ω_1$, it's N(0,1) since the mean vector is $[0,0]^T$ and the covariance matrix is I.\n",
        "2.  For $ω_2$, it's N(1,1) since the mean vector is $[1,1]^T$.\n",
        "2.  For $ω_2$, the distribution is a mixture: 0.5 x N(0.5, 1) + 0.5 x N(0.5, 1), with the means for the second characteristic being 0.5 in both components.\n",
        "\n",
        "To compute the probability of x =0.3 given each class $ω_i$ using these distributions, we use MultivariateNormal class from scipy library of python as part (a) with respective changes:\n"
      ],
      "metadata": {
        "id": "auuKKWdvLiHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# For the second dimension, we're only looking at the value 0.3\n",
        "x_2 = 0.3\n",
        "\n",
        "# Means for the second dimension in each distribution\n",
        "mu_1_2 = 0\n",
        "mu_2_2 = 1\n",
        "mu_3_1_2 = 0.5\n",
        "mu_3_2_2 = 0.5\n",
        "\n",
        "# Calculate likelihoods P(x_2|ω_i) for the second characteristic\n",
        "likelihood_1_2 = multivariate_normal.pdf(x_2, mean=mu_1_2, cov=1)\n",
        "likelihood_2_2 = multivariate_normal.pdf(x_2, mean=mu_2_2, cov=1)\n",
        "likelihood_3_2 = 0.5 * multivariate_normal.pdf(x_2, mean=mu_3_1_2, cov=1) + \\\n",
        "                 0.5 * multivariate_normal.pdf(x_2, mean=mu_3_2_2, cov=1)\n",
        "\n",
        "likelihood_1_2, likelihood_2_2, likelihood_3_2\n",
        "\n",
        "print(\"For w1, P(x|w1)=\", likelihood_1_2)\n",
        "print(\"For w2, P(x|w2)=\", likelihood_2_2)\n",
        "print(\"For w3, P(x|w3)=\", likelihood_3_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wPQEJR68OGtD",
        "outputId": "7c1438c1-28fb-4692-bf85-76c49352207e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For w1, P(x|w1)= 0.3813878154605241\n",
            "For w2, P(x|w2)= 0.3122539333667613\n",
            "For w3, P(x|w3)= 0.3910426939754559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given these likelihoods and assuming equal priors for each class, the class with the highest probability for the point x=[* 0.3], as it has the highest likelihood value. Therefore, with the least probability of error, this point should be classified into class $ω_3$ ."
      ],
      "metadata": {
        "id": "eex2nlxZOVvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6 - Probabilistic perspective on regression\n",
        "\n",
        "In linear regression problem, we intend to give different weights to different training samples. To be exact we want to $J(θ)$, which is defined as below:\n",
        "\n",
        "$$J(\\theta) = \\frac{1}{2} \\sum_{i=1}^{m} \\omega(i)(\\theta^T x^{(i)} - y^{(i)})^2$$\n",
        "\n",
        "(a) Show that matrix W exists such that we have:\n",
        "\n",
        "$$J(\\theta) = (X\\theta - y)^T W (X\\theta - y)$$\n",
        "\n",
        "(b) Find the $\\theta$ that minimizes $J(θ)$ by calculating $\\nabla_{\\theta} J(\\theta)\n",
        "$ and setting it to zero. (Notice: In the case where all weights are equal, we know that $\\theta^* = (X^T X)^{-1} X^T y\n",
        "$. Your answer for this part should be a closed form that is a function o WX and y.)\n",
        "\n",
        "(c) Assume we have dataset $\\{ (x^{(i)}, y^{(i)}) : i = 1, \\ldots, m \\}\n",
        "$ of m independent samples. We intend to model $y^{(i)}$ in such a way that they are derived from conditional distributions with different levels of variance. Specifically assume we have:\n",
        "\n",
        "$$p(y^{(i)}|x^{(i)}; \\theta) = \\frac{1}{\\sqrt{2\\pi} \\sigma^{(i)}} \\exp\\left(- \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2}\\right)$$\n",
        "\n",
        "In other words this is a Gaussian distribution function with average of $\\theta^Tx^{(i)}$ and variance of $(σ^{(i)})^2$. $σ^{(i)}$ is constant and has a specific value. Show that finding maximum likelihood estimation (MLE) for $\\theta$, equalls to solving a weighted linear regression problem. Specifically find values of $\\omega^{(i)}$ with respect to $σ^{(i)}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nuc4r-tpO4o6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "IL18zKM8735s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "\n",
        "For the final equation we should construct the W and X matrices.\n",
        "\n",
        "*   X is a matrix of size m×n (where m is the number of training samples and n is the number of features), with each row representing a training example $x^{(i)T}$.\n",
        "*   W is a diagonal matrix of size m×m with ω(i) as the diagonal elements, representing the weights for each training example. This means something like W=diag(ω(1),ω(2),...,ω(m)).\n",
        "\n",
        "Given these definitions and from the question's equation, Xθ yields a vector of size m×1, where each element $(Xθ)_i = θ^Tx^{(i)}$ represents the predicted output for the ith training example.\n",
        "\n",
        "The term Xθ−y then gives a vector of prediction errors (differences between predicted and actual values) for each training example.\n",
        "\n",
        "Multiplying this error vector by W weights the errors according to their importance. Specifically, W(Xθ−y) performs element-wise multiplication of the error vector by the weights.\n",
        "\n",
        "Finally, $(Xθ−y)^TW(Xθ−y)$ computes the weighted sum of squared errors. The left multiplication by $(Xθ−y)^T$ effectively sums up these weighted squared errors, because for any vector v, and a diagonal matrix W with weights on the diagonal, $v^TWv$ gives $∑v_i^2ω(i)$, which matches the given definition of J(θ).\n",
        "\n",
        "Hence, we have shown that the matrix W=diag(ω(1),ω(2),...,ω(m)) allows us to write J(θ) in the form:\n",
        "\n",
        "$$J(\\theta) = (X\\theta - y)^T W (X\\theta - y)$$\n",
        "\n",
        "Here the conversion is complete, but there is a constant (1/2) coefficient, which we can take  into effect in matrix W values for example."
      ],
      "metadata": {
        "id": "BcsIBuS-75Up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b\n",
        "\n",
        "To find the value of θ that minimizes J(θ), we need to calculate the gradient of J(θ) with respect to θ, set it to zero, and solve it for θ. The matrix form expression for J(θ) is:\n",
        "\n",
        "$$J(\\theta)=(X\\theta - y)^T W (X\\theta - y)$$\n",
        "\n",
        "The gradient of J(θ) with respect to θ:\n",
        "\n",
        "$$\\nabla_{\\theta} J(\\theta) = \\nabla_{\\theta} [(X\\theta - y)^T W (X\\theta - y)]=\\nabla_{\\theta} [\\theta^TX^TWX\\theta-\\theta^TX^TWy-y^TWX\\theta+y^TWy]\n",
        "$$\n",
        "\n",
        "*   $y^TWy$ is a constant with respect to θ, its gradient is zero.\n",
        "\n",
        "*   $\\theta^TX^TWy$ is a scalar, so $\\theta^TX^TWy = y^TWX\\theta$\n",
        "\n",
        "So we have:\n",
        "\n",
        "$$=\\nabla_{\\theta} [\\theta^TX^TWX\\theta-2y^TWX\\theta]\n",
        "$$\n",
        "\n",
        "$$=2X^T W X \\theta - 2X^T W y=0$$\n",
        "\n",
        "And we have:\n",
        "\n",
        "$$2X^T W X \\theta = 2X^T W y$$\n",
        "\n",
        "Where $\\theta$ is:\n",
        "\n",
        "$$\\theta = (X^T W X)^{-1} X^T W y$$\n",
        "\n",
        "And this $\\theta$ is a closed-form expression.\n",
        "\n"
      ],
      "metadata": {
        "id": "cuDDNw3VBBK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part c\n",
        "\n",
        "To show that finding the Maximum Likelihood Estimation (MLE) for θ in the given setting is equivalent to solving a weighted linear regression problem, we will start with the assumption that $y^{(i)}$ follows a Gaussian distribution with mean $\\theta^Tx^{(i)}$ and variance $(σ^{(i)})^2$, as given by:\n",
        "\n",
        "$$p(y^{(i)}|x^{(i)}; \\theta) = \\frac{1}{\\sqrt{2\\pi} \\sigma^{(i)}} \\exp\\left(- \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2}\\right)$$\n",
        "\n",
        "Given a dataset of m independent samples, the likelihood of observing the dataset given θ is the product of the probabilities for each individual observation:\n",
        "\n",
        "$$L(\\theta) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi} \\sigma^{(i)}} \\exp\\left(- \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2}\\right)$$\n",
        "\n",
        "Taking the natural logarithm of the likelihood (log-likelihood) to simplify the product into a sum, we get:\n",
        "\n",
        "$$\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ -\\log(\\sqrt{2\\pi} \\sigma^{(i)}) - \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2} \\right]$$\n",
        "\n",
        "Simplifying further and dropping constants that do not depend on θ, we have:\n",
        "\n",
        "$$\\log L(\\theta) = -\\sum_{i=1}^{m} \\left[ \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2} \\right]$$\n",
        "\n",
        "To maximize the log-likelihood, we equivalently minimize the negative log-likelihood. This yields a cost function J(θ) that we seek to minimize:\n",
        "\n",
        "$$J(\\theta) = \\sum_{i=1}^{m} \\left[ \\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2 (\\sigma^{(i)})^2} \\right]$$\n",
        "\n",
        "Comparing this expression to the weighted linear regression cost function:\n",
        "\n",
        "$$J(\\theta) = \\frac{1}{2} \\sum_{i=1}^{m} ω(i)(θ^Tx^{(i)}-y^{(i)})^2$$\n",
        "\n",
        "We can see that the two are equivalent if we set:\n",
        "\n",
        "$$\\omega(i) = \\frac{1}{(\\sigma^{(i)})^2}$$\n",
        "\n",
        "Thus, the weights $ω_{(i)}$ in the weighted linear regression problem are inversely proportional to the variances of the conditional distributions of the output variable $y^{(i)}$. Hence, solving for the MLE of θ under the assumption of Gaussian errors with different variances for each observation is equivalent to solving a weighted linear regression problem with weights $\\omega(i) = \\frac{1}{(\\sigma^{(i)})^2}$."
      ],
      "metadata": {
        "id": "FEmAomxDGzla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7 - Probabilistic perspective on classification\n",
        "\n",
        "Assume a Naive Bayes classification problem with 3 classes and 2 features. One of the features come from Bernoulli's distribution and the other one comes from Gaussian distribution. Features are showed with $X=[X_1, X_2]^T$ and class is showed with Y.\n",
        "\n",
        "Initial distribution is as below:\n",
        "\n",
        "$$P[Y = 0] = 0.5, \\quad P[Y = 1] = 0.25, \\quad P[Y = 2] = 0.25$$\n",
        "\n",
        "Features distribution is as below:\n",
        "\n",
        "$$p_{X_1|Y}(x_1|Y = c) = \\text{Ber}(x_1; \\theta_c),$$\n",
        "$$p_{X_2|Y}(x_2|Y = c) = \\text{Normal}(x_2; \\mu_c, \\sigma_c^2)$$\n",
        "\n",
        "Also Assume that:\n",
        "\n",
        "$$\\sigma_c = \\begin{cases}\n",
        "1 & \\text{if } c = 0 \\\\\n",
        "1 & \\text{if } c = 1 \\\\\n",
        "1 & \\text{if } c = 2\n",
        "\\end{cases},$$\n",
        "\n",
        "$$\\mu_c = \\begin{cases}\n",
        "-1 & \\text{if } c = 0 \\\\\n",
        "0 & \\text{if } c = 1 \\\\\n",
        "1 & \\text{if } c = 2\n",
        "\\end{cases},$$\n",
        "\n",
        "$$\\theta_c = \\begin{cases}\n",
        "0.5 & \\text{if } c = 0 \\\\\n",
        "0.5 & \\text{if } c = 1 \\\\\n",
        "0.5 & \\text{if } c = 2\n",
        "\\end{cases}$$\n",
        "\n",
        "\n",
        "(a) Calculate $p_{Y|X_1, X_2}(y|x_1 = 0, x_2 = 0)$. (The answer should be a vector in $R^3$ space that sum of its elements is 1.)\n",
        "\n",
        "(b) Calculate $p_{Y|X_1}(y|x_1 = 0)$.\n",
        "\n",
        "(c) Calculate $p_{Y|X_2}(y|x_2 = 0)$.\n",
        "\n",
        "(d) Analyze the pattern you found in the answers of the previous parts.\n"
      ],
      "metadata": {
        "id": "u_EhWUKfK9qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer"
      ],
      "metadata": {
        "id": "jtDyA1z6OFzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part a\n",
        "\n",
        "To calculate P for each class c∈{0,1,2}, we'll use Bayes' theorem in the context of Naive Bayes classification. The posterior probability of class c given features $X_1=x_1$ and $X_2=x_2$ is given by:\n",
        "\n",
        "$$p_{Y|X_1, X_2}(y=c|x_1, x_2) = \\frac{p_{X_1|Y}(x_1|Y = c) \\cdot p_{X_2|Y}(x_2|Y = c) \\cdot P[Y = c]}{p_{X_1, X_2}(x_1, x_2)}$$\n",
        "\n",
        "For $X_1=x_1$ and $X_2=x_2$, we substitute these values into the formula. Also, $p_{X_1, X_2}(x_1, x_2)$ acts as a normalizing constant to ensure the probabilities sum to 1, which can be calculated as the sum of numerators for all classes.\n",
        "\n",
        "As for the distributions we have:\n",
        "\n",
        "*   For $X_1$ (Bernoulli):$p_{X_1|Y}(x_1|Y = c) = \\theta_c^{x_1} (1 - \\theta_c)^{1-x_1}$\n",
        "*   For $X_2$ (Gaussian with $σ_c=1$):$p_{X_2|Y}(x_2|Y = c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_c} \\exp\\left(-\\frac{(x_2 - \\mu_c)^2}{2\\sigma_c^2}\\right)$\n",
        "\n",
        "\n",
        "Substituting $θ_c=0.5$, $σ_c=1$, and $μ_c$ for each class, we can write a code snipet to calculate the posterior probabilities as below:\n",
        "\n"
      ],
      "metadata": {
        "id": "3PX5GdWqOG-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm, bernoulli\n",
        "import numpy as np\n",
        "\n",
        "# Given values\n",
        "P_Y = np.array([0.5, 0.25, 0.25])  # Prior probabilities\n",
        "theta_c = 0.5  # Same for all classes\n",
        "sigma_c = 1  # Same for all classes\n",
        "mu_c = np.array([-1, 0, 1])  # Means for each class\n",
        "x_1 = 0\n",
        "x_2 = 0\n",
        "\n",
        "# Calculate Bernoulli and Normal probabilities for each class\n",
        "bernoulli_probs = bernoulli.pmf(x_1, theta_c)\n",
        "normal_probs = norm.pdf(x_2, mu_c, sigma_c)\n",
        "\n",
        "# Calculate unnormalized posteriors\n",
        "unnormalized_posteriors = bernoulli_probs * normal_probs * P_Y\n",
        "\n",
        "# Normalize to get probabilities\n",
        "posterior_probs = unnormalized_posteriors / unnormalized_posteriors.sum()\n",
        "\n",
        "\n",
        "print(\"The posterior probability for Y=0: \", posterior_probs[0])\n",
        "print(\"The posterior probability for Y=1: \", posterior_probs[1])\n",
        "print(\"The posterior probability for Y=2: \", posterior_probs[2])\n",
        "print(\"Sum of values: \", posterior_probs[0] + posterior_probs[1] + posterior_probs[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3EcS_L8kRAVS",
        "outputId": "478966b2-b5d3-40e9-ac58-060476ce8786"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The posterior probability for Y=0:  0.4302258370717044\n",
            "The posterior probability for Y=1:  0.35466124439244345\n",
            "The posterior probability for Y=2:  0.2151129185358522\n",
            "Sum of values:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part b and c\n",
        "\n",
        "To calculate $p_{Y|X_1}(y|x_1 = 0)$ and $p_{Y|X_2}(y|x_2 = 0)$, we can apply Naive Bayes approach with focusing on one feature at a time:\n",
        "\n",
        "#### **For (b)**\n",
        "Given the Bernoulli distribution of $X_1$, we use the given $θ_c$ for each class and $x_1=0$. The prior probabilities $P[Y=c]$are also provided.\n",
        "\n",
        "The posterior probability for class c having $X_1=x_1$ is proportional to:\n",
        "$$p_{Y|X_1}(y = c|x_1) \\propto p_{X_1|Y}(x_1|Y = c) \\cdot P[Y = c]$$\n",
        "\n",
        "As $x_1=0$, we can use $p_{X_1|Y}(0|Y = c) = 1-\\theta_c$ for all classes (with $\\theta_c = 0.5$).\n",
        "\n",
        "#### **For (c)**\n",
        "For $X_2$, given the normal distribution of $X_2$ with $\\mu_c$ for each class and $σ_c = 1$, we can calculate the likelihood $p_{X_2|Y}(x_2 = 0|Y = c) \\text{ for } x_2 = 0$.\n",
        "\n",
        "The posterior probability for class c given $X_2=x_2$ is proportional to:\n",
        "\n",
        "$$p_{Y|X_2}(y = c|x_2) \\propto p_{X_2|Y}(x_2|Y = c) \\cdot P[Y = c]$$\n",
        "\n",
        "#### **Calculations**\n",
        "To perform the calculations for both parts, we normalize the results to sum to 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7EvKukySEnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm, bernoulli\n",
        "import numpy as np\n",
        "\n",
        "# For p_{Y|X_1}(y|x_1 = 0)\n",
        "bernoulli_likelihoods_x1_0 = bernoulli.pmf(0, theta_c)  # Same for all classes\n",
        "posterior_probs_x1_0 = P_Y * bernoulli_likelihoods_x1_0\n",
        "posterior_probs_x1_0 /= posterior_probs_x1_0.sum()\n",
        "\n",
        "# For p_{Y|X_2}(y|x_2 = 0)\n",
        "normal_likelihoods_x2_0 = norm.pdf(0, mu_c, sigma_c)\n",
        "posterior_probs_x2_0 = P_Y * normal_likelihoods_x2_0\n",
        "posterior_probs_x2_0 /= posterior_probs_x2_0.sum()\n",
        "\n",
        "posterior_probs_x1_0, posterior_probs_x2_0\n",
        "\n",
        "print(\"Part (b), The posterior probability for Y=0: \", posterior_probs_x1_0[0])\n",
        "print(\"Part (b), The posterior probability for Y=1: \", posterior_probs_x1_0[1])\n",
        "print(\"Part (b), The posterior probability for Y=2: \", posterior_probs_x1_0[2])\n",
        "print(\"Part (b), Sum of values: \", posterior_probs_x1_0[0] + posterior_probs_x1_0[1] + posterior_probs_x1_0[2])\n",
        "\n",
        "print(\"Part (c), The posterior probability for Y=0: \", posterior_probs_x2_0[0])\n",
        "print(\"Part (c), The posterior probability for Y=1: \", posterior_probs_x2_0[1])\n",
        "print(\"Part (c), The posterior probability for Y=2: \", posterior_probs_x2_0[2])\n",
        "print(\"Part (c), Sum of values: \", posterior_probs_x2_0[0] + posterior_probs_x2_0[1] + posterior_probs_x2_0[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4etqEz_PUt3e",
        "outputId": "ff8ff524-4025-4e84-abb0-08167864d33b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part (b), The posterior probability for Y=0:  0.5\n",
            "Part (b), The posterior probability for Y=1:  0.25\n",
            "Part (b), The posterior probability for Y=2:  0.25\n",
            "Part (b), Sum of values:  1.0\n",
            "Part (c), The posterior probability for Y=0:  0.4302258370717044\n",
            "Part (c), The posterior probability for Y=1:  0.3546612443924434\n",
            "Part (c), The posterior probability for Y=2:  0.2151129185358522\n",
            "Part (c), Sum of values:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analytical results:\n",
        "\n",
        "\n",
        "Part (b): These are the same as the prior probabilities P[Y=c], due to the uniform distribution of $X_1$ across all classes.\n",
        "\n",
        "Part (c): These probabilities reflect the influence of the Gaussian-distributed feature $X_2$ on class likelihoods, adjusted by the different means $\\mu_c$ for each class.\n",
        "\n"
      ],
      "metadata": {
        "id": "R4e7ZqStVj19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part d\n",
        "\n",
        "\n",
        "The calculation for $p_{Y|X_1}(y|x_1=0)$ results in posterior probabilities that are identical to the prior probabilities of each class. This is because the feature $X_1$ is distributed uniformly across all classes ($θ_c=0.5$ for all c), making it non-informative in this specific case ($x_1=0$).\n",
        "\n",
        "On the other hand, $p_{Y|X_2}(y|x_2=0)$ shows variation in the posterior probabilities based on the Gaussian distribution's means ($μ_c$) for each class. The closer the mean of a class's Gaussian distribution to the observed value $x_2=0$, the higher the likelihood and hence the posterior probability of that class, given the observation. This illustrates the influence of the feature's distribution parameters on class probabilities.\n",
        "\n",
        "Hnce, the pattern indicates that the impact of each feature on the classification depends on its distribution parameters relative to the observed data. Uniform parameters across classes, as with $X_1$, may not differentiate well between classes, while varying parameters, as with $X_2$, directly influence class likelihoods based on the observed feature values. ​"
      ],
      "metadata": {
        "id": "Z1YXI_pnV5-w"
      }
    }
  ]
}