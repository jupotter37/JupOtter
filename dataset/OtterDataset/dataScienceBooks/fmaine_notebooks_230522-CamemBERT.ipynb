{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamemBERT for text classification task\n",
    "\n",
    "CamemBERT is a state-of-the-art language model for French based on the RoBERTa model.\n",
    "\n",
    "It is now available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data and pretraining data source domains.\n",
    "For more information here's the huggingface website: https://huggingface.co/camembert-base\n",
    "\n",
    "In this notebook I would like to finetune a camembert model for classifying french tweets based on the french-twitter-sentiment-analysis dataset: https://www.kaggle.com/hbaflast/french-twitter-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Geek/Work/Patat\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rs = 42 # Random State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:54:57.766588Z",
     "iopub.status.busy": "2023-05-11T14:54:57.766168Z",
     "iopub.status.idle": "2023-05-11T14:54:57.775281Z",
     "shell.execute_reply": "2023-05-11T14:54:57.774105Z",
     "shell.execute_reply.started": "2023-05-11T14:54:57.766542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "# import torch.optim as optim\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.file\n",
    "\n",
    "filename = 'data/prod/230517-OIDS-Label.pickle'\n",
    "\n",
    "df_label = patat.util.file.pickle_load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels ou textes nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Textes nuls\n",
    "df_label['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels nuls\n",
    "df_label['infox'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label[df_label['infox'].notna()]\n",
    "df_label.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='text').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.duplicated(subset='url').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patat.util.text\n",
    "\n",
    "df_label['pp_text']=df_label['text'].apply(patat.util.text.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='infox', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = df_label['infox'].value_counts()\n",
    "sns.barplot(x=label_count.index, y=label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>site</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>tags</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>date_iso</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>...</th>\n",
       "      <th>denigrement</th>\n",
       "      <th>degre_infox</th>\n",
       "      <th>observateur</th>\n",
       "      <th>source</th>\n",
       "      <th>p_count</th>\n",
       "      <th>text</th>\n",
       "      <th>c_count</th>\n",
       "      <th>p_size</th>\n",
       "      <th>url_h</th>\n",
       "      <th>pp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>610</td>\n",
       "      <td>https://www.francesoir.fr/politique-france/gue...</td>\n",
       "      <td>www.francesoir.fr</td>\n",
       "      <td>Guerre en Ukraine: Emmanuel Macron prévient le...</td>\n",
       "      <td>À l’occasion de la cérémonie pour le 78e anniv...</td>\n",
       "      <td>[Accueil, Politique]</td>\n",
       "      <td>[À l’occasion de la cérémonie pour le 78e anni...</td>\n",
       "      <td>2022-08-20T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>CN</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>11</td>\n",
       "      <td>Guerre en Ukraine: Emmanuel Macron prévient le...</td>\n",
       "      <td>2629</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>857bfacdd98e36dda26f1f92cf40c992904d6386</td>\n",
       "      <td>guerre en ukraine: emmanuel macron prévient le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>708</td>\n",
       "      <td>https://www.profession-gendarme.com/la-vaccina...</td>\n",
       "      <td>www.profession-gendarme.com</td>\n",
       "      <td>La vaccination Covid : un marquage de « type b...</td>\n",
       "      <td>De: Dr R Date: 16 avril 2022 à 08:17:22 ﻿bonjo...</td>\n",
       "      <td>[Actualités, Tribune]</td>\n",
       "      <td>[De: Dr R Date: 16 avril 2022 à 08:17:22 ﻿bonj...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test1</td>\n",
       "      <td>17</td>\n",
       "      <td>La vaccination Covid : un marquage de « type b...</td>\n",
       "      <td>6252</td>\n",
       "      <td>367.764706</td>\n",
       "      <td>166d32300f4d7766a82fe39a1185f35bc347c05f</td>\n",
       "      <td>la vaccination covid : un marquage de « type b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>https://www.mondialisation.ca/colonialisme-ene...</td>\n",
       "      <td>www.mondialisation.ca</td>\n",
       "      <td>Colonialisme énergétique</td>\n",
       "      <td>Visite d’État du président de la République it...</td>\n",
       "      <td>[Moyen-Orient et Afrique du Nord, Guerre USA O...</td>\n",
       "      <td>[Visite d’État du président de la République i...</td>\n",
       "      <td>2022-07-09T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>Pangea Grandangolo</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>GP</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>8</td>\n",
       "      <td>Colonialisme énergétique\\nVisite d’État du pré...</td>\n",
       "      <td>2794</td>\n",
       "      <td>349.250000</td>\n",
       "      <td>2a39a60fd5e2c6df0f6ec8ce9fedc2ee2eb4ab4d</td>\n",
       "      <td>colonialisme énergétique\\nvisite d état du pré...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>566</td>\n",
       "      <td>https://www.francesoir.fr/opinions-editos/de-l...</td>\n",
       "      <td>www.francesoir.fr</td>\n",
       "      <td>De l’importance d’une Assemblée vraiment natio...</td>\n",
       "      <td>Depuis hier soir, ne serions-nous pas en train...</td>\n",
       "      <td>[Accueil, Opinions]</td>\n",
       "      <td>[Depuis hier soir, ne serions-nous pas en trai...</td>\n",
       "      <td>2022-06-20T19:46:00</td>\n",
       "      <td></td>\n",
       "      <td>Xavier Azalbert</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>GP</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>16</td>\n",
       "      <td>De l’importance d’une Assemblée vraiment natio...</td>\n",
       "      <td>4582</td>\n",
       "      <td>286.375000</td>\n",
       "      <td>93b25370fea82c7039f7e2b00c0bd73151101af3</td>\n",
       "      <td>de l importance d une assemblée vraiment natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>232</td>\n",
       "      <td>https://www.polemia.com/quelle-politique-migra...</td>\n",
       "      <td>www.polemia.com</td>\n",
       "      <td>Quelle politique migratoire pour la France ? –...</td>\n",
       "      <td>Par André-Victor Robert, haut fonctionnaire ♦ ...</td>\n",
       "      <td>[Accueil, Géopolitique, Afrique, analyse, Andr...</td>\n",
       "      <td>[Facebook, Twitter, LinkedIn, Print Friendly, ...</td>\n",
       "      <td></td>\n",
       "      <td>Par André-Victor Robert, haut fonctionnaire ♦ ...</td>\n",
       "      <td>André Victor Robert</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>FB</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>31</td>\n",
       "      <td>Quelle politique migratoire pour la France ? –...</td>\n",
       "      <td>9123</td>\n",
       "      <td>294.290323</td>\n",
       "      <td>c12a81bb99810b5c13fba93abc5f9cea077a873d</td>\n",
       "      <td>quelle politique migratoire pour la france ?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>https://lesdeqodeurs.fr/des-scientifiques-de-h...</td>\n",
       "      <td>lesdeqodeurs.fr</td>\n",
       "      <td>Des scientifiques de Harvard et de Johns Hopki...</td>\n",
       "      <td>Article original datant du 31/08/22 par SSRNCO...</td>\n",
       "      <td>[ARNm, COVID, effets secondaires, étude, Harva...</td>\n",
       "      <td>[Les étudiants des universités nord-américaine...</td>\n",
       "      <td>2022-09-23T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FB</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>5</td>\n",
       "      <td>Des scientifiques de Harvard et de Johns Hopki...</td>\n",
       "      <td>1803</td>\n",
       "      <td>360.600000</td>\n",
       "      <td>1f56ed5fa54de7c492154ac8ee0d8d10724f1aa4</td>\n",
       "      <td>des scientifiques de harvard et de johns hopki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158</td>\n",
       "      <td>https://www.voltairenet.org/article217546.html</td>\n",
       "      <td>www.voltairenet.org</td>\n",
       "      <td>L’armée russe achète des exemplaires d’armemen...</td>\n",
       "      <td>L’achat de deux canons automoteurs CAESAR fran...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[L’achat de deux canons automoteurs CAESAR fra...</td>\n",
       "      <td>1900-01-01T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>FB</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>3</td>\n",
       "      <td>L’armée russe achète des exemplaires d’armemen...</td>\n",
       "      <td>718</td>\n",
       "      <td>239.333333</td>\n",
       "      <td>b3153ba0ad9e32c02a8d49c99a6748e0764b20b5</td>\n",
       "      <td>l armée russe achète des exemplaires d armemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>523</td>\n",
       "      <td>https://lemediaen442.fr/onu-le-premier-ministr...</td>\n",
       "      <td>lemediaen442.fr</td>\n",
       "      <td>ONU – Le Premier ministre de Nouvelle-Zélande ...</td>\n",
       "      <td>L’argument principal de la ministre est que le...</td>\n",
       "      <td>[Politique, Vidéos, censure, jacinda ardern, ONU]</td>\n",
       "      <td>[L’argument principal de la ministre est que l...</td>\n",
       "      <td>2022-09-29T09:56:31+02:00</td>\n",
       "      <td>Le terrible discours de Jacinda Ardern, Premie...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FB</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>7</td>\n",
       "      <td>ONU – Le Premier ministre de Nouvelle-Zélande ...</td>\n",
       "      <td>2420</td>\n",
       "      <td>345.714286</td>\n",
       "      <td>3d47a59ef99274fd9ee96c209cc2ab41d6e1f6bb</td>\n",
       "      <td>onu   le premier ministre de nouvelle-zélande ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>853</td>\n",
       "      <td>https://fr.sott.net/article/36258-Pandemie-ou-...</td>\n",
       "      <td>fr.sott.net</td>\n",
       "      <td>Pandémie ou le retour du grand Pan</td>\n",
       "      <td>Au cours des deux dernières décennies, les pub...</td>\n",
       "      <td>[La Science de l'Esprit]</td>\n",
       "      <td>[Au cours des deux dernières décennies, les pu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Verif</td>\n",
       "      <td>59</td>\n",
       "      <td>Pandémie ou le retour du grand Pan\\nAu cours d...</td>\n",
       "      <td>19227</td>\n",
       "      <td>325.881356</td>\n",
       "      <td>fd203102bf61c0cfc0387c3db38685556dc9aa0e</td>\n",
       "      <td>pandémie ou le retour du grand pan\\nau cours d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152</td>\n",
       "      <td>https://lesdeqodeurs.fr/le-president-trump-dec...</td>\n",
       "      <td>lesdeqodeurs.fr</td>\n",
       "      <td>Le président Trump dénonce la corruption de la...</td>\n",
       "      <td>Article original datant du 28/04/22Donald Trum...</td>\n",
       "      <td>[2016, 2020, Barack Obama, CNN, Donald Trump, ...</td>\n",
       "      <td>[Article original datant du 28/04/22, Le prési...</td>\n",
       "      <td>2022-05-01T00:00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>FB</td>\n",
       "      <td>Recueil</td>\n",
       "      <td>15</td>\n",
       "      <td>Le président Trump dénonce la corruption de la...</td>\n",
       "      <td>4512</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>a118d6a98c00f504fad2544531bd63b2267f1244</td>\n",
       "      <td>le président trump dénonce la corruption de la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                                url   \n",
       "609    610  https://www.francesoir.fr/politique-france/gue...  \\\n",
       "705    708  https://www.profession-gendarme.com/la-vaccina...   \n",
       "26      26  https://www.mondialisation.ca/colonialisme-ene...   \n",
       "565    566  https://www.francesoir.fr/opinions-editos/de-l...   \n",
       "231    232  https://www.polemia.com/quelle-politique-migra...   \n",
       "..     ...                                                ...   \n",
       "112    112  https://lesdeqodeurs.fr/des-scientifiques-de-h...   \n",
       "157    158     https://www.voltairenet.org/article217546.html   \n",
       "522    523  https://lemediaen442.fr/onu-le-premier-ministr...   \n",
       "847    853  https://fr.sott.net/article/36258-Pandemie-ou-...   \n",
       "151    152  https://lesdeqodeurs.fr/le-president-trump-dec...   \n",
       "\n",
       "                            site   \n",
       "609            www.francesoir.fr  \\\n",
       "705  www.profession-gendarme.com   \n",
       "26         www.mondialisation.ca   \n",
       "565            www.francesoir.fr   \n",
       "231              www.polemia.com   \n",
       "..                           ...   \n",
       "112              lesdeqodeurs.fr   \n",
       "157          www.voltairenet.org   \n",
       "522              lemediaen442.fr   \n",
       "847                  fr.sott.net   \n",
       "151              lesdeqodeurs.fr   \n",
       "\n",
       "                                                 title   \n",
       "609  Guerre en Ukraine: Emmanuel Macron prévient le...  \\\n",
       "705  La vaccination Covid : un marquage de « type b...   \n",
       "26                            Colonialisme énergétique   \n",
       "565  De l’importance d’une Assemblée vraiment natio...   \n",
       "231  Quelle politique migratoire pour la France ? –...   \n",
       "..                                                 ...   \n",
       "112  Des scientifiques de Harvard et de Johns Hopki...   \n",
       "157  L’armée russe achète des exemplaires d’armemen...   \n",
       "522  ONU – Le Premier ministre de Nouvelle-Zélande ...   \n",
       "847                 Pandémie ou le retour du grand Pan   \n",
       "151  Le président Trump dénonce la corruption de la...   \n",
       "\n",
       "                                               article   \n",
       "609  À l’occasion de la cérémonie pour le 78e anniv...  \\\n",
       "705  De: Dr R Date: 16 avril 2022 à 08:17:22 ﻿bonjo...   \n",
       "26   Visite d’État du président de la République it...   \n",
       "565  Depuis hier soir, ne serions-nous pas en train...   \n",
       "231  Par André-Victor Robert, haut fonctionnaire ♦ ...   \n",
       "..                                                 ...   \n",
       "112  Article original datant du 31/08/22 par SSRNCO...   \n",
       "157  L’achat de deux canons automoteurs CAESAR fran...   \n",
       "522  L’argument principal de la ministre est que le...   \n",
       "847  Au cours des deux dernières décennies, les pub...   \n",
       "151  Article original datant du 28/04/22Donald Trum...   \n",
       "\n",
       "                                                  tags   \n",
       "609                               [Accueil, Politique]  \\\n",
       "705                              [Actualités, Tribune]   \n",
       "26   [Moyen-Orient et Afrique du Nord, Guerre USA O...   \n",
       "565                                [Accueil, Opinions]   \n",
       "231  [Accueil, Géopolitique, Afrique, analyse, Andr...   \n",
       "..                                                 ...   \n",
       "112  [ARNm, COVID, effets secondaires, étude, Harva...   \n",
       "157                                                 []   \n",
       "522  [Politique, Vidéos, censure, jacinda ardern, ONU]   \n",
       "847                           [La Science de l'Esprit]   \n",
       "151  [2016, 2020, Barack Obama, CNN, Donald Trump, ...   \n",
       "\n",
       "                                            paragraphs   \n",
       "609  [À l’occasion de la cérémonie pour le 78e anni...  \\\n",
       "705  [De: Dr R Date: 16 avril 2022 à 08:17:22 ﻿bonj...   \n",
       "26   [Visite d’État du président de la République i...   \n",
       "565  [Depuis hier soir, ne serions-nous pas en trai...   \n",
       "231  [Facebook, Twitter, LinkedIn, Print Friendly, ...   \n",
       "..                                                 ...   \n",
       "112  [Les étudiants des universités nord-américaine...   \n",
       "157  [L’achat de deux canons automoteurs CAESAR fra...   \n",
       "522  [L’argument principal de la ministre est que l...   \n",
       "847  [Au cours des deux dernières décennies, les pu...   \n",
       "151  [Article original datant du 28/04/22, Le prési...   \n",
       "\n",
       "                      date_iso   \n",
       "609        2022-08-20T00:00:00  \\\n",
       "705                              \n",
       "26         2022-07-09T00:00:00   \n",
       "565        2022-06-20T19:46:00   \n",
       "231                              \n",
       "..                         ...   \n",
       "112        2022-09-23T00:00:00   \n",
       "157        1900-01-01T00:00:00   \n",
       "522  2022-09-29T09:56:31+02:00   \n",
       "847                              \n",
       "151        2022-05-01T00:00:00   \n",
       "\n",
       "                                              abstract               Auteur   \n",
       "609                                                                          \\\n",
       "705                                                                     NaN   \n",
       "26                                                       Pangea Grandangolo   \n",
       "565                                                         Xavier Azalbert   \n",
       "231  Par André-Victor Robert, haut fonctionnaire ♦ ...  André Victor Robert   \n",
       "..                                                 ...                  ...   \n",
       "112                                                                           \n",
       "157                                                                           \n",
       "522  Le terrible discours de Jacinda Ardern, Premie...                        \n",
       "847                                                                     NaN   \n",
       "151                                                                           \n",
       "\n",
       "     ... denigrement degre_infox  observateur   source  p_count   \n",
       "609  ...         0.0                       CN  Recueil       11  \\\n",
       "705  ...         NaN         NaN          NaN    Test1       17   \n",
       "26   ...         NaN                       GP  Recueil        8   \n",
       "565  ...         NaN                       GP  Recueil       16   \n",
       "231  ...         0.0                       FB  Recueil       31   \n",
       "..   ...         ...         ...          ...      ...      ...   \n",
       "112  ...         0.0           1           FB  Recueil        5   \n",
       "157  ...         NaN           1           FB  Recueil        3   \n",
       "522  ...         0.0           1           FB  Recueil        7   \n",
       "847  ...         NaN         NaN          NaN    Verif       59   \n",
       "151  ...         NaN           1           FB  Recueil       15   \n",
       "\n",
       "                                                  text  c_count      p_size   \n",
       "609  Guerre en Ukraine: Emmanuel Macron prévient le...     2629  239.000000  \\\n",
       "705  La vaccination Covid : un marquage de « type b...     6252  367.764706   \n",
       "26   Colonialisme énergétique\\nVisite d’État du pré...     2794  349.250000   \n",
       "565  De l’importance d’une Assemblée vraiment natio...     4582  286.375000   \n",
       "231  Quelle politique migratoire pour la France ? –...     9123  294.290323   \n",
       "..                                                 ...      ...         ...   \n",
       "112  Des scientifiques de Harvard et de Johns Hopki...     1803  360.600000   \n",
       "157  L’armée russe achète des exemplaires d’armemen...      718  239.333333   \n",
       "522  ONU – Le Premier ministre de Nouvelle-Zélande ...     2420  345.714286   \n",
       "847  Pandémie ou le retour du grand Pan\\nAu cours d...    19227  325.881356   \n",
       "151  Le président Trump dénonce la corruption de la...     4512  300.800000   \n",
       "\n",
       "                                        url_h   \n",
       "609  857bfacdd98e36dda26f1f92cf40c992904d6386  \\\n",
       "705  166d32300f4d7766a82fe39a1185f35bc347c05f   \n",
       "26   2a39a60fd5e2c6df0f6ec8ce9fedc2ee2eb4ab4d   \n",
       "565  93b25370fea82c7039f7e2b00c0bd73151101af3   \n",
       "231  c12a81bb99810b5c13fba93abc5f9cea077a873d   \n",
       "..                                        ...   \n",
       "112  1f56ed5fa54de7c492154ac8ee0d8d10724f1aa4   \n",
       "157  b3153ba0ad9e32c02a8d49c99a6748e0764b20b5   \n",
       "522  3d47a59ef99274fd9ee96c209cc2ab41d6e1f6bb   \n",
       "847  fd203102bf61c0cfc0387c3db38685556dc9aa0e   \n",
       "151  a118d6a98c00f504fad2544531bd63b2267f1244   \n",
       "\n",
       "                                               pp_text  \n",
       "609  guerre en ukraine: emmanuel macron prévient le...  \n",
       "705  la vaccination covid : un marquage de « type b...  \n",
       "26   colonialisme énergétique\\nvisite d état du pré...  \n",
       "565  de l importance d une assemblée vraiment natio...  \n",
       "231  quelle politique migratoire pour la france ?  ...  \n",
       "..                                                 ...  \n",
       "112  des scientifiques de harvard et de johns hopki...  \n",
       "157  l armée russe achète des exemplaires d armemen...  \n",
       "522  onu   le premier ministre de nouvelle-zélande ...  \n",
       "847  pandémie ou le retour du grand pan\\nau cours d...  \n",
       "151  le président trump dénonce la corruption de la...  \n",
       "\n",
       "[746 rows x 46 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df_label[df_label['infox'] == 0]\n",
    "df_1 = df_label[df_label['infox'] == 1]\n",
    "\n",
    "min_sample = min(len(df_0),len(df_1))\n",
    "\n",
    "df_0=df_0.sample(min_sample,random_state=_rs)\n",
    "df_1=df_1.sample(min_sample,random_state=_rs)\n",
    "df_ml = pd.concat([df_0,df_1])\n",
    "\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['infox']=df_ml['infox'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamemBERT\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:54:57.777807Z",
     "iopub.status.busy": "2023-05-11T14:54:57.777334Z",
     "iopub.status.idle": "2023-05-11T14:54:57.785810Z",
     "shell.execute_reply": "2023-05-11T14:54:57.784779Z",
     "shell.execute_reply.started": "2023-05-11T14:54:57.777758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 5\n",
    "MAX_LEN = 512\n",
    "batch_size = 16\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:54:57.788118Z",
     "iopub.status.busy": "2023-05-11T14:54:57.787796Z",
     "iopub.status.idle": "2023-05-11T14:54:57.799728Z",
     "shell.execute_reply": "2023-05-11T14:54:57.798659Z",
     "shell.execute_reply.started": "2023-05-11T14:54:57.788090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:01.319633Z",
     "iopub.status.busy": "2023-05-11T14:55:01.319249Z",
     "iopub.status.idle": "2023-05-11T14:55:01.770406Z",
     "shell.execute_reply": "2023-05-11T14:55:01.769447Z",
     "shell.execute_reply.started": "2023-05-11T14:55:01.319593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:01.772265Z",
     "iopub.status.busy": "2023-05-11T14:55:01.771887Z",
     "iopub.status.idle": "2023-05-11T14:55:03.411522Z",
     "shell.execute_reply": "2023-05-11T14:55:03.410734Z",
     "shell.execute_reply.started": "2023-05-11T14:55:01.772224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df_ml['text'].to_list()\n",
    "labels = df_ml['infox'].to_list()\n",
    "\n",
    "#user tokenizer to convert sentences into tokenizer\n",
    "input_ids = [\n",
    "    tokenizer.encode(sent, add_special_tokens=True, max_length=MAX_LEN,truncation=True)\n",
    "    for sent in text\n",
    "]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids,\n",
    "                          maxlen=MAX_LEN,\n",
    "                          dtype=\"long\",\n",
    "                          truncating=\"post\",\n",
    "                          padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i > 0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:03.413291Z",
     "iopub.status.busy": "2023-05-11T14:55:03.412895Z",
     "iopub.status.idle": "2023-05-11T14:55:03.508676Z",
     "shell.execute_reply": "2023-05-11T14:55:03.507803Z",
     "shell.execute_reply.started": "2023-05-11T14:55:03.413248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(\n",
    "    input_ids, labels, attention_masks, random_state=42, test_size=0.2)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks,\n",
    "                                validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,\n",
    "                                   sampler=validation_sampler,\n",
    "                                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    5,   407,    17,  ..., 22313,   454,     6],\n",
       "        [    5, 11671, 29351,  ...,   584,    17,     6],\n",
       "        [    5, 10752,    92,  ...,  1347,     9,     6],\n",
       "        ...,\n",
       "        [    5, 20295,    10,  ..., 11730,    37,     6],\n",
       "        [    5, 16199,     8,  ...,    72,    26,     6],\n",
       "        [    5,    54, 15448,  ..., 14977, 16099,     6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamemBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:03.510530Z",
     "iopub.status.busy": "2023-05-11T14:55:03.510118Z",
     "iopub.status.idle": "2023-05-11T14:55:23.769871Z",
     "shell.execute_reply": "2023-05-11T14:55:23.768939Z",
     "shell.execute_reply.started": "2023-05-11T14:55:03.510473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the parameters and metrics to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:23.772044Z",
     "iopub.status.busy": "2023-05-11T14:55:23.771659Z",
     "iopub.status.idle": "2023-05-11T14:55:23.787377Z",
     "shell.execute_reply": "2023-05-11T14:55:23.786517Z",
     "shell.execute_reply.started": "2023-05-11T14:55:23.772002Z"
    }
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.01\n",
    "}, {\n",
    "    'params':\n",
    "    [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate':\n",
    "    0.0\n",
    "}]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T14:55:23.789169Z",
     "iopub.status.busy": "2023-05-11T14:55:23.788803Z",
     "iopub.status.idle": "2023-05-11T14:56:23.249203Z",
     "shell.execute_reply": "2023-05-11T14:56:23.247643Z",
     "shell.execute_reply.started": "2023-05-11T14:55:23.789130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                                  | 0/5 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.96s/it]\u001b[A\n",
      "2it [00:03,  1.82s/it]\u001b[A\n",
      "3it [00:04,  1.56s/it]\u001b[A\n",
      "4it [00:06,  1.43s/it]\u001b[A\n",
      "5it [00:07,  1.36s/it]\u001b[A\n",
      "6it [00:08,  1.31s/it]\u001b[A\n",
      "7it [00:09,  1.28s/it]\u001b[A\n",
      "8it [00:11,  1.27s/it]\u001b[A\n",
      "9it [00:12,  1.25s/it]\u001b[A\n",
      "10it [00:13,  1.25s/it]\u001b[A\n",
      "11it [00:14,  1.24s/it]\u001b[A\n",
      "12it [00:15,  1.24s/it]\u001b[A\n",
      "13it [00:17,  1.24s/it]\u001b[A\n",
      "14it [00:18,  1.24s/it]\u001b[A\n",
      "15it [00:19,  1.25s/it]\u001b[A\n",
      "16it [00:20,  1.25s/it]\u001b[A\n",
      "17it [00:22,  1.24s/it]\u001b[A\n",
      "18it [00:23,  1.24s/it]\u001b[A\n",
      "19it [00:24,  1.23s/it]\u001b[A\n",
      "20it [00:25,  1.23s/it]\u001b[A\n",
      "21it [00:27,  1.23s/it]\u001b[A\n",
      "22it [00:28,  1.23s/it]\u001b[A\n",
      "23it [00:29,  1.24s/it]\u001b[A\n",
      "24it [00:30,  1.24s/it]\u001b[A\n",
      "25it [00:32,  1.24s/it]\u001b[A\n",
      "26it [00:33,  1.24s/it]\u001b[A\n",
      "27it [00:34,  1.25s/it]\u001b[A\n",
      "28it [00:35,  1.24s/it]\u001b[A\n",
      "29it [00:37,  1.25s/it]\u001b[A\n",
      "30it [00:38,  1.25s/it]\u001b[A\n",
      "31it [00:39,  1.26s/it]\u001b[A\n",
      "32it [00:40,  1.26s/it]\u001b[A\n",
      "33it [00:42,  1.25s/it]\u001b[A\n",
      "34it [00:43,  1.25s/it]\u001b[A\n",
      "35it [00:44,  1.25s/it]\u001b[A\n",
      "36it [00:45,  1.25s/it]\u001b[A\n",
      "37it [00:47,  1.25s/it]\u001b[A\n",
      "38it [00:47,  1.25s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6581274725888905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██████████████████                                                                        | 1/5 [00:50<03:22, 50.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.58125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.96s/it]\u001b[A\n",
      "2it [00:03,  1.53s/it]\u001b[A\n",
      "3it [00:04,  1.40s/it]\u001b[A\n",
      "4it [00:05,  1.33s/it]\u001b[A\n",
      "5it [00:06,  1.29s/it]\u001b[A\n",
      "6it [00:08,  1.27s/it]\u001b[A\n",
      "7it [00:09,  1.26s/it]\u001b[A\n",
      "8it [00:10,  1.25s/it]\u001b[A\n",
      "9it [00:11,  1.24s/it]\u001b[A\n",
      "10it [00:13,  1.24s/it]\u001b[A\n",
      "11it [00:14,  1.23s/it]\u001b[A\n",
      "12it [00:15,  1.23s/it]\u001b[A\n",
      "13it [00:16,  1.23s/it]\u001b[A\n",
      "14it [00:17,  1.23s/it]\u001b[A\n",
      "15it [00:19,  1.23s/it]\u001b[A\n",
      "16it [00:20,  1.23s/it]\u001b[A\n",
      "17it [00:21,  1.23s/it]\u001b[A\n",
      "18it [00:22,  1.24s/it]\u001b[A\n",
      "19it [00:24,  1.24s/it]\u001b[A\n",
      "20it [00:25,  1.23s/it]\u001b[A\n",
      "21it [00:26,  1.23s/it]\u001b[A\n",
      "22it [00:27,  1.23s/it]\u001b[A\n",
      "23it [00:29,  1.23s/it]\u001b[A\n",
      "24it [00:30,  1.23s/it]\u001b[A\n",
      "25it [00:31,  1.23s/it]\u001b[A\n",
      "26it [00:32,  1.23s/it]\u001b[A\n",
      "27it [00:33,  1.23s/it]\u001b[A\n",
      "28it [00:35,  1.23s/it]\u001b[A\n",
      "29it [00:36,  1.23s/it]\u001b[A\n",
      "30it [00:37,  1.23s/it]\u001b[A\n",
      "31it [00:38,  1.23s/it]\u001b[A\n",
      "32it [00:40,  1.23s/it]\u001b[A\n",
      "33it [00:41,  1.23s/it]\u001b[A\n",
      "34it [00:42,  1.23s/it]\u001b[A\n",
      "35it [00:43,  1.24s/it]\u001b[A\n",
      "36it [00:45,  1.24s/it]\u001b[A\n",
      "37it [00:46,  1.24s/it]\u001b[A\n",
      "38it [00:46,  1.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5827304634608721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████████████████████████████████████                                                      | 2/5 [01:40<02:30, 50.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7541666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.52s/it]\u001b[A\n",
      "2it [00:02,  1.36s/it]\u001b[A\n",
      "3it [00:04,  1.31s/it]\u001b[A\n",
      "4it [00:05,  1.28s/it]\u001b[A\n",
      "5it [00:06,  1.26s/it]\u001b[A\n",
      "6it [00:07,  1.25s/it]\u001b[A\n",
      "7it [00:08,  1.25s/it]\u001b[A\n",
      "8it [00:10,  1.24s/it]\u001b[A\n",
      "9it [00:11,  1.24s/it]\u001b[A\n",
      "10it [00:12,  1.25s/it]\u001b[A\n",
      "11it [00:13,  1.24s/it]\u001b[A\n",
      "12it [00:15,  1.24s/it]\u001b[A\n",
      "13it [00:16,  1.24s/it]\u001b[A\n",
      "14it [00:17,  1.24s/it]\u001b[A\n",
      "15it [00:18,  1.23s/it]\u001b[A\n",
      "16it [00:20,  1.23s/it]\u001b[A\n",
      "17it [00:21,  1.23s/it]\u001b[A\n",
      "18it [00:22,  1.23s/it]\u001b[A\n",
      "19it [00:23,  1.23s/it]\u001b[A\n",
      "20it [00:24,  1.23s/it]\u001b[A\n",
      "21it [00:26,  1.24s/it]\u001b[A\n",
      "22it [00:27,  1.24s/it]\u001b[A\n",
      "23it [00:28,  1.25s/it]\u001b[A\n",
      "24it [00:30,  1.25s/it]\u001b[A\n",
      "25it [00:31,  1.24s/it]\u001b[A\n",
      "26it [00:32,  1.24s/it]\u001b[A\n",
      "27it [00:33,  1.24s/it]\u001b[A\n",
      "28it [00:34,  1.25s/it]\u001b[A\n",
      "29it [00:36,  1.25s/it]\u001b[A\n",
      "30it [00:37,  1.25s/it]\u001b[A\n",
      "31it [00:38,  1.24s/it]\u001b[A\n",
      "32it [00:39,  1.24s/it]\u001b[A\n",
      "33it [00:41,  1.25s/it]\u001b[A\n",
      "34it [00:42,  1.24s/it]\u001b[A\n",
      "35it [00:43,  1.24s/it]\u001b[A\n",
      "36it [00:44,  1.24s/it]\u001b[A\n",
      "37it [00:46,  1.24s/it]\u001b[A\n",
      "38it [00:46,  1.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4309445392144354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████████████████████████████████████████████████████                                    | 3/5 [02:29<01:39, 49.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7520833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.52s/it]\u001b[A\n",
      "2it [00:02,  1.36s/it]\u001b[A\n",
      "3it [00:03,  1.30s/it]\u001b[A\n",
      "4it [00:05,  1.27s/it]\u001b[A\n",
      "5it [00:06,  1.26s/it]\u001b[A\n",
      "6it [00:07,  1.25s/it]\u001b[A\n",
      "7it [00:08,  1.25s/it]\u001b[A\n",
      "8it [00:10,  1.25s/it]\u001b[A\n",
      "9it [00:11,  1.24s/it]\u001b[A\n",
      "10it [00:12,  1.24s/it]\u001b[A\n",
      "11it [00:13,  1.23s/it]\u001b[A\n",
      "12it [00:15,  1.23s/it]\u001b[A\n",
      "13it [00:16,  1.23s/it]\u001b[A\n",
      "14it [00:17,  1.24s/it]\u001b[A\n",
      "15it [00:18,  1.24s/it]\u001b[A\n",
      "16it [00:20,  1.24s/it]\u001b[A\n",
      "17it [00:21,  1.24s/it]\u001b[A\n",
      "18it [00:22,  1.24s/it]\u001b[A\n",
      "19it [00:23,  1.24s/it]\u001b[A\n",
      "20it [00:25,  1.23s/it]\u001b[A\n",
      "21it [00:26,  1.23s/it]\u001b[A\n",
      "22it [00:27,  1.23s/it]\u001b[A\n",
      "23it [00:28,  1.23s/it]\u001b[A\n",
      "24it [00:29,  1.24s/it]\u001b[A\n",
      "25it [00:31,  1.24s/it]\u001b[A\n",
      "26it [00:32,  1.23s/it]\u001b[A\n",
      "27it [00:33,  1.23s/it]\u001b[A\n",
      "28it [00:34,  1.23s/it]\u001b[A\n",
      "29it [00:36,  1.23s/it]\u001b[A\n",
      "30it [00:37,  1.23s/it]\u001b[A\n",
      "31it [00:38,  1.23s/it]\u001b[A\n",
      "32it [00:39,  1.23s/it]\u001b[A\n",
      "33it [00:41,  1.23s/it]\u001b[A\n",
      "34it [00:42,  1.23s/it]\u001b[A\n",
      "35it [00:43,  1.23s/it]\u001b[A\n",
      "36it [00:44,  1.23s/it]\u001b[A\n",
      "37it [00:45,  1.23s/it]\u001b[A\n",
      "38it [00:46,  1.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3585239115514253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████████████████                  | 4/5 [03:18<00:49, 49.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7729166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.49s/it]\u001b[A\n",
      "2it [00:02,  1.33s/it]\u001b[A\n",
      "3it [00:03,  1.29s/it]\u001b[A\n",
      "4it [00:05,  1.27s/it]\u001b[A\n",
      "5it [00:06,  1.26s/it]\u001b[A\n",
      "6it [00:07,  1.25s/it]\u001b[A\n",
      "7it [00:08,  1.24s/it]\u001b[A\n",
      "8it [00:10,  1.23s/it]\u001b[A\n",
      "9it [00:11,  1.23s/it]\u001b[A\n",
      "10it [00:12,  1.23s/it]\u001b[A\n",
      "11it [00:13,  1.24s/it]\u001b[A\n",
      "12it [00:15,  1.23s/it]\u001b[A\n",
      "13it [00:16,  1.23s/it]\u001b[A\n",
      "14it [00:17,  1.23s/it]\u001b[A\n",
      "15it [00:18,  1.23s/it]\u001b[A\n",
      "16it [00:19,  1.23s/it]\u001b[A\n",
      "17it [00:21,  1.24s/it]\u001b[A\n",
      "18it [00:22,  1.24s/it]\u001b[A\n",
      "19it [00:23,  1.24s/it]\u001b[A\n",
      "20it [00:24,  1.24s/it]\u001b[A\n",
      "21it [00:26,  1.24s/it]\u001b[A\n",
      "22it [00:27,  1.24s/it]\u001b[A\n",
      "23it [00:28,  1.24s/it]\u001b[A\n",
      "24it [00:29,  1.24s/it]\u001b[A\n",
      "25it [00:31,  1.24s/it]\u001b[A\n",
      "26it [00:32,  1.23s/it]\u001b[A\n",
      "27it [00:33,  1.24s/it]\u001b[A\n",
      "28it [00:34,  1.24s/it]\u001b[A\n",
      "29it [00:36,  1.23s/it]\u001b[A\n",
      "30it [00:37,  1.23s/it]\u001b[A\n",
      "31it [00:38,  1.24s/it]\u001b[A\n",
      "32it [00:39,  1.24s/it]\u001b[A\n",
      "33it [00:41,  1.24s/it]\u001b[A\n",
      "34it [00:42,  1.24s/it]\u001b[A\n",
      "35it [00:43,  1.24s/it]\u001b[A\n",
      "36it [00:44,  1.23s/it]\u001b[A\n",
      "37it [00:45,  1.23s/it]\u001b[A\n",
      "38it [00:46,  1.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24483988865425713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:08<00:00, 49.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7729166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesure de performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
