{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown as md\n",
    "from myst_nb import glue\n",
    "\n",
    "from bisect import bisect\n",
    "from bisect import bisect_left, bisect_right\n",
    "\n",
    "dfCodes = pd.read_csv(\"resources/data/u_codes.csv\")\n",
    "dfBeaches = pd.read_csv(\"resources/data/u_beaches.csv\")\n",
    "dfBeaches.set_index(\"slug\", inplace=True)\n",
    "\n",
    "all_data = pd.read_csv(\"resources/data/u_all_data.csv\")\n",
    "all_data = all_data[all_data.river_bassin != 'les-alpes'].copy()\n",
    "all_data[\"date\"] = pd.to_datetime(all_data[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# import regional labels. labels are used\n",
    "# to identify the regional priors\n",
    "lac_leman_regions = pd.read_csv(\"resources/data/lac_leman_regions.csv\")\n",
    "\n",
    "# map to code decriptions\n",
    "dfCodes.set_index(\"code\", inplace=True)\n",
    "dfCodes.loc[\"Gcaps\", [\"material\", \"description\", \"groupname\"]] = [\"Plastic\", \"Plastic bottle lids\", \"food and drink\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# this defines the css rules for the note-book table displays\n",
    "header_row = {'selector': 'th:nth-child(1)', 'props': f'background-color: #FFF; text-align:right'}\n",
    "even_rows = {\"selector\": 'tr:nth-child(even)', 'props': f'background-color: rgba(139, 69, 19, 0.08);'}\n",
    "odd_rows = {'selector': 'tr:nth-child(odd)', 'props': 'background: #FFF;'}\n",
    "table_font = {'selector': 'tr', 'props': 'font-size: 10px;'}\n",
    "table_data = {'selector': 'td', 'props': 'padding: 12px;'}\n",
    "table_caption = {'selector': 'caption', 'props': 'font-size: 14px; font-style: italic; caption-side: bottom; text-align: left; margin-top: 10px'}\n",
    "table_css_styles = [even_rows, odd_rows, table_font, header_row, table_caption]\n",
    "\n",
    "\n",
    "table_large_data = {'selector': 'tr', 'props': 'font-size: 14px; padding: 12px;'}\n",
    "table_large_font = [even_rows, odd_rows, table_large_data, header_row, table_caption]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Testing 2023 predictions\n",
    "\n",
    "## The solid waste experience\n",
    "\n",
    "This is the seventh year that the Solid Waste Team from the EPFL collect beach litter samples. In the maritime environment people have been measuring beach litter for decades. There is a standard protocol ([Guidance on Monitoring Marine Litter in European Seas](https://publications.jrc.ec.europa.eu/repository/handle/JRC83985)) for the EU area and threshold values for good environmental standing ([Beach litter thresholds](https://mcc.jrc.ec.europa.eu/main/dev.py?N=41&O=454)). \n",
    "\n",
    "In Switzerland we started monitoring shoreline trash in 2015, it was not obvious to most observers (except for Prof Ludwig) why this might be of interest. However, by 2016 the EU realized that monitoring trash flows in rivers and lakes ([monitoring trash in rivers](https://mcc.jrc.ec.europa.eu/documents/201703034325.pdf)) might be a good way to monitor flows into the oceans. All the while conservationists and biologists have raised concerns about the presence of plastics and diminshing biodiversity. The threshold established by the EU is based on the principle of precaution: _the health effects are unknown, it is prudent to reduce contact with plastics when possible_ ([Beach litter thresholds](https://mcc.jrc.ec.europa.eu/main/dev.py?N=41&O=454)).\n",
    "\n",
    "### Observations and interpretations\n",
    "\n",
    "A beach litter survey is a detailed observation of the quantity and type of objects that were found at the beach. This observation is further defined by the time and place it occured. The location of the beach litter survey can be described numerically using a topographical map and some common overlay techniques in QGIS.\n",
    "\n",
    "The information gathered from the map are part of the _conditions_ that describe a survey location in particular. When beach litter surveys are considered in terms of their shared attributes we can use very simple techniques to find correlations between the conditions and the amount of trash found. For example, we can use Spearmans ranked correlation coefficient to quickly identify topographical attributes where specfic objects tend to accumulate. We wrote an article about it:  ([Near or far](https://hammerdirt-analyst.github.io/landuse/titlepage.html)).\n",
    "\n",
    "### A unique problem and a unique solution\n",
    "\n",
    "Trash in the environment is a unique problem. In general we know how an object becomes litter: either on purpose or on accident, people create the conditions that increase the chance that an end of lifecycle object will evade the waste recovery system. Resources are employed to change the behavior of people and therefore improve the chance that an end of lifcycle object will be approriately discarded, _(need reference)_. \n",
    "\n",
    "There are public services that are dedicated to collecting inappropriately discarded items. Beach litter surveys are the observed result of the difference between the effect of the systems in place to reduce litter and the amount of litter produced. Indifferent of how that litter was produced or the measures in place to prevent it. Therefore this environmental assessment is reliant on individual observations. We can look to orntithologists and botanists for examples on how to interpret this data.\n",
    "\n",
    "```{admonition} Asessing the environment:\n",
    "\n",
    "__What and how much are the volunteers likely to find?__\n",
    "      \n",
    "_This is the most honest answer that can be derived from the data._\n",
    "```\n",
    "\n",
    "There are 336 observations from 66 locations that describe the conditions under which 73,000 items were found on the 145km shore-line of Lake Geneva. Although this is only a small portion of the lake shore, this is still a good amount of samples in a six year period. It would be difficult to find a comparable stretch of coastline anywhere in the world that has that many samples in seven years. We can use that data to form our opinion of what we might find on October 5th.\n",
    "\n",
    "```{admonition} Asessing the environment:\n",
    "\n",
    "We can not tell you how much there is. __Only how much you are likely to find.__\n",
    "      \n",
    "What the difference is between the two statements is a philosophical discussion. In reality it may be hard to make such a distinction.\n",
    "```\n",
    "\n",
    "\n",
    "### Reducing dimensionality: find the most common\n",
    "\n",
    "There are 228 different categories of objects. We are interested in what we might find and how likely we are to find it. Therefore we limit the search to items that were previously identified in at least 50% of the surveys AND/OR objects that are distinctive (easy to identify). This accounts for 74% of all objects previously recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def prior_distributions(prior_data: pd.DataFrame = None, start: str = None, end: str = None,\n",
    "                        xrange: np.array = None, uninformed_prior: np.array = None):\n",
    "    data_args = {\n",
    "        'start':start,\n",
    "        'end':end,\n",
    "        'data': prior_data,\n",
    "    }\n",
    "    prior_pcs = period_pieces(*data_args.values())         \n",
    "\n",
    "    # get n and k for the prior data\n",
    "    prior_k, prior_notk, prior_k_n_minus_k = period_k_and_n(prior_pcs, xrange)\n",
    "   \n",
    "    # make the likelihood parameters\n",
    "    lhx = list(zip(prior_k, prior_notk))\n",
    "\n",
    "    # make the prior distribution\n",
    "    p_ui, prior_bmean = make_expected(lhx, uninformed_prior, xrange)\n",
    "\n",
    "    # the uninformed beta approximation of the prior data\n",
    "    prior_beta = [period_beta(x) for x in prior_k_n_minus_k]\n",
    "    p_beta= [x.mean() for x in prior_beta]\n",
    "\n",
    "    results=pd.DataFrame({\"x\":xrange, \"p\":p_ui})\n",
    "    results[\"pn\"] = results.p/results.p.sum()\n",
    "    \n",
    "    return np.array(p_ui), np.array(p_beta), prior_k_n_minus_k, results, prior_pcs\n",
    "\n",
    "def posterior_distribution(lh_data: pd.DataFrame = None, start: str = None, end: str = None,\n",
    "                           informed_prior: np.array = None, un_informed: np.array = None):\n",
    "                               \n",
    "    \n",
    "    data_args = {\n",
    "        'start': start,\n",
    "        'end':end,\n",
    "        'data': lh_data,   \n",
    "        }\n",
    "\n",
    "    period_all = period_pieces(*data_args.values())\n",
    "    \n",
    "    pall_k, pall_notk, pall_k_n_minus_k = period_k_and_n(period_all, xrange)\n",
    "    \n",
    "    lh_and_informed = np.array(pall_k_n_minus_k) + np.array(informed_prior)\n",
    "    lhx = list(zip(pall_k, pall_notk))        \n",
    "    \n",
    "    probi, probi_beta = make_expected(pall_k_n_minus_k, np.array(informed_prior), xrange)\n",
    "    grid_prox, grid_prox_beta = make_expected(pall_k_n_minus_k, un_informed, xrange)\n",
    "    \n",
    "    # beta distribution \n",
    "    pall_beta = [period_beta((x[0]+1, x[1]+1)) for x in pall_k_n_minus_k]\n",
    "    pall_bmean = [x.mean() for x in pall_beta]\n",
    "    return np.array(probi), np.array(grid_prox), pall_bmean, period_all\n",
    "                               \n",
    "def training_testing_compare(lh_pcs, pcs, post_quants, prior_quants):\n",
    "    \n",
    "    total_training = len(pcs) + len(lh_pcs)\n",
    "    prior_weight = len(pcs)/total_training\n",
    "    lh_weight = len(lh_pcs)/total_training\n",
    "\n",
    "    number_of_samples = {\"before may 2021\": len(pcs), \"after may 2021\": len(lh_pcs)}\n",
    "    weights = {\"before may 2021\":prior_weight, \"after may 2021\": lh_weight}\n",
    "    observed_median = {\"before may 2021\":np.median(pcs), \"after may 2021\": np.median(lh_pcs)}\n",
    "    observed_average = {\"before may 2021\":np.mean(pcs), \"after may 2021\": np.mean(lh_pcs)}\n",
    "    observed_25 = {\"before may 2021\": prior_quants[1], \"after may 2021\":post_quants[1]}\n",
    "    observed_75 = {\"before may 2021\": prior_quants[5], \"after may 2021\":post_quants[5]}\n",
    "    index = [\"weight all samples\", \"Number of samples\", \"Median\", \"Average\", \"25th percentile\", \"75th percentile\"]\n",
    "    components = [weights, number_of_samples, observed_median, observed_average, observed_25, observed_75]\n",
    "    unks_sum_table = pd.DataFrame(components, index=index).style.format(precision=2).set_table_styles(table_large_font)\n",
    "    styled = unks_sum_table.format(formatter=\"{:.0f}\", subset=pd.IndexSlice[['Number of samples'], :])\n",
    "    \n",
    "    return styled\n",
    "\n",
    "def predicted_summary(lh_pcs, pcs, prior_quants, median_2024):\n",
    "    \n",
    "\n",
    "    predicted = ((lh_pcs <= prior_quants[5])&(lh_pcs >= prior_quants[1])).sum()/len(lh_pcs)\n",
    "    predicted_94 = ((lh_pcs <= prior_quants[-1])&(lh_pcs >= prior_quants[0])).sum()/len(lh_pcs)\n",
    "    past_present_future = {\n",
    "        \"Median 2021\": np.median(pcs), \n",
    "        \"Median 2022\": np.median(lh_pcs), \n",
    "        \"Expected sampling median 2024\":median_2024,\n",
    "        \"% 2022 in 50% IQR  predicted\": predicted,\n",
    "        \"% 2022 in 94% IQR  predicted\": predicted_94,\n",
    "    }\n",
    "        \n",
    "    \n",
    "    ppf = pd.DataFrame(past_present_future, index=[\"pcs/m\"]).T\n",
    "\n",
    "    return ppf\n",
    "\n",
    "\n",
    "def make_results_df(prior_df, lh_c, source=None, source_norm=None):\n",
    "    \n",
    "    prior_df[source] = lh_c\n",
    "    prior_df[source_norm] = prior_df[source]/prior_df[source].sum()\n",
    "\n",
    "    return prior_df\n",
    "\n",
    "def data_profile(all_data):\n",
    "    date_min = all_data[\"date\"].min()\n",
    "    date_max = all_data[\"date\"].max()\n",
    "\n",
    "    if \"location\" in all_data.columns:\n",
    "        nlocations = all_data.location.nunique()\n",
    "    else:\n",
    "        nlocations = all_data.slug.nunique()\n",
    "    ncodes = all_data.code.nunique()\n",
    "    ncities = all_data.city.nunique()\n",
    "    quantity = all_data.quantity.sum()\n",
    "    nsamples = all_data.loc_date.nunique()\n",
    "\n",
    "    a_profile = dict(\n",
    "        start = date_min,\n",
    "        end = date_max,\n",
    "        nlocations = nlocations,\n",
    "        ncodes = ncodes,\n",
    "        ncities = ncities,\n",
    "        quantity = quantity,\n",
    "        nsamples = nsamples\n",
    "    )\n",
    "\n",
    "    return a_profile\n",
    "\n",
    "def a_fail_rate(x, total_number_of_samples):\n",
    "    return x[\"fail\"].sum()/total_number_of_samples\n",
    "\n",
    "\n",
    "def the_most_abundant(x):\n",
    "    t = x.groupby(\"code\").quantity.sum().copy()\n",
    "    t.sort_values(\"quantity\", ascending=False, inplace=True)\n",
    "    return t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "use_groups =  {\n",
    "    'Personal hygiene':['G95', 'G96'],\n",
    "    'Personal consumption':['G30', 'Gcaps', 'G27'],\n",
    "    'Industrial/professional': ['G67', 'G89', 'G112'],\n",
    "    'Unknown':['Gfrags', 'Gfoam'],\n",
    "    'Recreation/sports': ['G70', 'G32'],\n",
    "    \n",
    "}\n",
    "\n",
    "use_groups_i =  {\n",
    "    'G95':'Personal hygiene',\n",
    "    'G96': 'Personal hygiene',\n",
    "    'G30':'Personal consumption',\n",
    "    'Gcaps':'Personal consumption',\n",
    "    'G27':'Personal consumption',\n",
    "    'G67':'Industrial/professional',\n",
    "    'G89':'Industrial/professional',\n",
    "    'G112': 'Industrial/professional',\n",
    "    'Gfoam':'Unknown',\n",
    "    'Gfrags':'Unknown',\n",
    "    'G70':'Recreation/sports',\n",
    "    'G32':'Recreation/sports',\n",
    "}\n",
    "\n",
    "abbrev_use_g = {'Unknown':'Unk','Personal consumption':'Pc', 'Personal hygiene': 'Ph',    'Recreation/sports': 'Rc', 'Industrial/professional':'Ip'}\n",
    "toi = list(use_groups_i.keys())\n",
    "cbdi = pd.read_csv(\"resources/data/u_pstk_iqaasl_all.csv\")\n",
    "not_these = ['amphion', 'anthy', 'excenevex', 'lugrin', 'meillerie', 'saint-disdille', 'tougues']\n",
    "cbd = cbdi[~cbdi.slug.isin(not_these)]\n",
    "ssp = cbd[(cbd.city == 'Saint-Sulpice (VD)')].copy()\n",
    "ssp['quantity'] = 0\n",
    "\n",
    "ssp.to_csv('resources/data/swt_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_68d33 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_68d33 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_68d33 tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_68d33 th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_68d33 caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_68d33\">\n",
       "  <caption>Table 1: The objects of interest. The average pcs/m per sample for each object. The fail rate is the % of all samples that the object appeared in.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68d33_level0_col0\" class=\"col_heading level0 col0\" >pcs/m</th>\n",
       "      <th id=\"T_68d33_level0_col1\" class=\"col_heading level0 col1\" >quantity</th>\n",
       "      <th id=\"T_68d33_level0_col2\" class=\"col_heading level0 col2\" >fail rate</th>\n",
       "      <th id=\"T_68d33_level0_col3\" class=\"col_heading level0 col3\" >% of total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >code</th>\n",
       "      <th class=\"index_name level1\" >object</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row0\" class=\"row_heading level0 row0\" >G112</th>\n",
       "      <th id=\"T_68d33_level1_row0\" class=\"row_heading level1 row0\" >Industrial pellets (nurdles)</th>\n",
       "      <td id=\"T_68d33_row0_col0\" class=\"data row0 col0\" >0.16</td>\n",
       "      <td id=\"T_68d33_row0_col1\" class=\"data row0 col1\" >2686</td>\n",
       "      <td id=\"T_68d33_row0_col2\" class=\"data row0 col2\" >0.22</td>\n",
       "      <td id=\"T_68d33_row0_col3\" class=\"data row0 col3\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row1\" class=\"row_heading level0 row1\" >G27</th>\n",
       "      <th id=\"T_68d33_level1_row1\" class=\"row_heading level1 row1\" >Cigarette filters</th>\n",
       "      <td id=\"T_68d33_row1_col0\" class=\"data row1 col0\" >1.12</td>\n",
       "      <td id=\"T_68d33_row1_col1\" class=\"data row1 col1\" >16458</td>\n",
       "      <td id=\"T_68d33_row1_col2\" class=\"data row1 col2\" >0.85</td>\n",
       "      <td id=\"T_68d33_row1_col3\" class=\"data row1 col3\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row2\" class=\"row_heading level0 row2\" >G30</th>\n",
       "      <th id=\"T_68d33_level1_row2\" class=\"row_heading level1 row2\" >Food wrappers; candy, snacks</th>\n",
       "      <td id=\"T_68d33_row2_col0\" class=\"data row2 col0\" >0.54</td>\n",
       "      <td id=\"T_68d33_row2_col1\" class=\"data row2 col1\" >6767</td>\n",
       "      <td id=\"T_68d33_row2_col2\" class=\"data row2 col2\" >0.86</td>\n",
       "      <td id=\"T_68d33_row2_col3\" class=\"data row2 col3\" >0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row3\" class=\"row_heading level0 row3\" >G32</th>\n",
       "      <th id=\"T_68d33_level1_row3\" class=\"row_heading level1 row3\" >Toys and party favors</th>\n",
       "      <td id=\"T_68d33_row3_col0\" class=\"data row3 col0\" >0.05</td>\n",
       "      <td id=\"T_68d33_row3_col1\" class=\"data row3 col1\" >606</td>\n",
       "      <td id=\"T_68d33_row3_col2\" class=\"data row3 col2\" >0.48</td>\n",
       "      <td id=\"T_68d33_row3_col3\" class=\"data row3 col3\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row4\" class=\"row_heading level0 row4\" >G67</th>\n",
       "      <th id=\"T_68d33_level1_row4\" class=\"row_heading level1 row4\" >Industrial sheeting</th>\n",
       "      <td id=\"T_68d33_row4_col0\" class=\"data row4 col0\" >0.30</td>\n",
       "      <td id=\"T_68d33_row4_col1\" class=\"data row4 col1\" >3356</td>\n",
       "      <td id=\"T_68d33_row4_col2\" class=\"data row4 col2\" >0.57</td>\n",
       "      <td id=\"T_68d33_row4_col3\" class=\"data row4 col3\" >0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row5\" class=\"row_heading level0 row5\" >G70</th>\n",
       "      <th id=\"T_68d33_level1_row5\" class=\"row_heading level1 row5\" >Shotgun cartridges</th>\n",
       "      <td id=\"T_68d33_row5_col0\" class=\"data row5 col0\" >0.08</td>\n",
       "      <td id=\"T_68d33_row5_col1\" class=\"data row5 col1\" >1030</td>\n",
       "      <td id=\"T_68d33_row5_col2\" class=\"data row5 col2\" >0.48</td>\n",
       "      <td id=\"T_68d33_row5_col3\" class=\"data row5 col3\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row6\" class=\"row_heading level0 row6\" >G89</th>\n",
       "      <th id=\"T_68d33_level1_row6\" class=\"row_heading level1 row6\" >Plastic construction waste</th>\n",
       "      <td id=\"T_68d33_row6_col0\" class=\"data row6 col0\" >0.14</td>\n",
       "      <td id=\"T_68d33_row6_col1\" class=\"data row6 col1\" >1970</td>\n",
       "      <td id=\"T_68d33_row6_col2\" class=\"data row6 col2\" >0.51</td>\n",
       "      <td id=\"T_68d33_row6_col3\" class=\"data row6 col3\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row7\" class=\"row_heading level0 row7\" >G95</th>\n",
       "      <th id=\"T_68d33_level1_row7\" class=\"row_heading level1 row7\" >Cotton bud/swab sticks</th>\n",
       "      <td id=\"T_68d33_row7_col0\" class=\"data row7 col0\" >0.39</td>\n",
       "      <td id=\"T_68d33_row7_col1\" class=\"data row7 col1\" >4777</td>\n",
       "      <td id=\"T_68d33_row7_col2\" class=\"data row7 col2\" >0.74</td>\n",
       "      <td id=\"T_68d33_row7_col3\" class=\"data row7 col3\" >0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row8\" class=\"row_heading level0 row8\" >G96</th>\n",
       "      <th id=\"T_68d33_level1_row8\" class=\"row_heading level1 row8\" >Sanitary pads /panty liners/tampons and applicators</th>\n",
       "      <td id=\"T_68d33_row8_col0\" class=\"data row8 col0\" >0.04</td>\n",
       "      <td id=\"T_68d33_row8_col1\" class=\"data row8 col1\" >373</td>\n",
       "      <td id=\"T_68d33_row8_col2\" class=\"data row8 col2\" >0.29</td>\n",
       "      <td id=\"T_68d33_row8_col3\" class=\"data row8 col3\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row9\" class=\"row_heading level0 row9\" >Gcaps</th>\n",
       "      <th id=\"T_68d33_level1_row9\" class=\"row_heading level1 row9\" >Plastic bottle lids</th>\n",
       "      <td id=\"T_68d33_row9_col0\" class=\"data row9 col0\" >0.31</td>\n",
       "      <td id=\"T_68d33_row9_col1\" class=\"data row9 col1\" >3953</td>\n",
       "      <td id=\"T_68d33_row9_col2\" class=\"data row9 col2\" >0.84</td>\n",
       "      <td id=\"T_68d33_row9_col3\" class=\"data row9 col3\" >0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row10\" class=\"row_heading level0 row10\" >Gfoam</th>\n",
       "      <th id=\"T_68d33_level1_row10\" class=\"row_heading level1 row10\" >Expanded polystyrene</th>\n",
       "      <td id=\"T_68d33_row10_col0\" class=\"data row10 col0\" >1.02</td>\n",
       "      <td id=\"T_68d33_row10_col1\" class=\"data row10 col1\" >12871</td>\n",
       "      <td id=\"T_68d33_row10_col2\" class=\"data row10 col2\" >0.81</td>\n",
       "      <td id=\"T_68d33_row10_col3\" class=\"data row10 col3\" >0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68d33_level0_row11\" class=\"row_heading level0 row11\" >Gfrags</th>\n",
       "      <th id=\"T_68d33_level1_row11\" class=\"row_heading level1 row11\" >Fragmented plastics</th>\n",
       "      <td id=\"T_68d33_row11_col0\" class=\"data row11 col0\" >1.34</td>\n",
       "      <td id=\"T_68d33_row11_col1\" class=\"data row11 col1\" >17479</td>\n",
       "      <td id=\"T_68d33_row11_col2\" class=\"data row11 col2\" >0.93</td>\n",
       "      <td id=\"T_68d33_row11_col3\" class=\"data row11 col3\" >0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daab1bec730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cbd = cbd[cbd.code.isin(toi)].copy()\n",
    "cbd[\"fail\"] = cbd.quantity > 0\n",
    "\n",
    "\n",
    "cbd.loc[cbd.Project == \"Testing\", \"Project\"] = \"after may 2021\"\n",
    "cbd.loc[cbd.Project == \"Training\", \"Project\"] = \"before may 2021\"\n",
    "\n",
    "column_names_groups = {v:k for k,v in abbrev_use_g.items()}\n",
    "code_groups = list(column_names_groups.keys())\n",
    "\n",
    "cois = cities_of_interest = ['Saint-Sulpice (VD)', 'Saint Gingolph', 'Genéve', 'Cully', 'Vevey']\n",
    "\n",
    "some_quants = [.03, .25, .48, .5, .52, .75, .97]\n",
    "end_training_date = \"2021-05-31\"\n",
    "begin_training_date = \"2015-11-15\"\n",
    "codes_of_interest = cbd.groupby([\"code\"], as_index=False).agg({\"quantity\":\"sum\", \"pcs/m\":\"mean\", \"fail\": \"sum\"})\n",
    "codes_of_interest[\"fail rate\"] = (codes_of_interest.fail/cbd.loc_date.nunique()).round(2)\n",
    "code_d = dfCodes[\"description\"]\n",
    "codes_of_interest[\"object\"] = codes_of_interest.code.apply(lambda x: code_d.loc[x])\n",
    "codes_of_interest = codes_of_interest[[\"code\", \"object\", \"pcs/m\", \"quantity\", \"fail rate\"]]\n",
    "codes_of_interest.set_index([\"code\", \"object\"], inplace=True, drop=True)\n",
    "codes_of_interest[\"quantity\"] = codes_of_interest.quantity.astype(\"int\")\n",
    "codes_of_interest[\"% of total\"] = (codes_of_interest.quantity/cbdi.quantity.sum()).round(2)\n",
    "codes_of_interest.index.name = None\n",
    "caption = \"Table 1: The objects of interest. The average pcs/m per sample for each object. The fail rate is the % of all samples that the object appeared in.\" \n",
    "codes_of_interest.style.format(precision=2).set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Assessing the environment\n",
    "\n",
    "{Download}`Download the form </resources/figures/survey_estimates.pdf>`\n",
    "\n",
    "The goal for todays excercise in 2023 is to determine how well our previous experiences inform us about the present. This is a simple process. There are four steps:\n",
    "\n",
    "1. Start with your current understanding of the problem, consult the data here and form an opinion of how many of each item in the previous section you might find in 100 meters of shoreline. For example your might think 200 cigarette ends per 100m is a likely amount.\n",
    "2. Use the provided form and note your estimate for each item in red ink. Put your name on the form and the name of the beach.\n",
    "3. At the end of the litter survey note what you found for each item.\n",
    "\n",
    "After the survey we will compare what we found to what we though we might find and the predicted amount using the model that was explained in the previous section. \n",
    "\n",
    "### Semester project\n",
    "\n",
    "The semester project (if you choose to do it) is about documenting the process of updating the models and accessing data. It could be a narrated screencast. Something that next years class will consult. For those who are interested in data-science or application development we would be using python, R, Git and Annaconda.\n",
    "\n",
    "Specifically we would be adding survey results from this years experience:\n",
    "1. The results for Gfoams\n",
    "2. The reults for Plage de Pélican\n",
    "\n",
    "However, if you have done a data-science course or if you have some experience with application development you might find this an easy project that will allow you to demonstrate those skills and some creativity. Those that know how to use Git and Annaconda will find this fairly easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(data-context)=\n",
    "## Summary of previous results\n",
    "\n",
    "__Lake Geneva sample totals__\n",
    "\n",
    "The total pcs/m for all surveys is given in figure 1 and figure 2. Samples after May 2021 are considered separately, this is a new six year sampling period for the lake.  The distribution of the sample totals is given in table 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```{figure} resources/figures/lac-leman_city_labels.jpeg\n",
    "---\n",
    "name: lac_leman_cities\n",
    "---\n",
    "Previous survey results from Lake Geneva\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "summ_data = cbd.copy()\n",
    "\n",
    "summ_data[\"use group\"] = summ_data.code.map(lambda x: use_groups_i[x])\n",
    "\n",
    "summ_data[\"ug\"] = summ_data[\"use group\"].apply(lambda x: abbrev_use_g[x])\n",
    "summ_data[summ_data[\"use group\"] == 'Personal consumption'].code.unique()\n",
    "summ_data[\"date\"] = pd.to_datetime(summ_data[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "sd_x = summ_data.groupby([\"loc_date\", \"date\", \"city\", \"Project\", \"doy\"], as_index=False).agg({\"pcs/m\": 'sum', 'quantity':'sum'})\n",
    "sd_x_sp = sd_x[sd_x.city == 'Saint-Sulpice (VD)'].groupby([\"loc_date\", \"date\", \"city\", \"Project\", \"doy\"], as_index=False).agg({\"pcs/m\": 'sum', 'quantity':'sum'})\n",
    "\n",
    "trg = summ_data[summ_data.Project == \"before may 2021\"].copy()\n",
    "tst = summ_data[summ_data.Project == \"after may 2021\"].copy()\n",
    "trg_c, tst_c = trg.city.nunique(), tst.city.nunique()\n",
    "trg_lc, tst_lc = trg.slug.nunique(), tst.slug.nunique()\n",
    "trg_q, tst_q = trg.quantity.sum(), tst.quantity.sum()\n",
    "\n",
    "data_magnitude = [\n",
    "    {\"before may 2021\":trg_c, \"after may 2021\":tst_c},\n",
    "    {\"before may 2021\":trg_lc, \"after may 2021\":tst_lc},\n",
    "    {\"before may 2021\":trg_q, \"after may 2021\":tst_q}\n",
    "    \n",
    "]\n",
    "\n",
    "cities_set = list(set([*trg.city.unique(), *tst.city.unique()]))\n",
    "n_ind_cities = len(cities_set)\n",
    "\n",
    "caption = f'The number of different locations and cities for the data. Note that there are {n_ind_cities} different municipalitites in all.'\n",
    "\n",
    "data_summ_q = pd.DataFrame(data_magnitude, index=[\"Number of cities\", \"Number of locations\", \"Total objects\"]).astype('int')\n",
    "data_summ_q = data_summ_q.style.format(formatter=\"{:,}\").set_table_styles(table_large_font).set_caption(caption)\n",
    "styled = data_summ_q.format(formatter=\"{:,}\", subset=pd.IndexSlice[['Total objects'], :])\n",
    "glue(\"data-summ-q3\", styled, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# all the data by date\n",
    "the_99th_percentile = np.quantile(sd_x['pcs/m'].values, .99)\n",
    "px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "fig, ax = plt.subplots(figsize=(600*px,500*px))\n",
    "\n",
    "sns.scatterplot(data=sd_x, x='date', y='pcs/m',ax=ax, color=\"dodgerblue\", alpha=0.6,label=\"lac léman\")\n",
    "sns.scatterplot(data=sd_x_sp, x='date', y='pcs/m', color=\"magenta\", label=\"solid-waste-team\", ax=ax)\n",
    "\n",
    "ax.set_ylim(-1, the_99th_percentile)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel(\"\")\n",
    "glue(\"testing_training_chrono_2\", fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# all the data day of year\n",
    "fig, ax = plt.subplots(figsize=(600*px, 500*px))\n",
    "\n",
    "sns.scatterplot(data=sd_x, x='doy', y='pcs/m', ax=ax, color=\"dodgerblue\", alpha=0.6,label=\"lac léman\")\n",
    "sns.scatterplot(data=sd_x_sp, x='doy', y='pcs/m', color=\"magenta\", label=\"solid-waste-team\", ax=ax)\n",
    "ax.set_ylim(-1, the_99th_percentile)\n",
    "ax.set_xlabel(\"Day of the year\")\n",
    "glue('testing_training_doy_2', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "testing_vals= sd_x[sd_x.Project == \"after may 2021\"]['pcs/m'].values\n",
    "training_vals = sd_x[sd_x.Project == \"before may 2021\"]['pcs/m'].values\n",
    "\n",
    "\n",
    "train_quantiles = np.quantile(training_vals, some_quants)\n",
    "test_quantiles = np.quantile(testing_vals, some_quants)\n",
    "\n",
    "training_testing_summary = training_testing_compare(testing_vals, training_vals, test_quantiles, train_quantiles)\n",
    "caption = \"The observed values from the training and testing data. Remark that the testing data is only 22% of all the data. This is because we are only in the first year of a six year sampling period\"\n",
    "sum_table = training_testing_summary.set_caption(caption)\n",
    "sum_table.format(formatter=\"{:.0f}\", subset=pd.IndexSlice[['Number of samples'], :])\n",
    "glue(\"data-summary_2\", sum_table, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "|Figure 1, Table 2 | Table 3, Figure 2|\n",
    "|:-----------------------:|:---------------------:|\n",
    "|{glue:}`testing_training_chrono_2` |{glue}`data-summary_2`|\n",
    "|{glue:}`data-summ-q3`|{glue}`testing_training_doy_2`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def sampler_from_multinomial(normed, xrange, nsamples):\n",
    "    \n",
    "    choose = np.random.default_rng()\n",
    "    nunique = np.unique(normed)\n",
    "    norm_nunique = nunique/np.sum(nunique)\n",
    "    found = choose.multinomial(1, pvals=norm_nunique, size=nsamples)\n",
    "    ft = found.sum(axis=0)\n",
    "    samples = []\n",
    "    for i, asum in enumerate(ft):\n",
    "        if asum == 0:\n",
    "            samples += [0]\n",
    "        else:\n",
    "            choices = np.where(normed == nunique[i])\n",
    "            samps = choose.choice(choices[0], size=asum)\n",
    "            samples.extend(xrange[samps])\n",
    "\n",
    "    return samples, nunique, norm_nunique, ft\n",
    "\n",
    "def period_pieces(start, end, data):\n",
    "    # the results in pieces per meter for one code from a subset of data\n",
    "    date_mask = (data[\"date\"] >= start) & (data[\"date\"] <= end)\n",
    "    period_one = data[date_mask]\n",
    "    pone_pcs = period_one.pcs_m.values\n",
    "\n",
    "    return pone_pcs\n",
    "\n",
    "def period_k_and_n(data, xrange, add_one=False):\n",
    "\n",
    "    pone_k = [(data >= x).sum() for x in xrange]\n",
    "    pone_notk = [(data < x).sum() for x in xrange]\n",
    "\n",
    "    if add_one:\n",
    "        # if the use is for beta dist. This is the same\n",
    "        # as mulitplying the likelihood * uninform prior (0.5) or beta(1,1)\n",
    "        pone_k_n_minus_k = [(x+1, len(data) - x+1) for x in pone_k]\n",
    "    else:\n",
    "        pone_k_n_minus_k = [(x, len(data) - x) for x in pone_k]\n",
    "        \n",
    "    \n",
    "\n",
    "    return np.array(pone_k), np.array(pone_notk), np.array(pone_k_n_minus_k)\n",
    "\n",
    "def period_beta(k):\n",
    "    \n",
    "         \n",
    "    return beta(*k)\n",
    "        \n",
    "\n",
    "def current_possible_prior_locations(landuse, locations, attribute):    \n",
    "\n",
    "    # indentify the magnitude(s) of the attribute of interest from the\n",
    "    # locations in the current data there may be more than one, in this \n",
    "    # example we use all the possible magnitudes for the attribute\n",
    "    # locations = data[data.city == city].location.unique()\n",
    "\n",
    "    # magnitudes for the attribute from all the locations in the municipality\n",
    "    moa = magnitude_of_attribute = landuse.loc[locations][attribute].unique().astype('int')\n",
    "\n",
    "    # identify locations that have the same attribute by magnitude of attribute\n",
    "    possible_locations = landuse[landuse[attribute].isin(moa)].index\n",
    "\n",
    "    # remove the locations that are in the likelihood function\n",
    "    prior_locations = [x for x in possible_locations if x not in locations]\n",
    "\n",
    "    return locations, possible_locations, prior_locations\n",
    "\n",
    "\n",
    "def make_expected(lh_tuple, prior_tuple, xrange):\n",
    "    res = []\n",
    "    betas=[]\n",
    "    # print(lh_tuple, prior_tuple)\n",
    "    for i in np.arange(len(xrange)):\n",
    "        alpha = prior_tuple[i][0]\n",
    "        betai = prior_tuple[i][1]\n",
    "        success = lh_tuple[i][0]\n",
    "        n = lh_tuple[i][1] + lh_tuple[i][0] \n",
    "        numerator = alpha + success\n",
    "        denominator = alpha + betai + n\n",
    "        if numerator == 0:\n",
    "            numerator = 1\n",
    "        abeta = beta(numerator, (betai + lh_tuple[i][1] + lh_tuple[i][0])).mean()\n",
    "        betas.append(abeta)\n",
    "        # print(alpha, betai, success, numerator, n, denominator)\n",
    "        if numerator >= denominator:\n",
    "            numerator = denominator-1\n",
    "            \n",
    "        expected = numerator/denominator\n",
    "        res.append(expected)\n",
    "    return np.array(res), np.array(betas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "an_xrange = np.arange(0, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "comb_lu_agg = pd.read_csv(\"resources/data/u_comb_lu_cover_street_rivers.csv\")\n",
    "\n",
    "lu_scaled = comb_lu_agg.pivot(columns=\"use\", values=\"scaled\", index=\"slug\").fillna(0)\n",
    "\n",
    "lu_magnitude = comb_lu_agg.pivot(columns=\"use\", values=\"magnitude\", index=\"slug\").fillna(0)\n",
    "\n",
    "lu_binned = comb_lu_agg.pivot(columns=\"use\", values=\"binned\", index=\"slug\").fillna(0)\n",
    "\n",
    "# not_these = ['amphion', 'anthy', 'excenevex', 'lugrin', 'meillerie', 'saint-disdille', 'tougues']\n",
    "merge_locations = cbd.slug.unique()\n",
    "cbdu = cbd[~cbd.slug.isin(not_these)].merge(lu_scaled[lu_scaled.index.isin(merge_locations )], left_on=\"slug\", right_index=True, validate=\"many_to_one\", how=\"outer\")\n",
    "\n",
    "cbdu[\"use group\"] = cbdu.code.map(lambda x: use_groups_i[x])\n",
    "\n",
    "cbdu[\"ug\"] = cbdu[\"use group\"].apply(lambda x: abbrev_use_g[x])\n",
    "cbdu[cbdu[\"use group\"] == 'Personal consumption'].code.unique()\n",
    "cbdu[\"date\"] = pd.to_datetime(cbdu[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "attribute_columns = [x for x in lu_scaled.columns if x not in [\"Geroell\", \"Stausee\", \"See\", \"Sumpf\", \"Stadtzentr\", \"Fels\"]]\n",
    "work_columns = [x for x in cbdu.columns if x not in [\"Geroell\", \"Stausee\", \"See\", \"Sumpf\", \"Stadtzentr\", \"Fels\"]]\n",
    "cbdu = cbdu[work_columns].copy()\n",
    "cbdu.rename(columns={\"pcs/m\":\"pcs_m\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Expected survey results Saint Sulpice\n",
    "\n",
    "### Predicted values using empirical Bayes method\n",
    "\n",
    "The method proposed in chapter two produced the following expected survey results for October 5, 2023 at Saint Sulpice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<!-- |     Figure 11, Table 11  |    Table 12, Figure 12       | \n",
    "|:------------------------:|:----------------------------:|\n",
    "|{glue:}`ssp-outlook-2024` | {glue:}`ssp-2024-meds`|\n",
    "|{glue:}`ssp-summary` | {glue:}`ssp-predicted_samples`| -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "city =  'Saint-Sulpice (VD)'\n",
    "start, end = \"2015-11-15\", \"2021-05-31\"\n",
    "index_range = (0.0, 10)\n",
    "xrange =  np.arange(*index_range, step=.01)\n",
    "uninformed_tuple = np.array([(1,1) for x in xrange])\n",
    "\n",
    "\n",
    "g_resa = cbdu.copy()\n",
    "g_resa = g_resa.groupby(['loc_date', 'date','slug', 'city', 'Project', 'code'], as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "g_resadt = g_resa.groupby(['loc_date', 'date','slug', 'city', 'Project'], as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "\n",
    "# define the prior, likelihood data and likelihood locations\n",
    "posterior_df = pd.DataFrame(index=xrange)\n",
    "predictions = {}\n",
    "\n",
    "for code in toi:\n",
    "    \n",
    "    # code_index = 1\n",
    "    city_index = 0\n",
    "    attribute_index = 2\n",
    "    \n",
    "    this_code =  code\n",
    "    this_attribute = attribute_columns[attribute_index]\n",
    "    this_city = cois[city_index]\n",
    "    \n",
    "    prior_data = g_resa[(g_resa.code == this_code)&(g_resa.city != city)&(g_resa.Project ==\"before may 2021\")]\n",
    "    lh_data = g_resa[(g_resa.code == this_code)&(g_resa.city == city)]\n",
    "\n",
    "    # here the locations from Saint Sulpice are indentified\n",
    "    lh_locations = lh_data.slug.unique()\n",
    "\n",
    "    # remove any location with no land-use data\n",
    "    regions = lac_leman_regions[~lac_leman_regions.slug.isin(not_these)].copy()\n",
    "    # identify the region of interest\n",
    "    lh_regions = regions[regions.slug.isin(lh_locations)].alabel.unique()\n",
    "    # retireve any other survey locations in the region\n",
    "    regional_locations = regions[regions.alabel.isin(lh_regions)].slug.unique()\n",
    "    # retrieve the land use values of all locations in the region\n",
    "    land_use_data_of_interest = lu_binned.loc[regional_locations]\n",
    "\n",
    "    # the locations from Saint Sulpice as well as regional locations are passed\n",
    "    # to the current_possible_prior_locations method. The land use values are\n",
    "    # compared and the locations with similar land use values are identified.\n",
    "    locations, possible_locations, prior_locations = current_possible_prior_locations(land_use_data_of_interest, lh_locations, this_attribute)\n",
    "    \n",
    "    prior_args = {\n",
    "        'prior_data':prior_data[prior_data.slug.isin(prior_locations)],\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'xrange':xrange,\n",
    "        'uninformed_prior': uninformed_tuple,\n",
    "    }\n",
    "    # grid approximation of the prior\n",
    "    grid_prior, beta_prior, prior_k_n, prior_df, pcs = prior_distributions(**prior_args)\n",
    "    \n",
    "    posterior_args = {\n",
    "        'lh_data':lh_data,\n",
    "        'start': start,\n",
    "        'end': \"2022-12-31\",\n",
    "        'un_informed': uninformed_tuple,\n",
    "        'informed_prior': prior_k_n\n",
    "    }\n",
    "    \n",
    "    # grid approximation of posterior\n",
    "    informed, uninformed, beta_p, lh_pcs = posterior_distribution(**posterior_args)\n",
    "    \n",
    "    # the quantiles from the observed data\n",
    "    prior_quants = np.quantile(pcs, some_quants)\n",
    "    post_quants = np.quantile(lh_pcs, some_quants)\n",
    "    \n",
    "    # data frame with normalized results\n",
    "    post_df = make_results_df(prior_df.copy(), informed, source=\"Informed post\", source_norm=\"Ip_n\")\n",
    "    post_df = make_results_df(post_df, uninformed, source=\"Uninformed post\", source_norm=\"Un_n\")\n",
    "    \n",
    "    # samples from posterior \n",
    "    sim_2024 = sampler_from_multinomial(post_df[\"Ip_n\"].values, xrange, len(pcs) + len(lh_pcs))\n",
    "    sim_quants = np.quantile(sim_2024[0], some_quants)\n",
    "    \n",
    "    \n",
    "    predictions.update({this_code:sim_quants})\n",
    "    posterior_df[this_code]=informed\n",
    "\n",
    "index = ['{:.0%}'.format(x) for x in some_quants]\n",
    "pred_quants = pd.DataFrame(predictions, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_87d8d tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_87d8d tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_87d8d tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_87d8d th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_87d8d caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_87d8d\">\n",
       "  <caption>Table 4: The 94% probability interval of the objects of interest for Saint Sulpice. The median value is used for the predictions</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_87d8d_level0_col0\" class=\"col_heading level0 col0\" >G112</th>\n",
       "      <th id=\"T_87d8d_level0_col1\" class=\"col_heading level0 col1\" >G27</th>\n",
       "      <th id=\"T_87d8d_level0_col2\" class=\"col_heading level0 col2\" >G30</th>\n",
       "      <th id=\"T_87d8d_level0_col3\" class=\"col_heading level0 col3\" >G32</th>\n",
       "      <th id=\"T_87d8d_level0_col4\" class=\"col_heading level0 col4\" >G67</th>\n",
       "      <th id=\"T_87d8d_level0_col5\" class=\"col_heading level0 col5\" >G70</th>\n",
       "      <th id=\"T_87d8d_level0_col6\" class=\"col_heading level0 col6\" >G95</th>\n",
       "      <th id=\"T_87d8d_level0_col7\" class=\"col_heading level0 col7\" >G96</th>\n",
       "      <th id=\"T_87d8d_level0_col8\" class=\"col_heading level0 col8\" >Gcaps</th>\n",
       "      <th id=\"T_87d8d_level0_col9\" class=\"col_heading level0 col9\" >Gfrags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row0\" class=\"row_heading level0 row0\" >3%</th>\n",
       "      <td id=\"T_87d8d_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col1\" class=\"data row0 col1\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col5\" class=\"data row0 col5\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col6\" class=\"data row0 col6\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col7\" class=\"data row0 col7\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col8\" class=\"data row0 col8\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row0_col9\" class=\"data row0 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row1\" class=\"row_heading level0 row1\" >25%</th>\n",
       "      <td id=\"T_87d8d_row1_col0\" class=\"data row1 col0\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col3\" class=\"data row1 col3\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col4\" class=\"data row1 col4\" >0.05</td>\n",
       "      <td id=\"T_87d8d_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col6\" class=\"data row1 col6\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col7\" class=\"data row1 col7\" >0.03</td>\n",
       "      <td id=\"T_87d8d_row1_col8\" class=\"data row1 col8\" >0.00</td>\n",
       "      <td id=\"T_87d8d_row1_col9\" class=\"data row1 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row2\" class=\"row_heading level0 row2\" >48%</th>\n",
       "      <td id=\"T_87d8d_row2_col0\" class=\"data row2 col0\" >0.07</td>\n",
       "      <td id=\"T_87d8d_row2_col1\" class=\"data row2 col1\" >0.43</td>\n",
       "      <td id=\"T_87d8d_row2_col2\" class=\"data row2 col2\" >0.12</td>\n",
       "      <td id=\"T_87d8d_row2_col3\" class=\"data row2 col3\" >0.03</td>\n",
       "      <td id=\"T_87d8d_row2_col4\" class=\"data row2 col4\" >0.13</td>\n",
       "      <td id=\"T_87d8d_row2_col5\" class=\"data row2 col5\" >0.01</td>\n",
       "      <td id=\"T_87d8d_row2_col6\" class=\"data row2 col6\" >0.22</td>\n",
       "      <td id=\"T_87d8d_row2_col7\" class=\"data row2 col7\" >0.09</td>\n",
       "      <td id=\"T_87d8d_row2_col8\" class=\"data row2 col8\" >0.07</td>\n",
       "      <td id=\"T_87d8d_row2_col9\" class=\"data row2 col9\" >0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row3\" class=\"row_heading level0 row3\" >50%</th>\n",
       "      <td id=\"T_87d8d_row3_col0\" class=\"data row3 col0\" >0.14</td>\n",
       "      <td id=\"T_87d8d_row3_col1\" class=\"data row3 col1\" >0.44</td>\n",
       "      <td id=\"T_87d8d_row3_col2\" class=\"data row3 col2\" >0.13</td>\n",
       "      <td id=\"T_87d8d_row3_col3\" class=\"data row3 col3\" >0.03</td>\n",
       "      <td id=\"T_87d8d_row3_col4\" class=\"data row3 col4\" >0.15</td>\n",
       "      <td id=\"T_87d8d_row3_col5\" class=\"data row3 col5\" >0.02</td>\n",
       "      <td id=\"T_87d8d_row3_col6\" class=\"data row3 col6\" >0.28</td>\n",
       "      <td id=\"T_87d8d_row3_col7\" class=\"data row3 col7\" >0.09</td>\n",
       "      <td id=\"T_87d8d_row3_col8\" class=\"data row3 col8\" >0.07</td>\n",
       "      <td id=\"T_87d8d_row3_col9\" class=\"data row3 col9\" >0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row4\" class=\"row_heading level0 row4\" >52%</th>\n",
       "      <td id=\"T_87d8d_row4_col0\" class=\"data row4 col0\" >0.17</td>\n",
       "      <td id=\"T_87d8d_row4_col1\" class=\"data row4 col1\" >0.46</td>\n",
       "      <td id=\"T_87d8d_row4_col2\" class=\"data row4 col2\" >0.14</td>\n",
       "      <td id=\"T_87d8d_row4_col3\" class=\"data row4 col3\" >0.03</td>\n",
       "      <td id=\"T_87d8d_row4_col4\" class=\"data row4 col4\" >0.16</td>\n",
       "      <td id=\"T_87d8d_row4_col5\" class=\"data row4 col5\" >0.03</td>\n",
       "      <td id=\"T_87d8d_row4_col6\" class=\"data row4 col6\" >0.30</td>\n",
       "      <td id=\"T_87d8d_row4_col7\" class=\"data row4 col7\" >0.09</td>\n",
       "      <td id=\"T_87d8d_row4_col8\" class=\"data row4 col8\" >0.07</td>\n",
       "      <td id=\"T_87d8d_row4_col9\" class=\"data row4 col9\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row5\" class=\"row_heading level0 row5\" >75%</th>\n",
       "      <td id=\"T_87d8d_row5_col0\" class=\"data row5 col0\" >0.61</td>\n",
       "      <td id=\"T_87d8d_row5_col1\" class=\"data row5 col1\" >0.92</td>\n",
       "      <td id=\"T_87d8d_row5_col2\" class=\"data row5 col2\" >0.43</td>\n",
       "      <td id=\"T_87d8d_row5_col3\" class=\"data row5 col3\" >0.07</td>\n",
       "      <td id=\"T_87d8d_row5_col4\" class=\"data row5 col4\" >0.30</td>\n",
       "      <td id=\"T_87d8d_row5_col5\" class=\"data row5 col5\" >0.05</td>\n",
       "      <td id=\"T_87d8d_row5_col6\" class=\"data row5 col6\" >0.48</td>\n",
       "      <td id=\"T_87d8d_row5_col7\" class=\"data row5 col7\" >0.12</td>\n",
       "      <td id=\"T_87d8d_row5_col8\" class=\"data row5 col8\" >0.22</td>\n",
       "      <td id=\"T_87d8d_row5_col9\" class=\"data row5 col9\" >0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d8d_level0_row6\" class=\"row_heading level0 row6\" >97%</th>\n",
       "      <td id=\"T_87d8d_row6_col0\" class=\"data row6 col0\" >1.02</td>\n",
       "      <td id=\"T_87d8d_row6_col1\" class=\"data row6 col1\" >1.44</td>\n",
       "      <td id=\"T_87d8d_row6_col2\" class=\"data row6 col2\" >1.85</td>\n",
       "      <td id=\"T_87d8d_row6_col3\" class=\"data row6 col3\" >0.19</td>\n",
       "      <td id=\"T_87d8d_row6_col4\" class=\"data row6 col4\" >0.55</td>\n",
       "      <td id=\"T_87d8d_row6_col5\" class=\"data row6 col5\" >0.12</td>\n",
       "      <td id=\"T_87d8d_row6_col6\" class=\"data row6 col6\" >0.91</td>\n",
       "      <td id=\"T_87d8d_row6_col7\" class=\"data row6 col7\" >0.36</td>\n",
       "      <td id=\"T_87d8d_row6_col8\" class=\"data row6 col8\" >0.35</td>\n",
       "      <td id=\"T_87d8d_row6_col9\" class=\"data row6 col9\" >1.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daaa7e47a00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = [\"G112\", \"G27\", \"G30\", \"G32\", \"G67\", \"G70\", \"G95\", \"G96\", \"Gcaps\", \"Gfrags\"]\n",
    "pred_quants = pred_quants[objects]\n",
    "caption = \"Table 4: The 94% probability interval of the objects of interest for Saint Sulpice. The median value is used for the predictions\"\n",
    "pred_quants.style.format(precision=2).set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Recall that the previous results from Saint Sulpice are not used to make the predictions. Only locations in the same region with similar land-use characteristics are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Estimates from participants\n",
    "\n",
    "After a classroom discusion and review of the previous years results (but not the predicted results) the participants made an estimate of how many they expect to find of each item of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "length_p = 49.3\n",
    "\n",
    "estimated_p =[\n",
    "    [.16, 1.12, .54, .05, .30, .08, .39, .04, .31, 1.34],\n",
    "    [6, 3, .6, .1, .4, .03, .8, 1, 2, 1.34],\n",
    "    [.4, 1.5, .3, .1, 1.1, .01, .5, .2, .4, 2]    \n",
    "]\n",
    "\n",
    "def make_rows(estimated, objects):\n",
    "    rows = []\n",
    "    for row in estimated:\n",
    "        row = {objects[i]: x for i,x in enumerate(row)}\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "found_p = [4, 51, 7, 2, 0, 0, 12, 1, 12, 266]\n",
    "found_pm = [x/length_p for x in found_p]\n",
    "\n",
    "pierrette_rows = make_rows(estimated_p, objects)\n",
    "pierrette = pd.DataFrame(pierrette_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "found_pel = [4, 51, 7, 2, 0, 0, 12, 1, 12, 266]\n",
    "found_pelm = [x/length_p for x in found_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_177b5 tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_177b5 tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_177b5 tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_177b5 th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_177b5 caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_177b5\">\n",
       "  <caption>Table 5: The estimated amount in pcs/meter for each object that the participants expected to find.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_177b5_level0_col0\" class=\"col_heading level0 col0\" >G112</th>\n",
       "      <th id=\"T_177b5_level0_col1\" class=\"col_heading level0 col1\" >G27</th>\n",
       "      <th id=\"T_177b5_level0_col2\" class=\"col_heading level0 col2\" >G30</th>\n",
       "      <th id=\"T_177b5_level0_col3\" class=\"col_heading level0 col3\" >G32</th>\n",
       "      <th id=\"T_177b5_level0_col4\" class=\"col_heading level0 col4\" >G67</th>\n",
       "      <th id=\"T_177b5_level0_col5\" class=\"col_heading level0 col5\" >G70</th>\n",
       "      <th id=\"T_177b5_level0_col6\" class=\"col_heading level0 col6\" >G95</th>\n",
       "      <th id=\"T_177b5_level0_col7\" class=\"col_heading level0 col7\" >G96</th>\n",
       "      <th id=\"T_177b5_level0_col8\" class=\"col_heading level0 col8\" >Gcaps</th>\n",
       "      <th id=\"T_177b5_level0_col9\" class=\"col_heading level0 col9\" >Gfrags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_177b5_row0_col0\" class=\"data row0 col0\" >0.16</td>\n",
       "      <td id=\"T_177b5_row0_col1\" class=\"data row0 col1\" >1.12</td>\n",
       "      <td id=\"T_177b5_row0_col2\" class=\"data row0 col2\" >0.54</td>\n",
       "      <td id=\"T_177b5_row0_col3\" class=\"data row0 col3\" >0.05</td>\n",
       "      <td id=\"T_177b5_row0_col4\" class=\"data row0 col4\" >0.30</td>\n",
       "      <td id=\"T_177b5_row0_col5\" class=\"data row0 col5\" >0.08</td>\n",
       "      <td id=\"T_177b5_row0_col6\" class=\"data row0 col6\" >0.39</td>\n",
       "      <td id=\"T_177b5_row0_col7\" class=\"data row0 col7\" >0.04</td>\n",
       "      <td id=\"T_177b5_row0_col8\" class=\"data row0 col8\" >0.31</td>\n",
       "      <td id=\"T_177b5_row0_col9\" class=\"data row0 col9\" >1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_177b5_row1_col0\" class=\"data row1 col0\" >0.15</td>\n",
       "      <td id=\"T_177b5_row1_col1\" class=\"data row1 col1\" >0.57</td>\n",
       "      <td id=\"T_177b5_row1_col2\" class=\"data row1 col2\" >0.24</td>\n",
       "      <td id=\"T_177b5_row1_col3\" class=\"data row1 col3\" >0.08</td>\n",
       "      <td id=\"T_177b5_row1_col4\" class=\"data row1 col4\" >0.05</td>\n",
       "      <td id=\"T_177b5_row1_col5\" class=\"data row1 col5\" >0.05</td>\n",
       "      <td id=\"T_177b5_row1_col6\" class=\"data row1 col6\" >0.16</td>\n",
       "      <td id=\"T_177b5_row1_col7\" class=\"data row1 col7\" >0.10</td>\n",
       "      <td id=\"T_177b5_row1_col8\" class=\"data row1 col8\" >0.14</td>\n",
       "      <td id=\"T_177b5_row1_col9\" class=\"data row1 col9\" >0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_177b5_row2_col0\" class=\"data row2 col0\" >0.05</td>\n",
       "      <td id=\"T_177b5_row2_col1\" class=\"data row2 col1\" >0.80</td>\n",
       "      <td id=\"T_177b5_row2_col2\" class=\"data row2 col2\" >0.20</td>\n",
       "      <td id=\"T_177b5_row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "      <td id=\"T_177b5_row2_col4\" class=\"data row2 col4\" >0.15</td>\n",
       "      <td id=\"T_177b5_row2_col5\" class=\"data row2 col5\" >0.04</td>\n",
       "      <td id=\"T_177b5_row2_col6\" class=\"data row2 col6\" >0.30</td>\n",
       "      <td id=\"T_177b5_row2_col7\" class=\"data row2 col7\" >0.01</td>\n",
       "      <td id=\"T_177b5_row2_col8\" class=\"data row2 col8\" >0.25</td>\n",
       "      <td id=\"T_177b5_row2_col9\" class=\"data row2 col9\" >1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_177b5_row3_col0\" class=\"data row3 col0\" >0.10</td>\n",
       "      <td id=\"T_177b5_row3_col1\" class=\"data row3 col1\" >0.35</td>\n",
       "      <td id=\"T_177b5_row3_col2\" class=\"data row3 col2\" >0.15</td>\n",
       "      <td id=\"T_177b5_row3_col3\" class=\"data row3 col3\" >0.03</td>\n",
       "      <td id=\"T_177b5_row3_col4\" class=\"data row3 col4\" >0.05</td>\n",
       "      <td id=\"T_177b5_row3_col5\" class=\"data row3 col5\" >0.01</td>\n",
       "      <td id=\"T_177b5_row3_col6\" class=\"data row3 col6\" >0.06</td>\n",
       "      <td id=\"T_177b5_row3_col7\" class=\"data row3 col7\" >0.10</td>\n",
       "      <td id=\"T_177b5_row3_col8\" class=\"data row3 col8\" >0.15</td>\n",
       "      <td id=\"T_177b5_row3_col9\" class=\"data row3 col9\" >0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_177b5_row4_col0\" class=\"data row4 col0\" >0.07</td>\n",
       "      <td id=\"T_177b5_row4_col1\" class=\"data row4 col1\" >0.15</td>\n",
       "      <td id=\"T_177b5_row4_col2\" class=\"data row4 col2\" >0.05</td>\n",
       "      <td id=\"T_177b5_row4_col3\" class=\"data row4 col3\" >0.02</td>\n",
       "      <td id=\"T_177b5_row4_col4\" class=\"data row4 col4\" >0.01</td>\n",
       "      <td id=\"T_177b5_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_177b5_row4_col6\" class=\"data row4 col6\" >0.04</td>\n",
       "      <td id=\"T_177b5_row4_col7\" class=\"data row4 col7\" >0.01</td>\n",
       "      <td id=\"T_177b5_row4_col8\" class=\"data row4 col8\" >0.08</td>\n",
       "      <td id=\"T_177b5_row4_col9\" class=\"data row4 col9\" >0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_177b5_row5_col0\" class=\"data row5 col0\" >0.15</td>\n",
       "      <td id=\"T_177b5_row5_col1\" class=\"data row5 col1\" >0.50</td>\n",
       "      <td id=\"T_177b5_row5_col2\" class=\"data row5 col2\" >0.30</td>\n",
       "      <td id=\"T_177b5_row5_col3\" class=\"data row5 col3\" >0.03</td>\n",
       "      <td id=\"T_177b5_row5_col4\" class=\"data row5 col4\" >0.01</td>\n",
       "      <td id=\"T_177b5_row5_col5\" class=\"data row5 col5\" >0.00</td>\n",
       "      <td id=\"T_177b5_row5_col6\" class=\"data row5 col6\" >0.05</td>\n",
       "      <td id=\"T_177b5_row5_col7\" class=\"data row5 col7\" >0.05</td>\n",
       "      <td id=\"T_177b5_row5_col8\" class=\"data row5 col8\" >0.20</td>\n",
       "      <td id=\"T_177b5_row5_col9\" class=\"data row5 col9\" >0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_177b5_row6_col0\" class=\"data row6 col0\" >0.16</td>\n",
       "      <td id=\"T_177b5_row6_col1\" class=\"data row6 col1\" >1.12</td>\n",
       "      <td id=\"T_177b5_row6_col2\" class=\"data row6 col2\" >0.54</td>\n",
       "      <td id=\"T_177b5_row6_col3\" class=\"data row6 col3\" >0.05</td>\n",
       "      <td id=\"T_177b5_row6_col4\" class=\"data row6 col4\" >0.30</td>\n",
       "      <td id=\"T_177b5_row6_col5\" class=\"data row6 col5\" >0.08</td>\n",
       "      <td id=\"T_177b5_row6_col6\" class=\"data row6 col6\" >0.39</td>\n",
       "      <td id=\"T_177b5_row6_col7\" class=\"data row6 col7\" >0.04</td>\n",
       "      <td id=\"T_177b5_row6_col8\" class=\"data row6 col8\" >0.31</td>\n",
       "      <td id=\"T_177b5_row6_col9\" class=\"data row6 col9\" >1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_177b5_row7_col0\" class=\"data row7 col0\" >6.00</td>\n",
       "      <td id=\"T_177b5_row7_col1\" class=\"data row7 col1\" >3.00</td>\n",
       "      <td id=\"T_177b5_row7_col2\" class=\"data row7 col2\" >0.60</td>\n",
       "      <td id=\"T_177b5_row7_col3\" class=\"data row7 col3\" >0.10</td>\n",
       "      <td id=\"T_177b5_row7_col4\" class=\"data row7 col4\" >0.40</td>\n",
       "      <td id=\"T_177b5_row7_col5\" class=\"data row7 col5\" >0.03</td>\n",
       "      <td id=\"T_177b5_row7_col6\" class=\"data row7 col6\" >0.80</td>\n",
       "      <td id=\"T_177b5_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_177b5_row7_col8\" class=\"data row7 col8\" >2.00</td>\n",
       "      <td id=\"T_177b5_row7_col9\" class=\"data row7 col9\" >1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_177b5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_177b5_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
       "      <td id=\"T_177b5_row8_col1\" class=\"data row8 col1\" >1.50</td>\n",
       "      <td id=\"T_177b5_row8_col2\" class=\"data row8 col2\" >0.30</td>\n",
       "      <td id=\"T_177b5_row8_col3\" class=\"data row8 col3\" >0.10</td>\n",
       "      <td id=\"T_177b5_row8_col4\" class=\"data row8 col4\" >1.10</td>\n",
       "      <td id=\"T_177b5_row8_col5\" class=\"data row8 col5\" >0.01</td>\n",
       "      <td id=\"T_177b5_row8_col6\" class=\"data row8 col6\" >0.50</td>\n",
       "      <td id=\"T_177b5_row8_col7\" class=\"data row8 col7\" >0.20</td>\n",
       "      <td id=\"T_177b5_row8_col8\" class=\"data row8 col8\" >0.40</td>\n",
       "      <td id=\"T_177b5_row8_col9\" class=\"data row8 col9\" >2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daaa62e45b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_td = [\n",
    "    [.16, 1.12, .54, .05, .30, .08, .39, .04, .31, 1.34],\n",
    "    [.15, .57,.24,.08,.05,.05,.16,.1,.14, .22],\n",
    "    [.05, .8, .2, .02, .15, .04, .3, .01, .25, 1.2],\n",
    "    [.1,.35,.15,.03, .05, .01, .06, .1, .15, .5],\n",
    "    [.07, .15, .05, .02, .01, 0, .04, .01, .08, .12],\n",
    "    [.15, .5, .3, .03, .01, 0, .05, .05, .2, .2]\n",
    "]\n",
    "\n",
    "length_td=16.5\n",
    "\n",
    "found_td = [11, 60, 9, 3, 0, 0,13, 1, 3, 179]\n",
    "found_tdm = np.array([x/length_td for x in found_td])\n",
    "\n",
    "tiger_duck_rows = make_rows(estimated_td, objects)\n",
    "tiger_duck = pd.DataFrame(tiger_duck_rows)\n",
    "\n",
    "found = pd.DataFrame([found_tdm, found_pm], columns=objects)\n",
    "fmelted = pd.melt(found, value_vars=found.columns)\n",
    "fmelted[\"source\"] = \"found\"\n",
    "\n",
    "combined = pd.concat([tiger_duck, pierrette])\n",
    "caption = \"Table 5: The estimated amount in pcs/meter for each object that the participants expected to find.\"\n",
    "combined.reset_index(inplace=True, drop=True)\n",
    "combined.style.format(precision=2).set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Survey results October 5, 2023 Saint Sulpice\n",
    "\n",
    "After the particpants completed the forms, surveys were conducted at three beaches within the city limits of Saint Sulpice. Only the forms for two beaches were returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f770d tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_f770d tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_f770d tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_f770d th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_f770d caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f770d\">\n",
       "  <caption>Table 6: The survey results of the objects of interest on October 5, 2023 in pieces per meter</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f770d_level0_col0\" class=\"col_heading level0 col0\" >G112</th>\n",
       "      <th id=\"T_f770d_level0_col1\" class=\"col_heading level0 col1\" >G27</th>\n",
       "      <th id=\"T_f770d_level0_col2\" class=\"col_heading level0 col2\" >G30</th>\n",
       "      <th id=\"T_f770d_level0_col3\" class=\"col_heading level0 col3\" >G32</th>\n",
       "      <th id=\"T_f770d_level0_col4\" class=\"col_heading level0 col4\" >G67</th>\n",
       "      <th id=\"T_f770d_level0_col5\" class=\"col_heading level0 col5\" >G70</th>\n",
       "      <th id=\"T_f770d_level0_col6\" class=\"col_heading level0 col6\" >G95</th>\n",
       "      <th id=\"T_f770d_level0_col7\" class=\"col_heading level0 col7\" >G96</th>\n",
       "      <th id=\"T_f770d_level0_col8\" class=\"col_heading level0 col8\" >Gcaps</th>\n",
       "      <th id=\"T_f770d_level0_col9\" class=\"col_heading level0 col9\" >Gfrags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f770d_level0_row0\" class=\"row_heading level0 row0\" >tiger-duck-beach</th>\n",
       "      <td id=\"T_f770d_row0_col0\" class=\"data row0 col0\" >0.67</td>\n",
       "      <td id=\"T_f770d_row0_col1\" class=\"data row0 col1\" >3.64</td>\n",
       "      <td id=\"T_f770d_row0_col2\" class=\"data row0 col2\" >0.55</td>\n",
       "      <td id=\"T_f770d_row0_col3\" class=\"data row0 col3\" >0.18</td>\n",
       "      <td id=\"T_f770d_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_f770d_row0_col5\" class=\"data row0 col5\" >0.00</td>\n",
       "      <td id=\"T_f770d_row0_col6\" class=\"data row0 col6\" >0.79</td>\n",
       "      <td id=\"T_f770d_row0_col7\" class=\"data row0 col7\" >0.06</td>\n",
       "      <td id=\"T_f770d_row0_col8\" class=\"data row0 col8\" >0.18</td>\n",
       "      <td id=\"T_f770d_row0_col9\" class=\"data row0 col9\" >10.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f770d_level0_row1\" class=\"row_heading level0 row1\" >parc-des-pierrettes</th>\n",
       "      <td id=\"T_f770d_row1_col0\" class=\"data row1 col0\" >0.08</td>\n",
       "      <td id=\"T_f770d_row1_col1\" class=\"data row1 col1\" >1.03</td>\n",
       "      <td id=\"T_f770d_row1_col2\" class=\"data row1 col2\" >0.14</td>\n",
       "      <td id=\"T_f770d_row1_col3\" class=\"data row1 col3\" >0.04</td>\n",
       "      <td id=\"T_f770d_row1_col4\" class=\"data row1 col4\" >0.00</td>\n",
       "      <td id=\"T_f770d_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_f770d_row1_col6\" class=\"data row1 col6\" >0.24</td>\n",
       "      <td id=\"T_f770d_row1_col7\" class=\"data row1 col7\" >0.02</td>\n",
       "      <td id=\"T_f770d_row1_col8\" class=\"data row1 col8\" >0.24</td>\n",
       "      <td id=\"T_f770d_row1_col9\" class=\"data row1 col9\" >5.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daaa634efa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption=\"Table 6: The survey results of the objects of interest on October 5, 2023 in pieces per meter\"\n",
    "found_display = found.copy()\n",
    "found_display.loc[0, \"beach\"] = \"tiger-duck-beach\"\n",
    "found_display.loc[1, \"beach\"] = \"parc-des-pierrettes\"\n",
    "found_display.set_index(\"beach\", inplace=True, drop=True)\n",
    "found_display.index.name = None\n",
    "found_display.style.format(precision=2).set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Survey results October 5, 2023 Saint Sulpice\n",
    "\n",
    "After the particpants completed the forms, surveys were conducted at three beaches within the city limits of Saint Sulpice. Only the forms for two beaches were returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd17c tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_fd17c tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_fd17c tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_fd17c th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_fd17c caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd17c\">\n",
       "  <caption>Table 6: The survey results of the objects of interest on October 5, 2023 in pieces per meter</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd17c_level0_col0\" class=\"col_heading level0 col0\" >G112</th>\n",
       "      <th id=\"T_fd17c_level0_col1\" class=\"col_heading level0 col1\" >G27</th>\n",
       "      <th id=\"T_fd17c_level0_col2\" class=\"col_heading level0 col2\" >G30</th>\n",
       "      <th id=\"T_fd17c_level0_col3\" class=\"col_heading level0 col3\" >G32</th>\n",
       "      <th id=\"T_fd17c_level0_col4\" class=\"col_heading level0 col4\" >G67</th>\n",
       "      <th id=\"T_fd17c_level0_col5\" class=\"col_heading level0 col5\" >G70</th>\n",
       "      <th id=\"T_fd17c_level0_col6\" class=\"col_heading level0 col6\" >G95</th>\n",
       "      <th id=\"T_fd17c_level0_col7\" class=\"col_heading level0 col7\" >G96</th>\n",
       "      <th id=\"T_fd17c_level0_col8\" class=\"col_heading level0 col8\" >Gcaps</th>\n",
       "      <th id=\"T_fd17c_level0_col9\" class=\"col_heading level0 col9\" >Gfrags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd17c_level0_row0\" class=\"row_heading level0 row0\" >tiger-duck-beach</th>\n",
       "      <td id=\"T_fd17c_row0_col0\" class=\"data row0 col0\" >0.67</td>\n",
       "      <td id=\"T_fd17c_row0_col1\" class=\"data row0 col1\" >3.64</td>\n",
       "      <td id=\"T_fd17c_row0_col2\" class=\"data row0 col2\" >0.55</td>\n",
       "      <td id=\"T_fd17c_row0_col3\" class=\"data row0 col3\" >0.18</td>\n",
       "      <td id=\"T_fd17c_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_fd17c_row0_col5\" class=\"data row0 col5\" >0.00</td>\n",
       "      <td id=\"T_fd17c_row0_col6\" class=\"data row0 col6\" >0.79</td>\n",
       "      <td id=\"T_fd17c_row0_col7\" class=\"data row0 col7\" >0.06</td>\n",
       "      <td id=\"T_fd17c_row0_col8\" class=\"data row0 col8\" >0.18</td>\n",
       "      <td id=\"T_fd17c_row0_col9\" class=\"data row0 col9\" >10.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd17c_level0_row1\" class=\"row_heading level0 row1\" >parc-des-pierrettes</th>\n",
       "      <td id=\"T_fd17c_row1_col0\" class=\"data row1 col0\" >0.08</td>\n",
       "      <td id=\"T_fd17c_row1_col1\" class=\"data row1 col1\" >1.03</td>\n",
       "      <td id=\"T_fd17c_row1_col2\" class=\"data row1 col2\" >0.14</td>\n",
       "      <td id=\"T_fd17c_row1_col3\" class=\"data row1 col3\" >0.04</td>\n",
       "      <td id=\"T_fd17c_row1_col4\" class=\"data row1 col4\" >0.00</td>\n",
       "      <td id=\"T_fd17c_row1_col5\" class=\"data row1 col5\" >0.00</td>\n",
       "      <td id=\"T_fd17c_row1_col6\" class=\"data row1 col6\" >0.24</td>\n",
       "      <td id=\"T_fd17c_row1_col7\" class=\"data row1 col7\" >0.02</td>\n",
       "      <td id=\"T_fd17c_row1_col8\" class=\"data row1 col8\" >0.24</td>\n",
       "      <td id=\"T_fd17c_row1_col9\" class=\"data row1 col9\" >5.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daab0142a60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption=\"Table 6: The survey results of the objects of interest on October 5, 2023 in pieces per meter\"\n",
    "found_display = found.copy()\n",
    "found_display.loc[0, \"beach\"] = \"tiger-duck-beach\"\n",
    "found_display.loc[1, \"beach\"] = \"parc-des-pierrettes\"\n",
    "found_display.set_index(\"beach\", inplace=True, drop=True)\n",
    "found_display.index.name = None\n",
    "found_display.style.format(precision=2).set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Results: Estimated, found and predicted\n",
    "\n",
    "It appears that both the participants and the model underestimated the amount of plastic fragments. Recall that the participants were given the cumulative results for these objects, table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "combined.reset_index(inplace=True, drop=True)\n",
    "comb_long = pd.melt(combined, value_vars=combined.columns)\n",
    "comb_long[\"source\"] = \"estimated\"\n",
    "\n",
    "predicted_median = list(zip(objects,pred_quants.loc[\"50%\"]))\n",
    "pmelted = pd.DataFrame(predicted_median, columns=[\"variable\", \"value\"])\n",
    "pmelted[\"source\"] = \"predicted\"\n",
    "\n",
    "predict_estimate_found = pd.concat([fmelted, pmelted, comb_long])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "data_one = predict_estimate_found[predict_estimate_found.source == \"estimated\"]\n",
    "data_two = predict_estimate_found[predict_estimate_found.source == \"found\"]\n",
    "data_three = predict_estimate_found[predict_estimate_found.source == \"predicted\"]\n",
    "sns.scatterplot(data=data_one, x=\"variable\", y=\"value\", color=\"magenta\", zorder=0,ax=ax, label=\"estimated\")\n",
    "sns.scatterplot(data=data_two, x=\"variable\", y=\"value\", color=\"dodgerblue\", marker=\"X\", s=60, zorder=2,ax=ax, label=\"found\")\n",
    "sns.scatterplot(data=data_three, x=\"variable\", y=\"value\", color=\"black\", zorder=3,ax=ax,label=\"predicted\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"pcs/m\")\n",
    "ax.legend()\n",
    "glue('estimated-found-predicted-2023', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "|Figure 3|\n",
    "|:------------:|\n",
    "|{glue:}`estimated-found-predicted-2023`|\n",
    "|Figure 3: _The Estimated, observed and predicted results for the objects of interest, Saint Sulpice October 5, 2023_|\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The predicted values from the model were all closer than the predicted values by the participants, table 7. In total 17/20 oserved results fell within the 96% probability interval predicted by the model, 7/20 fell within the 50% probability interval, Annex: table 8. Of the objects not within the 96% interval there is:\n",
    "1. Fragmented plastics, (both surveys)\n",
    "2. Cigarette ends\n",
    "3. Toys and party favors\n",
    "\n",
    "From figure 4 we can see how close the predictions and the estimates are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_the_difference_estimated_found(combined, found_tdm, objects):\n",
    "    diffs = []\n",
    "    for i, o in enumerate(objects):\n",
    "        diff = combined[objects[i]] - found_tdm[i]\n",
    "        # diffpr = combined[objects[i]] - found_pm[i]\n",
    "        diff_sq = (diff**2)**.5\n",
    "        diffs.append(diff_sq)\n",
    "    return diffs\n",
    "difference_estimated_found_td = calculate_the_difference_estimated_found(tiger_duck, found_tdm, objects)\n",
    "difference_estimated_found_pr = calculate_the_difference_estimated_found(pierrette, found_pm, objects)\n",
    "td_diff = pd.DataFrame(difference_estimated_found_td).T\n",
    "pier_diff = pd.DataFrame(difference_estimated_found_pr).T\n",
    "combined_diffs = pd.concat([td_diff, pier_diff])\n",
    "c_diff_estimated = pd.melt(combined_diffs, value_vars=combined_diffs.columns)\n",
    "c_diff_estimated[\"source\"] = \"difference² of estimated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted_median = pred_quants.loc[\"50%\"].values\n",
    "diff_1 = []\n",
    "diff_2 = []\n",
    "for i, o in enumerate(objects):    \n",
    "    diffp = predicted_median[i] - found_tdm[i]\n",
    "    diffpr = predicted_median[i] - found_pm[i]\n",
    "    diff_sq = (np.array([diffp, diffpr])**2)**.5\n",
    "    diff_1.append(diff_sq[0])\n",
    "    diff_2.append(diff_sq[1])\n",
    "\n",
    "\n",
    "pred_diffs = pd.DataFrame([diff_1, diff_2], columns=objects)\n",
    "p_diff_predicted = pd.melt(pred_diffs, value_vars=pred_diffs.columns)\n",
    "p_diff_predicted[\"source\"] = \"difference² of predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "results = pd.concat([c_diff_estimated, p_diff_predicted])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(objects, [*[0]*len(objects)], label=\"zero\")\n",
    "sns.scatterplot(data=results, x=\"variable\", y=\"value\", ax=ax, hue=\"source\", palette=[\"magenta\", \"black\"])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"pcs/m\")\n",
    "ax.legend()\n",
    "glue('diference-estimated-found-predicted-2023', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "|Figure 4|\n",
    "|:------------:|\n",
    "|{glue:}`diference-estimated-found-predicted-2023`|\n",
    "|Figure 4: _The root of the squared difference between observed estimated and predicted, Saint Sulpice October 5, 2023_| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3589a tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_3589a tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_3589a tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_3589a th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_3589a caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3589a\">\n",
       "  <caption>Table 7: The average difference between what was found and the estimates of the participants and what was predicted using the empirical Bayes method</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3589a_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >source</th>\n",
       "      <th id=\"T_3589a_level1_col0\" class=\"col_heading level1 col0\" >difference² of estimated</th>\n",
       "      <th id=\"T_3589a_level1_col1\" class=\"col_heading level1 col1\" >difference² of predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row0\" class=\"row_heading level0 row0\" >G112</th>\n",
       "      <td id=\"T_3589a_row0_col0\" class=\"data row0 col0\" >1.07</td>\n",
       "      <td id=\"T_3589a_row0_col1\" class=\"data row0 col1\" >0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row1\" class=\"row_heading level0 row1\" >G27</th>\n",
       "      <td id=\"T_3589a_row1_col0\" class=\"data row1 col0\" >2.32</td>\n",
       "      <td id=\"T_3589a_row1_col1\" class=\"data row1 col1\" >1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row2\" class=\"row_heading level0 row2\" >G30</th>\n",
       "      <td id=\"T_3589a_row2_col0\" class=\"data row2 col0\" >0.31</td>\n",
       "      <td id=\"T_3589a_row2_col1\" class=\"data row2 col1\" >0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row3\" class=\"row_heading level0 row3\" >G32</th>\n",
       "      <td id=\"T_3589a_row3_col0\" class=\"data row3 col0\" >0.11</td>\n",
       "      <td id=\"T_3589a_row3_col1\" class=\"data row3 col1\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row4\" class=\"row_heading level0 row4\" >G67</th>\n",
       "      <td id=\"T_3589a_row4_col0\" class=\"data row4 col0\" >0.26</td>\n",
       "      <td id=\"T_3589a_row4_col1\" class=\"data row4 col1\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row5\" class=\"row_heading level0 row5\" >G70</th>\n",
       "      <td id=\"T_3589a_row5_col0\" class=\"data row5 col0\" >0.03</td>\n",
       "      <td id=\"T_3589a_row5_col1\" class=\"data row5 col1\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row6\" class=\"row_heading level0 row6\" >G95</th>\n",
       "      <td id=\"T_3589a_row6_col0\" class=\"data row6 col0\" >0.52</td>\n",
       "      <td id=\"T_3589a_row6_col1\" class=\"data row6 col1\" >0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row7\" class=\"row_heading level0 row7\" >G96</th>\n",
       "      <td id=\"T_3589a_row7_col0\" class=\"data row7 col0\" >0.15</td>\n",
       "      <td id=\"T_3589a_row7_col1\" class=\"data row7 col1\" >0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row8\" class=\"row_heading level0 row8\" >Gcaps</th>\n",
       "      <td id=\"T_3589a_row8_col0\" class=\"data row8 col0\" >0.26</td>\n",
       "      <td id=\"T_3589a_row8_col1\" class=\"data row8 col1\" >0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3589a_level0_row9\" class=\"row_heading level0 row9\" >Gfrags</th>\n",
       "      <td id=\"T_3589a_row9_col0\" class=\"data row9 col0\" >8.11</td>\n",
       "      <td id=\"T_3589a_row9_col1\" class=\"data row9 col1\" >7.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daaa5e3fc70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = results.groupby([\"source\", \"variable\"], as_index=False).value.mean()\n",
    "r.rename(columns={\"value\":\"average\"}, inplace=True)\n",
    "rp = r.pivot(index=\"variable\", columns=\"source\")\n",
    "rp.index.name = None\n",
    "caption = \"Table 7: The average difference between what was found and the estimates of the participants and what was predicted using the empirical Bayes method\"\n",
    "rp.style.set_table_styles(table_large_font).format(precision=2).set_caption(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def are_the_observed_values_within_the_hdi(found, objects, predicted, index=0):\n",
    "    place = []\n",
    "    for i, o in enumerate(objects):\n",
    "        f = found.loc[index, o]\n",
    "        p = predicted[o].values\n",
    "        ip = bisect_left(p, f)\n",
    "        if ip >= 0 and ip <= 6:\n",
    "            # is within 94% HDI\n",
    "            within_96 = True\n",
    "        else:\n",
    "            within_96 = False                  \n",
    "        if ip >= 1 and ip <= 5:\n",
    "            # is within 50% HDI           \n",
    "            within_50 = True\n",
    "        else:          \n",
    "            within_50 = False    \n",
    "            \n",
    "        place.append([o, within_96, within_50])\n",
    "    return place\n",
    "\n",
    "simple_results_td = are_the_observed_values_within_the_hdi(found, objects, pred_quants)\n",
    "td_predicted_results = pd.DataFrame(simple_results_td, columns=[\"object\",\"within 96% HDI\", \"within 50% HDI\"])\n",
    "\n",
    "simple_results_p = are_the_observed_values_within_the_hdi(found, objects, pred_quants, index=1)\n",
    "p_predicted_results = pd.DataFrame(simple_results_p, columns=[\"object\",\"within 96% HDI\", \"within 50% HDI\"])\n",
    "\n",
    "all_predicted_results = pd.concat([td_predicted_results, p_predicted_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Discussion\n",
    "\n",
    "There were three surveys completed, two are reflected in the report. Neither the the estimated amounts from the particpants or the survey results were returned for the third survey. On location the participants were shown examples of the objects of interest. The limits of the survey area were defined and the survey was conducted in small groups. The objects found on the beach were separated and counted on location. The identification or the differentiation of fragmented plastics and foams remains difficult for new participants. This is in one part due to the constraints of time and on the other to the lack of experience. Many times what initially appears to be an unidentifiable piece of plastic can actually be placed in a more precise category with reasonable certainty. The new paritcipants do not have the time to consider other possibilities or simply are unaware of the original use of the item in questions.\n",
    "\n",
    "Many participants used the previous aggregated survey results to estimate the expected values. This reasonable strategy produced estimates that were very close to the predicted survey results. This suggests that previous survey results can serve as an indicator for expected results as long as the objects have been identified correctly and consistently in the past. Yet, from table 7 it is clear that predictions are more accurate when a formal method is used. \n",
    "\n",
    "## Conclusions\n",
    "\n",
    "From this experience we conclude that the expected values in table 4 do represent probable beach-litter densities in the region. \n",
    "\n",
    "### Next steps\n",
    "\n",
    "Make hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The accuracy of the predictions in relation to what was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d9b4f tr:nth-child(even) {\n",
       "  background-color: rgba(139, 69, 19, 0.08);\n",
       "}\n",
       "#T_d9b4f tr:nth-child(odd) {\n",
       "  background: #FFF;\n",
       "}\n",
       "#T_d9b4f tr {\n",
       "  font-size: 14px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_d9b4f th:nth-child(1) {\n",
       "  background-color: #FFF;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_d9b4f caption {\n",
       "  font-size: 14px;\n",
       "  font-style: italic;\n",
       "  caption-side: bottom;\n",
       "  text-align: left;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d9b4f\">\n",
       "  <caption>Table 8: Whether the observed value fell within the predicted interval</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9b4f_level0_col0\" class=\"col_heading level0 col0\" >object</th>\n",
       "      <th id=\"T_d9b4f_level0_col1\" class=\"col_heading level0 col1\" >within 96% HDI</th>\n",
       "      <th id=\"T_d9b4f_level0_col2\" class=\"col_heading level0 col2\" >within 50% HDI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d9b4f_row0_col0\" class=\"data row0 col0\" >G112</td>\n",
       "      <td id=\"T_d9b4f_row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row0_col2\" class=\"data row0 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d9b4f_row1_col0\" class=\"data row1 col0\" >G27</td>\n",
       "      <td id=\"T_d9b4f_row1_col1\" class=\"data row1 col1\" >False</td>\n",
       "      <td id=\"T_d9b4f_row1_col2\" class=\"data row1 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d9b4f_row2_col0\" class=\"data row2 col0\" >G30</td>\n",
       "      <td id=\"T_d9b4f_row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row2_col2\" class=\"data row2 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d9b4f_row3_col0\" class=\"data row3 col0\" >G32</td>\n",
       "      <td id=\"T_d9b4f_row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row3_col2\" class=\"data row3 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d9b4f_row4_col0\" class=\"data row4 col0\" >G67</td>\n",
       "      <td id=\"T_d9b4f_row4_col1\" class=\"data row4 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row4_col2\" class=\"data row4 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d9b4f_row5_col0\" class=\"data row5 col0\" >G70</td>\n",
       "      <td id=\"T_d9b4f_row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row5_col2\" class=\"data row5 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d9b4f_row6_col0\" class=\"data row6 col0\" >G95</td>\n",
       "      <td id=\"T_d9b4f_row6_col1\" class=\"data row6 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row6_col2\" class=\"data row6 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d9b4f_row7_col0\" class=\"data row7 col0\" >G96</td>\n",
       "      <td id=\"T_d9b4f_row7_col1\" class=\"data row7 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row7_col2\" class=\"data row7 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d9b4f_row8_col0\" class=\"data row8 col0\" >Gcaps</td>\n",
       "      <td id=\"T_d9b4f_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row8_col2\" class=\"data row8 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d9b4f_row9_col0\" class=\"data row9 col0\" >Gfrags</td>\n",
       "      <td id=\"T_d9b4f_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "      <td id=\"T_d9b4f_row9_col2\" class=\"data row9 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row10\" class=\"row_heading level0 row10\" >0</th>\n",
       "      <td id=\"T_d9b4f_row10_col0\" class=\"data row10 col0\" >G112</td>\n",
       "      <td id=\"T_d9b4f_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row10_col2\" class=\"data row10 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row11\" class=\"row_heading level0 row11\" >1</th>\n",
       "      <td id=\"T_d9b4f_row11_col0\" class=\"data row11 col0\" >G27</td>\n",
       "      <td id=\"T_d9b4f_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row11_col2\" class=\"data row11 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row12\" class=\"row_heading level0 row12\" >2</th>\n",
       "      <td id=\"T_d9b4f_row12_col0\" class=\"data row12 col0\" >G30</td>\n",
       "      <td id=\"T_d9b4f_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row12_col2\" class=\"data row12 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row13\" class=\"row_heading level0 row13\" >3</th>\n",
       "      <td id=\"T_d9b4f_row13_col0\" class=\"data row13 col0\" >G32</td>\n",
       "      <td id=\"T_d9b4f_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row13_col2\" class=\"data row13 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row14\" class=\"row_heading level0 row14\" >4</th>\n",
       "      <td id=\"T_d9b4f_row14_col0\" class=\"data row14 col0\" >G67</td>\n",
       "      <td id=\"T_d9b4f_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row14_col2\" class=\"data row14 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row15\" class=\"row_heading level0 row15\" >5</th>\n",
       "      <td id=\"T_d9b4f_row15_col0\" class=\"data row15 col0\" >G70</td>\n",
       "      <td id=\"T_d9b4f_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row15_col2\" class=\"data row15 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row16\" class=\"row_heading level0 row16\" >6</th>\n",
       "      <td id=\"T_d9b4f_row16_col0\" class=\"data row16 col0\" >G95</td>\n",
       "      <td id=\"T_d9b4f_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row16_col2\" class=\"data row16 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row17\" class=\"row_heading level0 row17\" >7</th>\n",
       "      <td id=\"T_d9b4f_row17_col0\" class=\"data row17 col0\" >G96</td>\n",
       "      <td id=\"T_d9b4f_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row17_col2\" class=\"data row17 col2\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row18\" class=\"row_heading level0 row18\" >8</th>\n",
       "      <td id=\"T_d9b4f_row18_col0\" class=\"data row18 col0\" >Gcaps</td>\n",
       "      <td id=\"T_d9b4f_row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "      <td id=\"T_d9b4f_row18_col2\" class=\"data row18 col2\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9b4f_level0_row19\" class=\"row_heading level0 row19\" >9</th>\n",
       "      <td id=\"T_d9b4f_row19_col0\" class=\"data row19 col0\" >Gfrags</td>\n",
       "      <td id=\"T_d9b4f_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "      <td id=\"T_d9b4f_row19_col2\" class=\"data row19 col2\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7daaa652dbb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption = \"Table 8: Whether the observed value fell within the predicted interval\"\n",
    "all_predicted_results.style.set_table_styles(table_large_font).set_caption(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "within 96% HDI    0.85\n",
       "within 50% HDI    0.35\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alr = all_predicted_results[[\"within 96% HDI\", \"within 50% HDI\"]].sum()\n",
    "alr/len(all_predicted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "within 96% HDI    17\n",
       "within 50% HDI     7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "This script updated 26/09/2024 in Biel, CH\n",
       "\n",
       "❤️ __what you do everyday:__ *analyst at hammerdirt*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = dt.datetime.now().date().strftime(\"%d/%m/%Y\")\n",
    "where = \"Biel, CH\"\n",
    "\n",
    "my_block = f\"\"\"\n",
    "\n",
    "This script updated {today} in {where}\n",
    "\n",
    "\\u2764\\ufe0f __what you do everyday:__ *analyst at hammerdirt*\n",
    "\"\"\"\n",
    "\n",
    "md(my_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git repo: https://github.com/hammerdirt-analyst/solid-waste-team.git\n",
      "\n",
      "Git branch: main\n",
      "\n",
      "numpy     : 1.26.4\n",
      "matplotlib: 3.8.4\n",
      "seaborn   : 0.13.2\n",
      "pandas    : 2.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -b -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}