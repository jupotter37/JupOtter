{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modeling\n",
    "\n",
    "by Bart De Vylder and Pieter Buteneers from CoScale\n",
    "\n",
    "\n",
    "## 1. Imports\n",
    "\n",
    "Let's first start with importing all the necessary packages. Some imports will be repeated in the exercises but if you want to skip some parts you can just execute the imports below and start with any exercise.\n",
    "\n",
    "As you can see we also import packages from `__future__`. This is to improve the compatibility with Python 3, but will not guarantee it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (20.0, 14.0)\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import pickle_helper\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.gaussian_process\n",
    "import sklearn.ensemble\n",
    "\n",
    "# to make the code is compatible with python 3\n",
    "from __future__ import print_function   # turns print into a function\n",
    "from __future__ import division         # makes sure 3/2 = 1.5 and not 1 (use 3//2 = 1 instead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression\n",
    "\n",
    "Linear Regression assumes a linear relationship between 2 or more variables. \n",
    "\n",
    "As an example we'll consider the historical page views of a web server and compare it to its CPU usage. We'll try to predict the CPU usage of the server based on the page views of the different pages. \n",
    "\n",
    "### 2.1 Data import and inspection\n",
    "\n",
    "Let's import the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_usage, page_views, page_names, _ = pickle_helper.load('data/cpu_page_views.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the data. For CPU we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(cpu_usage, label='CPU')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now at the individual pageviews. First we check the pageview format: its a table that consists of 288 rows and 6 columns, to get out individual timeseries we need to transpose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_views.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(page_views).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "for page_name, timeseries in zip(page_names, np.transpose(page_views)):\n",
    "    plt.plot(timeseries, label=page_name)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Simple linear regression\n",
    "\n",
    "First, we're going to work with the total page views on the server, and compare it to the CPU usage. The numpy function [np.sum](http://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html)  can be used to calculate the total request rate when selecting the right direction (axis=1) for the summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "a1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "total_page_views = np.sum(page_views, axis=1) \n",
    "### END SOLUTION\n",
    "# total_page_views =\n",
    "\n",
    "assert total_page_views.shape == (288,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the total request rate to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(total_page_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of a [PyPlot's scatter plot](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter) to understand the relation between the total page views and the CPU usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "scatter",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "### BEGIN SOLUTION\n",
    "plt.scatter(total_page_views, cpu_usage)\n",
    "### END SOLUTION\n",
    "# plt.scatter( ? , ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There clearly is a strong correlation between the page views and the CPU usage. Because of this correlation we can build a model to predict the CPU usage from the total page views. If we use a linear model we get a formula like the following:\n",
    "\n",
    "$$ \\text{cpu_usage} = c_0 + c_1 \\text{total_page_views} $$\n",
    "\n",
    "Since we don't know the exact values for $c_0$ and $c_1$ we will have to compute them. For that we'll make use of the [scikit-learn](http://scikit-learn.org/stable/) machine learning library for Python and use [least-squares linear regression](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "simple_lin_model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to feed the data to the model to fit it. The [model.fit(X,y) method](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) in general takes a matrix X and vector y as arguments:\n",
    "```\n",
    "      X = [[x_11, x_12, x_13, ...],                  y = [y_1,\n",
    "           [x_21, x_22, x_23, ...],                       y_2,  \n",
    "           [x_31, x_32, x_33, ...],                       y_3,\n",
    "           ...]                                           ...]\n",
    "\n",
    "```\n",
    "\n",
    "and tries to find coefficients that allow to predict the `y_i`'s from the `x_ij`'s. In our case the matrix X will consist of only 1 column containing the total page views. Our `total_page_views` variable however, is still only a one-dimensional vector, so we need to [`np.reshape()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) it into a two-dimensional array. Since there is only 1 feature the second dimension should be 1.\n",
    "\n",
    "Then we fit our model using the the total page views and cpu. The coefficients found are automatically stored in the ```simple_lin_model``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "a2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "total_page_views_2D = np.reshape(total_page_views, (-1,1))\n",
    "### END SOLUTION\n",
    "# total_page_views_2D = \n",
    "\n",
    "# Test to see it's a two dimensional array\n",
    "assert len(total_page_views_2D.shape) == 2\n",
    "# Test to see it's got only 1 column\n",
    "assert total_page_views_2D.shape[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit our model using the the total request rate and cpu. The coefficients found are automatically stored in the ```simple_lin_model``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "model_fit",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "simple_lin_model.fit(total_page_views_2D, cpu_usage)\n",
    "### END SOLUTION\n",
    "# simple_lin_model.fit( ? , ? ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the coefficient $c_1$ and constant term (intercept) $c_0$ of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficient = %s, constant term = %f\" % (str(simple_lin_model.coef_), simple_lin_model.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this means that each additional page view adds about 0.11% CPU load to the server and all the other processes running on the server consume on average 0.72% CPU.\n",
    "\n",
    "How many page views per second will lead to a CPU load of 100% according to our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "critical",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "critical_page_views = (100 - simple_lin_model.intercept_) / simple_lin_model.coef_[0]\n",
    "### END SOLUTION\n",
    "# critical_page_views = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained we can use it to [```predict```](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict) the outcome for a given input (or array of inputs). Note that the predict function requires a 2-dimensional array similar to the ```fit``` function. We now test whether the ```critical_page_views``` is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "predict_100",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "predicted_cpu = simple_lin_model.predict([[critical_page_views]])[0]\n",
    "\n",
    "assert predicted_cpu == 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the linear model together with our data to verify it captures the relationship correctly (the predict method can accept the entire ```total_page_views``` array at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.scatter(total_page_views, cpu_usage,  color='black')\n",
    "plt.plot(total_page_views, simple_lin_model.predict(total_page_views.reshape((-1, 1))), color='blue', linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model can calculate the R2 [`score`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) indicating how well the linear model captures the data. A score of 1 means there is perfect linear correlation and the model can fit the data perfectly, a score of 0 (or lower) means that there is no correlation at all (and it does not make sense to try to model it that way). The score method takes the same arguments as the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lin_model.score(total_page_views.reshape((-1, 1)), cpu_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiple linear regression\n",
    "\n",
    "A server can host different pages and each of the page views will generate load on the CPU. This load will however not be the same for each page.\n",
    "\n",
    "Now let us consider the separate page views and build a linear model for that. The model we try to fit takes the form:\n",
    "\n",
    "$$\\text{cpu_usage} = c_0 + c_1 \\text{page_views}_1 + c_2 \\text{page_views}_2 + \\ldots + c_n \\text{page_views}_n$$\n",
    "\n",
    "where the $\\text{page_views}_i$'s correspond the our different pages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_usage, page_views, page_names, _ = pickle_helper.load('data/cpu_page_views.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start again by creating a [```LinearRegression```](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_lin_model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the model on the data, using `multi_lin_model.fit(X,y)`. In contrast to the case above our `page_views` variable already has the correct shape to pass as the X matrix: it has one column per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "multi_lin_model_fit",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "multi_lin_model.fit(page_views, cpu_usage)\n",
    "### END SOLUTION\n",
    "# multi_lin_model.fit( ? , ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given the coefficients calculated by the model, which capture the contribution of each page view to the total CPU usage, we can start to answer some interesting questions. For example, \n",
    "which page view causes most CPU usage, on a per visit basis? \n",
    "\n",
    "For this we can generate a table of page names with their coefficients in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Index \\t CPU (\\%) \\t\\t Page')\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "indices = np.argsort(multi_lin_model.coef_)\n",
    "for i in indices[::-1]:\n",
    "    print(i, '\\t', multi_lin_model.coef_[i], '\\t', page_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table we see that 'resources/js/basket.js' consumes the most per CPU per view. It generates about 0.30% CPU load for each additional page view. 'products/science.html' on the other hand is much leaner and only consumes about 0.04% CPU per view.\n",
    "\n",
    "Now let us investigate the constant term again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The other processes on the server consume %.2f%%' % multi_lin_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this term is very similar to the result achieved in single linear regression, but it is not entirely the same. This means that these models are not perfect. However, the seem to be able to give a reliable estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using the sklearn model to explore what-if scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we have modeled how much load each individual request generates. Now we want to use this model to simulate what-if scenarios. \n",
    "\n",
    "Suppose we want to minimize average CPU usage on this server by deviating traffic of only one webpage to another server, which page should we choose?\n",
    "\n",
    "For this we simulate diverting the traffic of one page to another server. This means that for the request that is diverted the rate becomes 0, for the other requests we use the average rate.\n",
    "\n",
    "We implement this by first calculating the `average_request_rates` using [```np.mean```](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html). These `average_request_rates` are then fed to the `multi_lin_model.predict()` method but with setting each individual request rate to 0 once.\n",
    "\n",
    "(For linear models you can also compute the result directly based on the coefficients, but this approach also works for non-linear models generated by sklearn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "what-if",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "average_page_views = np.mean(page_views, axis=0)\n",
    "### END SOLUTION\n",
    "# average_page_views = \n",
    "assert average_page_views.shape == (6,)\n",
    "\n",
    "predicted_cpus = []\n",
    "\n",
    "# Loop over all pages\n",
    "for i in range(len(page_names)):\n",
    "    # make a copy of the array to avoid overwriting\n",
    "    tweaked_load = np.copy(average_page_views)\n",
    "### BEGIN SOLUTION\n",
    "    tweaked_load[i] = 0\n",
    "    resulting_cpu = multi_lin_model.predict([tweaked_load])[0]\n",
    "### END SOLUTION\n",
    "    # tweaked_load[ ? ] = ?\n",
    "\n",
    "    # Make sure to pass a 2D array to predict and we want resulting_cpu to be a single number\n",
    "    # resulting_cpu = multi_lin_model.predict( ? )[0]\n",
    "    predicted_cpus.append(resulting_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CPU\\tCoef\\tRate\\tDiverted page')\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "indices = np.argsort(predicted_cpus)\n",
    "for i in indices:\n",
    "    print(\"%.3f\\t%.3f\\t%.3f\\t%s\" % (predicted_cpus[i], multi_lin_model.coef_[i], average_page_views[i], page_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the table above, it is best to divert the traffic of 'api/product/get.php'.\n",
    "\n",
    "Why is the result different than the table based on the coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
