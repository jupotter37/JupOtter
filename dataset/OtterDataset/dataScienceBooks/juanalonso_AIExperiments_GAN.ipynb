{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI0AxbCKFVVHuEy+Ip3hMw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChkChjWj37LL"
      },
      "source": [
        "# Generative Adversarial Network\n",
        "\n",
        "Basado en https://www.tensorflow.org/tutorials/generative/dcgan\n",
        "\n",
        "Algunos trucos: https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0\n",
        "\n",
        "Para usar imágenes RGB he consultado https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/\n",
        "\n",
        "https://www.tensorflow.org/js/tutorials/conversion/import_keras\n",
        "\n",
        "https://blog.tensorflow.org/2018/07/train-model-in-tfkeras-with-colab-and-run-in-browser-tensorflowjs.html\n",
        "\n",
        "https://medium.com/tensorflow/train-on-google-colab-and-run-on-the-browser-a-case-study-8a45f9b1474e\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWEGHEP35ARW"
      },
      "source": [
        "!pip install tensorflowjs \n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from google.colab import files as GCfiles\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "from ipywidgets import Output\n",
        "\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nirbQpy-6Yb_"
      },
      "source": [
        "# Número de elementos que va a tener nuestro conjunto de datos de entrenamiento\n",
        "BUFFER_SIZE = 25000\n",
        "\n",
        "# Tamaño del batch\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Número de entradas del generador\n",
        "INPUTS = 100\n",
        "\n",
        "# Ancho y alto de cada imagen \n",
        "w, h = 64, 64\n",
        "\n",
        "# Cuánto vamos a entrenar la red\n",
        "EPOCHS = 100\n",
        "\n",
        "# El número de ejemplos que vamos a mostrar durante el entrenamiento \n",
        "NUM_EXAMPLES = 18\n",
        "\n",
        "# La semilla para esos ejemplos\n",
        "seed = np.random.normal(size=(NUM_EXAMPLES, INPUTS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn0-1j2zfpba"
      },
      "source": [
        "### Crear el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tSkVw7JaTio"
      },
      "source": [
        "# El objetivo es rellenar un array de tamaño (BUFFER_SIZE,w,h,3) con todas \n",
        "# las imágenes que generamos. El array está normalizado entre -1 y 1 (0..255)\n",
        "\n",
        "train_images = np.empty((BUFFER_SIZE,w,h,3))\n",
        "\n",
        "colores = [(23, 63, 95), (32, 99, 155), (60, 174, 163), (246, 213, 92), (237, 85, 59)]\n",
        "\n",
        "for f in range(BUFFER_SIZE):\n",
        "\n",
        "  if f%1000==0:\n",
        "    print(f'{f}/{BUFFER_SIZE} elementos')\n",
        "\n",
        "  img = Image.new('RGB', (w, h), color=colores[0])\n",
        "  canvas = ImageDraw.Draw(img) \n",
        "  \n",
        "  coords = np.random.randint(-11,w-12,size=2)\n",
        "  coords = np.append(coords, coords+24)\n",
        "  canvas.ellipse(coords.tolist(), fill=colores[np.random.randint(4)+1], outline=None)\n",
        "  \n",
        "  for g in range(5): \n",
        "    coords = np.random.randint(-1,8,size=2)*8\n",
        "    coords = np.append(coords, coords+10)\n",
        "    canvas.rectangle(coords.tolist(), fill=colores[np.random.randint(4)+1], outline=None)\n",
        "  \n",
        "  item = np.array(img.getdata())\n",
        "  item = (item-127.5) / 127.5\n",
        "  item = np.reshape(item,(w, h, 3))\n",
        "  train_images[f]=item\n",
        "\n",
        "fig = plt.figure(figsize=(8, 4))\n",
        "for i in range(NUM_EXAMPLES):\n",
        "  plt.subplot(3, 6, i+1)\n",
        "  plt.imshow(train_images[i, :, :] * .5 + .5)\n",
        "  plt.axis('off')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fve3-rbzrUD-"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images.astype('float32')).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7lkvVvy6714"
      },
      "source": [
        "### Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a9Rh_SK6_hq"
      },
      "source": [
        "# El generador recibe INPUTS valores aleatorios entre -1 y 1 y devuelve\n",
        "# un array de W x H (la imagen generada)\n",
        "\n",
        "def make_generator_model():\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(INPUTS,)))\n",
        "  model.add(layers.Dense(4*4*128, use_bias=False, input_shape=(INPUTS,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((4, 4, 128)))\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n",
        "  \n",
        "  # model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "  # model.add(layers.BatchNormalization())\n",
        "  # model.add(layers.LeakyReLU())\n",
        "  # model.add(layers.Conv2D(3, (3,3), padding='same', activation='tanh'))\n",
        "\n",
        "\n",
        "\n",
        "  # assert model.output_shape == (None, w, h, 3)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUe0V2TgEx-9"
      },
      "source": [
        "# El discriminador recibe un array de W x H (la imagen generada) y devuelve \n",
        "# un 0 (es generada) o un 1 (es verdadera)\n",
        "\n",
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(64, (5, 5), \n",
        "                          strides=(2, 2), padding='same',\n",
        "                          input_shape=[w, h, 3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), \n",
        "                          strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(256, (5, 5), \n",
        "                          strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApVzPVcfEzQN"
      },
      "source": [
        "# Instanciamos los modelos\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "# Instanciamos los optimizadores\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Definimos el directorio donde se van a grabar los checkpoints\n",
        "checkpoint_dir = './'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'GAN-ckpt')\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYSpEHOAIzxj"
      },
      "source": [
        "# Como el problema es clasificación binaria, usamos esta función de error\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# El discriminador debería devolver un cero cuando la imagen ha sido generada por \n",
        "# el generador y un 1 si viene del training set.\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss\n",
        "\n",
        "# Las imágenes generadas por el generador siempre deberían conseguir \n",
        "# un 1 cuando se presentan al discriminador\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkGncQbgFOuf"
      },
      "source": [
        "# noise = tf.random.normal([1, INPUTS])\n",
        "# generated_image = generator(noise, training=False)\n",
        "# plt.imshow(generated_image[0, :, :] *0.5 + 0.5)\n",
        "\n",
        "# decision = discriminator(generated_image)\n",
        "# print (decision)\n",
        "\n",
        "# generator.summary()\n",
        "# discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsJqVpS1Qigx"
      },
      "source": [
        "# En cada paso, calculamos la salida del discriminador para las imágenes del\n",
        "# dataset, para las imágenes falsas, calculamos los gradientes y los opimizamos.\n",
        "@tf.function\n",
        "def train_step(real_images):\n",
        "\n",
        "  noise = tf.random.normal([BATCH_SIZE, INPUTS])\n",
        "  \n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "    # Salida del discriminador cuando se le presentan imágenes reales. \n",
        "    # Deberían ser todo unos.\n",
        "    real_output = discriminator(real_images, training=True) \n",
        "    \n",
        "    # Salida del discriminador cuando se le presentan imágenes falsas.\n",
        "    # Deberían ser todo ceros.\n",
        "    fake_images = generator(noise, training=True)\n",
        "    fake_output = discriminator(fake_images, training=True)\n",
        "\n",
        "    # Se calculan las pérdidas\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "  return gen_loss, disc_loss\n",
        "\n",
        "# Lo importante es iterar sobre el dataset tantas veces como epochs hayamos\n",
        "# indicado. El resto es para sacar información adicional y grabar de vez en \n",
        "# cuando.\n",
        "\n",
        "# La versión mínima sería\n",
        "# def train(dataset, epochs):\n",
        "#   for epoch in range(epochs):\n",
        "#     print(epoch)\n",
        "#     for image_batch in dataset:\n",
        "#       _, _ = train_step(image_batch)\n",
        "\n",
        "def train(dataset, epochs):\n",
        "\n",
        "  list_gen_loss = []\n",
        "  list_disc_loss = [] \n",
        "  \n",
        "  examples = Output()\n",
        "  display(examples)\n",
        "\n",
        "  loss_plot = Output()\n",
        "  display(loss_plot)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    total_gen_loss = 0\n",
        "    total_disc_loss = 0\n",
        "    steps = 0\n",
        "    for image_batch in dataset:\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      total_gen_loss += gen_loss\n",
        "      total_disc_loss += disc_loss\n",
        "      steps +=1\n",
        "\n",
        "    list_gen_loss.append(total_gen_loss/steps)\n",
        "    list_disc_loss.append(total_disc_loss/steps)\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    predictions = generator(seed, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(3, 6, i+1)\n",
        "      plt.imshow(predictions[i, :, :] * .5 + .5)\n",
        "      plt.axis('off')\n",
        "\n",
        "    with examples:\n",
        "      clear_output(wait=True)\n",
        "      plt.show()\n",
        "      print ('\\n\\nepoch {}: gen_loss={:.2f} disc_loss={:.2f} time={:.2f} sec'.format(epoch + 1, \n",
        "                                                                    list_gen_loss[-1],\n",
        "                                                                    list_disc_loss[-1],\n",
        "                                                                    time.time()-start))\n",
        "\n",
        "    if epoch%20 == 0:\n",
        "      plt.plot(list_gen_loss)\n",
        "      plt.plot(list_disc_loss)\n",
        "      plt.legend(['generator', 'discriminator'])\n",
        "      with loss_plot:\n",
        "        clear_output(wait=True)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnpjfBwdUHk5"
      },
      "source": [
        "# Entrenamiento\n",
        "# Es normal que el error del generador vaya creciendo con el tiempo\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuR7eXlJLmlA"
      },
      "source": [
        "# Generamos un modelo compatible con javascript y lo descargamos.\n",
        "tfjs.converters.save_keras_model(generator, './generator/')\n",
        "!zip -r generator.zip generator \n",
        "GCfiles.download('generator.zip') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiyZD--rPu9z"
      },
      "source": [
        "# Recuperamos del disco los pesos que se han grabado automáticamente.\n",
        "# Esta línea no pinta nada aquí, es solo un ejemplo de cómo hacerlo.\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmPbnacN2Yl"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIx0EU_KiZis"
      },
      "source": [
        "INTERPOLATION_STEPS = 12\n",
        "\n",
        "point = np.random.normal(size=INPUTS)\n",
        "latent_seed = np.stack([point for f in range(INTERPOLATION_STEPS)])\n",
        "\n",
        "delta = np.linspace(-1,1,INTERPOLATION_STEPS)\n",
        "\n",
        "for f in range(15):\n",
        "  dim = np.random.randint(INPUTS)\n",
        "  latent_seed[:,dim] += delta\n",
        "\n",
        "start = time.time()\n",
        "generated_images = generator(latent_seed, training=False)\n",
        "print ('time={:.2f} sec'.format(time.time()-start))\n",
        "\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i, coords in enumerate(latent_seed):\n",
        "  plt.subplot(1, 13, i+1)\n",
        "  plt.imshow(generated_images[i, :, :] * .5 + .5)\n",
        "  plt.axis('off')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaboAGlNah5K"
      },
      "source": [
        "latent_seed = tf.random.normal([1, INPUTS])\n",
        "generated_image = generator(latent_seed, training=False)\n",
        "plt.imshow(generated_image[0, :, :] * .5 + .5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}