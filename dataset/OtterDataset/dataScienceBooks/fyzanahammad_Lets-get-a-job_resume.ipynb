{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D Fyzan Ahammad\n",
      "(cid:211) 8309648519  fyzanahammad@gmail.com fl LinkedIn (cid:135) Github (cid:140) Portfolio\n",
      "Education\n",
      "Jamia Millia Islamia, New Delhi 2020 – 2024\n",
      "Bachelor of Technology in Electronics and Communication Engineering GPA - 8.6\n",
      "Sri Medha, Anantapur 2017 – 2019\n",
      "Class 12 Percentage - 92%\n",
      "Experience\n",
      "Deep Learning and Research Intern | Enord - AI on Edge Drone Tech Start-Up Feb 2024 - Present\n",
      "• Developed and fine-tuned computer vision models using YOLOx object detection framework, achieving over 90%\n",
      "accuracy on projects focused on runway foreign object detection and solar panel hotspot detection.\n",
      "• Annotated and prepared datasets comprising 30,000 images for runway foreign object detection and 5,000 images for\n",
      "solar panel hotspot detection, facilitating robust model training.\n",
      "• Trained the YOLOx Tiny Model with 5 million parameters on AWS EC2 instance over a period of 2 days,\n",
      "employing SSH access for streamlined model optimization and achieving significant performance gains.\n",
      "• Achieved a 10X increase in inference speed by optimizing deployment efficiency through the conversion of PyTorch\n",
      "model into TensorRT format, for facilitating seamless integration with NVIDIA Jetson Nano 4gb on drones.\n",
      "Research Intern | DR. Zeeshan - JMI, New Delhi Jan 2024 - Apr 2024\n",
      "• Conducted in-depth research on Parkinson’s disease, integrating deep learning for prediction and severity assessment.\n",
      "• Reviewed numerous research papers to gain insights into current methodologies and opportunities for innovation.\n",
      "• Developed a deep learning model for physiotherapy guidance in Parkinson’s disease, utilizing computer vision techniques\n",
      "for enhanced effectiveness.\n",
      "Projects\n",
      "(cid:135) RAG Implementation: Extracting Information from PDFs with RAG | Gemini-pro, Langchain, FAISS, Streamlit\n",
      "∗ Engineered a PDF Question Answering Application, integrating Google Generative AI for efficient text processing and\n",
      "answer generation.\n",
      "∗ Leveraged advanced language technologies like LangChain and LangChain Google GenAI for seamless text handling and\n",
      "conversational AI functionalities.\n",
      "(cid:135) Solar panel Hotspot detection using YOLOv8 | YOLOv8, Roboflow, TensorRT, NVIDIA-Jetson\n",
      "∗ Developed Solar Panel Hotspot Detection using YOLOv8, enhancing efficiency in identifying potential issues.\n",
      "∗ Implemented state-of-the-art Computer Vision techniques, and Roboflow for accurate detection.\n",
      "∗ Optimized model inference speed with TensorRT and deployed on NVIDIA Jetson for real-time monitoring.\n",
      "(cid:135) Life-Saving Signs: Real-Time Detection of Emergency Indian Sign Language | LSTM, Streamlit\n",
      "∗ Engineered Real-time Indian Sign Language Detection using LSTM, improving accessibility for the hearing-impaired\n",
      "community.\n",
      "∗ Integrated LSTM models for accurate sign language recognition, enhancing communication possibilities.\n",
      "∗ Developed a user-friendly interface with Streamlit for intuitive interaction and seamless deployment.\n",
      "Technical Skills\n",
      "Programming Languages: Python, C, C++, HTML/CSS, SQL\n",
      "Technologies: Tensorflow, PyTorch, Keras, Numpy, Pandas, Matplotlib, OpenCV, YOLO, Linux, GitHub, NVIDIA-Jetson\n",
      "Coursework: Data Structures and Algorithms, Object Oriented Programming, Computer Networks, Operating Systems,\n",
      "Database Management, Data Science, Artificial Intelligence, Machine Learning, Deep Learning\n",
      "Other Skills: UI & UX Design, Figma, Canva, MS Office, Graphic Designing, Digital Marketing\n",
      "Languages: English(Professionalproficiency), Urdu(Native), Telugu(Native), Hindi(Native), Tamil(ElementaryProficiency)\n",
      "Achievements\n",
      "Piranha Tank | Finalists in Startup Pitching event Sept 2022\n",
      "∗ Stood as finalists of Jamia’s E-Cell Pirana Tank, highlighting strong presentation and entrepreneurial skills.\n",
      "∗ Secured incubation space at Jamia Millia Islamia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"resume/Fyzan_Ahammad_Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\rough\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure GenAI with the API key\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'input_documents'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m chain \u001b[38;5;241m=\u001b[39m get_conversational_chain()\n\u001b[0;32m     67\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume/Fyzan_Ahammad_Resume.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m user_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextracted_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m user_info\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 58\u001b[0m, in \u001b[0;36mget_user_info\u001b[1;34m(chain, extracted_text)\u001b[0m\n\u001b[0;32m     55\u001b[0m context \u001b[38;5;241m=\u001b[39m extracted_text\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m---> 58\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     user_info[key] \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     60\u001b[0m     context \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\rough\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\rough\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\rough\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\rough\\Lib\\site-packages\\langchain\\chains\\base.py:154\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    148\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    149\u001b[0m     inputs,\n\u001b[0;32m    150\u001b[0m     run_id,\n\u001b[0;32m    151\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\rough\\Lib\\site-packages\\langchain\\chains\\base.py:284\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    282\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'input_documents'}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure GenAI with the API key\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "\n",
    "# Function to create the conversational chain\n",
    "def get_conversational_chain():\n",
    "    template = \"\"\"\n",
    "    you are a chatbot trained to collect information for creating a resume. \n",
    "    Please ask for each piece of information one by one and confirm the user input before proceeding to the next question.\n",
    "    Ask for the following details in order: \n",
    "    1. Full name\n",
    "    2. Email address\n",
    "    3. Phone number\n",
    "    4. LinkedIn URL\n",
    "    5. Education details (e.g., degree, university, year)\n",
    "    6. Project descriptions\n",
    "    Context:\\n{context}\\n\n",
    "    Question:\\n{question}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, prompt=prompt, verbose=True)\n",
    "    return chain\n",
    "\n",
    "# Function to get user information\n",
    "def get_user_info(chain, extracted_text):\n",
    "    user_info = {}\n",
    "    prompts = [\n",
    "        (\"name\", \"Please enter your full name.\"),\n",
    "        (\"email\", \"Can you provide your email address?\"),\n",
    "        (\"phone\", \"What is your phone number?\"),\n",
    "        (\"linkedin\", \"Please enter your LinkedIn URL.\"),\n",
    "        (\"education\", \"Please provide details of your education (e.g., degree, university, year).\"),\n",
    "        (\"projects\", \"Describe a project you have worked on.\"),\n",
    "        # Add more prompts as needed\n",
    "    ]\n",
    "\n",
    "    context = extracted_text\n",
    "    \n",
    "    for key, prompt in prompts:\n",
    "        response = chain({\"context\": context, \"question\": prompt})\n",
    "        user_info[key] = response['text'].strip()\n",
    "        context += f\"\\n{prompt}\\n{response['text']}\\n\"\n",
    "    \n",
    "    return user_info\n",
    "\n",
    "# Main function to run the application\n",
    "if __name__ == \"__main__\":\n",
    "    chain = get_conversational_chain()\n",
    "    extracted_text = extract_text_from_pdf(\"resume/Fyzan_Ahammad_Resume.pdf\")\n",
    "    user_info = get_user_info(chain, extracted_text)\n",
    "    for key, value in user_info.items():\n",
    "        print(f\"{key.capitalize()}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rough",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
