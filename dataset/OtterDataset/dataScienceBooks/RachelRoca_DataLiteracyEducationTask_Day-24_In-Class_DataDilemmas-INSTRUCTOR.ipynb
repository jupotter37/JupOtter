{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 24 - In-Class - Data Dilemmas: Ethics in an Algorithmic World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Put your name here</p>\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*rY3-IGAtdqiDDA9cutdOZA@2x.png\" width=600>\n",
    "\n",
    "## Learning Goals:\n",
    "\n",
    "By the end of this assignment, you should be able to:\n",
    "* Evaluate the impact the data and algorithmic bias can have on real-life decisions\n",
    "* Differentiate between intent and impact of Machine Learning models\n",
    "* Identify benefits and consequences of using ML and AI tools\n",
    "* Compare similarities between models and simulations to real-life inequities\n",
    "* Read and interpret professional code built to create a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survial of the Best Fit\n",
    "In the pre-class assignment, you played [\"Survival of the Best Fit\"](https://www.survivalofthebestfit.com/) and explored how bias inherent in our world and data can influence the results of an algorithm. Today, we are going to take a deeper dive in to the data that was used to create the simulation and explore how this game mimics hiring practices used by everyday companies. \n",
    "\n",
    "&#9989;&nbsp; In your groups, take a few minutes to discuss things you noticed about the game. Write down a few thoughts below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down some notes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "Recommended Time: 20-30min, Minimum Time: 15min\n",
    "\n",
    "\n",
    "This can be led as a \"think, pair, share\" activity, where the \"think\" happened in the pre-class assignment and the \"pair\" is happening within groups. Instructors should be actively moving around the room to listen to group discussions and help facilitate deeper conversations. After the few minutes of group discussion, bring the class back together to share some of the thoughts that were discussed. One way to start this (without dealing with the awkward silence of waiting for someone to volunteer) is to ask each group to share something they discussed. Groups should be made aware of this expectation at the beginning of the activity.\n",
    "\n",
    "See the pre-class assignment for a list of possible points to bring up.\n",
    "\n",
    "If norms have not previously been established, this is a good time to do so before starting this activity. If they have been established, remind students of the norms before starting the activity. Especially since we're dealing with a sensitive topic, it's important to remind students to be respectful of each other's perspectives and lived experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a Deep Dive into the Code\n",
    "\n",
    "Now open the `biased_data_gen.ipynb` file from the website. As a group work through that notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;&nbsp; After you finish going through the biased data generation notebook, take a few minutes to reflect on the code and the data. Write down some thoughts below. How does the simulated data reflect real systemic issues present in our world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down your answers here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "Recommended Time: 30-40min, Minimum:  20 min\n",
    "\n",
    "\n",
    "We can see how orange and blue people can be mapped to people of different identities in the real world. How bias is embedded within the code can also be mapped to different real world systemic issues, such as redlining, bias, and more. It is again worth emphasizing that blue and orange people are not meant to highlight that any one group is superior to the other, but rather to highlight the biases that exist in the world. Issues of bias affect the opportunities that people have access to, and it becomes reinforced when these biases are embedded in the data that is used to train algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life Application\n",
    "It turns out Amazon (and [many more companies](https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination ) more recently) have been using Machine Learning and AI algorithm to assist in their hiring practices with mixed success. \n",
    "\n",
    "&#9989;&nbsp; Take a few minutes to read [\"Amazon ditched AI recruiting tool that favored men for technical jobs\"](https://theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine). \n",
    "\n",
    "### Discuss\n",
    "\n",
    "&#9989;&nbsp;  Discuss the follow questions with your group and take some notes on what you talk about. \n",
    "1.  What connections do you seen between \"Survival of the Best Fit\" and Amazon's real-life recruiting tool?\n",
    "2.  Why was Amazon's algorithm bias? What was biased about the training data? \n",
    "3.  How would you feel if you knew a company you applied to was using AI to judge candidates' applications? \n",
    "4.  If you were in a hiring role, would you feel comfortable using AI in hiring decisions? What steps might you take to help mitigate bias? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Write down some notes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER\n",
    "Recommended Time: 15-20min, Minimum Time:10 min\n",
    "\n",
    "1. Students should notice similar outcomes of bias in the results of the algorithms. \n",
    "2. Negatively impacted women as a result of more men in the tech world and hence the applicant pool for the training data. Also, bias towards language commonly used in male applications. \n",
    "3. Any reasonable answer. In past experiences, students have expressed discomfort with the idea of AI judging their applications. They've also added qualifiers, such as \"only if there was a clear explanation of how the AI was used\" or \"only if there was a human auditing the AI's decisions.\"\n",
    "4. Any reasonable answer. Might talk about reviewing the data beforehand, adding intervening stages to review applicants and algorithm decisions, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share Your Highlights\n",
    "We will spend the last 10-15 minutes of class sharing what you learned and discussed. Make sure to note a few things to share with the rest of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "Recommended Time: 15-20min, Minimum Time:10 min\n",
    "\n",
    "Draw from what was discussed from both looking at the code and the real-life application. This is a great time to highlight some students' insights as well as to bring up any points that were not discussed in the group (some relevant points are given in above answers, but this is certainly not meant to be limiting). This discussion serves to close out the discussion for today, so make sure to address any confusions and close out with some takeaways from below (students might not read it, so it's good to reiterate some of the main points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways from Today's In-Class\n",
    "Today's assignment should have made you more aware about the power and the real-life harm that algorithm can cause. While they can provide great benefits like being cost-effective and speeding up time-consuming processes, they can also perpetuate harm existent in our world. Some more takeaways:\n",
    "- Pros: \n",
    "  * Algorithms can help reduce workload and synthesize large amounts of data. \n",
    "  * When implemented appropriately and thoughtfully, algorithms may help uncover patterns in candidates. \n",
    "- Cons: \n",
    "  * Algorithms reflect the data they are given. Bias in the data implies there is bias in the model. \n",
    "  * As we learned earlier in the class, all data contains bias!\n",
    "  * Bias goes beyond gender, as we talked about in this case. It can also portray ageism, ableism, racism, socioeconomic status, etc. Similarly, algorithms can favor key words in resumes that might not be present in resumes of candidates that are highly qualified.\n",
    "  * Not using data that explicitly contains race, sex, or other identities does not mean that our algorithms will not negatively impact certain groups. These groups tend to be the most marginalized and underrepresented.\n",
    "\n",
    "Read More in [Algorithmic and Data Bias](https://medium.com/@sahin.samia/navigating-the-pitfalls-of-ai-in-hiring-unveiling-algorithmic-bias-9e62b50b3f65#:~:text=Imagine%20AI%20tools%20as%20mirrors,and%20diversity%20in%20the%20workplace.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>   *Add any last reflections here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assignment wrapup\n",
    "Please fill out the form that appears when you run the code below. You must completely fill this out in order to receive credit for the assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://cmse.msu.edu/cmse201-ic-survey\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you're done!\n",
    "\n",
    "Submit this assignment by uploading your notebook to the course web page. \n",
    "\n",
    "See you next class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was designed by Emily Bolger and Rachel Roca (2024). \n",
    "\n",
    "&#169; Copyright 2024,  Department of Computational Mathematics, Science and Engineering at Michigan State University, All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
