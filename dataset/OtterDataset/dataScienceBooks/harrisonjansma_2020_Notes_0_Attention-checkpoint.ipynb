{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Primer-on-Attention\" data-toc-modified-id=\"Primer-on-Attention-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Primer on Attention</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Blogs\" data-toc-modified-id=\"Blogs-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Blogs</a></span></li><li><span><a href=\"#Papers\" data-toc-modified-id=\"Papers-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Papers</a></span></li></ul></li><li><span><a href=\"#Primer\" data-toc-modified-id=\"Primer-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Primer</a></span></li><li><span><a href=\"#In-Depth-with-the-Math\" data-toc-modified-id=\"In-Depth-with-the-Math-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>In Depth with the Math</a></span><ul class=\"toc-item\"><li><span><a href=\"#Self-attention\" data-toc-modified-id=\"Self-attention-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Self attention</a></span></li><li><span><a href=\"#Soft-Attention\" data-toc-modified-id=\"Soft-Attention-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Soft Attention</a></span></li><li><span><a href=\"#Hard-Attention\" data-toc-modified-id=\"Hard-Attention-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Hard Attention</a></span></li></ul></li></ul></li><li><span><a href=\"#Neural-Machine-Translation-w-TensorFlow\" data-toc-modified-id=\"Neural-Machine-Translation-w-TensorFlow-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Neural Machine Translation w TensorFlow</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Resources</a></span></li><li><span><a href=\"#TF2-Docs-NMT-Example-(link)\" data-toc-modified-id=\"TF2-Docs-NMT-Example-(link)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TF2 Docs NMT Example (<a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\" target=\"_blank\">link</a>)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-tf.data-dataset\" data-toc-modified-id=\"Create-a-tf.data-dataset-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Create a tf.data dataset</a></span></li><li><span><a href=\"#Implementing-the-Attention-Model\" data-toc-modified-id=\"Implementing-the-Attention-Model-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Implementing the Attention Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Model Evaluation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer on Attention\n",
    "\n",
    "## Resources\n",
    "### Blogs\n",
    "- [Visualizing A Neural Machine Translation Model](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n",
    "- [Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)\n",
    "- [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)\n",
    "- [Intuitive Understanding of Attention Mechanism in Deep Learning](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f)\n",
    "- [Attn: Illustrated Attention](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)\n",
    "\n",
    "### Papers\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\n",
    "- [Show, Attend and Tell: Neural Image Caption\n",
    "Generation with Visual Attention](http://proceedings.mlr.press/v37/xuc15.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer\n",
    "\n",
    "*Below is a summary of the above articles. Note that this is not a polished educational resource in its own right. This is simply me summarizing the concepts that I learn.*\n",
    "\n",
    "__Attention__ began with the task of __Neural Machine Translation__ (NMT). Prior to its discovery, LSTM __encoder-decoder architectures__ were standard practice. The *final hidden state of the encoder LSTM* is passed to the decoder LSTM (called a __context vector__). The decoder uses this summary of the input sentence to generate a sequence of words (translation) as output.\n",
    "\n",
    "![img](https://lilianweng.github.io/lil-log/assets/images/encoder-decoder-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Models with Attention__ the encoder passes hidden states for __all time steps__ to the decoder. The decoder translates these hidden states into a single context vector for each time step. (Note, Attention is in the decoder)\n",
    "\n",
    "The attention mechanism creates shortcuts between encoder hidden states and the output of the decoder, allowing better gradient flow during backpropagation. (As opposed to gradients having to flow through the final output hidden state in a traditional enc-dec arch)\n",
    "\n",
    "$$Encoder(X)\\rightarrow H_E$$\n",
    "$$Decoder(x_t)\\rightarrow h_t$$\n",
    "$$\\frac{\\partial Loss}{\\partial H_E} = \\frac{\\partial Loss}{\\partial H_E}$$\n",
    "\n",
    "\n",
    "\n",
    "__Encoder-Decoder w Attention__\n",
    "0. Encoder processes the input sequences and passes all hidden states ($H_E$) to decoder. \n",
    "1. The decoder RNN takes in the embedding of the `<END>` token and an initial decoder hidden state.\n",
    "2. RNN decoder produces an initial ouput and a hidden state vector ($h_1$) Output is discarded.\n",
    "3. Use the encoder hidden states $H_E$ and the $h_1$ decoder-hidden-state vector to create a prob mask for the hidden states (__attention step__). Combine the encoder hidden states weighted by the prob mask. $\\rightarrow$ Context vector $c_1$\n",
    "4. Concatenate decoder-hidden-state $h_1$ with context vector $c_1$\n",
    "5. Pass this vector through a feedforward head network to produce an output from the vocab.\n",
    "6. Output is saved as output of decoder for timestep 1 ($y_1$)\n",
    "7. Pass the output of prev step ($y_1$) and dec-hidden-state vector ($h_1$) to the decoder for the next time step $\\rightarrow$ produce new hidden state ($h_2$) Continue to 3. and repeat for entire sequence\n",
    "\n",
    "\n",
    "\n",
    "[Here's Jay Alammar's visual of the decoder](http://jalammar.github.io/images/attention_tensor_dance.mp4)\n",
    "\n",
    "__Things to Note:__ \n",
    "- Note that this process can be generalize to any Seq2Seq task. \n",
    "- The process is simply: encoder hidden states $\\rightarrow$ decoder hidden state $\\rightarrow$ attention prob mask $\\rightarrow$ context vector $\\rightarrow$ concatenate $\\rightarrow$ FeedForward Net to softmax output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Depth with the Math\n",
    "\n",
    "Task given a source seq of length n and output seq of length m, $$x = [x_1, ..., x_n]$$ $$y = [y_1,...y_m]$$\n",
    "\n",
    "__Encoder is a bidirectional RNN__ with concatenated hidden_states for forward and backward pass for each time step $i=1,..,n$. \n",
    "$$h_i = [\\overrightarrow{h_i},\\overleftarrow{h_i}]$$\n",
    "\n",
    "\n",
    "The encoder processes the input sequence $x$, and produces a matrix of hidden state vectors with shape = $(len(\\overrightarrow{h_i})+len(\\overleftarrow{h_i}),  n)$\n",
    "\n",
    "$$H_E = [h_1,...,h_n]$$\n",
    "\n",
    "\n",
    "The decoder has a hidden state $s_t = f(s_{t-1}, y_{t-1}, c_t)$ for output $t=1,..,m$. Here the context vector $c_t$ is a dot product between the encoder hidden-state matrix and the alignment vector $\\alpha_t$\n",
    "\n",
    "$$c_t = \\alpha_t\\cdot H_E$$\n",
    "$$\\alpha_t = softmax(score(s_{t-1},H_E)))$$\n",
    "\n",
    "__Alignment Score Functions__ score the previous hidden state $s_{t-1}$ with each vector of te encoder-hidden-state matrix $h_i$, by how well the two states align (dot-product of two vectors is a measure of similarity, higher if vectors are the same direction)\n",
    "\n",
    "\n",
    "$${score}_{Bahdanau}(s_t,H_E) = v^T\\cdot tanh(W \\cdot [s_t;H_E])$$\n",
    "$${score}_{Luong}(s_t, H_E) = s^T_t\\cdot W\\cdot H_E$$\n",
    "$${score}_{Vaswani}(s_t, H_E) = \\frac{s^T_t\\cdot H_E}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context vector $c_t$ is concatentated with the decoder hidden state $s_{t-1}$ and passef through a fully-connected layer and softmax to predict the output word.\n",
    "\n",
    "$$y_t = softmax(W_o\\cdot [c_t;s_{t-1}]+ b_o)$$\n",
    "$$c_t = softmax(s^T_{t-1}\\cdot W\\cdot H_E))\\cdot H_E$$  (Luong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self attention \n",
    "\n",
    "Relates different positions of the same input sequence in order to compute a representation of the same sequence.\n",
    "\n",
    "### Soft Attention\n",
    "\n",
    "Attention mechanism has access to the entire input. \n",
    "\n",
    "### Hard Attention\n",
    "\n",
    "Attention mechanism has access to one patch of input at a time (more efficient compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation w TensorFlow\n",
    "\n",
    "## Resources\n",
    "- [TF2 Docs Example NMT w Attention](https://www.tensorflow.org/tutorials/text/nmt_with_attention)\n",
    "- [NMT GitHub](https://github.com/tensorflow/nmt)\n",
    "- [NMT w Attention Notebook](https://github.com/tensorflow/examples/blob/master/community/en/nmt_with_luong_attention.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## TF2 Docs NMT Example ([link](https://www.tensorflow.org/tutorials/text/nmt_with_attention))\n",
    "\n",
    "Go through the basics of: \n",
    "- preprocessing and tokenizing a text sequence. \n",
    "- Pad the sequence to certain length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:50:42.341457Z",
     "start_time": "2020-02-21T03:50:38.573091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:50:42.369652Z",
     "start_time": "2020-02-21T03:50:42.362648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spa.txt', '_about.txt']\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"E://Data/spa-eng/\"\n",
    "print(os.listdir(base_dir))\n",
    "data_dir = os.path.join(base_dir, 'spa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:50:42.410526Z",
     "start_time": "2020-02-21T03:50:42.396564Z"
    }
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    \"\"\" Converts unicode characters to ascii.\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_data(sentence):\n",
    "    \"\"\"\n",
    "    Removes whitespaces, converts to ascii, adds spaces before after punctuation,\n",
    "    removes extra spaces, removes non letter/punctuation characters,\n",
    "    adds start and end tokens.\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = unicode_to_ascii(sentence)\n",
    "    sentence = re.sub(r'([?.!,¿])', r' \\1 ', sentence) #add space between words and punctuations\n",
    "    sentence = re.sub(r'[\" \"]+', r' ', sentence) #remove double spaces\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence = '<start> '+ sentence + ' <end>' #add start and end tokens\n",
    "    return sentence\n",
    "\n",
    "def create_dataset(path):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split(\"\\n\")\n",
    "    word_pairs = [[preprocess_data(sentence) for sentence in l.split('\\t')] for l in lines]\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:50:55.427652Z",
     "start_time": "2020-02-21T03:50:42.435087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
      "<start> puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboracion . sin embargo , si animamos a los miembros a contribuir frases en sus propios idiomas en lugar de experimentar con los idiomas que estan aprendiendo , podriamos ser capaces de minimizar los errores . <end>\n"
     ]
    }
   ],
   "source": [
    "eng, spa, _ = create_dataset(data_dir)\n",
    "\n",
    "print(eng[-1])\n",
    "print(spa[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:50:55.721746Z",
     "start_time": "2020-02-21T03:50:55.707097Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = \"\")\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path):\n",
    "    targ_lang, inp_lang, _ = create_dataset(data_dir)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:15.526645Z",
     "start_time": "2020-02-21T03:50:55.995917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98668 24667\n"
     ]
    }
   ],
   "source": [
    "input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer = load_dataset(data_dir)\n",
    "in_max, out_max = max_length(input_tensor), max_length(target_tensor)\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "print(len(input_tensor_train), len(input_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:15.835891Z",
     "start_time": "2020-02-21T03:51:15.827913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  370,    3,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [   1, 1397,    3,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what the tensor looks like. \n",
    "input_tensor[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:16.146873Z",
     "start_time": "2020-02-21T03:51:16.140889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1a29f5f3d88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:16.448241Z",
     "start_time": "2020-02-21T03:51:16.439266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ---> <start>\n",
      "370 ---> ve\n",
      "3 ---> .\n",
      "2 ---> <end>\n",
      "\n",
      "1 ---> <start>\n",
      "49 ---> go\n",
      "3 ---> .\n",
      "2 ---> <end>\n"
     ]
    }
   ],
   "source": [
    "def index_to_word(tokenizer, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print(\"%d ---> %s\" % (t, tokenizer.index_word[t]))\n",
    "    \n",
    "index_to_word(inp_lang_tokenizer, input_tensor[0])\n",
    "print()\n",
    "index_to_word(targ_lang_tokenizer, target_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:17.728489Z",
     "start_time": "2020-02-21T03:51:16.737740Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BATCH_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:51:18.070340Z",
     "start_time": "2020-02-21T03:51:18.029935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 59]), TensorShape([64, 54]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Attention Model\n",
    "\n",
    "Encoder will ouput a tensor with shape (batch_size, max_length, hidden_size) and an encoder hidden state of shape (batch_size, hidden_size).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T04:22:29.503050Z",
     "start_time": "2020-02-21T04:22:29.495071Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.GRU = tf.keras.layers.GRU(hidden_dim, \n",
    "                                       return_sequences=True, #because we are doing seq2seq vector for each timestep\n",
    "                                      return_state=True) #return the final hidden state\n",
    "    \n",
    "    def init_state(self):\n",
    "        return tf.zeros((self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.GRU(x, initial_state=self.init_state())\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T04:33:09.042580Z",
     "start_time": "2020-02-21T04:33:08.082660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Batch Shape: (64, 59)\n",
      "Output shape: (64, 59, 1024)\n",
      "Hidden Shape: (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_out, sample_hidden = enc(example_input_batch)\n",
    "print(\"Input Batch Shape:\",example_input_batch.shape) \n",
    "#Input to GRU will be shape (batch_size, max_length, emb_dim)\n",
    "print(\"Output shape:\",sample_out.shape)\n",
    "print(\"Hidden Shape:\", sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:54:52.647491Z",
     "start_time": "2020-02-21T03:54:52.635523Z"
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, activation=None)\n",
    "        self.W2 = tf.keras.layers.Dense(units, activation=None)\n",
    "        self.W3 = tf.keras.layers.Dense(1, activation=None)\n",
    "    \n",
    "    def call(self, s, h):\n",
    "        \"\"\"\n",
    "        s - Decoder output for t-1, shape: (batch_size, dec_hidden_units)\n",
    "        h - Encoder outputs for t=1,..,n. shape: (batch_size, max_len, enc_hidden_units)\n",
    "        \"\"\"\n",
    "        s = tf.expand_dims(s,1) #makes s and h both have rank 3\n",
    "        score = self.W3(tf.nn.tanh(self.W1(s) + self.W2(h)))\n",
    "        a = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = a*h\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1) #how can i write this as mat_vec mult\n",
    "        return context_vector, a\n",
    "\n",
    "    \n",
    "class LuongAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "    \n",
    "    def call(self, s, h):\n",
    "        score = tf.linalg.matmul(h, self.W1(s))\n",
    "        a = tf.nn.softmax(score, axis=1)\n",
    "        return tf.linalg.matmul(a, h, transpose_b=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:55:45.704383Z",
     "start_time": "2020-02-21T03:55:45.675087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector Shape: (64, 1024)\n",
      "Attention Vector Shape: (64, 59, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = BahdanauAttention(10)\n",
    "context, att = attention(tf.random.normal([BATCH_SIZE,units]), sample_out)\n",
    "print(\"Context Vector Shape:\", context.shape)\n",
    "print(\"Attention Vector Shape:\", att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T04:28:01.036567Z",
     "start_time": "2020-02-21T04:28:01.025597Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, target_lang_size, emb_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.batch_size = batch_size\n",
    "        self.emb = tf.keras.layers.Embedding(target_lang_size, emb_dim)\n",
    "        self.GRU = tf.keras.layers.GRU(dec_units, \n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True)\n",
    "        self.attention = BahdanauAttention(dec_units)\n",
    "        self.Dense1 = tf.keras.layers.Dense(target_lang_size)\n",
    "    \n",
    "    def init_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.dec_units))\n",
    "    \n",
    "    def call(self, x, dec_hidden, enc_output):\n",
    "        #context vector has shape (batch_size, enc_units)\n",
    "        context, att = self.attention(dec_hidden, enc_output)\n",
    "        x = self.emb(x)\n",
    "        # x shape after concatenation == (batch_size, 1, hidden_size + embedding_dim)\n",
    "        x = tf.concat([tf.expand_dims(context, axis=1), x], axis=-1)\n",
    "        #note that the GRU will only output one vector per sample since the input format is (batch_size, time_steps=1, features)\n",
    "        out, hidden = self.GRU(x)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.Dense1(out)\n",
    "        return out, hidden, att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T04:33:35.284706Z",
     "start_time": "2020-02-21T04:33:34.328972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 13048)\n"
     ]
    }
   ],
   "source": [
    "dec = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_output, _, att_weights = dec(tf.random.uniform((BATCH_SIZE, 1)), #simulate a word\n",
    "                                      sample_hidden, \n",
    "                                    sample_out)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_output.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'E://Models/Neural_Machine_Translation'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        #teacher forcing\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            precitions, dec_hidden, _ =decoder(dec_inputs, dec_hidden, enc_output)\n",
    "    \n",
    "            loss += loss_function(targ[:,t], predictions)\n",
    "            dec_input - tf.expand_dims(targ[:,t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradient = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradient, variables))\n",
    "    return batch_loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss+=batch_loss\n",
    "        if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
