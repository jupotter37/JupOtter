{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd026b0-21b2-4d7b-8bd7-665fd2eae38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs found: 319\n",
      "                             Title               Company  \\\n",
      "0                 Report Developer  Kontoor Brands, Inc.   \n",
      "1  AI Researcher (Computer Vision)       Datalytics Labs   \n",
      "2               IDT Data Scientist                   BAT   \n",
      "3                  System Engineer                 Wipro   \n",
      "\n",
      "                                                Link         Time  \\\n",
      "0  https://bd.linkedin.com/jobs/view/report-devel...   1 week ago   \n",
      "1  https://bd.linkedin.com/jobs/view/ai-researche...  8 hours ago   \n",
      "2  https://bd.linkedin.com/jobs/view/idt-data-sci...   1 week ago   \n",
      "3  https://bd.linkedin.com/jobs/view/system-engin...   2 days ago   \n",
      "\n",
      "              Level       Type                                 Funtion  \\\n",
      "0  Mid-Senior level  Full-time                  Information Technology   \n",
      "1        Internship  Full-time  Engineering and Information Technology   \n",
      "2  Mid-Senior level  Full-time                    Research and Science   \n",
      "3    Not Applicable  Full-time                  Information Technology   \n",
      "\n",
      "                                  Industry  \n",
      "0               Retail Apparel and Fashion  \n",
      "1                     Software Development  \n",
      "2  Manufacturing and Tobacco Manufacturing  \n",
      "3            IT Services and IT Consulting  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Entering website\n",
    "url = 'https://www.linkedin.com/'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Function to check for the login page and go back\n",
    "def check_and_go_back_if_login_page():\n",
    "    try:\n",
    "        login_element = driver.find_element(By.XPATH, '//*[@id=\"join-form-submit\"]')\n",
    "        if login_element:\n",
    "            print(\"Login page detected. Going back to continue scraping.\")\n",
    "            driver.back()\n",
    "            time.sleep(3)  # Wait for the previous page to load\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def scrape_jobs():\n",
    "    driver.find_element(By.XPATH, '/html/body/nav/ul/li[4]').click()\n",
    "    time.sleep(3)\n",
    "    search_bar = driver.find_element(By.XPATH, '//*[@id=\"job-search-bar-keywords\"]')\n",
    "    search_bar.click()\n",
    "    \n",
    "    search_query = \"Data Analyst\"\n",
    "    search_bar.send_keys(search_query)\n",
    "    \n",
    "    # Press Enter to search\n",
    "    search_bar.send_keys(Keys.ENTER)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    driver.find_element(By.XPATH, '//*[@id=\"jobs-search-panel\"]/form/section[2]/button').click()\n",
    "    time.sleep(3)\n",
    "    search_bar = driver.find_element(By.XPATH, '//*[@id=\"job-search-bar-location\"]')\n",
    "    search_bar.click()\n",
    "\n",
    "    # Clear the location and enter a new one\n",
    "    search_bar.send_keys(Keys.CONTROL + \"a\")\n",
    "    search_bar.send_keys(Keys.DELETE)\n",
    "    search_query = \"Dhaka\"\n",
    "    search_bar.send_keys(search_query)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Press Enter to search\n",
    "    search_bar.send_keys(Keys.ENTER)\n",
    "    time.sleep(3)\n",
    "\n",
    "    #selecting filter option\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"jserp-filters\"]/ul/li[2]/div/div/button').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"f_TPR-1\"]').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"jserp-filters\"]/ul/li[2]/div/div/div/button').click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract the total number of jobs\n",
    "    total_jobs_element = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/div/h1/span[1]')\n",
    "    total_jobs_text = total_jobs_element.text.split()[0].replace(',', '')\n",
    "    total_jobs = int(total_jobs_text)\n",
    "\n",
    "    print(f\"Total jobs found: {total_jobs}\")\n",
    "    \n",
    "    Title = []\n",
    "    Company = []\n",
    "    Link = []\n",
    "    Time = []\n",
    "    Level = []\n",
    "    Type = []\n",
    "    Funtion = []\n",
    "    Industry = []\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        try:\n",
    "            if check_and_go_back_if_login_page():\n",
    "                continue\n",
    "                \n",
    "            job_listing_xpath = f'//*[@id=\"main-content\"]/section[2]/ul/li[{i}]/div/a'\n",
    "            job_link = driver.find_element(By.XPATH, job_listing_xpath)\n",
    "            \n",
    "            link = job_link.get_attribute('href')\n",
    "            \n",
    "            job_link.click()\n",
    "            time.sleep(6)\n",
    "\n",
    "            if check_and_go_back_if_login_page():\n",
    "                # Re-click the job link after going back\n",
    "                job_link = driver.find_element(By.XPATH, job_listing_xpath)\n",
    "                job_link.click()\n",
    "                time.sleep(3)\n",
    "\n",
    "            # Extract job details\n",
    "            job_title = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]//h1').text\n",
    "            job_company = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/section[2]/div/div[1]/div/h4/div[1]/span[1]/a').text\n",
    "            times = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/section[2]/div/div[1]/div/h4/div[2]/span').text\n",
    "            level = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/div/section[1]/div/ul/li[1]/span').text\n",
    "            type = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/div/section[1]/div/ul/li[2]/span').text\n",
    "            func = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/div/section[1]/div/ul/li[3]/span').text\n",
    "            industry = driver.find_element(By.XPATH, '//*[@id=\"main-content\"]/section[1]/div/div/section[1]/div/ul/li[4]/span').text\n",
    "\n",
    "            # Append data to lists only if all elements are successfully retrieved\n",
    "            Title.append(job_title)\n",
    "            Company.append(job_company)\n",
    "            Link.append(link)        \n",
    "            Time.append(times)\n",
    "            Level.append(level)\n",
    "            Type.append(type)\n",
    "            Funtion.append(func)\n",
    "            Industry.append(industry)\n",
    "            \n",
    "            driver.back()\n",
    "            time.sleep(3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping job {i}: {e}\")\n",
    "\n",
    "\n",
    "    # Convert the data to a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Title': Title,\n",
    "        'Company': Company,\n",
    "        'Link': Link,\n",
    "        'Time': Time,\n",
    "        'Level': Level,\n",
    "        'Type': Type,\n",
    "        'Funtion': Funtion,\n",
    "        'Industry': Industry,\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    df.to_csv('C:/Users/Saiful Hasan/Downloads/job_list.csv', index=False)\n",
    "\n",
    "scrape_jobs()\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abd18c-0a60-4e4b-a497-dadfd8ad03e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
