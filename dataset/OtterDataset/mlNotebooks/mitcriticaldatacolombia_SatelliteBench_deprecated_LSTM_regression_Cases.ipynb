{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050bec7b",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958b74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84037746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64f8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Tabular_data/dengue_tabular.csv'\n",
    "MUNICIPALITY = 'Ibagué'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ea630",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bab31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36e5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353460de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Cases']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3fe70",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd5eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=MUNICIPALITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d92490",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448ff98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200701</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200702</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200703</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200704</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200705</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201948</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201949</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201950</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201951</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201952</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cases\n",
       "200701     16\n",
       "200702     15\n",
       "200703     13\n",
       "200704     12\n",
       "200705     17\n",
       "...       ...\n",
       "201948    149\n",
       "201949    171\n",
       "201950    175\n",
       "201951    116\n",
       "201952     43\n",
       "\n",
       "[676 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = labels_df\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc103e3",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6ba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1352b223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (540, 1)\n",
      "The test shape is: (136, 1)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a2c8c5",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7770eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), scaler=True):\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, scaler=True):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "        \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d764aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "Cases   -1.0\n",
      "dtype: float64\n",
      " Max values are: \n",
      "Cases    1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200701</th>\n",
       "      <td>-0.925072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200702</th>\n",
       "      <td>-0.930836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200703</th>\n",
       "      <td>-0.942363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200704</th>\n",
       "      <td>-0.948127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200705</th>\n",
       "      <td>-0.919308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cases\n",
       "200701 -0.925072\n",
       "200702 -0.930836\n",
       "200703 -0.942363\n",
       "200704 -0.948127\n",
       "200705 -0.919308"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32563dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "Cases   -1.0\n",
      "dtype: float64\n",
      " Max values are: \n",
      "Cases    0.210375\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201721</th>\n",
       "      <td>-0.953890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201722</th>\n",
       "      <td>-0.942363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201723</th>\n",
       "      <td>-0.930836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201724</th>\n",
       "      <td>-0.907781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201725</th>\n",
       "      <td>-0.936599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cases\n",
       "201721 -0.953890\n",
       "201722 -0.942363\n",
       "201723 -0.930836\n",
       "201724 -0.907781\n",
       "201725 -0.936599"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea114e",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07de9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-1])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-1)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406c8644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var1(t-9)</th>\n",
       "      <th>var1(t-8)</th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200711</th>\n",
       "      <td>-0.925072</td>\n",
       "      <td>-0.930836</td>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.919308</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.936599</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.959654</td>\n",
       "      <td>-0.850144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200712</th>\n",
       "      <td>-0.930836</td>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.919308</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.936599</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.959654</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.942363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200713</th>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.919308</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.936599</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.959654</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200714</th>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.919308</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.936599</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.959654</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.890490</td>\n",
       "      <td>-0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200715</th>\n",
       "      <td>-0.919308</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.936599</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.873199</td>\n",
       "      <td>-0.959654</td>\n",
       "      <td>-0.850144</td>\n",
       "      <td>-0.942363</td>\n",
       "      <td>-0.890490</td>\n",
       "      <td>-0.890490</td>\n",
       "      <td>-0.919308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201716</th>\n",
       "      <td>-0.896254</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.971182</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.953890</td>\n",
       "      <td>-0.925072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201717</th>\n",
       "      <td>-0.948127</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.971182</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.953890</td>\n",
       "      <td>-0.925072</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201718</th>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.971182</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.953890</td>\n",
       "      <td>-0.925072</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.965418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201719</th>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.971182</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.953890</td>\n",
       "      <td>-0.925072</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.965418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201720</th>\n",
       "      <td>-0.982709</td>\n",
       "      <td>-0.971182</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.953890</td>\n",
       "      <td>-0.925072</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.948127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
       "200711   -0.925072  -0.930836  -0.942363  -0.948127  -0.919308  -0.850144   \n",
       "200712   -0.930836  -0.942363  -0.948127  -0.919308  -0.850144  -0.936599   \n",
       "200713   -0.942363  -0.948127  -0.919308  -0.850144  -0.936599  -0.873199   \n",
       "200714   -0.948127  -0.919308  -0.850144  -0.936599  -0.873199  -0.873199   \n",
       "200715   -0.919308  -0.850144  -0.936599  -0.873199  -0.873199  -0.959654   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "201716   -0.896254  -0.948127  -0.965418  -0.982709  -0.982709  -0.971182   \n",
       "201717   -0.948127  -0.965418  -0.982709  -0.982709  -0.971182  -0.976945   \n",
       "201718   -0.965418  -0.982709  -0.982709  -0.971182  -0.976945  -0.976945   \n",
       "201719   -0.982709  -0.982709  -0.971182  -0.976945  -0.976945  -0.965418   \n",
       "201720   -0.982709  -0.971182  -0.976945  -0.976945  -0.965418  -0.953890   \n",
       "\n",
       "        var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)   var1(t)  \n",
       "200711  -0.936599  -0.873199  -0.873199  -0.959654 -0.850144  \n",
       "200712  -0.873199  -0.873199  -0.959654  -0.850144 -0.942363  \n",
       "200713  -0.873199  -0.959654  -0.850144  -0.942363 -0.890490  \n",
       "200714  -0.959654  -0.850144  -0.942363  -0.890490 -0.890490  \n",
       "200715  -0.850144  -0.942363  -0.890490  -0.890490 -0.919308  \n",
       "...           ...        ...        ...        ...       ...  \n",
       "201716  -0.976945  -0.976945  -0.965418  -0.953890 -0.925072  \n",
       "201717  -0.976945  -0.965418  -0.953890  -0.925072 -1.000000  \n",
       "201718  -0.965418  -0.953890  -0.925072  -1.000000 -0.965418  \n",
       "201719  -0.953890  -0.925072  -1.000000  -0.965418 -0.965418  \n",
       "201720  -0.925072  -1.000000  -0.965418  -0.965418 -0.948127  \n",
       "\n",
       "[530 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = False\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "test = series_to_supervised(test_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7557923",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7ee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (Cases and media cloud)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use Covid cases in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-1])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8263e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (530, 10)\n",
      "The shape of the labels is (530, 1)\n",
      "Test:\n",
      "The shape of the features is (126, 10)\n",
      "The shape of the labels is (126, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ae166",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "917ebd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features, no_autoregressive=None):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    if no_autoregressive:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features-1))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features-1))\n",
    "    \n",
    "    else:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ae00937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (530, 10)\n",
      "The test shape is (126, 10)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (530, 10, 1)\n",
      "The test shape is (126, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features, no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da105ac",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2e571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "        tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "        smape\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddd61c",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78645483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ea9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, plot=None, epochs=50):\n",
    "    if monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e5ac5",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bf46373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "def test_model(model, test_X, test_y, scaler, rnn = None):\n",
    "    \n",
    "    # If model is a classical machine learning model and test_X is a 3D tensor, then convert to 2D\n",
    "    if not rnn and (len(test_X.shape) == 3):\n",
    "        test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    # do the prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    # Inverse Scaler\n",
    "    \n",
    "    # Predicted\n",
    "    if not rnn:\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        \n",
    "    if not scaler:\n",
    "        return yhat, test_y\n",
    "    \n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    \n",
    "    # Real:\n",
    "    inv_y = scaler.inverse_transform(test_y)\n",
    "    \n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc2e0",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$$\n",
    "MAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{x_i-y_i}{y_t}\\right|\n",
    "$$\n",
    "\n",
    "MAPE has a problem if there are zeros in the test data, so other metrics can be explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf17031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Test MAPE: %.3f' % mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe975dc",
   "metadata": {},
   "source": [
    "### Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "\n",
    "$$\n",
    "sMAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n} \\frac{|x_i-y_i|}{|x_i|+|y_t|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da7e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    smape = 1/len(y_true) * np.sum(2 * np.abs(y_pred-y_true) / (np.abs(y_true) + np.abs(y_pred))*100)\n",
    "    print('Test sMAPE: %.3f' % smape)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c94c63",
   "metadata": {},
   "source": [
    "### Mean Absoulte Error (MAE)\n",
    "$$\n",
    "RMSE = \\sqrt{(\\frac{1}{n})\\sum_{i=1}^{n}(x_i-y_i)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee190b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de66f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(inv_y, inv_yhat, model_name = ''):\n",
    "    data_predict = inv_yhat  ## predicted target cases\n",
    "    dataY_plot = inv_y  ##  real test-target cases\n",
    "\n",
    "    data_predict = data_predict.reshape(len(data_predict), 1)\n",
    "    dataY_plot = dataY_plot.reshape(len(dataY_plot), 1)\n",
    "\n",
    "    plt.plot(dataY_plot, label = 'actual')\n",
    "    plt.plot(data_predict, label = 'predicted')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.suptitle(f'Time-Series Prediction with {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e968250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_X, test_y, scaler):\n",
    "    stored_results = {}\n",
    "    \n",
    "    inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=y_scaler, rnn = True)\n",
    "    stored_results['mape'] = mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['smape'] = symmetric_mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['rmse'] = root_mean_squared_error(inv_y_lstm, inv_yhat_lstm)\n",
    "\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8d56e",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3ca87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM:\n",
    "#print(f'The scalers are: {scalers.keys()}')\n",
    "y_scaler = scalers['scaler_Cases']\n",
    "\n",
    "def calculate_mean_std():\n",
    "    \n",
    "    metrics = {\n",
    "        \"rmse\": [],\n",
    "        \"mape\": [],\n",
    "        \"smape\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor)\n",
    "        stored_results = evaluate(model, test_X, test_y, y_scaler)\n",
    "        print(stored_results)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1fd5ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 - 3s - loss: 0.1015 - rmse: 0.3186 - mape: 92.3656 - smape: 0.3869 - val_loss: 0.0260 - val_rmse: 0.1614 - val_mape: 79.1736 - val_smape: 0.2332\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0388 - rmse: 0.1969 - mape: 79.5974 - smape: 0.2258 - val_loss: 0.0179 - val_rmse: 0.1339 - val_mape: 81.0336 - val_smape: 0.1820\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0305 - rmse: 0.1747 - mape: 73.2644 - smape: 0.2017 - val_loss: 0.0174 - val_rmse: 0.1318 - val_mape: 77.1057 - val_smape: 0.1663\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0326 - rmse: 0.1805 - mape: 71.1147 - smape: 0.2111 - val_loss: 0.0155 - val_rmse: 0.1246 - val_mape: 70.8776 - val_smape: 0.1728\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0327 - rmse: 0.1809 - mape: 67.5988 - smape: 0.2125 - val_loss: 0.0146 - val_rmse: 0.1208 - val_mape: 68.8869 - val_smape: 0.1584\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0301 - rmse: 0.1736 - mape: 69.3522 - smape: 0.2016 - val_loss: 0.0144 - val_rmse: 0.1198 - val_mape: 70.9593 - val_smape: 0.1640\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0283 - rmse: 0.1683 - mape: 74.3750 - smape: 0.1935 - val_loss: 0.0142 - val_rmse: 0.1192 - val_mape: 70.4052 - val_smape: 0.1661\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0310 - rmse: 0.1760 - mape: 73.6777 - smape: 0.2066 - val_loss: 0.0157 - val_rmse: 0.1255 - val_mape: 66.8247 - val_smape: 0.1786\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0249 - rmse: 0.1578 - mape: 72.8484 - smape: 0.1805 - val_loss: 0.0134 - val_rmse: 0.1160 - val_mape: 77.3155 - val_smape: 0.1597\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0250 - rmse: 0.1580 - mape: 64.6170 - smape: 0.1809 - val_loss: 0.0125 - val_rmse: 0.1119 - val_mape: 63.2485 - val_smape: 0.1556\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0229 - rmse: 0.1513 - mape: 68.9137 - smape: 0.1737 - val_loss: 0.0124 - val_rmse: 0.1114 - val_mape: 73.9030 - val_smape: 0.1452\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0229 - rmse: 0.1515 - mape: 58.6949 - smape: 0.1757 - val_loss: 0.0120 - val_rmse: 0.1095 - val_mape: 54.1906 - val_smape: 0.1487\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0320 - rmse: 0.1790 - mape: 70.8833 - smape: 0.2082 - val_loss: 0.0168 - val_rmse: 0.1296 - val_mape: 88.9951 - val_smape: 0.1895\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0259 - rmse: 0.1609 - mape: 64.8168 - smape: 0.1826 - val_loss: 0.0124 - val_rmse: 0.1115 - val_mape: 59.4778 - val_smape: 0.1550\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0227 - rmse: 0.1508 - mape: 67.9257 - smape: 0.1751 - val_loss: 0.0120 - val_rmse: 0.1094 - val_mape: 71.2506 - val_smape: 0.1477\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0214 - rmse: 0.1463 - mape: 65.4765 - smape: 0.1661 - val_loss: 0.0112 - val_rmse: 0.1060 - val_mape: 67.6070 - val_smape: 0.1436\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0208 - rmse: 0.1443 - mape: 61.0837 - smape: 0.1658 - val_loss: 0.0114 - val_rmse: 0.1068 - val_mape: 56.5592 - val_smape: 0.1398\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0221 - rmse: 0.1485 - mape: 67.6655 - smape: 0.1725 - val_loss: 0.0123 - val_rmse: 0.1107 - val_mape: 81.8712 - val_smape: 0.1547\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0195 - rmse: 0.1396 - mape: 58.5608 - smape: 0.1648 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 48.3850 - val_smape: 0.1439\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0266 - rmse: 0.1630 - mape: 71.2389 - smape: 0.1949 - val_loss: 0.0123 - val_rmse: 0.1111 - val_mape: 78.5485 - val_smape: 0.1538\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0249 - rmse: 0.1578 - mape: 67.3914 - smape: 0.1870 - val_loss: 0.0122 - val_rmse: 0.1103 - val_mape: 52.2319 - val_smape: 0.1501\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1563 - mape: 56.6374 - smape: 0.1808 - val_loss: 0.0121 - val_rmse: 0.1102 - val_mape: 75.6443 - val_smape: 0.1536\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 48.0439 - smape: 0.1672 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 55.1346 - val_smape: 0.1425\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0259 - rmse: 0.1608 - mape: 67.0645 - smape: 0.1870 - val_loss: 0.0133 - val_rmse: 0.1151 - val_mape: 63.1341 - val_smape: 0.1611\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 56.9498 - smape: 0.1645 - val_loss: 0.0115 - val_rmse: 0.1071 - val_mape: 61.9105 - val_smape: 0.1448\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0203 - rmse: 0.1426 - mape: 63.2671 - smape: 0.1639 - val_loss: 0.0114 - val_rmse: 0.1070 - val_mape: 70.8321 - val_smape: 0.1447\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1455 - mape: 65.9742 - smape: 0.1676 - val_loss: 0.0122 - val_rmse: 0.1104 - val_mape: 56.2637 - val_smape: 0.1509\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0203 - rmse: 0.1424 - mape: 59.9588 - smape: 0.1659 - val_loss: 0.0114 - val_rmse: 0.1068 - val_mape: 65.1300 - val_smape: 0.1497\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0193 - rmse: 0.1390 - mape: 60.7373 - smape: 0.1615 - val_loss: 0.0112 - val_rmse: 0.1059 - val_mape: 56.1668 - val_smape: 0.1400\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0211 - rmse: 0.1451 - mape: 68.0168 - smape: 0.1739 - val_loss: 0.0096 - val_rmse: 0.0980 - val_mape: 59.0124 - val_smape: 0.1328\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0173 - rmse: 0.1315 - mape: 61.9913 - smape: 0.1556 - val_loss: 0.0111 - val_rmse: 0.1055 - val_mape: 63.5661 - val_smape: 0.1467\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0193 - rmse: 0.1388 - mape: 61.7159 - smape: 0.1579 - val_loss: 0.0121 - val_rmse: 0.1102 - val_mape: 69.4371 - val_smape: 0.1508\n",
      "Epoch 33/50\n",
      "34/34 - 0s - loss: 0.0184 - rmse: 0.1355 - mape: 61.1051 - smape: 0.1599 - val_loss: 0.0120 - val_rmse: 0.1097 - val_mape: 64.3798 - val_smape: 0.1513\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0197 - rmse: 0.1403 - mape: 66.2013 - smape: 0.1670 - val_loss: 0.0099 - val_rmse: 0.0997 - val_mape: 60.9019 - val_smape: 0.1319\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0158 - rmse: 0.1257 - mape: 63.2466 - smape: 0.1518 - val_loss: 0.0110 - val_rmse: 0.1047 - val_mape: 70.7820 - val_smape: 0.1462\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0177 - rmse: 0.1331 - mape: 62.7446 - smape: 0.1579 - val_loss: 0.0132 - val_rmse: 0.1148 - val_mape: 48.0078 - val_smape: 0.1537\n",
      "Epoch 37/50\n",
      "34/34 - 0s - loss: 0.0200 - rmse: 0.1413 - mape: 55.2547 - smape: 0.1701 - val_loss: 0.0096 - val_rmse: 0.0979 - val_mape: 75.3978 - val_smape: 0.1340\n",
      "Epoch 38/50\n",
      "34/34 - 0s - loss: 0.0196 - rmse: 0.1402 - mape: 56.4393 - smape: 0.1708 - val_loss: 0.0142 - val_rmse: 0.1190 - val_mape: 59.1232 - val_smape: 0.1624\n",
      "Epoch 39/50\n",
      "34/34 - 0s - loss: 0.0219 - rmse: 0.1481 - mape: 67.3691 - smape: 0.1747 - val_loss: 0.0089 - val_rmse: 0.0943 - val_mape: 73.4005 - val_smape: 0.1329\n",
      "Epoch 40/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 67.3569 - smape: 0.1755 - val_loss: 0.0175 - val_rmse: 0.1323 - val_mape: 67.0919 - val_smape: 0.1852\n",
      "Epoch 41/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1420 - mape: 63.8511 - smape: 0.1695 - val_loss: 0.0117 - val_rmse: 0.1082 - val_mape: 68.8249 - val_smape: 0.1534\n",
      "Epoch 42/50\n",
      "34/34 - 0s - loss: 0.0183 - rmse: 0.1353 - mape: 65.1132 - smape: 0.1588 - val_loss: 0.0139 - val_rmse: 0.1180 - val_mape: 89.6771 - val_smape: 0.1694\n",
      "Epoch 43/50\n",
      "34/34 - 0s - loss: 0.0180 - rmse: 0.1343 - mape: 62.1560 - smape: 0.1591 - val_loss: 0.0147 - val_rmse: 0.1211 - val_mape: 58.6986 - val_smape: 0.1686\n",
      "Epoch 44/50\n",
      "34/34 - 0s - loss: 0.0165 - rmse: 0.1285 - mape: 59.5264 - smape: 0.1468 - val_loss: 0.0128 - val_rmse: 0.1133 - val_mape: 83.8052 - val_smape: 0.1630\n",
      "Epoch 45/50\n",
      "34/34 - 0s - loss: 0.0209 - rmse: 0.1446 - mape: 49.8282 - smape: 0.1673 - val_loss: 0.0159 - val_rmse: 0.1261 - val_mape: 68.0158 - val_smape: 0.1760\n",
      "Epoch 46/50\n",
      "34/34 - 0s - loss: 0.0185 - rmse: 0.1359 - mape: 55.9743 - smape: 0.1588 - val_loss: 0.0157 - val_rmse: 0.1251 - val_mape: 69.6268 - val_smape: 0.1764\n",
      "Epoch 47/50\n",
      "34/34 - 0s - loss: 0.0194 - rmse: 0.1394 - mape: 59.4762 - smape: 0.1566 - val_loss: 0.0143 - val_rmse: 0.1197 - val_mape: 80.3300 - val_smape: 0.1700\n",
      "Epoch 48/50\n",
      "34/34 - 0s - loss: 0.0175 - rmse: 0.1323 - mape: 58.1137 - smape: 0.1538 - val_loss: 0.0130 - val_rmse: 0.1141 - val_mape: 64.6747 - val_smape: 0.1599\n",
      "Epoch 49/50\n",
      "34/34 - 0s - loss: 0.0174 - rmse: 0.1320 - mape: 54.7832 - smape: 0.1489 - val_loss: 0.0160 - val_rmse: 0.1264 - val_mape: 68.7856 - val_smape: 0.1781\n",
      "Epoch 50/50\n",
      "34/34 - 0s - loss: 0.0163 - rmse: 0.1277 - mape: 60.5183 - smape: 0.1494 - val_loss: 0.0168 - val_rmse: 0.1297 - val_mape: 87.5252 - val_smape: 0.1880\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "Test MAPE: 64.851\n",
      "Test sMAPE: 42.792\n",
      "Test RMSE: 17.002\n",
      "{'mape': 64.85118579124047, 'smape': 42.79239070029966, 'rmse': 17.001793968598406}\n",
      "Epoch 1/50\n",
      "34/34 - 3s - loss: 0.0973 - rmse: 0.3120 - mape: 88.3135 - smape: 0.3790 - val_loss: 0.0261 - val_rmse: 0.1615 - val_mape: 76.5049 - val_smape: 0.2326\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0387 - rmse: 0.1966 - mape: 81.4643 - smape: 0.2281 - val_loss: 0.0176 - val_rmse: 0.1326 - val_mape: 78.3558 - val_smape: 0.1785\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0334 - rmse: 0.1829 - mape: 80.2217 - smape: 0.2109 - val_loss: 0.0163 - val_rmse: 0.1275 - val_mape: 73.7251 - val_smape: 0.1729\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0365 - rmse: 0.1910 - mape: 79.9604 - smape: 0.2251 - val_loss: 0.0177 - val_rmse: 0.1330 - val_mape: 68.6193 - val_smape: 0.1898\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0289 - rmse: 0.1701 - mape: 74.9288 - smape: 0.1989 - val_loss: 0.0145 - val_rmse: 0.1205 - val_mape: 68.4014 - val_smape: 0.1632\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0265 - rmse: 0.1628 - mape: 72.8323 - smape: 0.1904 - val_loss: 0.0136 - val_rmse: 0.1167 - val_mape: 64.9146 - val_smape: 0.1606\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0248 - rmse: 0.1576 - mape: 71.7110 - smape: 0.1822 - val_loss: 0.0130 - val_rmse: 0.1141 - val_mape: 67.0113 - val_smape: 0.1556\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0247 - rmse: 0.1573 - mape: 70.7936 - smape: 0.1823 - val_loss: 0.0122 - val_rmse: 0.1104 - val_mape: 62.2767 - val_smape: 0.1434\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0258 - rmse: 0.1607 - mape: 63.8233 - smape: 0.1849 - val_loss: 0.0125 - val_rmse: 0.1117 - val_mape: 68.6874 - val_smape: 0.1484\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1563 - mape: 69.5855 - smape: 0.1802 - val_loss: 0.0123 - val_rmse: 0.1109 - val_mape: 58.2056 - val_smape: 0.1534\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0297 - rmse: 0.1725 - mape: 71.9127 - smape: 0.2070 - val_loss: 0.0138 - val_rmse: 0.1173 - val_mape: 81.0841 - val_smape: 0.1668\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0257 - rmse: 0.1603 - mape: 69.9100 - smape: 0.1842 - val_loss: 0.0136 - val_rmse: 0.1166 - val_mape: 53.7520 - val_smape: 0.1607\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0278 - rmse: 0.1668 - mape: 67.1458 - smape: 0.1967 - val_loss: 0.0167 - val_rmse: 0.1293 - val_mape: 101.9411 - val_smape: 0.1877\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0283 - rmse: 0.1683 - mape: 71.3900 - smape: 0.1899 - val_loss: 0.0126 - val_rmse: 0.1124 - val_mape: 60.3449 - val_smape: 0.1563\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0245 - rmse: 0.1564 - mape: 67.9824 - smape: 0.1825 - val_loss: 0.0119 - val_rmse: 0.1092 - val_mape: 71.0711 - val_smape: 0.1481\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0201 - rmse: 0.1419 - mape: 57.0618 - smape: 0.1641 - val_loss: 0.0113 - val_rmse: 0.1062 - val_mape: 57.9263 - val_smape: 0.1450\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0223 - rmse: 0.1495 - mape: 69.4962 - smape: 0.1745 - val_loss: 0.0117 - val_rmse: 0.1084 - val_mape: 72.1863 - val_smape: 0.1502\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0221 - rmse: 0.1486 - mape: 65.2389 - smape: 0.1742 - val_loss: 0.0124 - val_rmse: 0.1115 - val_mape: 54.7864 - val_smape: 0.1521\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0260 - rmse: 0.1612 - mape: 53.2441 - smape: 0.1878 - val_loss: 0.0144 - val_rmse: 0.1198 - val_mape: 88.3045 - val_smape: 0.1731\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0222 - rmse: 0.1491 - mape: 64.0801 - smape: 0.1686 - val_loss: 0.0121 - val_rmse: 0.1099 - val_mape: 52.1845 - val_smape: 0.1505\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0218 - rmse: 0.1477 - mape: 68.2307 - smape: 0.1723 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 67.9888 - val_smape: 0.1504\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0208 - rmse: 0.1441 - mape: 64.7623 - smape: 0.1652 - val_loss: 0.0130 - val_rmse: 0.1140 - val_mape: 58.2580 - val_smape: 0.1577\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1528 - mape: 57.2811 - smape: 0.1759 - val_loss: 0.0117 - val_rmse: 0.1082 - val_mape: 65.5410 - val_smape: 0.1483\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0229 - rmse: 0.1513 - mape: 62.8207 - smape: 0.1780 - val_loss: 0.0118 - val_rmse: 0.1088 - val_mape: 58.7043 - val_smape: 0.1507\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0197 - rmse: 0.1405 - mape: 66.3188 - smape: 0.1627 - val_loss: 0.0107 - val_rmse: 0.1032 - val_mape: 64.9469 - val_smape: 0.1389\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0177 - rmse: 0.1331 - mape: 61.2694 - smape: 0.1559 - val_loss: 0.0111 - val_rmse: 0.1053 - val_mape: 60.9884 - val_smape: 0.1412\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0179 - rmse: 0.1339 - mape: 57.1422 - smape: 0.1587 - val_loss: 0.0109 - val_rmse: 0.1042 - val_mape: 67.4076 - val_smape: 0.1394\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0199 - rmse: 0.1410 - mape: 65.6835 - smape: 0.1650 - val_loss: 0.0118 - val_rmse: 0.1086 - val_mape: 58.0429 - val_smape: 0.1447\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0242 - rmse: 0.1556 - mape: 61.2638 - smape: 0.1836 - val_loss: 0.0123 - val_rmse: 0.1108 - val_mape: 69.7845 - val_smape: 0.1388\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0249 - rmse: 0.1579 - mape: 65.5746 - smape: 0.1773 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 90.7233 - val_smape: 0.1578\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0214 - rmse: 0.1462 - mape: 63.4394 - smape: 0.1678 - val_loss: 0.0119 - val_rmse: 0.1093 - val_mape: 46.1259 - val_smape: 0.1450\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1596 - mape: 72.7836 - smape: 0.1884 - val_loss: 0.0120 - val_rmse: 0.1096 - val_mape: 65.4685 - val_smape: 0.1526\n",
      "Epoch 33/50\n",
      "34/34 - 0s - loss: 0.0190 - rmse: 0.1378 - mape: 66.5640 - smape: 0.1639 - val_loss: 0.0122 - val_rmse: 0.1103 - val_mape: 47.3555 - val_smape: 0.1446\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0233 - rmse: 0.1525 - mape: 67.3046 - smape: 0.1778 - val_loss: 0.0125 - val_rmse: 0.1117 - val_mape: 89.1790 - val_smape: 0.1465\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1483 - mape: 60.5251 - smape: 0.1805 - val_loss: 0.0134 - val_rmse: 0.1157 - val_mape: 49.8755 - val_smape: 0.1566\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0265 - rmse: 0.1626 - mape: 68.3743 - smape: 0.1854 - val_loss: 0.0102 - val_rmse: 0.1012 - val_mape: 85.7271 - val_smape: 0.1457\n",
      "Epoch 37/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1598 - mape: 71.7886 - smape: 0.1988 - val_loss: 0.0183 - val_rmse: 0.1351 - val_mape: 81.5456 - val_smape: 0.1934\n",
      "Epoch 38/50\n",
      "34/34 - 0s - loss: 0.0152 - rmse: 0.1235 - mape: 53.1384 - smape: 0.1410 - val_loss: 0.0112 - val_rmse: 0.1060 - val_mape: 73.1019 - val_smape: 0.1402\n",
      "Epoch 39/50\n",
      "34/34 - 0s - loss: 0.0170 - rmse: 0.1305 - mape: 57.0179 - smape: 0.1533 - val_loss: 0.0109 - val_rmse: 0.1044 - val_mape: 72.0935 - val_smape: 0.1467\n",
      "Epoch 40/50\n",
      "34/34 - 0s - loss: 0.0167 - rmse: 0.1293 - mape: 37.4548 - smape: 0.1514 - val_loss: 0.0123 - val_rmse: 0.1110 - val_mape: 66.4077 - val_smape: 0.1552\n",
      "Epoch 41/50\n",
      "34/34 - 0s - loss: 0.0178 - rmse: 0.1333 - mape: 59.8060 - smape: 0.1565 - val_loss: 0.0154 - val_rmse: 0.1241 - val_mape: 75.8581 - val_smape: 0.1750\n",
      "Epoch 42/50\n",
      "34/34 - 0s - loss: 0.0228 - rmse: 0.1509 - mape: 63.7559 - smape: 0.1771 - val_loss: 0.0160 - val_rmse: 0.1264 - val_mape: 56.8661 - val_smape: 0.1768\n",
      "Epoch 43/50\n",
      "34/34 - 0s - loss: 0.0222 - rmse: 0.1491 - mape: 67.7028 - smape: 0.1687 - val_loss: 0.0118 - val_rmse: 0.1087 - val_mape: 97.5954 - val_smape: 0.1585\n",
      "Epoch 44/50\n",
      "34/34 - 0s - loss: 0.0223 - rmse: 0.1493 - mape: 61.9067 - smape: 0.1799 - val_loss: 0.0148 - val_rmse: 0.1217 - val_mape: 71.9547 - val_smape: 0.1696\n",
      "Epoch 45/50\n",
      "34/34 - 0s - loss: 0.0198 - rmse: 0.1408 - mape: 55.3823 - smape: 0.1626 - val_loss: 0.0165 - val_rmse: 0.1283 - val_mape: 57.0877 - val_smape: 0.1782\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "Test MAPE: 62.067\n",
      "Test sMAPE: 41.855\n",
      "Test RMSE: 17.911\n",
      "{'mape': 62.067014307685795, 'smape': 41.85503415795363, 'rmse': 17.910723457366327}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1256 - rmse: 0.3544 - mape: 94.9744 - smape: 0.4334 - val_loss: 0.0279 - val_rmse: 0.1669 - val_mape: 84.2163 - val_smape: 0.2420\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0400 - rmse: 0.1999 - mape: 75.1661 - smape: 0.2278 - val_loss: 0.0192 - val_rmse: 0.1386 - val_mape: 89.3793 - val_smape: 0.1935\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0297 - rmse: 0.1724 - mape: 73.2199 - smape: 0.1934 - val_loss: 0.0169 - val_rmse: 0.1299 - val_mape: 80.1181 - val_smape: 0.1707\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0347 - rmse: 0.1863 - mape: 79.3385 - smape: 0.2191 - val_loss: 0.0182 - val_rmse: 0.1350 - val_mape: 76.2031 - val_smape: 0.1939\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0340 - rmse: 0.1843 - mape: 78.0598 - smape: 0.2158 - val_loss: 0.0152 - val_rmse: 0.1235 - val_mape: 70.2320 - val_smape: 0.1726\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0293 - rmse: 0.1713 - mape: 76.0835 - smape: 0.1987 - val_loss: 0.0150 - val_rmse: 0.1223 - val_mape: 70.7093 - val_smape: 0.1731\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0251 - rmse: 0.1585 - mape: 62.2579 - smape: 0.1860 - val_loss: 0.0132 - val_rmse: 0.1151 - val_mape: 62.9892 - val_smape: 0.1598\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0250 - rmse: 0.1580 - mape: 65.2262 - smape: 0.1801 - val_loss: 0.0124 - val_rmse: 0.1114 - val_mape: 65.0668 - val_smape: 0.1432\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0259 - rmse: 0.1608 - mape: 70.6829 - smape: 0.1853 - val_loss: 0.0123 - val_rmse: 0.1107 - val_mape: 62.9062 - val_smape: 0.1528\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1529 - mape: 68.7979 - smape: 0.1722 - val_loss: 0.0121 - val_rmse: 0.1098 - val_mape: 67.7028 - val_smape: 0.1466\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0225 - rmse: 0.1499 - mape: 57.2576 - smape: 0.1733 - val_loss: 0.0112 - val_rmse: 0.1059 - val_mape: 54.3570 - val_smape: 0.1389\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0272 - rmse: 0.1650 - mape: 72.0548 - smape: 0.1972 - val_loss: 0.0146 - val_rmse: 0.1208 - val_mape: 77.2523 - val_smape: 0.1736\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0239 - rmse: 0.1547 - mape: 69.1737 - smape: 0.1819 - val_loss: 0.0120 - val_rmse: 0.1094 - val_mape: 55.4993 - val_smape: 0.1500\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1528 - mape: 70.1578 - smape: 0.1768 - val_loss: 0.0144 - val_rmse: 0.1199 - val_mape: 81.9814 - val_smape: 0.1722\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0218 - rmse: 0.1477 - mape: 59.5452 - smape: 0.1708 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 54.7768 - val_smape: 0.1389\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0236 - rmse: 0.1537 - mape: 67.8347 - smape: 0.1770 - val_loss: 0.0124 - val_rmse: 0.1114 - val_mape: 71.8964 - val_smape: 0.1562\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0231 - rmse: 0.1519 - mape: 64.8291 - smape: 0.1729 - val_loss: 0.0120 - val_rmse: 0.1094 - val_mape: 64.8819 - val_smape: 0.1475\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1482 - mape: 63.8466 - smape: 0.1731 - val_loss: 0.0132 - val_rmse: 0.1147 - val_mape: 69.5856 - val_smape: 0.1618\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0187 - rmse: 0.1369 - mape: 54.9793 - smape: 0.1551 - val_loss: 0.0106 - val_rmse: 0.1029 - val_mape: 60.0883 - val_smape: 0.1326\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0198 - rmse: 0.1406 - mape: 61.2693 - smape: 0.1632 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 65.9452 - val_smape: 0.1458\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1562 - mape: 57.1097 - smape: 0.1803 - val_loss: 0.0120 - val_rmse: 0.1095 - val_mape: 60.8234 - val_smape: 0.1495\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1598 - mape: 73.4667 - smape: 0.1915 - val_loss: 0.0125 - val_rmse: 0.1117 - val_mape: 71.6795 - val_smape: 0.1558\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1483 - mape: 66.7949 - smape: 0.1715 - val_loss: 0.0118 - val_rmse: 0.1088 - val_mape: 57.9467 - val_smape: 0.1380\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0231 - rmse: 0.1519 - mape: 65.4491 - smape: 0.1821 - val_loss: 0.0127 - val_rmse: 0.1126 - val_mape: 83.2862 - val_smape: 0.1593\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0238 - rmse: 0.1544 - mape: 68.0706 - smape: 0.1785 - val_loss: 0.0130 - val_rmse: 0.1140 - val_mape: 46.5891 - val_smape: 0.1506\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0353 - rmse: 0.1878 - mape: 66.0945 - smape: 0.2219 - val_loss: 0.0176 - val_rmse: 0.1326 - val_mape: 99.0581 - val_smape: 0.1726\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0346 - rmse: 0.1860 - mape: 72.3647 - smape: 0.2197 - val_loss: 0.0171 - val_rmse: 0.1306 - val_mape: 49.0353 - val_smape: 0.1765\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0603 - rmse: 0.2455 - mape: 72.2798 - smape: 0.2670 - val_loss: 0.0237 - val_rmse: 0.1541 - val_mape: 126.5176 - val_smape: 0.2242\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0350 - rmse: 0.1872 - mape: 62.0939 - smape: 0.2136 - val_loss: 0.0156 - val_rmse: 0.1250 - val_mape: 45.7961 - val_smape: 0.1570\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0294 - rmse: 0.1715 - mape: 67.3426 - smape: 0.1995 - val_loss: 0.0309 - val_rmse: 0.1758 - val_mape: 152.7416 - val_smape: 0.2771\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0289 - rmse: 0.1699 - mape: 66.2254 - smape: 0.1867 - val_loss: 0.0133 - val_rmse: 0.1153 - val_mape: 60.4410 - val_smape: 0.1519\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1596 - mape: 66.4796 - smape: 0.1808 - val_loss: 0.0161 - val_rmse: 0.1270 - val_mape: 97.3511 - val_smape: 0.1858\n",
      "Epoch 33/50\n",
      "34/34 - 0s - loss: 0.0204 - rmse: 0.1430 - mape: 56.0258 - smape: 0.1646 - val_loss: 0.0147 - val_rmse: 0.1214 - val_mape: 52.2952 - val_smape: 0.1677\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0190 - rmse: 0.1377 - mape: 58.2817 - smape: 0.1555 - val_loss: 0.0142 - val_rmse: 0.1192 - val_mape: 76.5720 - val_smape: 0.1670\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0194 - rmse: 0.1393 - mape: 58.5890 - smape: 0.1619 - val_loss: 0.0147 - val_rmse: 0.1213 - val_mape: 68.1419 - val_smape: 0.1696\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0209 - rmse: 0.1445 - mape: 60.0083 - smape: 0.1665 - val_loss: 0.0157 - val_rmse: 0.1252 - val_mape: 71.3874 - val_smape: 0.1755\n",
      "Epoch 37/50\n",
      "34/34 - 0s - loss: 0.0215 - rmse: 0.1467 - mape: 62.2188 - smape: 0.1673 - val_loss: 0.0177 - val_rmse: 0.1330 - val_mape: 64.0802 - val_smape: 0.1848\n",
      "Epoch 38/50\n",
      "34/34 - 0s - loss: 0.0176 - rmse: 0.1327 - mape: 59.2806 - smape: 0.1545 - val_loss: 0.0152 - val_rmse: 0.1233 - val_mape: 76.2123 - val_smape: 0.1744\n",
      "Epoch 39/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1420 - mape: 61.0309 - smape: 0.1639 - val_loss: 0.0189 - val_rmse: 0.1376 - val_mape: 60.3288 - val_smape: 0.1895\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Test MAPE: 44.915\n",
      "Test sMAPE: 33.879\n",
      "Test RMSE: 17.860\n",
      "{'mape': 44.91536789432287, 'smape': 33.87885328214041, 'rmse': 17.85986051449829}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1189 - rmse: 0.3448 - mape: 92.5198 - smape: 0.4160 - val_loss: 0.0299 - val_rmse: 0.1729 - val_mape: 87.0653 - val_smape: 0.2510\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0356 - rmse: 0.1886 - mape: 74.6590 - smape: 0.2122 - val_loss: 0.0183 - val_rmse: 0.1352 - val_mape: 84.9766 - val_smape: 0.1776\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0313 - rmse: 0.1770 - mape: 65.5454 - smape: 0.2016 - val_loss: 0.0163 - val_rmse: 0.1277 - val_mape: 74.9228 - val_smape: 0.1722\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0336 - rmse: 0.1834 - mape: 78.0341 - smape: 0.2108 - val_loss: 0.0154 - val_rmse: 0.1242 - val_mape: 72.2233 - val_smape: 0.1697\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0338 - rmse: 0.1838 - mape: 75.4247 - smape: 0.2141 - val_loss: 0.0171 - val_rmse: 0.1309 - val_mape: 68.5724 - val_smape: 0.1872\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0304 - rmse: 0.1744 - mape: 66.8670 - smape: 0.2043 - val_loss: 0.0148 - val_rmse: 0.1217 - val_mape: 70.1346 - val_smape: 0.1711\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0283 - rmse: 0.1683 - mape: 70.6388 - smape: 0.1939 - val_loss: 0.0138 - val_rmse: 0.1176 - val_mape: 68.9966 - val_smape: 0.1636\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0305 - rmse: 0.1748 - mape: 74.1567 - smape: 0.2064 - val_loss: 0.0150 - val_rmse: 0.1223 - val_mape: 70.4918 - val_smape: 0.1744\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0265 - rmse: 0.1628 - mape: 70.6180 - smape: 0.1858 - val_loss: 0.0128 - val_rmse: 0.1130 - val_mape: 67.5703 - val_smape: 0.1540\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0247 - rmse: 0.1570 - mape: 63.4778 - smape: 0.1784 - val_loss: 0.0134 - val_rmse: 0.1158 - val_mape: 72.7108 - val_smape: 0.1606\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0221 - rmse: 0.1486 - mape: 63.6352 - smape: 0.1670 - val_loss: 0.0127 - val_rmse: 0.1127 - val_mape: 76.8782 - val_smape: 0.1469\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0249 - rmse: 0.1577 - mape: 66.6776 - smape: 0.1842 - val_loss: 0.0124 - val_rmse: 0.1115 - val_mape: 43.2516 - val_smape: 0.1445\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0330 - rmse: 0.1816 - mape: 77.6084 - smape: 0.2180 - val_loss: 0.0204 - val_rmse: 0.1428 - val_mape: 103.0059 - val_smape: 0.2140\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0277 - rmse: 0.1665 - mape: 67.1448 - smape: 0.1862 - val_loss: 0.0126 - val_rmse: 0.1121 - val_mape: 62.3397 - val_smape: 0.1558\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0245 - rmse: 0.1565 - mape: 70.7453 - smape: 0.1781 - val_loss: 0.0121 - val_rmse: 0.1099 - val_mape: 71.1912 - val_smape: 0.1528\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1458 - mape: 65.4362 - smape: 0.1640 - val_loss: 0.0112 - val_rmse: 0.1056 - val_mape: 59.3887 - val_smape: 0.1418\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0243 - rmse: 0.1558 - mape: 70.7694 - smape: 0.1832 - val_loss: 0.0111 - val_rmse: 0.1052 - val_mape: 62.6986 - val_smape: 0.1387\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0232 - rmse: 0.1522 - mape: 59.2546 - smape: 0.1783 - val_loss: 0.0122 - val_rmse: 0.1103 - val_mape: 70.9732 - val_smape: 0.1530\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0215 - rmse: 0.1467 - mape: 67.3567 - smape: 0.1690 - val_loss: 0.0123 - val_rmse: 0.1107 - val_mape: 62.4957 - val_smape: 0.1530\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0192 - rmse: 0.1385 - mape: 63.9050 - smape: 0.1577 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 68.8918 - val_smape: 0.1381\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0209 - rmse: 0.1444 - mape: 66.0595 - smape: 0.1708 - val_loss: 0.0129 - val_rmse: 0.1138 - val_mape: 58.3541 - val_smape: 0.1580\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0191 - rmse: 0.1382 - mape: 61.9564 - smape: 0.1577 - val_loss: 0.0123 - val_rmse: 0.1108 - val_mape: 93.2507 - val_smape: 0.1495\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0229 - rmse: 0.1512 - mape: 55.9388 - smape: 0.1775 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 51.6316 - val_smape: 0.1414\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0236 - rmse: 0.1535 - mape: 71.5222 - smape: 0.1818 - val_loss: 0.0110 - val_rmse: 0.1050 - val_mape: 75.5558 - val_smape: 0.1421\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0219 - rmse: 0.1481 - mape: 68.0643 - smape: 0.1746 - val_loss: 0.0127 - val_rmse: 0.1129 - val_mape: 54.2603 - val_smape: 0.1568\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0197 - rmse: 0.1403 - mape: 65.5892 - smape: 0.1641 - val_loss: 0.0108 - val_rmse: 0.1039 - val_mape: 76.5177 - val_smape: 0.1424\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0185 - rmse: 0.1360 - mape: 55.2106 - smape: 0.1636 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 58.2491 - val_smape: 0.1540\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0222 - rmse: 0.1490 - mape: 60.0586 - smape: 0.1761 - val_loss: 0.0114 - val_rmse: 0.1066 - val_mape: 88.3945 - val_smape: 0.1492\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0229 - rmse: 0.1512 - mape: 61.0451 - smape: 0.1734 - val_loss: 0.0131 - val_rmse: 0.1143 - val_mape: 50.2294 - val_smape: 0.1505\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0215 - rmse: 0.1465 - mape: 67.9484 - smape: 0.1726 - val_loss: 0.0112 - val_rmse: 0.1060 - val_mape: 102.1630 - val_smape: 0.1488\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0210 - rmse: 0.1448 - mape: 66.1996 - smape: 0.1721 - val_loss: 0.0130 - val_rmse: 0.1141 - val_mape: 48.7032 - val_smape: 0.1545\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0195 - rmse: 0.1398 - mape: 68.3853 - smape: 0.1654 - val_loss: 0.0108 - val_rmse: 0.1040 - val_mape: 81.4141 - val_smape: 0.1449\n",
      "Epoch 33/50\n",
      "34/34 - 0s - loss: 0.0189 - rmse: 0.1374 - mape: 67.6805 - smape: 0.1690 - val_loss: 0.0132 - val_rmse: 0.1148 - val_mape: 62.8609 - val_smape: 0.1576\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0191 - rmse: 0.1384 - mape: 66.9297 - smape: 0.1572 - val_loss: 0.0112 - val_rmse: 0.1059 - val_mape: 88.7939 - val_smape: 0.1483\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0167 - rmse: 0.1292 - mape: 46.1080 - smape: 0.1536 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 59.5584 - val_smape: 0.1441\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0200 - rmse: 0.1415 - mape: 67.2647 - smape: 0.1622 - val_loss: 0.0104 - val_rmse: 0.1020 - val_mape: 81.1251 - val_smape: 0.1422\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "Test MAPE: 61.701\n",
      "Test sMAPE: 41.678\n",
      "Test RMSE: 18.330\n",
      "{'mape': 61.701421730983384, 'smape': 41.67767810371682, 'rmse': 18.33013926137212}\n",
      "Epoch 1/50\n",
      "34/34 - 3s - loss: 0.1122 - rmse: 0.3350 - mape: 97.9874 - smape: 0.4073 - val_loss: 0.0284 - val_rmse: 0.1686 - val_mape: 78.1154 - val_smape: 0.2426\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0385 - rmse: 0.1963 - mape: 82.9277 - smape: 0.2233 - val_loss: 0.0187 - val_rmse: 0.1368 - val_mape: 83.7613 - val_smape: 0.1892\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0290 - rmse: 0.1703 - mape: 71.4265 - smape: 0.1913 - val_loss: 0.0174 - val_rmse: 0.1317 - val_mape: 80.6490 - val_smape: 0.1706\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0322 - rmse: 0.1795 - mape: 78.1890 - smape: 0.2093 - val_loss: 0.0158 - val_rmse: 0.1257 - val_mape: 72.9185 - val_smape: 0.1723\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0317 - rmse: 0.1781 - mape: 77.9217 - smape: 0.2082 - val_loss: 0.0152 - val_rmse: 0.1235 - val_mape: 69.7454 - val_smape: 0.1724\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0312 - rmse: 0.1766 - mape: 76.0086 - smape: 0.2063 - val_loss: 0.0158 - val_rmse: 0.1256 - val_mape: 70.1675 - val_smape: 0.1786\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0293 - rmse: 0.1712 - mape: 71.9031 - smape: 0.1977 - val_loss: 0.0136 - val_rmse: 0.1168 - val_mape: 68.3433 - val_smape: 0.1574\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0281 - rmse: 0.1677 - mape: 75.4903 - smape: 0.1990 - val_loss: 0.0132 - val_rmse: 0.1149 - val_mape: 67.3109 - val_smape: 0.1561\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0254 - rmse: 0.1594 - mape: 62.3253 - smape: 0.1798 - val_loss: 0.0125 - val_rmse: 0.1117 - val_mape: 62.3664 - val_smape: 0.1481\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0261 - rmse: 0.1615 - mape: 68.2487 - smape: 0.1874 - val_loss: 0.0144 - val_rmse: 0.1200 - val_mape: 65.9761 - val_smape: 0.1700\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0243 - rmse: 0.1559 - mape: 61.7764 - smape: 0.1799 - val_loss: 0.0135 - val_rmse: 0.1163 - val_mape: 83.6011 - val_smape: 0.1602\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0242 - rmse: 0.1556 - mape: 71.9466 - smape: 0.1808 - val_loss: 0.0128 - val_rmse: 0.1133 - val_mape: 48.5249 - val_smape: 0.1520\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0252 - rmse: 0.1587 - mape: 65.7827 - smape: 0.1858 - val_loss: 0.0143 - val_rmse: 0.1196 - val_mape: 90.3992 - val_smape: 0.1701\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0227 - rmse: 0.1505 - mape: 58.4428 - smape: 0.1723 - val_loss: 0.0115 - val_rmse: 0.1074 - val_mape: 62.5666 - val_smape: 0.1413\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0257 - rmse: 0.1604 - mape: 68.4059 - smape: 0.1855 - val_loss: 0.0140 - val_rmse: 0.1184 - val_mape: 67.5691 - val_smape: 0.1678\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0249 - rmse: 0.1577 - mape: 68.5705 - smape: 0.1817 - val_loss: 0.0143 - val_rmse: 0.1195 - val_mape: 73.5355 - val_smape: 0.1701\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0214 - rmse: 0.1462 - mape: 66.5536 - smape: 0.1697 - val_loss: 0.0117 - val_rmse: 0.1083 - val_mape: 64.4462 - val_smape: 0.1493\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0231 - rmse: 0.1521 - mape: 68.0072 - smape: 0.1797 - val_loss: 0.0123 - val_rmse: 0.1111 - val_mape: 74.2438 - val_smape: 0.1539\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0201 - rmse: 0.1419 - mape: 65.0879 - smape: 0.1635 - val_loss: 0.0112 - val_rmse: 0.1060 - val_mape: 58.7922 - val_smape: 0.1379\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0267 - rmse: 0.1632 - mape: 66.5852 - smape: 0.1948 - val_loss: 0.0128 - val_rmse: 0.1131 - val_mape: 81.9001 - val_smape: 0.1511\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0221 - rmse: 0.1488 - mape: 66.7684 - smape: 0.1731 - val_loss: 0.0128 - val_rmse: 0.1130 - val_mape: 55.9241 - val_smape: 0.1544\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0250 - rmse: 0.1580 - mape: 71.2558 - smape: 0.1822 - val_loss: 0.0122 - val_rmse: 0.1103 - val_mape: 85.0297 - val_smape: 0.1543\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1483 - mape: 64.9199 - smape: 0.1670 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 52.6714 - val_smape: 0.1511\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0292 - rmse: 0.1710 - mape: 71.0112 - smape: 0.2005 - val_loss: 0.0123 - val_rmse: 0.1108 - val_mape: 79.8059 - val_smape: 0.1517\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0204 - rmse: 0.1427 - mape: 59.7545 - smape: 0.1659 - val_loss: 0.0112 - val_rmse: 0.1056 - val_mape: 48.6601 - val_smape: 0.1361\n",
      "Epoch 26/50\n",
      "34/34 - 1s - loss: 0.0267 - rmse: 0.1633 - mape: 58.6247 - smape: 0.1977 - val_loss: 0.0139 - val_rmse: 0.1180 - val_mape: 94.9570 - val_smape: 0.1731\n",
      "Epoch 27/50\n",
      "34/34 - 1s - loss: 0.0229 - rmse: 0.1513 - mape: 60.4671 - smape: 0.1781 - val_loss: 0.0140 - val_rmse: 0.1181 - val_mape: 42.4383 - val_smape: 0.1480\n",
      "Epoch 28/50\n",
      "34/34 - 1s - loss: 0.0322 - rmse: 0.1794 - mape: 64.5382 - smape: 0.2137 - val_loss: 0.0145 - val_rmse: 0.1203 - val_mape: 109.6913 - val_smape: 0.1765\n",
      "Epoch 29/50\n",
      "34/34 - 1s - loss: 0.0299 - rmse: 0.1728 - mape: 69.0733 - smape: 0.2006 - val_loss: 0.0141 - val_rmse: 0.1186 - val_mape: 43.6599 - val_smape: 0.1464\n",
      "Epoch 30/50\n",
      "34/34 - 1s - loss: 0.0313 - rmse: 0.1770 - mape: 76.2693 - smape: 0.2081 - val_loss: 0.0183 - val_rmse: 0.1352 - val_mape: 120.3990 - val_smape: 0.2084\n",
      "Epoch 31/50\n",
      "34/34 - 1s - loss: 0.0244 - rmse: 0.1561 - mape: 69.3695 - smape: 0.1775 - val_loss: 0.0124 - val_rmse: 0.1116 - val_mape: 52.4258 - val_smape: 0.1388\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0247 - rmse: 0.1571 - mape: 72.5850 - smape: 0.1840 - val_loss: 0.0127 - val_rmse: 0.1127 - val_mape: 85.4234 - val_smape: 0.1613\n",
      "Epoch 33/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1484 - mape: 67.3614 - smape: 0.1732 - val_loss: 0.0148 - val_rmse: 0.1215 - val_mape: 45.2776 - val_smape: 0.1587\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0262 - rmse: 0.1619 - mape: 72.4633 - smape: 0.1864 - val_loss: 0.0132 - val_rmse: 0.1148 - val_mape: 85.5698 - val_smape: 0.1666\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1456 - mape: 67.3637 - smape: 0.1681 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 51.2901 - val_smape: 0.1463\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0172 - rmse: 0.1311 - mape: 65.8144 - smape: 0.1530 - val_loss: 0.0127 - val_rmse: 0.1129 - val_mape: 68.5486 - val_smape: 0.1562\n",
      "Epoch 37/50\n",
      "34/34 - 0s - loss: 0.0163 - rmse: 0.1279 - mape: 62.1883 - smape: 0.1508 - val_loss: 0.0114 - val_rmse: 0.1068 - val_mape: 70.6212 - val_smape: 0.1474\n",
      "Epoch 38/50\n",
      "34/34 - 0s - loss: 0.0173 - rmse: 0.1315 - mape: 50.8548 - smape: 0.1538 - val_loss: 0.0127 - val_rmse: 0.1127 - val_mape: 52.1982 - val_smape: 0.1548\n",
      "Epoch 39/50\n",
      "34/34 - 0s - loss: 0.0190 - rmse: 0.1378 - mape: 54.4868 - smape: 0.1585 - val_loss: 0.0131 - val_rmse: 0.1144 - val_mape: 94.7644 - val_smape: 0.1676\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Test MAPE: 52.541\n",
      "Test sMAPE: 37.739\n",
      "Test RMSE: 18.391\n",
      "{'mape': 52.54110651648185, 'smape': 37.73937114218687, 'rmse': 18.39103497676446}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1239 - rmse: 0.3520 - mape: 95.5092 - smape: 0.4246 - val_loss: 0.0273 - val_rmse: 0.1652 - val_mape: 85.8555 - val_smape: 0.2403\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0340 - rmse: 0.1845 - mape: 68.4416 - smape: 0.2069 - val_loss: 0.0188 - val_rmse: 0.1372 - val_mape: 85.2866 - val_smape: 0.1762\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0328 - rmse: 0.1811 - mape: 75.9109 - smape: 0.2081 - val_loss: 0.0170 - val_rmse: 0.1305 - val_mape: 73.4698 - val_smape: 0.1817\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0357 - rmse: 0.1889 - mape: 79.1406 - smape: 0.2225 - val_loss: 0.0161 - val_rmse: 0.1269 - val_mape: 71.8310 - val_smape: 0.1761\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0320 - rmse: 0.1789 - mape: 75.0236 - smape: 0.2104 - val_loss: 0.0163 - val_rmse: 0.1278 - val_mape: 67.9608 - val_smape: 0.1811\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0308 - rmse: 0.1755 - mape: 71.3410 - smape: 0.2057 - val_loss: 0.0149 - val_rmse: 0.1220 - val_mape: 68.3851 - val_smape: 0.1709\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0280 - rmse: 0.1673 - mape: 69.9322 - smape: 0.1962 - val_loss: 0.0154 - val_rmse: 0.1240 - val_mape: 67.4525 - val_smape: 0.1760\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0248 - rmse: 0.1574 - mape: 71.5707 - smape: 0.1776 - val_loss: 0.0128 - val_rmse: 0.1133 - val_mape: 66.1483 - val_smape: 0.1513\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0231 - rmse: 0.1519 - mape: 66.4784 - smape: 0.1723 - val_loss: 0.0123 - val_rmse: 0.1109 - val_mape: 64.3198 - val_smape: 0.1485\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0260 - rmse: 0.1613 - mape: 63.6079 - smape: 0.1883 - val_loss: 0.0128 - val_rmse: 0.1129 - val_mape: 65.0196 - val_smape: 0.1575\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0237 - rmse: 0.1539 - mape: 61.9665 - smape: 0.1801 - val_loss: 0.0119 - val_rmse: 0.1091 - val_mape: 59.2568 - val_smape: 0.1499\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1561 - mape: 68.1729 - smape: 0.1800 - val_loss: 0.0115 - val_rmse: 0.1071 - val_mape: 54.7482 - val_smape: 0.1419\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0235 - rmse: 0.1532 - mape: 61.6448 - smape: 0.1772 - val_loss: 0.0125 - val_rmse: 0.1116 - val_mape: 59.2237 - val_smape: 0.1521\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0226 - rmse: 0.1505 - mape: 62.9140 - smape: 0.1765 - val_loss: 0.0125 - val_rmse: 0.1116 - val_mape: 75.0830 - val_smape: 0.1562\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0214 - rmse: 0.1461 - mape: 64.5302 - smape: 0.1698 - val_loss: 0.0122 - val_rmse: 0.1102 - val_mape: 44.0742 - val_smape: 0.1380\n",
      "Epoch 16/50\n",
      "34/34 - 1s - loss: 0.0246 - rmse: 0.1570 - mape: 65.0941 - smape: 0.1871 - val_loss: 0.0167 - val_rmse: 0.1293 - val_mape: 100.7420 - val_smape: 0.1929\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1597 - mape: 68.7437 - smape: 0.1824 - val_loss: 0.0107 - val_rmse: 0.1035 - val_mape: 50.7921 - val_smape: 0.1307\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0216 - rmse: 0.1468 - mape: 69.2466 - smape: 0.1723 - val_loss: 0.0122 - val_rmse: 0.1105 - val_mape: 64.3540 - val_smape: 0.1547\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0204 - rmse: 0.1429 - mape: 66.7598 - smape: 0.1680 - val_loss: 0.0107 - val_rmse: 0.1034 - val_mape: 56.8909 - val_smape: 0.1327\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 62.3193 - smape: 0.1623 - val_loss: 0.0109 - val_rmse: 0.1044 - val_mape: 62.3916 - val_smape: 0.1347\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0204 - rmse: 0.1429 - mape: 63.9161 - smape: 0.1651 - val_loss: 0.0115 - val_rmse: 0.1075 - val_mape: 60.5141 - val_smape: 0.1475\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0233 - rmse: 0.1527 - mape: 63.4401 - smape: 0.1761 - val_loss: 0.0123 - val_rmse: 0.1111 - val_mape: 72.6799 - val_smape: 0.1548\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0178 - rmse: 0.1334 - mape: 46.5373 - smape: 0.1538 - val_loss: 0.0111 - val_rmse: 0.1054 - val_mape: 61.7999 - val_smape: 0.1356\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0219 - rmse: 0.1481 - mape: 68.3287 - smape: 0.1753 - val_loss: 0.0108 - val_rmse: 0.1038 - val_mape: 67.2430 - val_smape: 0.1389\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0247 - rmse: 0.1571 - mape: 64.7010 - smape: 0.1873 - val_loss: 0.0111 - val_rmse: 0.1053 - val_mape: 72.6031 - val_smape: 0.1399\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0196 - rmse: 0.1399 - mape: 48.4618 - smape: 0.1610 - val_loss: 0.0125 - val_rmse: 0.1120 - val_mape: 51.0905 - val_smape: 0.1478\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0247 - rmse: 0.1573 - mape: 71.1261 - smape: 0.1876 - val_loss: 0.0128 - val_rmse: 0.1132 - val_mape: 89.3558 - val_smape: 0.1579\n",
      "Epoch 28/50\n",
      "34/34 - 1s - loss: 0.0240 - rmse: 0.1548 - mape: 63.3519 - smape: 0.1767 - val_loss: 0.0142 - val_rmse: 0.1190 - val_mape: 62.2109 - val_smape: 0.1686\n",
      "Epoch 29/50\n",
      "34/34 - 1s - loss: 0.0177 - rmse: 0.1329 - mape: 65.3367 - smape: 0.1533 - val_loss: 0.0119 - val_rmse: 0.1090 - val_mape: 87.2108 - val_smape: 0.1517\n",
      "Epoch 30/50\n",
      "34/34 - 1s - loss: 0.0172 - rmse: 0.1313 - mape: 61.0586 - smape: 0.1571 - val_loss: 0.0120 - val_rmse: 0.1097 - val_mape: 53.9243 - val_smape: 0.1489\n",
      "Epoch 31/50\n",
      "34/34 - 1s - loss: 0.0205 - rmse: 0.1431 - mape: 65.4480 - smape: 0.1678 - val_loss: 0.0105 - val_rmse: 0.1026 - val_mape: 87.3573 - val_smape: 0.1341\n",
      "Epoch 32/50\n",
      "34/34 - 1s - loss: 0.0200 - rmse: 0.1413 - mape: 57.7258 - smape: 0.1747 - val_loss: 0.0139 - val_rmse: 0.1181 - val_mape: 52.0224 - val_smape: 0.1633\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "Test MAPE: 62.104\n",
      "Test sMAPE: 41.789\n",
      "Test RMSE: 18.587\n",
      "{'mape': 62.10369537268095, 'smape': 41.7894188075326, 'rmse': 18.58741247729507}\n",
      "Epoch 1/50\n",
      "34/34 - 3s - loss: 0.1113 - rmse: 0.3335 - mape: 94.1590 - smape: 0.4105 - val_loss: 0.0294 - val_rmse: 0.1716 - val_mape: 80.8582 - val_smape: 0.2472\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0370 - rmse: 0.1924 - mape: 77.8511 - smape: 0.2179 - val_loss: 0.0182 - val_rmse: 0.1350 - val_mape: 83.7461 - val_smape: 0.1781\n",
      "Epoch 3/50\n",
      "34/34 - 1s - loss: 0.0341 - rmse: 0.1847 - mape: 76.3686 - smape: 0.2139 - val_loss: 0.0174 - val_rmse: 0.1320 - val_mape: 75.4026 - val_smape: 0.1864\n",
      "Epoch 4/50\n",
      "34/34 - 1s - loss: 0.0302 - rmse: 0.1737 - mape: 63.0097 - smape: 0.1984 - val_loss: 0.0152 - val_rmse: 0.1232 - val_mape: 70.5829 - val_smape: 0.1625\n",
      "Epoch 5/50\n",
      "34/34 - 1s - loss: 0.0294 - rmse: 0.1714 - mape: 67.7582 - smape: 0.2025 - val_loss: 0.0149 - val_rmse: 0.1221 - val_mape: 73.6095 - val_smape: 0.1600\n",
      "Epoch 6/50\n",
      "34/34 - 1s - loss: 0.0282 - rmse: 0.1678 - mape: 69.6014 - smape: 0.1898 - val_loss: 0.0138 - val_rmse: 0.1174 - val_mape: 68.2600 - val_smape: 0.1558\n",
      "Epoch 7/50\n",
      "34/34 - 1s - loss: 0.0299 - rmse: 0.1728 - mape: 73.7736 - smape: 0.2026 - val_loss: 0.0140 - val_rmse: 0.1183 - val_mape: 69.7469 - val_smape: 0.1638\n",
      "Epoch 8/50\n",
      "34/34 - 1s - loss: 0.0321 - rmse: 0.1792 - mape: 74.8332 - smape: 0.2108 - val_loss: 0.0143 - val_rmse: 0.1194 - val_mape: 68.0000 - val_smape: 0.1669\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0263 - rmse: 0.1621 - mape: 67.8758 - smape: 0.1910 - val_loss: 0.0136 - val_rmse: 0.1168 - val_mape: 70.6555 - val_smape: 0.1623\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0266 - rmse: 0.1631 - mape: 64.3458 - smape: 0.1890 - val_loss: 0.0138 - val_rmse: 0.1173 - val_mape: 62.5223 - val_smape: 0.1652\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0263 - rmse: 0.1623 - mape: 69.6740 - smape: 0.1901 - val_loss: 0.0128 - val_rmse: 0.1131 - val_mape: 68.1211 - val_smape: 0.1585\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0236 - rmse: 0.1538 - mape: 61.7337 - smape: 0.1736 - val_loss: 0.0113 - val_rmse: 0.1064 - val_mape: 63.4556 - val_smape: 0.1416\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0214 - rmse: 0.1464 - mape: 64.5012 - smape: 0.1683 - val_loss: 0.0116 - val_rmse: 0.1076 - val_mape: 54.9144 - val_smape: 0.1419\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0295 - rmse: 0.1718 - mape: 70.8475 - smape: 0.2022 - val_loss: 0.0144 - val_rmse: 0.1200 - val_mape: 83.9949 - val_smape: 0.1720\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0240 - rmse: 0.1549 - mape: 58.7627 - smape: 0.1707 - val_loss: 0.0125 - val_rmse: 0.1116 - val_mape: 57.0871 - val_smape: 0.1377\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0265 - rmse: 0.1629 - mape: 63.8508 - smape: 0.1909 - val_loss: 0.0147 - val_rmse: 0.1211 - val_mape: 67.8677 - val_smape: 0.1720\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0208 - rmse: 0.1441 - mape: 63.2354 - smape: 0.1630 - val_loss: 0.0125 - val_rmse: 0.1120 - val_mape: 70.1245 - val_smape: 0.1548\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0230 - rmse: 0.1515 - mape: 68.6081 - smape: 0.1778 - val_loss: 0.0130 - val_rmse: 0.1142 - val_mape: 64.6274 - val_smape: 0.1601\n",
      "Epoch 19/50\n",
      "34/34 - 1s - loss: 0.0230 - rmse: 0.1515 - mape: 64.9437 - smape: 0.1769 - val_loss: 0.0132 - val_rmse: 0.1151 - val_mape: 64.5220 - val_smape: 0.1617\n",
      "Epoch 20/50\n",
      "34/34 - 1s - loss: 0.0206 - rmse: 0.1437 - mape: 55.9421 - smape: 0.1641 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 58.1896 - val_smape: 0.1374\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0220 - rmse: 0.1483 - mape: 62.7008 - smape: 0.1746 - val_loss: 0.0143 - val_rmse: 0.1195 - val_mape: 92.2545 - val_smape: 0.1740\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 62.6996 - smape: 0.1610 - val_loss: 0.0126 - val_rmse: 0.1120 - val_mape: 46.5351 - val_smape: 0.1368\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0281 - rmse: 0.1676 - mape: 71.0709 - smape: 0.1974 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 72.3010 - val_smape: 0.1435\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0219 - rmse: 0.1479 - mape: 64.7132 - smape: 0.1730 - val_loss: 0.0129 - val_rmse: 0.1136 - val_mape: 41.4206 - val_smape: 0.1434\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0342 - rmse: 0.1849 - mape: 70.8885 - smape: 0.2112 - val_loss: 0.0151 - val_rmse: 0.1227 - val_mape: 91.4951 - val_smape: 0.1765\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0270 - rmse: 0.1642 - mape: 68.1587 - smape: 0.1888 - val_loss: 0.0132 - val_rmse: 0.1151 - val_mape: 42.2900 - val_smape: 0.1505\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0304 - rmse: 0.1743 - mape: 70.9474 - smape: 0.2114 - val_loss: 0.0226 - val_rmse: 0.1504 - val_mape: 125.2442 - val_smape: 0.2338\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0259 - rmse: 0.1610 - mape: 64.5077 - smape: 0.1758 - val_loss: 0.0141 - val_rmse: 0.1187 - val_mape: 49.3075 - val_smape: 0.1405\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0280 - rmse: 0.1673 - mape: 76.1528 - smape: 0.1998 - val_loss: 0.0142 - val_rmse: 0.1194 - val_mape: 96.8959 - val_smape: 0.1770\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0230 - rmse: 0.1516 - mape: 65.7419 - smape: 0.1758 - val_loss: 0.0131 - val_rmse: 0.1143 - val_mape: 46.3793 - val_smape: 0.1400\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0274 - rmse: 0.1656 - mape: 68.6423 - smape: 0.1875 - val_loss: 0.0149 - val_rmse: 0.1222 - val_mape: 100.6874 - val_smape: 0.1829\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0251 - rmse: 0.1585 - mape: 57.8279 - smape: 0.1809 - val_loss: 0.0140 - val_rmse: 0.1183 - val_mape: 47.5920 - val_smape: 0.1452\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "Test MAPE: 52.489\n",
      "Test sMAPE: 37.673\n",
      "Test RMSE: 18.460\n",
      "{'mape': 52.4888898641674, 'smape': 37.672558813396854, 'rmse': 18.459535400991488}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1199 - rmse: 0.3462 - mape: 98.9426 - smape: 0.4204 - val_loss: 0.0299 - val_rmse: 0.1728 - val_mape: 91.3044 - val_smape: 0.2523\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0362 - rmse: 0.1903 - mape: 74.4227 - smape: 0.2121 - val_loss: 0.0195 - val_rmse: 0.1396 - val_mape: 91.4845 - val_smape: 0.1928\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0322 - rmse: 0.1793 - mape: 75.8579 - smape: 0.1985 - val_loss: 0.0173 - val_rmse: 0.1316 - val_mape: 81.5492 - val_smape: 0.1741\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0306 - rmse: 0.1750 - mape: 65.7139 - smape: 0.2024 - val_loss: 0.0154 - val_rmse: 0.1239 - val_mape: 69.5059 - val_smape: 0.1628\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0337 - rmse: 0.1836 - mape: 76.2234 - smape: 0.2152 - val_loss: 0.0167 - val_rmse: 0.1293 - val_mape: 72.8947 - val_smape: 0.1834\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0325 - rmse: 0.1803 - mape: 77.2595 - smape: 0.2090 - val_loss: 0.0148 - val_rmse: 0.1218 - val_mape: 72.1884 - val_smape: 0.1646\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0295 - rmse: 0.1719 - mape: 70.7473 - smape: 0.1982 - val_loss: 0.0151 - val_rmse: 0.1229 - val_mape: 66.6510 - val_smape: 0.1737\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0293 - rmse: 0.1711 - mape: 72.0461 - smape: 0.1985 - val_loss: 0.0140 - val_rmse: 0.1182 - val_mape: 63.8754 - val_smape: 0.1658\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0279 - rmse: 0.1671 - mape: 67.8064 - smape: 0.1981 - val_loss: 0.0138 - val_rmse: 0.1173 - val_mape: 68.7905 - val_smape: 0.1650\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0248 - rmse: 0.1576 - mape: 66.4552 - smape: 0.1786 - val_loss: 0.0131 - val_rmse: 0.1143 - val_mape: 69.8224 - val_smape: 0.1461\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0268 - rmse: 0.1638 - mape: 69.1640 - smape: 0.1956 - val_loss: 0.0138 - val_rmse: 0.1175 - val_mape: 63.3293 - val_smape: 0.1659\n",
      "Epoch 12/50\n",
      "34/34 - 1s - loss: 0.0252 - rmse: 0.1587 - mape: 70.1743 - smape: 0.1826 - val_loss: 0.0142 - val_rmse: 0.1190 - val_mape: 79.9657 - val_smape: 0.1704\n",
      "Epoch 13/50\n",
      "34/34 - 1s - loss: 0.0209 - rmse: 0.1445 - mape: 58.4606 - smape: 0.1616 - val_loss: 0.0110 - val_rmse: 0.1049 - val_mape: 58.0593 - val_smape: 0.1338\n",
      "Epoch 14/50\n",
      "34/34 - 1s - loss: 0.0239 - rmse: 0.1544 - mape: 69.5325 - smape: 0.1801 - val_loss: 0.0125 - val_rmse: 0.1120 - val_mape: 62.6419 - val_smape: 0.1566\n",
      "Epoch 15/50\n",
      "34/34 - 1s - loss: 0.0220 - rmse: 0.1483 - mape: 67.0953 - smape: 0.1683 - val_loss: 0.0110 - val_rmse: 0.1048 - val_mape: 60.5023 - val_smape: 0.1425\n",
      "Epoch 16/50\n",
      "34/34 - 1s - loss: 0.0229 - rmse: 0.1514 - mape: 63.9844 - smape: 0.1748 - val_loss: 0.0119 - val_rmse: 0.1090 - val_mape: 65.4286 - val_smape: 0.1513\n",
      "Epoch 17/50\n",
      "34/34 - 1s - loss: 0.0229 - rmse: 0.1512 - mape: 66.7723 - smape: 0.1712 - val_loss: 0.0108 - val_rmse: 0.1038 - val_mape: 52.2141 - val_smape: 0.1334\n",
      "Epoch 18/50\n",
      "34/34 - 1s - loss: 0.0213 - rmse: 0.1460 - mape: 66.5582 - smape: 0.1728 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 72.9593 - val_smape: 0.1458\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0232 - rmse: 0.1523 - mape: 68.0050 - smape: 0.1792 - val_loss: 0.0140 - val_rmse: 0.1182 - val_mape: 45.5429 - val_smape: 0.1436\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0425 - rmse: 0.2061 - mape: 67.9085 - smape: 0.2349 - val_loss: 0.0195 - val_rmse: 0.1395 - val_mape: 112.0597 - val_smape: 0.2044\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0344 - rmse: 0.1855 - mape: 71.1600 - smape: 0.2126 - val_loss: 0.0129 - val_rmse: 0.1137 - val_mape: 45.0577 - val_smape: 0.1509\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0270 - rmse: 0.1645 - mape: 72.6877 - smape: 0.2001 - val_loss: 0.0205 - val_rmse: 0.1432 - val_mape: 108.5119 - val_smape: 0.2176\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0243 - rmse: 0.1558 - mape: 60.6990 - smape: 0.1725 - val_loss: 0.0111 - val_rmse: 0.1056 - val_mape: 57.4736 - val_smape: 0.1414\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0210 - rmse: 0.1450 - mape: 66.5327 - smape: 0.1705 - val_loss: 0.0128 - val_rmse: 0.1131 - val_mape: 77.6893 - val_smape: 0.1604\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0182 - rmse: 0.1349 - mape: 61.3637 - smape: 0.1527 - val_loss: 0.0114 - val_rmse: 0.1066 - val_mape: 61.1613 - val_smape: 0.1339\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0230 - rmse: 0.1516 - mape: 69.5739 - smape: 0.1795 - val_loss: 0.0134 - val_rmse: 0.1157 - val_mape: 64.5877 - val_smape: 0.1618\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0201 - rmse: 0.1418 - mape: 63.8661 - smape: 0.1651 - val_loss: 0.0111 - val_rmse: 0.1056 - val_mape: 66.5984 - val_smape: 0.1380\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0173 - rmse: 0.1316 - mape: 63.5157 - smape: 0.1534 - val_loss: 0.0131 - val_rmse: 0.1144 - val_mape: 59.7216 - val_smape: 0.1598\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0178 - rmse: 0.1334 - mape: 63.2678 - smape: 0.1571 - val_loss: 0.0108 - val_rmse: 0.1037 - val_mape: 63.7884 - val_smape: 0.1423\n",
      "Epoch 30/50\n",
      "34/34 - 1s - loss: 0.0199 - rmse: 0.1412 - mape: 66.5819 - smape: 0.1650 - val_loss: 0.0119 - val_rmse: 0.1093 - val_mape: 58.6318 - val_smape: 0.1492\n",
      "Epoch 31/50\n",
      "34/34 - 1s - loss: 0.0209 - rmse: 0.1445 - mape: 55.6562 - smape: 0.1682 - val_loss: 0.0135 - val_rmse: 0.1163 - val_mape: 84.0903 - val_smape: 0.1670\n",
      "Epoch 32/50\n",
      "34/34 - 1s - loss: 0.0183 - rmse: 0.1353 - mape: 61.6243 - smape: 0.1602 - val_loss: 0.0118 - val_rmse: 0.1084 - val_mape: 47.3739 - val_smape: 0.1397\n",
      "Epoch 33/50\n",
      "34/34 - 1s - loss: 0.0230 - rmse: 0.1516 - mape: 70.2598 - smape: 0.1794 - val_loss: 0.0108 - val_rmse: 0.1041 - val_mape: 67.0095 - val_smape: 0.1457\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "Test MAPE: 40.666\n",
      "Test sMAPE: 31.832\n",
      "Test RMSE: 18.195\n",
      "{'mape': 40.66600127233192, 'smape': 31.83201177087473, 'rmse': 18.194665846768427}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.0960 - rmse: 0.3098 - mape: 76.1968 - smape: 0.3751 - val_loss: 0.0249 - val_rmse: 0.1578 - val_mape: 75.3157 - val_smape: 0.2273\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0343 - rmse: 0.1853 - mape: 76.4168 - smape: 0.2074 - val_loss: 0.0177 - val_rmse: 0.1331 - val_mape: 78.6102 - val_smape: 0.1695\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0326 - rmse: 0.1804 - mape: 71.9813 - smape: 0.2119 - val_loss: 0.0161 - val_rmse: 0.1271 - val_mape: 70.1717 - val_smape: 0.1753\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0300 - rmse: 0.1732 - mape: 74.5561 - smape: 0.1975 - val_loss: 0.0151 - val_rmse: 0.1230 - val_mape: 68.5989 - val_smape: 0.1564\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0340 - rmse: 0.1845 - mape: 75.4981 - smape: 0.2205 - val_loss: 0.0145 - val_rmse: 0.1205 - val_mape: 68.4412 - val_smape: 0.1642\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0304 - rmse: 0.1744 - mape: 75.7433 - smape: 0.2018 - val_loss: 0.0144 - val_rmse: 0.1199 - val_mape: 67.3715 - val_smape: 0.1679\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0274 - rmse: 0.1656 - mape: 71.5995 - smape: 0.1902 - val_loss: 0.0130 - val_rmse: 0.1141 - val_mape: 66.7999 - val_smape: 0.1497\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0322 - rmse: 0.1795 - mape: 72.1972 - smape: 0.2077 - val_loss: 0.0136 - val_rmse: 0.1167 - val_mape: 61.0410 - val_smape: 0.1632\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0240 - rmse: 0.1550 - mape: 70.9765 - smape: 0.1737 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 63.4951 - val_smape: 0.1426\n",
      "Epoch 10/50\n",
      "34/34 - 1s - loss: 0.0247 - rmse: 0.1573 - mape: 69.5268 - smape: 0.1880 - val_loss: 0.0132 - val_rmse: 0.1150 - val_mape: 77.1167 - val_smape: 0.1621\n",
      "Epoch 11/50\n",
      "34/34 - 1s - loss: 0.0237 - rmse: 0.1538 - mape: 67.0502 - smape: 0.1724 - val_loss: 0.0115 - val_rmse: 0.1073 - val_mape: 64.0049 - val_smape: 0.1424\n",
      "Epoch 12/50\n",
      "34/34 - 1s - loss: 0.0222 - rmse: 0.1491 - mape: 67.1066 - smape: 0.1717 - val_loss: 0.0115 - val_rmse: 0.1072 - val_mape: 62.5607 - val_smape: 0.1371\n",
      "Epoch 13/50\n",
      "34/34 - 1s - loss: 0.0284 - rmse: 0.1685 - mape: 66.9905 - smape: 0.2001 - val_loss: 0.0145 - val_rmse: 0.1205 - val_mape: 79.5273 - val_smape: 0.1714\n",
      "Epoch 14/50\n",
      "34/34 - 1s - loss: 0.0227 - rmse: 0.1507 - mape: 63.2325 - smape: 0.1740 - val_loss: 0.0118 - val_rmse: 0.1086 - val_mape: 59.0905 - val_smape: 0.1460\n",
      "Epoch 15/50\n",
      "34/34 - 1s - loss: 0.0246 - rmse: 0.1568 - mape: 64.4093 - smape: 0.1852 - val_loss: 0.0134 - val_rmse: 0.1159 - val_mape: 73.4248 - val_smape: 0.1638\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1561 - mape: 59.1823 - smape: 0.1784 - val_loss: 0.0129 - val_rmse: 0.1135 - val_mape: 48.5305 - val_smape: 0.1517\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0342 - rmse: 0.1849 - mape: 77.6884 - smape: 0.2165 - val_loss: 0.0209 - val_rmse: 0.1446 - val_mape: 116.2404 - val_smape: 0.2197\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0317 - rmse: 0.1781 - mape: 66.2841 - smape: 0.2035 - val_loss: 0.0135 - val_rmse: 0.1162 - val_mape: 64.2429 - val_smape: 0.1625\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0244 - rmse: 0.1563 - mape: 70.1031 - smape: 0.1806 - val_loss: 0.0131 - val_rmse: 0.1145 - val_mape: 83.2093 - val_smape: 0.1585\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0215 - rmse: 0.1465 - mape: 64.8983 - smape: 0.1695 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 58.8348 - val_smape: 0.1448\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0196 - rmse: 0.1400 - mape: 64.1880 - smape: 0.1632 - val_loss: 0.0122 - val_rmse: 0.1105 - val_mape: 60.7940 - val_smape: 0.1483\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0201 - rmse: 0.1419 - mape: 64.3926 - smape: 0.1569 - val_loss: 0.0118 - val_rmse: 0.1086 - val_mape: 67.5302 - val_smape: 0.1499\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0185 - rmse: 0.1362 - mape: 60.8946 - smape: 0.1599 - val_loss: 0.0123 - val_rmse: 0.1108 - val_mape: 52.4879 - val_smape: 0.1398\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0237 - rmse: 0.1538 - mape: 72.2287 - smape: 0.1835 - val_loss: 0.0129 - val_rmse: 0.1137 - val_mape: 82.2684 - val_smape: 0.1607\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1529 - mape: 61.3529 - smape: 0.1690 - val_loss: 0.0116 - val_rmse: 0.1076 - val_mape: 53.0499 - val_smape: 0.1453\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0210 - rmse: 0.1450 - mape: 65.4010 - smape: 0.1708 - val_loss: 0.0118 - val_rmse: 0.1087 - val_mape: 76.6034 - val_smape: 0.1478\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0173 - rmse: 0.1316 - mape: 59.2767 - smape: 0.1550 - val_loss: 0.0116 - val_rmse: 0.1078 - val_mape: 61.5722 - val_smape: 0.1482\n",
      "Epoch 28/50\n",
      "34/34 - 1s - loss: 0.0175 - rmse: 0.1322 - mape: 55.6061 - smape: 0.1592 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 72.8600 - val_smape: 0.1444\n",
      "Epoch 29/50\n",
      "34/34 - 1s - loss: 0.0151 - rmse: 0.1227 - mape: 59.0092 - smape: 0.1487 - val_loss: 0.0118 - val_rmse: 0.1085 - val_mape: 57.4537 - val_smape: 0.1492\n",
      "Epoch 30/50\n",
      "34/34 - 1s - loss: 0.0188 - rmse: 0.1370 - mape: 52.7539 - smape: 0.1637 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 77.2901 - val_smape: 0.1445\n",
      "Epoch 31/50\n",
      "34/34 - 1s - loss: 0.0182 - rmse: 0.1350 - mape: 66.2631 - smape: 0.1643 - val_loss: 0.0106 - val_rmse: 0.1032 - val_mape: 64.0569 - val_smape: 0.1425\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Test MAPE: 50.901\n",
      "Test sMAPE: 36.971\n",
      "Test RMSE: 18.620\n",
      "{'mape': 50.90056611513242, 'smape': 36.97096161014275, 'rmse': 18.61962412698546}\n",
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1240 - rmse: 0.3521 - mape: 94.5363 - smape: 0.4251 - val_loss: 0.0285 - val_rmse: 0.1687 - val_mape: 86.0542 - val_smape: 0.2452\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0383 - rmse: 0.1957 - mape: 77.0973 - smape: 0.2248 - val_loss: 0.0191 - val_rmse: 0.1383 - val_mape: 88.6138 - val_smape: 0.1792\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0330 - rmse: 0.1818 - mape: 76.4135 - smape: 0.2082 - val_loss: 0.0174 - val_rmse: 0.1319 - val_mape: 78.1927 - val_smape: 0.1835\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0301 - rmse: 0.1735 - mape: 74.6494 - smape: 0.2013 - val_loss: 0.0158 - val_rmse: 0.1257 - val_mape: 73.9399 - val_smape: 0.1674\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0306 - rmse: 0.1749 - mape: 76.4282 - smape: 0.2025 - val_loss: 0.0148 - val_rmse: 0.1218 - val_mape: 67.2306 - val_smape: 0.1681\n",
      "Epoch 6/50\n",
      "34/34 - 0s - loss: 0.0300 - rmse: 0.1732 - mape: 78.2390 - smape: 0.2042 - val_loss: 0.0144 - val_rmse: 0.1202 - val_mape: 62.8393 - val_smape: 0.1670\n",
      "Epoch 7/50\n",
      "34/34 - 0s - loss: 0.0294 - rmse: 0.1715 - mape: 69.5395 - smape: 0.2038 - val_loss: 0.0133 - val_rmse: 0.1155 - val_mape: 64.8685 - val_smape: 0.1571\n",
      "Epoch 8/50\n",
      "34/34 - 0s - loss: 0.0264 - rmse: 0.1626 - mape: 64.4419 - smape: 0.1894 - val_loss: 0.0145 - val_rmse: 0.1203 - val_mape: 57.9437 - val_smape: 0.1688\n",
      "Epoch 9/50\n",
      "34/34 - 0s - loss: 0.0255 - rmse: 0.1596 - mape: 71.2086 - smape: 0.1877 - val_loss: 0.0126 - val_rmse: 0.1123 - val_mape: 65.4750 - val_smape: 0.1553\n",
      "Epoch 10/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1530 - mape: 64.4462 - smape: 0.1770 - val_loss: 0.0117 - val_rmse: 0.1083 - val_mape: 64.5458 - val_smape: 0.1470\n",
      "Epoch 11/50\n",
      "34/34 - 0s - loss: 0.0237 - rmse: 0.1539 - mape: 54.8179 - smape: 0.1726 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 54.5341 - val_smape: 0.1463\n",
      "Epoch 12/50\n",
      "34/34 - 0s - loss: 0.0266 - rmse: 0.1632 - mape: 70.2630 - smape: 0.1932 - val_loss: 0.0147 - val_rmse: 0.1211 - val_mape: 91.0080 - val_smape: 0.1727\n",
      "Epoch 13/50\n",
      "34/34 - 0s - loss: 0.0274 - rmse: 0.1655 - mape: 67.2301 - smape: 0.1881 - val_loss: 0.0118 - val_rmse: 0.1086 - val_mape: 52.8120 - val_smape: 0.1456\n",
      "Epoch 14/50\n",
      "34/34 - 0s - loss: 0.0267 - rmse: 0.1634 - mape: 72.6836 - smape: 0.1887 - val_loss: 0.0138 - val_rmse: 0.1173 - val_mape: 84.3428 - val_smape: 0.1628\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0221 - rmse: 0.1486 - mape: 66.6818 - smape: 0.1692 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 58.7249 - val_smape: 0.1442\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0333 - rmse: 0.1824 - mape: 62.3549 - smape: 0.2180 - val_loss: 0.0165 - val_rmse: 0.1283 - val_mape: 81.3937 - val_smape: 0.1856\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0256 - rmse: 0.1600 - mape: 67.6581 - smape: 0.1840 - val_loss: 0.0126 - val_rmse: 0.1121 - val_mape: 55.0107 - val_smape: 0.1528\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0280 - rmse: 0.1672 - mape: 60.8946 - smape: 0.1957 - val_loss: 0.0145 - val_rmse: 0.1203 - val_mape: 81.2405 - val_smape: 0.1716\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0227 - rmse: 0.1506 - mape: 68.5021 - smape: 0.1708 - val_loss: 0.0119 - val_rmse: 0.1090 - val_mape: 59.1119 - val_smape: 0.1500\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0235 - rmse: 0.1531 - mape: 69.5389 - smape: 0.1798 - val_loss: 0.0124 - val_rmse: 0.1113 - val_mape: 65.2761 - val_smape: 0.1555\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1457 - mape: 62.8232 - smape: 0.1646 - val_loss: 0.0119 - val_rmse: 0.1091 - val_mape: 55.6569 - val_smape: 0.1450\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0261 - rmse: 0.1615 - mape: 67.7706 - smape: 0.1827 - val_loss: 0.0168 - val_rmse: 0.1297 - val_mape: 96.5043 - val_smape: 0.1914\n",
      "Epoch 23/50\n",
      "34/34 - 1s - loss: 0.0212 - rmse: 0.1457 - mape: 45.1854 - smape: 0.1570 - val_loss: 0.0117 - val_rmse: 0.1081 - val_mape: 64.3476 - val_smape: 0.1479\n",
      "Epoch 24/50\n",
      "34/34 - 1s - loss: 0.0209 - rmse: 0.1447 - mape: 67.2038 - smape: 0.1652 - val_loss: 0.0120 - val_rmse: 0.1094 - val_mape: 71.7418 - val_smape: 0.1457\n",
      "Epoch 25/50\n",
      "34/34 - 1s - loss: 0.0193 - rmse: 0.1389 - mape: 61.9062 - smape: 0.1609 - val_loss: 0.0114 - val_rmse: 0.1070 - val_mape: 54.9611 - val_smape: 0.1438\n",
      "Epoch 26/50\n",
      "34/34 - 1s - loss: 0.0200 - rmse: 0.1413 - mape: 63.0354 - smape: 0.1596 - val_loss: 0.0115 - val_rmse: 0.1071 - val_mape: 72.3129 - val_smape: 0.1379\n",
      "Epoch 27/50\n",
      "34/34 - 1s - loss: 0.0217 - rmse: 0.1472 - mape: 60.3253 - smape: 0.1729 - val_loss: 0.0114 - val_rmse: 0.1069 - val_mape: 62.1409 - val_smape: 0.1411\n",
      "Epoch 28/50\n",
      "34/34 - 1s - loss: 0.0273 - rmse: 0.1654 - mape: 60.4495 - smape: 0.1995 - val_loss: 0.0145 - val_rmse: 0.1202 - val_mape: 85.0878 - val_smape: 0.1731\n",
      "Epoch 29/50\n",
      "34/34 - 1s - loss: 0.0215 - rmse: 0.1465 - mape: 65.6090 - smape: 0.1713 - val_loss: 0.0120 - val_rmse: 0.1096 - val_mape: 52.4337 - val_smape: 0.1500\n",
      "Epoch 30/50\n",
      "34/34 - 1s - loss: 0.0200 - rmse: 0.1414 - mape: 57.5839 - smape: 0.1652 - val_loss: 0.0121 - val_rmse: 0.1100 - val_mape: 85.7634 - val_smape: 0.1484\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Test MAPE: 58.796\n",
      "Test sMAPE: 40.586\n",
      "Test RMSE: 18.795\n",
      "{'mape': 58.79632308620452, 'smape': 40.58586697859349, 'rmse': 18.794683324264273}\n",
      "rmse : average=18.215, std=0.493\n",
      "mape : average=55.103, std=7.701\n",
      "smape : average=38.679, std=3.522\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc416953",
   "metadata": {},
   "source": [
    "# Plot an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbaec13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 - 4s - loss: 0.1232 - rmse: 0.3510 - mape: 94.7256 - smape: 0.4274 - val_loss: 0.0322 - val_rmse: 0.1795 - val_mape: 86.7770 - val_smape: 0.2591\n",
      "Epoch 2/50\n",
      "34/34 - 0s - loss: 0.0390 - rmse: 0.1974 - mape: 74.5006 - smape: 0.2256 - val_loss: 0.0187 - val_rmse: 0.1368 - val_mape: 88.3846 - val_smape: 0.1884\n",
      "Epoch 3/50\n",
      "34/34 - 0s - loss: 0.0312 - rmse: 0.1767 - mape: 73.8945 - smape: 0.2008 - val_loss: 0.0167 - val_rmse: 0.1293 - val_mape: 78.2369 - val_smape: 0.1771\n",
      "Epoch 4/50\n",
      "34/34 - 0s - loss: 0.0319 - rmse: 0.1785 - mape: 65.6200 - smape: 0.2103 - val_loss: 0.0158 - val_rmse: 0.1258 - val_mape: 69.3922 - val_smape: 0.1763\n",
      "Epoch 5/50\n",
      "34/34 - 0s - loss: 0.0304 - rmse: 0.1743 - mape: 75.1048 - smape: 0.2021 - val_loss: 0.0144 - val_rmse: 0.1200 - val_mape: 67.1962 - val_smape: 0.1547\n",
      "Epoch 6/50\n",
      "34/34 - 1s - loss: 0.0347 - rmse: 0.1862 - mape: 71.7377 - smape: 0.2161 - val_loss: 0.0160 - val_rmse: 0.1265 - val_mape: 73.4092 - val_smape: 0.1797\n",
      "Epoch 7/50\n",
      "34/34 - 1s - loss: 0.0276 - rmse: 0.1661 - mape: 72.1362 - smape: 0.1912 - val_loss: 0.0136 - val_rmse: 0.1168 - val_mape: 65.5040 - val_smape: 0.1599\n",
      "Epoch 8/50\n",
      "34/34 - 1s - loss: 0.0274 - rmse: 0.1656 - mape: 72.9092 - smape: 0.1966 - val_loss: 0.0130 - val_rmse: 0.1140 - val_mape: 64.8893 - val_smape: 0.1526\n",
      "Epoch 9/50\n",
      "34/34 - 1s - loss: 0.0262 - rmse: 0.1619 - mape: 72.7738 - smape: 0.1846 - val_loss: 0.0134 - val_rmse: 0.1157 - val_mape: 68.7439 - val_smape: 0.1613\n",
      "Epoch 10/50\n",
      "34/34 - 1s - loss: 0.0254 - rmse: 0.1594 - mape: 72.8083 - smape: 0.1862 - val_loss: 0.0131 - val_rmse: 0.1143 - val_mape: 67.5506 - val_smape: 0.1604\n",
      "Epoch 11/50\n",
      "34/34 - 1s - loss: 0.0213 - rmse: 0.1459 - mape: 54.5319 - smape: 0.1643 - val_loss: 0.0118 - val_rmse: 0.1087 - val_mape: 65.4943 - val_smape: 0.1478\n",
      "Epoch 12/50\n",
      "34/34 - 1s - loss: 0.0221 - rmse: 0.1488 - mape: 66.3477 - smape: 0.1757 - val_loss: 0.0119 - val_rmse: 0.1093 - val_mape: 68.1059 - val_smape: 0.1501\n",
      "Epoch 13/50\n",
      "34/34 - 1s - loss: 0.0222 - rmse: 0.1490 - mape: 64.5207 - smape: 0.1699 - val_loss: 0.0122 - val_rmse: 0.1104 - val_mape: 55.1559 - val_smape: 0.1515\n",
      "Epoch 14/50\n",
      "34/34 - 1s - loss: 0.0283 - rmse: 0.1681 - mape: 70.2391 - smape: 0.2002 - val_loss: 0.0144 - val_rmse: 0.1201 - val_mape: 75.8862 - val_smape: 0.1723\n",
      "Epoch 15/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1454 - mape: 64.9704 - smape: 0.1654 - val_loss: 0.0110 - val_rmse: 0.1050 - val_mape: 62.8096 - val_smape: 0.1405\n",
      "Epoch 16/50\n",
      "34/34 - 0s - loss: 0.0258 - rmse: 0.1608 - mape: 71.6838 - smape: 0.1902 - val_loss: 0.0135 - val_rmse: 0.1163 - val_mape: 66.6775 - val_smape: 0.1645\n",
      "Epoch 17/50\n",
      "34/34 - 0s - loss: 0.0226 - rmse: 0.1503 - mape: 62.9737 - smape: 0.1722 - val_loss: 0.0116 - val_rmse: 0.1077 - val_mape: 68.2395 - val_smape: 0.1499\n",
      "Epoch 18/50\n",
      "34/34 - 0s - loss: 0.0225 - rmse: 0.1501 - mape: 63.1493 - smape: 0.1767 - val_loss: 0.0122 - val_rmse: 0.1103 - val_mape: 64.0294 - val_smape: 0.1489\n",
      "Epoch 19/50\n",
      "34/34 - 0s - loss: 0.0212 - rmse: 0.1456 - mape: 59.0624 - smape: 0.1664 - val_loss: 0.0118 - val_rmse: 0.1086 - val_mape: 71.4923 - val_smape: 0.1493\n",
      "Epoch 20/50\n",
      "34/34 - 0s - loss: 0.0205 - rmse: 0.1433 - mape: 65.4185 - smape: 0.1625 - val_loss: 0.0127 - val_rmse: 0.1126 - val_mape: 41.9448 - val_smape: 0.1498\n",
      "Epoch 21/50\n",
      "34/34 - 0s - loss: 0.0353 - rmse: 0.1880 - mape: 76.2083 - smape: 0.2123 - val_loss: 0.0218 - val_rmse: 0.1477 - val_mape: 117.3333 - val_smape: 0.2232\n",
      "Epoch 22/50\n",
      "34/34 - 0s - loss: 0.0283 - rmse: 0.1683 - mape: 57.4813 - smape: 0.1852 - val_loss: 0.0123 - val_rmse: 0.1108 - val_mape: 44.9147 - val_smape: 0.1377\n",
      "Epoch 23/50\n",
      "34/34 - 0s - loss: 0.0314 - rmse: 0.1771 - mape: 80.7768 - smape: 0.2139 - val_loss: 0.0222 - val_rmse: 0.1490 - val_mape: 114.2720 - val_smape: 0.2284\n",
      "Epoch 24/50\n",
      "34/34 - 0s - loss: 0.0266 - rmse: 0.1632 - mape: 66.1979 - smape: 0.1751 - val_loss: 0.0114 - val_rmse: 0.1067 - val_mape: 53.5214 - val_smape: 0.1338\n",
      "Epoch 25/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1529 - mape: 68.4904 - smape: 0.1819 - val_loss: 0.0128 - val_rmse: 0.1133 - val_mape: 82.0288 - val_smape: 0.1605\n",
      "Epoch 26/50\n",
      "34/34 - 0s - loss: 0.0234 - rmse: 0.1529 - mape: 66.0184 - smape: 0.1685 - val_loss: 0.0115 - val_rmse: 0.1072 - val_mape: 56.2144 - val_smape: 0.1458\n",
      "Epoch 27/50\n",
      "34/34 - 0s - loss: 0.0211 - rmse: 0.1454 - mape: 65.6038 - smape: 0.1700 - val_loss: 0.0143 - val_rmse: 0.1198 - val_mape: 80.9443 - val_smape: 0.1723\n",
      "Epoch 28/50\n",
      "34/34 - 0s - loss: 0.0191 - rmse: 0.1381 - mape: 60.9514 - smape: 0.1553 - val_loss: 0.0106 - val_rmse: 0.1028 - val_mape: 58.0393 - val_smape: 0.1335\n",
      "Epoch 29/50\n",
      "34/34 - 0s - loss: 0.0188 - rmse: 0.1373 - mape: 58.4846 - smape: 0.1608 - val_loss: 0.0114 - val_rmse: 0.1067 - val_mape: 60.3055 - val_smape: 0.1456\n",
      "Epoch 30/50\n",
      "34/34 - 0s - loss: 0.0265 - rmse: 0.1628 - mape: 64.4879 - smape: 0.1931 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 62.2526 - val_smape: 0.1549\n",
      "Epoch 31/50\n",
      "34/34 - 0s - loss: 0.0194 - rmse: 0.1393 - mape: 65.1574 - smape: 0.1604 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 66.5825 - val_smape: 0.1455\n",
      "Epoch 32/50\n",
      "34/34 - 0s - loss: 0.0191 - rmse: 0.1381 - mape: 63.0977 - smape: 0.1590 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 64.6521 - val_smape: 0.1447\n",
      "Epoch 33/50\n",
      "34/34 - 1s - loss: 0.0182 - rmse: 0.1350 - mape: 56.5779 - smape: 0.1613 - val_loss: 0.0140 - val_rmse: 0.1182 - val_mape: 50.3717 - val_smape: 0.1621\n",
      "Epoch 34/50\n",
      "34/34 - 0s - loss: 0.0204 - rmse: 0.1429 - mape: 66.4955 - smape: 0.1647 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 93.5875 - val_smape: 0.1595\n",
      "Epoch 35/50\n",
      "34/34 - 0s - loss: 0.0216 - rmse: 0.1471 - mape: 68.0901 - smape: 0.1737 - val_loss: 0.0133 - val_rmse: 0.1154 - val_mape: 47.6979 - val_smape: 0.1577\n",
      "Epoch 36/50\n",
      "34/34 - 0s - loss: 0.0201 - rmse: 0.1417 - mape: 59.3626 - smape: 0.1634 - val_loss: 0.0113 - val_rmse: 0.1063 - val_mape: 82.2647 - val_smape: 0.1369\n",
      "Epoch 37/50\n",
      "34/34 - 0s - loss: 0.0190 - rmse: 0.1379 - mape: 62.3977 - smape: 0.1682 - val_loss: 0.0128 - val_rmse: 0.1129 - val_mape: 43.2193 - val_smape: 0.1479\n",
      "Epoch 38/50\n",
      "34/34 - 0s - loss: 0.0277 - rmse: 0.1665 - mape: 58.1431 - smape: 0.1952 - val_loss: 0.0119 - val_rmse: 0.1089 - val_mape: 99.5656 - val_smape: 0.1615\n",
      "Epoch 39/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 62.0407 - smape: 0.1766 - val_loss: 0.0132 - val_rmse: 0.1148 - val_mape: 58.7402 - val_smape: 0.1516\n",
      "Epoch 40/50\n",
      "34/34 - 0s - loss: 0.0202 - rmse: 0.1421 - mape: 64.9753 - smape: 0.1656 - val_loss: 0.0094 - val_rmse: 0.0971 - val_mape: 76.6905 - val_smape: 0.1353\n",
      "Epoch 41/50\n",
      "34/34 - 0s - loss: 0.0181 - rmse: 0.1347 - mape: 65.5918 - smape: 0.1616 - val_loss: 0.0127 - val_rmse: 0.1128 - val_mape: 55.7344 - val_smape: 0.1555\n",
      "Epoch 42/50\n",
      "34/34 - 0s - loss: 0.0173 - rmse: 0.1314 - mape: 64.6732 - smape: 0.1558 - val_loss: 0.0119 - val_rmse: 0.1090 - val_mape: 80.0953 - val_smape: 0.1521\n",
      "Epoch 43/50\n",
      "34/34 - 0s - loss: 0.0196 - rmse: 0.1400 - mape: 62.8109 - smape: 0.1647 - val_loss: 0.0124 - val_rmse: 0.1113 - val_mape: 62.6374 - val_smape: 0.1550\n",
      "Epoch 44/50\n",
      "34/34 - 0s - loss: 0.0183 - rmse: 0.1354 - mape: 63.0106 - smape: 0.1529 - val_loss: 0.0129 - val_rmse: 0.1138 - val_mape: 61.4558 - val_smape: 0.1588\n",
      "Epoch 45/50\n",
      "34/34 - 0s - loss: 0.0148 - rmse: 0.1218 - mape: 58.6922 - smape: 0.1450 - val_loss: 0.0132 - val_rmse: 0.1147 - val_mape: 85.6788 - val_smape: 0.1670\n",
      "Epoch 46/50\n",
      "34/34 - 0s - loss: 0.0157 - rmse: 0.1255 - mape: 62.7054 - smape: 0.1460 - val_loss: 0.0132 - val_rmse: 0.1149 - val_mape: 63.3027 - val_smape: 0.1596\n",
      "Epoch 47/50\n",
      "34/34 - 1s - loss: 0.0176 - rmse: 0.1326 - mape: 60.0919 - smape: 0.1567 - val_loss: 0.0140 - val_rmse: 0.1185 - val_mape: 89.0266 - val_smape: 0.1737\n",
      "Epoch 48/50\n",
      "34/34 - 1s - loss: 0.0184 - rmse: 0.1355 - mape: 63.6464 - smape: 0.1607 - val_loss: 0.0121 - val_rmse: 0.1098 - val_mape: 57.6246 - val_smape: 0.1512\n",
      "Epoch 49/50\n",
      "34/34 - 1s - loss: 0.0155 - rmse: 0.1247 - mape: 52.0831 - smape: 0.1482 - val_loss: 0.0139 - val_rmse: 0.1179 - val_mape: 74.2544 - val_smape: 0.1666\n",
      "Epoch 50/50\n",
      "34/34 - 1s - loss: 0.0164 - rmse: 0.1281 - mape: 61.2238 - smape: 0.1491 - val_loss: 0.0138 - val_rmse: 0.1175 - val_mape: 64.2847 - val_smape: 0.1637\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAHNCAYAAAA0bIApAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAACMsUlEQVR4nO3dd3hUVfrA8e+UTCa9F0IChN57i4CgoICKotiQtS2Kq7AWdtX159p1sa26NlwrrisWrCsKCkjvvZcAAQKkh/Qyk5n7++PO3GSSSSVlEt7P88yTyb13Zs7clPvOe95zjk5RFAUhhBBCCA+ib+kGCCGEEEJUJgGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKaDF33HEHnTp1aulmtCidTsfTTz/d0s1oVu5+7o19HsaNG8e4ceMa7fmaWn3+Fu644w78/f2btkFCeAAJUESj0ul0dbqtWrWqpZtarZ9++omxY8cSGRmJr68vnTt35sYbb2Tp0qUt3bTzduLECZefg8FgoEOHDlx77bXs2rWrpZtXLwcOHODpp5/mxIkTLd2URldUVMTTTz/dJH8n48aNo2/fvrUet27dOiZPnkz79u0xm8106NCBKVOmsHDhQkANlOryt37HHXdor6vT6ejWrZvb11u2bJn2mG+++abR3q9ovYwt3QDRtnz22Wcu3//nP/9h2bJlVbb36tWLDz74ALvd3pzNq9Wrr77Kww8/zNixY3nsscfw9fXl6NGjLF++nC+//JJJkyY16usVFxdjNDb/n+H06dO54oorsNlsHDx4kPnz57NkyRI2bdrEwIEDm709DTkPBw4c4JlnnmHcuHFVsg+//fZbI7au6VX+WygqKuKZZ54BaJFM0KJFi7jpppsYOHAgDzzwACEhISQlJbFmzRo++OADbrnlFu655x4mTJigPSYpKYknn3ySWbNmMWbMGG17ly5dtPtms5mjR4+yZcsWhg8f7vKan3/+OWazmZKSkqZ/g6JVkABFNKo//OEPLt9v2rSJZcuWVdnuicrKynjuuee47LLL3F7g0tPTG+V17HY7FosFs9mM2WxulOesr8GDB7v8TEaNGsXVV1/N/Pnz+fe//+32MYWFhfj5+TVJexr7PJhMpkZ9vqbm5eXV0k1w8fTTT9O7d282bdpU5Vw6/w4SEhJISEjQtm/bto0nn3yShISEav/eu3TpQllZGV988YVLgFJSUsL333/PlVdeybffftsE70i0RtLFI1pM5X53Z/fDq6++yjvvvEPnzp3x9fXl8ssvJzk5GUVReO6554iNjcXHx4drrrmG7OzsKs+7ZMkSxowZg5+fHwEBAVx55ZXs37+/1vZkZmaSl5fHqFGj3O6PjIx0+b60tJSnnnqKrl274u3tTVxcHI888gilpaUux+l0OubMmcPnn39Onz598Pb21rqL3NVenDlzhj/+8Y9ERUXh7e1Nnz59+Pjjj6u056233qJPnz74+voSEhLC0KFDtfR7fV166aWA+ikYYMGCBeh0OlavXs19991HZGQksbGx2vF1Pcc//PADffv2xWw207dvX77//nu3r1/deZg5cyYxMTF4e3sTHx/Pvffei8ViYcGCBdxwww0AXHLJJVW6Dt3VoKSnpzNz5kyioqIwm80MGDCATz/91OWYir+D77//Pl26dMHb25thw4axdevWGs9hTk4OBoOBN998U9uWmZmJXq8nLCyMigvH33vvvURHR2vfV/xbOHHiBBEREQA888wz2ntzd36mTp2Kv78/ERER/PWvf8Vms9XYxro6duwYw4YNcxvoVf47qK/p06fz1VdfuWSMfvrpJ4qKirjxxhvP67lF2yIZFOFxPv/8cywWC3/+85/Jzs7m5Zdf5sYbb+TSSy9l1apVPProoxw9epS33nqLv/71ry4X788++4zbb7+diRMn8tJLL1FUVMT8+fMZPXo0O3furLEQMTIyEh8fH3766Sf+/Oc/ExoaWu2xdrudq6++mnXr1jFr1ix69erF3r17ef311zly5Ag//PCDy/G///47X3/9NXPmzCE8PLzadqSlpTFy5EgtqImIiGDJkiXMnDmTvLw8HnzwQUDtErj//vu5/vrreeCBBygpKWHPnj1s3ryZW265pa6nWnPs2DEAwsLCXLbfd999RERE8OSTT1JYWAjU/Rz/9ttvTJs2jd69ezNv3jyysrK48847XQKd6pw9e5bhw4eTk5PDrFmz6NmzJ2fOnOGbb76hqKiIiy++mPvvv58333yT//u//6NXr14A2tfKiouLGTduHEePHmXOnDnEx8ezaNEi7rjjDnJycnjggQdcjl+4cCH5+fncc8896HQ6Xn75Za677jqOHz9ebbYjODiYvn37smbNGu6//35ArePQ6XRkZ2dz4MAB+vTpA8DatWtdukEqioiIYP78+dx7771ce+21XHfddQD0799fO8ZmszFx4kRGjBjBq6++yvLly/nnP/9Jly5duPfee2s9v7Xp2LEjK1as4PTp03X6edXHLbfcotXXOAPjhQsXMn78+PMOfkQbowjRhGbPnq1U92t2++23Kx07dtS+T0pKUgAlIiJCycnJ0bY/9thjCqAMGDBAsVqt2vbp06crJpNJKSkpURRFUfLz85Xg4GDl7rvvdnmd1NRUJSgoqMp2d5588kkFUPz8/JTJkycrL7zwgrJ9+/Yqx3322WeKXq9X1q5d67L9vffeUwBl/fr12jZA0ev1yv79+6s8D6A89dRT2vczZ85U2rVrp2RmZrocd/PNNytBQUFKUVGRoiiKcs011yh9+vSp9f1U5jzHzzzzjJKRkaGkpqYqq1atUgYNGqQAyrfffqsoiqJ88sknCqCMHj1aKSsr0x5fn3M8cOBApV27di4/y99++00BXH7u7s7Dbbfdpuj1emXr1q1V3oPdblcURVEWLVqkAMrKlSurHDN27Fhl7Nix2vdvvPGGAij//e9/tW0Wi0VJSEhQ/P39lby8PJfzExYWpmRnZ2vH/vjjjwqg/PTTT1Veq6LZs2crUVFR2vdz585VLr74YiUyMlKZP3++oiiKkpWVpeh0OuVf//qXdlzlv4WMjIwq56TisYDy7LPPumwfNGiQMmTIkBrbpyjquantd+ejjz5SAMVkMimXXHKJ8sQTTyhr165VbDZbtY/ZunWrAiiffPJJra87dOhQZebMmYqiKMq5c+cUk8mkfPrpp8rKlSsVQFm0aFGt70O0fdLFIzzODTfcQFBQkPb9iBEjALW+pWIh5YgRI7BYLJw5cwZQRwHk5OQwffp0MjMztZvBYGDEiBGsXLmy1td+5plnWLhwIYMGDeLXX3/l8ccfZ8iQIQwePJiDBw9qxy1atIhevXrRs2dPl9dyfiKs/Fpjx46ld+/eNb62oih8++23TJkyBUVRXJ534sSJ5ObmsmPHDkD9tH769Olaux2q89RTTxEREUF0dDTjxo3j2LFjvPTSS9qndae7774bg8GgfV/Xc5ySksKuXbu4/fbbXX6Wl112Wa3nwW6388MPPzBlyhSGDh1aZb9Op6v3+/3ll1+Ijo5m+vTp2jYvLy/uv/9+CgoKWL16tcvxN910EyEhIdr3zmzH8ePHa3ydMWPGkJaWxuHDhwE1U3LxxRczZswY1q5dC6hZFUVRqs2g1NWf/vSnKq9dW/vq6o9//CNLly5l3LhxrFu3jueee44xY8bQrVs3NmzYcN7Pf8stt/Ddd99hsVj45ptvMBgMXHvttY3QctGWSBeP8DgdOnRw+d55gYuLi3O7/dy5cwAkJiYC5fUUlQUGBgJquj83N9dlX8V6gOnTpzN9+nTy8vLYvHkzCxYsYOHChUyZMoV9+/ZhNptJTEzk4MGDWq1AZZULauPj46t/ww4ZGRnk5OTw/vvv8/7779f4vI8++ijLly9n+PDhdO3alcsvv5xbbrml2vqZymbNmsUNN9yAXq8nODhYq42prHK763qOT548CeB2SGmPHj20QMudjIwM8vLy6jQUtq5OnjxJt27d0OtdP5M5u4Sc7XWq/DvoDFacv2vVcQYda9euJTY2lp07d/L8888TERHBq6++qu0LDAxkwIABDX4/ZrO5yu9eSEhIre2rj4kTJzJx4kSKiorYvn07X331Fe+99x5XXXUVhw4dOq/umJtvvpm//vWvLFmyhM8//5yrrrqKgICARmu7aBskQBEep+In9rpsVxzFh86iu88++8wl4HByZl+++uor7rzzTrfPUVFgYCCXXXYZl112GV5eXnz66ads3ryZsWPHYrfb6devH6+99prbNlUOpnx8fNweV5Gz/X/4wx+4/fbb3R7jrEPo1asXhw8fZvHixSxdupRvv/2Wd999lyeffFIbnlqTbt26uQwRrU7ldtf1HLd2tf2uVScmJob4+HjWrFlDp06dUBSFhIQEIiIieOCBBzh58iRr167loosuqhIsNUb7moKvry9jxoxhzJgxhIeH88wzz7BkyZJqf0frol27dowbN45//vOfrF+/XkbuCLfaxn8TISifbyEyMrLGi+/EiRNZtmxZvZ576NChfPrpp6SkpGivtXv3bsaPH9+gLgd3IiIiCAgIwGaz1Sl48PPz46abbuKmm27CYrFw3XXX8cILL/DYY4812fDlup7jjh07AuUZl4qc3R/ViYiIIDAwkH379tV4XH3Oe8eOHdmzZw92u90lMDh06JBLexvDmDFjWLNmDfHx8QwcOJCAgAAGDBhAUFAQS5cuZceOHbUGkY31O9XYnF1uzr+D83HLLbdw1113ERwczBVXXHHezyfaHqlBEW3GxIkTCQwM5B//+AdWq7XK/oyMDED99DZhwgSXG6iTY23cuNHtcy9ZsgRQuycAbrzxRs6cOcMHH3xQ5dji4mJtxEt9GAwGpk2bxrfffuv24uxsP0BWVpbLPpPJRO/evVEUxe17byz1OccDBw7k008/delOW7ZsGQcOHKjxNfR6PVOnTuWnn35i27ZtVfY7sxjOOVlycnJqbfcVV1xBamoqX331lbatrKyMt956C39/f8aOHVvrc9TVmDFjOHHiBF999ZXW5aPX67nooot47bXXsFqttdaf+Pr6AnV7b01hxYoVbrf/8ssvQPnfwfm4/vrreeqpp3j33Xdb3bw1onlIBkW0GYGBgcyfP59bb72VwYMHc/PNNxMREcGpU6f4+eefGTVqFG+//Xa1jy8qKuKiiy5i5MiRTJo0ibi4OHJycvjhhx9Yu3YtU6dOZdCgQQDceuutfP311/zpT39i5cqVjBo1CpvNxqFDh/j666/59ddf3RZ41ubFF19k5cqVjBgxgrvvvpvevXuTnZ3Njh07WL58uTbvy+WXX050dDSjRo0iKiqKgwcP8vbbb3PllVc2aV9+fc7xvHnzuPLKKxk9ejR//OMfyc7O1uZuKSgoqPF1/vGPf/Dbb78xduxYbRh3SkoKixYtYt26dQQHBzNw4EAMBgMvvfQSubm5eHt7c+mll7qtjZg1axb//ve/ueOOO9i+fTudOnXim2++Yf369bzxxhuNes6cwcfhw4f5xz/+oW2/+OKLWbJkiTavSk18fHzo3bs3X331Fd27dyc0NJS+ffs2Wl1ORkYGzz//fJXt8fHxzJgxg2uuuYb4+HimTJlCly5dKCwsZPny5fz0008MGzaMKVOmnHcbgoKCLrh1qET9SIAi2pRbbrmFmJgYXnzxRV555RVKS0tp3749Y8aMqVJ3UllwcDAffPABP//8M5988gmpqakYDAZ69OjBK6+8os1tAeon4h9++IHXX3+d//znP3z//ffauj0PPPAA3bt3b1D7o6Ki2LJlC88++yzfffcd7777LmFhYfTp04eXXnpJO+6ee+7h888/57XXXqOgoIDY2Fjuv/9+/v73vzfodeujrud40qRJLFq0iL///e889thjdOnShU8++YQff/yx1jVm2rdvz+bNm3niiSf4/PPPycvLo3379kyePFnLLkRHR/Pee+8xb948Zs6cic1mY+XKlW4DFB8fH1atWsXf/vY3Pv30U/Ly8ujRoweffPKJtlZMY+nRoweRkZGkp6czevRobbszcBk+fLjbguTKPvzwQ/785z/z0EMPYbFYeOqppxotQElPT+eJJ56osn38+PHMmDGDDz/8kB9//JGvv/6as2fPoigKnTt35vHHH+fRRx9tM7VGwrPplNqqvoQQQgghmpnUoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DgSoAghhBDC40iAIoQQQgiPIwGKEEIIITyOBChCCCGE8DjGlm5AQ9jtds6ePUtAQAA6na6lmyOEEEKIOlAUhfz8fGJiYtDra86RtMoA5ezZs8TFxbV0M4QQQgjRAMnJycTGxtZ4TKsMUAICAgD1DQYGBrZwa4QQQghRF3l5ecTFxWnX8Zq0ygDF2a0TGBgoAYoQQgjRytSlPEOKZIUQQgjhcSRAEUIIIYTHkQBFCCGEEB6nVdag1IWiKJSVlWGz2Vq6KaKBDAYDRqNRhpILIcQFqE0GKBaLhZSUFIqKilq6KeI8+fr60q5dO0wmU0s3RQghRDNqcwGK3W4nKSkJg8FATEwMJpNJPoG3QoqiYLFYyMjIICkpiW7dutU6qY8QQoi2o80FKBaLBbvdTlxcHL6+vi3dHHEefHx88PLy4uTJk1gsFsxmc0s3SQghRDNpsx9J5dN22yA/RyGEuDDJf38hhBBCeBwJUESt7rjjDqZOndrSzRBCCHEBkQCljXj66acZOHBgSzdDCCGEaBQSoAghhBDC40iA4kGWLl3K6NGjCQ4OJiwsjKuuuopjx45p+0+fPs306dMJDQ3Fz8+PoUOHsnnzZhYsWMAzzzzD7t270el06HQ6FixYwIkTJ9DpdOzatUt7jpycHHQ6HatWrQLAZrMxc+ZM4uPj8fHxoUePHvzrX/9q5ncuhBCtz9mcYt5ZeZTcImtLN6VNanPDjN1RFIVia/PPKOvjZajXHCyFhYXMnTuX/v37U1BQwJNPPsm1117Lrl27KCoqYuzYsbRv357//e9/REdHs2PHDux2OzfddBP79u1j6dKlLF++HICgoCDS0tJqfU273U5sbCyLFi0iLCyMDRs2MGvWLNq1a8eNN97Y4PcuhBBt3Xurj/GfjSex2xX+PL5bSzenzbkgApRiq43eT/7a7K974NmJ+JrqfoqnTZvm8v3HH39MREQEBw4cYMOGDWRkZLB161ZCQ0MB6Nq1q3asv78/RqOR6OjoerXRy8uLZ555Rvs+Pj6ejRs38vXXX0uAIoQQNUjNLQFg/9m8Fm5J2yRdPB4kMTGR6dOn07lzZwIDA+nUqRMAp06dYteuXQwaNEgLThrTO++8w5AhQ4iIiMDf35/333+fU6dONfrrCCFEW3KuyALAkbT8Fm5J23RBZFB8vAwceHZii7xufUyZMoWOHTvywQcfEBMTg91up2/fvlgsFnx8fOr9+s5JzhRF0bZZra59pV9++SV//etf+ec//0lCQgIBAQG88sorbN68ud6vJ4QQF5LsQjVAOZFVSInVhrme//NFzS6IAEWn09Wrq6UlZGVlcfjwYT744APGjBkDwLp167T9/fv358MPPyQ7O9ttFsVkMlVZuTkiIgKAlJQUBg0aBOBSMAuwfv16LrroIu677z5tW8XCXCGEEO6dcxTH2hU4ml5A3/ZBLdyitkW6eDxESEgIYWFhvP/++xw9epTff/+duXPnavunT59OdHQ0U6dOZf369Rw/fpxvv/2WjRs3AtCpUyeSkpLYtWsXmZmZlJaW4uPjw8iRI3nxxRc5ePAgq1ev5u9//7vL63br1o1t27bx66+/cuTIEZ544gm2bt3arO9dCCFaG5tdIcfRxQNwKFW6eRqbBCgeQq/X8+WXX7J9+3b69u3LQw89xCuvvKLtN5lM/Pbbb0RGRnLFFVfQr18/XnzxRQwGNaU4bdo0Jk2axCWXXEJERARffPEFoBbalpWVMWTIEB588EGef/55l9e95557uO6667jpppsYMWIEWVlZLtkUIYQQVeUVW7GX955LHUoT0CkVCxRaiby8PIKCgsjNzSUwMNBlX0lJCUlJScTHx8vqt22A/DyFEJ7oWEYB4/+5Wvt+bPcIPv3j8BZsUetQ0/W7MsmgCCGEEPV0rtDi8v1h6eJpdBKgCCGEEPXkHMHTJcIPgNS8EplRtpFJgCKEEELUU44jGOkQ6kv7YHUaiMNSh9KoJEARQggh6inbMYInxM9E9yh/QAKUxiYBihBCCFFPzhqUUF8TPaLVYs8jUofSqDx79jIhhBDCAzlrUEL8TMQEqyMMpVC2cUkGRQghhKgn5zo8oX4mekSpGZTDafm0wpk7PJYEKEIIIUQ9aRkUXxOdI/ww6HXkFltJzy9t4Za1HRKgCCGEEPXkXIcn1M+E2ctApzBfQKa8b0z1ClDmzZvHsGHDCAgIIDIykqlTp3L48GGXY0pKSpg9ezZhYWH4+/szbdo00tLSXI45deoUV155Jb6+vkRGRvLwww9TVlZ2/u9G1FmnTp144403tO91Oh0//PBDs7fj6aefZuDAgc3+ukIIcT6cGZRQPy8AekqhbKOrV4CyevVqZs+ezaZNm1i2bBlWq5XLL7+cwsJC7ZiHHnqIn376iUWLFrF69WrOnj3Lddddp+232WxceeWVWCwWNmzYwKeffsqCBQt48sknG+9diXpLSUlh8uTJdTpWggohxIWszGYnt1jNoAT7mgDoHhUASAalMdVrFM/SpUtdvl+wYAGRkZFs376diy++mNzcXD766CMWLlzIpZdeCsAnn3xCr1692LRpEyNHjuS3337jwIEDLF++nKioKAYOHMhzzz3Ho48+ytNPP43JZGq8d9fGWSyWRjtf0dHRjfI8QgjR1uUUl88YG+yjZlB6RKsBiiwa2HjOqwYlNzcXgNDQUAC2b9+O1WplwoQJ2jE9e/akQ4cObNy4EYCNGzfSr18/oqKitGMmTpxIXl4e+/fvd/s6paWl5OXludzaonHjxjFnzhzmzJlDUFAQ4eHhPPHEE1pVeKdOnXjuuee47bbbCAwMZNasWQCsW7eOMWPG4OPjQ1xcHPfff79LVis9PZ0pU6bg4+NDfHw8n3/+eZXXrtzFc/r0aaZPn05oaCh+fn4MHTqUzZs3s2DBAp555hl2796NTqdDp9OxYMECAHJycrjrrruIiIggMDCQSy+9lN27d7u8zosvvkhUVBQBAQHMnDmTkpKSRj6LQgjRtHIcI3iCfLwwGtTLqDNASUzPx2aXkTyNocEBit1u58EHH2TUqFH07dsXgNTUVEwmE8HBwS7HRkVFkZqaqh1TMThx7nfuc2fevHkEBQVpt7i4uPo1VlHAUtj8twYMN/v0008xGo1s2bKFf/3rX7z22mt8+OGH2v5XX32VAQMGsHPnTp544gmOHTvGpEmTmDZtGnv27OGrr75i3bp1zJkzR3vMHXfcQXJyMitXruSbb77h3XffJT09vdo2FBQUMHbsWM6cOcP//vc/du/ezSOPPILdbuemm27iL3/5C3369CElJYWUlBRuuukmAG644QbS09NZsmQJ27dvZ/DgwYwfP57s7GwAvv76a55++mn+8Y9/sG3bNtq1a8e7775b73MkhBAtKbuwvEDWqUOoL95GPSVWO6fPFbVU09qUBk/UNnv2bPbt28e6desasz1uPfbYY8ydO1f7Pi8vr35BirUI/hHTBC2rxf+dBZNfvR4SFxfH66+/jk6no0ePHuzdu5fXX3+du+++G4BLL72Uv/zlL9rxd911FzNmzODBBx8EoFu3brz55puMHTuW+fPnc+rUKZYsWcKWLVsYNmwYAB999BG9evWqtg0LFy4kIyODrVu3atmxrl27avv9/f0xGo0u3ULr1q1jy5YtpKen4+3tDajB1A8//MA333zDrFmzeOONN5g5cyYzZ84E4Pnnn2f58uWSRRFCtCrlQ4y9tG0GvY74cD8OpeZzPLOQjmH1+98vqmpQBmXOnDksXryYlStXEhsbq22Pjo7GYrGQk5PjcnxaWpp2MYuOjq4yqsf5fXV1EN7e3gQGBrrc2qqRI0ei0+m07xMSEkhMTMRmswEwdOhQl+N3797NggUL8Pf3124TJ07EbreTlJTEwYMHMRqNDBkyRHtMz549q2S5Ktq1axeDBg3SgpO62L17NwUFBdroLectKSmJY8eOAXDw4EFGjBjh8riEhIQ6v4YQQniCipO0VRQfrgYlxzMKqzxG1F+9MiiKovDnP/+Z77//nlWrVhEfH++yf8iQIXh5ebFixQqmTZsGwOHDhzl16pR2IUpISOCFF14gPT2dyMhIAJYtW0ZgYCC9e/dujPdUlZevms1obl6+jf6Ufn6uUXlBQQH33HMP999/f5VjO3TowJEjR+r9Gj4+PvV+TEFBAe3atWPVqlVV9tUUDAkhRGtTcZK2ijpHqP+fkzILmr1NbVG9ApTZs2ezcOFCfvzxRwICArSakaCgIHx8fAgKCmLmzJnMnTuX0NBQAgMD+fOf/0xCQgIjR44E4PLLL6d3797ceuutvPzyy6SmpvL3v/+d2bNna10DjU6nq3dXS0vZvHmzy/ebNm2iW7duGAwGt8cPHjyYAwcOuHTBVNSzZ0/KysrYvn271sVz+PDhKlmuivr378+HH35Idna22yyKyWTSMjoV25GamorRaKRTp05un7dXr15s3ryZ2267zeX9CSFEa6ItFFglg6KuapyUKRmUxlCvLp758+eTm5vLuHHjaNeunXb76quvtGNef/11rrrqKqZNm8bFF19MdHQ03333nbbfYDCwePFiDAYDCQkJ/OEPf+C2227j2Wefbbx31YqdOnWKuXPncvjwYb744gveeustHnjggWqPf/TRR9mwYQNz5sxh165dJCYm8uOPP2pFsj169GDSpEncc889bN68me3bt3PXXXfVmCWZPn060dHRTJ06lfXr13P8+HG+/fZbbSRWp06dSEpKYteuXWRmZlJaWsqECRNISEhg6tSp/Pbbb5w4cYINGzbw+OOPs23bNgAeeOABPv74Yz755BOOHDnCU089Ve3ILSGE8FTZReULBVbkzKBIF0/jqHcXT23MZjPvvPMO77zzTrXHdOzYkV9++aU+L33BuO222yguLmb48OEYDAYeeOABbTixO/3792f16tU8/vjjjBkzBkVR6NKlizayBtS5aO666y7Gjh1LVFQUzz//PE888US1z2kymfjtt9/4y1/+whVXXEFZWRm9e/fWfqbTpk3ju+++45JLLiEnJ4dPPvmEO+64g19++YXHH3+cO++8k4yMDKKjo7n44ou1UVo33XQTx44d45FHHqGkpIRp06Zx77338uuvvzbS2RNCiKZ3zk2RLEBnRw1KSm4JRZYyfE0NHociAJ3SCpdezMvLIygoiNzc3CoFsyUlJSQlJREfH4/ZbG6hFjbMuHHjGDhwoMsU9Be61vzzFEK0Tde8s57dyTm8f+sQLu/jOrhj8HPLyC608POckfRJ+R66XgYhHVuopZ6nput3ZbJYoBBCCFEPOdWM4oHykTzKlg/h57/A4oeatW1tiQQoQgghRD1oo3jcBCjObp7QE4vVDSfWgbW42drWlkgHmQdxN0RXCCGE57Da7OSXlAEQ6usmgxLhRzRZxOTtUTfYSuHUJuhySXM2s02QDIoQQghRR85J2vQ6CPTxqrK/c7g/kwxbXTceX9UMLWt7JEARQggh6uicYx2eYF8TBr2uyv7OEX5cYVDns1JiBqsbJUBpkDYboLTCwUnCDfk5CiE8ibt1eCrqaMplqE6dwTvnknnqxpTdUJTdLO1rS9pcgOLlpf7SFBXJapJtgfPn6Py5CiFES6puHR4n7yO/oNcpbLd3I9HYHSJ7AwokrW7GVrYNba5I1mAwEBwcTHp6OgC+vr4ui++J1kFRFIqKikhPTyc4OLjaqf6FEKI5OTMowW4KZAE48AMAv9hG0C2jgOGdx0H6AZK3L+GN/Z154dq+mL3k/1ldtLkABcpXRXYGKaL1Cg4OrnaVayGEaG7aOjzuApT8NDi5AYAltuEYMwuh6zjY9C4cX8W3JdcwrkcEUwbENGOLW682GaDodDratWtHZGQkVqu1pZsjGsjLy0syJ0IIj3KuSL2muJsDhYP/AxQygvpxtiScYxmFMP4i7DojcUoacbo0TmVL+UFdtckAxclgMMgFTgghRKMpr0FxUxd34EcACrpcBWmQlFlAmdGPfbruDFQOMFq/j1NZQ5uzua1amyuSFUIIIZpK+SieShmUMovWvePT/xoATmUX8fPeFH4v7Q3AKP0+yaDUgwQoQgghRB1VO4on/ywoNjB4ExnXA7OXHqtN4aUlh1hn7wvAKP1+krMKmqxt649mcsmrq9hwNLPJXqM5SYAihBBC1FG16/Dknla/BsWiN+jpFKauyXM2t4RDhq7YvPwJ0RUQmn8Qq83e6O1SFIXnFh8gKbOQJftSG/35W4IEKEIIIUQdVTuKxxmgBMcB0CXCX9t1zeBO6LuMA2C8fgdncxp/8cC1iZkcSs0HIL+kbQwOkQBFCCGEqIMSq41Ciw1wk0HJSVa/BsUCEO9Y1Rhg5uh4dD2vAuBy/dYmqUP5YO1x7X6eYzHD1k4CFCGEEKIOchxDjA16HYHmSoNgc50BippBGdIpBIDJfaPpGukP3SdiQ08vfTLZyYcatV0HU/JYm1hedyIZFCGEEOICklVYCkCwj1fVGcor1KAAjOsewY+zR/H6TQPV7b6hnAgYAkBA0tJGbdeHa5MAiAzwBiBfMihCCCHEheNEpto1ExviU3WnFqCoGRSdTseAuGCXae3TYiYA0Cnj90ZrU1peCf/bfQaA2Zd0BSRAEUIIIS4oh9PUItQe0QGuOxSlQhdPbLWPL+t+BQCdSw5AXkqjtGnBhhNYbQrDOoUwpls4AHnSxSOEEEJcOA6n5gHQIzrQdUfxObA6Cl8D21f7+OjYeHbYuzqe7Ofzbk+xxcbnm04CcNeYzgSY1dltC0rLsNuV837+liYBihBCCFEHR9LUSdZ6RFXKoDizJ36R4GWu9vFxIb4stQ0DwLrvf+fdno3HM8krKSMmyMyEXlEEOAp3FQUKLK2/m0cCFCGEEKIWxRYbJ7IKATddPM4hxo45UKrjYzKw1WcUAMZT66Eo+7zatOpwBgCX9IzEoNdh9jJgMqiX9bZQhyIBihBCCFGLo+kFKIo6xX24f/WzyNZGH9aFg/Y4dEoZHPn1vNq0+ogaoIztHqFtc2ZR2sJQYwlQhBBCiFo4C2S7R/m7GWLsOgdKTTqE+vKbXe3m4dDiBrfnRGYhJ7OK8DLouKhruLa9PECRDIoQQgjR5jkLZHtWLpCFemVQ4kJ9+c2mzofC8VVgb9i6PM7sydCOofh7l08aF+ijFspKBkUIIYS4ABx2FMh2r1wgC/XOoBxSOmDBBJYCOJfUoPZo3Ts9Ily2OzMoecWSQRFCCCHavCOp1cyBAvXKoHQI9cWGgWP6juqG1D31bkuJ1cbGY1mAa/0JQIC3ZFCEEEKIC0JukZXUvBJArUFxUVYKBWnq/TpkUOJC1Vlod1k7qBtS6h+gbD2RTbHVRmSANz0rBUxaBkVqUIQQQoi2zVkg2z7YR5sMTZOnTjOP0Qd8Q2t9rqgAMyaDnv12R4DSgAzK6sPlo3cqF+w62ydFskIIIUQbVz6DrJvunYpzoFQe3eOGXq8jNtSH/fZO6obUvfVuT3X1JwCBPjLMWAghhLgglA8xPr/6Eye1UDYOBZ3aPZSfVufHnskpJjG9AL0OxnStGqA4Myi1dfGsTczg/i92klvkuYGMBChCCCFEDY6kqiN4Ktd7AA0OUIoxk212FsrWnEXJLCglMS2fxLR8ftipdikN6hBCkK9XlWPrMlFbbpGV+7/Yyf92n+W3A6l1bndzM9Z+iBBCCHFhUhSFQ44uHvcZlFPq1zoUyDp1CPUFIMmrM2ElJyB1N3Sb4PbYfWdyufrtdVRe+6/y6B2nwDpM1PbW74mcc2ROCks9t1ZFAhQhhBCiGml5peSVlGHQ6+gS6Vf1AC2DUvcAJc4RoOyzdWQo1JhB2X06B7sCJoMef0fwEepn4rrB7ldNLi+SdZ9BOZFZyKcbT2jfF1sbNlFcc5AARQghhKiGM3sSH+6Ht9FQ9YAGdvEAbChqzx1Q41Dj7AILANcOas9L1/ev9blrm+r+xSWHsNrK0zHFVlvdGt0CpAZFCCGEqMYRR4FsD3fdO4rSoAAlPtwPnQ62lTgek30MSvPdHptVqAYooZUXKKxGoLNItrhqBmXz8SyW7k/FoNcxzjECqFQCFCGEEKL1OewokHU7xLgwE8pKAB0Euu9yccfsZSAuxJdsAin1jVY3pu13e+y5IkeA4lu3AMWZQSm02LBVKFyx2xWe//kgANOHx9G/fRAgGRQhhBCiVTqaXr6KcRXONXgCosFYtwDCqVuk+nwZft3VDdV082Q7Myh+dQ1Qykf2FFTo5tl4PIu9Z3IJ8Dby4ITumE1qd1WxRQIUIYQQotXJdNSARAaaq+5sQPeOU1dHgHJMH69uqGZG2ayC+nXxmIx6vI3qpT2vQqHsiaxCAEZ0DiPc3xsfL0eAIhkUIYQQovVx1nIE+VSdc6R8FeP6ByhdHAHKjrKap7yvbxcPuJ/uPi2vFIDoIG9A7WYCKPHgUTwSoAghhBBu2OwK+Y55QtwGKDnOOVAankFZnddO3ZB+EGyuha2KopQXydaxiwfcT3eflqsudhgVoGaCfLQARTIoQgghRKtScSSM2wDlxHr1a1Tfej+3M0DZlR+E4h0INgtkHHY5pshiw1KmZjjC6tjFA+6nu0/LdwQojq4qs3TxCCGEEK1TriNA8TUZ8DJUulzmnoG0vYAOul5W7+cONHsRFegN6CgI6aVurNTN4yyQ9TbqtYxH3Z5bzaAUFBWCRa09cXbxRAaqXTw+UiQrhBBCtCKZifD2MNj7jRaguM2eJP6qfo0dBn5hDXopZxYlxaebuiF1n8t+Z/dOmJ8JXR1WSnZyDjUeuX4WvNEfCrNIz1MzKNFBlbp4yiRAEUIIITzfvm8h8wiseaXmAOXIb+rX7hMb/FJdIxwjeRRHDUumaxfPOUeAElKP+hOAAG8vQsmj3bmtUJSJNWmtFuw4a1DMXurlv0QyKEIIIUQrkJmofs04hDXjGACBlQMUazEcX6XeP58AxTE77a6SKMdrHnHZ35ACWVAzKP31x7XvS5K2AOp6PsGOFZBlmLEQQgjRmmQd1e4GJS9Xv1YOUE6sg7JidfbYBhTIOjkzKOtzHV1EuaegtEDbn12o1o2E1TNACfTxor+uPEDhzDZArT9xdhVJkawQQgjh4UqsNqw2u7q2TtYxbXt06irATYByxFF/0u1yqEdtSGXOGpT9OUYUP3VtHLIStf3ZhWoXU727eMxG+uvL34dPxl702LURPFBeJFtitaMoSpXn8AQSoAghhLhgWW12rnprHRNfX0NZbgpYyhfta5e7g0AKXQMURSkPUM6jewcg3N9EkI8XigJFgV3VjRWGGjc0gxLgbWRAhS4eo62IbrrTRFcIUMwVRgWVlnnmZG0SoAghhLhgbT95jqPpBRzPLCT3jLqYHiGdILwHBsXGWP1u1wAl45DaFWPwhviLz+u1dTqdtiZPurmj4/krBigNy6BEKJlE6HKxoYf2QwEYqD+mDTEGMBvLL/+eOtRYAhQhhBAXrNVHMrT7JamOItWwbtBjMgATDDtcAxRn9iT+YjD5nffrO7t5knCM5GmEDEpUwQH1OfUdodNoAAbojrp08RgNekyOuV08tQ5FAhQhhBAXrNWHywMUe4aj/iOsqxagjNPvIti7wgMaqXvHyRmg7LVEqxsyDmn7ylcy9q7yuJqE5ajzqeyjC8SqGZRB+mOOieHKOYcaS4AihBBCeJD0vBIOpORp3xtzHIWlYV0gdhi5ukCCdEV0KNirbs84Asmb1fvdLm+UNjgXDdyYF65uOJcEZWrmpDxAcTMPSw0CstT27iiLh/ZDAOiuS6ad2TUQKS+UlQBFCCGE8BgVu3cAfPJOqHfCu4HewHq9enGPSV8JBxfDB5eCYlPrOkI6NkobnDUo27NN6po8ih2yjmK12bW1dOqVQbHbMWXsBmCbNR6rXzRpSigGnUKcJdHlULOHLxgoAYoQQogLkjNAMeh1GCkjoDhZ3RGmjqhZZhsEQMThL+CrGeoInw4Xwc0LG60NMUE++HgZsNqgNMQx5X3GYW0WWb2umplsq5N9HH1pHiWKF0eUWNLzS9lh7wJAeM5el0O1ydosMopHCCGE8Ag2u8LaxEwAxnQLJ1aXgUGxgdEHAmKw2RV+K+lDqWJEX1akPmjkfXD7/yAgqtHaodfr6BKpFttmmjupGzMOk12kBijBviYM+nrMtXJ2BwAHiacMI0fTC9hlVwMu79QdLod6+mRtEqAIIYS44Ow+nUNusZVAs5HxPSOJ16WqO8K6gl5PfomVQnz4zjYGxTsApn0Ek+aBoX71IHXhnFH2pD5O3ZB5mOyChk1zzxk1CDlsUIOSxLR8ditdHPu2uxzq6dPdS4AihBDiguMcvTOmWwQRAWY6686qO8LUi7lzocBndX9C98gJ6Hd9k7Wlm2NNnn3aSJ7yDEqobz0DFEcGJcnUA4Cj6QXssXfGjh7yzkBeinaotmCgBChCCCGEZ1jlqD8Z2z2CMH8TnStmUMB1JWODsUnb0jNaDVA25DpG8mQd5Vy+2q1UrwyKrQxS9gBw2rcXoAYoRZhJ9e6kHlMhiyKjeIQQQggPkl1oYc/pHAAu7h5BmJ+JeJ0jsxCuFqq6BChNrLsjg7Ix2wfFyxdsFsqykgAI9a9HgJJxUF3E0DuQAj91lNHRDHXxwfTAPuoxjoUDoUINiswkK4QQQrS8tYkZKIqauYgOMhPm501nvRqgWILjgeYNUNoH++BnMmCx6SgNUruYvM+pqyrXq4vHmR2JGYi/j/q4nCL1fRSED1T37fsWcs8AUoMihBBCeJT1R9XRO2O7qysIBxpKiNadAyDb3AEoD1ACfZq2ewfUkTzdHd08mT6dAPDLdwQo9eniOe3IjrQfQqDZtd2FXa6AoA6QcwoWXAE5p7QApcRqhzKLuhCiB5EARQghxAVl3xl19tghHUMA0GWrK/9mKoFklvkCFQOUps+gAPRwdPMk6dQ1eUIK1S6esPp08ZzapH6NG0mg2bXdYeHRcOcv6kKI507AJ1cSXXaWi/W7uerI/8G8WPiocWbHbSxNHxoKIYQQHsJSZicxPR+A3jGB6sZMdYbVJCWaIscEac3ZxQPldSh7S6MZA0RbTgIQUtcunsIsyHLMFBs3nIAzWS67owLNEBwKdy6BT6dA1lFm7rqeu0wKnHMcdHoLlBaAt38jvKPzJxkUIYQQF4zE9HysNoVAs5H2wT7qxix1DZ4kezttBeG8Zg5QnCN5nGvyxNpOo8Ne9y4e5xpB4T3AN5SAShmUiADHdPmBMXDHzxDeAx0K5xR/VgdfC15q5oiCtPN+L41FAhQhhBAXjANn1e6d3jGB6HSOGVqz1HqP40o7sgpaKIPiDFByAlH0XvhSQntdVt0DlFMb1a8dRgIQUKEGJdjXSxuxo+6MhrtXsHz4R4wofYf/hs5RAxeA/PJ5UlqaBChCCCEuGM7Vi3u3CyrfmOXs4mlHlqOLJ69YXaivuQKUcH9vwv1NlCkGigLUkURddWfqn0HRApTydkcFmKse7x1AXvRILHip86D4OyaJy09t8HtobPUOUNasWcOUKVOIiYlBp9Pxww8/uOy/44470Ol0LrdJkya5HJOdnc2MGTMIDAwkODiYmTNnUlBQcF5vRAghhKhNxQwKoI5ccXTxqBkUtYunuTMoUF6HkmxURxL1Np51zXxUx1oCZ3eq9+NGAK4ZlKggNwEKVBjFYytfX6g1d/EUFhYyYMAA3nnnnWqPmTRpEikpKdrtiy++cNk/Y8YM9u/fz7Jly1i8eDFr1qxh1qxZ9W+9EEIIUUeKolTIoDgClOJzUKpuO6VEkt1CRbJQHqDsKlGDhd5edexuObsTbBbwi4TQzgAuo3iinPUnlZhNFeZBCWinbvSgLp56j+KZPHkykydPrvEYb29voqOj3e47ePAgS5cuZevWrQwdOhSAt956iyuuuIJXX32VmJiY+jZJCCGEqNXpc8Xkl5ThZdDRNdIxUiU3GYBS7zBKS0xaF09LBCjOQtn1OeHc7KV28dRJsmN4cYcR4KirccmgBNacQSm22MDfkUHJb8UZlLpYtWoVkZGR9OjRg3vvvZesrPLhThs3biQ4OFgLTgAmTJiAXq9n8+bNbp+vtLSUvLw8l5sQQghRH87sSbfIAExGx+XPMatqmb/64TirwILdrpBX0gIZFEeAcsjeHoAOtlN1mzzNOf9JhwRtk0sGJdB9BsVlorYAZw2K52RQGj1AmTRpEv/5z39YsWIFL730EqtXr2by5MnYbOpUuqmpqURGRro8xmg0EhoaSmqq++KcefPmERQUpN3i4uIau9lCCCHauP2V609AXeEXIEidIC270EJ+aZkWFzTXRG1Q3sVzQommTNHjqxRB3tmaH2S3lxfIxo3UNvtXyKBEVpNBMbvUoDgClNZcg1Kbm2++mauvvpp+/foxdepUFi9ezNatW1m1alWDn/Oxxx4jNzdXuyUnJzdeg4UQQlwQtALZdhUCFEcXjzFE/eBbUFpGRr5aKOtt1NetSLWR+HsbiQ3xwYqRE4ojYMg4VPODshLVOhqjD7Trr2026HX4e6tBSq1dPC6jeNpwgFJZ586dCQ8P5+hRdZx5dHQ06enpLseUlZWRnZ1dbd2Kt7c3gYGBLjchhBCiPg46unj6VMygOLp4TKFxeBnU+o2kzEKgebt3nJxT3icqajcPGYdrfoBz/pPYoWBwbe/04XEkdA5zDcgqMJvUEKDYakPxd/RslOaCpahhjW9kTR6gnD59mqysLNq1UyuEExISyMnJYfv27doxv//+O3a7nREjRjR1c4QQQlyAcoosnMkpBqCXmy4eXVCsNq388Qx12ouWCFCcdSjlAUotGZRTzu6dqtfPx6/szRezRpbX21TizKAoCpQa/CvMJusZc6HUO0ApKChg165d7Nq1C4CkpCR27drFqVOnKCgo4OGHH2bTpk2cOHGCFStWcM0119C1a1cmTpwIQK9evZg0aRJ33303W7ZsYf369cyZM4ebb75ZRvAIIYRoEs4C2bhQH9eF9HJPq1+DYgnzV4tJWzKD4hzJk2hXa2LqnEHpMLLm49yo2H1VWqZ43Eieegco27ZtY9CgQQwaNAiAuXPnMmjQIJ588kkMBgN79uzh6quvpnv37sycOZMhQ4awdu1avL3Lq4g///xzevbsyfjx47niiisYPXo077//fuO9KyGEEKICt/Undlt5EWpge8Ics7Yeb8EApbvWxeMMUA5VP5InJxnOJQE6iB1W79fyMugx6tVureKKhbIeMpKn3vOgjBs3DqWGYU+//vprrc8RGhrKwoUL6/vSQgghRIO4neK+IA0UG+gMEBBNmL9aH3k8o+UClC4R/ngZdCTZolF0enQlOVCQXj7Ta0VbP1S/dhwFPsENej0fLwP5pWWuAYqHjOSpd4AihBBCtDZVpriH8u6dwBjQG7R1bzId09035xBjJ5NRz9NX9+HMuWI4Eg/Zx9QsSuUAxVII2xeo90fe2+DXM5scAYrF89bjkQBFCCFEm1ZaZuNoulr46j5AUQtSwyotzNcSGRSAGSM6qnfO9XQEKIeh81jXg3Z/ASU5ENIJetQ8u3tNtMnayiqsx+MhAYqsZiyEEKJNS0wroMyuEOTjRUzFhfMqTdLmLJJ1aqkARRPRQ/2acdB1u90Om95T74+4F/QNn6vF7KWGASUVMyitdRSPEEII0Zo4i167Rfqjc6xVA1QYwaNmUEI9JIOiieipfq08kufocnWCNu9AGDTjvF7CZbK2AM+arE0CFCGEEG3aSUeA0incz3WH1sWjZlDC/T0tQHFmUCrNhbLpXfXr4NvAO+C8XsLsNkDxjFE8EqAIIYRo005kqTOjdgrzdd1RqYsn1K9SF49vCwco4d0BHRRlQWGmui3tABxfCTo9DJ913i/hY3KzonFJDlhLzvu5z5cEKEIIIdq0k1lqBqVjWDUZFE/t4jH5QnAH9X7GITVIWfKI+n3PqyCk43m/hNnoLJK1g08IGBxBmgcMNZYARQghRJtWnkGpEKCUlUJhhnrf0cUTaDZq6/GABwQoUF6Hsu1jeDcBTqwFgwnGzG2Up3dmUEosNtDpPGokjwQoQggh2qz8Eqs2r0mHil08zu4dow/4hgKg0+lcsiieEaA46lD2fQuF6RDRC+5aATGDGuXpXWpQwKNG8kiAIoQQos066ciehPqZXAOOit07FUb2OOtQTEa9y1o1LSa6X/n9hDkwaxW0699oT+9TOUDxoJE8MlGbEEKINssZoHSsXCCb68igOCZpc3KO5PGI7AlAr6vh0pPQ4SLoNKrRn97H5JgHpUqA0vIjeSRAEUII0WadcBTIdqpcIJvnzKDEuWx2dvF4TIDiZYaLH26yp9eKZLUuHkcNihTJCiGEEE2nfARP5QyK6wgepzBHF4/HBChNzGWYMUBAO/WrFMkKIYQQTcc5gie+yiRt7rt4wjyti6eJVSmSlVE8QgghRNOrdg6USpO0OQ3tGIJRr2NYp9DmaF6LKy+StasbPGgUj9SgCCGEaJOKLGWk5alDjKvMIqt18bgGKCM6h7H36Yla10db58yglBfJOrp4irKgzAJGUzWPbHqSQRFCCNEmncpWu3eCfLwI9q1woS3Jg9I89X6lLh7ggglOwM0oHt9Q0Du6t1q4UFYCFCGEEG3Sicxa1uAxB4O3f/M2ysNoNSjOIlmdzmNG8kiAIoQQok2qfQ2eWC50VSZqgwpzobRsHYoEKEIIIdqkalcxdgYobrp3LjTaWjzOIlnwmMnaJEARQgjRJtV3BM+FqMpEbSBdPEIIIURTOpHpmEU2vG6TtF2ItInarDYURVE3ekgXjwwzFkII0eaUWG2czS0BaqhBCZQMirNI1mZXsNoUTEYddB0P3oHQbkCLtk0CFCGEEG1OsmOIsb+3kTC/SnN5SBePxqfCis3FVhsmox7aD1FvLUy6eIQQQrQ5JyqsYqzT6cp3KEr5NPfSxYOXQYfecXpKK9aheAAJUIQQQrQ5J6tbxbgwE2ylgA4CYpq/YR5Gp9O5H2rsASRAEUII0eacyKquQDZZ/eof1aLTuHuSioWynkQCFCGEEG3OSa2Lp7ohxtK941RlNlkPIQGKEEKINse5Dk+H0MoZFCmQrczHy81kbR5AAhQhhBBtiqIopDiGGLcP9nHd6ezikSHGmiorGnsICVCEEEK0KeeKrFjK1GxAZKC3607p4qlCimSFEEKIZpDqyJ6E+ZnwNhpcd0oXTxVmk9SgCCGEEE0uNa8YgKhAc9WdMotsFT5eaiggGRQhhBCiCaXmlgLQLqhSgGIrgwLH+jKSQdFIDYoQQgjRDFJzHRmUygFKfgoodtB7gV9EC7TMM/lIgCKEEEI0vdQ8tQalXeUuHq17Jwb0cvlzMkuRrBBCCNH0nEOMq2RQtBE8cc3cIs+mzSRrkXlQhBBCiCaT5sygVA5QnHOgyBBjF1oXT5lkUIQQQogm48ygRFfp4nFkUAIlQKnI7BjFUyLDjIUQQoimUWQpI7+kDIDoart4ZARPRTJRmxBCCNHEnJO0+ZkMBJi9XHdqXTwSoFQkRbJCCCFEE3MGKFWyJyCzyFbDR2aSFUIIIZqWc4hxlQDFUgTF2ep9qUFxYTY6i2RlFI8QQgjRJMoLZCutYuysPzH5gzmomVvl2ZwZFCmSFUIIIZpImpZBqbSKsXOStqBY0OmauVWeTWpQhBBCiCamZVCCKmVQtFlkpXunMhnFI4QQQjQxLYNSeQ4UbYixBCiVaV08EqAIIYQQTcOZQak6i6yzi0emua/MOVGbjOIRQgghmoDVZiezoBSAqGoXCpQMSmXOUTxldgWbXWnh1pSTAEUIIUSbkJ5fiqKAl0FHmJ/Jdad08VTL26s8FLB40FBjCVCEEEK0Cc5J2iIDzOj1FUbqKEqFSdqki6cyk6E8FCj1oAUDJUARQgjRJlQ7i2zxObAWqvcDY5q5VZ7PaNBjcAR0pZJBEUIIIRpXtbPIOrt3fMPBq9LwYwGAt1ENB0qtEqAIIYQQjaraIcbnTqhfg6V7pzpagCJdPEIIIUT95JdYWX80kzKb+0/51Q4xzjqmfg3t0pTNa9W8HSN5pItHCCGEqKcXlxxixoebueez7RRZyqrsT3MEKFWGGGc7ApQwCVCq4xzJIxkUIYQQop5OZRcBsOJQOtM/2KzNeeKUklcMuMugHFe/SgalWlKDIoQQQjRQYWl51mR3cg7T5m/gRKY6OkdRFNJyq5mkTTIotZIuHiGEEKKBCkvV7ofnrulDbIgPJ7OKmDZ/A7uSc8gutGBx1Ka4BCiWQshPUe+Hdm7uJrca5UWyEqAIIYQQ9VLgyKD0iw3mu/suom/7QLIKLUx/fxNfbDkFQLi/CZOxwqUt29G94xMCvqHN3eRWQ2pQhBBCiAZyBij+3gYiA8x8OSuBi7tHUGy18epvRwA3c6A4R/CEdW3OprY60sUjhBBCNICiKBUCFC/HVyMf3T6U64fEasdVmQMl66j6VQpka+Sc7l4CFCGEEKIeSsvs2kq7ft4GbbuXQc8r1/fn/vHdMOh1XNQl3PWBzi4eKZCtkdbFY/WcLh5jSzdACCGEqE1BhRE8fibXS5dOp2PuZd25d2wXfEwG1wdqk7RJgWxNpEhWCCGEaICCEjVA8TMZXFcqrqBKcAIyxLiOpAZFCCGEaABnBsXPux6J/5I8KMxQ70sNSo1kLR4hhBCiAbQCWXM9AhRn9sQvAsyBTdCqtqO8BkUyKEIIIUSdFWojeOoRoMgigXUmXTxCCCFEAxQ0JECRETx11ia6eNasWcOUKVOIiYlBp9Pxww8/uOxXFIUnn3ySdu3a4ePjw4QJE0hMTHQ5Jjs7mxkzZhAYGEhwcDAzZ86koKDgvN6IEEKItqtBNSgygqfOnAGKpTVnUAoLCxkwYADvvPOO2/0vv/wyb775Ju+99x6bN2/Gz8+PiRMnUlJSoh0zY8YM9u/fz7Jly1i8eDFr1qxh1qxZDX8XQggh2rQGdfHICJ468/byvC6ees+DMnnyZCZPnux2n6IovPHGG/z973/nmmuuAeA///kPUVFR/PDDD9x8880cPHiQpUuXsnXrVoYOHQrAW2+9xRVXXMGrr75KTEzMebwdIYQQbZFzmHGDalBkmvtatfl5UJKSkkhNTWXChAnatqCgIEaMGMHGjRsB2LhxI8HBwVpwAjBhwgT0ej2bN292+7ylpaXk5eW53IQQQlw4ChwrGde5i6coG4qz1fvSxVMr5wKLnjSTbKMGKKmpqQBERUW5bI+KitL2paamEhkZ6bLfaDQSGhqqHVPZvHnzCAoK0m5xcXGN2WwhhBAerqDUCkBAXYcZOwtkA9qBya+JWtV2yCieBnrsscfIzc3VbsnJyS3dJCGEEM2o0JlBcTdbrDsyxLhe2nwXT3R0NABpaWku29PS0rR90dHRpKenu+wvKysjOztbO6Yyb29vAgMDXW5CCCEuHPUexaMVyEr3Tl20iWHGNYmPjyc6OpoVK1Zo2/Ly8ti8eTMJCQkAJCQkkJOTw/bt27Vjfv/9d+x2OyNGjGjM5gghhGgjnAFKnbt4JINSL9ooHg+aSbbeo3gKCgo4evSo9n1SUhK7du0iNDSUDh068OCDD/L888/TrVs34uPjeeKJJ4iJiWHq1KkA9OrVi0mTJnH33Xfz3nvvYbVamTNnDjfffLOM4BFCCOFWYYMzKBKg1IUndvHUO0DZtm0bl1xyifb93LlzAbj99ttZsGABjzzyCIWFhcyaNYucnBxGjx7N0qVLMZvN2mM+//xz5syZw/jx49Hr9UybNo0333yzEd6OEEKItii/PsOMrcWQtl+9H9m7CVvVdnhiF0+9A5Rx48ahKEq1+3U6Hc8++yzPPvtstceEhoaycOHC+r60EEKIC1ShpR4BypntYLOoI3hkiHGdeOJEba1iFI8QQogLl6Io5RO11aUG5eQG9WvHi0Cna8KWtR0Vp7qvKQnRnCRAEUII4dFKy+yU2dWLZp1qUE6uV792vKgJW9W2OAMUAIvNM7IoEqAIIYTwaM4CWQA/Uy0Bis0KyVvU+x1HNWGr2hbnRG3gOd08EqAIIYTwaM4hxr4mAwZ9LV02KbvBWgQ+oRDeoxla1zZ4GcrPq6cMNZYARQghhEer1yRtFbt39HKJqyudTudxI3nkpyeEEMKjOQtkA+oUoFQokBX14mlzoUiAIoQQwqM5hxjXmkGx2+DkRvW+BCj15mmzyUqAIoQQwqMVOBcK9K5locD0A1CaC6YAiOrXDC1rW6SLRwghhKgHbQ4Ub6+aD3R273QYAYZ6z0N6wZMuHiGEEKIenMOM/WvLoMj8J+fFOdRYAhQhhBCiDvJL6zCLrKJUKJCV+U8awturfDZZTyABihBCCI9Wp5WMMxOhMAOMZogZ1Ewta1ukBkUIIYSohzoNM3Z278QOA6N3M7Sq7dG6eGQUjxBCCFG7groMM3ZOb99hZDO0qG2SIlkhhBCiHurUxZO8Wf0aN6IZWtQ2maSLRwghhKi7Wrt4CrMg+5h6P3ZoM7Wq7ZFRPEIIIUQ91LoWz2lH9054D/AJaaZWtT3OUTxSgyKEEELUQUFtw4y17p3hzdSitklG8QghhBD1UD5RW3UBiiODIvUn50W6eIQQQoh6KNTW4nEToNiscGaHel8yKOdFMihCCCFEHZWW2bDY1E/0bjMoqXuhrBjMwRDWrXkb18ZIDYoQQghRR87sCYCfyc1aPFr3znDQyyXtfDi7eJwBYUuTn6YQQogWY7XZ2XA0E2s1F0XnEGMfLwNGg5tLlnMET6x075wvrYtHMihCCCEudF9vS+aWDzfz6Dd73O6vdYhxxQyKOC9SgyKEEEI4HEnNB+C7nWfYeepclf3aEGNvN907uWcgNxl0emg/pEnbeSHw9pJRPEIIIQQAmQUW7f7zPx9EURSX/YU1zYHi7N6J6gPe/k3WxguFySBr8QghhBAAZBSUave3nzzHL3tTXfZrXTwmNwFK8lb1q8x/0ii0UTzSxSOEEOJCl+kIUBI6hwEwb8lBSqzlF0hngBLgLoMiCwQ2KimSFUIIIRwy89UA5f+u6EVUoDenzxWzYMMJbX+1KxlbSyBlt3o/dlhzNLXNk5lkhRBCCNSuhDzHMOK4UB8emdgTgLd/P0pukRWA/JJqprlP2Q12K/hFQEinZmtzWyajeIQQQgjKC2S9DDqCfLy4dlB7Okf4UVBaxrqjmUAN6/Cc2aZ+jR0GOl2ztbktM3tJkawQQgihde+E+3uj0+nQ63WM7R4BwKbjWQAUWqrp4jntKJCNHdo8jb0AaF08UoMihBDiQuYskA3399a2jXQUyzoDlGq7eE5vV7+2lwClsTi7eGSqeyGEEBe08gDFpG0bER+KTgeJ6QVk5Je67+LJT4PcU4AO2g9uzia3ac4Mis2uUOYBQYoEKEIIIVqEswalYgYl2NdEz+hAADYnZZXPJFtxmLGz/iSyF3gHNE9jLwDOeVDAM+pQJEARQgjRIjKcNSgB3i7bR3YOBdRungLHasYuNShSf9IkTAYJUIQQQgi3NShQsQ4lm4JSdbixy1o8pyuM4BGNRq/X4WVQR0R5wlDjapaHFEIIIZqWuxoUKK9DOZpegMlRuOnv7aXutNvgzA71vhTINjpvowGrrcwjRvJIBkUIIcR5O5NTzPaT2djtSu0HOzhrUCIqZVCCfU30ctShWBxdDX7ODEr6QbAWgikAIno0QstFReWTtbV8gCIZFCGEEOfFble4+f2NJGcX0znCjz+Oimfa4Fh8TIYaH6dlUCrVoIDazXMgJU/7PsCZQXEWyLYfDPqan1/UnyfNJisZFCGEEOflQEoeydnFABzPKOTvP+wj4cUV/G/32WofYymzk+OYzr5yDQqUF8o6aRkUKZBtUt5enrMejwQoQgghzsvqIxkAjOkWzlNTetMh1JecIitv/55Y7WOyCtXsiVGvI9jHq8r+4Y46FFCnYDc6R5hIgWyT8qQVjSVAEUIIcV5WHU4HYGKfaO4cFc/X9yQAcCyjkBKr+66CzHy1/iTM34ReX3UtnYp1KNokbSW5kHFYvS8Fsk1CuniEEEK0CbnFVnacygHQ1tGJCvQm1M+Eza5wJC3f7eOqG2JckXO4sTYHypkdgALBHcE/onHegHDhnE3W4gFdPFIkK4QQosE2HM3EZlfoHOFHXKgvADqdjt7tAll3NJMDZ/PoHxtc5XEZdQhQxnQNJXXjF4wmB1ZuhOQt6g7p3mky3h60orEEKEIIIRrMWX8yrnuky/beMY4ApcJInIrqkkEZd+otLjG9DYXA6go7Oow8rzaL6nlSF48EKEIIIRpEURQtQBnbw7XLpXc7tX7kwNlqAhRHDUp4gMntfjb/G93Gt9X7/W4AcxAYTOAXAQNnNELrhTvOLh7JoAghhGi1EtMLSMktwduoZ0S867Dg3jFqgHIwJQ+7XalSCOvMoFSepE190GJY8qh6f/yTMOYvjd944ZZJRvEIIYRoTWx2hSd/3Mdrvx3G5pgtdvVhNXsysnMYZi/XSdM6h/vhbdRTaLFxKruoyvNV28WTvBW+nQkoMOQOGD230d+LqJ4ndfFIgCKEEKJWG49l8Z+NJ3nz96P86b/bKbbYyrt3ulcdUWM06OkZHQDgtg7FbYBSZoFv7oSyEuh2OVzxT7TJUESz8KSp7iVAEUIIUaul+1O0+8sOpDH9g01sScoGqtafODm7efafza2yT1uHp+I093u+gtxk8I+C6z8Bg1QhNDeZSVYIIUSrYbcr/Lo/DYD7L+1KkI8Xu5JzsNjsxIb40Dncz+3jqiuULbPZOVfkKJJ1rmRst8G619X7CXPA278J3omoTflMstLFI4QQwsPtOHWOjPxSAsxG5lzajW/vTaB9sA8Al/aMRFdNN4wzg1K5iye70IKigEGvI8TXEaAc+AGyj4E5GIb+saneiqiFJ3XxSP5MCCFEjZbuSwVgQq8oTEY9XSMD+H72RSzencLUQe2rfVyP6EB0OkjLKyWzoFSrN0nPV+tPQv0c09wrCqx9TX3QyHsle9KCPGmYsWRQhBBCVEtRFJY4ApSJfaK17ZEBZv44Op5Qv2rmMUFdQ6dTmNr9c7BCFqVKgeyRXyFtH5j8Yfisxn4Loh6cM8l6wlT3EqAIIYSo1v6zeZzJKcbHy+B2tE5t3NWhOAtkw/1NjuzJq+qOYTPBN7TKc4jm40nDjKWLRwghRLWW7FNH74zrEYGPyVDL0VX1jgnk570p5XUotjICjy/mr8YNDMuzwmfFcHorGLxh5OzGbLpoAE/q4pEARQghRLWc9SeT+kbXcqR7zgzKkTNZsOM/sPY1Lj+XxOVGINdxA7UwNiDq/Bsszou3B80kKwGKEEIItxLT8jmWUYjJoOfSnpG1P8CN3jGBJOj382rev+F/mQAUGIL4vnQYPbt3Z1jf3hAYA53GNGbTRQOVr2YsXTxCCCE8lDN7MqprGAFmrwY9R6TZzr9M84kkG6tPBF5jHuSBfX1ZcbyQ1/oOYNjg2MZssjhPJoPndPFIkawQQgi31iaqGY+Ko3fqS7f1AyLJ5rQSzjSvd0npM5MzReqlx2UWWeERyjMoLR+gSAZFCCFEFYqicCQ9H4B+sUENe5LiHG1+k4+MN7En3cp1724gv6QMcLNQoGhxMpOsEEIIj5ZVaCGnyIpOB10iGjhx2oa3oCQHInoy877H6BLhR0puCQWlEqB4Kk8axSMBihBCiCqOphcAEBfii9mr/sOLKUiHTe+q9y/9O7FhAXx770UM6xQCgFGvq3GSN9EyZKp7IYQQHi3REaB0jWxg9mTNK2AtgvZDoOdVAAT7mvhs5gheX36E9sE+GPTu1/ARLUdG8QghhPBox84nQDl3ErZ9ot4f/xRUWEzQ7GXgscm9GqOJogk4u3isNgW7XVHXSmoh0sUjhBCiCmcXT9eG1J9sfAfsVogfC53HNnLLRFNydvEAWGwt280jAYoQQogqnAFKl/pmUIqyYedn6v3RDzVyq0RTqxigtPRsshKgCCGEcJFfYiU1rwRoQBfPto/U2pPoftB5XOM3TjQpo0Gv1Qa1dB1KowcoTz/9NDqdzuXWs2dPbX9JSQmzZ88mLCwMf39/pk2bRlpaWmM3QwghRAM5syeRAd4E+dRjBllrCWx+X71/0f0utSei9fCUkTxNkkHp06cPKSkp2m3dunXavoceeoiffvqJRYsWsXr1as6ePct1113XFM0QQgjRAEcbWiC792soTIfAWOhzbRO0TDQHk9EzRvI0ySgeo9FIdHTVqZFzc3P56KOPWLhwIZdeeikAn3zyCb169WLTpk2MHDmyKZojhBCiHo5mNCBAsdvVidkARt4Lhoat3SNanjODUtIWa1ASExOJiYmhc+fOzJgxg1OnTgGwfft2rFYrEyZM0I7t2bMnHTp0YOPGjdU+X2lpKXl5eS43IYQQTcM5xLhbfQKUxN8g8wh4B8Lg25qoZaI5eMpsso0eoIwYMYIFCxawdOlS5s+fT1JSEmPGjCE/P5/U1FRMJhPBwcEuj4mKiiI1NbXa55w3bx5BQUHaLS4urrGbLYQQwiGxviN4FAXWv6HeH3IHmAObpF2ieXi31S6eyZMna/f79+/PiBEj6NixI19//TU+Pj4Nes7HHnuMuXPnat/n5eVJkCKEEE2gxGojObsIqEcXz95FcGojGM1q945o1TxlReMmH2YcHBxM9+7dOXr0KNHR0VgsFnJyclyOSUtLc1uz4uTt7U1gYKDLTQghRONLyizErkCg2UhEXRbzK8qGpY+p9y9+GAJjmraBoslpXTxtsQalooKCAo4dO0a7du0YMmQIXl5erFixQtt/+PBhTp06RUJCQlM3RQghRC0qjuDR1WWY8PKnoCgTInqqQ4tFq+fs4mnpmWQbvYvnr3/9K1OmTKFjx46cPXuWp556CoPBwPTp0wkKCmLmzJnMnTuX0NBQAgMD+fOf/0xCQoKM4BFCCA+QqBXIBtR+8MkNsOM/6v2r3gCjrE7cFmg1KNY2VoNy+vRppk+fTlZWFhEREYwePZpNmzYREREBwOuvv45er2fatGmUlpYyceJE3n333cZuhhBCiAao8yKBZRb46UH1/uDboaNkwdsKTxnF0+gBypdfflnjfrPZzDvvvMM777zT2C8thBDiPNV5krZN70DmYfCLgAlPN33DRLO5YIpkhRBCtA5lNjtJmYVALQFKYSas+ad6/7LnwDe0GVonmounDDOWAEUIIQQAp7KLsNjsmL30tA+uYVqI1S+BJR/aDYD+NzVfA0Wz0Ka6b+ujeIQQQrQOe8/kAtAlwh+9vpoRPJlHYdvH6v3LngO9XEbaGk+pQZHfLCGEEFhtdv61IhGAcT0iqj9wxdNgL4Nul0Pnsc3TONGspItHCCGEx1i4+RTHMwoJ8zNxz9gu7g86uREO/gQ6PVz2bPM2UDQbyaAIIYRodr8fSmPUi7/z+eaT2rbcIiuvLz8CwEOXdSfQ7GYlYkWBZU+o9wfdCpG9mqO5ogUMiw9h9iVdGNe9hkxaM2j0YcZCCCE810+7UziTU8zj3+/jzLliHp7Yg7d+TySnyEr3KH9uHlbNOmdbP4TTW8HLFy75v+ZttGhWF3UJ56Iu4S3dDAlQhBDiQnIiq1C7/+6qYxzLKOD3Q+kAPH5lb4wGN4n1rGOw7En1/vgnIaD6tdOEaCzSxSOEEBeQk1nqSsUzR8dj0Ov4dX8aVpvC2O4RjHWX0rfb4Id7wVoEncbA8HuaucXiQiUBihBCXCByi61kF1oAmHtZdz68bSg+XgZMRj2PX1lNTcmGNyF5M5gCYOq7MqxYNBvp4hFCiAvEKUf2JCLAGz9vI5f0jGT1I+MottjoGOZX9QFp+2HlP9T7k+ZBcIdmbK240EmAIoQQFwhn/UmnMF9tW2SA2f3Bx1fDt3eBzQLdJ8GgPzRHE4XQSIAihBAXiBOZzgDFTbbEyW6DNa/CqnmAApF94Oq3QFfNzLJCNBEJUIQQ4gJxwtHF0ym8mgAl4wgseQSOr1S/H3QrTH4ZTL7ujxeiCUmAIoQQF4iTji6ejmGVAo70Q7DmFdj3LaCoc51c+RoMnN78jRTCQQIUIYS4QGgZFGcXT0keLP0b7FoIKOq2HlfChKcgokfLNFIIBwlQhBDiAlBQWkZmQSkAHcJ8IWU3LLoDso+rB/SaAhc/Au36t1wjhahAAhQhhGhjbHaFYqsNf2/Hv3i7nVOpGQSTT7QvBO5ZAL/+nzpCJzAWrv8IOoxs0TYLUZkEKEII0cb8/Ye9fLfjDD/9aSjdkxfButfpXZjOLjNgB35xHNh9sjr5mm9oC7ZWCPckQBFCiLZCUVCsRWzbd4hrlc1E/+d+sKS7HGLDgME3BMbMhZH3yfBh4bEkQBFCiNbGboe805CyB87uhLM7IHUvFGWjU2wsA/ACLEBgexj3N55I7M7CnencP6EXD0zo1rLtF6IOJEARQoiWZCtTa0EUG9jLoPgcpB9UbxmHoawYDCb1Zi+DrKPqfCXWwmqf0q7oSCWED8uu5L4/vkB4cBBHtm7EhoFO4TKniWgdJEARwgMdyyjAqNe5Xx/FnbJSKM2H0jywFKlpe50B9AYwB4NfuKTyPUlZKRxZCru/gsTfwG6t/3PovSC8O7QfBDGDIWYQBLTj35vTeXHFKRTHWrB9j+dz3eAgbZr7Ov9OCdHCJEARwsPkl1iZ+s56vI0GNjw8BtOOj2DrB2AtdgQdenXKirJisJaoX+1lNT+pKQBC4yG0MwTFgn8UBLQDc5D66d1WCmUWiOiuXuwkmGkaOadgw1uw5ysoyXV/jMFb/TlE9oaInmAOBJvVkWVRIKwLhPdQf54GryoP351+FgU9wb5e5BRZWX0kg0l9o0nLU4cYd6o8SZsQHkoClIosReonGXNQ1X25p9Ulx+12CIhWb34RYDSD3qh+UrUWQd5Z9VaQrv5jCYxR+4B9QuSfvqiTw6n55JeU0Ve/G+W9/4Nzh+v+YJM/ePmoFzLFrnYblOSBJR9S96i32gR3hD7Xqrd2A+T3tjFkHYN1r8HuL8uDycD20O8G6H+jes71Bsf/EuN5nfMDZ/MAuD2hE/9akciaIxkkOdbgCfLxItjXdN5vR4jmIAFKRUeWwDd/BJ9QCOmk3vRGOLUJck+d33N7+aqfXsO6QGgX9eKRdwZyz0BhhjrMz/mp1icY0Dn+SenAP0L9BxbSCYLiwCj/YNocuw3S9kH6Qcy7NvNfr82MNuyHc6i/j+OfgPZD1OMUO6ADL7MaIBvN4O2vBid6Q9XntpZAzkn1InkuCfJTID9VvZXmqZ/Yjd6g08Ppbeqx699Qb0EdoOeV6i1uuFoH4e7iqShQkgP5aVCQprYlNN7zh68Wn1PbHNJJPZ/uKIr6nrKOql0z5mD1b9Q7QO1WKz4HRdnq33PWUchMhOxj6j6bVQ1ISvPRZmrtPA5GPQjxY9VsWCPKL7Fqs8XOGNmBj9clca7Iys97UgDJnojWRQKUivLUP2KKs9Xb2R3l+3QGiO6n/lPKT1H/qVnyqz6HyV/NmvhHqSncvLNQlKlmV9L2qTd3surYRp1BnYI6up96C2inpnn1RvVCExgDIR3B1Az9zGUWNWXtG1r/DFFRtvrVHOzoslDUi+eJdeqtMNNx0Q1Qz3lwHIR1VW/BHdymtlul4nOw87+w5X31XAJ9AQxgU3Tsib6eQbe/fH4Xei+z+jtTl6nLLUVqTcT+7+DIb2pgvnm+enNyFmzqnBdXnaOLqKTq85mDICRezRYERKu/r37hanbRO1D92eq91N8BnUENtvzCXX+f7DYoylID+ZJcxy1PfU2DSf1dMJjU1/INK79V9ztiK4Njv8Ou/8LhJWrXCTrH71g3tQ22UjUYKcmF7CT3f+v11e1yuPhhNdBrIodS1Xa2CzITGWBmVNdwlu5P5cutyYDUn4jWRQKUii6aA0Nuh3Mn1YtldpLa7x87VP2n4h3gery1RO0Sspep/0QNJvUfb2XWErWLKPuY+ik2+5j6zzgoFoLaq11Fxeccn2pT1E9biuPTlmJTt587obarrBjSD6i3PV9V/158w9V/uAEx5V1SvqFqQOAdqGZh8tMg/6z6/Pay8guGyU8NEPJT1JvNqgYG4d3ULFBmIhxfBSfXq4EXqMGRf5Sa7XFeIHxCHJ/MHanr0nxI3w9pB6DQMTeDTq9mCHT68m11YQ5Sn98nRL3vHaiee5O/+jOzFIDFMcrB+YnXWSzqG6ae84B26idnQyP9Gdjt6kVab1Dfd8XtRZnq70B+ivppvCBd/f06+L/yc+gdCNH9+TUjmLW5EWy096az32A+aM4shMkX+kxVb5YidVXbg4vV7GLxOfUYm8VxUXfDHKT+HpQWqL9bJbmQsku91YfeS/0Z2cvUc6fY6/d4nV7NOoZ3UwtJdXr13OelQOZhNdhx8vJTR8TknNKCxGqfz+SnvqfiHDVoMfmrv7++IeAX6fg7cQTSPqHlAZR3APhHkl9i5afNp4gI8Oay3lH1e0914Oze6d1O/T80rkcES/enkl2o/ryqXcVYCA8kAUpl3gEQ3Ve91cbLDFSTFq58XLjjH9f5UBQ1jZy6D9L2avMeqAFSmSMQSlZT7UWZ6o2d5/eaTkmr3W83mtWLsq1U/bRd364wxXHxBvWiFDsMOo1WAwdLoXoRKMlVA7QsR4BXVlz+SfrcifN4U472R/RUf94mf/XCU5LjSMmjXph0evXC5OyC8wtXL3CZiZCVqAYeliK1XU4Gk/q7ZDSrx1Z3QQeI7AMj7oF+N6B4+fDoc8vIsamjOqypjfDJvaFMvuXdO3aber7tZeUBijOIBjUA9Y9U61+cLEWOwPpEeSCcl6JmJ50jjrRuEJsajFtLoDRXDfzzz1ZojK48wDYHqcGowVs9zmYtz3YUZanPr9jVDxnnktSMUGU+odD/Jhh4i5qJLMyEzCPqhwd7WXm3l8lPDcpDOrkGnaC+/zpmDZOzi/h08QG+3JpMQWkZOh2sf/RSYoJ9an9wPWgBSowaoFzcPcJlv3TxiNZEApTWRKdzZF1iocek6o8ryVWzLbmnoSC1PDNTfK78wl5Wql5QAto5uolM5RcMS4GaZXDu0+kdfetH1IXFAmOg8yVqX3pkb/UiUZCmvk5hpnqRKMpSX8/ZB28vUy/WkT3LRycYTOrFpChLzXpE9lYvijVxZiOKc9Tnd76n0jz1q6VQvUia/B3dXEr5J97ic46ugszyjIa1qGGf8Gtjs6ivpdGVd3EERKvn3j8KOo1RAzLHhS4jr4ScIis6nXr9O5VdRJGlDF9TC/+p6g3172Yy+UJUb/VWH2WlaoapMF0NWv0j1YxgXTNddrv6WGcAmZmonszAmPKi9fZDXGu5/CPUW6dRdW9nHYOTRduSefTbPdgd8ZxeB3YFft2fyp2j4uv+enVwIMU1gxIT7EP3KH+OpBUA0sUjWhcJUNoic5C6ImlzrUqq91brQoI71P+xzu6nOr+W3nFxj6z/a1Vmd3zKTtsHafvVoEIrgAxUL0B2m3pxK80rD8IK0sEvTK1XCO+mfro2+auF0F5m9TGWAjXYsxaVdyfVoW7GWUPQOdyP3GJ19dkjaQUMjAs+//fbWhi91e7J4LiGPV6vL/+9ih/TuG1rgB93ncWuwJCOIcy5tCvH0gt4/ueDLNnXuAGK1WbncJr6++PMoACM7R6hBSiSQRGtiQQo4sKl16ujqsK6QO9rGve5fYIb9LAjjgtMj+gAcoutZB4t5Uhq/oUVoLQxzqDziat6MzAumO5RATz/80G2nsgmI7+UiADvWp6hbo5nFGIpsxPgbSQupDwQGds9kg/WJhFgNhLqJyMARevRuGPchBDn5bDjYtY9KoDuUWpRtvNTsWh9sgpKySxQJ0jrHuUPQPtgHwbEBqEosOxAWqO91oEUdeK3Xu0C0evLu58u6hLG/Zd25YVr+6GTOW1EKyIBihAexBmM9IwOoGe0I0BpyUJZcV6cP88Oob4udUQT+6rdmkv3pzb4uUusNoos5TMI7z/jWiDrpNfrmHt5D64eENPg1xKiJUiAIoSHsNsVrYtHMihtw5EKGbGKJvVRA5QNRzPJLar/Ojx7T+dy8csrGfmPFWw4po6Cq1wgK0RrJwGKEC3Ablf4dMMJ9p8tX4/lVHYRJVY73kY9HcP8tItaRn6pNo+FaF0OO4pTndkwp84R/vSICqDMrrDiUP26eVYdTuem9zeSnl9KXkkZt3+8hR93nSkPUGIkQBFtgwQoQrSAlYfTeep/+7nr021YbeokZM5MSbcofwx6HX7eRuJC1XkypJundTqcqgYN3SsFKFDezbNkX927eb7elszMT7dRZLExqmsYV/SLxmpTeODLXeQUWTHqdXSN9G+cxgvRwiRAEaIF7DilzsqakluirZPirjugh7Obx3GhE+dn56lzjHtlJasO12PW4gZSFEUb3ls5gwIw2RGgrDmSQX6JleUH0pjx4SYmvr6G0+eKqhz/1dZTPPLNHmx2hakDY/jkjuG8PX0wd47qpB3TNdIfs5eb9ZiEaIUkQBGiBew5Xd618/6a4yiKwiHnEOOKAYqzUNZxoRPn5/PNpziRVcRXjrVpmtKZnGIKSsvwMujo5GaCtJ7RAXQM86W0zM7YV1Zx13+2sf5oFofT8nlxySGXY3OKLPzjF3XbXaPjee3GgZiMevR6HU9N6cPfr+yFUa9rkunzhWgpEqAI0cwURdECFJ1OLW7ccCxLy6D0qPBp25lNOSKFso1ix0k1c9UcXWbOn1nncH9Mxqr/anU6nVYsm11oIcBs5JYRHdDpYPGeFLafzNaO/deKRHKLrfSMDuCxK3q5DCMGuGtMZ/Y8fTl/ubwOC0IK0UrIRG01+HV/KisOpvH01X1afqpx0Wacyi4it9iKyaBn2pD2fLElmXdWHiUpU13csGKA0jNaLXg8kpqPoigyj8V5yC60cNxxjk9kFVJitTVpd8jhVDXr1cNN947TPWO7kFNkpVe7AG4YGoeftxGbTeGrbck8u/gg3997ESeyCvls40kAHr+yFwa9+98B+R8l2hrJoNTg+Z8P8PW203y7/XRLN0W0Ic7sSa92AfxpbBd0OthwLIsyu0KA2Uh0YPkClPHhfhj1OvJLyzibW9JSTW4TdjrqfkBdC+doetN2mznrhmoKUEL9TLx0fX/uGBWPn7caYPxlYnd8TQZ2J+fw056zzFtyiDK7wqU9IxnTLaLa5xKirZEApRrpeSUkZ6ur09anyl6I2uw5nQNA/9hgOob5MbF3+VpEPaMDXLIkJqOeLhHqqAwplD0/20+ec/m+qbt5nHVDPaKqD1DciQwwc9+4LgA8+eN+lh1Iw6DX8X9X9Gz0NgrhySRAqcaOCp+2NidlyzwUTSgtr4R/rz7mMitmW+bMoPSLDQLg7os7a/sqT+gF5UNUD8lQ4/PiDFCCfNRFG5uyrsdqs3MsvfYunurcNaYzMUFmcovVSdxmjOhA18j6P48QrZkEKNWo+GnLZldY3ohrZghXLy09xLwlh3j796Mt3ZQmZ7Mr7DujBigDYoMBdZXbIR1DAOjXPqjKY/o6Jt56b9UxNh/Pap6GtjFWm10LDK8d1B5o2oDvZFYhFpsdX5OB9sE+9X682cvAo5PVjEmA2ciDE7o3dhOF8HgSoFTDGaB0iVCHB9a0ZoalzM5dn27jxvc2UmK1NUv7WkJOkYWr317H68uONOrzbklSRyv8sjcFRVEa9bk9TVJmAYUWGz5eBu13C+DdGYN5bmpfpg2JrfKYW0Z0YEjHEPJKyrj1oy3avClZBaX8a3kio1/6nQe+3Nmmf/fO16GUfIqtNgLNRq7s3w5ovAyKoig8/b/9XP32OpKz1flLnAWy3aMCqoy4qaurB8Tw2o0D+GzmCFmFWFyQJEBxo7TMxj7Hwlt/m9wLgHWJmeSXuF8z4+Wlh1h+MI0tJ7IbdXVST/P7oXT2nM7lw7XHtdlPz1d6Xgmnz6m1Pieyitr8ujO7k9VP8X3bB2I0lP/5RQWauXVkR7wMVf8kA8xefH7XCC7vHYXFZmfOFzuYuWArCS/+zuvLj3D6XDE/7jrLjA83c64eXZEZ+aVV6jIaIquglE0entlxDtkd3DFE63JJyS2pcR2cgtIy1iZm1Bo0f7L+BAs2nGDP6VzmfLETS5m9vEC2nvUnFel0Oq4bHMvAuOAGP4cQrZkEKG7sO5OHxWYnzM/EhF6RdI7ww2Kz8/uhqrNP/rY/lQ/XJWnfL2rDI36cKfJCi03rpjhfFWt9AJa28YLkvY7z1q99cL0eZ/YyMP8PQ7gtoSOKAisOpWMpszMgNoj/u6IngWYj20+eY9p7G7RP8TWxlNm56d8bmTZ/Q5WfQX3klVi5bv4Gbn5/U7PMztpQ20/lADCkQwiBZi9igtSRUkfS3QfEiqJw73+3c+tHW/jvppPVPu+u5BzmLTkIgJdBx+7kHF5cckgLtN1NcS+EqBsJUNxwTuY0uGOIy2RKv1bq5knOLuKvi3YDcGU/NW28LjGD1BqGg5bZ7Dz9v/18uPZ4UzS9STlHnwBsOp5d/YH14PwEH+6vprDbeoCy23EOB8RVrTWpjUGv45mr+/Dc1L5cPySWb/6UwA+zRzHr4i58c+9FxASZOZ5RyHXzN2hzqlTnPxtPaHOC/La/YVk/RVH427d7OJmlBkRfbmn62VkbquLfNFSYobeaOpTfD6WzNlFdJfj9tcex2atmUXKLrMz+fAdWm8LkvtG8O2MIAB+vT2LNEfWx7qa4F0LUjQQobjg/UToLFyf3VYOPlYcyKLao/fyWMjtzvthJXkkZA+KCef2mgQzvFIpdge92Vp9FWXk4gwUbTvD8zwfP65Nrcyuz2dl/tnyYa31T+lab3W0XmTNAuW9cV4x6HYdS82u9uLZWVpudA45z6K4Yti50Oh23juzIqzcMYGinUG1IcveoAL67bxQ9owPIyC/lqf/tr/Y5zhVaeHNFovb96iMZDWrLZ5tO8sveVG3isBWH0jxytFtqbglncorR62CAo7ukew0BitVm54VfDmrfJ2cXV/lwoigKf/1mN2dyiukQ6stL1/fnst5R3D0mHoBiRz2Qu1FZQoi6kQClEkVR2HbSNUDp2z6Q9sE+FFtt/HYglS+2nOKKN9eyOzmHQLORd24ZhMmo53pHgeM3209X22/9zfbyT5nPLz7QaopCj6QVUFpmx1nvt+1Edr3qUOYs3MHwF1ZwtEJKvWKtz6U9I0noEga03SzKkbR8SsvsBJiNbtdmOV/RQWb+fesQvAw61hzJqLbL5V8rEskrKaNzhB86HRxMySMtr36TwO09ncvzi9WL+P9d0Yt+7YOw2hR+3HXmvN9HY3N+EOgZHYi/YzI0bRFGNzVPCzef4nhGIWF+Ju64qBNQvl6S00frklh2IA2TQc+7MwYTaFaHLj8yqSeDOgQDEOZnIiLAu6nelhBtngQolZw+V0xGfilGvU77lKvT6ZjkWHn0gS938dh3ezmaXoC/t5E3pw8iNsQXgCv6t8PHy8DxjEJ2JudUee6sglJWHFQvGiajnh2ncljsGJHhtPpIBt/vrD7AaWp5JVbeXXWUlNxil+17z+QAMDw+lGBfLwotNq2eojYnswr5dX8axVYbn28+pW2vWOvTMcxXO8dL96VU91St2l7n/Cftgxo8sqM2HcP8tIvqCz8fpKxSEHk0vYDPHDUVz13Tl/6Ooc61ZVF+25/KMz/t125/+u92LDY7l/WO4o+jOrkE556mvHsnWNtWsYun4t9abpGVN5aro9Qeuqw7sy/pismoZ1dyjpbt23nqnLaY3xNX9aJvhWyYl0HP27cMZkjHEP44Or5J35cQbZ0EKJU4P231aR/ksk6Hc2giQPtgH/5+ZS82PnYp43pEatv9vY1M7qdeZN39o/5x11nK7Ar9Y4OYc0lXAF5ccogSqw1FUfjX8kRu/3gLD321m18bWBdwvp76cT8vLz3Msz8dcNm+23FxHRAXzIj4UKDu3TwVlwr4cddZLGXqRbNyrc9lvaPQ6dTXOpNT7Pa5WjPnOXQGBU1lzqXdCPH1IjG9gC8qrdr74pKD2OwKE3pFMqprOGO7q1On1xSg5BZZue/zHXyy/oR2O5NTTPtgH169fgA6nY6rB8RgMujZfzZP68byFNsrddkCdInwx6DXkVtsJT2/VNv+9spEzhVZ6Rbpz83D4ogI8OY6x7wp7685Tk6RhTkLd1JmV7iyXzv+MLJjlddrH+zDt/dexGzH37gQomFkdalKnBfNIR1CXLYP7hDCuzMGo9fpmNAr0mWIaEXXD4nlux1n+Gn3WZ68qrdLkOMMWq4fEssNQ+L4YsspzuQU8+Ha45zJKeaLCkWG85Yc5NKekW5XQT1fn208wftrj/P6jQMZ2ilU274rOYfvd6op+pWH0ym22PAxqe13fvrv3z6YdoFmft2fxqbj2dw3rubXstsVvt2hPqdOpy7YtvJwOhP7RGvB4GDHuY4MMDOsYyhbTmTz675Uj/wEmpxdxB8+2syYbuE8NaWP22HBTmsTM7j/i50UOeuWHNmM/rENqz+pqyAfLx66rDtP/rif15cd4ZqBMZwrtPDh2iSWH0zHqNfx2BXq8Pmx3SN4c0Ui6xIzKbPZ3f5erzuaSZldoV2QmesGqxdrk8HADUNjCfJVuzZC/ExM6B3JL3tT+XbHaXrH9D6v95BXYmX6+5tc1ssxGfRc3ieamaPj6e2YvK42JdbyEWdDOpT/rpu9DHQK8+VYRiGHU/OJCjRzND2fBRtOAOqifM5zcdeYeL7cmsyyg2nc/Z9tnMkppmOYL/Om9ZPFG4VoQpJBqcT5aatiOtjpin7tmNQ3utrgBGBkfBjtg33ILylzKazbfzaXAyl5mAx6pvSPwcdk4JFJ6tLor/52hC+2JKPXweNX9CIiwJuTWUX8Z+OJRn1vAIWlZbzy62GSs4uZvXAHmQXqp0dFUXh+cXnWpMRqZ/URtTuqtMzGIce8Dv1jgxjpqBWpSx3KpuNZnMkpJsBs5PaETkB5jU7lWh+Aic5unhomxmtJX21N5mRWEf/ddIqZn26joNT99PyKovDy0sOcK7JSWmantMyOoqjBgzMD1ZSmD+9Alwg/sgstTH17PeNeXaV17dx9cWdtfZ8BsUEE+XiRW2zVMjyVOX8PrujXjocn9uThiT15YEI3YirNkOrs5vlh55nznifnnZVH2X82Tzt3pWV28kvL+HbHaa54cy23fLCJtYm1F/cuP5iG1aYQE2QmLtS1vRW7eYotNmZ/vhOrTeGSHhEumdGukQFc2jMSRYGtJ85hMuh555byuhMhRNOQAKWCIksZB1PUormKF8360Ot12mygLy45pM1W+e12NYswoXckIY5ZIa8Z0F77NO1t1PPeH4Zw98Wd+evl6rTW/1qR2OijIr7elkxeiXpRTcsr5aGvdmG3KyzZl8q2k+cwe+mZMiAGKC9WPZSSj9WmEOLrRWyID90jAwjx9aKoDnUozqzRlAExzBjRAYCVh9LZfTpXq/WpmFGY2CcKgK0nspt8tdmGqBg4rTmSwc3vbyQ9v2qB6eakbPaeycXbqOfXBy9m3aOXsO7RS9j02HjC/Ju+cNLLoOfxK9UsyfHMQhQFxvWI4L8zR/DIxB7acUaDntHdwgH33TyKomjbnd1B1bm4WwTh/t5kFVpY6WbOoLpKzi7ik3UnAPjXzQO1c7foTwlc1b8dBr2ODceyuPWjLby5IrHGei3n7991g2OrZDu6VyiUffLHfRxOyyciwJuXrx9Q5XnuGlOezXtiSm+XuhMhRNOQAKWC3cm52Ozqp612QfVfP8Ppjos60TnCj5TcEq6fv4H1RzP5wTG64foKU5nr9Tr+dfMgbh4Wx1f3JHC5Y76V64fE0atdIPklZS7DQSuy2uy88PMB/r36WJ0Lastsdj5en6S10eylZ21iJq8vP6JNNnXPxV244yK1X33FwXRKy2wuq+/qdDr0eh0j4tUsSk11KPklVn5xFLxePySWblEBDIgLpsyuaMNg+8QEunSDxYb4MqFXFIoC8yoM9ayL9UczmbNwh5btaWxH0/M5ml6Al0HHf2eOIMzPxL4zeVz37oYqNTMfrFHnuZk2JJYe0QHEhvgSG+KrdZk1h0t6RPLwxB7cOaoTy+dezII7hzO6W3iVC3VNdSiH0/JJyyvF7KVneC2ZH6NBr3UBvbf6GMczqg8wy2x2ftp9lrs+3eZSowRqYG+x2RndNZyrB8Ro525Yp1DevmUwax65RAt2X1t2hP/7fm+VYmBQF6Fc43hP7pYQcM5R8sveFBZtP41epwZE7kbeJHQOY+5l3Xl4Yg/+4HhtIUTTkgClAmdNxKAGZk+cQv1MfPuni7T1U2Z8uJnsQgsRAd5c3M31U2h8uB8vTuvvMp21Qa/j745Pv59tOuk2k/DKr4f5YG0S85Yccqldqcmv+9NIzi4mxNeLRyf15Llr+gLw1u9HSc4uJjLAm3vGdmZQXAiRAd7kl5ax4ViWNoNsxUzHyM7qxWrjseoDlF/2plBitdMlwo9BjvfnDNB2O0Y5DXZzrh+7oidGvY4Vh9JZ55gsqzaLtiVz28dbWLwnhZkLttU4hbk7ucVWEtPytduprKIqgZ8zozSqaziju4Xz7b0X0THMl9PnipmzcIdW/Hs0vYAVh9LR6WBmC9bR6HQ6Zl/Slaem9KlxJVxngLLndA5ZBaUu+1YfVi/wCZ3DXALJ6tw4NA4vg44dp3IY/9pq7vp0K2uOZGjn9XBqPh+sOc7YV1bx5y92svxgGn9ZtJvXfjusdvudyObnvSnodfD3q3q5rfFoH+zDC9f247mpfdHr4Istydzz2fYqq2F/t+MMdgWGdgwhPrzqsG5nBsVZI/TghO5c1CXc7fvS6XTcP74bsy/pKnUnQjQTCVAquHlYHP++dYhWK3E+QvxMfH7XCK3LAuC6Qe1rrF+paFTXcCb0isRmV3joq10uF47lB9J4f035TLRP/7Sf/Wdr7mpRFIUPHLPX3jqyIz4mAzcMjWPa4PJPlg9P7IGvyYher2OiI5uzdG9qhQAlWDu2vA7lXLX1BuVFwXHaP/Wr+6ujPZzcdaV1ifDXRkc8//MBt7N4Vnxfb65I5OFv9mCzK5iMes7kFPPXb3bXObOUkV/K6Jd+57LX12i3i19Z6XKOobx7Z7KjTqZTuB//nTmCALORnadyeOVXdejpR+vUx43vGaXVeniyqEAzPaMDUBS1ILaiunbvOHWN9OfLWSMZ76jZWH4wnds+3qKd14lvrOGFXw5yJqeYMD8TVzhGvb35+1Ee+WYPz/2sZs1uGhZHz+iaC2FvHdmR9/4wBG+jnhWH0rnns+3a74qiKNqcQzcMrZo9AXVItrejCH1013AZdSOEh5EApYIwf28m9omuNZVdV2YvA+/OGMI9YzvTMzqAWxOqDkmsyeNX9ibY14u9Z3KZNn8DJ7MKOX2uiL84pte/46JOjO8Zqc5qu3BntYsZgjpj667kHExGPbdWCMCem9qHsd0juLJ/O5dgxTknya8HUkl0TK5WMYPirEMpttq0NHrl19t64hx6Xfny9gBBvl5cViFoq67W54Hx3Qg0GzmUmu8yuV1F6fklPPLNHl5zrK5877gufPOnBEwGPcsOpPFRhTWSavL9ztPkl5RhMuoJ9TMR7BiZ8q8ViaQ7JjBLzi5i35k89DqY0Ku8/XGhvrziqFn4YG0SX245pY1amnVx5zq9vidwFoU6MyagFlRvPaEuaTC2QtFobYZ0DOWjO4bx+1/GcuvIjkQFehPqZ9JufdsH8vK0/qz/26W8O2MI867rh16nrmO1OzkHP5OBhy7rXqfXurxPNAvvHomPl4G1iZm8/ftRQB2RdiyjELOXniv6tXP7WINex11j4hkeH8rrNw3UZsQVQngGGWbcxAx6HY9N7sVjjlWR6yM+3I9v/nQRd3yyhRNZRVz37gYiA83kFlsdi8T1orC0jCvfXEtSZiGPfbeXt6YPcpuCdmYDrh3Y3qWP3ddk5NM/Dq9yvHNCthxHV0lUoDdRgWZtv16vY3S3CH7afZaZn25jdNdwtTtDBx+tTdI+iV/cPYLoILPLc984NI6f96TQIdS32lqfED8T94/vxvM/H+TV345wZf8YbRbQgyl5fLQuif/tOovFZkeng2eu7sNtjsDr71f14skf9/PikkMM6RjCoA7Vd9mpn7TVTM/TU/pwy4gOKIrCdfM3sPNUDq/+dpiXrx+gjcgaER9Wpch1Ut9o/jgqno/XJ/G37/YC6uiYYZ3Or6uwOY3rEcF7q4+xeG8Kd43pTO+YQDYcy8JqU+gQ6kunMN96P2fnCH+em9qX56b2rfG46cM7EBngzeyFOyix2rnvkq5EBphrfExFQzqG8PzUvvxl0W7eWHGEYZ1C+HmvWvs0uW87AmoYbfPwxJ51fh0hRPOSAMXDdY3057v7LuLOT7ay/2weWYUWAs1G3r5lMCajHpPRxFu3DOamf29k8Z4UfjuQhrvPgaWO+oiKoxFq4mXQc1mvKG11Zner7z5xVS/HCKAU1h3NdOke0OvUi8OTU6rOhzG2ewRvTR/kti6gotsSOvHfTSc5kVXEoGd/Q+8IvJzvBWBQh2DmXtadMRVqe24d2ZHNx9Vahrv/s537xnXhxmFxWoBT0d4zuRxJK8DbqOeqAeonbZ1OxxNX9ea6dzewaPtpbkvoxBJH/Ykzs1TZ3yb3ZPupc1ptzd0Xd25VtQoj4kO5tGckvx9KZ/bCHfz059Ha8OKx3SOa/L2M7xXFT3NGsys5h+sGu++Sqcm0IbFsTsri622nuf/LXZSWqXUlN7gpjhVCtA7SxdMKRAaY+eqeBMb3jMTspeefNw4kLrT8E+2QjiE8OaU3Rr0OS4V5IyreAK7q345u9Vi8rOLFeICbycUiA8y8M2Mwqx++hLtGx+PvbcTf28hdo+NZ/fAlvDNjsEvWpaIpA2JqHappMup5akofdDqw2hTtveh16urR3957Ed/fN8olOAE1wJg3rR9dI/3JLCjl2cUHSPjHCv7xy8EqRaDO7MmkvtEu81oM7hDClAExKAr87bs92jTnztocd219e/ogIgO86d0uUFsBu7XQ6XT884YBtAsya9k4Z/3JuB51qz85X92iArhhaFyDu1qeubovPaICyCwoJb+kjPbBPozsHNbIrRRCNBed0lpWq6sgLy+PoKAgcnNzCQys24ySbUWJ1VbtaIpzhRYKLe4nDtPrdLQLMtfrk3CJ1cbQ55dTUFrGgjuHuUxe5Y5zqGddC4HrKqfI4jIhWoC3lzaDaU2KLTa+3XGaj9clcdyxQnLP6AB+mD0Ks5eB0jIbw19YQW6xlc9mDq8S6CRnFzH+tdXa6JxBHYL5/r5RNb5midWGUa9r9HPQXLafzObGf2/Sik1NBj07n7wMPzfZJ090NL2Aq99eR5HFxv2XdmXu5T1qf5AQotnU5/rdOv+LXsBqGuoZ4mfS5oyofIsJ9ql3mt7sZeDl6/tzz9jOVS7e7hgN+ia5MAf7ur6vugQnAD4mA38Y2ZHlc8fy8R1DCfc3cSg1n2d+UudgWXEwndxiK+2CzG6Hl8aF+roME55cTfdORWYvQ6sNTkAtcK04kduw+JBWE5yA2iX671uHcP2QWI9cKkEIUXet9z+paBZX9GvHY5N7teoRDnq9jkt7RvHGTYPQOebN+GHnmQqzjLav9v3dN64LUYHemIx6Jvd1Pxqkrbl7TGcm9FKzZZNa4Xse0y2CV28YQLCvqaWbIoQ4D9LFIy4ory07wpsrEvE1GSgts2OzK/z+l7F0rmG+kvS8EvJKyuga6flzmjQWq83O7uQcBncIQd+Kg1MhhGeRLh4hqvHA+G4kdA6jyGLDZlcY0jGkxuAEIDLQfEEFJ6CO4hraKVSCEyFEi5EARVxQDHod/5o+kHDHXCYyDFUIITxTiwYo77zzDp06dcJsNjNixAi2bNnSks0RF4jIADNfzhrJc1P7csPQuJZujhBCCDdaLED56quvmDt3Lk899RQ7duxgwIABTJw4kfT0hi/TLkRddY3059aRHVt18a8QQrRlLRagvPbaa9x9993ceeed9O7dm/feew9fX18+/vjjlmqSEEIIITxEiwQoFouF7du3M2HChPKG6PVMmDCBjRs3Vjm+tLSUvLw8l5sQQggh2q4WCVAyMzOx2WxERUW5bI+KiiI1NbXK8fPmzSMoKEi7xcVJ3YAQQgjRlrWKUTyPPfYYubm52i05ObmlmySEEEKIJtQic1iHh4djMBhIS0tz2Z6WlkZ0dNXpxL29vfH29q6yXQghhBBtU4tkUEwmE0OGDGHFihXaNrvdzooVK0hISGiJJgkhhBDCg7TYKmBz587l9ttvZ+jQoQwfPpw33niDwsJC7rzzzpZqkhBCCCE8RIsFKDfddBMZGRk8+eSTpKamMnDgQJYuXVqlcFYIIYQQFx5ZLFAIIYQQzUIWCxRCCCFEqyYBihBCCCE8jgQoQgghhPA4EqAIIYQQwuO02Cie8+Gs65U1eYQQQojWw3ndrsv4nFYZoOTn5wPImjxCCCFEK5Sfn09QUFCNx7TKYcZ2u52zZ88SEBCATqdr1OfOy8sjLi6O5ORkGcLshpyfmsn5qZmcn5rJ+amZnJ/aefo5UhSF/Px8YmJi0OtrrjJplRkUvV5PbGxsk75GYGCgR/5wPYWcn5rJ+amZnJ+ayfmpmZyf2nnyOaotc+IkRbJCCCGE8DgSoAghhBDC40iAUom3tzdPPfUU3t7eLd0UjyTnp2Zyfmom56dmcn5qJuendm3pHLXKIlkhhBBCtG2SQRFCCCGEx5EARQghhBAeRwIUIYQQQngcCVCEEEII4XEkQKngnXfeoVOnTpjNZkaMGMGWLVtaukktYt68eQwbNoyAgAAiIyOZOnUqhw8fdjmmpKSE2bNnExYWhr+/P9OmTSMtLa2FWtyyXnzxRXQ6HQ8++KC27UI/P2fOnOEPf/gDYWFh+Pj40K9fP7Zt26btVxSFJ598knbt2uHj48OECRNITExswRY3H5vNxhNPPEF8fDw+Pj506dKF5557zmVtkgvt/KxZs4YpU6YQExODTqfjhx9+cNlfl/ORnZ3NjBkzCAwMJDg4mJkzZ1JQUNCM76Lp1HR+rFYrjz76KP369cPPz4+YmBhuu+02zp496/IcrfH8SIDi8NVXXzF37lyeeuopduzYwYABA5g4cSLp6ekt3bRmt3r1ambPns2mTZtYtmwZVquVyy+/nMLCQu2Yhx56iJ9++olFixaxevVqzp49y3XXXdeCrW4ZW7du5d///jf9+/d32X4hn59z584xatQovLy8WLJkCQcOHOCf//wnISEh2jEvv/wyb775Ju+99x6bN2/Gz8+PiRMnUlJS0oItbx4vvfQS8+fP5+233+bgwYO89NJLvPzyy7z11lvaMRfa+SksLGTAgAG88847bvfX5XzMmDGD/fv3s2zZMhYvXsyaNWuYNWtWc72FJlXT+SkqKmLHjh088cQT7Nixg++++47Dhw9z9dVXuxzXKs+PIhRFUZThw4crs2fP1r632WxKTEyMMm/evBZslWdIT09XAGX16tWKoihKTk6O4uXlpSxatEg75uDBgwqgbNy4saWa2ezy8/OVbt26KcuWLVPGjh2rPPDAA4qiyPl59NFHldGjR1e73263K9HR0corr7yibcvJyVG8vb2VL774ojma2KKuvPJK5Y9//KPLtuuuu06ZMWOGoihyfgDl+++/176vy/k4cOCAAihbt27VjlmyZImi0+mUM2fONFvbm0Pl8+POli1bFEA5efKkoiit9/xIBgWwWCxs376dCRMmaNv0ej0TJkxg48aNLdgyz5CbmwtAaGgoANu3b8dqtbqcr549e9KhQ4cL6nzNnj2bK6+80uU8gJyf//3vfwwdOpQbbriByMhIBg0axAcffKDtT0pKIjU11eX8BAUFMWLEiAvi/Fx00UWsWLGCI0eOALB7927WrVvH5MmTATk/ldXlfGzcuJHg4GCGDh2qHTNhwgT0ej2bN29u9ja3tNzcXHQ6HcHBwUDrPT+tcrHAxpaZmYnNZiMqKsple1RUFIcOHWqhVnkGu93Ogw8+yKhRo+jbty8AqampmEwm7ZffKSoqitTU1BZoZfP78ssv2bFjB1u3bq2y70I/P8ePH2f+/PnMnTuX//u//2Pr1q3cf//9mEwmbr/9du0cuPt7uxDOz9/+9jfy8vLo2bMnBoMBm83GCy+8wIwZMwAu+PNTWV3OR2pqKpGRkS77jUYjoaGhF9w5Kykp4dFHH2X69OnaYoGt9fxIgCJqNHv2bPbt28e6detauikeIzk5mQceeIBly5ZhNptbujkex263M3ToUP7xj38AMGjQIPbt28d7773H7bff3sKta3lff/01n3/+OQsXLqRPnz7s2rWLBx98kJiYGDk/4rxYrVZuvPFGFEVh/vz5Ld2c8yZdPEB4eDgGg6HKKIu0tDSio6NbqFUtb86cOSxevJiVK1cSGxurbY+OjsZisZCTk+Ny/IVyvrZv3056ejqDBw/GaDRiNBpZvXo1b775JkajkaioqAv6/LRr147evXu7bOvVqxenTp0C0M7Bhfr39vDDD/O3v/2Nm2++mX79+nHrrbfy0EMPMW/ePEDOT2V1OR/R0dFVBjSUlZWRnZ19wZwzZ3By8uRJli1bpmVPoPWeHwlQAJPJxJAhQ1ixYoW2zW63s2LFChISElqwZS1DURTmzJnD999/z++//058fLzL/iFDhuDl5eVyvg4fPsypU6cuiPM1fvx49u7dy65du7Tb0KFDmTFjhnb/Qj4/o0aNqjIs/ciRI3Ts2BGA+Ph4oqOjXc5PXl4emzdvviDOT1FREXq9679eg8GA3W4H5PxUVpfzkZCQQE5ODtu3b9eO+f3337Hb7YwYMaLZ29zcnMFJYmIiy5cvJywszGV/qz0/LV2l6ym+/PJLxdvbW1mwYIFy4MABZdasWUpwcLCSmpra0k1rdvfee68SFBSkrFq1SklJSdFuRUVF2jF/+tOflA4dOii///67sm3bNiUhIUFJSEhowVa3rIqjeBTlwj4/W7ZsUYxGo/LCCy8oiYmJyueff674+voq//3vf7VjXnzxRSU4OFj58ccflT179ijXXHONEh8frxQXF7dgy5vH7bffrrRv315ZvHixkpSUpHz33XdKeHi48sgjj2jHXGjnJz8/X9m5c6eyc+dOBVBee+01ZefOndoolLqcj0mTJimDBg1SNm/erKxbt07p1q2bMn369JZ6S42qpvNjsViUq6++WomNjVV27drl8j+7tLRUe47WeH4kQKngrbfeUjp06KCYTCZl+PDhyqZNm1q6SS0CcHv75JNPtGOKi4uV++67TwkJCVF8fX2Va6+9VklJSWm5RrewygHKhX5+fvrpJ6Vv376Kt7e30rNnT+X999932W+325UnnnhCiYqKUry9vZXx48crhw8fbqHWNq+8vDzlgQceUDp06KCYzWalc+fOyuOPP+5yMbnQzs/KlSvd/s+5/fbbFUWp2/nIyspSpk+frvj7+yuBgYHKnXfeqeTn57fAu2l8NZ2fpKSkav9nr1y5UnuO1nh+dIpSYfpCIYQQQggPIDUoQgghhPA4EqAIIYQQwuNIgCKEEEIIjyMBihBCCCE8jgQoQgghhPA4EqAIIYQQwuNIgCKEEEIIjyMBihBCCCE8jgQoQgghhPA4EqAIIYQQwuNIgCKEEEIIjyMBihBCCCE8zv8DItktIX5dAmQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model=model, monitor=monitor)\n",
    "inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=y_scaler, rnn = True)\n",
    "    \n",
    "# LSTM\n",
    "plot_predictions(inv_y_lstm, inv_yhat_lstm, model_name = 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a13459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
