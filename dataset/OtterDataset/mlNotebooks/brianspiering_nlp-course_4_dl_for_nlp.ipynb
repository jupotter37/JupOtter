{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DL for NLP\n",
    "-----\n",
    "\n",
    "<center><img src=\"http://rutumulkar.com/public/images/blog/nlp-ml.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Identify when to use different Deep Learning architecture to solve NLP tasks\n",
    "- Compare and contrast CNN, RNN, and LSTM\n",
    "- Explain the role that attention has in NLP tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DL makes ML pipelines simplier\n",
    "------\n",
    "\n",
    "<center><img src=\"http://adilmoujahid.com/images/traditional-ml-deep-learning-2.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can Recurrent Neural Network (RNN) be used for text classification?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes!\n",
    "\n",
    "The input is text document.\n",
    "\n",
    "We process it sequentially, constructing a state representation.\n",
    "\n",
    "At the end, we choose the category closest to the current state representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can Multi Layer Perception (MLP) be used for text classification?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes! \n",
    "\n",
    "Each token is weighted towards a category.\n",
    "\n",
    "Very similar to a Bag-of-Words model in traditional Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can Convolutional Neural Network (CNN) be used for text classification?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes!\n",
    "\n",
    "It is very similar to a ngram model in traditional Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From RNN to CNNs\n",
    "-------\n",
    "\n",
    "RNN has to use previous word (in order).\n",
    "\n",
    "Example:  \n",
    "> the country of my birth\n",
    "\n",
    "CNN can learn weights for each n-gram independently:\n",
    "> the country | country of | of my |  my  birth |    \n",
    "the country of | country  of  my |  of  my  birth |   \n",
    "the country of  my |  country of  my  birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CNN  Architecture for NLP\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/cnn.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/cnn_flat.png\" width=\"45%\"/></center>\n",
    "\n",
    "The 1st layer embeds words into low-dimensional vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/cnn_flat.png\" width=\"45%\"/></center>\n",
    "\n",
    "The next layer performs convolutions over the embedded word vectors using multiple filter sizes. \n",
    "\n",
    "For example, sliding over 3, 4 or 5 words at a time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/cnn_flat.png\" width=\"45%\"/></center>\n",
    "\n",
    "Next, the result of the convolutional layer is max-pooled into a long feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/cnn_flat.png\" width=\"45%\"/></center>\n",
    "\n",
    "Create a classification prediction with a softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source with TF code](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Other CNN slides](cnn_example.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the advantages for using a CNN over a RNN for NLP?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Somewhat interpretable. You can exam the weights and see the ngram filters.\n",
    "- CNNs are quicker to train. Fewer parameters.\n",
    "- Simpler. No state.\n",
    "- RNN __have__ to use the previous word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://cs224d.stanford.edu/lectures/CS224d-Lecture13.pdf) & Conversation with Edward Banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "Which NLP tasks would CNN be useful for? Which ones would it be __less__ useful for? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__More Useful__:\n",
    "\n",
    "Classifications tasks (Sentiment Analysis, Spam Detection or Topic Categorization) \n",
    "\n",
    "_Why?_: Classification is high-level combination of word vectors to predict labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Less Useful__:\n",
    "\n",
    "PoS Tagging or Entity Extraction:\n",
    "\n",
    "_Why?_: Convolutions and pooling operations lose information about the local order of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NLP: It's All Question Answering\n",
    "------\n",
    "\n",
    "All of NLP can be reframed as answers to questions\n",
    "\n",
    "<br>\n",
    "<details><summary>\n",
    "Language Modeling\n",
    "</summary>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What is the next word?\n",
    "</details>\n",
    "<br>\n",
    "<details><summary>\n",
    "Word Tagging\n",
    "</summary>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What category does this token belong to?\n",
    "</details>\n",
    "<br>\n",
    "<details><summary>\n",
    "Classification\n",
    "</summary>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What category does this document belong to?\n",
    "</details>\n",
    "<br>\n",
    "<details><summary>\n",
    "Information Retrieval\n",
    "</summary>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What search result do I want?\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Summarization: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What is the gist of this document?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What is the POS of this token?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Translation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What is this sentence in Arabic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to build domain-based Question Answering systems? Attention\n",
    "------\n",
    "\n",
    "<center><img src=\"images/attention.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Source: https://arxiv.org/pdf/1506.07285.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A LSTM that learns to point to the start and end of the answer (dynamic pointing decoder)\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/dpd.png\" width=\"45%\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://arxiv.org/abs/1611.01604)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Everything could just be chatbots__:  \n",
    "-------\n",
    "\n",
    "<center><img src=\"https://tctechcrunch2011.files.wordpress.com/2016/05/robot-customer-service.png?w=738\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "----\n",
    "\n",
    "- DL is \"eating\" NLP.\n",
    "- Choose the right architecture for the problem\n",
    "- RNN is good default\n",
    "- CNN can be applied to NLP where the answer is combination of features.\n",
    "- Question Answering might be the \"killer app\" for DL in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dynamic Coattention Network (DCN): The Promise\n",
    "-----\n",
    "\n",
    "Do __not__ produce a single, static representation of the document without context.\n",
    "\n",
    "Interpret the document differently depending on the question.\n",
    "\n",
    "Use the same corpus for many NLP tasks; In theory, construct a \"universal\" corpus for all NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dynamic Coattention Network (DCN): The Mechanics\n",
    "-----\n",
    "\n",
    "Naive approach: cram as much information about the document as possible, not knowing what the questions will be (similar to the traditional approach of building a static representation).\n",
    "\n",
    "DCN approach: Read the document again for each question, based on the question (building a conditional representation of the document) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dynamic Coattention Network (DCN): Example\n",
    "-----\n",
    "\n",
    "Document:\n",
    "\n",
    "> On Carolina's next possession fullback Mike Tolbert lost a fumble while being tackled by safety Darian Stewart, which linebacker Danny Trevathan recovered on the Broncos 40-yard line. However, the Panthers soon took the ball back when defensive end Kony Ealy tipped a Manning pass to himself and then intercepted it, returning the ball 19 yards to the Panthers 39-yard line with 1:55 left on the clock. \n",
    "\n",
    "Question:\n",
    "\n",
    "> Who recovered Tolbert's fumble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dynamic Coattention Network (DCN): Example\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://metamind.io/static/images/layouts/research/squad-qa-attn.svg\" height=\"500\"/></center>\n",
    "\n",
    "The top row is the first iteration and the prediction position for the start word. The top prediction is the answer starts with \"fullback\" \n",
    "\n",
    "The second from top row denotes is the first iteration and the prediction position for the end word. The top prediction is the answer ends with \"Trevathan\".\n",
    "\n",
    "The subsequent iterations (i = 2, 3) are the next row pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://metamind.io/research/state-of-the-art-deep-learning-model-for-question-answering/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
