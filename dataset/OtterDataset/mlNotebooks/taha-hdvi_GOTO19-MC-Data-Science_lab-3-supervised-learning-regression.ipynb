{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Peformance Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download some data to play with\n",
    "# source: UCI ML Repo\n",
    "!mkdir ./data/cpu_perf\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data > ./data/cpu_perf/machine.data\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.names > ./data/cpu_perf/machine.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat data/cpu_perf/machine.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['vendor', 'model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "path = './data/cpu_perf/machine.data'\n",
    "\n",
    "# this specifies data types for each column to avoid mis-interpretation of data type by Pandas\n",
    "dtype = {\n",
    "    **{i: 'category' for i in columns[:1]},\n",
    "    **{i: int for i in columns[2:]}\n",
    "}\n",
    "\n",
    "df = pd.read_csv(path, names=columns, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first five rows of the DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the size of the dataset? a.k.a. how many rows and columns are in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many vendors are in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many models are in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other relationships you want to look into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data\"></a>\n",
    "## Our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatterplot of `CHMAX` against `ERP`\n",
    "_ = plt.subplots(figsize=(12, 8))\n",
    "_ = plt.scatter(df.CHMAX, df.ERP)\n",
    "_ = plt.xlabel('Maximum Channels in Unit')\n",
    "_ = plt.ylabel('Relative CPU Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Seaborn to create a scatterplot with regression line\n",
    "# sns.lmplot does not allow us to pass in an Axes object.\n",
    "# It creates a FaceGrid object that has the relevant Axes object\n",
    "# as its ax attribute.\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.lmplot(x='CHMAX', y='ERP', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a linear regression model!\n",
    "\n",
    "- **Formula for a line:** $y = mx + b$\n",
    "- **Alternative notation:** $y = \\beta_0 + \\beta_1 * x$\n",
    "- **Our model:** <br>\n",
    "    $\\mbox{CPU_Performance} = \\beta_0 + \\beta_1 * \\mbox{Maximum_Number_of_Channels} + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call $\\beta_0$ the **model intercept** and $\\beta_1$ the **coefficient of `CHMAX`**.\n",
    "\n",
    "We call $\\epsilon$ the **error term**. It accounts for the fact that our points do not lie exactly on a line. Linear regression is designed to be optimal when this noise is normally distributed with constant variance. We ignore it when we use the model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q&A** What would our model predict for `ERP` when `CHMAX` is 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "\n",
    "- Linear regression with one input feature chooses the *line* that \"best fits\" a scatterplot of the target variable against that input feature.\n",
    "- The model intercept tells you what the model would predict if all of the input variables were zero.\n",
    "- The coefficient on a variable tells you how much and in what direction the model's prediction would change if the relevant variable were to increase by 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Linear Regression Models with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we called `sns.lmplot`, `seaborn` created a linear regression model which it then displayed to us.\n",
    "\n",
    "A more typical workflow for creating a linear regression model uses **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scikit-learn](https://scikit-learn.org/) is the most popular Python library for machine learning.\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "- Includes good implementations of a wide range of algorithms.\n",
    "- Provides consistent interface across model types.\n",
    "- Provides excellent documentation.\n",
    "- Large community --> tons of resources for learning and getting questions answered.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- Designed primarily for single-thread, in-memory computing.\n",
    "- Has only basic capabilites for deep learning.\n",
    "- Reflects machine learning rather than statistics mindset: focuses on predictive accuracy on held-out data rather than hypothesis testing, parameter estimation, and model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the LinearRegression model class.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Make an instance of the LinearRegression class.\n",
    "lrg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train the model instance on our data to recreate what we just did in the previous step\n",
    "lrg.fit(df[['CHMAX']], df.ERP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Use the model to make predictions.\n",
    "y_pred = lrg.predict(df[['CHMAX']])\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare fitted values to actual.\n",
    "result = df.ERP.to_frame().assign(predicted=y_pred, error=y_pred-df.ERP)\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to see how accurate our model performs\n",
    "_ = plt.subplots(figsize=(12, 8))\n",
    "_ = plt.scatter(result.ERP, result.predicted)\n",
    "_ = plt.xlabel('Actual Value')\n",
    "_ = plt.ylabel('Predicted Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q&A** What would the plot above look like if our model's predictions were **perfectly accurate**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scikit-learns--step-modeling-pattern\"></a>\n",
    "### scikit-learn's Four-Step Modeling Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the class you plan to use.\n",
    "2. \"Instantiate\" the class. You can specify \"hyperparameters\" at this point.\n",
    "3. Fit the model instance with data. (This step changes the model object in-place.)\n",
    "4. Use the fitted model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Multiple Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using `CHMAX` only:** <br>$\\mbox{ERP} = \\beta_0 +  \\beta_1 * \\mbox{CHMAX} + \\epsilon$\n",
    "- **Using `CHMAX` and `CHMIN`:** <br>$\\mbox{ERP} = \\beta_0 +  \\beta_1 * \\mbox{CHMIN} +  \\beta_2 * \\mbox{CHMAX} + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with two input features chooses the \"plane\" that \"best fits\" a 3D scatterplot of the target variable against those input features.\n",
    "\n",
    "In general, linear regression chooses the \"hyperplane\" that \"best fits\" a scatterplot of the target variable against the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Answer each question below for the second model written out above, in terms of $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\epsilon$ (\"epsilon\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What would our model predict for `ERP` at `CHMIN=0` and `CHMAX=0`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `CHMIN` increases by 5 while `CHMAX` remains the same, how does our model's prediction for `ERP` change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `CHMAX` decreases by 3 while `CHMIN` remains the same, how does our model's prediction for `ERP` change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bonus:** Why does the previous question say \"while `CHMIN` remains the same?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on [Ceteris Paribus](https://www.investopedia.com/terms/c/ceterisparibus.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:** Interpretation of the parameters of a linear regression model does not change as we add more variables, except that each coefficient tells us how the model's prediction would change if the associated variable were to change *while all other variables remained the same*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build another linear regression model, this time using all of our features as input instead of just `temp_celsius`, except `vendor` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model using all columns as given:** \n",
    "\n",
    "$\\mbox{ERP} = \\beta_0 + \\beta_1 * \\mbox{MYCT} + \\beta_2 * \\mbox{MMIN} + \\beta_3 * \\mbox{MMAX} + \\beta_4 * \\mbox{CACH} + \\beta_5 * \\mbox{CHMIN} + \\beta_6 * \\mbox{CHMAX} + \\beta_7 * \\mbox{PRP} + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store a pandas DataFrame with the values of the feature variables (everything except `vendor`, `model` and `ERP`) as a Python variable X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columns[2:-1]]\n",
    "y = df[columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a new instance of the LinearRegression class. Call it lr_all to distinguish it from our last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model instance using our new feature matrix $X$ and the same target variable $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store `lr_all`'s fitted values in a new `predictions` column of the `df` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare predicted values to actual\n",
    "_ = plt.subplots(figsize=(12, 8))\n",
    "_ = plt.scatter(df.ERP, df.predicted)\n",
    "_ = plt.xlabel('Actual Value')\n",
    "_ = plt.ylabel('Predicted Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows how well the model fits the data it was trained on. How well it would predict new data that it wasn't trained on is a further issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fitted values from our DataFrame\n",
    "df.drop('predicted', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the intercept and coefficients of the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print intercept\n",
    "lr_all.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coefficient\n",
    "pd.DataFrame(zip(columns[2:-1], lr_all.coef_), columns=['variable', 'coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the documentation for a LinearRegression model object\n",
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a linear regression selects the coefficients and intercept that minimize the **sum of squared errors** of the fitted values on the training set.\n",
    "\n",
    "![Estimating coefficients](./img/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification:** Minimizing the sum of squared errors maximizes *the probability of the data given the model* (call the **likelihood** of the model on the data) on the assumption that the target variable really is a linear function of the features plus normally distributed noise: $y = \\beta_0 + \\sum \\beta_i x_i + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "![](./assets/400px-Linear_regression.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
    "### Evaluation Metrics for Regression Problems\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Calculate MAE, MSE, and RMSE for the values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example true and predicted response values\n",
    "true = y.copy().values\n",
    "pred = lr_all.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating errors by hand\n",
    "mae = np.average(np.abs(true - pred))\n",
    "mse = np.average(np.power(true-pred, 2))\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare manual work with pre-implemented work\n",
    "from sklearn import metrics\n",
    "\n",
    "print(mae)\n",
    "np.testing.assert_almost_equal(mae, metrics.mean_absolute_error(true, pred))\n",
    "\n",
    "print(mse)\n",
    "np.testing.assert_almost_equal(mse, metrics.mean_squared_error(true, pred))\n",
    "\n",
    "print(rmse)\n",
    "np.testing.assert_almost_equal(rmse, np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, primary because the fact that it is continuous and differentiable makes it easier to work with.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "- MSE/MSE punishes large errors more than MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared** is a metric that directly addresses the question of how well your model does compared to the null model, which usually is just the average of the target variable.\n",
    "\n",
    "$$R^2=1-\\frac{\\mbox{Mean Squared Error}}{\\mbox{Mean Squared Total}}$$\n",
    "\n",
    "\"Mean Squared Total\" is exactly the MSE of the null model, which is essentially the variance of the data.\n",
    "\n",
    "**R-squared properties:**\n",
    "\n",
    "- *Typically* greater than 0 (unless your model is worse than the null model, which can happen) or read more about it in this [article](http://www.fairlynerdy.com/what-is-r-squared/)\n",
    "- Never greater than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/r_squared.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside:** Despite common usage, R-squared *does not tell you how much of the variance in the data the model explains*, at least in the normal sense of \"explains.\"\n",
    "\n",
    "Explanations are usually *causal*, and R-squared *does nothing to distinguish between causation and association*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sklearn .score() method to calculate test-set R-squared\n",
    "?lr_all.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_all.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret,<br>\n",
    "    1) Our model is 95.95% better than the null model (**preferred**)<br>\n",
    "    2) Our model explains 95.95% of variance in the dataset<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to learn next: Regularization\n",
    "\n",
    "Note: This is an advanced concept that is out of scope of the workshop. It is strongly encouraged to learn more about this after you are comfortable with linear regression concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overly complicated models don't generalize well.\n",
    "- One way to reduce model complexity is to use fewer features.\n",
    "- Another way is to incorporate a penalty for coefficient size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-does-regularization-work\"></a>\n",
    "### How Does Regularization Work?\n",
    "\n",
    "For a normal linear regression model, we estimate the coefficients using the least squares criterion, which minimizes the residual sum of squares (RSS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regularized linear regression model, we minimize the sum of MSE and a \"penalty term\" that penalizes coefficient size.\n",
    "\n",
    "**Ridge regression** (or \"L2 regularization\") minimizes: $$\\mbox{MSE} + \\alpha \\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "**Lasso regression** (or \"L1 regularization\") minimizes: $$\\text{Mse} + \\alpha \\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "- $p$ is the number of features.\n",
    "- $\\beta_j$ is a model coefficient.\n",
    "- $\\alpha$ is a tuning parameter:\n",
    "    - A tiny $\\alpha$ imposes no penalty on the coefficient size, and is equivalent to a normal linear regression model.\n",
    "    - Increasing the $\\alpha$ penalizes the coefficients and thus shrinks them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more about Ridge and Lasso Regression, check out this awesome [article](https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net) by DataCamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
