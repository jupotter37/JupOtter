{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f24931-b6a7-4255-97eb-2425f30ba8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv ,find_dotenv\n",
    "from langchain_community.llms.openai import OpenAI\n",
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d49dd97-5f47-43b7-8172-011259a22b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe00abce-0150-413a-baa8-1baa84296799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip uninstall langchain langchain-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee4fdc9-a510-4e7f-93cd-a6a27cf81f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19703132-1b4d-49d7-92cf-f684004964cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cc7219-797f-49f6-810a-aff1a1d4aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain langchain-core langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ca284e-cba1-479e-9e1e-40b419ccafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ecd4aa-4a63-4789-9128-5beaf4a136f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8d8576-3b18-4981-bcf5-caad1730717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517da050-c000-4005-b2ae-5400f0bfe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd4f020d-a105-4ebf-8cd9-85ac0fa15e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005cece-1c8b-456f-ac05-151ff12ca9e3",
   "metadata": {},
   "source": [
    "## LLM WRAPPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3332b7ab-de55-4b4a-b5fd-0bf2865d5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dbe4555-5ce5-4572-bdeb-2a73b012053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "184a3472-e98f-4999-8a76-420df8b33d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(chat_model.get_num_tokens('explain india in one senetence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaaead-5282-4086-a204-9c35e1a2691f",
   "metadata": {},
   "source": [
    "## simple prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cdb12af-7f47-4085-9d38-92e6f6aa544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model.invoke(\"who is prime minister of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9956c93-f2c6-4af1-9cc1-94e90a39b6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of my knowledge cutoff in October 2021, the Prime Minister of India is Narendra Modi.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230a85b-3915-4f2b-83f4-395733ac241d",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "532d72f2-ea1b-4912-bb81-9f980514ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "934277a9-63ba-4388-85d0-09e3e58628f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template='''you are experienced healthcare assistant having knowledge of medicine and its side effects .\n",
    "            Suggest few side effects and Prevention  about the following {medicine}  in {language}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2227f986-cc4c-4bd4-afb6-5eb1b035099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=['medicine','language'],template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11b06811-9c92-453b-996a-4767994cb153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'medicine'], input_types={}, partial_variables={}, template='you are experienced healthcare assistant having knowledge of medicine and its side effects .\\n            Suggest few side effects and Prevention  about the following {medicine}  in {language}')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef568a7d-755d-4464-a096-c894cbdbd16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡•á ‡§ï‡•Å‡§õ ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü‡•ç‡§∏:\n",
      "\n",
      "1. ‡§â‡§≤‡§ù‡§®\n",
      "2. ‡§™‡•á‡§ü ‡§¶‡§∞‡•ç‡§¶\n",
      "3. ‡§ñ‡•Ç‡§® ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§≤‡•á‡§ü‡§≤‡•á‡§ü‡•ç‡§∏ ‡§ï‡•Ä ‡§ï‡§Æ‡•Ä\n",
      "4. ‡§ñ‡•Ç‡§® ‡§Æ‡•á‡§Ç ‡§™‡•Ä‡§≤‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§≤‡§ï‡•ç‡§∑‡§£\n",
      "5. ‡§ñ‡•Ç‡§® ‡§ï‡•Ä ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä\n",
      "6. ‡§§‡•ç‡§µ‡§ö‡§æ ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§è‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‡§ñ‡•Å‡§ú‡§≤‡•Ä, ‡§â‡§ú‡§≤‡§æ ‡§Ø‡§æ ‡§≤‡§æ‡§≤ ‡§§‡•ç‡§µ‡§ö‡§æ\n",
      "7. ‡§§‡•á‡§ú ‡§¶‡§∞‡•ç‡§¶ ‡§Ø‡§æ ‡§ú‡§≤‡§® ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡•Ç‡§§‡•ç‡§∞ ‡§§‡•ç‡§Ø‡§æ‡§ó ‡§ï‡§∞‡§®‡§æ\n",
      "\n",
      "‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡•á ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•Ä ‡§∞‡•ã‡§ï‡§•‡§æ‡§Æ:\n",
      "\n",
      "1. ‡§Ö‡§ó‡§∞ ‡§Ü‡§™‡§ï‡•ã ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§∏‡§Æ‡•ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "2. ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§Æ‡§æ‡§§‡•ç‡§∞‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡§æ‡§§‡•ç‡§∞‡§æ ‡§Æ‡•á‡§Ç ‡§á‡§∏‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§≤‡•Ä‡§µ‡§∞ ‡§ï‡•ã ‡§®‡•Å‡§ï‡§∏‡§æ‡§® ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "3. ‡§Ö‡§®‡•ç‡§Ø ‡§¶‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•ã ‡§ú‡§∞‡•Ç‡§∞ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§\n",
      "4. ‡§Ö‡§ó‡§∞ ‡§Ü‡§™ ‡§ó‡§∞‡•ç‡§≠‡§µ‡§§‡•Ä ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§≤‡•á‡§Ç‡•§\n",
      "5. ‡§∂‡§∞‡§æ‡§¨ ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡•Ä ‡§ñ‡•Å‡§∞‡§æ‡§ï ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§∏‡•Ä‡§Æ‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§Ü‡§™‡§ï‡•á ‡§≤‡•Ä‡§µ‡§∞ ‡§ï‡•ã ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï ‡§®‡•Å‡§ï‡§∏‡§æ‡§® ‡§™‡§π‡•Å‡§Ç‡§ö‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "6. ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á, ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•Ä ‡§§‡•ç‡§µ‡§ö‡§æ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§π‡•à, ‡§§‡•ã ‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§∏‡§≤‡§æ‡§π ‡§≤‡•á‡§Ç‡•§\n",
      "7. ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§¨‡§æ‡§∞-‡§¨‡§æ‡§∞ ‡§Æ‡•Ç‡§§‡•ç‡§∞ ‡§§‡•ç‡§Ø‡§æ‡§ó‡§®‡•á ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à, ‡§§‡•ã ‡§™‡•à‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡§æ ‡§∏‡•á‡§µ‡§® ‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§\n"
     ]
    }
   ],
   "source": [
    "output=chat_model.invoke(prompt.format(medicine='paracetamol',language='Hindi'))\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cd8dd-0dea-4b39-a0d3-67a66c8616f2",
   "metadata": {},
   "source": [
    "## Example -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c7c3490-2639-4391-9680-9869da2b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2=\"\"\"\" You are a expert data scientist , give responses to the following question: {question}. \n",
    " Do not use technical words, give easy to understand responses. Your response should be in {language}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f2ee6fe-2eb0-4582-a31a-a8998e81078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2=PromptTemplate(input_variables=[\"question\",\"language\"],template=template_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cac8175-1e6e-43ea-b9fd-a05931a70b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=chat_model.invoke(prompt_2.format(question=\"what is Large language model\",language=\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2faabfb2-2258-489e-958b-a765b9eafce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is like a big virtual brain that has been trained to understand and generate human language. Imagine if you read a lot of books, web pages, and other texts, you'd learn a lot about how people use words, sentences, and ideas to communicate. A large language model does something similar, it reads a lot of text data, and learns patterns and rules of the language from that data.\\n\\nWhen you ask it a question or give it a prompt, it uses what it has learned to generate a response. It's not truly understanding or thinking like a human, but it's using its knowledge of language patterns to create responses that seem like they come from a human.\\n\\nSo, in simple terms, a large language model is a computer program that has learned from lots of text data and can generate human-like text based on that learning.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7004b-6a7d-4adf-9017-5bf6d6badcc1",
   "metadata": {},
   "source": [
    "## # text to emoji conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "319b0bab-9da5-4a97-9efd-89cae9b49020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to emoji conversion\n",
    "temp_3= \"\"\" Convert the following list of sports to emojis:\n",
    "1. Cricket,\n",
    "2. Football,\n",
    "3. Tennis,\n",
    "4. Cycling,\n",
    "5. Volleyball,\n",
    "6.chess\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8964a878-6304-4598-af05-8f9246b61c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model.invoke(temp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59c1c96c-3625-4ceb-9ce6-489139c8f253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. üèè\n",
      "2. üèà\n",
      "3. üéæ\n",
      "4. üö¥\n",
      "5. üèê\n",
      "6. ‚ôüÔ∏è\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8354f2-1b49-4673-ab5f-17c0695fdc67",
   "metadata": {},
   "source": [
    "## Entity Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a51bd5ed-8f46-4e14-9150-249d9ae72117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "text = \"Elon Musk was born in Pretoria and is the CEO of SpaceX. Chandan working in IBM at Noida\"\n",
    "temp_3 = f\"From the text: '{text}', extract the named entities and categorize them as follows: {{name:, city:, org:}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58b8ad7c-a9a8-4fe2-b0d0-0b8daf38bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3=chat_model.invoke(temp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bab8d9f7-359f-4773-920e-a079f3962b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{name: Elon Musk, Chandan, city: Pretoria, Noida, org: SpaceX, IBM}\n"
     ]
    }
   ],
   "source": [
    "print(result_3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116e484-7836-4990-aebe-9976e49e56a8",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6beb467-238d-4b10-b2f6-b03b43758b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2d960fa-a33e-413d-a2cc-d0325b9cc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_1=ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),model='gpt-4',temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6574a82-deb1-4f1e-a03b-ddcebad56df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"ChatGPT is an artificial intelligence language model developed by OpenAI. It's designed to generate text that resembles human writing and can engage in conversation with users, answer questions, write essays, and more. It's based on the GPT (Generative Pretrained Transformer) model, which uses machine learning algorithms to produce its output.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 12, 'total_tokens': 79, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6d2d4947-582c-4e93-8245-e886b43a111a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 67, 'total_tokens': 79})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model_1.invoke(\n",
    "    [\n",
    "        HumanMessage(content='what is chatgpt')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec279760-340a-4463-a55b-19b2337b0804",
   "metadata": {},
   "source": [
    "## Exmple 2: ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54a5bbc8-68a8-42b0-8555-0d226029bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "ChatPromptTemplate,\n",
    "SystemMessagePromptTemplate,\n",
    "HumanMessagePromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "877878c9-ad69-49e8-955c-e1ee2961fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You will provided with the sample text. \\\n",
    "Your task is to translate the text into {output_language} language \\\n",
    "and summarize the translated text in at most {max_words} words. \\ \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "970e7e1d-a300-4b78-871c-e6267b4d2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "605a44ee-bb8c-4564-8816-84292596bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{sample_text}\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb4ca651-8847-4ca6-aeb3-4cfeb779e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§Æ‡•à‡§Ç ‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§Ç‡§§ ‡§ï‡§æ ‡§¨‡•á‡§∏‡§¨‡•ç‡§∞‡•Ä ‡§∏‡•á ‡§á‡§Ç‡§§‡§ú‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§\n",
      "\n",
      "‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™: ‡§∏‡§™‡•ç‡§§‡§æ‡§π‡§æ‡§Ç‡§§ ‡§ï‡•Ä ‡§â‡§§‡•ç‡§∏‡•Å‡§ï‡§§‡§æ ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt_template, human_message_prompt_template])\n",
    "final_prompt = chat_prompt_template.format_prompt(output_language=\"Hindi\", max_words=15,\n",
    "                          sample_text=\"Estoy deseando que llegue el fin de semana.\").to_messages()\n",
    "# generate the output by calling ChatGPT model and passing the prompt\n",
    "completion = chat_model_1.invoke(final_prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae100c6-bac5-4fd6-8598-1f8f5931a87a",
   "metadata": {},
   "source": [
    "## Exmple 3: ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ff08219-e009-4419-adfd-865dfe9a3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fac86a3e-0d3a-4e9d-870f-9148faa01c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_2=ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),model='gpt-3.5-turbo-1106',temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14ad6df7-8ac3-416b-98e3-9dea8b8a4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7df62e8-391b-4457-9cc8-55eb35636664",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.invoke([HumanMessage(content=\"Tell me about large language Model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3269ab21-213f-419a-8c5c-5a56f15b6979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Large language models are a type of artificial intelligence that is designed to understand and generate human language. These models are trained on vast amounts of text data from the internet and other sources, allowing them to learn the patterns and nuances of language.\\n\\nOne of the most well-known large language models is OpenAI's GPT-3 (Generative Pre-trained Transformer 3), which has 175 billion parameters and is capable of performing a wide range of language tasks, such as translation, summarization, and question-answering.\\n\\nLarge language models have the potential to revolutionize many industries, including customer service, content creation, and language translation. They can also be used to generate human-like text, such as articles, stories, and poetry.\\n\\nHowever, there are also concerns about the ethical implications of large language models, such as their potential to spread misinformation and their impact on privacy and data security. As a result, there is ongoing debate about the responsible use of these powerful AI systems.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3da9cc06-0b91-4338-94c3-e87a91399f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.invoke([SystemMessage(content=\"Consider you are data scientist\"),\n",
    "    HumanMessage(content=\"Tell me about large language Model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "945d46e4-05cd-46a5-b152-21ee5d4d766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model refers to a type of artificial intelligence (AI) model that is designed to understand and generate human language. These models are trained on vast amounts of text data and use deep learning techniques to learn the patterns and structures of language. Large language models are capable of understanding context, generating coherent text, and performing a variety of natural language processing tasks such as language translation, text summarization, and question answering.\\n\\nOne of the most well-known large language models is OpenAI's GPT-3 (Generative Pre-trained Transformer 3), which has 175 billion parameters and has demonstrated impressive capabilities in understanding and generating human-like text. Large language models have a wide range of applications, including chatbots, content generation, language translation, and assisting with language-related tasks in various industries.\\n\\nHowever, large language models also raise ethical and societal concerns, such as potential biases in the training data, the spread of misinformation, and the potential for malicious use. As a data scientist, it's important to consider these ethical implications when working with large language models and to ensure that they are used responsibly and ethically.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562853e3-c821-44da-ab74-3f21a2ccbf0b",
   "metadata": {},
   "source": [
    "### Example 4:Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c451947e-ca2e-40f6-b0e3-20138c85e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=chat_model_2.generate(\n",
    "    [[SystemMessage(content=\"Consider you are expert Data Scientst and having Knowledge of Deep Learning and NLP\"),\n",
    "    HumanMessage(content=\"Explain what is Large Language Model\")],\n",
    "    [SystemMessage(content=\"Consider You are doctor having knowledge of heathcare domain\"),\n",
    "    HumanMessage(content=\"Explain what is Large Language Model\")]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59d35fd5-50a8-4042-bbdf-1ebe2938a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 429,\n",
       "  'prompt_tokens': 63,\n",
       "  'total_tokens': 492,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-1106',\n",
       " 'system_fingerprint': 'fp_e81b59fe66'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8271466-3c60-43ad-91f4-8c59250424e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A large language model is a type of deep learning model that is designed to understand and generate human language. These models are trained on vast amounts of text data and are capable of learning the complex patterns and structures of language. Large language models are typically based on deep learning architectures such as transformers and are trained on massive datasets to develop a deep understanding of natural language.\\n\\nThese models are capable of performing a wide range of natural language processing tasks, including language generation, translation, summarization, sentiment analysis, and more. They have the ability to understand and generate human-like text, making them extremely powerful tools for a variety of applications in NLP.\\n\\nSome well-known examples of large language models include OpenAI's GPT (Generative Pre-trained Transformer) series, Google's BERT (Bidirectional Encoder Representations from Transformers), and Facebook's RoBERTa (A Robustly Optimized BERT Pretraining Approach). These models have significantly advanced the state of the art in natural language processing and have been used in a wide range of applications, from chatbots and virtual assistants to language translation and content generation.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0bdcd83-2fbc-4b41-addd-5e540c87434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Large Language Model is a type of artificial intelligence (AI) model that is designed to understand and generate human language. These models are trained on vast amounts of text data, such as books, articles, and websites, to learn the patterns and structures of language. They use this knowledge to perform tasks such as language translation, text generation, and natural language understanding.\\n\\nLarge language models are typically built using deep learning techniques, such as neural networks, and they require significant computational resources to train due to the massive amount of data they need to process. Examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers).\\n\\nThese models have the ability to understand and generate human-like text, making them useful for a wide range of applications, including chatbots, language translation, content generation, and more. They have the potential to significantly impact various industries, including healthcare, by improving communication, automating tasks, and providing valuable insights from large volumes of text data.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545656b3-ad68-4236-b420-d304b81800b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dcb10-a889-4c4b-8fdb-a92ec604cf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7af032-fa89-4f5b-8efa-534ffa45c2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
