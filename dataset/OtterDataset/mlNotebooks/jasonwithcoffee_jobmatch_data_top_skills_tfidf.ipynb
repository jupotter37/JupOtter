{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'/Users/jason/Documents/Jason/JobMatch/job-match-271401-74d3c9eb9112.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    "from job_search.job_details\n",
    "where search_datetime between '2020-05-01' and '2020-05-03'\n",
    "and lower(title) like '%data%sci%'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()\n",
    "df = bq_client.query(query).result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>search_datetime</th>\n",
       "      <th>location</th>\n",
       "      <th>search_title</th>\n",
       "      <th>search_location</th>\n",
       "      <th>search_detail_datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>company_rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44581b261abec239</td>\n",
       "      <td>2020-05-02 15:29:00+00:00</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>IT+Engineer</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Sr. Data Scientist (Dallas, TX)</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16bdb1763913307c</td>\n",
       "      <td>2020-05-02 23:14:00+00:00</td>\n",
       "      <td>Louisville, CO 80027</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>GHX</td>\n",
       "      <td>3.2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8dc961b84c2d9b33</td>\n",
       "      <td>2020-05-02 23:14:00+00:00</td>\n",
       "      <td>Tampa, FL 33607</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>2020-05-04 02:00:00+00:00</td>\n",
       "      <td>Director of Data Science &amp; Analytics</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>ClearSource</td>\n",
       "      <td>3.8</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60baeac4d4fbd010</td>\n",
       "      <td>2020-05-02 23:12:00+00:00</td>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>data+scientist</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2020-05-04 02:00:00+00:00</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>GrainBridge, LLC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fb253e56a646292a</td>\n",
       "      <td>2020-05-02 23:13:00+00:00</td>\n",
       "      <td>Reston, VA</td>\n",
       "      <td>data+scientist</td>\n",
       "      <td>Reston</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Senior Data Science Consultant</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>Raft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id           search_datetime              location  \\\n",
       "0  44581b261abec239 2020-05-02 15:29:00+00:00            Dallas, TX   \n",
       "1  16bdb1763913307c 2020-05-02 23:14:00+00:00  Louisville, CO 80027   \n",
       "2  8dc961b84c2d9b33 2020-05-02 23:14:00+00:00       Tampa, FL 33607   \n",
       "3  60baeac4d4fbd010 2020-05-02 23:12:00+00:00             Omaha, NE   \n",
       "4  fb253e56a646292a 2020-05-02 23:13:00+00:00            Reston, VA   \n",
       "\n",
       "     search_title search_location    search_detail_datetime  \\\n",
       "0     IT+Engineer          Dallas 2020-05-04 02:01:00+00:00   \n",
       "1    data+analyst          Denver 2020-05-04 02:01:00+00:00   \n",
       "2    data+analyst           Tampa 2020-05-04 02:00:00+00:00   \n",
       "3  data+scientist           Omaha 2020-05-04 02:00:00+00:00   \n",
       "4  data+scientist          Reston 2020-05-04 02:01:00+00:00   \n",
       "\n",
       "                                  title  \\\n",
       "0       Sr. Data Scientist (Dallas, TX)   \n",
       "1               Data Science Internship   \n",
       "2  Director of Data Science & Analytics   \n",
       "3                        Data Scientist   \n",
       "4        Senior Data Science Consultant   \n",
       "\n",
       "                                            job_desc           company  \\\n",
       "0  <div class=\"jobsearch-jobDescriptionText\" id=\"...   Tiger Analytics   \n",
       "1  <div class=\"jobsearch-jobDescriptionText\" id=\"...               GHX   \n",
       "2  <div class=\"jobsearch-jobDescriptionText\" id=\"...       ClearSource   \n",
       "3  <div class=\"jobsearch-jobDescriptionText\" id=\"...  GrainBridge, LLC   \n",
       "4  <div class=\"jobsearch-jobDescriptionText\" id=\"...              Raft   \n",
       "\n",
       "   company_rating  company_rating_count  \n",
       "0             0.0                     0  \n",
       "1             3.2                    22  \n",
       "2             3.8                    69  \n",
       "3             0.0                     0  \n",
       "4             0.0                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_desc'] = df['job_desc'].apply(lambda x: BeautifulSoup(x, 'html.parser').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>search_datetime</th>\n",
       "      <th>location</th>\n",
       "      <th>search_title</th>\n",
       "      <th>search_location</th>\n",
       "      <th>search_detail_datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>company_rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44581b261abec239</td>\n",
       "      <td>2020-05-02 15:29:00+00:00</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>IT+Engineer</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Sr. Data Scientist (Dallas, TX)</td>\n",
       "      <td>Tiger Analytics is looking for experienced Dat...</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16bdb1763913307c</td>\n",
       "      <td>2020-05-02 23:14:00+00:00</td>\n",
       "      <td>Louisville, CO 80027</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>The Intern would work in support of Data Scien...</td>\n",
       "      <td>GHX</td>\n",
       "      <td>3.2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8dc961b84c2d9b33</td>\n",
       "      <td>2020-05-02 23:14:00+00:00</td>\n",
       "      <td>Tampa, FL 33607</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>2020-05-04 02:00:00+00:00</td>\n",
       "      <td>Director of Data Science &amp; Analytics</td>\n",
       "      <td>As the Director of the eCommerce Data Science ...</td>\n",
       "      <td>ClearSource</td>\n",
       "      <td>3.8</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60baeac4d4fbd010</td>\n",
       "      <td>2020-05-02 23:12:00+00:00</td>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>data+scientist</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2020-05-04 02:00:00+00:00</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DESCRIPTION\\nGrainBridge is seeking a talented...</td>\n",
       "      <td>GrainBridge, LLC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fb253e56a646292a</td>\n",
       "      <td>2020-05-02 23:13:00+00:00</td>\n",
       "      <td>Reston, VA</td>\n",
       "      <td>data+scientist</td>\n",
       "      <td>Reston</td>\n",
       "      <td>2020-05-04 02:01:00+00:00</td>\n",
       "      <td>Senior Data Science Consultant</td>\n",
       "      <td>Who we are: We (http://goraft.tech/) are growi...</td>\n",
       "      <td>Raft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id           search_datetime              location  \\\n",
       "0  44581b261abec239 2020-05-02 15:29:00+00:00            Dallas, TX   \n",
       "1  16bdb1763913307c 2020-05-02 23:14:00+00:00  Louisville, CO 80027   \n",
       "2  8dc961b84c2d9b33 2020-05-02 23:14:00+00:00       Tampa, FL 33607   \n",
       "3  60baeac4d4fbd010 2020-05-02 23:12:00+00:00             Omaha, NE   \n",
       "4  fb253e56a646292a 2020-05-02 23:13:00+00:00            Reston, VA   \n",
       "\n",
       "     search_title search_location    search_detail_datetime  \\\n",
       "0     IT+Engineer          Dallas 2020-05-04 02:01:00+00:00   \n",
       "1    data+analyst          Denver 2020-05-04 02:01:00+00:00   \n",
       "2    data+analyst           Tampa 2020-05-04 02:00:00+00:00   \n",
       "3  data+scientist           Omaha 2020-05-04 02:00:00+00:00   \n",
       "4  data+scientist          Reston 2020-05-04 02:01:00+00:00   \n",
       "\n",
       "                                  title  \\\n",
       "0       Sr. Data Scientist (Dallas, TX)   \n",
       "1               Data Science Internship   \n",
       "2  Director of Data Science & Analytics   \n",
       "3                        Data Scientist   \n",
       "4        Senior Data Science Consultant   \n",
       "\n",
       "                                            job_desc           company  \\\n",
       "0  Tiger Analytics is looking for experienced Dat...   Tiger Analytics   \n",
       "1  The Intern would work in support of Data Scien...               GHX   \n",
       "2  As the Director of the eCommerce Data Science ...       ClearSource   \n",
       "3  DESCRIPTION\\nGrainBridge is seeking a talented...  GrainBridge, LLC   \n",
       "4  Who we are: We (http://goraft.tech/) are growi...              Raft   \n",
       "\n",
       "   company_rating  company_rating_count  \n",
       "0             0.0                     0  \n",
       "1             3.2                    22  \n",
       "2             3.8                    69  \n",
       "3             0.0                     0  \n",
       "4             0.0                     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Challenge:\n",
      "Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data.\n",
      "We have an opportunity for you to use your analytical skills to improve mission integration across the US intelligence community (IC). You’ll work closely with your customer to understand their questions and needs, then dig into their data-rich environment to find the pieces of their information puzzle. You’ll write scripts to integrate data, conduct exploratory data analysis to discover hidden trends, apply machine learning to train predictive models, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior managers make informed decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in support of the IC's global mission.\n",
      "Empower change with us.\n",
      "You Have:\n",
      "3 years of experience with using programming languages, including Python, R, or Java to manipulate and analyze dataExperience with using SQL to conduct complex database queriesExperience with developing data visualizations or dashboards to communicate key insightsTS/SCI clearanceBA or BS degree\n",
      "Nice If You Have:\n",
      "Experience with using Tableau to blend and analyze data from various sourcesKnowledge of natural language processing techniquesKnowledge of commercial cloud services used by the ICPossession of excellent oral and written communication skills, including communicating information to a senior executive audienceMA or MS degree in Mathematics, Statistics, CS, Data Analytics, or a related technical field\n",
      "\n",
      "Clearance:\n",
      "Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n",
      "\n",
      "Build Your Career:\n",
      "At Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you’ll have the chance to:\n",
      "access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "change the world with the Data Science Bowl—the world’s premier data science for social good competition\n",
      "participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      "You’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want as you chart your own course for success.\n",
      "We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.\n",
      "#LI-AH1, APC1, CJ1, NSG1, WP1\n"
     ]
    }
   ],
   "source": [
    "print(df.job_desc[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.XrykpBNKiL4\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    " \n",
    "#get the text column \n",
    "docs=df.job_desc.tolist()\n",
    " \n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords.words('english'))\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort_coo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b8cce8cade2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#sort the tf-idf vectors by descending order of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msorted_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_coo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#extract only the top n; n here is 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sort_coo' is not defined"
     ]
    }
   ],
   "source": [
    "# you only needs to do this once, this is a mapping of index to \n",
    "feature_names=cv.get_feature_names()\n",
    " \n",
    "# get the document that we want to extract keywords from\n",
    "doc=df.job_desc[0]\n",
    " \n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    " \n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    " \n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\n=====Doc=====\")\n",
    "print(doc)\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47638877/using-phrasematcher-in-spacy-to-find-multiple-match-types\n",
    "# https://course.spacy.io/en/chapter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_skills = ['Python', 'ReactJS', 'MongoDB','SQL','JavaScript', 'Tableau', 'Java'\n",
    "               'R', 'Matlab', 'Julia', 'Matlab', 'Mathematica', 'Spark', 'PySpark' ,'Hadoop', 'NoSQL', 'Postgres',\n",
    "              'S3', 'EC2', 'MapReduce', 'Pig', 'Hive', 'HTML5', 'CSS', 'R Shiny', 'Power BI', 'matplotlib', \n",
    "               'seaborn', 'bokeh', 'pandas', 'JIRA', 'Agile', 'Natural Language Processing',\n",
    "              'AWS', 'Azure', 'Google Cloud', 'GCP', 'Databricks', 'Deep Learning', 'Graph database', 'Scala',\n",
    "               'SAS','C++', 'Linux','Spotfire', 'Oracle','Apache', 'SPSS','SAP', 'Teradata'\n",
    "              ]\n",
    "concepts = ['machine learning', 'Business Intelligence', 'Computer Science', 'Statistics', 'Economics',\n",
    "            'Physics', 'Engineering', 'Mathematics','feature engineering', 'recommender systems', 'NLP', \n",
    "            'computer vision', 'Information Systems', 'Economics', 'ML', 'AI'\n",
    "           ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
