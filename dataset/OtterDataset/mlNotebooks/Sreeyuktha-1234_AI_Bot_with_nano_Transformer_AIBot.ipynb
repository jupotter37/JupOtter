{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "class ArtificialAssistant:\n",
        "    responses_notrequired = (\"no\", \"sorry i dont need your help\")\n",
        "    words_to_end_program = (\"quit\", \"exit\", \"goodbye\", \"bye\")\n",
        "    start_phrases = (\n",
        "        \"What are the doubts you have in Artificial Intelligence?\\n\",\n",
        "        \"Ask me anything in Artificial Intelligence Field I will help you?\\n\",\n",
        "        \"Any Questions about Artificial Intelligence?\\n\"\n",
        "    )\n",
        "\n",
        "    def __init__(self):\n",
        "        self.questions = {\n",
        "            'programming': re.compile(r'.*\\s*(programming languages|languages to learn)\\s*', re.IGNORECASE),\n",
        "            'fields_of_ai': re.compile(r'.*\\s*fields of ai\\s*', re.IGNORECASE),\n",
        "            'about_python': re.compile(r'.*\\s*Python*', re.IGNORECASE),\n",
        "            'about_artificial_intelligence': re.compile(r'.*\\s*(Artificial Intelligence|AI)\\s*', re.IGNORECASE),\n",
        "            'concepts': re.compile(r'.*\\s*fields\\s*', re.IGNORECASE),\n",
        "            'machine_learning': re.compile(r'.*\\s*Machine Learning\\s*', re.IGNORECASE),\n",
        "            'deep_learning': re.compile(r'.*\\s*Deep Learning\\s*', re.IGNORECASE),\n",
        "            'nlp': re.compile(r'.*\\s*Natural Language Processing\\s*', re.IGNORECASE),\n",
        "            'neural_network': re.compile(r'.*\\s*Neural Network\\s*', re.IGNORECASE),\n",
        "            'computer_vision': re.compile(r'.*\\s*Computer Vision\\s*', re.IGNORECASE),\n",
        "            'variables': re.compile(r'.*\\s*Variables\\s*', re.IGNORECASE),\n",
        "            'data_types': re.compile(r'.*\\s*Data types\\s*', re.IGNORECASE),\n",
        "            'operators': re.compile(r'.*\\s*Operators\\s*', re.IGNORECASE)\n",
        "        }\n",
        "        self.user_name = None\n",
        "        self.can_assist = None\n",
        "        self.reply = None\n",
        "\n",
        "    def main(self):\n",
        "        self.user_name = input(\"Hello may I know your name?\\n\")\n",
        "        self.can_assist = input(\n",
        "            f\"Hi {self.user_name}, I am your Personal AI Assistant Bot. I am here to teach you about Artificial Intelligence?\\n\")\n",
        "        if self.can_assist in self.responses_notrequired:\n",
        "            print(\"Ok no problem have a nice day ahead!\")\n",
        "            return\n",
        "        self.chat()\n",
        "\n",
        "    def should_end_conversation(self, reply):\n",
        "        for command in self.words_to_end_program:\n",
        "            if reply == command:\n",
        "                print(\"Okay, have a nice day!\")\n",
        "                return True\n",
        "\n",
        "    def chat(self):\n",
        "        self.reply = input(random.choice(self.start_phrases)).lower()\n",
        "        while not self.should_end_conversation(self.reply):\n",
        "            self.reply = input(self.provide_response(self.reply))\n",
        "\n",
        "    def provide_response(self, reply):\n",
        "        for key, value in self.questions.items():\n",
        "            instance = key\n",
        "            regex_pattern = value\n",
        "            similarity = re.match(regex_pattern, reply)\n",
        "            if similarity and instance == 'programming':\n",
        "                return self.programming(instance)\n",
        "            elif similarity and instance == 'fields_of_ai':\n",
        "                return self.fields_of_ai()\n",
        "            elif similarity and instance == 'about_python':\n",
        "                return self.about_python()\n",
        "            elif similarity and instance == 'about_artificial_intelligence':\n",
        "                return self.about_artificial_intelligence(instance)\n",
        "            elif similarity and instance == 'machine_learning':\n",
        "                return self.machine_learning()\n",
        "            elif similarity and instance == 'deep_learning':\n",
        "                return self.deep_learning()\n",
        "            elif similarity and instance == 'nlp':\n",
        "                return self.nlp()\n",
        "            elif similarity and instance == 'neural_network':\n",
        "                return self.neural_network()\n",
        "            elif similarity and instance == 'computer_vision':\n",
        "                return self.computer_vision()\n",
        "            elif similarity and instance == 'variables':\n",
        "                return self.variables()\n",
        "            elif similarity and instance == 'data_types':\n",
        "                return self.data_types()\n",
        "            elif similarity and instance == 'operators':\n",
        "                return self.operators()\n",
        "        if not similarity:\n",
        "            return self.no_match_instance()\n",
        "\n",
        "    def programming(self, instance):\n",
        "        if instance in ['programming']:\n",
        "            definition = (\"The Languages you need to learn are Python, R, etc.\\n\",)\n",
        "            return random.choice(definition)\n",
        "        else:\n",
        "            return \"Sorry, I didn't get you.\\n\"\n",
        "\n",
        "    def fields_of_ai(self):\n",
        "        definition = (\"Artificial intelligence encompasses various fields, including machine learning, deep learning, computer vision, natural language processing, neural networks, and robotics. etc \\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def about_python(self):\n",
        "        definition = (\"Python is frequently used for data analysis, task automation, and the development of software and websites. It isn't tailored for any particular issue and can be used to construct a wide range of programs.\\n\",\n",
        "                     \"Python is a widely used language for software and web development because it allows you to write sophisticated, multi-protocol programs with legible, simple syntax.\\n\")\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def about_artificial_intelligence(self, instance):\n",
        "        if instance in ['about_artificial_intelligence']:\n",
        "            definition = (\"The theory and creation of computer systems that are capable of carrying out operations like speech recognition, visual perception, decision-making, and language translation that ordinarily call for human intellect.\\n\",\n",
        "                         \"The science of creating machines with human-like thought processes is known as artificial intelligence. It is capable of actions that are deemed intelligent. Large volumes of data can be processed by AI technology in ways that humans cannot. AI wants to be able to do human-like tasks including pattern recognition, decision-making, and judgment.\\n\")\n",
        "            return random.choice(definition)\n",
        "        else:\n",
        "            return \"Sorry, I didn't get you.\\n\"\n",
        "\n",
        "    def concepts(self):\n",
        "        definition = (\"The many subfields of AI study are focused on specific objectives and the use of certain instruments. Reasoning, knowledge representation, planning, learning, natural language processing, perception, and robotics support are among the traditional objectives of AI study.\\n\",\n",
        "                     \"To help executives get up to speed, we've identified the six main subsets of AI as machine learning, deep learning, robotics, neural networks, natural language processing, and genetic algorithms.\\n\",\n",
        "                    )\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def machine_learning(self):\n",
        "        responses = (\"Within the fields of computer science and artificial intelligence, machine learning focuses on leveraging data and algorithms to help AI mimic human learning processes while continuously increasing its accuracy.\\n\",\n",
        "                     \"Without being specifically trained to do so, computers can now learn through data and make predictions or choices thanks to machine learning.\\n\",\n",
        "                    )\n",
        "        return random.choice(responses)\n",
        "\n",
        "    def deep_learning(self):\n",
        "        responses = (\"An artificial intelligence technique called deep learning trains machines to digest information in a manner similar to that of the human brain. To generate precise insights and forecasts, deep learning models are able to identify intricate patterns in images, text, noises, and other types of data.\\n\",\n",
        "                     \"The subset of machine learning techniques based on representation learning and artificial neural networks is known as deep learning.\\n\",\n",
        "                    )\n",
        "        return random.choice(responses)\n",
        "\n",
        "    def nlp(self):\n",
        "        definition = (\"A machine learning technique called natural language processing (NLP) enables computers to understand, manipulate, and interpret human language.\\n\",\n",
        "                      \"A cutting-edge area of artificial intelligence called natural language processing allows computers to comprehend, interpret, and produce human language, facilitating smooth communication between people and machines.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def neural_network(self):\n",
        "        definition = (\"An artificial intelligence technique called a neural network trains computers to process information in a manner similar to that of the human brain.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def computer_vision(self):\n",
        "        definition = (\"The goal of computer vision, a branch of computer science, is to make it possible for machines to recognize and comprehend objects and people in pictures and movies. Similar to other forms of artificial intelligence, computer vision aims to execute and mechanize activities that mimic human abilities.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def variables(self):\n",
        "        definition = (\"Data values are kept in a container called a variable.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def data_types(self):\n",
        "        definition = (\"Data types define the kinds of information that can be stored in a variable.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def operators(self):\n",
        "        definition = (\"Values and variables can be operated on using operators.\\n\",)\n",
        "        return random.choice(definition)\n",
        "\n",
        "    def no_match_instance(self):\n",
        "        definition = (\"Sorry, I didn't get you.\\n\", \"I don't have an answer.\\n\",\"Can you repeat the question.\")\n",
        "        return random.choice(definition)\n",
        "\n",
        "\n",
        "my_bot = ArtificialAssistant()\n",
        "my_bot.main()\n"
      ],
      "metadata": {
        "id": "Ie1nSPzp7ZX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590481da-42be-4d6a-fc12-d87e48e20c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello may I know your name?\n",
            "Sree\n",
            "Hi Sree, I am your Personal AI Assistant Bot. I am here to teach you about Artificial Intelligence?\n",
            "Ok\n",
            "Any Questions about Artificial Intelligence?\n",
            "What is Artificial Intelligence\n",
            "The science of creating machines with human-like thought processes is known as artificial intelligence. It is capable of actions that are deemed intelligent. Large volumes of data can be processed by AI technology in ways that humans cannot. AI wants to be able to do human-like tasks including pattern recognition, decision-making, and judgment.\n",
            "What is Machine Learning\n",
            "Without being specifically trained to do so, computers can now learn through data and make predictions or choices thanks to machine learning.\n",
            "what is deep learning\n",
            "An artificial intelligence technique called deep learning trains machines to digest information in a manner similar to that of the human brain. To generate precise insights and forecasts, deep learning models are able to identify intricate patterns in images, text, noises, and other types of data.\n",
            "what are data types\n",
            "Data types define the kinds of information that can be stored in a variable.\n",
            "bye\n",
            "Okay, have a nice day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "FOLZlxjQhydv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_handle = open('Myfile.txt', 'r', errors='ignore')\n",
        "raw_document = file_handle.read()"
      ],
      "metadata": {
        "id": "sD-YO9_Ph7up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_document = raw_document.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r5BlVZmiBEY",
        "outputId": "66d3c89d-18ce-46c3-c70a-b6bc7c763fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokenizer = nltk.sent_tokenize(raw_document)\n",
        "word_tokenizer = nltk.word_tokenize(raw_document)"
      ],
      "metadata": {
        "id": "N3D85SDmiGyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "remove_punctuation_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def lemmatize_normalize(text):\n",
        "    return lemmatize_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_dict)))\n"
      ],
      "metadata": {
        "id": "NolRsQzHiRHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "greeting_inputs = ('hello', 'hi')\n",
        "greeting_responses = ('hi', 'Hey', 'Hey There!')\n",
        "\n",
        "def greet_user(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in greeting_inputs:\n",
        "            return random.choice(greeting_responses)\n"
      ],
      "metadata": {
        "id": "_Y2Maj2fikPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "GRSSDsuHi29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(user_response):\n",
        "    robo_response = ''\n",
        "    tfidf_vectorizer = TfidfVectorizer(tokenizer=lemmatize_normalize, stop_words='english')\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentence_tokenizer)\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix)\n",
        "    indices_sorted = cosine_similarities.argsort()[0][-2]\n",
        "    flat_cosine_similarities = cosine_similarities.flatten()\n",
        "    flat_cosine_similarities.sort()\n",
        "    required_tfidf = flat_cosine_similarities[-2]\n",
        "    if required_tfidf == 0:\n",
        "        robo_response = robo_response + \"I am sorry. Unable to understand you!\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response + sentence_tokenizer[indices_sorted]\n",
        "        return robo_response"
      ],
      "metadata": {
        "id": "ukOEnwFxi3at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_active = True\n",
        "print('Hello! I am the Intelligent Bot, You can start typing the text and For ending type bye!')\n",
        "\n",
        "while is_active:\n",
        "    user_input = input()\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    if user_input != 'bye':\n",
        "        if user_input == 'thank you' or user_input == 'thanks':\n",
        "            is_active = False\n",
        "            print('You are Welcome..')\n",
        "        else:\n",
        "            if greet_user(user_input) is not None:\n",
        "                print(greet_user(user_input))\n",
        "            else:\n",
        "                sentence_tokenizer.append(user_input)\n",
        "                word_tokenizer += nltk.word_tokenize(user_input)\n",
        "                final_words = list(set(word_tokenizer))\n",
        "                print(generate_response(user_input))\n",
        "                sentence_tokenizer.remove(user_input)\n",
        "    else:\n",
        "        is_active = False\n",
        "        print('Good Bye!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjnTF3PRi95L",
        "outputId": "17ca0a9c-8e35-4e2e-e11d-dc395aba6923"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am the Intelligent Bot, You can start typing the text and For ending type bye!\n",
            "hi\n",
            "hi\n",
            "Artificial Intelligence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artificial intelligence.\n",
            "Machine learning\n",
            "machine learning.\n",
            "deep learning\n",
            "machine learning.\n",
            "neural network\n",
            "and warren mcculloch and walter pitts laid the foundation for neural networks.\n",
            "artificial intelligence\n",
            "artificial intelligence.\n",
            "bye\n",
            "Good Bye!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGHWj8VmjEFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}