{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use Machine Learning vs. Deep Learning\n",
    "\n",
    "**Machine Learning:**\n",
    "- Tabular data\n",
    "- Feature Engineering and Selection\n",
    "- Few Data e.g., 20-500 \n",
    "- Use of CPU\n",
    "- More Explanable\n",
    "\n",
    "**Deep Learning:**\n",
    "- Image, Audio, Signals, test\n",
    "- No Feature Engineering\n",
    "- Large Data e.g., 10000-100000000\n",
    "- Use of GPU\n",
    "- Less Explanable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practicing code (Code written by Dr. Chaklam Shilpasuwanchai)\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version check\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c4ffd10790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Checking gpu\n",
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. Specify input and target\n",
    "2. Dataset and DataLoader\n",
    "3. nn.Linear\n",
    "4. Define loss function\n",
    "5. Define optimizer function\n",
    "6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Specifying input and target\n",
    "\n",
    "# Input\n",
    "x_train = np.array([[72, 67, 43],[91,88,64], [87,134,58],\n",
    "                    [102, 43, 37], [69,96,70],[72, 67, 43],[91,88,64], [87,134,58],\n",
    "                    [102, 43, 37], [69,96,70],[72, 67, 43],[91,88,64], [87,134,58],\n",
    "                    [102, 43, 37], [69,96,70]\n",
    "                    ], dtype='float32')\n",
    "\n",
    "# Target\n",
    "y_train = np.array([[56,70], [81,101], [119,133], [22,37], [103,119],\n",
    "                    [56,70], [81,101], [119,133], [22,37], [103,119],\n",
    "                    [56,70], [81,101], [119,133], [22,37], [103,119]\n",
    "                    ],  dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.from_numpy** is a Pytorch function that converts a NumPy array into a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3])\n",
      "torch.Size([15, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(x_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "\n",
    "print(inputs.size())\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoaders** are utility classes used to effeciently manage, load, and process data in batches. \n",
    "\n",
    "**TensorDataset** is a simple dataset wrapper provided by the torch.utils.data module. It combines multiple tensors (typically input featurs ans outputs) into a single dataset, which can then be used with a **DataLoader** for batching, shuffling, and parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dataset and DataLoader\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 72.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[102.,  43.,  37.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [119., 133.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4557, -0.2662, -0.1630],\n",
      "        [-0.3471,  0.0545, -0.5702]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([ 0.5214, -0.4904], requires_grad=True)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Define some layer - nn.Linear\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "model = nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.weight.size())\n",
    "print(model.bias)\n",
    "print(model.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4557, -0.2662, -0.1630],\n",
       "         [-0.3471,  0.0545, -0.5702]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.5214, -0.4904], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model.parameter():** returns an iterator over all the parameters(weigths and biases) of the model. Each layer in a nn has assocoated parameters, such as weights and biases.\n",
    "\n",
    "**p.requires_grad:** The condition checks if the parameter p requires gradient. If it does, it means that the parameter is trainable and will be updated during the training process. Some parameters, such as frozen layers, might have requires_grad = False to exclude them from the training process.\n",
    "\n",
    "**p.numel():** Returns the total number of parameters in that parameter tensir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# complexity by the number of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-57.1354, -46.3541],\n",
       "        [-74.8075, -63.7805],\n",
       "        [-84.2500, -56.4638],\n",
       "        [-63.4415, -54.6548],\n",
       "        [-67.8887, -59.1288],\n",
       "        [-57.1354, -46.3541],\n",
       "        [-74.8075, -63.7805],\n",
       "        [-84.2500, -56.4638],\n",
       "        [-63.4415, -54.6548],\n",
       "        [-67.8887, -59.1288],\n",
       "        [-57.1354, -46.3541],\n",
       "        [-74.8075, -63.7805],\n",
       "        [-84.2500, -56.4638],\n",
       "        [-63.4415, -54.6548],\n",
       "        [-67.8887, -59.1288]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "pred = model(inputs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_softmax_cross_entropy_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23160.7246, grad_fn=<MseLossBackward0>)\n",
      "23160.724609375\n"
     ]
    }
   ],
   "source": [
    "mse = criterion_mse(pred, targets)\n",
    "print(mse)\n",
    "print(mse.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train with batches of data\n",
    "        for xb, yb in train_dl:\n",
    "            xb.to(device)\n",
    "            yb.to(device)\n",
    "\n",
    "            # Predict\n",
    "            pred = model(xb)\n",
    "\n",
    "            # Caluclate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            # Caluclate gradient\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update params\n",
    "            opt.step()\n",
    "        \n",
    "        if(epoch+1)%10==0:\n",
    "            sys.stdout.write(\"\\rEpoch[{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[100/100], Loss: 19.3841"
     ]
    }
   ],
   "source": [
    "fit(100, model, criterion_mse, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.766687393188477\n"
     ]
    }
   ],
   "source": [
    "pred = model(inputs)\n",
    "loss = criterion_mse(pred, targets)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
