{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1c7ec3",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:maroon\">Ensemble Methods</h1>\n",
    "    <img src=\"figures/06-ensemble_methods.jpeg\" style=\"width:1300px\">\n",
    "    <h3><span style=\"color: #045F5F\">Data Science & Machine Learning for Planet Earth Lecture Series</span></h3><h6><i> by C√©dric M. John <span style=\"size:6pts\">(2022)</span></i></h6></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82171c4",
   "metadata": {},
   "source": [
    "## Plan for today's Lecture üóì "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff5eb1",
   "metadata": {},
   "source": [
    "* <code>DecisionTree</code> for classification\n",
    "* <code>DecisionTree</code> for regression\n",
    "* Bagging algorithms: <code>RandomForest</code>\n",
    "* Boosting: <code>AdaBoost</code> and <code>xgboost</code>\n",
    "* Stacking algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec9b00",
   "metadata": {},
   "source": [
    "## Intended learning outcomes üë©‚Äçüéì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ab445",
   "metadata": {},
   "source": [
    "* Understand variance in decision trees\n",
    "* Apply <code>RandomForest</code> and <code>xgboost</code> (some of the most powerful algorithms\n",
    "* Unleash the power of Ensemble methods on your problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c169d05",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "<br>\n",
    "<center><img src=\"figures/DALL-E_tree.png\" style=\"width:900px;\">\n",
    " ¬© C√©dric John, 2022; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>\n",
    "    <br>Prompt: <i>3D rending of a glass Christmas bubble in purple colors with a tree visible in the reflection</i>.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04bc32",
   "metadata": {},
   "source": [
    "\n",
    "<p>Decision Trees are hierarchical supervised learning algorithms.</p>\n",
    "<ul>\n",
    "<li>Classification and Regression</li>\n",
    "<li>Non-linear modelling</li>\n",
    "<li>Break down the data through binary decisions</li>\n",
    "</ul>\n",
    "<p><img src=\"figures/decision_tree_7.png\" style=\"margin:auto\" width=\"400\"/></p>\n",
    "<a href=\"https://medium.com/analytics-vidhya/ensemble-models-bagging-boosting-c33706db0b0b\">Silipo, 2020</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc920913",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "<span style=\"color:teal\">**Let's start with a classic:** </span><a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris Dataset (Fisher, 1936)</a>\n",
    "<img src=\"figures/iris-machinelearning.png\" style=\"width:1500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d196ac",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.1-üñ•-DecisionTreeClassifier\">1.1 üñ• <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\"><code>DecisionTreeClassifier</code></a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare iris dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "X = data[['petal length (cm)', 'petal width (cm)']]\n",
    "y = data.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instanciate and train model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=2)\n",
    "tree_clf.fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "# Export model graph\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree_clf, out_file=\"iris_tree.dot\", feature_names=X.columns,\n",
    "                class_names=['0','1','2'], rounded=True, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model graph\n",
    "with open(\"iris_tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "    display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35811dc",
   "metadata": {},
   "source": [
    "\n",
    "## Jargon\n",
    "<p><img src=\"figures/decision_tree_jargon.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/\">G√©ron, 2017</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddbeef",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Gini-Index\">Gini Index</h3><p>The Gini index measures the ability of each feature to <strong>separate</strong> the data.</p>\n",
    "<p>It calculates the <strong>impurity</strong> of each node, between [0,1]. The lower the better</p>\n",
    "<span class=\"MathJax_Preview\" style=\"color: inherit;\"></span><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-chtml MathJax_CHTML\" data-mathml='&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"&gt;&lt;mtext&gt;Gini(node)&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/math&gt;' id=\"MathJax-Element-1-Frame\" role=\"presentation\" style=\"font-size: 116%; text-align: center; position: relative;\" tabindex=\"0\"><span aria-hidden=\"true\" class=\"mjx-math\" id=\"MJXc-Node-1\"><span class=\"mjx-mrow\" id=\"MJXc-Node-2\"><span class=\"mjx-mtext\" id=\"MJXc-Node-3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.434em; padding-bottom: 0.619em;\">Gini(node)</span></span><span class=\"mjx-mo MJXc-space3\" id=\"MJXc-Node-4\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.065em; padding-bottom: 0.311em;\">=</span></span><span class=\"mjx-mn MJXc-space3\" id=\"MJXc-Node-5\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\">1</span></span><span class=\"mjx-mo MJXc-space2\" id=\"MJXc-Node-6\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.311em; padding-bottom: 0.434em;\">‚àí</span></span><span class=\"mjx-mo MJXc-space2\" id=\"MJXc-Node-7\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.742em; padding-bottom: 0.742em;\">‚àë</span></span><span class=\"mjx-msubsup MJXc-space1\" id=\"MJXc-Node-8\"><span class=\"mjx-base\"><span class=\"mjx-mi\" id=\"MJXc-Node-9\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.496em;\">p</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" id=\"MJXc-Node-11\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" id=\"MJXc-Node-10\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.311em;\">i</span></span></span></span></span></span></span><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math display=\"block\" xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>Gini(node)</mtext><mo>=</mo><mn>1</mn><mo>‚àí</mo><mo>‚àë</mo><msubsup><mi>p</mi><mi>i</mi><mn>2</mn></msubsup></math></span></span></span><script id=\"MathJax-Element-1\" type=\"math/tex; mode=display\">\\text{Gini(node)} = 1 - \\sum p_i^2</script><p><span class=\"MathJax_Preview\" style=\"color: inherit;\"></span><span class=\"mjx-chtml MathJax_CHTML\" data-mathml='&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;' id=\"MathJax-Element-2-Frame\" role=\"presentation\" style=\"font-size: 116%; position: relative;\" tabindex=\"0\"><span aria-hidden=\"true\" class=\"mjx-math\" id=\"MJXc-Node-12\"><span class=\"mjx-mrow\" id=\"MJXc-Node-13\"><span class=\"mjx-msubsup\" id=\"MJXc-Node-14\"><span class=\"mjx-base\"><span class=\"mjx-mi\" id=\"MJXc-Node-15\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.496em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" id=\"MJXc-Node-16\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.311em;\">i</span></span></span></span></span></span><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>p</mi><mi>i</mi></msub></math></span></span><script id=\"MathJax-Element-2\" type=\"math/tex\">p_i</script> being the ratio of observation of being of class <span class=\"MathJax_Preview\" style=\"color: inherit;\"></span><span class=\"mjx-chtml MathJax_CHTML\" data-mathml='&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/math&gt;' id=\"MathJax-Element-3-Frame\" role=\"presentation\" style=\"font-size: 116%; position: relative;\" tabindex=\"0\"><span aria-hidden=\"true\" class=\"mjx-math\" id=\"MJXc-Node-17\"><span class=\"mjx-mrow\" id=\"MJXc-Node-18\"><span class=\"mjx-mi\" id=\"MJXc-Node-19\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.311em;\">i</span></span></span></span><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>i</mi></math></span></span><script id=\"MathJax-Element-3\" type=\"math/tex\">i</script> at each node</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb5136",
   "metadata": {},
   "source": [
    "\n",
    "<p><img src=\"figures/decision_tree_jargon.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/\">G√©ron, 2017</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate gini of root node\n",
    "1 - 3*(50/150)**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcultate gini green leaf\n",
    "1 - 0**2 - (49/54)**2 - (5/54)**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1546bd",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id='\"Growing\"-a-tree?'>\"Growing\" a tree?</h3><p>The tree structure is decided through the following steps:</p>\n",
    "<ol>\n",
    "<li>Start at root node containing all your dataset</li>\n",
    "<li>Try various combination of <strong>(feature, threshold)</strong> tuples. Each would split your dataset into 2 child nodes</li>\n",
    "<li>For each combination, compute <strong>weighted average gini index</strong> of both child nodes (weighted by number of instances)</li>\n",
    "<li>Select (feature, threshold) yielding the <strong>lowest</strong> index (i.e the \"purest child nodes\")</li>\n",
    "<li>Split dataset in two using this rule. Repeat step 2 for both subsets.</li>\n",
    "<li>Stop when no feature improves node impurity (...at what risk?)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe6e08",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Predicting\">Predicting</h3><ul>\n",
    "<li>A new point is passed through the tree from top down until it reaches a leaf. </li>\n",
    "<li>It is predicted to correspond to the most represented class in that leaf. </li>\n",
    "</ul>\n",
    "<p>E.g. New point: <code>X_new = [4(length), 1(width)]</code></p>\n",
    "<p><img src=\"figures/decision_tree_predict.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/\">G√©ron, 2017</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92010ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict a flower from the top right quardrant\n",
    "print(tree_clf.predict([[4,1]]))\n",
    "\n",
    "# Predict proba is just the ratio of flowers in this leaf/quadrant\n",
    "print(tree_clf.predict_proba([[4,1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb59881",
   "metadata": {},
   "source": [
    "\n",
    "<p>‚ö†Ô∏è 91% is not really a \"probability\"</p>\n",
    "<p>Trees are not <em>calibrated</em> probability classifiers as opposed to logistic regression</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c789d4",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id='Think-about-decision-trees-as-\"orthogonal\"-classifiers'>Think about decision trees as \"orthogonal\" classifiers</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decision_regions\n",
    "\n",
    "plot_decision_regions(X, y, classifier=tree_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de5e3f",
   "metadata": {},
   "source": [
    "\n",
    "<p><img src=\"figures/decision_boundaries.png\" style=\"width:1700px\"></p>\n",
    "<a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">scikit-learn doc</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d564f",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.2-DecisionTreeRegressor\"><code>DecisionTreeRegressor</code></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bed80f",
   "metadata": {},
   "source": [
    "\n",
    "<p>Regression trees consist of predicting a continuous value. They are \"grown\" differently than classification trees.<br>\n",
    "<img src=\"figures/regression_tree_14.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee4b91",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Growing-the-Regression-tree\">Growing the Regression tree</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba92e2a",
   "metadata": {},
   "source": [
    "\n",
    "<p><img src=\"figures/regression_tree_1.png\" style=\"margin:auto\" width=\"900\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ad448",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>Select a threshold </li>\n",
    "<li>Compute the <strong>SSR residuals</strong> between average and true values on both side</li>\n",
    "<li>Compute weighted-average sum of SSR on both sides, weighted by number of datapoints</li>\n",
    "</ul>\n",
    "<p><img src=\"figures/regression_tree_6.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604585e",
   "metadata": {},
   "source": [
    "\n",
    "<p>Compute residuals for next hypothetical threshold\n",
    "<img src=\"figures/regression_tree_7.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ccb503",
   "metadata": {},
   "source": [
    "\n",
    "<p>The threshold that minimizes residuals becomes the Root node of the tree</p>\n",
    "<p><img src=\"figures/regression_tree_8.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8f5a7",
   "metadata": {},
   "source": [
    "\n",
    "<p><img src=\"figures/regression_tree_9.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f041c",
   "metadata": {},
   "source": [
    "\n",
    "<p>We could further split the points below a dosage of 14.5, but we probably shouldnt. Why?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a1fc4",
   "metadata": {},
   "source": [
    "\n",
    "<p>‚ö†Ô∏è We would be <strong>overfitting</strong>!</p>\n",
    "<p><img src=\"figures/regression_tree_10.png\" style=\"margin:auto\" width=\"900\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad7613",
   "metadata": {},
   "source": [
    "\n",
    "<p>Instead, stop splitting and use the average value of points within group to <strong>generalize</strong>.</p>\n",
    "<p><img src=\"figures/regression_tree_12.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fa343",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"‚ö†Ô∏è-Controlling-overfitting\">‚ö†Ô∏è Controlling overfitting</h3><ul>\n",
    "<li><strong>Decision trees must be tuned!!</strong></li>\n",
    "<li>Default parameters will almost certainly overfit</li>\n",
    "<li>Control split</li>\n",
    "<li>Control tree depth</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b9996",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"min_samples_split\"><code>min_samples_split</code></h4><ul>\n",
    "<li>Specify the minimum number of samples required to split an internal node</li>\n",
    "<li>In the example, <code>min_samples_split</code> is set to 7</li>\n",
    "</ul>\n",
    "<p><img  src=\"figures/regression_tree_14.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<p><a href=\"https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw\">John Starmer, 2019</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e382f",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"max_depth\"><code>max_depth</code></h4><ul>\n",
    "<li>The maximum depth of the tree</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc0408",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"min_samples_leaf\"><code>min_samples_leaf</code></h4><ul>\n",
    "<li>The minimum number of samples required to be at a leaf node.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d3962",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"üíª--Variance-illustrated\">üíª  Variance illustrated</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb3678",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "We will use a dataset of <span style=\"color:teal\">**Greenhouse Temperatures** </span>to illustrate all regressions metrics today.\n",
    "<img src=\"figures/greenhouse.jpg\" style=\"width:1500px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reg_data = pd.read_csv('data/greenhouse.csv')\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg_X = reg_data.drop(columns=['Average Temperature'])\n",
    "reg_y = reg_data['Average Temperature']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(reg_X, reg_y, train_size=0.7, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "cv_results = cross_validate(tree, reg_X, reg_y, scoring = \"r2\", cv=30)\n",
    "\n",
    "print(cv_results['test_score'])\n",
    "print('std: ', cv_results['test_score'].std())\n",
    "print('mean: ',cv_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv_results['test_score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffab72",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "<span style=\"color:teal\">**We will use a dataset of pH vs water chemistry for classification** </span><br>\n",
    "<img src=\"figures/ph-scale.jpg\" style=\"width:1500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = pd.read_csv('data/geochem.csv')\n",
    "class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = class_data.drop(columns='pH')\n",
    "y = class_data['pH']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train['Ca_ICP_PCT'],X_train['K_ICP_PCT'], c=y_train)\n",
    "plt.xlabel('Ca_ICP_PCT')\n",
    "plt.ylabel('K_ICP_PCT')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25748a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "@interact(max_depth=IntSlider(min=1, max=15, step=1, value=3))\n",
    "def plot_classifier(max_depth):\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    print(f'Test Accuracy: {clf.score(X_test.values, y_test.values)}')\n",
    "    plot_decision_regions(X_train, y_train, classifier=clf, y_pad=.0,x_pad=.2)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30c75b",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Pros-and-cons-of-Decision-Trees\">Pros and cons of Decision Trees</h2><p>üëç Advantages</p>\n",
    "<ul>\n",
    "<li>No scaling necessary</li>\n",
    "<li>Resistant to outliers</li>\n",
    "<li>Intuitive and interpretable</li>\n",
    "<li>Allow feature selection (see gini-based <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_\"><code>feature_importance_</code></a>)</li>\n",
    "<li>Non-Linear modelisation</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da2257",
   "metadata": {},
   "source": [
    "\n",
    "<p>üëé Disadvantages</p>\n",
    "<ul>\n",
    "<li>High variance (i.e small change in data has a big change in the tree structure)</li>\n",
    "<li>Long training time if grown up to max depth <span class=\"MathJax_Preview\" style=\"color: inherit;\"></span><span class=\"mjx-chtml MathJax_CHTML\" data-mathml='&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\"&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=\"false\"&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow class=\"MJX-TeXAtom-ORD\"&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mrow class=\"MJX-TeXAtom-ORD\"&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mo stretchy=\"false\"&gt;)&lt;/mo&gt;&lt;/math&gt;' id=\"MathJax-Element-4-Frame\" role=\"presentation\" style=\"font-size: 116%; position: relative;\" tabindex=\"0\"><span aria-hidden=\"true\" class=\"mjx-math\" id=\"MJXc-Node-20\"><span class=\"mjx-mrow\" id=\"MJXc-Node-21\"><span class=\"mjx-mi\" id=\"MJXc-Node-22\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.496em; padding-bottom: 0.311em;\">O</span></span><span class=\"mjx-mo\" id=\"MJXc-Node-23\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.434em; padding-bottom: 0.619em;\">(</span></span><span class=\"mjx-msubsup\" id=\"MJXc-Node-24\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\" id=\"MJXc-Node-25\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.249em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" id=\"MJXc-Node-26\" style=\"\"><span class=\"mjx-mrow\" id=\"MJXc-Node-27\"><span class=\"mjx-mi\" id=\"MJXc-Node-28\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">o</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-29\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.496em; padding-bottom: 0.311em;\">b</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-30\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">s</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\" id=\"MJXc-Node-31\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.188em; padding-bottom: 0.311em;\">‚àó</span></span><span class=\"mjx-msubsup MJXc-space2\" id=\"MJXc-Node-32\"><span class=\"mjx-base\"><span class=\"mjx-mi\" id=\"MJXc-Node-33\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">m</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" id=\"MJXc-Node-34\" style=\"\"><span class=\"mjx-mrow\" id=\"MJXc-Node-35\"><span class=\"mjx-mi\" id=\"MJXc-Node-36\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.496em; padding-bottom: 0.496em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-37\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">e</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-38\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">a</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-39\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.311em;\">t</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\" id=\"MJXc-Node-40\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.188em; padding-bottom: 0.311em;\">‚àó</span></span><span class=\"mjx-mi MJXc-space2\" id=\"MJXc-Node-41\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.496em; padding-bottom: 0.311em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-42\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\">e</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-43\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.496em;\">p</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-44\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.434em; padding-bottom: 0.311em;\">t</span></span><span class=\"mjx-mi\" id=\"MJXc-Node-45\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.496em; padding-bottom: 0.311em;\">h</span></span><span class=\"mjx-mo\" id=\"MJXc-Node-46\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.434em; padding-bottom: 0.619em;\">)</span></span></span></span><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msub><mi>N</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>b</mi><mi>s</mi></mrow></msub><mo>‚àó</mo><msub><mi>m</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>‚àó</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>t</mi><mi>h</mi><mo stretchy=\"false\">)</mo></math></span></span><script id=\"MathJax-Element-4\" type=\"math/tex\">O(N_{obs}*m_{feat}*depth)</script></li>\n",
    "<li>Split data \"orthogonally\" to feature directions (use PCA upfront to \"orient\" data)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22a062",
   "metadata": {},
   "source": [
    "\n",
    "# Ensemble Methods\n",
    "<br>\n",
    "<center><img src=\"figures/DALL-E_forest.png\" style=\"width:900px;\">\n",
    "Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>: <i>A photo of a forest in autumn with colorful leaves and many animals in the branches</i>. <br>¬© C√©dric John, 2022.</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b2da1",
   "metadata": {},
   "source": [
    "# Boostrap Aggregation\n",
    "\n",
    "<p>Bootstrap aggregating, also known as Bagging, is the aggregation of multiple versions of a model.</p>\n",
    "<ul>\n",
    "<li>It is a <strong>parallel</strong> ensemble method</li>\n",
    "<li>The aim of bagging is to <strong>reduce variance</strong></li>\n",
    "<li>Each version of the model is called a <strong>weak learner</strong></li>\n",
    "<li>Weak learners are trained on <strong>boostrapped</strong> samples of the dataset</li>\n",
    "</ul>\n",
    "<p><img align=\"center\" src=\"figures/trees_forests1.png\" style=\"margin:auto\" width=\"900\"/></p>\n",
    "<a href=\"https://medium.com/analytics-vidhya/ensemble-models-bagging-boosting-c33706db0b0b\">Silipo, 2020</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6249ed3",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Bootstrapping\">Bootstrapping</h2><ul>\n",
    "<li>Generating \"bootstrapped\" samples from the given dataset</li>\n",
    "<li>The samples are created by randomly drawing the data points with replacement.</li>\n",
    "<li>Features can also be randomly filtered to increase bagging diversity</li>\n",
    "</ul>\n",
    "<p><img align=\"center\" src=\"figures/boostrapping_3.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://towardsdatascience.com/seeing-the-forest-for-the-trees-an-introduction-to-random-forest-41a24fc842ac\">Firmin, 2019</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28a81a",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Random-Forests-=-Bagged-Trees\">Random Forests = Bagged Trees</h2><p>Random Forests are a Bagged ensemble of Decision trees.</p>\n",
    "<p><img align=\"center\" src=\"figures/boostrapping_4.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://towardsdatascience.com/seeing-the-forest-for-the-trees-an-introduction-to-random-forest-41a24fc842ac\">Firmin, 2019</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fdf97",
   "metadata": {},
   "source": [
    "\n",
    "<p>Prediction are averaged (for regression) or voted (classification)</p>\n",
    "<p><img align=\"center\" src=\"figures/random_forest.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://www.researchgate.net/publication/301638643_Electromyographic_Patterns_during_Golf_Swing_Activation_Sequence_Profiling_and_Prediction_of_Shot_Effectiveness\">Verikas et al, 2016</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dda7fe",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"üíª-Sklearn-RandomForestRegressor-and-Classifier\">üíª Sklearn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">RandomForestRegressor</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">Classifier</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "cv_results = cross_validate(forest, reg_X, reg_y, scoring = \"r2\", cv=10)\n",
    "\n",
    "print(cv_results['test_score'])\n",
    "print('mean r2: ',cv_results['test_score'].mean())\n",
    "print('std r2: ', cv_results['test_score'].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "@interact(max_depth=IntSlider(min=1, max=30, step=1, value=3))\n",
    "def plot_classifier(max_depth):\n",
    "    clf = RandomForestClassifier(max_depth=max_depth)\n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "    print(f'Test Accuracy: {clf.score(X_test.values, y_test.values)}')\n",
    "    plot_decision_regions(X_train, y_train, classifier=clf, y_pad=.0,x_pad=.2)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1f90c",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"üíª-Bagging-any-algorithm-!\">üíª Bagging any algorithm !</h2><p>Bagging can be implemented on any algorithm using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\"><code>BaggingRegressor</code></a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\"><code>BaggingClassifier</code></a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "bagged_model = BaggingRegressor(linear_model, n_estimators=50)\n",
    "\n",
    "cv_results = cross_validate(bagged_model, reg_X, reg_y, scoring = \"r2\", cv=10)\n",
    "print('mean r2: ',cv_results['test_score'].mean())\n",
    "print('std r2: ', cv_results['test_score'].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e94bd",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Out-of-Bag-samples\">Out-of-Bag samples</h4><p>Sample not \"drawn\" by the bagging can be used to give a pseudo \"test\" score</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bagged_model = BaggingRegressor(\n",
    "    linear_model,\n",
    "    n_estimators=50,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "bagged_model.fit(reg_X,reg_y).oob_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b5d36",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Pros-and-cons-of-Bagging\">Pros and cons of Bagging</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2abeb",
   "metadata": {},
   "source": [
    "\n",
    "<p>üëç Advantages:</p>\n",
    "<ul>\n",
    "<li>Reduces variance/overfitting</li>\n",
    "<li>Can be applied to any model</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c0b7d",
   "metadata": {},
   "source": [
    "\n",
    "<p>üëé Disadvantages</p>\n",
    "<ul>\n",
    "<li>Complex structure</li>\n",
    "<li>High training time</li>\n",
    "<li>Disregards the performance of individual sub-models</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1150e",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"3.-Boosting\">3. Boosting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edc471",
   "metadata": {},
   "source": [
    "\n",
    "<p>Boosting is a sequential ensemble method made up of weak learners that learn from their predecessor's mistakes.</p>\n",
    "<ul>\n",
    "<li>It is a <strong>sequential</strong> ensemble method</li>\n",
    "<li>The aim of boosting is to <strong>reduce bias</strong></li>\n",
    "<li>Focuses on the observations that are harder to predict</li>\n",
    "<li>The best weak learners are given more weight in the final vote</li>\n",
    "</ul>\n",
    "<p><img align=\"center\" src=\"figures/boosting_bagging3.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "<a href=\"https://medium.com/analytics-vidhya/ensemble-models-bagging-boosting-c33706db0b0b\">Silipo, 2020</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c55aa2",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"3.1-AdaBoost-(Adaptative-Boosting)\">3.1 AdaBoost (Adaptative Boosting)</h2><p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\"><code>AdaBoostRegressor</code></a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\"><code>AdaBoostClassifier</code></a></p>\n",
    "<p><strong>One implementation</strong> of boosting that works particularly well with trees.</p>\n",
    "<p><img align=\"center\" src=\"figures/adaboost_albon.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<a href=\"https://chrisalbon.com/code/machine_learning/trees_and_forests/adaboost_classifier/\">Albon, 2017</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd51cac",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"üíª-AdaBoosted-Trees-in-Sklearn\">üíª AdaBoosted Trees in Sklearn</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e112dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaboost = AdaBoostRegressor(DecisionTreeRegressor(max_depth=3))\n",
    "\n",
    "cv_results = cross_validate(adaboost, reg_X, reg_y, scoring = \"r2\", cv=10)\n",
    "\n",
    "print('mean r2: ',cv_results['test_score'].mean())\n",
    "print('std r2: ', cv_results['test_score'].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f78c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "@interact(n_estimators=[10, 30, 50,100], max_depth=IntSlider(min=1, max=30, step=1, value=2))\n",
    "def plot_classifier(n_estimators, max_depth):\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth),\n",
    "                               n_estimators=n_estimators)    \n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    print(f'Test Accuracy: {model.score(X_test.values, y_test.values)}')\n",
    "    plot_decision_regions(X_train, y_train, classifier=model,  y_pad=.0,x_pad=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80344020",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"3.2-Gradient-Boosting-üî•\">3.2 Gradient Boosting üî•</h2><ul>\n",
    "<li>Only implemented for trees</li>\n",
    "<li>Generally more performant than AdaBoost</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458d0a8",
   "metadata": {},
   "source": [
    "\n",
    "<p>Instead of updating the weights of observations misclassified...</p>\n",
    "<ol>\n",
    "<li>Recursively fit each weak-learner on the <strong>residuals</strong> of the previous one</li>\n",
    "<li>Then <strong>adds</strong> all the predictions of each weak learners (for regression)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c7c0e",
   "metadata": {},
   "source": [
    "\n",
    "<p>For classification, ~ similar principle but in the logit space (if loss chosen is log-loss)</p>\n",
    "<p>üìö Read sklearn <a href=\"https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting\">user guide</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_reg, y_train_reg)\n",
    "print(f'Test Accuracy: {model.score(X_test_reg, y_test_reg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3750f",
   "metadata": {},
   "source": [
    "### XGBOOST\n",
    "\n",
    "* Extreme Gradient Tree Boosting\n",
    "* Dedicated library, optimized for this task\n",
    "* Nice features inspired from Deep Learning\n",
    "\n",
    "<a href=\"https://xgboost.readthedocs.io/en/latest/\">See the XGBOOST Documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b034bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "xgb_reg = XGBRegressor(early_stopping_rounds=15,\n",
    "    eval_metric=r2_score)\n",
    "\n",
    "xgb_reg.fit(\n",
    "    X_train_reg, y_train_reg,\n",
    "    # evaluate loss at each iteration\n",
    "    eval_set=[(X_test_reg, y_test_reg)], \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b27d26",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Pros-and-cons-of-boosting\">Pros and cons of boosting</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3a625",
   "metadata": {},
   "source": [
    "\n",
    "<p>üëç Advantages:</p>\n",
    "<ul>\n",
    "<li>Strong sub-models have more influence in final decision</li>\n",
    "<li>Reduce bias</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f76f5d",
   "metadata": {},
   "source": [
    "\n",
    "<p>üëé Disadvantages:</p>\n",
    "<ul>\n",
    "<li>Computationally expensive (sequential)</li>\n",
    "<li>Easily overfit</li>\n",
    "<li>Sensitive to outliers (too much time spent trying to correctly predict them)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a449fee",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Ensemble-methods-recap\">Ensemble methods recap</h2><p>Ensemble learning combines several base algorithms (e.g. Decision trees) to form one optimized predictive algorithm. Ensemble methods can be broken down into two categories:</p>\n",
    "<ul>\n",
    "<li><strong>Parallel Learners</strong>:  different models are trained in parallel and their predictions are aggregated (e.g. Random Forest)</li>\n",
    "</ul>\n",
    "<ul>\n",
    "<li><strong>Sequential Learners</strong>: different models are trained sequentially and the mistakes of previous models are learned by their successors (e.g. Boosted trees)</li>\n",
    "</ul>\n",
    "<p><img align=\"center\" src=\"figures/boosting_bagging3.png\" style=\"margin:auto\" width=\"1000\"/></p>\n",
    "\n",
    "<a href=\"https://medium.com/analytics-vidhya/ensemble-models-bagging-boosting-c33706db0b0b\">Silipo, 2020</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77be16",
   "metadata": {},
   "source": [
    "# Models Stacking\n",
    "<br>\n",
    "\n",
    "<center><img src=\"figures/DALLE_stacking.png\" style=\"width:900px;\">\n",
    " ¬© C√©dric John, 2022; Image generated with <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a>\n",
    "<br>Prompt: <i>A very high stack of delicious looking pancakes with glass-looking mapple sirup, creamy butter, and colorful rasberries, soft lighting</i>.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69851dac",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55566b",
   "metadata": {},
   "source": [
    "\n",
    "<p>Stacking consists of training different algorithms and aggregating their predictions.</p>\n",
    "<ul>\n",
    "<li>Different algorithms capture different structures of data</li>\n",
    "<li>Combining sometimes enhances the predictive power</li>\n",
    "<li>The results are aggregated by voting (classification) or averaging (regression)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152dd5f",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Simple-aggregation\">Simple aggregation</h3><p>sklearn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\">VotingClassifier</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html\">VotingRegressor</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997d1eb",
   "metadata": {},
   "source": [
    "\n",
    "<p><img align=\"center\" src=\"figures/ensemble_models.png\" style=\"margin:auto\" width=\"1300\"/></p>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/\">G√©ron, 2017-2022</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "forest = RandomForestClassifier(max_depth=2)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators = [(\"rf\", forest),(\"lr\", logreg)],\n",
    "    voting = 'soft', # to use predict_proba of each classifier before voting\n",
    "    weights = [1,1] # to equally weight forest and logreg in the vote\n",
    ")\n",
    "ensemble.fit(X_train.values, y_train.values)\n",
    "print(f'Test Accuracy: {ensemble.score(X_test.values, y_test.values)}')\n",
    "plot_decision_regions(X_train, y_train, classifier=ensemble,  y_pad=.0,x_pad=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77e44f",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Multi-layer-stacking!\">Multi-layer stacking!</h3><p>sklearn <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\">StackingClassifier</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html\">StackingRegressor</a></p>\n",
    "<p>Train a <strong>final estimator</strong> on the predictions of the previous ones</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19564882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "ensemble = StackingClassifier(\n",
    "    estimators = [(\"rf\", RandomForestClassifier(max_depth=2)),\n",
    "                  (\"knn\", KNeighborsClassifier(n_neighbors=10))],\n",
    "    final_estimator = LogisticRegression())\n",
    "\n",
    "ensemble.fit(X_train.values, y_train.values)\n",
    "print(f'Test Accuracy: {ensemble.score(X_test.values, y_test.values)}')\n",
    "plot_decision_regions(X_train, y_train, classifier=ensemble, y_pad=.0,x_pad=.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40258dba",
   "metadata": {},
   "source": [
    "# Suggested Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc08165",
   "metadata": {},
   "source": [
    "## üì∫ Videos \n",
    "#### Short videos from my Undegraduate Machine Learning Classes:\n",
    "* üìº <a href=\"https://youtu.be/FHk46klXgZs?list=PLZzjCZ3QdgQCcRIwQdd-_cJNAUgiEBB_n\">Decision Trees</a>\n",
    "* üìº <a href=\"https://youtu.be/v15RrzYaXqY?list=PLZzjCZ3QdgQCcRIwQdd-_cJNAUgiEBB_n\">RandomForest</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2b78a",
   "metadata": {},
   "source": [
    "## üìö Further Reading \n",
    "* üìñ <a href=\"https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f\">Ensemble Methods in Machine Learning: What are They and Why Use Them?</a> by Evan Lutins\n",
    "* üìñ <a href=\"https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/\">A Gentle Introduction to Ensemble Learning Algorithms</a> by Jason Brown, 2021\n",
    "* üìñ <a href=\"https://towardsdatascience.com/understanding-random-forest-58381e0602d2\">Understanding Random Forest - How the Algorithm Works and Why it Is So Effective</a> by Tony Yiu, 2019\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
