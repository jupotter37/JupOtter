{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2d0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df41c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
      "     ------------------------------------- 807.5/807.5 kB 50.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
      "     --------------------------------------- 66.6/66.6 kB 64.5 kB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "     ------------------------------------ 366.0/366.0 kB 110.0 kB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Collecting langchain-core<0.2,>=0.1.29\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
      "     ------------------------------------ 256.9/256.9 kB 175.4 kB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Collecting langchain-community<0.1,>=0.0.25\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 44.3 kB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "     ------------------------------------ 395.2/395.2 kB 190.9 kB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "     --------------------------------------- 76.9/76.9 kB 63.7 kB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "     -------------------------------------- 50.7/50.7 kB 172.0 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "     --------------------------------------- 49.4/49.4 kB 69.6 kB/s eta 0:00:00\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     --------------------------------------- 53.0/53.0 kB 29.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.5.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.9.15-cp39-none-win_amd64.whl (135 kB)\n",
      "     ------------------------------------ 135.9/135.9 kB 108.6 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp39-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 114.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: typing-extensions, tenacity, packaging, orjson, multidict, jsonpointer, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 multidict-6.0.5 orjson-3.9.15 packaging-23.2 pydantic-2.6.3 pydantic-core-2.16.3 tenacity-8.2.3 typing-extensions-4.10.0 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a13bfaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "     -------------------------------------- 227.4/227.4 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.6/75.6 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from openai) (2.6.3)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.8/77.8 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76351bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586c6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960a5f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3758f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b72a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54acf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36926de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashkumar Dubey\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9ee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001A6E424DBB0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001A6E425E610>, temperature=0.5, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0154fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------ 232.6/232.6 kB 547.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\yashkumar dubey\\anaconda3\\lib\\site-packages (from PyPDF2) (4.10.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1a358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d196117",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bbcb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f4b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"allquiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "612c4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b5e893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28ff023",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=LLMChain(llm=llm, prompt=prompt2, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "648f50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text=SequentialChain(chains=[quiz, review], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"allquiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51766a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fad9a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = 'utf-8'\n",
    "with open(file_path, 'r', encoding=enc) as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5b7a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.\\n\\nThe way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).\\n\\nClassical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.\\n\\nNeural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94aed240",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "100ac174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf76db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"biology\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38ecd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yashkumar Dubey\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:    Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.\n",
      "\n",
      "The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).\n",
      "\n",
      "Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.\n",
      "\n",
      "Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for biology students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:    Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.\n",
      "\n",
      "The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com).\n",
      "\n",
      "Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.\n",
      "\n",
      "Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for biology students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response=generate_text(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c6a1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"What is the relationship between deep learning and machine learning?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Deep learning is a sub-field of machine learning\",\n",
      "            \"b\": \"Machine learning is a sub-field of deep learning\",\n",
      "            \"c\": \"Deep learning and machine learning are completely separate fields\",\n",
      "            \"d\": \"Deep learning and machine learning are the same thing\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"What type of data can deep learning algorithms ingest?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Only labeled datasets\",\n",
      "            \"b\": \"Only structured data\",\n",
      "            \"c\": \"Unstructured data in its raw form\",\n",
      "            \"d\": \"No data at all\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"What is the main difference between deep machine learning and classical machine learning?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Deep machine learning requires more human intervention\",\n",
      "            \"b\": \"Classical machine learning can handle unstructured data\",\n",
      "            \"c\": \"Deep machine learning can automatically determine features from unstructured data\",\n",
      "            \"d\": \"Classical machine learning is faster than deep machine learning\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"What is the purpose of a neural network's hidden layers?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"To store data\",\n",
      "            \"b\": \"To make decisions\",\n",
      "            \"c\": \"To connect input and output layers\",\n",
      "            \"d\": \"To process information and extract features\"\n",
      "        },\n",
      "        \"correct\": \"d\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"mcq\": \"How many layers does a neural network need to have to be considered a deep learning algorithm?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"1\",\n",
      "            \"b\": \"2\",\n",
      "            \"c\": \"3\",\n",
      "            \"d\": \"More than 3\"\n",
      "        },\n",
      "        \"correct\": \"d\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response['allquiz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584f159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
