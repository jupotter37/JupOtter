{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, the author introduces a few data manipulations.  These skills are necessary for any person entering in data science/machine learning.  Using PyTorch, and not MXnet, I had developed the same code/results showed in the book.  \n",
    "\n",
    "Linear algebra is the base of machine learning.  It gives us a robust set of techniques for working with tabular data.  Matrix operation is the core of machine learning,  principally using algorithms like backpropagation to optimization ours models parameters to fit our data as best possible, determining which way to optimize parameters of the models requires a little bit of calculus.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, data manipulation has two core tasks:\n",
    "- Acquire data\n",
    "- Process data\n",
    "Using the tensors of Pytorch, this kind of tool is necessary to store our data.  The tensors provide a few key advantages. First, it provides asynchronous computations using GPU and CPU.  Secondly, tensors can provide support for automatic differentiation. It is necessary for backpropagation and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter is focusing on getting you up and running with the basic functionality.  The next two chapters will be more concentrate on the math behind element-wise, normal distributions, and other essential operations.  In section 17.2, we have more in-depth mathematical content to be explored. <br><br>\n",
    "First, we need to import the Torch module.  In Torch we have tensors. Tensors are numerical arrays. It is like NDArrays of MXNet and can be stored in CPU or GPU. Tensors with two axes correspond to matrices, and arrays with more than two axes don't have any unique names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable x contains a tensor one-dimensional with length 12.  Another way to get the shape of a tensor is by using propriety .shape! If we have a two-dimensional array, the shape will be a tensor with two numbers! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function reshape allow us to change the shape of the tensors.  You can transform the one-dimensional tensor y into a matrix with shape (3,4).  If you don't want to make all calculations of dimensions, you can omit one dimension using the number -1 and writer the other dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "print(x.reshape((3,4)))\n",
    "print(x.reshape((-1,4)))\n",
    "print(x.reshape((3,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pytorch*** allows us to initialize tensors in multiple ways.  For example, you can initialize tensors with one's, zero's, or grab catch from memory.  The last method is more performative, but not too useful, because of the big numbers. Take a look of numbers [4.5710e-41, -2.4891e-37,  3.0899e-41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0.0000e+00, 0.0000e+00, 7.0065e-45, 0.0000e+00, 8.9683e-44])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(5))\n",
    "print(torch.zeros(5))\n",
    "print(torch.empty(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can randomly sample numbers from known distributions like gaussian or exponential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1.4635]), tensor([-0.7932]), tensor([-0.9193]), tensor([1.2948]), tensor([0.3475])]\n",
      "[tensor([0.0188]), tensor([0.8526]), tensor([0.6789]), tensor([1.2094]), tensor([0.0985])]\n"
     ]
    }
   ],
   "source": [
    "normal = torch.distributions.normal.Normal(torch.tensor([0.0]),torch.tensor([1.0]))\n",
    "exponential = torch.distributions.exponential.Exponential(torch.tensor([1.0]))\n",
    "sample_n = [normal.sample() for _ in range(5)]\n",
    "sample_e = [exponential.sample() for _ in range(5)]\n",
    "print(sample_n)\n",
    "print(sample_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code snippet above, we created five samples of normal distributions with mean = 0 and std = 1($\\mathcal{N}(0,1)$) and five samples with exponential with rate = 1($\\lambda = 1$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([0, 1, 2, 3])\n",
      "y =  tensor([2, 2, 2, 2])\n",
      "x + y =  tensor([2, 3, 4, 5])\n",
      "x - y =  tensor([-2, -1,  0,  1])\n",
      "x * y =  tensor([0, 2, 4, 6])\n",
      "x / y =  tensor([0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "y = torch.ones_like(x) * 2\n",
    "print(\"x = \",x)\n",
    "print(\"y = \",y)\n",
    "print(\"x + y = \", x + y)\n",
    "print(\"x - y = \", x - y)\n",
    "print(\"x * y = \", x * y)\n",
    "print(\"x / y = \", x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in Pytorch are element-wise. But, if you pay attention to div operation, it doesn't look right correct? It is because x and y are Long type tensors.  You have to transform these tensors in Float type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([0., 1., 2., 3.], dtype=torch.float64)\n",
      "y =  tensor([2., 2., 2., 2.], dtype=torch.float64)\n",
      "x + y =  tensor([2., 3., 4., 5.], dtype=torch.float64)\n",
      "x - y =  tensor([-2., -1.,  0.,  1.], dtype=torch.float64)\n",
      "x * y =  tensor([0., 2., 4., 6.], dtype=torch.float64)\n",
      "x / y =  tensor([0.0000, 0.5000, 1.0000, 1.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "y = torch.ones_like(x) * 2\n",
    "\n",
    "# Transformation\n",
    "x = x.double()\n",
    "y = y.double()\n",
    "\n",
    "print(\"x = \",x)\n",
    "print(\"y = \",y)\n",
    "print(\"x + y = \", x + y)\n",
    "print(\"x - y = \", x - y)\n",
    "print(\"x * y = \", x * y)\n",
    "print(\"x / y = \", x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many operations can be applied element-wise, such as exponentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000,  2.7183,  7.3891, 20.0855], dtype=torch.float64)\n",
      "tensor([ 1.0000,  2.7183,  7.3891, 20.0855], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x = x.double()\n",
    "print(x.exp())\n",
    "print(torch.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***torch.mm*** allow us to made matrix operations. In the next code snippet, we create two matrices and transpose the second to make a dot multiplication between x and y. x has the shape (3,4), and y transpose has the shape(4,3), then creating a matrix with shape (3,3): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[2, 1, 4],\n",
      "        [1, 2, 3],\n",
      "        [4, 3, 2],\n",
      "        [3, 4, 1]])\n",
      "tensor([[ 18,  20,  10],\n",
      "        [ 58,  60,  50],\n",
      "        [ 98, 100,  90]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "y = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "print(y.t())\n",
    "print(torch.mm(x,y.t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another operations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 2,  1,  4,  3],\n",
      "        [ 1,  2,  3,  4],\n",
      "        [ 4,  3,  2,  1]])\n",
      "tensor([[ 0,  1,  2,  3,  2,  1,  4,  3],\n",
      "        [ 4,  5,  6,  7,  1,  2,  3,  4],\n",
      "        [ 8,  9, 10, 11,  4,  3,  2,  1]])\n",
      "tensor([[0, 1, 0, 1],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]], dtype=torch.uint8)\n",
      "tensor(66)\n",
      "22.494443758403985\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((x,y),0)) # Concatenation along axes 0\n",
    "print(torch.cat((x,y),1)) # Concatenation along axes 0\n",
    "print(x == y) # Binary statement: if x(i,j) == y(i,j) than 1, else 0\n",
    "print(x.sum())\n",
    "print(x.double().norm().item()) # Only for floating-point types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function .item() transform the tensor into python scalar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Broadcast Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]]) torch.Size([3, 1])\n",
      "tensor([[0, 1]]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "print(a,a.shape)\n",
    "print(b,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The broadcast mechanism is similar to Numpy. First, replicate the elements in rows and columns, so the two tensors have the same shape, and then apply the operations by elements.  Above Pytorch replicate column of tensor a and row b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Indexing and slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Python array, elements in tensor can be accessed by its index.  One example, x[0:3] select the first element to last - 1 element, in that case, items [0,1,2] will be chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1,4)[1:3] # Matrix: Selects second and third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1,4)[1:3,0:2] # Matrix: Selects second and third row and first and second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5, -1,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [-2, -2, -2, -2],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x_diff = x.reshape(-1,4)\n",
    "x_diff[1,2] = -1\n",
    "print(x_diff)\n",
    "x_diff[1,:] = -2\n",
    "print(x_diff) #Assign multiple times in the second row and all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write elements of a matrix. Like above! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5 Saving memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving memory is useful when we have restricted memory.  The last operations made in this notebooks, we always allocate new memory to host results.  In the example below,  y = x + y, the matrix pointed to y will be different after you get the result. Python id() function gives us the exact address of the referenced object in memory.  First, evaluates y + x, allocate new memory for the result and then subsequently redirects y to point at this new location in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(y)\n",
    "y = y.reshape(12) + x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using inplace operations, we can have the same space of memory to store our results and avoid memory leak and unnecessarily allocation of memory.  Using zeros_likes, we clone the shape of a matrix and allocate zeros values into this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z): 140120981356120\n",
      "id(z): 140120981356120\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros_like(y)\n",
    "print('id(z):', id(z))\n",
    "z[:] = x + y\n",
    "print('id(z):', id(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make even better use of memory, because of x + y here still allocate a temporary buffer to store x + y, we can directly invoke torch operations, avoiding temporary buffers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(z)\n",
    "torch.add(x, y, out=z)\n",
    "id(z) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to make in-place operations are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(x): 140120981561848\n",
      "tensor([0, 2, 4, 6]) id(x): 140120981561848\n",
      "id(x): 140121834222216\n",
      "tensor([0, 2, 4, 6]) id(x): 140121834222216\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "y = torch.arange(4)\n",
    "print(\"id(x):\", id(x))\n",
    "x += y\n",
    "print(x,\"id(x):\",id(x))\n",
    "x = torch.arange(4)\n",
    "y = torch.arange(4)\n",
    "print(\"id(x):\",id(x))\n",
    "x.add_(y)\n",
    "print(x,\"id(x):\",id(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! Careful !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations for autograd is ***dangerous!*** <br>\n",
    "https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6 Mututal Transformation of NDArray and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last subsection is only a minor and easy example of converting a numpy array to tensor and vice-versa. The converted arrays don't share the same memory, because you don't want the Torch or numpy waits for each other to make operation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "y = np.arange(5)\n",
    "n_x = x.data.numpy()\n",
    "t_x = torch.from_numpy(y)\n",
    "print(type(n_x))\n",
    "print(type(t_x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.7 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [1, 2, 3, 4],\n",
      "        [4, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "y = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x < y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x > y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0],\n",
      "         [1],\n",
      "         [2]],\n",
      "\n",
      "        [[3],\n",
      "         [4],\n",
      "         [5]]])\n",
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape((2,3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [1, 2],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[3, 4],\n",
       "         [4, 5],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5,5,2,1)\n",
    "y = torch.empty(    3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-cd60f97aa77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting operations have to respect two rules:\n",
    "- The correspondent dimensions of vectors are equal, or\n",
    "- One of the correspondent dimensions are 1\n",
    "\n",
    "In the case above, 2 $\\neq$ 3, so the operation is impossible! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[2, 1, 4],\n",
      "        [1, 2, 3],\n",
      "        [4, 3, 2],\n",
      "        [3, 4, 1]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "id(out_mm): 140120977403120\n",
      "tensor([[ 19,  21,  11],\n",
      "        [ 59,  61,  51],\n",
      "        [ 99, 101,  91]])\n",
      "id(out_mm): 140120977403120\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12).reshape((3,4))\n",
    "b = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "c = torch.ones(9).reshape((3,3)).long()\n",
    "print(a)\n",
    "print(b.t())\n",
    "print(c)\n",
    "out_mm = torch.zeros_like(c)\n",
    "print(\"id(out_mm):\",id(out_mm))\n",
    "torch.mm(a, b.t(), out = out_mm)\n",
    "torch.add(out_mm, c,  out = out_mm)\n",
    "print(out_mm)\n",
    "print(\"id(out_mm):\",id(out_mm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following sections will have some basics linear algebra. Algebra is one of the cores of machine learning concepts. Mathematical notations, codes, and explanations will fill the next sections of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalars are numbers in ${\\rm I\\!R}$ space that can be represented in mathematical notation using ordinary lower-case letters (x, y, z).  In equation like this: x = 10 + y, 10 is a scalar and x e y are variables representing unknown scalars.  Another way to said that scalars are in ${\\rm I\\!R}$ is a math notation x $\\in$ R, the symbol $\\in$ represents \"in\" and denotes membership in a set. <br>\n",
    "We can create scalars in Pytorch using torch.tensor. But, we have to pay attention to what type of scalar creates. The type of scalars makes a difference for training and evaluate models. Integers scalars are suitable for labels and classification, while float scalars are useful for regression.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.LongTensor\n",
      "x + y =  tensor([1.])\n",
      "x * y =  tensor([0.1600])\n",
      "x / y =  tensor([0.2500])\n",
      "x ** y =  tensor([0.2759])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'exponent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e0aad23b93bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x / y = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x ** y = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x ** y = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Differs type can be manipulate together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'exponent'"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.2])\n",
    "b = torch.tensor([1])\n",
    "c = torch.tensor([0.8])\n",
    "print(a.type())\n",
    "print(b.type()) # Long int\n",
    "print('a + c = ', a + c)\n",
    "print('a * c = ', a * c)\n",
    "print('a / c = ', a / c)\n",
    "print('a ** c = ', torch.pow(a,c))\n",
    "print(a + b) # Differs type can be manipulate together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors are a list of scalars. For example: [3.0, 0.4, 1.2]. Each scalar in a vector is known as entries or component.  Features in machine learning are represented using vectors. If the problem is predicting the value of a house, the features vector can be numbers of rooms, numbers of bathrooms, size, etc. Vectors are represented in math notation using lower-case bold letters, like this: (**x, v, b**).  In ***Pytorch*** vectors are tensors with multiple scalars, and these are in the same type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "print(x)\n",
    "print(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensors are zero-based numbering similar to lists and arrays.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Dimensionality, length and shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors have length, in another way, numbers of components.  In math notation vectors with n elements are in R^n-dim spaces.  So, here, we have some confuse concepts.  In python, the function len(), return the size of a vector, but, this size, can be accessed using the attribute shape. Tensors vectors in Pytorch only have one dimension, so, the attribute shape will return a tuple with one number. Matrix returns a tuple with two numbers and goes on. Scalars have 0-dimension. \n",
    "<br>\n",
    "*Note that the word dimension is overloaded and this tends to confuse people. Some use the dimensionality\n",
    "of a vector to refer to its length (the number of components). However, some use the word dimensionality to\n",
    "refer to the number of axes that an array has. In this sense, a scalar would have 0 dimensions, and a vector\n",
    "would have one dimension.\n",
    "To avoid confusion, when we say a 2D array or 3D array, we mean an array with 2 or 3 axes. Pag-45* **Dive into deep learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5])\n",
      "tensor([12, 24, 36])\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([10,20,30])\n",
    "print(x + a)\n",
    "print(a * x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices are 2D vectors and are represented by capital letters(*A, B, C*).  Matrices are a table, and each component are $a_{ij}$ belongs to i-th row and j-th column.  \n",
    "$$ \\begin{pmatrix}\n",
    "a_{11} & a_{12} & a_{13} \\\\ \n",
    "a_{21} & a_{22} & a_{23} \\\\ \n",
    "\\end{pmatrix} $$\n",
    "<br> \n",
    "In Pytorch, matrices will create by specifying the two components of a tuple(n,m). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.ones((2,3))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using reshape to modify a tensor vector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.ones(6)\n",
    "print(m)\n",
    "m.reshape((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices are useful to store tabular with rows representing samples and columns representing features. In the example of house cited above, one row is a house with its features in columns. In Pytorch an entire row is accessed using one number(desire row) and colons. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.arange(6).reshape((2,3))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,1] # Same for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix can be transposed using t() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Just as vectors generalize scalars, and matrices generalize vectors, we can actually build data structures\n",
    "with even more axes. Tensors give us a generic way of discussing arrays with an arbitrary number of axes.\n",
    "Vectors, for example, are first-order tensors, and matrices are second-order tensors. <br>\n",
    "Using tensors will become more important when we start working with images, which arrive as 3D data\n",
    "structures, with axes corresponding to the height, width, and the three (RGB) color channels. Pag-46* **Dive into deep learning**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([2, 3, 4])\n",
      "X = tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(24).reshape((2, 3, 4))\n",
    "print('X.shape =', X.shape)\n",
    "print('X =', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Basic properties of tensor arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise operations don't change the shape of tensors. It same happens a scalar multiplies tensors. In math, these properties called AXPT operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "x = torch.ones(3)\n",
    "y = torch.ones(3)\n",
    "print(x.shape)\n",
    "print((a * x).shape)\n",
    "print((x + y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Sums and means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some operations we can do with matrices and arrays. We can call *.sum()* to sum elements of an array or a matrix. We can calculate the mean of an array or a matrix using the function *.mean()*.  The symbol that represents sum is $\\sum$.  To express the sum of the vector components u with dimension d; we can write $\\sum_{i=1}^{d}a_{i}$. Mean is $\\frac{1}{d}\\sum_{i=1}^{d}a_{i}$. Sum of a marix $\\sum_{i=1}^{d_1}\\sum_{j=1}^{d_2}a_{ij}$. Mean of a matrix $\\frac{1}{d_1 \\times d_2}\\sum_{i=1}^{d_1}\\sum_{j=1}^{d_2}a_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n",
      "tensor(2.)\n",
      "tensor(66.)\n",
      "tensor(5.5000)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "b = torch.arange(12).reshape((3,4)).float() # Only calculate mean of float type\n",
    "print(a.sum()) \n",
    "print(a.mean())\n",
    "print(b.sum())\n",
    "print(b.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others possible operations:\n",
    "- std(Standard Deviation): *.std()*\n",
    "- var(Variance): *.var()*\n",
    "- unique(Unique values): *.unique()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3,1,4,1,1,1,5,6])\n",
    "a.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Dot products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is an essential operation in machine learning.  Given two vectors <b>u</b> and <b>v</b>, which has the same length,  we multiplication elements with the correspondent index and sum the multiplications. So the returned result is a scalar.  \n",
    "$$a \\cdot b = \\sum_{i}^{d}a_{i}b_{i} = a_{1}b_{1} + a_{2}b_{2} + \\cdots + a_{n}b_{n}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4.])\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(5).float()\n",
    "b = torch.tensor([2]).repeat_interleave(5).float() # Repeat elements of a vector N times\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty([])\n",
    "torch.dot(a,b,out=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a * b) # Another way "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are special cases when the dot product has context.  For example, when we have a vector with values that sum to 1 and are non-negative, and another vector, the dot product between these two vectors are a weighted average. \n",
    "$$ \\sum_{i}^{d}w_{i} = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.9 Matrix-vector products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix is a set of vectors. The matrix below can be represented in terms of its row vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} & a_{13}  \\\\ \n",
    "a_{21} & a_{22} & a_{23}  \\\\ \n",
    "a_{31} & a_{32} & a_{33}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Representa as: \n",
    "$$ A = \\begin{pmatrix}\n",
    "a_{1}^{T} \\\\\n",
    "a_{2}^{T} \\\\\n",
    "a_{3}^{T} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$ x = \\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "x_{3} \n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each $a_{i}^{T} \\in {\\rm I\\!R}^{m}$ is row representing the <i>i-th</i> row of matrix $A$. The result's vector of the multiplication between A and <b>x</b> is <b>y</b> $\\in {\\rm I\\!R}^{n}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A\\textbf{x} = \\begin{pmatrix}\n",
    "a_{1}^{T} \\\\\n",
    "a_{2}^{T} \\\\\n",
    "a_{3}^{T} \n",
    "\\end{pmatrix} \\begin{pmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "x_{3} \n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "a_{1}^{T}\\textbf{x} \\\\\n",
    "a_{2}^{T}\\textbf{x} \\\\\n",
    "a_{3}^{T}\\textbf{x} \n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see the the multiplication by a matrix $A  \\in {\\rm I\\!R}^{n\\times m}$ as a tranformation that projects vectors from ${\\rm I\\!R}^{m}$ to ${\\rm I\\!R}^{n}$. \n",
    "\n",
    "In pytorch we use the function *.mv()*, this means matrix-vector product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*These transformations turn out to be remarkably useful. For example, we can represent rotations as multi-\n",
    "plications by a square matrix. As we will see in subsequent chapters, we can also use matrix-vector products\n",
    "to describe the calculations of each layer in a neural network. Pag-49* **Dive into deep learning**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([2., 2., 2.])\n",
      "tensor([ 6., 24., 42.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(9).reshape((3,3)).float()\n",
    "b = torch.tensor([2]).repeat_interleave(3).float()\n",
    "result = torch.empty([])\n",
    "print(a)\n",
    "print(b)\n",
    "result = torch.mv(a,b,out=result) # .mv\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.10 Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-matrix is similar to the section above. So if we have two matrices $A \\in {\\rm I\\!R}^{n\\times m}$ e $B \\in {\\rm I\\!R}^{m\\times k}$, the result is $C \\in {\\rm I\\!R}^{n\\times k}$ .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "tensor([[10., 13.],\n",
      "        [28., 40.],\n",
      "        [46., 67.],\n",
      "        [64., 94.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(12).reshape((4,3)).float()\n",
    "b = torch.arange(6).reshape((3,2)).float()\n",
    "result = torch.empty([])\n",
    "torch.mm(a,b,out=result)\n",
    "print(result.shape) # 4x3 and 3x2 transform to 4x2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.11 Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norms are essential concepts in machine learning. In machine learning, we are often trying to solve optimization problems:  Maximize the probability of observed data. Create representations of items likes words, sentences,  books, texts, products, in way that similar items have representations that minimize their distances.  These objectives are expressed using norms.  \n",
    "Norms can calculate how \"big\" is a vector or matrix. The representation of a norm is: $\\| \\cdot \\|$. So the norm of vector or matrix is: $\\| \\textbf{x}\\| - \\| A\\| $ respectivily.\n",
    "<br>\n",
    "All norms has to satisfy these properties:\n",
    "- $\\| \\alpha A\\|= |\\alpha|\\| A\\|$ (We multiply absolute value of scalar to norm)\n",
    "- $\\| A + B \\| \\leq \\| A \\| + \\| B \\|$ (Triangle inequality)\n",
    "- $\\| A \\| \\geq 0$ (All norms must be non-negative)\n",
    "- If $ \\forall i,j,a_{ij} = 0$, then $\\| A \\| = 0$ (The smallest norm is achieved by a matrix or vector consisting of all zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to have zero norm with non-zero matrices, but is impossible to have norm non-zero to zero matrices.\n",
    "\n",
    "\n",
    "*If you remember Euclidean distances (think Pythagoras’ theorem) from grade school, then non-negativity\n",
    "and the triangle inequality might ring a bell. You might notice that norms sound a lot like measures of\n",
    "distance. <br>\n",
    "In fact, the Euclidean distance $\\sqrt{x_{1}^{2} + \\cdots + x_{n}^{2}} $ is a norm. Specifically it is the L2-norm. An analogous\n",
    "computation, performed over the entries of a matrix, e.g. $\\sqrt{\\sum_{i,j}a_{i,j}^{2}}$ is called the Frobenius norm. More\n",
    "often, in machine learning we work with the squared L2 norm (notated $L_{2}^{2}$). We also commonly work with\n",
    "the L1 norm. The L1 norm is simply the sum of the absolute values. It has the convenient property of placing. Pag 50* **Dive into deep learning**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.12 Basic Vector Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Addtive axioms (x,y,z are vectors)\n",
    "    - x + y = y + x\n",
    "    - (x + y) + z = x + (y + z)\n",
    "    - 0 + x = x + 0 =  x\n",
    "    - (-x) + x = x + (-x) = 0\n",
    "- Multiplicative axioms (x is a vector and a, b are scalars)\n",
    "    - 0 $\\cdot$ x = 0\n",
    "    - 1 $\\cdot$ x = x\n",
    "    - (ab)x = a(bx)\n",
    "- Distributive axioms (x and y are vectors and a, b are scalars)\n",
    "    - a(x + y) = ax + ay\n",
    "    - (a + b)x = ax + bx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.13 Special matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Symmetric Matrix</b>: • Symmetric Matrix These are matrices where the entries below and above the diagonal are the same.\n",
    "In other words, we have that $M^{T} = M$. An example of such matrices are those that describe pairwise\n",
    "distances, i.e. $M_{ij} =\\|x_{i} −x_{j}\\|$. Likewise, the Facebook friendship graph can be written as a symmetric matrix where $M_{ij} = 1$ if i and j are friends and $M_{ij} = 0$ if they are not. Note that the Twitter graph\n",
    "is asymmetric - $M_{ij} = 1$, i.e. i following j does not imply that $M_{ji} = 1$, i.e. j following i.\n",
    "- <b>Antisymmetric Matrix</b>: These matrices satisfy $M^{T} = −M$. Note that any square matrix can always be decomposed into a symmetric and into an antisymmetric matrix by using $M = \\frac{1}{2}(M + M^{T}) + \\frac{1}{2}(M - M^{T}).$ \n",
    "- <b>Diagonally Dominant Matrix</b>: These are matrices where the off-diagonal elements are small relative\n",
    "to the main diagonal elements. In particular we have that $M_{ii} \\geq \\sum_{j \\neq i}M_{ij}$ and $M_{ii} \\geq \\sum_{j \\neq i} M_{ji}$. If a matrix has this property, we can often approximate M by its diagonal. This is often expressed as diag(M).\n",
    "• <b>Positive Definite Matrix</b> These are matrices that have the nice property where $x^{⊤}Mx > 0$ whenever $x \\neq 0$. Intuitively, they are a generalization of the squared norm of a vector $\\|x \\|^{2} = x^{⊤}x$. It is easy\n",
    "to check that whenever $M = A^{⊤}A$, this holds since there $x^{⊤}Mx = x^{⊤}A^{⊤}Ax = \\|Ax\\|^{2}$. There is a\n",
    "somewhat more profound theorem which states that all positive definite matrices can be written in form.\n",
    "\n",
    "These concepts above are essential to understand better machine learning. These properties and special matrices are widely used in fundamental machine learning concepts. Only go further if you understand all the concepts above.  Pag 52 **Dive into deep learning**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Automati Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation is one of the best tools that \n",
    "PyTorch contains. It frees the users to calculate the gradient by ourself.  The package <i>autograd</i> provides automatic differentiation for all operations on <i>Tensors</i>. The graph of operations is defined-by-run, so the backpropagation is defined by how your code executes, and that every single operation can be different. \n",
    "\n",
    "Train a neural network is updating the weights, so they get better each iteration. Minimizing a <i>loss function</i> is the way we can know if the neural network will be successful. That <i>loss function</i> gives us the directions, whether the weights need <b>increases</b> or <b>decreases</b> according to actual values. So, in that case, the <i>loss function</i> needs to be differentiable concerning our parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 A simple example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensors if you set the attribute <i>requires_grad</i> to True, then all operations will be tracked.  And after these operations, using the <i>function backward()</i>,  you will have all the gradients computed automatically. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float()\n",
    "x.requires_grad_(True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y.backward()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pay attention, there is attribute <i>grad_fn</i>; this attribute is an object of class <i>Function</i>. This class is responsible for tracking all operations made with <i>tensors</i>. In our case, the operation dot creates an op: grad_fn=MulBackward0, or in other words, multiplication of two vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad - (4 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of the function $y = x^{T}x$ with respect to <b>x</b> should be 4x. The above operation shows it to us. <br>\n",
    "If you make another operation with <b>x</b>, the grad attribute will have other values because of overwritten. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  4.2673,  8.5345, 12.8018])\n"
     ]
    }
   ],
   "source": [
    "y = x.norm()\n",
    "y.backward()\n",
    "print(x.grad) # Different from the book, because of the grads sum itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Backward fo Non-scalar Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the <b>y</b> is not a scalar anymore, autograd could not compute full Jacobian directly because it is too complex to calculate. In both machine learning and deep learning, we only compute the gradient of a <i>loss function</i>, whose values are often scalars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Detach Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Detach</i> is a function to stop tracking operations. We can use this to consume less memory from GPU or CPU, preventing future computation from being tracked.  \n",
    "Another way is to put your code inside a <i>\"with torch.no_grad()\"</i>. This can be particularly helpful when evaluating model because the model may have trainable parameters with requires_grad=True, but for which we don't need the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.],requires_grad=True)\n",
    "y = x * x \n",
    "u = y.detach()\n",
    "z = u * x\n",
    "z.backward()\n",
    "x.grad - u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In code above, the following backward computes $ \\frac{\\partial u^{2}x}{\\partial x}$ with $u = x$ instead of $ \\frac{\\partial x^{3}}{\\partial x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the computation of <b>y</b> is still recorded, we can call <i>y.backward()</i> to get $\\frac{\\partial y}{\\partial x} = 2x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.],requires_grad=True)\n",
    "y = x * x \n",
    "u = y.detach()\n",
    "z = u * x\n",
    "# z.backward() If you maintain this line the grad will be summed \n",
    "y.backward()\n",
    "x.grad - 2*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.], requires_grad=True)\n",
      "tensor([25.])\n"
     ]
    }
   ],
   "source": [
    "# Other way\n",
    "with torch.no_grad():\n",
    "    x = torch.tensor([5.],requires_grad=True)\n",
    "    print(x)\n",
    "    y = x * x\n",
    "    print(y) # Take a look, y don't have requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Head gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use detach to break computations into several parts.  Assume  $u = f(x)$ and $z = g(x)$, by chain rule we have $\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x}$. To compute $\\frac{\\partial z}{\\partial u}$, we can first detach u from the calculation and then call z.backward() to calculate the first term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.]), None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.],requires_grad=True)\n",
    "y = torch.ones(1) * 2\n",
    "y.requires_grad_(True)\n",
    "u = x * y\n",
    "v = u.detach()\n",
    "v.requires_grad_(True)\n",
    "z = v + x\n",
    "z.backward()\n",
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>We can call <i>u.backward()</i> to compute the second term, but pass the first term as the head gradients to multiply both terms so that <b>x.grad</b> will contains $\\frac{\\partial z}{\\partial x}$ instead of $\\frac{\\partial u}{\\partial x}.$ Pag-56 </i> <b>Dive nto Deep learning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.]), tensor([5.]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.],requires_grad=True)\n",
    "y = torch.ones(1) * 2\n",
    "y.requires_grad_(True)\n",
    "u = x * y\n",
    "v = u.detach()\n",
    "v.requires_grad_(True)\n",
    "z = v + x\n",
    "z.backward()\n",
    "x.grad, y.grad\n",
    "u.backward(v.grad)\n",
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 Training mode and prediction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training mode is implicit. We will see later when we train the models. But, for curiosity,  *model.train() - *Not necessary* -  put models into training mode and *model.eval()* put models into prediction mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.6 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4.,  8., 12.])\n",
      "tensor([ 0.,  8., 16., 24.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float()\n",
    "x.requires_grad_(True)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y.backward(retain_graph=True)\n",
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4.,  8., 12.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-ee386616e645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "#### If you not put retain graph, this happens\n",
    "x = torch.arange(4).float()\n",
    "x.requires_grad_(True)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm().item() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum().item() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "\n",
    "a = torch.normal(torch.tensor([1.]))\n",
    "a.requires_grad_(True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "print(a.grad == (d / a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[937.7441],\n",
      "        [933.7056]], grad_fn=<MulBackward0>)\n",
      "tensor([[256.],\n",
      "        [256.]])\n",
      "tensor([[1],\n",
      "        [1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "n = torch.distributions.Normal(torch.tensor([4.0]), torch.tensor([0.5]))\n",
    "a = n.sample((2,))\n",
    "a.requires_grad_(True)\n",
    "d = f(a)\n",
    "print(d)\n",
    "d.sum().backward() # Need to sum because d is vector and not a scalar. \n",
    "print(a.grad) \n",
    "print(a.grad == (d / a)) # Verifying the grad: Seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.])\n",
      "5.986322548778844\n",
      "1.002284783539428\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def f(a):\n",
    "    b = a ** 2\n",
    "    return b\n",
    "\n",
    "def derive(function, value):\n",
    "    h = 0.0000000000001\n",
    "    top = function(value + h) - function(value)\n",
    "    bottom = h\n",
    "    slope = top / bottom\n",
    "    # Returns the slope to the third decimal\n",
    "    return slope\n",
    "\n",
    "a = torch.tensor([3.])\n",
    "a.requires_grad_(True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "print(a.grad)\n",
    "print(derive(f,a.item()))\n",
    "print(a.grad.item() / derive(f,a.item())) # Too close to one *.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because in the second derivate, we need to calculate  Hessians matrices, which means, we need to calculate matrix inverse, requiring $O(n^{3})$ operations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the forward difference formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive(function, value):\n",
    "    h = 0.0000000000001\n",
    "    top = function(value + h) - function(value)\n",
    "    bottom = h\n",
    "    slope = top / bottom\n",
    "    # Returns the slope to the third decimal\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = np.sin(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999999999999994\n",
      "0.8665290707199347\n"
     ]
    }
   ],
   "source": [
    "print(f(math.pi/6))\n",
    "print(derive(f,math.pi/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1974f12e8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3gUVdvH8e+dhCR0EkBagIQqoUMIIL1JKIIiCIhKFaVjL/g8ih0fu6KIdKUJSi9KC0VqQu+EJqGGXgMp5/1jFt+I1JDd2U3uz3Xtld0pu78MIXdmzplzxBiDUkopda+87A6glFLKM2kBUUoplSpaQJRSSqWKFhCllFKpogVEKaVUqvjYHcCV8uTJY4KDg+2OoZRSHiU6OvqkMSbvjcszVAEJDg4mKirK7hhKKeVRROTgzZbrJSyllFKpogVEKaVUqmgBUUoplSoZqg1EKaXuRUJCArGxscTHx9sdxSX8/f0JCgoiU6ZMd7W9FhCllLqF2NhYsmfPTnBwMCJidxynMsZw6tQpYmNjCQkJuat9bL2EJSKjROSEiGy9xXoRka9FJEZENotIlRTrOovIHsejs+tSK6Uyivj4eHLnzp3uiweAiJA7d+57Otuyuw1kDBBxm/XNgJKOR0/gewARCQTeBqoD4cDbIhLg1KRKqQwpIxSP6+71e7W1gBhjlgGnb7NJa2CcsawGcolIAaApsMAYc9oYcwZYwO0LkVJOkZxs2HXsAuPXHGTB9uPo9AgqI3H3NpBCwKEUr2Mdy261/F9EpCfW2QtFihRxTkqVYVxLTGbL4XOsO3CadftPE3XwDOeuJPy9vkaxQAa3Kkfp/NltTKnSk2zZsnHx4sVbrj9w4AAtW7Zk69abtgTcVJcuXWjZsiVt27a9r2zuXkDumzFmODAcICwsTP88VPfk4tVE1h88YxWMA6fZeOgs8QnJABTLm5WIsvmpFhJIWNEAVsSc5NM/dtH86+U8XaMoLzQpRc7Md9ebRSlP5O4F5DBQOMXrIMeyw0D9G5ZHuiyVSrfiLlwl6sBp1h44TdSBM2w7co5kA14CZQvm5MnwooSHBBAWHEiebH7/2Dc4T1ZalC/AZwt2MW7VAWZtOsJrEQ/StmoQXl4Z5zq6co6LFy/SunVrzpw5Q0JCAu+//z6tW7cGIDExkU6dOrF+/XrKli3LuHHjyJIlC9HR0bz44otcvHiRPHnyMGbMGAoUKJBmmdy9gMwE+orIJKwG83PGmKMi8jvwYYqG84eBN5yWYuuvcO0yFG8AOYOc9jHKtYwx/HX6Mmv3W8Vi3YHT7Dt5CQA/Hy8qF8lF3wYlqBYSSOUiAWTzu/N/l4Csvrz/aHk6VCvCOzO38eqvmxm/9i8GtypLpcK5nP0tqXTM39+fadOmkSNHDk6ePEmNGjVo1aoVALt27WLkyJHUqlWLbt268d133zFgwAD69evHjBkzyJs3L5MnT2bQoEGMGjUqzTLZWkBEZCLWmUQeEYnF6lmVCcAYMwyYCzQHYoDLQFfHutMi8h6wzvFW7xpjbtcYf382jIe9i6zneUpBicZQujkUqQne7l6D1XVJyYadx86zbv9p1h08w7r9pzlx4SoAOTNnolpwAO2rFaZaSCDlCubE1yf1fUzKFcrJlOdrMn3jYT6au5NHh/7JE2FBvBrx4L/OXJS6G8YY3nzzTZYtW4aXlxeHDx/m+PHjABQuXJhatWoB8NRTT/H1118TERHB1q1badKkCQBJSUlpevYBNhcQY0zHO6w3QJ9brBsFpF0pvZ2nfoUTO2DfEti7GNaNhNXfQeYAKNkUQltDiUbgo78Y3El8QhKbY8/93X4RfeAMF64mAlAwpz81i+emWnAg4SGBlMibLc0vM4kIj1UOoklofr5ZtIeRK/Yzb+sxXmxSiqdrFMXH2+5e9MqTjB8/nri4OKKjo8mUKRPBwcF/37NxY/dbEcEYQ9myZVm1apXTMumfz3dDBPKFWo+afeDqRauQ7JoLu+bB5knglxPKtISybaBYPfDWxlNXOx+fQPSB/2/w3nToHNeSrAbvkg9k45FKBQkPDiQsOICggCwuy5XNz4c3mpehXVhhBs/axuBZ25m09hDvtCpLzeK5XZZDebZz587xwAMPkClTJpYsWcLBg/8/wvpff/3FqlWrqFmzJhMmTKB27dqULl2auLi4v5cnJCSwe/duypYtm2aZtICkhl82CG1lPZISYN9S2PYb7JgFG8dDltxQri1U7gT5K1gFSKW54+fjHe0Xp1l74Aw7j53HGPDxEsoVykmXWsFUCw6katEAArP62h2XEg9kY1y3cP7Yfpz3Zm+n44+raVGhAIOal6Fgrsx2x1NurlOnTjzyyCOUL1+esLAwHnzwwb/XlS5dmqFDh9KtWzdCQ0Pp1asXvr6+TJ06lf79+3Pu3DkSExMZOHBgmhYQyUg3PoWFhRmnTiiVeBViFsGWX2DnHEi6BvnKQaVOUL4dZPvXhF7qLhlj2HfyklUs9ltnGX+dvgxAFl9vqhQJoFpwINVCAqhUOBdZfN37b6P4hCR+WLqP7yJj8BKhT4Pi9KhTDP9M3nZHUyns2LGDMmXK2B3DpW72PYtItDEm7MZttYA4y+XT1lnJhvFwZD14+VjtJdW6QbGG4KXXv28nMSmZHUcvsPbvG/ZOc/LiNQACs/pSLdhRMIIDCS2Yg0we2p5w6PRlPpizg/nbjlE0dxb+2zKURmXy2R1LOWgBsWgBwcUFJKUTO2DjBNg0ES7FQWBxqNYDKj0JmbVrJ8CVa0lsPHT27/aL9QfPcOlaEgCFAzNbjd3BgYQFB1I8b9Z0Nz7Rij0neXvmVvbGXaJB6bz895GyhOTJanesDE8LiEULCDYWkOsSr8L2mbB2OMSuhUxZoMITUO1ZyF/Ovlw2OHv52t/3Xqw9cJqth8+RkGQQgdL5shMeYhWL8OBA8uf0tzuuS1xLTGbsygN8tWgP1xKT6VEnhD4NSpD1Lu4/Uc6hBcSiBQQ3KCApHdkI636ELVMhMR6KPAThz1pdgr3S33Xw8/EJLNl5grX7rTOM3cetsX18vb2oEJSTaiGBVAsOoGqRQHJmydg92E6cj+fj+Tv5bf1h8ufw580WZXikQoF0d9blCbSAWLSA4GYF5LrLp2HDz7BuBJw9aN2oWO81qztwOmgnSUxKZuLav/hi4R5OX7pGNj8fqhYNsM4wigZQsXAubTi+heiDp3l75ja2Hj5P9ZBA3mlVljIFctgdK0PRAmLRAoKbFpDrkpNgx0yIHAJxOyBvGaj/OpRp5ZGFxBhD5O44Ppizg5gTF6keEsgrTUtTuUgA3jou1F1LSjZMWvcXn/6+i3NXEnimZjAvNC6V4c/SXEULiOVWBcTzfjOlV17eUPYx6LUS2o4CkwRTOsMPdaz7Szyo0O88dp5nRq2l6+h1JCYlM/zpqkzqWYOw4EAtHvfI20voVL0oS16uT6fqRRm36gANPotk0tq/SE72nJ8JlbZ69OjB9u3b7Y6hZyBuKznJGsRx6RA4FWPdkNjgTSgV4bY3JsZduMrnC3Yzed1fZPPzYUBja8iO+xlTSv3TtiPneGfmNtYdOEOFoJwMblWWykV0Mk5n0TMQi56BeBovb6uHVu818OgwuHoBJnaAHxvA7j/c6owkPiGJ7yJjaPBpJFOiDtH5oWCWvtKA7rVDtHiksbIFc/LLczX5sn0ljp2L57HvVvLKlE3EOQaFVOnPpUuXaNGiBRUrVqRcuXJMnjyZ+vXrc/2P4WzZsjFo0CAqVqxIjRo1/h5g0RW0f6C78/aBSh2hfFvYPNk6I5nQDgqFQdMPoUh126IZY5i1+ShD5u3k8NkrNC6TjzebP0ixvNlsy5QRiAiPVi5E49B8fLN4D6NW7Gf+1mMMbFKKZ2oW9dibKt3d4Fnb2H7kfJq+Z2jBHLz9yO2HFpk/fz4FCxZkzpw5gDUm1vfff//3+kuXLlGjRg0++OADXn31VX788UfeeuutNM15K/qT5im8M0Hlp6BvNDzyFZw/AqMehul94GKcy+NEHzxDm+9X0n/iBnJmzsSEHtUZ0TlMi4cLZfPz4Y1mZZg/sC5Vigbw3uzttPh6OStjTtodTaWh8uXLs2DBAl577TWWL19Ozpw5/7He19eXli1bAlC1alUOHDjgsmx6BuJpfHyhahdrsMZl/4NV38LOWdDov1C1q9PvITl0+jJD5u9k9uaj5M3uxydtK/B4lSBtHLdR8bzZGNO1Ggt3nODd2dt4csQaWpQvwJstylBIB2lMM3c6U3CWUqVKsX79eubOnctbb71Fo0aN/rE+U6ZMf98j5O3tTWJiosuyaQHxVH7ZoMlgaziUOS9Zj/U/QYvPIahqmn/chfgEvovcy8gV+/ES6N+oJM/VLaZ3SbsJEaFJaD7qlMzD8GX7GLokhkU7j9OnfgmerauDNHqyI0eOEBgYyFNPPUWuXLkYMWKE3ZH+ZuslLBGJEJFdIhIjIq/fZP0XIrLR8dgtImdTrEtKsW6ma5O7kbylofMseHwkXDgGIxrBzP7WDYppIDEpmfFrDlL/f5F8H7mXluULsPil+rzYpJQWDzfkn8mb/o1KsuilejQo/QCfLdjNw18sY+H242SkHpfpyZYtWwgPD6dSpUoMHjzYZe0bd8O2brwi4g3sBpoAsVjT03Y0xty0c7OI9AMqG2O6OV5fNMbc0wV3j+rGmxpXL0Dkx7D6e/DPAY3fgcrPpPpGxGWOGwF3Hb9AeHAgb7UsQ4UgHfzRk/wZc5K3Z24j5sRF6pfOy39bhmo71T3QbrwWd+zGGw7EGGP2GWOuAZOA1rfZviMw0SXJPJVfdmj6ATy/Ah4IhVkDYGRjOLLhnt5mz/ELdBm9lmdGreVKQhLDnqrC5OdqaPHwQLVK5GHegDq81aIM0QfO0PTLZXw8byeXrrruOrlKv+wsIIWAQylexzqW/YuIFAVCgMUpFvuLSJSIrBaRR2/1ISLS07FdVFyc63sr2SJfKHSZA48Nh7OHYHgDmP0iXDlz291OXbzKW9O3EPHVcqIPnmFQ8zIseLEuEeV0ID9Plsnbix51irHo5Xq0rlSIYUv30uizpczYeFgva6n74indeDsAU40xSSmWFXWcUj0JfCkixW+2ozFmuDEmzBgTljdvBpoRUAQqtod+UVD9OYgeDd9UtQZuTE7+x6bxCUkMW7qX+v+LZOLaQzxVvQhLX2nAs3WL4eejja/pxQPZ/fm0XUV+7fUQebP7MWDSRtoPX82Oo2l7b4PKOOwsIIeBwileBzmW3UwHbrh8ZYw57Pi6D4gEKqd9xHTAPyc0GwLPLYPcJWBGHxgdAUc3Y4xhzuajNPliKR/P20m1kEB+H1iXwa3LucUc4so5qhYNYHqfWnzUpjx7jl+gxdfL+e+MrZy9fM3uaMrD2NmNZh1QUkRCsApHB6yziX8QkQeBAGBVimUBwGVjzFURyQPUAj5xSWpPlb88dJ1vzYq44L+Y4fWYk/kRXjr9GCH5c/NT93DqlMxAZ2gZnLeX0DG8CM3K5efzBbv5efVBZm06wqsRD/JEWGG9r0fdFdvOQIwxiUBf4HdgB/CLMWabiLwrIq1SbNoBmGT+ebG2DBAlIpuAJcDHt+q9pVLw8iK54pOMC/uVCYmNaXl5BmvyvM+cjnm1eGRQubL48m7rcszuV4eSD2Tnjd+28OjQP1n/1+3by5QCHY03Qzl67govT9nEnzGnaBKaj8+qnCTHvL5w9SI0/wQqP+22I/0q5zPGMHPTET6cu4Pj56/yeJUgXmtWmgeyZ4wphW/GHbvxvvPOO2TLlo2XX37ZKe9/L9149U6wDGLO5qO8OW0L1xKT+ahNeTpUK2z1rCr6J0zrCTP7wb5IaPmldQ+JynBEhNaVCtG4TD6+WRzDyBX7+GPbMQY0Lknnh4J1kEb1L/oTkc5diE/gpV820WfCeoJzZ2HugDp0DC/y/91ys+eDp6ZZY2ltm25NYHV4vb2hla2y+vnwerMH+X1gXaoGB/D+nB00/2o5f+ogjbb54IMPKFWqFLVr12bXrl0A7N27l4iICKpWrUqdOnXYuXMn586do2jRoiQ7elpeunSJwoULk5CQ4JRcegaSjkUdOM0Lv2zk8Jkr9G9Ygn6NSt78r0gvL6jzEhStDb92h5EPW3ex1+jtkdPpqrRRLG82RnepxqIdJ3h39nY6jVhDs3L5GdSiDEEBWeyO53rzXodjW9L2PfOXh2Yf33aT6OhoJk2axMaNG0lMTKRKlSpUrVqVnj17MmzYMEqWLMmaNWvo3bs3ixcvplKlSixdupQGDRowe/ZsmjZtSqZMzpkCWQtIOpSQlMzXi/YwdEkMhQIyM+X5mlQtGnjnHYtUt7r7zuwHfwyC/Uvh0e8hax7nh1ZuSURoHJqP2iXz8OOyfQyNjGHJrhP0rl+CnjpIo0ssX76cxx57jCxZrKLdqlUr4uPjWblyJe3atft7u6tXrUnF2rdvz+TJk2nQoAGTJk2id+/eTsumBSSd2Rd3kRcmb2RT7DnaVg3i7UdCye5/D399ZAmE9j/DuhHw+yAYVhva/AghdZwXWrk9/0ze9GtUkjZVg/hwzg4+X7CbKdGH+E+LUJqE5ssYIxXc4UzBlZKTk8mVKxcbN27817pWrVrx5ptvcvr0aaKjo2nYsKHTcuj1iXTCGMOENX/R4usVHDh1me86VeHTdhXvrXhcJwLhz0KPheCbDcY+Aks+hCQdPymjK5QrM0M7VWFCj+pkzuRNz5+i6Tx6HXvjLtodLd2qW7cu06dP58qVK1y4cIFZs2aRJUsWQkJCmDJlCmD9/9+0aRNgTXFbrVo1BgwYQMuWLfH2dt5ZohaQdODUxas8Oy6aN6dtoWrRAH4fWJfm5Qvc/xsXqAA9I605R5YOgXGt4NytBgtQGclDJfIwp38d/tMylA0HzxDx5TI+mreDizpIY5qrUqUK7du3p2LFijRr1oxq1aoBMH78eEaOHEnFihUpW7YsM2bM+Huf9u3b8/PPP9O+fXunZtP7QDzckl0neGXKZs5fSeDViNJ0qxWClzPuIt40GWa/YM2I+Oj3ULpZ2n+G8khxF67yyfydTImO5YHsfrzZvAytKxVMF5e13PE+EGfzlOHc1X24ci2J/87YStfR68id1ZeZ/WrRo04x5xQPsAZmfG4Z5CwMEzvA/Dcg8apzPkt5lLzZ/fhfu4r81vsh8uf0Z+DkjTzxwyq2HTlndzTlZFpAPNDu4xd45NsVjFt1kO61Q5jRtxYP5nfBzX95SljtItWfh9XfwcgmcGqv8z9XeYQqRQKY3rsWH7cpz964SzzyzQr+M10HaUzPtIB4mBkbD9P62z85ezmBn7qH85+Woa7tSunjZ43u22ECnDkIP9SFzVNc9/nKrXl5CR3Ci7Dkpfo8UzOY8WsO0uDTSMavOUhSsmdeLs9Il/nv9XvVAuIhriUm887MbQyYtJGyBXMwp39tewdAfLAF9PrTuhHqtx4wvQ9cu2RfHuVWcmbJxDutyjKnfx1K5svOoGlbaT10BdEHPWuQRn9/f06dOpUhiogxhlOnTuHvf/djn2kjugc4di6ePhPWE33wDN1qhfBG8wfdZ1yipERY+jEs+xTylIS2oyF/ObtTKTdijGHW5qN8OGcHx87H06ZKIV5v9qBHDNKYkJBAbGws8fHxdkdxCX9/f4KCgv515/qtGtG1gLi5lXtP0n/iBi5fS2LI4xV4pGJBuyPd3L6l8NuzcOUsRHwIYd11ZF/1D5euJjJ0SQwjlu/H18eLAY1K0qWWDtLoCbSA4FkFxBjDD8v28cn8nYTkycqwp6pSMl92u2Pd3sU4mP48xCyEMq2g1deQOcDuVMrN7D95iXdnbWPJrjiK583KO63K6nw0bk4LCJ5TQC7EJ/DKlM3M33aM5uXz80nbimTz85BRZ5KTYdW3sGgwZC8IbUdC4XC7Uyk3tGjHcd6dvZ2Dpy4TUTY/b7XMoIM0egC3vA9ERCJEZJeIxIjI6zdZ30VE4kRko+PRI8W6ziKyx/Ho7NrkzrP7+AVaf/snC3Yc560WZRj6ZBXPKR5gjd5bqz90+8O6hDUqApZ/bhUWpVJoVCYfvw+syytNS7N0dxyNPlvKlwt3E5+QZHc0dZdsOwMREW9gN9AEiMWaI71jyqlpRaQLEGaM6XvDvoFAFBAGGCAaqGqMuW0XD3c/A5mx8TCv/7qFrH4+DH2yMtWL5bY70v2JPwcz+8P26VCsAbQZDtkesDuVckNHzl7hg7k7mLP5KEEBmflPy1AeziiDNHoAdzwDCQdijDH7jDHXgElA67vctymwwBhz2lE0FgARTsrpdIlJybw/e/s/uuh6fPEA8M8J7cZYsxz+tQqG1YGjm+1OpdxQwVyZGfpkFSY8W52svj4891M0z4xaS8wJHaTRndlZQAoBh1K8jnUsu9HjIrJZRKaKSOF73BcR6SkiUSISFRcXlxa509S5Kwl0GxvFiBX76VyzKBN71iBfDvfv3njXRCCsKzy7GLx8YHQziFlkdyrlph4qnoc5/Wvz9iOhbDx0logvl/HhXB2k0V25e/+5WUCwMaYC1lnG2Ht9A2PMcGNMmDEmLG9e9+rpsTfuIo8N/ZNVe0/yUZvyDG5dLv12acxX1hoGJSAYJjwBGyfYnUi5KR9vL7rWCmHJy/VpU6UQw5fto+GnkUzbEJshbujzJHb+tjoMFE7xOsix7G/GmFPGmOsj9o0Aqt7tvu4uctcJHh36J2evJDC+Rw06hhexO5Lz5SgAXedB0VowvRcs+x/oLwR1C3my+fFJ24pM71OLAjn9eWHyJtoNW8XWwzpIo7uws4CsA0qKSIiI+AIdgJkpNxCRlJNatAJ2OJ7/DjwsIgEiEgA87Fjm9owx/LhsH93GrKNQrszM7FuL8JC7mG42vfDPAZ2mQoX2sPh9a4h4nahK3UalwrmY1rsWQx4vz/6Tl2j17Qremr6FM5d0kEa72dY/1BiTKCJ9sX7xewOjjDHbRORdIMoYMxPoLyKtgETgNNDFse9pEXkPqwgBvGuMOe3yb+IexSckMWjaVn5dH0uzcvn5tF1FsnpSF9204uMLj/0AOQrCii/gwjHrfhHfrHYnU27Ky0toX60IEeUK8MWC3fy0+iCzNx/l5YdL0zG8CN7OmsZA3ZbeSOgiJy7E89xP0Wz46ywDG5ekf8OSzpu7w5Os/RHmvQoFK8OTv0DWPHYnUh5g57HzvDNzG6v3naZswRwMblWWsOAMdCbvYnonOvYVkB1Hz9N9zDrOXE7gi/YViSiXBtPNpic758DU7lYbSaepkLu43YmUBzDGMHvzUT6cu4Oj5+J5rHIh3mj2IA+kp16MbkILCPYUkMU7j9Nvwgay+2diROcwyhXK6dLP9xiH1lm9s8TLOhMJqnrnfZQCLl+zBmn8cdl+MnkLAxqXpMtDIfj6pNMejTZwxxsJ0zVjDKNW7KfH2ChC8mZlep9aWjxup3A16L7AagcZ0wJ2zbc7kfIQWXx9eKXpg/zxQl2qF8vNh3N3EvHVMpbtdr/7vtIbLSBOkJCUzFvTt/Lu7O00Cc3HL8/VJH9OPa2+o+tT5j7wIEzqCFGj7U6kPEhwnqyM6lKNUV3CSE42PDNqLc/9FMWh05ftjpZu6SWsNHY+PoE+49ezfM9Jnq9XnFebltbG8nt19SJM7Qp7/oC6r0CDQTq3iLonVxOTGLF8P98ujiHZGJ6vV5xe9Yu7dvrndETbQHB+AYk9c5luY9axL+4SHz5WnieqFb7zTurmkhJh9kDY8BNUfNKaW8Q70533UyqFI2ev8OHcHczefJRCuTLzn5ZlaFo2vw7SeI+0DcTJNsee5bHvVnL0XDzjuoVr8bhf3j7Q6huo/yZsmmA1sF+9YHcq5WEK5srMt09WYeKzNcjm58PzP6/XQRrTkJ6BpIEF24/Tf+IGArP6MqZrNfefOdDTbPjZGhY+X6jVzTd7frsTKQ+UmJTMz6sP8vmC3Vy+lkTXWsH0b1SS7P56ZnsnegbiJGP+3E/Pn6IolS8b0/o8pMXDGSo/ZXXtPbUPRjSBuF12J1IeyMfbiy6OQRrbVg1ixIr9NPxsKb9Gx5KcnHH+kE5LWkBSKTnZ8N7s7bwzazuNy+RjUs+aPJBde1o5TcnG0HUOJMbDyIfh4Cq7EykPlTubHx8/XoHpvWtRMFdmXpqyiXY/6CCNqaEFJBXiE5LoM2E9I1fsp8tDwQx7qiqZfbV3h9MVrAw9FljDnYxrDdtn2J1IebCKhXMxrddDfNK2AgdPXeKRb1fw5jQdpPFeaBvIPTpz6Ro9xkURffAMb7UoQ/faIdqjw9Uun4aJHeDQWoj4GGo8b3ci5eHOXUngq4V7GLvqANn8fHi5aWme1EEa/6bdeLn/AnLo9GU6j1pL7NkrfPFEJVpU0DGtbJNwBX7tATtnw0P9oPG74KUn1Or+7Dp2gXdmbmPVvlOEFsjB4NZlqaaDNGoj+v3aEnuOx75byalL1xjfo7oWD7tlygxPjIPwnrDyG/itByRevfN+St1G6fzZmfBsdYY+WYWzl6/RbtgqBk7awPHz8XZHc0sZcDKKexe56wS9x68nIIsvk3pWp8QD2tPKLXh5Q7NPIEchWPg2XDgOHcZD5lx2J1MeTERoUaEADR7My3dL9jJ82T6rq36jknStpYM0pmTrkRCRCBHZJSIxIvL6Tda/KCLbRWSziCwSkaIp1iWJyEbHY+aN+6YVYwxjVh4gOHdWpvV+SIuHuxGB2gOhzQg4tAZGRcC5WLtTqXQgi6/VFrLgxbrULJ6bj+ZZgzQu1UEa/2ZbG4iIeAO7gSZALNbsgh2NMdtTbNMAWGOMuSwivYD6xpj2jnUXjTHZ7uUzU9sGciE+AUBvOHJ3+5bC5KfANxs8NRXylbU7kUpHluw6wbuztrP/5CWahObjvy1DKRyYxe5YLuGObSDhQIwxZp8x5howCWidcgNjzBJjzPWhNFcDQS7OCFiFQ4uHByhWD7rOs56PirAKilJppEHpB5g/sA6vRpTmz5iTNPp8KZ//sYsr15LsjmYbOwtIIeBQitexjmW30h2Yl+K1v4hEichqEXn0VjuJSE/HdlFxcXrqme7lL2fdK5KjEPz8OGyeYncilY74+VrhB1wAAB2wSURBVHjTu34JFr9Un4iy+fl6cQyNP1/KvC1HyUg9Wq/ziNYgEXkKCAP+l2JxUccp1ZPAlyJy03lQjTHDjTFhxpiwvHnzuiCtsl3OIOg2H4rUsHpnrfgCMuB/buU8+XP683XHykzqWYPs/j70Gr+ep0auYc/xjDXgp50F5DCQcsjaIMeyfxCRxsAgoJUx5u9+msaYw46v+4BIoLIzwyoPkzkXPPUrlHscFr4Dc1+B5Ix7qUE5R41iuZndrzaDW5VlS+w5mn21nPdmb+e8o900vbOzgKwDSopIiIj4Ah2Af/SmEpHKwA9YxeNEiuUBIuLneJ4HqAVsR6mUfPys3lkP9YN1P8Ivz1g3ICqVhny8vej8UDBLXq5Pu7AgRv25n4afLmVqBhik0bYCYoxJBPoCvwM7gF+MMdtE5F0RaeXY7H9ANmDKDd11ywBRIrIJWAJ8nLL3llJ/8/KCh9+HiCGwcw6MbWUNhaJUGsudzY+P2lRgRp9aBAVk5uUpm2g7bCVbYtPvII06lInKOLbPgF+fhVyFrctbAcF2J1LpVHKy4df1sQyZv5NTl67RoVoRXmlamsCsvnZHSxV37MarlGuFtobOM+HSSWtekSMb7E6k0ikvL6FdWGEWv1yfbrVC+CXqEA0+jWTcqgMkJiXbHS/NaAFRGUuRGtB9Afj4w+gWsGeB3YlUOpbDPxP/aRnKvAF1KFswB/+dsY2W36xg7f70cRlVC4jKePKWsu4VyV0cJrSH9T/ZnUilc6XyZWd8j+p816kK568k8MQPqxgwaQPHznn2II1aQFTGlD0/dJ1r3b0+sy9Efqz3iiinEhGaly/Aopfq079hCeZtPUbDzyL5PnIvVxM9s4u5FhCVcfllt+Zar9QJIj+CWf0hKdHuVCqdy+zrzYsPl2bhC/V4qHgehszfScSXy4ncdeLOO7sZLSAqY/POBK2HQt1XYf04mNQRrl60O5XKAIrkzsKIzmGM6VoNgC6j19FjbBR/nbp8hz3dhxYQpUSg4SBo+SXELISxLeGi5/01qDxTfccgja9FPMjKvSdp/MVSPvOQQRq1gCh1XVhX6DAR4nbBiMZwMsbuRCqD8PPxplf94ix+qT7NyuXnm8UxNPoskjmb3XuQRi0gSqVUOgI6z4Zrl2BkEzi01u5EKgPJn9OfrzpU5pfnapIziy99Jqyn04g17HbTQRq1gCh1o6Cq0P0Pa0DGsY9YQ6Ao5ULhIYHM6luL91qXZduR8zT7ajnvznK/QRq1gCh1M7mLWzcc5itrzXK4boTdiVQG4+PtxdM1rUEanwgrzOiV+2n4aSS/RB1ym0EatYAodStZ81iXs0o2hTkvWcPCJ6efYSiUZwjM6stHbcozs09tigRm4dWpm2nz/Uo2x561O5oWEKVuyzcLtP8Zqna1Jqaa9hwkXrM7lcqAygflZOrzD/FZu4rEnrlC66F/8vqvmzl18eqdd3YSLSBK3Ym3D7T8Ahr+B7b8AuPbQnz6HaJbuS8vL+HxqkEsfrke3WuFMDU6lgafRjJ2pT2DNGoBUepuiEDdl+HRYXDwTxjdHM4fsTuVyqBy+GfirZahzB9YhwpBuXh7pjVI45p9p1yaQwuIUveiUkdr+JMzB6wh4U/ssDuRysBKPJCdn7qH832nKlyIT6T98NX0m7iBo+dcM/OmrQVERCJEZJeIxIjI6zdZ7ycikx3r14hIcIp1bziW7xKRpq7MrTK4Eo2g6zxIToRRTeHACrsTqQxMRGhWvgALX6xH/0Yl+X3bMRp9tpTvImOcPkijbQVERLyBoUAzIBToKCKhN2zWHThjjCkBfAEMcewbijWHelkgAvjO8X5KuUaBCtaQ8Nnyw0+Pwdbf7E6kMrjMvt682KQUi16sR+0Sefhk/i4ivlzOkp3OG5bnjgVERPqJSIATPjsciDHG7DPGXAMmAa1v2KY1MNbxfCrQSETEsXySMeaqMWY/EON4P6VcJ1cR6DYfCoXB1K4QOUR7aCnbFQ7MwvBnwhjbLRwBuo5ZR/cx6zhyNu0va93NGUg+YJ2I/OK45CRp9NmFgEMpXsc6lt10G2NMInAOyH2X+wIgIj1FJEpEouLi4tIoulIOWQLh6WlQri1Efgjf14Q9C+1OpRT1SuVl/sC6vNHsQbYcPodXmv3q/n93LCDGmLeAksBIoAuwR0Q+FJHiaZ7GCYwxw40xYcaYsLx589odR6VHmfyh7UjoNNWalGr84zCxI5zeb3cylcH5+njxXL3iLH+tAflz+qf5+99VG4ixhoM85ngkAgHAVBH55D4++zBQOMXrIMeym24jIj5ATuDUXe6rlGuVbAK9V0Hjd2DfUhhaHRa/D9c8Z34HlT75+Tinifhu2kAGiEg08AnwJ1DeGNMLqAo8fh+fvQ4oKSIhIuKL1Sg+84ZtZgKdHc/bAosdxWwm0MHRSysE6wxJh01V9vPxg9ovQL8oCG0Fy/4H31aDbdN1ylyV7tzNGUgg0MYY09QYM8UYkwBgjEkGWqb2gx1tGn2B34EdwC/GmG0i8q6ItHJsNhLILSIxwIvA6459twG/ANuB+UAfY4z7z76iMo4cBeHxEVZ338wBMKUzjGul942odEXcebKStBYWFmaioqLsjqEymqREiB5tXc66egGqPwf1Xwf/nHYnU+quiEi0MSbsxuV6J7pSzubtA+HPQr/1UOUZWP09fFMVNvyso/sqj6YFRClXyZobHvkSekZCQAjM6GPNeng42u5kSqWKFhClXK1gJej2uzUw49m/4MdGMKMvXDppdzKl7okWEKXs4OVlDczYLxpq9oFNE+HrKrB6mNVmopQH0AKilJ38c0DTD6DXSihUBea/Bj/Ugf3L7U6m1B1pAVHKHeQtbQ2J0v5nuHYRxraEKV3gXKzdyZS6JS0gSrkLESjzCPRZC/XfgF3zrJsQl30KifZNW6rUrWgBUcrdZMps3SfSZ60198ji96xhUXbNtzuZUv+gBUQpdxVQ1Lqk9fQ08M4EE9vD+HZwaq/dyZQCtIAo5f6KN7Qa2R/+AA6ugu9qwMJ34OpFu5OpDE4LiFKewDsTPNTX6vZb7nFY8YXVPrJlqg7SqGyjBUQpT5I9Hzw2DLr9Adnywq/dYUxLOLbV7mQqA9ICopQnKlIdnl0CLb+EE9ute0fmvgJXztidTGUgWkCU8lRe3hDW1bqsFdYd1o2wBmmMHgPJOruBcj4tIEp5uiyB0OJTeG4Z5CkNswbAjw3h0Dq7k6l0TguIUulF/vLQdS60GQEXj8PIxjCtF1w4bncylU7ZUkBEJFBEFojIHsfXgJtsU0lEVonINhHZLCLtU6wbIyL7RWSj41HJtd+BUm5KBCq0g75RUGsgbJkC34bBym8hKcHudCqdsesM5HVgkTGmJLDI8fpGl4FnjDFlgQjgSxHJlWL9K8aYSo7HRudHVsqD+GWDJoOh92ooXB3+GATf14K9S+xOptIRuwpIa2Cs4/lY4NEbNzDG7DbG7HE8PwKcAPK6LKFS6UGeEtBpCnScBElX4adHYfLT1jwkSt0nuwpIPmPMUcfzY0C+220sIuGAL5ByDIcPHJe2vhARv9vs21NEokQkKi4u7r6DK+VxRKB0M+i9Bhq+BXsWwLfhEDkEEq7YnU55MDFOuotVRBYC+W+yahAw1hiTK8W2Z4wx/2oHcawrAEQCnY0xq1MsO4ZVVIYDe40x794pU1hYmImKirrXb0Wp9OVcLPzxFmybBrmKQNOP4MEWVqFR6iZEJNoYE3bjcqedgRhjGhtjyt3kMQM47igC14vBiVuEzgHMAQZdLx6O9z5qLFeB0UC4s74PpdKdnEHQbgx0ngW+2WByJ/i5DcTttjuZ8jB2XcKaCXR2PO8MzLhxAxHxBaYB44wxU29Yd734CFb7iY7joNS9CqkLzy2HiCEQGw3f17TOTOLP251MeQi7CsjHQBMR2QM0drxGRMJEZIRjmyeAukCXm3TXHS8iW4AtQB7gfdfGVyqd8PaBGs9bd7NX7AArv7G6/W6arIM0qjtyWhuIO9I2EKXuIDYa5r4MR9ZD4RrQ/BMoUNHuVMpmLm8DUUp5oKCq0GMRtPoWTsXAD/Vg9gtw+bTdyZQb0gKilPonLy+o8rR1Wav68xA9Fr6pYg3WqIM0qhS0gCilbi5zLmj2MTy/AvKVgzkvwfB61qyISqEFRCl1J/lCrS6/bUdbl7JGR8Cvz8L5o3feV6VrWkCUUncmAuXaQN91UOdl2D7d6q214ktIvGZ3OmUTLSBKqbvnmxUa/Qf6rIHgOrDwbev+kT0L7U6mbKAFRCl17wKLwZOToNNU636R8Y/DxCfh9H67kykX0gKilEq9kk2g9ypo/A7si4Sh1WHxB3Dtss3BlCtoAVFK3R8fP6j9AvSLgtBWsOwTGBoO26br3ezpnBYQpVTayFEQHh8BXeeBf06Y0hnGtYITO+xOppxEC4hSKm0VfQh6LoXmn8LRzdZMiPPfgPhzdidTaUwLiFIq7Xn7QPiz0G+9dVf76u/hm6qw4WdITrY7nUojWkCUUs6TNTc88hX0XAIBITCjD4xsAoej7U6m0oAWEKWU8xWsDN1+h0eHWfOx/9gIZvSFSyftTqbugxYQpZRreHlBpY7WII01+8CmifB1FVg9DJIS7U6nUsGWAiIigSKyQET2OL7eaj70pBSTSc1MsTxERNaISIyITHbMXqiU8gT+OaDpB9BrJRSqAvNfgx/qwoEVdidT98iuM5DXgUXGmJLAIsfrm7lijKnkeLRKsXwI8IUxpgRwBuju3LhKqTSXtzQ8PQ3a/wxXL8CYFjClK5w7bHcydZfsKiCtgbGO52Ox5jW/K4550BsC1+dJv6f9lVJuRATKPAJ910L9N2DXXGuQxmWfQuJVu9OpO7CrgOQzxlwfC/oYkO8W2/mLSJSIrBaR60UiN3DWGHP9omksUMiJWZVSzpYpM9R/HfqsheINYfF71rAou+bbnUzdho+z3lhEFgL5b7JqUMoXxhgjIrca76CoMeawiBQDFovIFuCe7kYSkZ5AT4AiRYrcy65KKVcLKAodxsPexTDvNZjYHko+DBEfQ+7idqdTN3DaGYgxprExptxNHjOA4yJSAMDx9cQt3uOw4+s+IBKoDJwCconI9eIXBNzyoqkxZrgxJswYE5Y3b940+/6UUk5UvCE8/yc8/L41A+J3NWDhYLh60e5kKgW7LmHNBDo7nncGZty4gYgEiIif43keoBaw3RhjgCVA29vtr5TycD6+8FA/a5DGco/Dis/h22qwZaoO0ugm7CogHwNNRGQP0NjxGhEJE5ERjm3KAFEisgmrYHxsjNnuWPca8KKIxGC1iYx0aXqllOtkzw+PDYNuf0C2vPBrdxjTEo5ttTtZhicmA1XysLAwExUVZXcMpVRqJSfB+rGw6D2IPwvVekCDNyHzTW8lU2lERKKNMWE3Ltc70ZVSnsPLG8K6WXezh3WDdSOsQRqjx1jFRbmUFhCllOfJEggtPoPnlkGe0jBrAPzYEA6tsztZhqIFRCnlufKXh65zoc0IuHgcRjaGab3gwnG7k2UIWkCUUp5NBCq0g77roNZA2DLFupt95beQlGB3unRNC4hSKn3wyw5NBkPv1VC4OvwxyJoNcV+k3cnSLS0gSqn0JU8J6DQFOk6CpKswrjVMftqah0SlKS0gSqn0RwRKN4Pea6DhW7BnAXwbDpFDIOGK3enSDS0gSqn0K5M/1H3Fah8p1RQiP4Sh4bBjtt7Nnga0gCil0r9cheGJsfDMTMiUFSZ3gp/bwMk9difzaFpAlFIZR7F68Pxya3Tf2Gj4rib88R9rQit1z7SAKKUyFu9MUKOXdTd7xfaw8mv4Jgw2TdbLWvdIC4hSKmPKlhdaD4UeiyBHQZjWE0ZFwNFNdifzGFpAlFIZW1CYVURafQOnYuCHejD7Bbh82u5kbk8LiFJKeXlBlWesy1rVn4PosfBNFWuwRh2k8Za0gCil1HWZc0GzIfD8CshXDua8BMPrWbMiqn/RAqKUUjfKFwqdZ0Hb0dalrNER8OuzcP6o3cncii0FREQCRWSBiOxxfP3XbDAi0kBENqZ4xIvIo451Y0Rkf4p1lVz/XSil0jURKNfGugmxzsuwfbo1SOOKLyHxmt3p3IJdZyCvA4uMMSWBRY7X/2CMWWKMqWSMqQQ0BC4Df6TY5JXr640xG12SWimV8fhmhUb/gT5rILgOLHwbvq8JMQvtTmY7uwpIa2Cs4/lY4NE7bN8WmGeMuezUVEopdSuBxeDJSdBpqnW/yM+Pw8Qn4fR+u5PZxq4Cks8Yc/1i4jEg3x227wBMvGHZByKyWUS+EBG/W+0oIj1FJEpEouLi4u4jslJKASWbQO9V0Pgda6j4odVh8QdwLeP9fSvGSXdeishCIP9NVg0CxhpjcqXY9owx5l/tII51BYDNQEFjTEKKZccAX2A4sNcY8+6dMoWFhZmoqKh7/l6UUuqmzh+xhkLZOhVyFoaH34fQ1lb7SToiItHGmLAblzvtDMQY09gYU+4mjxnAcUcRuF4MTtzmrZ4Apl0vHo73PmosV4HRQLizvg+llLqlHAWh7UjoMhf8c8KUzjCuFZzYaXcyl7DrEtZMoLPjeWdgxm227cgNl69SFB/Baj/Z6oSMSil1d4JrQc+l0PxTOLoZvn8I5r8B8efsTuZUdhWQj4EmIrIHaOx4jYiEiciI6xuJSDBQGFh6w/7jRWQLsAXIA7zvgsxKKXVr3j4Q/iz0Ww9VnobV38M3VWHDz5CcbHc6p3BaG4g70jYQpZTLHNkAc1+F2LVQKAyafwKFqtqdKlVc3gailFIZWsHK0O13eHSYNR/7j41gZj+4dNLuZGlGC4hSSjmLlxdU6mgN0lizD2ycYA3SuOYHSEq0O9190wKilFLO5p8Dmn4AvVZaZybzXoUf6sKBFXYnuy9aQJRSylXyloanp8MTP1nT6I5pAVO6wrnDdidLFS0gSinlSiIQ2soaW6ve67BrrjVI47JPIfGq3enuiRYQpZSyg28WaPAG9FkLxRvC4vesYVF2/253srumBUQppewUUBQ6jIenp4F3JpjwBIx/Ak7ttTvZHWkBUUopd1C8ITz/JzR5Dw7+Cd/VgIWD4epFu5PdkhYQpZRyFz6+UKu/1e23bBtY8Tl8Ww22OIaQdzNaQJRSyt1kzw9tfoBuf0DWPPBrdxjTEo6517B/WkCUUspdFakOPSOh5RdwYhv8UAfmvgJXztidDNACopRS7s3LG8K6WYM0hnWDdSOsQRqjx0Bykr3RbP10pZRSdydLILT4zBo2Pk8pmDUAfmwIh9bZFkkLiFJKeZICFaDrPGgzAi4eh5GNYXpvuHi7efmcQwuIUkp5GhGo0A76roNaA2HzL9ZlrVVDISnhzvunES0gSinlqfyyQ5PB0HsVFA6H39+EYbVhX6RLPt6WAiIi7URkm4gki8i/JilJsV2EiOwSkRgReT3F8hARWeNYPllEfF2TXCml3FCektBpKnSYCInxMK41TH7amofEiew6A9kKtAGW3WoDEfEGhgLNgFCgo4iEOlYPAb4wxpQAzgDdnRtXKaXcnAg82Bx6r4EGb8GeBfBtOEQOgYQrTvlIWwqIMWaHMWbXHTYLB2KMMfuMMdeASUBrERGgITDVsd1Y4FHnpVVKKQ+SyR/qvWK1j5RqCpEfwtBwOL49zT/KndtACgGHUryOdSzLDZw1xiTesPymRKSniESJSFRcXJzTwiqllFvJVRieGAvPzITcJSBXkTT/CJ80f0cHEVkI5L/JqkHGmBnO+twbGWOGA8MBwsLC3G8wGaWUcqZi9ayHEzitgBhjGt/nWxwGCqd4HeRYdgrIJSI+jrOQ68uVUkq5kDtfwloHlHT0uPIFOgAzjTEGWAK0dWzXGXDZGY1SSimLXd14HxORWKAmMEdEfncsLygicwEcZxd9gd+BHcAvxphtjrd4DXhRRGKw2kRGuvp7UEqpjE6MG44x7yxhYWEmKirK7hhKKeVRRCTaGPOve/bc+RKWUkopN6YFRCmlVKpoAVFKKZUqWkCUUkqlSoZqRBeROOCgE946D3DSCe97PzTT3XHHTOCeuTTT3UmPmYoaY/LeuDBDFRBnEZGom/VQsJNmujvumAncM5dmujsZKZNewlJKKZUqWkCUUkqlihaQtDHc7gA3oZnujjtmAvfMpZnuTobJpG0gSimlUkXPQJRSSqWKFhCllFKpogXkHohIYRFZIiLbRWSbiAxwLA8UkQUissfxNcCGbN4iskFEZjteh4jIGhGJEZHJjiHxXZ0pl4hMFZGdIrJDRGrafaxE5AXHv91WEZkoIv6uPlYiMkpETojI1hTLbnpcxPK1I9tmEaniwkz/c/zbbRaRaSKSK8W6NxyZdolIU2dkulWuFOteEhEjInkcr207Vo7l/RzHa5uIfJJiudOP1S3+/SqJyGoR2eiYlTXcsTztjpMxRh93+QAKAFUcz7MDu4FQ4BPgdcfy14EhNmR7EZgAzHa8/gXo4Hg+DOhlQ6axQA/Hc18gl53HCmvq4/1A5hTHqIurjxVQF6gCbE2x7KbHBWgOzAMEqAGscWGmhwEfx/MhKTKFApsAPyAE2At4uyqXY3lhrKkeDgJ53OBYNQAWAn6O1w+48ljdItMfQLMUxyYyrY+TnoHcA2PMUWPMesfzC1jzlBQCWmP9ssTx9VFX5hKRIKAFMMLxWoCGwFQbM+XE+qEeCWCMuWaMOYvNxwprFs7MIuIDZAGO4uJjZYxZBpy+YfGtjktrYJyxrMaajbOAKzIZY/4w1rw8AKuxZv+8nmmSMeaqMWY/EAOEp3WmW+Vy+AJ4FUjZC8i2YwX0Aj42xlx1bHMiRSanH6tbZDJADsfznMCRFJnS5DhpAUklEQkGKgNrgHzGmKOOVceAfC6O8yXWf6Zkx+vcwNkU//ljsQqdK4UAccBox6W1ESKSFRuPlTHmMPAp8BdW4TgHRGP/sYJbH5dCwKEU29mVrxvWX61gcyYRaQ0cNsZsumGVnblKAXUcl0KXikg1N8g0EPifiBzC+rl/I60zaQFJBRHJBvwKDDTGnE+5zljniC7rGy0iLYETxphoV33mXfLBOqX+3hhTGbiEdWnmbzYcqwCsv75CgIJAViDCVZ9/t1x9XO5ERAYBicB4N8iSBXgT+K/dWW7gAwRiXRJ6BfjFcSXATr2AF4wxhYEXcMLMrVpA7pGIZMIqHuONMb85Fh+/fgro+HriVvs7QS2glYgcACZhXY75Cuu01MexTRBw2IWZwPqrJtYYs8bxeipWQbHzWDUG9htj4owxCcBvWMfP7mMFtz4uh7Gu91/n0nwi0gVoCXRyFDa7MxXH+gNgk+NnPghYLyL5bc4VC/zmuCy0FutqQB6bM3XG+hkHmML/XzpLs0xaQO6B4y+KkcAOY8znKVbNxPrHwvF1hqsyGWPeMMYEGWOCgQ7AYmNMJ2AJ0NaOTI5cx4BDIlLasagRsB0bjxXWpasaIpLF8W95PZOtx8rhVsdlJvCMo+dMDeBciktdTiUiEViXRlsZYy7fkLWDiPiJSAhQEljrikzGmC3GmAeMMcGOn/lYrI4tx7DxWAHTsRrSEZFSWJ1GTmLjscJq86jneN4Q2ON4nnbHKa17A6TnB1Ab69LCZmCj49Ecq81hkeMfaCEQaFO++vx/L6xiWD+oMVh/ffjZkKcSEOU4XtOBALuPFTAY2AlsBX7C6h3j0mMFTMRqg0nA+gXY/VbHBaunzFCs3jtbgDAXZorBulZ+/Wd9WIrtBzky7cLR08dVuW5Yf4D/74Vl57HyBX52/FytBxq68ljdIlNtrDa+TVhttVXT+jjpUCZKKaVSRS9hKaWUShUtIEoppVJFC4hSSqlU0QKilFIqVbSAKKWUShUtIEoppVJFC4hSSqlU0QKilI1EpJpjTgZ/EcnqmEuinN25lLobeiOhUjYTkfcBfyAz1vhhH9kcSam7ogVEKZuJNQPiOiAeeMgYk2RzJKXuil7CUsp+uYFsWLNc+tucRam7pmcgStlMRGZiDcUfAhQwxvS1OZJSd8XnzpsopZxFRJ4BEowxE0TEG1gpIg2NMYvtzqbUnegZiFJKqVTRNhCllFKpogVEKaVUqmgBUUoplSpaQJRSSqWKFhCllFKpogVEKaVUqmgBUUoplSr/Byu8L4mpfXeoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sin_values = [f(np.pi/float(x)) for x in range(1,12)]\n",
    "derivate_values = [derive(f,np.pi/float(x)) for x in range(1,12)]\n",
    "pis = [math.degrees(np.pi/float(x)) for x in range(1,12)]\n",
    "pis = pis + pis\n",
    "labels_sin = ['sin' for x in range(1,12)]\n",
    "labels_derivate = ['dev' for x in range(1,12)]\n",
    "\n",
    "\n",
    "\n",
    "d = {'y':sin_values + derivate_values,'x':pis, 'label': labels_sin + labels_derivate}\n",
    "data = pd.DataFrame(d)\n",
    "sns.lineplot(data=data, x='x', y='y', hue='label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
