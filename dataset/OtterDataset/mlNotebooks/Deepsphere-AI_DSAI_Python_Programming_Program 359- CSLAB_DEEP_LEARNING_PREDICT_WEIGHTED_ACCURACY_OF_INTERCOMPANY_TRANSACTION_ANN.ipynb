{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE/rlG4ZcjqEKavLTGvTT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20359-%20CSLAB_DEEP_LEARNING_PREDICT_WEIGHTED_ACCURACY_OF_INTERCOMPANY_TRANSACTION_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb8r4CuADKP6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_PREDICT_WEIGHTED_ACCURACY_OF_INTERCOMPANY_TRANSACTION_ANN\n",
        "  # Purpose \t:   A Program in Python for Predicting Weighted Accuracy of IC Using ANN in Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program in Python for Predicting Weighted Accuracy of IC Using ANN in Deep Learning\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "# Step 0 - Read Data from .INI File for Hardcoded Values\n",
        "\n",
        "import sys\n",
        "#print('Arguments:', len(sys.argv))\n",
        "#vAR_Fetched_Data_INI_File_Path = sys.argv[1]\n",
        "#print(vAR_Fetched_Data_INI_File_Path)\n",
        "\n",
        "import configparser\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "import os\n",
        "\n",
        "vAR_INI_File_Path = os.environ.get('PYTHON_TUTORIAL')\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "import configparser\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "vAR_Config.read(vAR_INI_File_Path)\n",
        "\n",
        "vAR_CSLAB_INI_File = vAR_Config['Data File Path']['vAR_CSLAB_PROGRAM_359_INI_FILE']  \n",
        "\n",
        "vAR_Config.read(vAR_CSLAB_INI_File)\n",
        "\n",
        "vAR_Data = vAR_Config.sections()\n",
        "\n",
        "vAR_Config.sections()\n",
        "\n",
        "vAR_Fetched_Data_Source = vAR_Config['Data Source']['DATA_SOURCE1']\n",
        "#print(vAR_Fetched_Data_Source)\n",
        "\n",
        "vAR_Fetched_Data_Source_Connection_String = vAR_Config['Data Source Connection String']['SAP_CONNECTION_STRING']\n",
        "#print(vAR_Fetched_Data_Source_Connection_String)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Input_Data = vAR_Config['Data Source Path']['INPUT_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Input_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Train_Data = vAR_Config['Data Source Path']['TRAIN_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Train_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Test_Data = vAR_Config['Data Source Path']['Test_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features1 = vAR_Config['Train Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Train_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features2 = vAR_Config['Train Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Train_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features3 = vAR_Config['Train Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Train_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features4 = vAR_Config['Train Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Train_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Train_All_Features = vAR_Config['Train Features - Problem 1']['ALL_FEATURES_TRAIN']\n",
        "#print(vAR_Fetched_Data_Train_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features1 = vAR_Config['Train Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Test_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features2 = vAR_Config['Train Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Test_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features3 = vAR_Config['Train Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Test_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features4 = vAR_Config['Train Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Test_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Test_All_Features = vAR_Config['Test Features - Problem 1']['ALL_FEATURES_TEST']\n",
        "#print(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Model_Path = vAR_Config['Model Ouput Path']['MODEL_OUTPUT_PATH']\n",
        "#print(vAR_Fetched_Data_Model_Path)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_1 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_2 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_1 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_2 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_1 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_2 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_3 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['BEFORE_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_After_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['AFTER_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_After_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Best_Fit_Test = vAR_Config['Model Fitting']['BEST_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Best_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Under_Fit_Test = vAR_Config['Model Fitting']['UNDER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Under_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Over_Fit_Test = vAR_Config['Model Fitting']['OVER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Over_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Required = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_REQUIRED']\n",
        "#print(Fetched_Data_Cross_Validation_Required)\n",
        "\n",
        "vAR_Fetched_Data_Hyperparameter_Tuning_Required = vAR_Config['Model_Validation_Tuning']['HYPERPARAMETERS_TUNING_REQUIRED']\n",
        "#print(Fetched_Data_Hyperparameter_Tuning_Required)\n",
        "\n",
        "# Step 1 - Import the Required Libraries\n",
        "\n",
        "#Our Model Implementation needs the Following Libraries:\n",
        "\n",
        "#Sklearn: Sklearn is the Machine Learning Library which is used for numerical & scientific computations.\n",
        "\n",
        "#Pandas: Pandas is a library used for data manipulation and analysis. \n",
        "\n",
        "#In Our Implementation. we are using it for Importing the Data file & Creating Dataframes (Stores the Data).\n",
        "\n",
        "import pandas as vAR_pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 2 - Import Training Data\n",
        "\n",
        "#Next step after importing all libraries is getting the Training data imported. \n",
        "\n",
        "#We are importing the Clustering data stored in our local system with the use of Pandas library.\n",
        "\n",
        "vAR_df = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Train_Data)\n",
        "vAR_df.head(3)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 3 � Select the Features & Lables\n",
        "\n",
        "vAR_Features_Train = vAR_pd.read_excel(vAR_Fetched_Data_Train_All_Features)\n",
        "vAR_Labels_Train = vAR_df.iloc[:,12]\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 4 � Train the Model\n",
        "\n",
        "# Training the data means Making the model to Learn, understand & recognize the Pattern in the data.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "vAR_model = Sequential()\n",
        "\n",
        "vAR_model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
        "vAR_model.add(Dense(5, activation='relu'))\n",
        "vAR_model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Adam optimizer with learning rate of 0.001\n",
        "vAR_optimizer = Adam(lr=0.001)\n",
        "vAR_model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "\n",
        "# Train the model\n",
        "vAR_model.fit(vAR_Features_Train, vAR_Labels_Train, verbose=0, batch_size=5, epochs=200)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 5 � Review Learning AlgorithmvAR_Labels_Train\n",
        "\n",
        "# We Review the Algorithm as to see how it has learned from the Features we Provided\n",
        "vAR_model.predict(vAR_Features_Train).astype(int)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 6 - Import Test Data\n",
        "\n",
        "# Importing the Test Data is to check how the data used on the Model Performs\n",
        "\n",
        "vAR_df6 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "vAR_df6.head(5)\n",
        "vAR_Features_Test = vAR_pd.read_excel(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 7 � Running Model on Test Data\n",
        "\n",
        "# Running the Model on Test Data is to use the imported test data to Prodict our Outcome\n",
        "\n",
        "vAR_Labels_Pred = vAR_model.predict(vAR_Features_Test).astype(int)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 8 � Review Model Outcome\n",
        "\n",
        "# We check the Output of Model i.e the Prediction it has made on the test data\n",
        "\n",
        "vAR_Labels_Pred = vAR_pd.DataFrame(vAR_Labels_Pred,columns={'Predicted_Inter_Transaction_Weighted_Accuracy'})\n",
        "#vAR_Features_test = vAR_Features_test.sort()\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 9 - Write Model Outcome to File\n",
        "\n",
        "# Write the Model Output to an excel file for analysis.\n",
        "\n",
        "vAR_df7 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "vAR_df8 = vAR_df7.iloc[:,:-1]\n",
        "vAR_df10 = vAR_df8.merge(vAR_Labels_Pred,left_index=True, right_index=True)\n",
        "vAR_df11 = vAR_df10.to_excel(vAR_Fetched_Data_Model_Path)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 10 - To open and view the file outcome\n",
        "\n",
        "# Open the Written File &amp; Check the Outcome as Shown. Execute to View the data\n",
        "\n",
        "vAR_df12 = vAR_pd.read_excel(vAR_Fetched_Data_Model_Path)\n",
        "vAR_df12.head()\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    }
  ]
}