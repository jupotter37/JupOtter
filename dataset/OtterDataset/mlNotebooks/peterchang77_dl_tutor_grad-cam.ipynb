{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Understanding the basis for neural network prediction is a key task for troubleshooting errors, improving model architecture and/or increasing data consistency. One of the most popular techniques for feature visualization is the Gradient-weighted Class Activation Mapping (Grad-CAM) approach, which uses the gradients of any target concept flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept. Grad-CAM is applicable to a wide variety of CNN model-families. In this tutorial, we will provide implementation details for the Grad-CAM technique in Tensorflow / Keras using a pneumonia detection algorithm on chest radiograph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Environment\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Jarvis library\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers, optimizers, losses, metrics\n",
    "from matplotlib import pyplot\n",
    "from scipy.ndimage import zoom\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow, montage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of (frontal projection) chest radiographs from a subset of the RSNA / Kaggle pneumonia challenge (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge). From the complete cohort, a random subset of 1,000 exams will be used for training and evaluation.\n",
    "\n",
    "### Download\n",
    "\n",
    "The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/xr_pna`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='xr/pna-512')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python generators\n",
    "\n",
    "Once the dataset is downloaded locally, Python generators to iterate through the dataset can be easily prepared using the `datasets.prepare(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='xr/pna-512', keyword='cls-512')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created generators, `gen_train` and `gen_valid`, are designed to yield two variables per iteration: `xs` and `ys`. Both `xs` and `ys` each represent a dictionary of NumPy arrays containing model input(s) and output(s) for a single *batch* of training. The use of Python generators provides a generic interface for data input for a number of machine learning libraries including Tensorflow 2 / Keras.\n",
    "\n",
    "Note that any valid Python iterable method can be used to loop through the generators indefinitely. For example the Python built-in `next(...)` method will yield the next batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield one example\n",
    "xs, ys = next(gen_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "To help facilitate algorithm design, each original chest radiograph has been resampled to a uniform `(512, 512)` matrix. Overall, the dataset comprises a total of `1,000` 2D images: a total of `500` negaative exams and `500` positive exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xs` dictionary\n",
    "\n",
    "The `xs` dictionary contains a single batch of model inputs:\n",
    "\n",
    "1. `dat`: input chest radiograph resampled to `(1, 512, 512, 1)` matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print keys \n",
    "for key, arr in xs.items():\n",
    "    print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ys` dictionary\n",
    "\n",
    "The `ys` dictionary contains a single batch of model outputs:\n",
    "\n",
    "1. `pna`: binary classification of pneumonia vs. not pneumonia chest radiographs\n",
    "\n",
    "* 0 = negative\n",
    "* 1 = positive of pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print keys \n",
    "for key, arr in ys.items():\n",
    "    print('ys key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Use the following lines of code to visualize a single input image using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show labels\n",
    "xs, ys = next(gen_train)\n",
    "imshow(xs['dat'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following lines of code to visualize an N x N mosaic of all images in the current batch using the `imshow(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show \"montage\" of all images\n",
    "imshow(xs['dat'], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inputs\n",
    "\n",
    "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the equivalent Python code to generate `inputs` would be:\n",
    "\n",
    "```python\n",
    "inputs = {}\n",
    "inputs['dat'] = Input(shape=(1, 512, 512, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "To visualize learned features using Grad-CAM, we will first train a simple binary classifier CNN model for detection of pnuemonia. The simple model will consist of simple alternating stride-1 and stride-2 convolutions with a 3 x 3 kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define lambda functions\n",
    "conv = lambda x, filters, stride : layers.Conv3D(\n",
    "    kernel_size=(1, 3, 3),\n",
    "    filters=filters, \n",
    "    strides=stride, \n",
    "    padding='same')(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.ReLU()(x)\n",
    "\n",
    "# --- Define standard stride-1 and stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters=filters, stride=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters=filters, stride=(1, 2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define contracting layers\n",
    "l1 = conv1(16, inputs['dat'])\n",
    "l2 = conv1(32, conv2(32, l1))\n",
    "l3 = conv1(48, conv2(48, l2))\n",
    "l4 = conv1(64, conv2(64, l3))\n",
    "l5 = conv1(80, conv2(80, l4))\n",
    "l6 = conv1(96, conv2(96, l5))\n",
    "\n",
    "c1 = layers.GlobalAveragePooling3D()(l6)\n",
    "\n",
    "# --- Create logits\n",
    "logits = {}\n",
    "logits['pna'] = layers.Dense(2, name='pna')(c1)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from an original input of `(512, 512)`, application of 5 total subsampling operations will yield a `(16, 16)` feature map in the `l6` (last) convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4), \n",
    "    loss={'pna': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n",
    "    metrics={'pna': 'sparse_categorical_accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Memory Data\n",
    "\n",
    "The following line of code will load all training data into RAM memory. This strategy can be effective for increasing speed of training for small to medium-sized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data into memory\n",
    "client.load_data_in_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=100, \n",
    "    epochs=8,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=100,\n",
    "    validation_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM\n",
    "\n",
    "Gradient-weighted class activation mapping (Grad-CAM) uses the gradients of any target concept flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept. Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers, (2) CNNs used for structured outputs, (3) CNNs used in tasks with multimodal inputs or reinforcement learning, without any architectural changes or re-training. \n",
    "\n",
    "![Grad-CAM](https://miro.medium.com/proxy/1*hHPn81BbKEl7xDsHr5aSIA.png)\n",
    "\n",
    "Additional information can be found here: https://arxiv.org/pdf/1610.02391.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(x, model, layer_index=-5, pred_class=1):\n",
    "    \"\"\"\n",
    "    Method to create heatmap using Grad-CAM technique\n",
    "    \n",
    "    \"\"\"\n",
    "    # --- Create new model including the last layer index\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.layers[layer_index].output, model.output])\n",
    "\n",
    "    # --- Record forward pass operations as TF objects \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(x)\n",
    "        class_channel = preds['pna'][:, pred_class]\n",
    "\n",
    "    # --- Calculate gradient\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # --- Determine mean gradient for each channel (feature map)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2, 3))\n",
    "\n",
    "    # --- Scale and squeeze\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # --- Convert to Numpy\n",
    "    heatmap = heatmap.numpy()\n",
    "    \n",
    "    # --- Clip and normalize to [0 - 1]\n",
    "    heatmap = heatmap.clip(min=0) / heatmap.max(axis=(1,2), keepdims=True)\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create heatmaps for data batch in xs\n",
    "heatmap = create_heatmap(xs, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to overlay heatmaps onto raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(x, heatmap, cmap='jet', alpha=0.2, figsize=(7, 7)):\n",
    "    \n",
    "    # --- Use Jarvis montage function to collapse into a N x N grid\n",
    "    im = np.squeeze(montage(x['dat']))\n",
    "    hm = np.squeeze(montage(heatmap))\n",
    "    \n",
    "    # --- Zoom\n",
    "    hm = zoom(hm, zoom=np.array(im.shape) / np.array(hm.shape), order=1)\n",
    "    \n",
    "    # --- Draw figure\n",
    "    pyplot.clf()\n",
    "    pyplot.figure(figsize=figsize)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(im, cmap='gray')\n",
    "    pyplot.imshow(hm, cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Draw\n",
    "xs, ys = next(gen_train)\n",
    "overlay(xs, heatmap, figsize=(12, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
