{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf-based lexical embedding pipeline\n",
    "\n",
    "In this example notebook we will illustrate how Tf-Idf encoding based on character n-grams of aliases from the [NCIt](https://ncithesaurus.nci.nih.gov/ncitbrowser/) ontology can be used to constuct embeddings of words and lexical similarity search using BlueGraph's `EmbeddingPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import jwt\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import rdflib\n",
    "from rdflib import RDFS, XSD\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "from joblib import parallel_backend\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from kgforge.core import KnowledgeGraphForge\n",
    "from kgforge.specializations.resources import Dataset\n",
    "\n",
    "from bluegraph import version as bg_version\n",
    "from bluegraph import PandasPGFrame\n",
    "from bluegraph.core.utils import Preprocessor\n",
    "from bluegraph.downstream import EmbeddingPipeline\n",
    "from bluegraph.downstream.similarity import FaissSimilarityIndex, SimilarityProcessor\n",
    "from bluegraph.preprocess.utils import TfIdfEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_uri_by_label(graph, label, lang=\"en\", dtype=XSD.string):\n",
    "    params = [\n",
    "        {},\n",
    "        {\"lang\": \"en\"},\n",
    "        {\"datatype\": dtype},\n",
    "        {\"lang\": \"en\", \"datatype\": dtype}\n",
    "    ]\n",
    "    resource = None\n",
    "    for param_set in params:\n",
    "        for s in graph.subjects(RDFS.label, rdflib.Literal(label, **param_set)):\n",
    "            resource = str(s)\n",
    "            break\n",
    "        if resource is not None:\n",
    "            break\n",
    "    \n",
    "    return resource\n",
    "\n",
    "def get_agent(token):\n",
    "    agent_data = jwt.decode(token, verify=False)\n",
    "    agent = forge.reshape(\n",
    "        forge.from_json(agent_data), keep=[\n",
    "            \"name\", \"email\", \"sub\", \"preferred_username\"])\n",
    "    agent.id = agent.sub\n",
    "    agent.type = \"Person\"\n",
    "    return agent\n",
    "\n",
    "\n",
    "def register_model(forge, agent, name, description, label, distribution, similarity, dimension):\n",
    "    # Create a new model resource\n",
    "    model_resource = Dataset(\n",
    "        forge,\n",
    "        name=name,\n",
    "        description=description)\n",
    "    model_resource.type = \"EmbeddingModel\"\n",
    "    model_resource.prefLabel = label\n",
    "    model_resource.similarity = similarity\n",
    "    model_resource.vectorDimension = dimension\n",
    "\n",
    "    # Add distrubution\n",
    "    if distribution is not None:\n",
    "        model_resource.add_distribution(\n",
    "            distribution, content_type=\"application/octet-stream\")\n",
    "\n",
    "    # Add contribution\n",
    "    model_resource.add_contribution(agent, versioned=False)\n",
    "    role = forge.from_json({\n",
    "        \"hadRole\": {\n",
    "            \"id\": \"http://purl.obolibrary.org/obo/CRO_0000064\",\n",
    "            \"label\": \"software engineering role\"\n",
    "        }\n",
    "    })\n",
    "    model_resource.contribution.hadRole = role\n",
    "\n",
    "    # Add software agent\n",
    "    software_agent = {\n",
    "        \"type\": \"SoftwareAgent\",\n",
    "        \"description\": \"Unifying Python framework for graph analytics and co-occurrence analysis.\",\n",
    "        \"name\": \"BlueGraph\",\n",
    "        \"softwareSourceCode\": {\n",
    "            \"type\": \"SoftwareSourceCode\",\n",
    "            \"codeRepository\": \"https://github.com/BlueBrain/BlueGraph\",\n",
    "            \"programmingLanguage\": \"Python\",\n",
    "            \"runtimePlatform\": f\"{sys.version_info.major}.{sys.version_info.minor}\",\n",
    "            \"version\": bg_version.__version__\n",
    "        }\n",
    "    }\n",
    "    model_resource.wasAssociatedWith = software_agent\n",
    "    \n",
    "    forge.register(model_resource)\n",
    "    return model_resource.id\n",
    "\n",
    "\n",
    "def update_model_distribution(forge, model_resource, new_distribution, vector_dim=None):\n",
    "    if vector_dim is not None:\n",
    "        model_resource.vectorDimension = vector_dim\n",
    "    model_resource.distribution = forge.attach(new_distribution, content_type=\"application/octet-stream\")\n",
    "    forge.update(model_resource)\n",
    "    \n",
    "\n",
    "def push_model(forge, agent, name, description, label, distribution, similarity, dimension):\n",
    "    result = forge.search({\"name\": name})\n",
    "    if result:\n",
    "        print(\"Model exists, updating...\")\n",
    "        model_resource = result[0]\n",
    "        update_model_distribution(forge, model_resource, distribution, dimension)\n",
    "    else:\n",
    "        print(\"Registering new model...\")\n",
    "        register_model(forge, agent, name, description, label, distribution, similarity, dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_graph = rdflib.Graph()\n",
    "ontology_graph.parse(\"../../ontologies/bbp/bmo.ttl\", format=\"ttl\")\n",
    "ontology_graph.parse(\"../../ontologies/bbp/molecular-systems.ttl\", format=\"ttl\")\n",
    "ontology_graph.parse(\"../../ontologies/bbp/etypes.ttl\", format=\"ttl\")\n",
    "ontology_graph.parse(\"../../ontologies/bbp/mtypes.ttl\", format=\"ttl\")\n",
    "# ontology_graph.parse(\"../../ontologies/external/allen_MBA_ontology_ccfv3.ttl\", format=\"ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = PandasPGFrame.from_ontology(rdf_graph=ontology_graph, remove_prop_uris=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIAS_PROPS = [\"label\", \"prefLabel\", \"synonym\", \"altLabel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all unique aliases (all lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_mapping = {}\n",
    "for node in frame.nodes():\n",
    "    record = frame._nodes.loc[node].to_dict()\n",
    "    for prop in ALIAS_PROPS:\n",
    "        if not isinstance(record[prop], float):\n",
    "            value = record[prop]\n",
    "            if isinstance(value, str):\n",
    "                alias_mapping[record[prop].lower()] = find_uri_by_label(ontology_graph, node)\n",
    "            else:\n",
    "                for el in value:\n",
    "                    alias_mapping[el.lower()] = find_uri_by_label(ontology_graph, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = list(alias_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Tf-Idf model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"analyzer\": \"char\",\n",
    "    \"dtype\": np.float32,\n",
    "    \"max_df\": 1.0,\n",
    "    \"min_df\": 0.0001,\n",
    "    \"ngram_range\": (3, 3),\n",
    "    \"max_features\": 1024\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of `EmbeddingPipeline` using:\n",
    "\n",
    "- `TfIdfEncoder` as a preprocessor,\n",
    "- No embedder\n",
    "- BlueGraph `SimilarityProcessor` with Euclidean distance based on an index segmented into 100 Voronoi cells (more details can be found [here](https://github.com/facebookresearch/faiss/wiki/Faster-search))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = FaissSimilarityIndex(\n",
    "    dimension=d, similarity=\"euclidean\", n_segments=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = EmbeddingPipeline(\n",
    "    preprocessor=TfIdfEncoder(params),\n",
    "    embedder=None,\n",
    "    similarity_processor=SimilarityProcessor(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run fitting of the pipeline on the aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run_fitting(aliases, point_ids=aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save(\"../data/BMO-linking\", compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push model into Nexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge = KnowledgeGraphForge(\n",
    "    \"../../config/forge-config.yml\",\n",
    "    endpoint=\"https://bbp.epfl.ch/nexus/v1\",\n",
    "    token=TOKEN,\n",
    "    bucket=\"dke/embedding-pipelines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_model_resource = push_model(\n",
    "    forge, agent, \"BMO term embedding with Tf-Idf\",\n",
    "    \"Embedding of BMO terms using a simple Tf-Idf-based model on on character n-grams\",\n",
    "    \"BMO Tf-Idf Embedding\",\n",
    "    \"../data/BMO-linking.zip\", \"euclidean\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_table = pipeline.generate_embedding_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_table.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve embedding vectors for the trems of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    \"l5_lbc\",\n",
    "    \"layer 5 bipolar cell\",\n",
    "    \"burst non-accommodating electrical type\",\n",
    "    \"lalala not in index\",\n",
    "    \"emodel building workflow\",\n",
    "#     \"primary somatosensory area\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pipeline.retrieve_embeddings(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector sizes: \")\n",
    "for i, v in enumerate(vectors):\n",
    "    print(\"\\t'{}': {}\".format(terms[i], len(v) if v is not None else None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get similar points to the query terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, points = pipeline.get_neighbors(\n",
    "    existing_points=terms, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, el in enumerate(terms):\n",
    "    print(f\"Similar terms to '{el}': \")\n",
    "    if points[i] is not None:\n",
    "        for p in points[i]:\n",
    "            print(f\"\\t- {p} (ontology term {alias_mapping[p]})\")\n",
    "    else:\n",
    "        print(f\"\\t {el} is not in index\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict vectors for potentially unseen points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_predict = [\n",
    "    \"bipolar cell\",\n",
    "    \"burst non-accommodating neuron\",\n",
    "    \"mariotti cell\",\n",
    "    \"e-model reconstruction workflow\",\n",
    "    \"burst electrical type\",\n",
    "#     \"primary somatosensory cortex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pipeline.run_prediction(terms_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get similar points for these vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, points = pipeline.get_neighbors(vectors=vectors, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, el in enumerate(terms_to_predict):\n",
    "    print(f\"Similar terms to '{el}': \")\n",
    "    if points[i] is not None:\n",
    "        for p in points[i]:\n",
    "            print(f\"\\t- {p} (ontology term {alias_mapping[p]})\")\n",
    "    else:\n",
    "        print(f\"\\t {el} is not in index\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "bg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
