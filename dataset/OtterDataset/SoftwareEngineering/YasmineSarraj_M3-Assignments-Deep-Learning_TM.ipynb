{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis based on topic extraction\n",
    "In this part we are performing a network analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import math\n",
    "import ast #for transforming dataframes\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from bertopic import BERTopic\n",
    "\n",
    "#Network analysis \n",
    "import seaborn as sns\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.drawing.layout import bipartite_layout\n",
    "import networkx as nx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis\n",
    "We are going to explore co-authorship network in authors that wrote about AI. \n",
    "Our goal is to get the eigenvector centrality to establish our well connected author in order to set up the recommender system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the docs that had the topic modelling done with the BERTopic\n",
    "docs = pd.read_csv('/Users/yasminesarraj/Documents/GitHub/M3-Assignment-Deep-Learning/Assignment_4/data/full_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Attention Is All You Need\\nAshish Vaswani\u0003\\nG...</td>\n",
       "      <td>This paper proposes the Transformer, a model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>On the Beneﬁts of Biophysical Synapses\\nJulia...</td>\n",
       "      <td>This paper examines the use of biophysical sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MOREA: a GPU-accelerated Evolutionary Algorit...</td>\n",
       "      <td>This paper presents MOREA, a GPU-accelerated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What Performance Indicators to Use for Self-A...</td>\n",
       "      <td>This paper investigates the use of self-adapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Using Affine Combinations of BBOB Problems fo...</td>\n",
       "      <td>This paper examines the use of affine combina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arXiv:2303.04347v1  [cs.NE]  8 Mar 2023Publis...</td>\n",
       "      <td>This paper presents a method for converting a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Evolutionary Reinforcement Learning: A Survey...</td>\n",
       "      <td>This article provides an overview of Evolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>RADAM: T EXTURE RECOGNITION THROUGH RANDOMIZE...</td>\n",
       "      <td>This paper proposes a new method called Rando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A Computer Vision Enabled damage detection mo...</td>\n",
       "      <td>This paper presents a novel deep learning-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Patch of Invisibility:\\nNaturalistic Black-Bo...</td>\n",
       "      <td>This paper proposes a gradient-free method to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>MAP-Elites with Descriptor-Conditioned Gradie...</td>\n",
       "      <td>This paper presents DCG-MAP-Elites, a new alg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Multiplexed gradient descent: Fast online tra...</td>\n",
       "      <td>This paper presents the Multiplexed Gradient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1 Wang et al. Evolutionary Deep Nets for Non-...</td>\n",
       "      <td>\\n\\nThis paper presents a novel approach to no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>SYMBOLIC SYNTHESIS OF NEURAL NETWORKS\\nEli Wh...</td>\n",
       "      <td>This paper presents Graph-based Symbolically ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Noname manuscript No.\\n(will be inserted by t...</td>\n",
       "      <td>This paper presents an optimization framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Using a Variational Autoencoder  to Learn Val...</td>\n",
       "      <td>This paper explores the use of a hybrid machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Vectorial Genetic Programming { Optimizing\\nS...</td>\n",
       "      <td>This paper presents Vectorial Genetic Program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>This work has been submitted to the IEEE for ...</td>\n",
       "      <td>This paper proposes a new acceleration techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1   S  \\n \\nEmerging AI Technologies Inspirin...</td>\n",
       "      <td>This paper explores the potential of emerging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Networks’ modulation: How diﬀerent structural...</td>\n",
       "      <td>This paper examines the impact of different n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>On Modifying a Neural Network’s Perception\\nM...</td>\n",
       "      <td>This paper reviews a variety of research pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Notice\\nThis work has been submitted to the I...</td>\n",
       "      <td>This paper proposes Swim, a new activation fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Ensemble Reinforcement Learning: A Survey\\nYa...</td>\n",
       "      <td>This paper provides an overview of Ensemble R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Diffusion Models Generate Images Like Painter...</td>\n",
       "      <td>This paper examines the use of diffusion mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Conﬂict-driven Structural Learning Towards Hi...</td>\n",
       "      <td>This paper proposes a Conflict-Driven Structu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>TopSpark: A Timestep Optimization Methodology...</td>\n",
       "      <td>This paper presents TopSpark, a novel methodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>arXiv:2303.01695v1  [cs.NE]  3 Mar 2023EVOLUT...</td>\n",
       "      <td>This paper reviews five studies on evolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Linear CNNs discover the statistical structur...</td>\n",
       "      <td>This paper examines the use of linear convolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Magnetic Stochastic Synapses\\nMachine learnin...</td>\n",
       "      <td>This paper presents a novel learning rule for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Reservoir computing based on solitary-like wa...</td>\n",
       "      <td>This paper presents a novel reservoir computi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>EVOLUTIONARY AUGMENTATION POLICY OPTIMIZATION...</td>\n",
       "      <td>This paper proposes an evolutionary augmentat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Hindsight States:\\nBlending Sim &amp; Real Task E...</td>\n",
       "      <td>This paper presents Hindsight States (HiS), a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>ChatGPT and Other Large Language Models as Ev...</td>\n",
       "      <td>This paper presents a framework combining int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>PDSketch: Integrated Planning Domain\\nProgram...</td>\n",
       "      <td>This paper introduces PDSketch, a domain defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Learning Rational Subgoals from Demonstration...</td>\n",
       "      <td>This paper presents a framework for learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Knowledge-augmented Risk Assessment (KaRA): a...</td>\n",
       "      <td>This paper presents the Knowledge-augmented R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Published as a conference paper at ICLR 2023\\...</td>\n",
       "      <td>This paper presents a novel algorithm, Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Published as a conference paper at ICLR 2023\\...</td>\n",
       "      <td>This paper presents TANGOS, a regularization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Accepted to the ICLR 2023 TrustML-(un)Limited...</td>\n",
       "      <td>This paper examines the vulnerability of pre-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Multiplexed gradient descent: Fast online tra...</td>\n",
       "      <td>This paper presents the Multiplexed Gradient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>SYMBOLIC SYNTHESIS OF NEURAL NETWORKS\\nEli Wh...</td>\n",
       "      <td>This paper presents Graph-based Symbolically ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>MAP-Elites with Descriptor-Conditioned Gradie...</td>\n",
       "      <td>This paper presents DCG-MAP-Elites, a Quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>A Computer Vision Enabled damage detection mo...</td>\n",
       "      <td>This paper presents a novel deep learning-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Using a Variational Autoencoder  to Learn Val...</td>\n",
       "      <td>This paper explores the use of a hybrid machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Vectorial Genetic Programming { Optimizing\\nS...</td>\n",
       "      <td>This paper presents Vectorial Genetic Program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Networks’ modulation: How diﬀerent structural...</td>\n",
       "      <td>This paper examines the impact of different n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>arXiv:2303.01695v1  [cs.NE]  3 Mar 2023EVOLUT...</td>\n",
       "      <td>This paper reviews five studies on evolutiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  \\\n",
       "0            0   Attention Is All You Need\\nAshish Vaswani\u0003\\nG...   \n",
       "1            1   On the Beneﬁts of Biophysical Synapses\\nJulia...   \n",
       "2            2   MOREA: a GPU-accelerated Evolutionary Algorit...   \n",
       "3            3   What Performance Indicators to Use for Self-A...   \n",
       "4            4   Using Affine Combinations of BBOB Problems fo...   \n",
       "5            5   arXiv:2303.04347v1  [cs.NE]  8 Mar 2023Publis...   \n",
       "6            6   Evolutionary Reinforcement Learning: A Survey...   \n",
       "7            7   RADAM: T EXTURE RECOGNITION THROUGH RANDOMIZE...   \n",
       "8            8   A Computer Vision Enabled damage detection mo...   \n",
       "9            9   Patch of Invisibility:\\nNaturalistic Black-Bo...   \n",
       "10          10   MAP-Elites with Descriptor-Conditioned Gradie...   \n",
       "11          11   Multiplexed gradient descent: Fast online tra...   \n",
       "12          12   1 Wang et al. Evolutionary Deep Nets for Non-...   \n",
       "13          13   SYMBOLIC SYNTHESIS OF NEURAL NETWORKS\\nEli Wh...   \n",
       "14          14   Noname manuscript No.\\n(will be inserted by t...   \n",
       "15          15   Using a Variational Autoencoder  to Learn Val...   \n",
       "16          16   Vectorial Genetic Programming { Optimizing\\nS...   \n",
       "17          17   This work has been submitted to the IEEE for ...   \n",
       "18          18   1   S  \\n \\nEmerging AI Technologies Inspirin...   \n",
       "19          19   Networks’ modulation: How diﬀerent structural...   \n",
       "20          20   On Modifying a Neural Network’s Perception\\nM...   \n",
       "21          21   Notice\\nThis work has been submitted to the I...   \n",
       "22          22   Ensemble Reinforcement Learning: A Survey\\nYa...   \n",
       "23          23   Diffusion Models Generate Images Like Painter...   \n",
       "24          24   Conﬂict-driven Structural Learning Towards Hi...   \n",
       "25          25   TopSpark: A Timestep Optimization Methodology...   \n",
       "26          26   arXiv:2303.01695v1  [cs.NE]  3 Mar 2023EVOLUT...   \n",
       "27          27   Linear CNNs discover the statistical structur...   \n",
       "28          28   Magnetic Stochastic Synapses\\nMachine learnin...   \n",
       "29          29   Reservoir computing based on solitary-like wa...   \n",
       "30          30   EVOLUTIONARY AUGMENTATION POLICY OPTIMIZATION...   \n",
       "31          31   Hindsight States:\\nBlending Sim & Real Task E...   \n",
       "32          32   ChatGPT and Other Large Language Models as Ev...   \n",
       "33          33   PDSketch: Integrated Planning Domain\\nProgram...   \n",
       "34          34   Learning Rational Subgoals from Demonstration...   \n",
       "35          35   Knowledge-augmented Risk Assessment (KaRA): a...   \n",
       "36          36   Published as a conference paper at ICLR 2023\\...   \n",
       "37          37   Published as a conference paper at ICLR 2023\\...   \n",
       "38          38   Accepted to the ICLR 2023 TrustML-(un)Limited...   \n",
       "39          39   Multiplexed gradient descent: Fast online tra...   \n",
       "40          40   SYMBOLIC SYNTHESIS OF NEURAL NETWORKS\\nEli Wh...   \n",
       "41          41   MAP-Elites with Descriptor-Conditioned Gradie...   \n",
       "42          42   A Computer Vision Enabled damage detection mo...   \n",
       "43          43   Using a Variational Autoencoder  to Learn Val...   \n",
       "44          44   Vectorial Genetic Programming { Optimizing\\nS...   \n",
       "45          45   Networks’ modulation: How diﬀerent structural...   \n",
       "46          46   arXiv:2303.01695v1  [cs.NE]  3 Mar 2023EVOLUT...   \n",
       "\n",
       "                                              summary  \n",
       "0    This paper proposes the Transformer, a model ...  \n",
       "1    This paper examines the use of biophysical sy...  \n",
       "2    This paper presents MOREA, a GPU-accelerated ...  \n",
       "3    This paper investigates the use of self-adapt...  \n",
       "4    This paper examines the use of affine combina...  \n",
       "5    This paper presents a method for converting a...  \n",
       "6    This article provides an overview of Evolutio...  \n",
       "7    This paper proposes a new method called Rando...  \n",
       "8    This paper presents a novel deep learning-bas...  \n",
       "9    This paper proposes a gradient-free method to...  \n",
       "10   This paper presents DCG-MAP-Elites, a new alg...  \n",
       "11   This paper presents the Multiplexed Gradient ...  \n",
       "12  \\n\\nThis paper presents a novel approach to no...  \n",
       "13   This paper presents Graph-based Symbolically ...  \n",
       "14   This paper presents an optimization framework...  \n",
       "15   This paper explores the use of a hybrid machi...  \n",
       "16   This paper presents Vectorial Genetic Program...  \n",
       "17   This paper proposes a new acceleration techni...  \n",
       "18   This paper explores the potential of emerging...  \n",
       "19   This paper examines the impact of different n...  \n",
       "20   This paper reviews a variety of research pape...  \n",
       "21   This paper proposes Swim, a new activation fu...  \n",
       "22   This paper provides an overview of Ensemble R...  \n",
       "23   This paper examines the use of diffusion mode...  \n",
       "24   This paper proposes a Conflict-Driven Structu...  \n",
       "25   This paper presents TopSpark, a novel methodo...  \n",
       "26   This paper reviews five studies on evolutiona...  \n",
       "27   This paper examines the use of linear convolu...  \n",
       "28   This paper presents a novel learning rule for...  \n",
       "29   This paper presents a novel reservoir computi...  \n",
       "30   This paper proposes an evolutionary augmentat...  \n",
       "31   This paper presents Hindsight States (HiS), a...  \n",
       "32   This paper presents a framework combining int...  \n",
       "33   This paper introduces PDSketch, a domain defi...  \n",
       "34   This paper presents a framework for learning ...  \n",
       "35   This paper presents the Knowledge-augmented R...  \n",
       "36   This paper presents a novel algorithm, Planni...  \n",
       "37   This paper presents TANGOS, a regularization ...  \n",
       "38   This paper examines the vulnerability of pre-...  \n",
       "39   This paper presents the Multiplexed Gradient ...  \n",
       "40   This paper presents Graph-based Symbolically ...  \n",
       "41   This paper presents DCG-MAP-Elites, a Quality...  \n",
       "42   This paper presents a novel deep learning-bas...  \n",
       "43   This paper explores the use of a hybrid machi...  \n",
       "44   This paper presents Vectorial Genetic Program...  \n",
       "45   This paper examines the impact of different n...  \n",
       "46   This paper reviews five studies on evolutiona...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'summary'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  47 non-null     int64 \n",
      " 1   text        47 non-null     object\n",
      " 2   summary     47 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(data):\n",
    "    \"\"\"\n",
    "    Compact function to clean up the data\n",
    "\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(docs)), desc = 'Clean up'):\n",
    "        df = data.copy()\n",
    "        \n",
    "        #Delete missings\n",
    "        df_clean = df.dropna(subset=['Author Keywords'])\n",
    "                \n",
    "        #Format the dtypes of year column + extract the year\n",
    "        df_clean = df_clean.rename(columns={\"Year\": \"date\"}) #rename year column\n",
    "        df_clean[\"date\"] = pd.to_datetime(df_clean[\"date\"]) #format to datetime\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean up: 100%|██████████| 2000/2000 [00:03<00:00, 620.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>date</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>...</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>PubMed ID</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Krishnan P., Jain K., Aldweesh A., Prabu P., B...</td>\n",
       "      <td>57194605863;57215744374;57200513576;5720079815...</td>\n",
       "      <td>OpenStackDP: a scalable network security frame...</td>\n",
       "      <td>1970-01-01 00:00:00.000002023</td>\n",
       "      <td>Journal of Cloud Computing</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Cloud Comput.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85149016620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cai J., Xu Z., Sun X., Guo X., Fu X.</td>\n",
       "      <td>57715240900;58115802100;57211301540;5811503830...</td>\n",
       "      <td>Validity and reliability of the Chinese versio...</td>\n",
       "      <td>1970-01-01 00:00:00.000002023</td>\n",
       "      <td>Psicologia: Reflexao e Critica</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Psicol. Reflexao Crit.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85148711886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tlili A., Shehata B., Adarkwah M.A., Bozkurt A...</td>\n",
       "      <td>57188567626;57782639700;57219025710;5656618160...</td>\n",
       "      <td>What if the devil is my guardian angel: ChatGP...</td>\n",
       "      <td>1970-01-01 00:00:00.000002023</td>\n",
       "      <td>Smart Learning Environments</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Smart Learn. Environ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85148704172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cheikh Youssef S., Haram K., Noël J., Patel V....</td>\n",
       "      <td>57891446400;58113891400;57212704902;8564080000...</td>\n",
       "      <td>Evolution of the digital operating room: the p...</td>\n",
       "      <td>1970-01-01 00:00:00.000002023</td>\n",
       "      <td>Langenbeck's Archives of Surgery</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LASUF</td>\n",
       "      <td>36807211.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Langenbeck's Arch. Surg.</td>\n",
       "      <td>Review</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85148679306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wang J., Dou J., Han J., Li G., Tao J.</td>\n",
       "      <td>57192107513;58108655300;58108630800;5595179220...</td>\n",
       "      <td>A population-based study to assess two convolu...</td>\n",
       "      <td>1970-01-01 00:00:00.000002023</td>\n",
       "      <td>BMC Oral Health</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36803132.0</td>\n",
       "      <td>English</td>\n",
       "      <td>BMC Oral Health</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85148394539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Authors  \\\n",
       "6   Krishnan P., Jain K., Aldweesh A., Prabu P., B...   \n",
       "10               Cai J., Xu Z., Sun X., Guo X., Fu X.   \n",
       "11  Tlili A., Shehata B., Adarkwah M.A., Bozkurt A...   \n",
       "12  Cheikh Youssef S., Haram K., Noël J., Patel V....   \n",
       "19             Wang J., Dou J., Han J., Li G., Tao J.   \n",
       "\n",
       "                                         Author(s) ID  \\\n",
       "6   57194605863;57215744374;57200513576;5720079815...   \n",
       "10  57715240900;58115802100;57211301540;5811503830...   \n",
       "11  57188567626;57782639700;57219025710;5656618160...   \n",
       "12  57891446400;58113891400;57212704902;8564080000...   \n",
       "19  57192107513;58108655300;58108630800;5595179220...   \n",
       "\n",
       "                                                Title  \\\n",
       "6   OpenStackDP: a scalable network security frame...   \n",
       "10  Validity and reliability of the Chinese versio...   \n",
       "11  What if the devil is my guardian angel: ChatGP...   \n",
       "12  Evolution of the digital operating room: the p...   \n",
       "19  A population-based study to assess two convolu...   \n",
       "\n",
       "                            date                      Source title Volume  \\\n",
       "6  1970-01-01 00:00:00.000002023        Journal of Cloud Computing     12   \n",
       "10 1970-01-01 00:00:00.000002023    Psicologia: Reflexao e Critica     36   \n",
       "11 1970-01-01 00:00:00.000002023       Smart Learning Environments     10   \n",
       "12 1970-01-01 00:00:00.000002023  Langenbeck's Archives of Surgery    408   \n",
       "19 1970-01-01 00:00:00.000002023                   BMC Oral Health     23   \n",
       "\n",
       "   Issue Art. No. Page start Page end  ...  ISBN  CODEN   PubMed ID  \\\n",
       "6      1       26        NaN      NaN  ...   NaN    NaN         NaN   \n",
       "10     1        5        NaN      NaN  ...   NaN    NaN         NaN   \n",
       "11     1       15        NaN      NaN  ...   NaN    NaN         NaN   \n",
       "12     1       95        NaN      NaN  ...   NaN  LASUF  36807211.0   \n",
       "19     1      109        NaN      NaN  ...   NaN    NaN  36803132.0   \n",
       "\n",
       "   Language of Original Document  Abbreviated Source Title Document Type  \\\n",
       "6                        English          J. Cloud Comput.       Article   \n",
       "10                       English    Psicol. Reflexao Crit.       Article   \n",
       "11                       English     Smart Learn. Environ.       Article   \n",
       "12                       English  Langenbeck's Arch. Surg.        Review   \n",
       "19                       English           BMC Oral Health       Article   \n",
       "\n",
       "   Publication Stage                   Open Access  Source                 EID  \n",
       "6              Final         All Open Access, Gold  Scopus  2-s2.0-85149016620  \n",
       "10             Final  All Open Access, Gold, Green  Scopus  2-s2.0-85148711886  \n",
       "11             Final         All Open Access, Gold  Scopus  2-s2.0-85148704172  \n",
       "12             Final                           NaN  Scopus  2-s2.0-85148679306  \n",
       "19             Final         All Open Access, Gold  Scopus  2-s2.0-85148394539  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execute function\n",
    "data_clean = clean_up(docs)\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating different edges that we will use as both edges and or as nodes attributes\n",
    "- Author_paper: each author and the paper that they have wrote this will be the base of our bipartite graph \n",
    "\n",
    "It's important to note that we are using ID's instead of names as they are more Institution ID's, this might be due to the face that some institution have the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors                                  object\n",
      "Author(s) ID                             object\n",
      "Title                                    object\n",
      "date                             datetime64[ns]\n",
      "Source title                             object\n",
      "Volume                                   object\n",
      "Issue                                    object\n",
      "Art. No.                                 object\n",
      "Page start                               object\n",
      "Page end                                 object\n",
      "Page count                              float64\n",
      "Cited by                                float64\n",
      "DOI                                      object\n",
      "Link                                     object\n",
      "Affiliations                             object\n",
      "Authors with affiliations                object\n",
      "Abstract                                 object\n",
      "Author Keywords                          object\n",
      "Index Keywords                           object\n",
      "Correspondence Address                   object\n",
      "Editors                                  object\n",
      "Publisher                                object\n",
      "ISSN                                     object\n",
      "ISBN                                     object\n",
      "CODEN                                    object\n",
      "PubMed ID                               float64\n",
      "Language of Original Document            object\n",
      "Abbreviated Source Title                 object\n",
      "Document Type                            object\n",
      "Publication Stage                        object\n",
      "Open Access                              object\n",
      "Source                                   object\n",
      "EID                                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Multiple columns string conversion\n",
    "data_clean['Abstract'] = data_clean['Abstract'].astype(str)\n",
    "data_clean['Title'] = data_clean['Title'].astype(str)\n",
    "print(data_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_paper= []\n",
    "\n",
    "for i in data_clean.iterrows(): #iterate through each row\n",
    "  targets_x = [i.strip() for i in i[1]['Author(s) ID'].split(';')]\n",
    "  edges_x = [(i[1]['Title'], j) for j in targets_x] #connect to the paper\n",
    "  \n",
    "    #append each of the found edges to the list\n",
    "  author_paper.extend(edges_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_abstract= []\n",
    "\n",
    "for i in data_clean.iterrows(): #iterate through each row\n",
    "  targets_y = [i.strip() for i in i[1]['Title']]\n",
    "  edges_y = [[i[1]['Abstract'], j] for j in targets_x] #connect to the paper\n",
    "  \n",
    "    #append each of the found edges to the list\n",
    "  paper_abstract.extend(edges_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['Abstract'] = data_clean['Abstract'].astype(str)\n",
    "test = data_clean['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/fabiochiu/t5-base-tag-generation\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = query({\n",
    "\t\"inputs\": docs.iloc[4,1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Optimization, Software, Digital, Software Development, Programming, Coding, Code, Software Engineering'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(language=\"english\")\n",
    "topics, probs = model.fit_transform(docs['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count\n",
       "0     -1     20\n",
       "1      0     14\n",
       "2      1     13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_topic_freq().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.10321597836088299),\n",
       " ('of', 0.08382433717510913),\n",
       " ('and', 0.07348330546638471),\n",
       " ('to', 0.06685250935462915),\n",
       " ('in', 0.05935176629978951),\n",
       " ('is', 0.04007197364810682),\n",
       " ('neural', 0.03580892956103275),\n",
       " ('for', 0.034663546338450264),\n",
       " ('as', 0.02916828654800408),\n",
       " ('we', 0.029046300893989054)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_topic(0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mvisualize_topics()\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/bertopic/_bertopic.py:2042\u001b[0m, in \u001b[0;36mBERTopic.visualize_topics\u001b[0;34m(self, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Visualize topics, their sizes, and their corresponding words\u001b[39;00m\n\u001b[1;32m   2013\u001b[0m \n\u001b[1;32m   2014\u001b[0m \u001b[39mThis visualization is highly inspired by LDAvis, a great visualization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 2042\u001b[0m \u001b[39mreturn\u001b[39;00m plotting\u001b[39m.\u001b[39;49mvisualize_topics(\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2043\u001b[0m                                  topics\u001b[39m=\u001b[39;49mtopics,\n\u001b[1;32m   2044\u001b[0m                                  top_n_topics\u001b[39m=\u001b[39;49mtop_n_topics,\n\u001b[1;32m   2045\u001b[0m                                  custom_labels\u001b[39m=\u001b[39;49mcustom_labels,\n\u001b[1;32m   2046\u001b[0m                                  title\u001b[39m=\u001b[39;49mtitle,\n\u001b[1;32m   2047\u001b[0m                                  width\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m   2048\u001b[0m                                  height\u001b[39m=\u001b[39;49mheight)\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/bertopic/plotting/_topics.py:73\u001b[0m, in \u001b[0;36mvisualize_topics\u001b[0;34m(topic_model, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     71\u001b[0m embeddings \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mc_tf_idf_\u001b[39m.\u001b[39mtoarray()[indices]\n\u001b[1;32m     72\u001b[0m embeddings \u001b[39m=\u001b[39m MinMaxScaler()\u001b[39m.\u001b[39mfit_transform(embeddings)\n\u001b[0;32m---> 73\u001b[0m embeddings \u001b[39m=\u001b[39m UMAP(n_neighbors\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhellinger\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(embeddings)\n\u001b[1;32m     75\u001b[0m \u001b[39m# Visualize with plotly\u001b[39;00m\n\u001b[1;32m     76\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: embeddings[:, \u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m: embeddings[:, \u001b[39m1\u001b[39m],\n\u001b[1;32m     77\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m: topic_list, \u001b[39m\"\u001b[39m\u001b[39mWords\u001b[39m\u001b[39m\"\u001b[39m: words, \u001b[39m\"\u001b[39m\u001b[39mSize\u001b[39m\u001b[39m\"\u001b[39m: frequencies})\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/umap/umap_.py:2772\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2743\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2744\u001b[0m \u001b[39m    output.\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[39m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2771\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2772\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m   2773\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2774\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/umap/umap_.py:2684\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2681\u001b[0m     \u001b[39mprint\u001b[39m(ts(), \u001b[39m\"\u001b[39m\u001b[39mConstruct embedding\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2684\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, aux_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_embed_data(\n\u001b[1;32m   2685\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_data[index],\n\u001b[1;32m   2686\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_epochs,\n\u001b[1;32m   2687\u001b[0m         init,\n\u001b[1;32m   2688\u001b[0m         random_state,  \u001b[39m# JH why raw data?\u001b[39;49;00m\n\u001b[1;32m   2689\u001b[0m     )\n\u001b[1;32m   2690\u001b[0m     \u001b[39m# Assign any points that are fully disconnected from our manifold(s) to have embedding\u001b[39;00m\n\u001b[1;32m   2691\u001b[0m     \u001b[39m# coordinates of np.nan.  These will be filtered by our plotting functions automatically.\u001b[39;00m\n\u001b[1;32m   2692\u001b[0m     \u001b[39m# They also prevent users from being deceived a distance query to one of these points.\u001b[39;00m\n\u001b[1;32m   2693\u001b[0m     \u001b[39m# Might be worth moving this into simplicial_set_embedding or _fit_embed_data\u001b[39;00m\n\u001b[1;32m   2694\u001b[0m     disconnected_vertices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mflatten() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/umap/umap_.py:2717\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_embed_data\u001b[39m(\u001b[39mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[1;32m   2714\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[1;32m   2715\u001b[0m \u001b[39m    replaced by subclasses.\u001b[39;00m\n\u001b[1;32m   2716\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2717\u001b[0m     \u001b[39mreturn\u001b[39;00m simplicial_set_embedding(\n\u001b[1;32m   2718\u001b[0m         X,\n\u001b[1;32m   2719\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_,\n\u001b[1;32m   2720\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m   2721\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initial_alpha,\n\u001b[1;32m   2722\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a,\n\u001b[1;32m   2723\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b,\n\u001b[1;32m   2724\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepulsion_strength,\n\u001b[1;32m   2725\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_sample_rate,\n\u001b[1;32m   2726\u001b[0m         n_epochs,\n\u001b[1;32m   2727\u001b[0m         init,\n\u001b[1;32m   2728\u001b[0m         random_state,\n\u001b[1;32m   2729\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_distance_func,\n\u001b[1;32m   2730\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_kwds,\n\u001b[1;32m   2731\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdensmap,\n\u001b[1;32m   2732\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_densmap_kwds,\n\u001b[1;32m   2733\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_dens,\n\u001b[1;32m   2734\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_distance_func,\n\u001b[1;32m   2735\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_metric_kwds,\n\u001b[1;32m   2736\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_metric \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ml2\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   2737\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2738\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   2739\u001b[0m         tqdm_kwds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtqdm_kwds,\n\u001b[1;32m   2740\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/umap/umap_.py:1066\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     n_epochs \u001b[39m=\u001b[39m default_epochs\n\u001b[1;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m n_epochs \u001b[39m>\u001b[39m \u001b[39m10\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(n_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m   1067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1068\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(default_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/M3-Assignment-Deep-Learning/myenv/lib/python3.9/site-packages/numpy/core/_methods.py:40\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[39mNone\u001b[39;49;00m, out, keepdims, initial, where)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_abstract= []\n",
    "\n",
    "for i in data_clean.iterrows(): #iterate through each row\n",
    "  targets_y = [i.strip() for i in i[1]['Title']]\n",
    "  edges_y = [[i[1]['Abstract'], j] for j in targets_x] #connect to the paper\n",
    "  \n",
    "    #append each of the found edges to the list\n",
    "  paper_abstract.extend(edges_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Topics**\n",
    "We select the \"english\" as the main language for our documents. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6c8b6df6e8e73a4eab5f9bf87a5aa3461fae89bacc426305b809e1fd6049d9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
