{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=400,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create  a chatbot with question - user input , and context - set of instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction_base_message =\"You are an AI assistant that helps people find information about IBM and responds in rhyme.\\\n",
    "#                         -Only answer questions related to IBM \\\n",
    "#                         if the user asks a  question , which you do not know , the answer to that question should be - I do not know.\\\n",
    "#                         -Example1: \\\n",
    "#                         User :Who was the first CEO of IBM?\\\n",
    "#                         Assistant :Thomas John Watson Sr\\\n",
    "#                         Example2:\\\n",
    "#                         User:What was the total employee strength of IBM in 2022?\\\n",
    "#                         Assistant:288000\"     \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_base_message =\"You are an AI assistant that helps people find information about IBM and responds in rhyme.\\\n",
    "                          if the user asks a  question , which you do not know , the answer to that question should be - I do not know.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## type the user_message or question_input \n",
    "\n",
    "question_input =\"What is the generative AI product for IBM?\"\n",
    "context = \"\\nOnly answer questions related to IBM with perspective to 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frame the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = instruction_base_message+context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_messages =  [  \n",
    "{'role':'system', 'content':system_message},\n",
    "{'role':'user', 'content':question_input}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM's generative AI product is known as IBM Watson Studio. \n",
      "It helps businesses analyze data and make decisions that are astute. \n",
      "With its machine learning capabilities, it can create models and predict, \n",
      "Empowering organizations to gain insights and stay ahead, that's the effect.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(prompt_messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using model for open ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Nice to meet you, John! What kind of software engineering do you do?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello, my name is John and I am a software engineer.\"\n",
    "model = \"text-davinci-003\"\n",
    "response = openai.Completion.create(engine=model, prompt=prompt, max_tokens=50)\n",
    "\n",
    "generated_text = response.choices[0].text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing  text generation using openai -use case of prompt engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumps over the lazy dog\n",
      "\n",
      "The quick brown fox jumped over the lazy dog with ease. He then proceeded to trot away, feeling quite pleased with himself.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The quick brown fox\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Translation -use case of prompt engineering\n",
    "The OpenAI API also supports language translation. You can provide a piece of text in one language and ask the API to translate it into another language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, ¿cómo estás?\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, how are you?\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=f\"Translate from English to Spanish: {text}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "translation = response.choices[0].text.strip()\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"I love ice cream!\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-002\",\n",
    "  prompt=f\"Sentiment analysis: {text}\",\n",
    "  max_tokens=1\n",
    ")\n",
    "\n",
    "sentiment = response.choices[0].text.strip()\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question -answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Albert Einstein was a German-born theoretical physicist who developed the theory of relativity.\"\n",
    "question = \"Where was Albert Einstein born?\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=f\"Question answering:\\nContext: {context}\\nQuestion: {question}\",\n",
    "  max_tokens=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Albert Einstein was born in Ulm, Germany.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer = response.choices[0].text.strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Whisper is an automatic speech recognition (ASR) system trained on 680,000 hours of multilingual and multitask supervised data collected from the web. We show that the use of such a large and diverse dataset leads to improved robustness to accents, background noise and technical language. Moreover, it enables transcription in multiple languages, as well as translation from those languages into English. We are open-sourcing models and inference code to serve as a foundation for building useful applications and for further research on robust speech processing.\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=f\"Summarize:\\n{text}\",\n",
    "  max_tokens=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article discusses the Whisper system, an automatic speech recognition system trained on 680,000 hours of multilingual and multitask data. The system is shown to be robust to accent, noise and technical language and is able to transcribe\n"
     ]
    }
   ],
   "source": [
    "summary = response.choices[0].text.strip()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Python program to sort a list of numbers in ascending order\n",
      "\n",
      "# list of numbers \n",
      "list1 = [3, 5, 1, 8, 6, 0, 9, 4, 2, 7]\n",
      "\n",
      "# sorting the list \n",
      "list1.sort() \n",
      "\n",
      "# printing the sorted list \n",
      "print(\"Sorted list:\",list1)\n"
     ]
    }
   ],
   "source": [
    "description = \"Create a Python script to sort a list of numbers in ascending order.\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=f\"Code generation:\\n{description}\",\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "code = response.choices[0].text.strip()\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbots\n",
    "The OpenAI API can also be used for building chatbots. You can provide some context and a user’s message, and the API will generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Representative: Hi there! What seems to be the issue?\n"
     ]
    }
   ],
   "source": [
    "context = \"You are chatting with a customer service representative.\"\n",
    "message = \"Hi, I have a problem with my account.\"\n",
    "response = openai.Completion.create(\n",
    "  #engine=\"gpt-3.5-turbo\",\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=f\"Chat:\\n{context}\\nUser: {message}\\n\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "reply = response.choices[0].text.strip()\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
