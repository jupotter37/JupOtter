{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e9eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fingerprint_enhancer  # Load the library\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import imageio\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "import h5py, pickle\n",
    "from random import randint, choice, shuffle, sample\n",
    "from itertools import product\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy import signal \n",
    "\n",
    "import os, os.path, time\n",
    "import time as time\n",
    "import timeit\n",
    "\n",
    "from sys import argv\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load other functions ==================================================\n",
    "import glob\n",
    "import csv\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import math as math\n",
    "# folder = \"E:\\BTP\\SOCOFing\\Real\"\n",
    "folder = \"E:\\BTP\\SOCOFing\\Test\"\n",
    "# alt_folder = \"E:\\BTP\\SOCOFing\\AltTest\"\n",
    "alt_folder = \"E:\\BTP\\SOCOFing\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0354c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerprintImageEnhancer(object):\n",
    "    def __init__(self):\n",
    "        self.ridge_segment_blksze = 16\n",
    "        self.ridge_segment_thresh = 0.1\n",
    "        self.gradient_sigma = 1\n",
    "        self.block_sigma = 7\n",
    "        self.orient_smooth_sigma = 7\n",
    "        self.ridge_freq_blksze = 38\n",
    "        self.ridge_freq_windsze = 5\n",
    "        self.min_wave_length = 5\n",
    "        self.max_wave_length = 15\n",
    "        self.kx = 0.65\n",
    "        self.ky = 0.65\n",
    "        self.angleInc = 3\n",
    "        self.ridge_filter_thresh = -3\n",
    "\n",
    "\n",
    "        self._mask = []\n",
    "        self._normim = []\n",
    "        self._orientim = []\n",
    "        self._mean_freq = []\n",
    "        self._median_freq = []\n",
    "        self._freq = []\n",
    "        self._freqim = []\n",
    "        self._binim = []\n",
    "\n",
    "    def __normalise(self, img, mean, std):\n",
    "        if(np.std(img) == 0):\n",
    "            raise ValueError(\"Image standard deviation is 0. Please review image again\")\n",
    "        normed = (img - np.mean(img)) / (np.std(img))\n",
    "        return (normed)\n",
    "\n",
    "    def __ridge_segment(self, img):\n",
    "        # RIDGESEGMENT - Normalises fingerprint image and segments ridge region\n",
    "        #\n",
    "        # Function identifies ridge regions of a fingerprint image and returns a\n",
    "        # mask identifying this region.  It also normalises the intesity values of\n",
    "        # the image so that the ridge regions have zero mean, unit standard\n",
    "        # deviation.\n",
    "        #\n",
    "        # This function breaks the image up into blocks of size blksze x blksze and\n",
    "        # evaluates the standard deviation in each region.  If the standard\n",
    "        # deviation is above the threshold it is deemed part of the fingerprint.\n",
    "        # Note that the image is normalised to have zero mean, unit standard\n",
    "        # deviation prior to performing this process so that the threshold you\n",
    "        # specify is relative to a unit standard deviation.\n",
    "        #\n",
    "        # Usage:   [normim, mask, maskind] = ridgesegment(im, blksze, thresh)\n",
    "        #\n",
    "        # Arguments:   im     - Fingerprint image to be segmented.\n",
    "        #              blksze - Block size over which the the standard\n",
    "        #                       deviation is determined (try a value of 16).\n",
    "        #              thresh - Threshold of standard deviation to decide if a\n",
    "        #                       block is a ridge region (Try a value 0.1 - 0.2)\n",
    "        #\n",
    "        # Ouput:     normim - Image where the ridge regions are renormalised to\n",
    "        #                       have zero mean, unit standard deviation.\n",
    "        #              mask   - Mask indicating ridge-like regions of the image,\n",
    "        #                       0 for non ridge regions, 1 for ridge regions.\n",
    "        #              maskind - Vector of indices of locations within the mask.\n",
    "        #\n",
    "        # Suggested values for a 500dpi fingerprint image:\n",
    "        #\n",
    "        #   [normim, mask, maskind] = ridgesegment(im, 16, 0.1)\n",
    "        #\n",
    "        # See also: RIDGEORIENT, RIDGEFREQ, RIDGEFILTER\n",
    "\n",
    "        ### REFERENCES\n",
    "\n",
    "        # Peter Kovesi\n",
    "        # School of Computer Science & Software Engineering\n",
    "        # The University of Western Australia\n",
    "        # pk at csse uwa edu au\n",
    "        # http://www.csse.uwa.edu.au/~pk\n",
    "        rows, cols = img.shape\n",
    "        im = self.__normalise(img, 0, 1)  # normalise to get zero mean and unit standard deviation\n",
    "\n",
    "        new_rows = np.int(self.ridge_segment_blksze * np.ceil((np.float(rows)) / (np.float(self.ridge_segment_blksze))))\n",
    "        new_cols = np.int(self.ridge_segment_blksze * np.ceil((np.float(cols)) / (np.float(self.ridge_segment_blksze))))\n",
    "\n",
    "        padded_img = np.zeros((new_rows, new_cols))\n",
    "        stddevim = np.zeros((new_rows, new_cols))\n",
    "        padded_img[0:rows][:, 0:cols] = im\n",
    "        for i in range(0, new_rows, self.ridge_segment_blksze):\n",
    "            for j in range(0, new_cols, self.ridge_segment_blksze):\n",
    "                block = padded_img[i:i + self.ridge_segment_blksze][:, j:j + self.ridge_segment_blksze]\n",
    "\n",
    "                stddevim[i:i + self.ridge_segment_blksze][:, j:j + self.ridge_segment_blksze] = np.std(block) * np.ones(block.shape)\n",
    "\n",
    "        stddevim = stddevim[0:rows][:, 0:cols]\n",
    "        self._mask = stddevim > self.ridge_segment_thresh\n",
    "        mean_val = np.mean(im[self._mask])\n",
    "        std_val = np.std(im[self._mask])\n",
    "        self._normim = (im - mean_val) / (std_val)\n",
    "\n",
    "    def __ridge_orient(self):\n",
    "        # RIDGEORIENT - Estimates the local orientation of ridges in a fingerprint\n",
    "        #\n",
    "        # Usage:  [orientim, reliability, coherence] = ridgeorientation(im, gradientsigma,...\n",
    "        #                                             blocksigma, ...\n",
    "        #                                             orientsmoothsigma)\n",
    "        #\n",
    "        # Arguments:  im                - A normalised input image.\n",
    "        #             gradientsigma     - Sigma of the derivative of Gaussian\n",
    "        #                                 used to compute image gradients.\n",
    "        #             blocksigma        - Sigma of the Gaussian weighting used to\n",
    "        #                                 sum the gradient moments.\n",
    "        #             orientsmoothsigma - Sigma of the Gaussian used to smooth\n",
    "        #                                 the final orientation vector field.\n",
    "        #                                 Optional: if ommitted it defaults to 0\n",
    "        #\n",
    "        # Output:    orientim          - The orientation image in radians.\n",
    "        #                                 Orientation values are +ve clockwise\n",
    "        #                                 and give the direction *along* the\n",
    "        #                                 ridges.\n",
    "        #             reliability       - Measure of the reliability of the\n",
    "        #                                 orientation measure.  This is a value\n",
    "        #                                 between 0 and 1. I think a value above\n",
    "        #                                 about 0.5 can be considered 'reliable'.\n",
    "        #                                 reliability = 1 - Imin./(Imax+.001);\n",
    "        #             coherence         - A measure of the degree to which the local\n",
    "        #                                 area is oriented.\n",
    "        #                                 coherence = ((Imax-Imin)./(Imax+Imin)).^2;\n",
    "        #\n",
    "        # With a fingerprint image at a 'standard' resolution of 500dpi suggested\n",
    "        # parameter values might be:\n",
    "        #\n",
    "        #    [orientim, reliability] = ridgeorient(im, 1, 3, 3);\n",
    "        #\n",
    "        # See also: RIDGESEGMENT, RIDGEFREQ, RIDGEFILTER\n",
    "\n",
    "        ### REFERENCES\n",
    "\n",
    "        # May 2003      Original version by Raymond Thai,\n",
    "        # January 2005  Reworked by Peter Kovesi\n",
    "        # October 2011  Added coherence computation and orientsmoothsigma made optional\n",
    "        #\n",
    "        # School of Computer Science & Software Engineering\n",
    "        # The University of Western Australia\n",
    "        # pk at csse uwa edu au\n",
    "        # http://www.csse.uwa.edu.au/~pk\n",
    "\n",
    "        rows,cols = self._normim.shape\n",
    "        #Calculate image gradients.\n",
    "        sze = np.fix(6*self.gradient_sigma)\n",
    "        if np.remainder(sze,2) == 0:\n",
    "            sze = sze+1\n",
    "\n",
    "        gauss = cv2.getGaussianKernel(np.int(sze),self.gradient_sigma)\n",
    "        f = gauss * gauss.T\n",
    "\n",
    "        fy,fx = np.gradient(f)                               #Gradient of Gaussian\n",
    "\n",
    "        Gx = signal.convolve2d(self._normim, fx, mode='same')\n",
    "        Gy = signal.convolve2d(self._normim, fy, mode='same')\n",
    "\n",
    "        Gxx = np.power(Gx,2)\n",
    "        Gyy = np.power(Gy,2)\n",
    "        Gxy = Gx*Gy\n",
    "\n",
    "        #Now smooth the covariance data to perform a weighted summation of the data.\n",
    "        sze = np.fix(6*self.block_sigma)\n",
    "\n",
    "        gauss = cv2.getGaussianKernel(np.int(sze), self.block_sigma)\n",
    "        f = gauss * gauss.T\n",
    "\n",
    "        Gxx = ndimage.convolve(Gxx,f)\n",
    "        Gyy = ndimage.convolve(Gyy,f)\n",
    "        Gxy = 2*ndimage.convolve(Gxy,f)\n",
    "\n",
    "        # Analytic solution of principal direction\n",
    "        denom = np.sqrt(np.power(Gxy,2) + np.power((Gxx - Gyy),2)) + np.finfo(float).eps\n",
    "\n",
    "        sin2theta = Gxy/denom                   # Sine and cosine of doubled angles\n",
    "        cos2theta = (Gxx-Gyy)/denom\n",
    "\n",
    "\n",
    "        if self.orient_smooth_sigma:\n",
    "            sze = np.fix(6*self.orient_smooth_sigma)\n",
    "            if np.remainder(sze,2) == 0:\n",
    "                sze = sze+1\n",
    "            gauss = cv2.getGaussianKernel(np.int(sze), self.orient_smooth_sigma)\n",
    "            f = gauss * gauss.T\n",
    "            cos2theta = ndimage.convolve(cos2theta,f)                   # Smoothed sine and cosine of\n",
    "            sin2theta = ndimage.convolve(sin2theta,f)                   # doubled angles\n",
    "\n",
    "        self._orientim = np.pi/2 + np.arctan2(sin2theta,cos2theta)/2\n",
    "\n",
    "    def __ridge_freq(self):\n",
    "        # RIDGEFREQ - Calculates a ridge frequency image\n",
    "        #\n",
    "        # Function to estimate the fingerprint ridge frequency across a\n",
    "        # fingerprint image. This is done by considering blocks of the image and\n",
    "        # determining a ridgecount within each block by a call to FREQEST.\n",
    "        #\n",
    "        # Usage:\n",
    "        #  [freqim, medianfreq] =  ridgefreq(im, mask, orientim, blksze, windsze, ...\n",
    "        #                                    minWaveLength, maxWaveLength)\n",
    "        #\n",
    "        # Arguments:\n",
    "        #         im       - Image to be processed.\n",
    "        #         mask     - Mask defining ridge regions (obtained from RIDGESEGMENT)\n",
    "        #         orientim - Ridge orientation image (obtained from RIDGORIENT)\n",
    "        #         blksze   - Size of image block to use (say 32)\n",
    "        #         windsze  - Window length used to identify peaks. This should be\n",
    "        #                    an odd integer, say 3 or 5.\n",
    "        #         minWaveLength,  maxWaveLength - Minimum and maximum ridge\n",
    "        #                     wavelengths, in pixels, considered acceptable.\n",
    "        #\n",
    "        # Output:\n",
    "        #         freqim     - An image  the same size as im with  values set to\n",
    "        #                      the estimated ridge spatial frequency within each\n",
    "        #                      image block.  If a  ridge frequency cannot be\n",
    "        #                      found within a block, or cannot be found within the\n",
    "        #                      limits set by min and max Wavlength freqim is set\n",
    "        #                      to zeros within that block.\n",
    "        #         medianfreq - Median frequency value evaluated over all the\n",
    "        #                      valid regions of the image.\n",
    "        #\n",
    "        # Suggested parameters for a 500dpi fingerprint image\n",
    "        #   [freqim, medianfreq] = ridgefreq(im,orientim, 32, 5, 5, 15);\n",
    "        #\n",
    "\n",
    "        # See also: RIDGEORIENT, FREQEST, RIDGESEGMENT\n",
    "\n",
    "        # Reference:\n",
    "        # Hong, L., Wan, Y., and Jain, A. K. Fingerprint image enhancement:\n",
    "        # Algorithm and performance evaluation. IEEE Transactions on Pattern\n",
    "        # Analysis and Machine Intelligence 20, 8 (1998), 777 789.\n",
    "\n",
    "        ### REFERENCES\n",
    "\n",
    "        # Peter Kovesi\n",
    "        # School of Computer Science & Software Engineering\n",
    "        # The University of Western Australia\n",
    "        # pk at csse uwa edu au\n",
    "        # http://www.csse.uwa.edu.au/~pk\n",
    "\n",
    "        rows, cols = self._normim.shape\n",
    "        freq = np.zeros((rows, cols))\n",
    "\n",
    "        for r in range(0, rows - self.ridge_freq_blksze, self.ridge_freq_blksze):\n",
    "            for c in range(0, cols - self.ridge_freq_blksze, self.ridge_freq_blksze):\n",
    "                blkim = self._normim[r:r + self.ridge_freq_blksze][:, c:c + self.ridge_freq_blksze]\n",
    "                blkor = self._orientim[r:r + self.ridge_freq_blksze][:, c:c + self.ridge_freq_blksze]\n",
    "\n",
    "                freq[r:r + self.ridge_freq_blksze][:, c:c + self.ridge_freq_blksze] = self.__frequest(blkim, blkor)\n",
    "\n",
    "        self._freq = freq * self._mask\n",
    "        freq_1d = np.reshape(self._freq, (1, rows * cols))\n",
    "        ind = np.where(freq_1d > 0)\n",
    "\n",
    "        ind = np.array(ind)\n",
    "        ind = ind[1, :]\n",
    "\n",
    "        non_zero_elems_in_freq = freq_1d[0][ind]\n",
    "\n",
    "        self._mean_freq = np.mean(non_zero_elems_in_freq)\n",
    "        self._median_freq = np.median(non_zero_elems_in_freq)  # does not work properly\n",
    "\n",
    "        self._freq = self._mean_freq * self._mask\n",
    "\n",
    "    def __frequest(self, blkim, blkor):\n",
    "        # FREQEST - Estimate fingerprint ridge frequency within image block\n",
    "        #\n",
    "        # Function to estimate the fingerprint ridge frequency within a small block\n",
    "        # of a fingerprint image.  This function is used by RIDGEFREQ\n",
    "        #\n",
    "        # Usage:\n",
    "        #  freqim =  freqest(im, orientim, windsze, minWaveLength, maxWaveLength)\n",
    "        #\n",
    "        # Arguments:\n",
    "        #         im       - Image block to be processed.\n",
    "        #         orientim - Ridge orientation image of image block.\n",
    "        #         windsze  - Window length used to identify peaks. This should be\n",
    "        #                    an odd integer, say 3 or 5.\n",
    "        #         minWaveLength,  maxWaveLength - Minimum and maximum ridge\n",
    "        #                     wavelengths, in pixels, considered acceptable.\n",
    "        #\n",
    "        # Output:\n",
    "        #         freqim    - An image block the same size as im with all values\n",
    "        #                     set to the estimated ridge spatial frequency.  If a\n",
    "        #                     ridge frequency cannot be found, or cannot be found\n",
    "        #                     within the limits set by min and max Wavlength\n",
    "        #                     freqim is set to zeros.\n",
    "        #\n",
    "        # Suggested parameters for a 500dpi fingerprint image\n",
    "        #   freqim = freqest(im,orientim, 5, 5, 15);\n",
    "        #\n",
    "        # See also:  RIDGEFREQ, RIDGEORIENT, RIDGESEGMENT\n",
    "\n",
    "        ### REFERENCES\n",
    "\n",
    "        # Peter Kovesi\n",
    "        # School of Computer Science & Software Engineering\n",
    "        # The University of Western Australia\n",
    "        # pk at csse uwa edu au\n",
    "        # http://www.csse.uwa.edu.au/~pk\n",
    "\n",
    "        rows, cols = np.shape(blkim)\n",
    "\n",
    "        # Find mean orientation within the block. This is done by averaging the\n",
    "        # sines and cosines of the doubled angles before reconstructing the\n",
    "        # angle again.  This avoids wraparound problems at the origin.\n",
    "\n",
    "        cosorient = np.mean(np.cos(2 * blkor))\n",
    "        sinorient = np.mean(np.sin(2 * blkor))\n",
    "        orient = math.atan2(sinorient, cosorient) / 2\n",
    "\n",
    "        # Rotate the image block so that the ridges are vertical\n",
    "\n",
    "        # ROT_mat = cv2.getRotationMatrix2D((cols/2,rows/2),orient/np.pi*180 + 90,1)\n",
    "        # rotim = cv2.warpAffine(im,ROT_mat,(cols,rows))\n",
    "        rotim = scipy.ndimage.rotate(blkim, orient / np.pi * 180 + 90, axes=(1, 0), reshape=False, order=3,\n",
    "                                     mode='nearest')\n",
    "\n",
    "        # Now crop the image so that the rotated image does not contain any\n",
    "        # invalid regions.  This prevents the projection down the columns\n",
    "        # from being mucked up.\n",
    "\n",
    "        cropsze = int(np.fix(rows / np.sqrt(2)))\n",
    "        offset = int(np.fix((rows - cropsze) / 2))\n",
    "        rotim = rotim[offset:offset + cropsze][:, offset:offset + cropsze]\n",
    "\n",
    "        # Sum down the columns to get a projection of the grey values down\n",
    "        # the ridges.\n",
    "\n",
    "        proj = np.sum(rotim, axis=0)\n",
    "        dilation = scipy.ndimage.grey_dilation(proj, self.ridge_freq_windsze, structure=np.ones(self.ridge_freq_windsze))\n",
    "\n",
    "        temp = np.abs(dilation - proj)\n",
    "\n",
    "        peak_thresh = 2\n",
    "\n",
    "        maxpts = (temp < peak_thresh) & (proj > np.mean(proj))\n",
    "        maxind = np.where(maxpts)\n",
    "\n",
    "        rows_maxind, cols_maxind = np.shape(maxind)\n",
    "\n",
    "        # Determine the spatial frequency of the ridges by divinding the\n",
    "        # distance between the 1st and last peaks by the (No of peaks-1). If no\n",
    "        # peaks are detected, or the wavelength is outside the allowed bounds,\n",
    "        # the frequency image is set to 0\n",
    "\n",
    "        if (cols_maxind < 2):\n",
    "            return(np.zeros(blkim.shape))\n",
    "        else:\n",
    "            NoOfPeaks = cols_maxind\n",
    "            waveLength = (maxind[0][cols_maxind - 1] - maxind[0][0]) / (NoOfPeaks - 1)\n",
    "            if waveLength >= self.min_wave_length and waveLength <= self.max_wave_length:\n",
    "                return(1 / np.double(waveLength) * np.ones(blkim.shape))\n",
    "            else:\n",
    "                return(np.zeros(blkim.shape))\n",
    "\n",
    "    def __ridge_filter(self):\n",
    "        # RIDGEFILTER - enhances fingerprint image via oriented filters\n",
    "        #\n",
    "        # Function to enhance fingerprint image via oriented filters\n",
    "        #\n",
    "        # Usage:\n",
    "        #  newim =  ridgefilter(im, orientim, freqim, kx, ky, showfilter)\n",
    "        #\n",
    "        # Arguments:\n",
    "        #         im       - Image to be processed.\n",
    "        #         orientim - Ridge orientation image, obtained from RIDGEORIENT.\n",
    "        #         freqim   - Ridge frequency image, obtained from RIDGEFREQ.\n",
    "        #         kx, ky   - Scale factors specifying the filter sigma relative\n",
    "        #                    to the wavelength of the filter.  This is done so\n",
    "        #                    that the shapes of the filters are invariant to the\n",
    "        #                    scale.  kx controls the sigma in the x direction\n",
    "        #                    which is along the filter, and hence controls the\n",
    "        #                    bandwidth of the filter.  ky controls the sigma\n",
    "        #                    across the filter and hence controls the\n",
    "        #                    orientational selectivity of the filter. A value of\n",
    "        #                    0.5 for both kx and ky is a good starting point.\n",
    "        #         showfilter - An optional flag 0/1.  When set an image of the\n",
    "        #                      largest scale filter is displayed for inspection.\n",
    "        #\n",
    "        # Output:\n",
    "        #         newim    - The enhanced image\n",
    "        #\n",
    "        # See also: RIDGEORIENT, RIDGEFREQ, RIDGESEGMENT\n",
    "\n",
    "        # Reference:\n",
    "        # Hong, L., Wan, Y., and Jain, A. K. Fingerprint image enhancement:\n",
    "        # Algorithm and performance evaluation. IEEE Transactions on Pattern\n",
    "        # Analysis and Machine Intelligence 20, 8 (1998), 777 789.\n",
    "\n",
    "        ### REFERENCES\n",
    "\n",
    "        # Peter Kovesi\n",
    "        # School of Computer Science & Software Engineering\n",
    "        # The University of Western Australia\n",
    "        # pk at csse uwa edu au\n",
    "        # http://www.csse.uwa.edu.au/~pk\n",
    "\n",
    "        im = np.double(self._normim)\n",
    "        rows, cols = im.shape\n",
    "        newim = np.zeros((rows, cols))\n",
    "\n",
    "        freq_1d = np.reshape(self._freq, (1, rows * cols))\n",
    "        ind = np.where(freq_1d > 0)\n",
    "\n",
    "        ind = np.array(ind)\n",
    "        ind = ind[1, :]\n",
    "\n",
    "        # Round the array of frequencies to the nearest 0.01 to reduce the\n",
    "        # number of distinct frequencies we have to deal with.\n",
    "\n",
    "        non_zero_elems_in_freq = freq_1d[0][ind]\n",
    "        non_zero_elems_in_freq = np.double(np.round((non_zero_elems_in_freq * 100))) / 100\n",
    "\n",
    "        unfreq = np.unique(non_zero_elems_in_freq)\n",
    "\n",
    "        # Generate filters corresponding to these distinct frequencies and\n",
    "        # orientations in 'angleInc' increments.\n",
    "\n",
    "        sigmax = 1 / unfreq[0] * self.kx\n",
    "        sigmay = 1 / unfreq[0] * self.ky\n",
    "\n",
    "        sze = np.int(np.round(3 * np.max([sigmax, sigmay])))\n",
    "\n",
    "        x, y = np.meshgrid(np.linspace(-sze, sze, (2 * sze + 1)), np.linspace(-sze, sze, (2 * sze + 1)))\n",
    "\n",
    "        reffilter = np.exp(-(((np.power(x, 2)) / (sigmax * sigmax) + (np.power(y, 2)) / (sigmay * sigmay)))) * np.cos(\n",
    "            2 * np.pi * unfreq[0] * x)        # this is the original gabor filter\n",
    "\n",
    "        filt_rows, filt_cols = reffilter.shape\n",
    "\n",
    "        angleRange = np.int(180 / self.angleInc)\n",
    "\n",
    "        gabor_filter = np.array(np.zeros((angleRange, filt_rows, filt_cols)))\n",
    "\n",
    "        for o in range(0, angleRange):\n",
    "            # Generate rotated versions of the filter.  Note orientation\n",
    "            # image provides orientation *along* the ridges, hence +90\n",
    "            # degrees, and imrotate requires angles +ve anticlockwise, hence\n",
    "            # the minus sign.\n",
    "\n",
    "            rot_filt = scipy.ndimage.rotate(reffilter, -(o * self.angleInc + 90), reshape=False)\n",
    "            gabor_filter[o] = rot_filt\n",
    "\n",
    "        # Find indices of matrix points greater than maxsze from the image\n",
    "        # boundary\n",
    "\n",
    "        maxsze = int(sze)\n",
    "\n",
    "        temp = self._freq > 0\n",
    "        validr, validc = np.where(temp)\n",
    "\n",
    "        temp1 = validr > maxsze\n",
    "        temp2 = validr < rows - maxsze\n",
    "        temp3 = validc > maxsze\n",
    "        temp4 = validc < cols - maxsze\n",
    "\n",
    "        final_temp = temp1 & temp2 & temp3 & temp4\n",
    "\n",
    "        finalind = np.where(final_temp)\n",
    "\n",
    "        # Convert orientation matrix values from radians to an index value\n",
    "        # that corresponds to round(degrees/angleInc)\n",
    "\n",
    "        maxorientindex = np.round(180 / self.angleInc)\n",
    "        orientindex = np.round(self._orientim / np.pi * 180 / self.angleInc)\n",
    "\n",
    "        # do the filtering\n",
    "        for i in range(0, rows):\n",
    "            for j in range(0, cols):\n",
    "                if (orientindex[i][j] < 1):\n",
    "                    orientindex[i][j] = orientindex[i][j] + maxorientindex\n",
    "                if (orientindex[i][j] > maxorientindex):\n",
    "                    orientindex[i][j] = orientindex[i][j] - maxorientindex\n",
    "        finalind_rows, finalind_cols = np.shape(finalind)\n",
    "        sze = int(sze)\n",
    "        for k in range(0, finalind_cols):\n",
    "            r = validr[finalind[0][k]]\n",
    "            c = validc[finalind[0][k]]\n",
    "\n",
    "            img_block = im[r - sze:r + sze + 1][:, c - sze:c + sze + 1]\n",
    "\n",
    "            newim[r][c] = np.sum(img_block * gabor_filter[int(orientindex[r][c]) - 1])\n",
    "\n",
    "        self._binim = newim < self.ridge_filter_thresh\n",
    "\n",
    "    def save_enhanced_image(self, path):\n",
    "        # saves the enhanced image at the specified path\n",
    "        cv2.imwrite(path, (255 * self._binim))\n",
    "\n",
    "    def enhance(self, img, resize=True):\n",
    "        # main function to enhance the image.\n",
    "        # calls all other subroutines\n",
    "\n",
    "        if(resize):\n",
    "            rows, cols = np.shape(img)\n",
    "            aspect_ratio = np.double(rows) / np.double(cols)\n",
    "\n",
    "            new_rows = 350                      # randomly selected number\n",
    "            new_cols = new_rows / aspect_ratio\n",
    "\n",
    "            img = cv2.resize(img, (np.int(new_cols), np.int(new_rows)))\n",
    "\n",
    "        self.__ridge_segment(img)   # normalise the image and find a ROI\n",
    "        self.__ridge_orient()       # compute orientation image\n",
    "        self.__ridge_freq()         # compute major frequency of ridges\n",
    "        self.__ridge_filter()       # filter the image using oriented gabor filter\n",
    "        return(self._binim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327f51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:500: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  img = cv2.resize(img, (np.int(new_cols), np.int(new_rows)))\n",
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:78: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_rows = np.int(self.ridge_segment_blksze * np.ceil((np.float(rows)) / (np.float(self.ridge_segment_blksze))))\n",
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:78: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_rows = np.int(self.ridge_segment_blksze * np.ceil((np.float(rows)) / (np.float(self.ridge_segment_blksze))))\n",
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:79: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_cols = np.int(self.ridge_segment_blksze * np.ceil((np.float(cols)) / (np.float(self.ridge_segment_blksze))))\n",
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:79: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_cols = np.int(self.ridge_segment_blksze * np.ceil((np.float(cols)) / (np.float(self.ridge_segment_blksze))))\n",
      "C:\\Users\\Arpit\\AppData\\Local\\Temp\\ipykernel_14136\\2850205710.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  gauss = cv2.getGaussianKernel(np.int(sze),self.gradient_sigma)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(np.shape(img))\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_enhancer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menhance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     14\u001b[0m keypoints_1, descriptors_1 \u001b[38;5;241m=\u001b[39m sift\u001b[38;5;241m.\u001b[39mdetectAndCompute(img, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [2], line 503\u001b[0m, in \u001b[0;36mFingerprintImageEnhancer.enhance\u001b[1;34m(self, img, resize)\u001b[0m\n\u001b[0;32m    500\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (np\u001b[38;5;241m.\u001b[39mint(new_cols), np\u001b[38;5;241m.\u001b[39mint(new_rows)))\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ridge_segment(img)   \u001b[38;5;66;03m# normalise the image and find a ROI\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__ridge_orient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# compute orientation image\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ridge_freq()         \u001b[38;5;66;03m# compute major frequency of ridges\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ridge_filter()       \u001b[38;5;66;03m# filter the image using oriented gabor filter\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [2], line 154\u001b[0m, in \u001b[0;36mFingerprintImageEnhancer.__ridge_orient\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    150\u001b[0m f \u001b[38;5;241m=\u001b[39m gauss \u001b[38;5;241m*\u001b[39m gauss\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    152\u001b[0m fy,fx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgradient(f)                               \u001b[38;5;66;03m#Gradient of Gaussian\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m Gx \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241m.\u001b[39mconvolve2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normim, fx, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    155\u001b[0m Gy \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mconvolve2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normim, fy, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    157\u001b[0m Gxx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(Gx,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'signal' is not defined"
     ]
    }
   ],
   "source": [
    "SIFT_DATA = []\n",
    "#   sift = cv2.xfeatures2d.SIFT_create()\n",
    "sift = cv2.SIFT_create()\n",
    "image_enhancer = FingerprintImageEnhancer() \n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    img = cv2.imread(os.path.join(folder,filename))\n",
    "#     plt.imshow(img,cmap='gray')\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # print(np.shape(img))\n",
    "    img = image_enhancer.enhance(img)\n",
    "    img = np.array(img, dtype=np.uint8)*255\n",
    "    \n",
    "    keypoints_1, descriptors_1 = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    SIFT_DATA.append([filename, keypoints_1, descriptors_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c3bc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num = random.randint(0, len(os.listdir(alt_folder)))\n",
    "# num = 1\n",
    "sample_filename = os.listdir(alt_folder)[num]\n",
    "sample_img = cv2.imread(os.path.join(alt_folder,sample_filename))\n",
    "\n",
    "bestscore = 0\n",
    "result = None\n",
    "mp = None\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adedab60",
   "metadata": {},
   "source": [
    "The images on the left side is the image that is trying to be found. And the image on the right side is the image that the algorithm matches the left side image in database. In this code first all the feature points of the images are being extracted and are stored in a variable after that we are manually searching for the bestmatch. this taken O(n) time for one image.\n",
    "### Matching images without any transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075de70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_img = fingerprint_enhancer.enhance_Fingerprint(sample_img)\n",
    "sample_img = cv2.cvtColor(sample_img,cv2.COLOR_BGR2GRAY)\n",
    "sample_img = image_enhancer.enhance(sample_img)\n",
    "sample_img = np.array(sample_img, dtype=np.uint8)*255\n",
    "keypoints_2, descriptors_2 = sift.detectAndCompute(sample_img, None)\n",
    "\n",
    "for i in range(len(SIFT_DATA)):\n",
    "#     print(result)\n",
    "\n",
    "    matches = cv2.FlannBasedMatcher(dict(algorithm=1, trees=10),\n",
    "                                    dict()).knnMatch(SIFT_DATA[i][2], descriptors_2, k=2)\n",
    "    match_points = []\n",
    "    for p, q in matches:\n",
    "        if p.distance < 0.1*q.distance:\n",
    "            match_points.append(p)\n",
    "\n",
    "    keypoints = min(len(SIFT_DATA[i][1]), len(keypoints_2))\n",
    "    results.append(len(match_points)/keypoints*100)\n",
    "    if len(match_points)/keypoints*100 > bestscore:\n",
    "        bestscore = len(match_points)/keypoints*100\n",
    "        result, mp = i, match_points\n",
    "\n",
    "print(results)\n",
    "print(str(result) + \" \" + str(num))\n",
    "print(\" Score: \" + str(bestscore))\n",
    "\n",
    "out = cv2.imread(os.path.join(folder, SIFT_DATA[result][0]))\n",
    "f = plt.figure(figsize=(8,4))\n",
    "sp = f.add_subplot(1, 2, 1)\n",
    "plt.imshow(sample_img,cmap='gray')\n",
    "sp = f.add_subplot(1, 2, 2)\n",
    "plt.imshow(out,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652c2cf",
   "metadata": {},
   "source": [
    "### Shifting Images and matching it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdad631",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols = sample_img.shape[0], sample_img.shape[1]\n",
    "\n",
    "for j in range(0, 26, 5):\n",
    "    \n",
    "    bestscore = -1\n",
    "    result = None\n",
    "    \n",
    "    M = np.float32([[1,0,rows*(j/100)],[0,1,cols*(j/100)]])\n",
    "    changed_img = cv2.warpAffine(sample_img,M,(cols,rows))\n",
    "    changed_img = cv2.cvtColor(changed_img,cv2.COLOR_BGR2GRAY)\n",
    "    changed_img = image_enhancer.enhance(changed_img)\n",
    "    changed_img = np.array(changed_img, dtype=np.uint8)*255\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(changed_img, None)\n",
    "    c_map = None \n",
    "\n",
    "    for i in range(len(SIFT_DATA)):\n",
    "        matches = cv2.FlannBasedMatcher(dict(algorithm=1, trees=10),\n",
    "                                        dict()).knnMatch(SIFT_DATA[i][2], descriptors_2, k=2)\n",
    "        match_points = []\n",
    "        for p, q in matches:\n",
    "            if p.distance < 0.1*q.distance:\n",
    "                match_points.append(p)\n",
    "\n",
    "        keypoints = min(len(SIFT_DATA[i][1]), len(keypoints_2))\n",
    "        if len(match_points)/keypoints*100 > bestscore:\n",
    "            bestscore = len(match_points)/keypoints*100\n",
    "            result = i\n",
    "    \n",
    "#     print(\" Score: \" + str(bestscore) + \" \" + str(result) + \" \" + str(num))\n",
    "    if result==num : \n",
    "        c_map = 'Greens'\n",
    "    else:\n",
    "        c_map = 'Reds'\n",
    "        \n",
    "    out = cv2.imread(os.path.join(folder, SIFT_DATA[result][0]))\n",
    "    f = plt.figure(figsize=(6,3))\n",
    "    sp = f.add_subplot(1, 4, 1)\n",
    "#     plt.imshow(cv2.cvtColor(changed_img, cv2.COLOR_BGR2GRAY),cmap=c_map)\n",
    "    plt.title(\"Moved-{}%   Img no.{}\".format(j, num))\n",
    "    plt.imshow(changed_img ,cmap=c_map)\n",
    "    sp = f.add_subplot(1, 4, 4)\n",
    "    plt.title(\"Score-{0:1.2f}%   Img no.\".format(bestscore)+str(result))\n",
    "    plt.imshow(cv2.cvtColor(out, cv2.COLOR_BGR2GRAY),cmap=c_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a51d77",
   "metadata": {},
   "source": [
    "### Rotating Images and matching it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00084da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 26, 5):\n",
    "    \n",
    "    bestscore = -1\n",
    "    result = None\n",
    "    \n",
    "    M = np.float32([[1,0,rows*(j/100)],[0,1,cols*(j/100)]])\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center=(rows/2, cols/2), angle=3.6*j, scale=1)\n",
    "    changed_img = cv2.warpAffine(src=sample_img, M=rotate_matrix, dsize=(rows, cols))\n",
    "    changed_img = cv2.cvtColor(changed_img,cv2.COLOR_BGR2GRAY)\n",
    "    changed_img = image_enhancer.enhance(changed_img)\n",
    "    changed_img = np.array(changed_img, dtype=np.uint8)*255\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(changed_img, None)\n",
    "    c_map = None \n",
    "\n",
    "    for i in range(len(SIFT_DATA)):\n",
    "        matches = cv2.FlannBasedMatcher(dict(algorithm=1, trees=10),\n",
    "                                        dict()).knnMatch(SIFT_DATA[i][2], descriptors_2, k=2)\n",
    "        match_points = []\n",
    "        for p, q in matches:\n",
    "            if p.distance < 0.1*q.distance:\n",
    "                match_points.append(p)\n",
    "\n",
    "        keypoints = min(len(SIFT_DATA[i][1]), len(keypoints_2))\n",
    "        if len(match_points)/keypoints*100 > bestscore:\n",
    "            bestscore = len(match_points)/keypoints*100\n",
    "            result = i\n",
    "    \n",
    "#     print(\" Score: \" + str(bestscore) + \" \" + str(result) + \" \" + str(num))\n",
    "    if result==num : \n",
    "        c_map = 'Greens'\n",
    "    else:\n",
    "        c_map = 'Reds'\n",
    "        \n",
    "    out = cv2.imread(os.path.join(folder, SIFT_DATA[result][0]))\n",
    "    f = plt.figure(figsize=(6,3))\n",
    "    sp = f.add_subplot(1, 4, 1)\n",
    "#     plt.imshow(cv2.cvtColor(changed_img, cv2.COLOR_BGR2GRAY),cmap=c_map)\n",
    "    plt.title(\"Rotated-{}Â°   Img no.{}\".format(3.6*j, num))\n",
    "    plt.imshow(changed_img ,cmap=c_map)\n",
    "    sp = f.add_subplot(1, 4, 4)\n",
    "    plt.title(\"Score-{0:1.2f}%   Img no.\".format(bestscore)+str(result))\n",
    "    plt.imshow(cv2.cvtColor(out, cv2.COLOR_BGR2GRAY),cmap=c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a9b63757e054ccb441e69fa1b788ddc24d2c146c47900e50c0e26d1c154e777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
